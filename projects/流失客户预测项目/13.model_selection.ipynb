{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df3 = pd.read_pickle('./data/feature_select_fill2_v1_15W.pkl') \n",
    "# train_df3 = pd.read_pickle('./data/raw_merge_top100featuretools50_v1.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bayes调参 模型融合\n",
    "\n",
    "随机抽样+参数扰动训练子模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe, Trials, STATUS_OK, Trials, anneal\n",
    "from functools import partial\n",
    "from hyperopt.fmin import fmin\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score,roc_curve,auc, cohen_kappa_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def model_metrics(model, x, y):\n",
    "    \"\"\" 评估 \"\"\"\n",
    "    yhat = model.predict(x)\n",
    "\n",
    "    return cohen_kappa_score(y, yhat)\n",
    "\n",
    "\n",
    "def bayes_fmin(train_x, test_x, train_y, test_y, eval_iters=50, gap_d=0):\n",
    "    \"\"\"\n",
    "    bayes 优化超参数\n",
    "    \"\"\"\n",
    "    \n",
    "    def lgb_factory(params):\n",
    "        \"\"\"\n",
    "        定义调参目标函数\n",
    "        \"\"\"\n",
    "        fit_params = {\n",
    "            \"boosting\":params[\"boosting\"],\n",
    "            'max_depth':int(params['max_depth']),\n",
    "            'n_estimators':int(params['n_estimators']),\n",
    "            \"learning_rate\":params[\"learning_rate\"],\n",
    "            \"num_leaves\": int(params[\"num_leaves\"]),\n",
    "            \"lambda_l1\":params[\"lambda_l1\"],\n",
    "            \"lambda_l2\":params[\"lambda_l2\"],\n",
    "            'subsample_for_bin':int(params['subsample_for_bin']),            \n",
    "            'bagging_fraction':params['bagging_fraction'],\n",
    "            \"feature_fraction\":params[\"feature_fraction\"],\n",
    "            \"min_data_in_leaf\":int(params[\"min_data_in_leaf\"]),            \n",
    "            'min_child_weight': params['min_child_weight'],\n",
    "            \"min_split_gain\":params[\"min_split_gain\"]\n",
    "            }\n",
    "        fit_params.update(base_params)\n",
    "        # 模型训练\n",
    "        model=lgb.LGBMClassifier(**fit_params)\n",
    "        model.fit(train_x, train_y)\n",
    "        \n",
    "        # 测试集最小化（- kappa）,且gap较小为目标\n",
    "        train_metric = model_metrics(model, train_x, train_y)\n",
    "        test_metric = model_metrics(model, test_x, test_y)\n",
    "        # 测试进度 +训练-测试gap惩罚系数\n",
    "        loss = -(test_metric-gap_d*(train_metric-test_metric))\n",
    "        return {\"loss\": loss, \"status\":STATUS_OK}\n",
    "\n",
    "    # 参数空间\n",
    "    base_params = {\n",
    "            \"n_jobs\":-1, \n",
    "            \"objective\":'multi:softprob', \n",
    "            \"random_state\":None,\n",
    "            \"silent\":True,\n",
    "            \"verbose\":-1\n",
    "            }\n",
    "    space = {\n",
    "        'max_depth': hp.quniform('max_depth', 2, 12, 1),\n",
    "        'n_estimators': hp.quniform('n_estimators', 2, 3000, 2), \n",
    "        'boosting': hp.choice('boosting', ['gbdt','dart','goss']),\n",
    "        \"class_weight\": hp.choice('class_weight',['balanced',None]),\n",
    "        'num_leaves': hp.quniform('num_leaves', 2, 3000, 2), \n",
    "        'learning_rate': hp.uniform('learning_rate', 1e-4, 9e-1),\n",
    "        'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "        'feature_fraction': hp.uniform('feature_fraction', 0.1, 1),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0.1, 1), \n",
    "        'min_data_in_leaf': hp.qloguniform('min_data_in_leaf', 0, 6, 1),\n",
    "        'lambda_l1': hp.uniform('lambda_l1', 0, 1),\n",
    "        'lambda_l2': hp.uniform('lambda_l2', 0, 1),\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', -16, 5), \n",
    "        'min_split_gain': hp.uniform('min_split_gain', 0, 1)\n",
    "            }\n",
    "    \n",
    "    best_params = fmin(lgb_factory, space, algo=partial(anneal.suggest,), max_evals=eval_iters, trials=Trials(),return_argmin=True)\n",
    "    \n",
    "    # 取最优参数\n",
    "    best_params.update(base_params)\n",
    "    best_params[\"class_weight\"] = ['balanced',None][int(best_params[\"class_weight\"])]\n",
    "    best_params[\"boosting\"] = ['gbdt','dart','goss'][int(best_params[\"boosting\"])]\n",
    "    best_params[\"min_data_in_leaf\"] = int(best_params[\"min_data_in_leaf\"])\n",
    "    best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "    best_params[\"subsample_for_bin\"] = int(best_params[\"subsample_for_bin\"])\n",
    "    best_params[\"num_leaves\"] = int(best_params[\"num_leaves\"])\n",
    "    best_params[\"n_estimators\"] = int(best_params[\"n_estimators\"])\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from hyperopt import hp, tpe, Trials, STATUS_OK, Trials, anneal\n",
    "from functools import partial\n",
    "from hyperopt.fmin import fmin\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score,roc_curve,auc, cohen_kappa_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import plot_importance\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def to_category_or_num(df, category_list):\n",
    "    \"\"\"数据预处理\"\"\"\n",
    "    for ft in df.columns:\n",
    "        if ft in category_list:\n",
    "            df[ft] = df[ft].astype('category')\n",
    "        else:\n",
    "            df[ft] = pd.to_numeric(df[ft], errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "def base_model_predict(lgbmodel,train_df, probs_df):\n",
    "    # 模型融合step1:生成子模型的预测值   \n",
    "    probs_x = train_df.drop(['cust_q','label','cust_no'],axis=1)\n",
    "    to_category_or_num(probs_x, category_list)\n",
    "\n",
    "    probs_df[str(model_no)] = lgbmodel.predict(probs_x)\n",
    "    probs_df[(str(model_no)+'_prob')] = lgbmodel.predict(probs_x) + lgbmodel.predict_proba(probs_x).max(axis=1)\n",
    "    \n",
    "\n",
    "    \n",
    "def data_train_bayes2(df, category_list,test_size, iters):\n",
    "    \"\"\"\n",
    "    数据处理及训练\n",
    "    \n",
    "    # type 1:训练集按比例抽样\n",
    "    # df = train_df[train_df.label.notnull()].sample(frac=0.632)\n",
    "    # type 2:样本均衡抽样 按最小类的0.8均衡取样\n",
    "    # df = train_df.groupby('label', group_keys=False).apply(pd.DataFrame.sample, n=18000)\n",
    "    # type 3:分割上层模型/子模型的样本0.2\n",
    "    # regmodel_df = train_df[train_df.label.notnull()].sample(frac=0.8,random_state=0)\n",
    "    # 子模型样本均衡抽样 按最小类的0.6\n",
    "    # df = regmodel_df.groupby('label', group_keys=False).apply(pd.DataFrame.sample, n=9608)\n",
    "    # type 4:非均衡抽样 按总类的0.8 ，子模型有0.4的不确定样本\n",
    "    # df = train_df[train_df.label.notnull()].sample(frac=0.8,random_state=0)\n",
    "    # type5 train无交集\n",
    "    # df = train_df[train_df.label.notnull()]\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "    # 训练集预处理\n",
    "    x = df.drop(['cust_q','label','cust_no'],axis=1)\n",
    "    to_category_or_num(x, category_list)\n",
    "\n",
    "    # 划分训练集，测试集\n",
    "    y = df.label\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y,test_size=test_size)\n",
    "\n",
    "    \n",
    "        \n",
    "    # 参数优化 \n",
    "\n",
    "    best_params = bayes_fmin(train_x, test_x, train_y, test_y, iters)\n",
    "    print(best_params)\n",
    "    \n",
    "    # 评估\n",
    "    lgbmodel=lgb.LGBMClassifier(**best_params)\n",
    "    lgbmodel.fit(train_x, train_y)\n",
    "    \n",
    "    print('-'*30, 'train')\n",
    "    print(model_metrics(lgbmodel, train_x, train_y))\n",
    "\n",
    "    print('-'*30, 'test')\n",
    "    print(model_metrics(lgbmodel, test_x, test_y))\n",
    "    \n",
    "    # 重要特征\n",
    "    plot_importance(lgbmodel, max_num_features=20,figsize=(5,5),importance_type='split')\n",
    "    plt.show()\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': lgbmodel.booster_.feature_name(),\n",
    "        'gain': lgbmodel.booster_.feature_importance('gain'),\n",
    "        'split': lgbmodel.booster_.feature_importance('split')\n",
    "\n",
    "    }).sort_values('gain',ascending=False)\n",
    "    print(feature_importance[0:50])\n",
    "    \n",
    "    return lgbmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.6098972330824208, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6098972330824208\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3                     \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.6632095022882218, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6632095022882218        \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.9293194023588456, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9293194023588456\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.00978229183122814, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00978229183122814     \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.8047586134357417, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8047586134357417\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44                   \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.7905213938136575, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7905213938136575        \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.6155744100645493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6155744100645493\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.4211233041439998, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4211233041439998       \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.5527590836260549, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5527590836260549\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37                   \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.926596266235223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.926596266235223          \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.6703649002046652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6703649002046652\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.17047324557975957, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17047324557975957     \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=goss, boosting_type=gbdt will be ignored. Current value: boosting=goss                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.46774720327547653, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46774720327547653\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=84, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=84                   \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.4562464116396535, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4562464116396535        \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.3480701948708894, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3480701948708894\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.24076975803084577, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24076975803084577     \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.6824716448038075, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6824716448038075\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21                   \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.862974737993274, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.862974737993274          \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.8423264615303525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8423264615303525\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.05325767026886633, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05325767026886633     \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.7101952301851868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7101952301851868\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74                   \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.3605345368383811, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3605345368383811        \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.6759975975558383, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6759975975558383\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.4354053289210785, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4354053289210785       \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=goss, boosting_type=gbdt will be ignored. Current value: boosting=goss                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.49419571132057893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.49419571132057893\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=190, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=190                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.5859478049569423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5859478049569423        \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.4785068267229693, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4785068267229693\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.3186628991904593, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3186628991904593       \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=goss, boosting_type=gbdt will be ignored. Current value: boosting=goss                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.5756572202158634, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5756572202158634\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=69, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=69                   \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.44195051263442386, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.44195051263442386      \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.741173587731601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.741173587731601\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.5576738788475214, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5576738788475214       \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=goss, boosting_type=gbdt will be ignored. Current value: boosting=goss                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.5648802677083613, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5648802677083613\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.13149482005924293, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13149482005924293      \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.6009930924231242, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6009930924231242\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.4317112503628268, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4317112503628268       \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.9160240577344272, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9160240577344272\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9                     \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.6535297894387164, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6535297894387164        \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.6809469313952737, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6809469313952737\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.2602600611248447, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2602600611248447       \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.7333408930693697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7333408930693697\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30                   \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.6075805066951367, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6075805066951367        \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.9190921156563572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9190921156563572\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.19054967920341187, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19054967920341187     \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.8058764202404394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8058764202404394\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51                   \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.8832240344405364, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8832240344405364        \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.9487218421158847, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9487218421158847\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.071131847687931, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.071131847687931         \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=goss, boosting_type=gbdt will be ignored. Current value: boosting=goss                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.6976275973502735, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6976275973502735\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51                   \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.6837299297837676, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6837299297837676        \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.6383642194884052, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6383642194884052\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.15529356511466932, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15529356511466932     \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.6141236802534679, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6141236802534679\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33                   \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.7789545472556618, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7789545472556618        \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.604476443866218, subsample=1.0 will be ignored. Current value: bagging_fraction=0.604476443866218\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.5473708232586882, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5473708232586882       \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.6458830493347059, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6458830493347059\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=41, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41                   \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.4134392090741796, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4134392090741796        \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.8740929949807181, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8740929949807181\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.020721901706827285, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.020721901706827285   \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart                                 \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "feature_fraction is set=0.5391336312740566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5391336312740566\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49                   \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l1 is set=0.23553655423715036, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23553655423715036      \n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "bagging_fraction is set=0.7911857530989366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7911857530989366\n",
      "[LightGBM] [Warning]                                                                                                   \n",
      "lambda_l2 is set=0.47538330044507826, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.47538330044507826     \n",
      " 30%|█████████████▌                               | 15/50 [1:58:55<4:48:07, 493.93s/it, best loss: -0.4596865632829945]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a0de119bfa59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodels_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel_no\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mlgbmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_train_bayes2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_train_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mbase_model_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgbmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_df3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-0505b9fe508f>\u001b[0m in \u001b[0;36mdata_train_bayes2\u001b[1;34m(df, category_list, test_size, iters)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# 参数优化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbayes_fmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-fb3ad4bdadf1>\u001b[0m in \u001b[0;36mbayes_fmin\u001b[1;34m(train_x, test_x, train_y, test_y, eval_iters, gap_d)\u001b[0m\n\u001b[0;32m     74\u001b[0m             }\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgb_factory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manneal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m# 取最优参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         )\n\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             show_progressbar=show_progressbar)\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    420\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[0;32m    421\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    239\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                         \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    854\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 856\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-fb3ad4bdadf1>\u001b[0m in \u001b[0;36mlgb_factory\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m# 模型训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# 测试集最小化（- kappa）,且gap较小为目标\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    836\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                                         callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[0;32m    839\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    598\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                               callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   2370\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   2371\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2372\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   2373\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2374\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# type 1 跑子模型概率及类别\n",
    "\n",
    "\n",
    "probs_df = train_df3.loc[:,['cust_q','label','cust_no']]\n",
    "category_list = ['I1','I3','I5','I8','I10','I13','I14','lastq_I1','lastq_I3','lastq_I5','lastq_I8','lastq_I10','lastq_I13','lastq_I14']\n",
    "\n",
    "# type 4:非均衡抽样 按总类的0.8 ，子模型有0.4的不确定样本\n",
    "# 子模型训练集\n",
    "base_train_df = train_df3[train_df3.label.notnull()].sample(frac=0.8,random_state=0)\n",
    "\n",
    "models_num = 5\n",
    "for model_no in range(models_num):\n",
    "    lgbmodel = data_train_bayes2(base_train_df, category_list, test_size=0.3, iters=50)\n",
    "    base_model_predict(lgbmodel,train_df3, probs_df)\n",
    "    \n",
    "    # save base_model\n",
    "    print(model_no)\n",
    "    with open('./data/stack_lgb'+str(model_no)+'.v1pkl','wb') as fileobj:\n",
    "        pickle.dump(lgbmodel,fileobj)\n",
    "    \n",
    "    \n",
    "# 保存子模型预测结果\n",
    "probs_df.to_pickle('./data/basemodel_ft_50w_1209.v1pkl')  \n",
    "# 备注子模型的样本\n",
    "probs_df.loc[base_train_df.index,\"regmodel\"] = 1\n",
    "\n",
    "# # type2 跑kfold子模型预测概率\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# folds = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# for train_index, test_index in folds.split(train_df3):\n",
    "#     train_df, test_df = train_df3.iloc[train_index], train_df3.iloc[test_index]\n",
    "#     lgbmodel = data_train_bayes2(test_df, category_list)\n",
    "#     # savemodel\n",
    "#     print(model_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_df.to_pickle('./data/basemodel_ft_50w_1208.v1pkl')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import lightgbm as lgb\n",
    "# import matplotlib.pyplot as plt\n",
    "# from lightgbm import plot_importance\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# def stack_models_bayes(df, iters=200, model_type='lgb'):\n",
    "#     \"\"\"\n",
    "#     stack 模型融合及训练\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # 训练集预处理&df.regmodel.isnull()\n",
    "#     x = df[df.label.notnull()].drop(['cust_q','label','cust_no'],axis=1)\n",
    "#     y = df[df.label.notnull()].label\n",
    "#     # 划分训练集，测试集\n",
    "#     train_x, test_x, train_y, test_y = train_test_split(x, y,test_size=0.2, random_state=0)\n",
    "#     if model_type == 'lgb':\n",
    "#         # LGB参数优化\n",
    "#         best_params = bayes_fmin(train_x, test_x, train_y, test_y, iters, 0.5)\n",
    "#         print(best_params)    \n",
    "#         # 评估\n",
    "#         model=lgb.LGBMClassifier(**best_params)\n",
    "#         model.fit(train_x, train_y)\n",
    "#         # 重要特征\n",
    "#         plot_importance(model, max_num_features=100,figsize=(10,30),importance_type='gain')\n",
    "#         plt.show()    \n",
    "#         feature_importance = pd.DataFrame({\n",
    "#             'feature': lgbmodel.booster_.feature_name(),\n",
    "#             'gain': lgbmodel.booster_.feature_importance('gain'),\n",
    "#             'split': lgbmodel.booster_.feature_importance('split')\n",
    "#         }).sort_values('gain',ascending=False)\n",
    "#     elif model_type == 'lr':\n",
    "        \n",
    "#         model = LogisticRegression(penalty='l2', dual=False, tol=0.01, C=0.1, fit_intercept=True, intercept_scaling=1,\n",
    "#                                    class_weight='balanced', max_iter=500, multi_class='ovr', random_state=0,n_jobs=1,\n",
    "#                                    solver='newton-cg', verbose=5, warm_start=True,l1_ratio=None)\n",
    "#         model.fit(train_x, train_y)\n",
    "    \n",
    "#     print('-'*30, 'train')\n",
    "#     print(model_metrics(model, train_x, train_y))\n",
    "\n",
    "#     print('-'*30, 'test')\n",
    "#     print(model_metrics(model, test_x, test_y))\n",
    "    \n",
    "#     # 融合的数据生成竞赛结果 &df.regmodel.isnull()\n",
    "#     result_df = df.loc[df.label.isnull()]\n",
    "\n",
    "#     test_df_x = result_df.drop(['cust_q','label', 'cust_no'],axis=1)\n",
    "#     result_df['label'] = model.predict(test_df_x)\n",
    "\n",
    "\n",
    "#     # 保存为 固定格式结果\n",
    "#     result_df['label'] = result_df['label'].astype('int')\n",
    "#     result_df[['cust_no','label']].to_csv('./data/%sstack_1209.csv'%model_type,index=False)\n",
    "#     print(result_df[['cust_no','label']].head())\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # 模型融合step2: 融合最终模型，预测，并保存test结果\n",
    "\n",
    "# probs_df = pd.read_pickle('./data/basemodel_ft_50w_1208.v1pkl')  \n",
    "# # 微调-1概率值\n",
    "# for row in probs_df.loc[:,probs_df.columns.str.contains('_prob')].columns:\n",
    "#     probs_df.loc[probs_df[row]< 0, row] =  -(probs_df.loc[probs_df[row]< 0, row])  - 2\n",
    "# print(row)\n",
    "    \n",
    "# # 模型融合\n",
    "# model = stack_models_bayes(probs_df,iters=20,model_type='lr')\n",
    "# print(model.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均值融合\n",
    "\n",
    "test_df = probs_df.set_index('cust_no')\n",
    "# probs_df = train_df3.loc[:,[,'cust_no']]\n",
    "result_df = pd.DataFrame(test_df.loc[test_df.label.isnull(),~test_df.columns.str.contains('_prob')].mode(axis=1)[0].astype('int'))\n",
    "result_df.columns =['label']\n",
    "result_df.to_csv('./data/result_df-aa.csv',header=True,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
