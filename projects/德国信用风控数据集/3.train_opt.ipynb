{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c477715f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from hyperopt import hp, tpe, Trials, STATUS_OK, Trials, anneal\n",
    "from functools import partial\n",
    "from hyperopt.fmin import fmin\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_curve,auc, fbeta_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%reload_ext autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "from feas_select import  calc_feas,get_drop\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow import random\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense,Dropout,BatchNormalization,GaussianNoise\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import  mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import  mean_squared_error\n",
    "import keras_tuner as kt  # pip install tf.keras_tuner \n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # 全屏展示\n",
    "pd.set_option('display.max_columns', 600)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2306773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train(file='./data/filter_feas_df32n_old.pkl',model='tree'):\n",
    "    df = pd.read_pickle(file)\n",
    "    df3 = pd.read_csv('./data/EXPERIAN_FEATURE_0327.csv',nrows=2) # 取旧模型特征列表\n",
    "    print(df.shape)\n",
    "    df.head()\n",
    "\n",
    "    ##############################配置\n",
    "    oot_dt ='20220200000000'\n",
    "    nofeas = ['ID', 'report_timestamp','label','pan','label_y','order_id','label_pred']\n",
    "    catefeas= list(pd.read_pickle('./data/catefeas.pkl').values)\n",
    "    cbfeas = [col for col in df.columns if '_cb'in str(col)]\n",
    "    vcount = [col for col in df.columns if 'vcount'in str(col)]\n",
    "    old_feas = [col for col in df.columns if 'feature_'in str(col)]\n",
    "    old_cols = list(df3.columns)\n",
    "    sms_feas = [col for col in df3.columns if '_sms'in str(col)]\n",
    "    nosms_feas = [col for col in df3.columns if '_sms' not in str(col) and col not in nofeas]\n",
    "    drop_list=[]\n",
    "    # try:\n",
    "    #     upper1\n",
    "    # except:\n",
    "    #     print('first run')\n",
    "    #     upper1,upper2,var_features,miss_features,sigle_rate = calc_feas(df,catefeas) ## 过滤法特征选择\n",
    "    # drop_list = get_drop(upper1,upper2,var_features,miss_features,sigle_rate)\n",
    "\n",
    "    drop_feas = nofeas+cbfeas+vcount+drop_list+catefeas                # 去除旧模型部分特征、类别特征等等\n",
    "    final_feas = [col for col in df.columns if col not in drop_feas]\n",
    "    \n",
    "\n",
    "\n",
    "    ###########################\n",
    "    # 强制类型转换\n",
    "    def to_category_or_num(df, category_list, drop_list):\n",
    "        if model == 'nn':  # 全数值型\n",
    "            for ft in set(df.columns)-set(drop_list):\n",
    "                df[ft] = pd.to_numeric(df[ft], errors='coerce').fillna(0).replace([np.inf], 99999).replace([-np.inf], -99999)\n",
    "        else:\n",
    "            for ft in set(df.columns)-set(drop_list):\n",
    "                if ft in category_list:\n",
    "                    df[ft] = df[ft].astype('category')\n",
    "                else:\n",
    "                    df[ft] = pd.to_numeric(df[ft], errors='coerce')\n",
    "\n",
    "    to_category_or_num(df, catefeas, nofeas)\n",
    "    df = df.reset_index(drop=True)\n",
    "    ### 剔除特征 \n",
    "\n",
    "    x = df[df['label'].notnull()&(df.report_timestamp<=oot_dt)][final_feas]\n",
    "    y = df[df['label'].notnull()&(df.report_timestamp<=oot_dt)]['label']\n",
    "    oot_x = df[df['label'].notnull()&(df.report_timestamp>oot_dt)][final_feas]\n",
    "    oot_y = df[df['label'].notnull()&(df.report_timestamp>oot_dt)]['label']\n",
    "\n",
    "    # ### 直接用旧模型的特征\n",
    "    # x = df.loc[df['label'].notnull()&(df.report_timestamp<=oot_dt),old_fea]\n",
    "    # y = df.loc[df['label'].notnull()&(df.report_timestamp<=oot_dt)]['label']\n",
    "    # oot_x = df.loc[df['label'].notnull()&(df.report_timestamp>oot_dt),old_fea]\n",
    "    # oot_y = df.loc[df['label'].notnull()&(df.report_timestamp>oot_dt)]['label']\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y,test_size=0.2,random_state=42)\n",
    "    print(y.value_counts())\n",
    "    print(oot_y.value_counts())\n",
    "    display(train_x.head())\n",
    "    print(train_x.shape)\n",
    "    return train_x, test_x, train_y, test_y,oot_x,oot_y,df,final_feas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "130bf64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9123, 1802)\n",
      "1.0    5631\n",
      "0.0    2040\n",
      "Name: label, dtype: int64\n",
      "1.0    1035\n",
      "0.0     417\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BureauScore</th>\n",
       "      <th>MissingRate</th>\n",
       "      <th>Len_Name</th>\n",
       "      <th>Tel_nuniq</th>\n",
       "      <th>Email_nuniq</th>\n",
       "      <th>Len_of_addrs</th>\n",
       "      <th>City_nuniq</th>\n",
       "      <th>Current_State</th>\n",
       "      <th>CreditAccountActive</th>\n",
       "      <th>CreditAccountTotal</th>\n",
       "      <th>CreditAccountActivePor</th>\n",
       "      <th>Outstanding_Balance_Secured</th>\n",
       "      <th>Outstanding_Balance_UnSecured_Percentage</th>\n",
       "      <th>Outstanding_Balance_All</th>\n",
       "      <th>Outstanding_Balance_Secured_Percentage</th>\n",
       "      <th>Outstanding_Balance_UnSecured</th>\n",
       "      <th>Diff_dateBirth</th>\n",
       "      <th>State_nuniq</th>\n",
       "      <th>Birth_nuniq</th>\n",
       "      <th>TotalCAPSLast90Days</th>\n",
       "      <th>TotalCAPSLast7Days</th>\n",
       "      <th>TotalCAPSLast30Days</th>\n",
       "      <th>TotalCAPSLast180Days</th>\n",
       "      <th>CAPSLast30Days</th>\n",
       "      <th>CAPSLast7Days</th>\n",
       "      <th>CAPSLast180Days</th>\n",
       "      <th>NonCreditCAPSLast180Days</th>\n",
       "      <th>Pin_nuniq</th>\n",
       "      <th>Pan_nuniq</th>\n",
       "      <th>Ident_nuniq</th>\n",
       "      <th>Name_nuniq2</th>\n",
       "      <th>Tel_nuniq2</th>\n",
       "      <th>Email_nuniq2</th>\n",
       "      <th>Pan_nuniq2</th>\n",
       "      <th>Account_nuniq2</th>\n",
       "      <th>Ident_nuniq2</th>\n",
       "      <th>Gender_nuniq</th>\n",
       "      <th>Amount_Past_Due35_sum_30</th>\n",
       "      <th>Amount_Past_Due35_min_30</th>\n",
       "      <th>Amount_Past_Due35_sum_90</th>\n",
       "      <th>Amount_Past_Due35_mean_90</th>\n",
       "      <th>Amount_Past_Due35_max_90</th>\n",
       "      <th>Amount_Past_Due35_min_90</th>\n",
       "      <th>Amount_Past_Due35_std_90</th>\n",
       "      <th>Amount_Past_Due35_sum_360</th>\n",
       "      <th>Amount_Past_Due35_mean_360</th>\n",
       "      <th>Amount_Past_Due35_max_360</th>\n",
       "      <th>Amount_Past_Due35_std_360</th>\n",
       "      <th>Amount_Past_Due35_sum_9999</th>\n",
       "      <th>Amount_Past_Due35_max_9999</th>\n",
       "      <th>Amount_Past_Due35_min_9999</th>\n",
       "      <th>Amount_Past_Due35_std_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_9999</th>\n",
       "      <th>Terms_Duration34_sum_30</th>\n",
       "      <th>Terms_Duration34_std_30</th>\n",
       "      <th>Terms_Duration34_sum_90</th>\n",
       "      <th>Terms_Duration34_std_90</th>\n",
       "      <th>Terms_Duration34_mean_360</th>\n",
       "      <th>Terms_Duration34_max_360</th>\n",
       "      <th>Terms_Duration34_min_360</th>\n",
       "      <th>Terms_Duration34_std_360</th>\n",
       "      <th>Terms_Duration34_sum_9999</th>\n",
       "      <th>Terms_Duration34_mean_9999</th>\n",
       "      <th>Terms_Duration34_max_9999</th>\n",
       "      <th>Terms_Duration34_min_9999</th>\n",
       "      <th>Terms_Duration34_std_9999</th>\n",
       "      <th>Payment_Rating34_sum_90</th>\n",
       "      <th>Payment_Rating34_mean_90</th>\n",
       "      <th>Payment_Rating34_max_90</th>\n",
       "      <th>Payment_Rating34_min_90</th>\n",
       "      <th>Payment_Rating34_std_90</th>\n",
       "      <th>Payment_Rating34_sum_360</th>\n",
       "      <th>Payment_Rating34_mean_360</th>\n",
       "      <th>Payment_Rating34_max_360</th>\n",
       "      <th>Payment_Rating34_min_360</th>\n",
       "      <th>Payment_Rating34_std_360</th>\n",
       "      <th>Payment_Rating34_sum_9999</th>\n",
       "      <th>Payment_Rating34_mean_9999</th>\n",
       "      <th>Payment_Rating34_max_9999</th>\n",
       "      <th>Payment_Rating34_min_9999</th>\n",
       "      <th>Payment_Rating34_std_9999</th>\n",
       "      <th>Current_Balance35_mean_30</th>\n",
       "      <th>Current_Balance35_min_30</th>\n",
       "      <th>Current_Balance35_std_30</th>\n",
       "      <th>Current_Balance35_sum_90</th>\n",
       "      <th>Current_Balance35_mean_90</th>\n",
       "      <th>Current_Balance35_max_90</th>\n",
       "      <th>Current_Balance35_std_90</th>\n",
       "      <th>Current_Balance35_sum_360</th>\n",
       "      <th>Current_Balance35_max_360</th>\n",
       "      <th>Current_Balance35_std_360</th>\n",
       "      <th>Current_Balance35_max_9999</th>\n",
       "      <th>Current_Balance35_std_9999</th>\n",
       "      <th>Settlement_Amount37_max_360</th>\n",
       "      <th>Settlement_Amount37_min_360</th>\n",
       "      <th>Settlement_Amount37_std_360</th>\n",
       "      <th>Settlement_Amount37_sum_9999</th>\n",
       "      <th>Settlement_Amount37_mean_9999</th>\n",
       "      <th>Settlement_Amount37_max_9999</th>\n",
       "      <th>Settlement_Amount37_min_9999</th>\n",
       "      <th>Settlement_Amount37_std_9999</th>\n",
       "      <th>Value_of_Collateral39_std_90</th>\n",
       "      <th>Value_of_Collateral39_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_360</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_360</th>\n",
       "      <th>Written_Off_Amt_Total41_min_360</th>\n",
       "      <th>Written_Off_Amt_Total41_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_max_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_min_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_std_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_mean_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_std_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_max_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_9999</th>\n",
       "      <th>Rate_of_Interest36_sum_30</th>\n",
       "      <th>Rate_of_Interest36_std_30</th>\n",
       "      <th>Rate_of_Interest36_sum_90</th>\n",
       "      <th>Rate_of_Interest36_mean_90</th>\n",
       "      <th>Rate_of_Interest36_max_90</th>\n",
       "      <th>Rate_of_Interest36_std_90</th>\n",
       "      <th>Rate_of_Interest36_sum_360</th>\n",
       "      <th>Rate_of_Interest36_mean_360</th>\n",
       "      <th>Rate_of_Interest36_max_360</th>\n",
       "      <th>Rate_of_Interest36_min_360</th>\n",
       "      <th>Rate_of_Interest36_std_360</th>\n",
       "      <th>Rate_of_Interest36_sum_9999</th>\n",
       "      <th>Rate_of_Interest36_mean_9999</th>\n",
       "      <th>Rate_of_Interest36_max_9999</th>\n",
       "      <th>Rate_of_Interest36_min_9999</th>\n",
       "      <th>Rate_of_Interest36_std_9999</th>\n",
       "      <th>Repayment_Tenure36_std_30</th>\n",
       "      <th>Repayment_Tenure36_mean_90</th>\n",
       "      <th>Repayment_Tenure36_max_90</th>\n",
       "      <th>Repayment_Tenure36_min_90</th>\n",
       "      <th>Repayment_Tenure36_std_90</th>\n",
       "      <th>Repayment_Tenure36_sum_360</th>\n",
       "      <th>Repayment_Tenure36_mean_360</th>\n",
       "      <th>Repayment_Tenure36_min_360</th>\n",
       "      <th>Repayment_Tenure36_std_360</th>\n",
       "      <th>Repayment_Tenure36_mean_9999</th>\n",
       "      <th>Repayment_Tenure36_min_9999</th>\n",
       "      <th>Repayment_Tenure36_std_9999</th>\n",
       "      <th>Income26_count_360</th>\n",
       "      <th>Income26_std_360</th>\n",
       "      <th>Open_Date29_max_30</th>\n",
       "      <th>Open_Date29_min_30</th>\n",
       "      <th>Open_Date29_mean_30</th>\n",
       "      <th>Open_Date29_nuniq_30</th>\n",
       "      <th>Open_Date29_maxcount_30</th>\n",
       "      <th>Open_Date29_max_90</th>\n",
       "      <th>Open_Date29_mean_90</th>\n",
       "      <th>Open_Date29_mode_90</th>\n",
       "      <th>Open_Date29_nuniq_90</th>\n",
       "      <th>Open_Date29_maxcount_90</th>\n",
       "      <th>Open_Date29_max_360</th>\n",
       "      <th>Open_Date29_mean_360</th>\n",
       "      <th>Open_Date29_mode_360</th>\n",
       "      <th>Open_Date29_nuniq_360</th>\n",
       "      <th>Open_Date29_maxcount_360</th>\n",
       "      <th>Open_Date29_max_9999</th>\n",
       "      <th>Open_Date29_mean_9999</th>\n",
       "      <th>Open_Date29_mode_9999</th>\n",
       "      <th>Open_Date29_maxcount_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_30</th>\n",
       "      <th>Portfolio_Type34_nuniq_90</th>\n",
       "      <th>Portfolio_Type34_nuniq_360</th>\n",
       "      <th>Portfolio_Type34_nuniq_9999</th>\n",
       "      <th>Account_Type32_nuniq_30</th>\n",
       "      <th>Account_Type32_nuniq_90</th>\n",
       "      <th>Account_Type32_nuniq_360</th>\n",
       "      <th>Account_Type32_nuniq_9999</th>\n",
       "      <th>Occupation_Code35_nuniq_30</th>\n",
       "      <th>Occupation_Code35_nuniq_90</th>\n",
       "      <th>Occupation_Code35_nuniq_360</th>\n",
       "      <th>Occupation_Code35_nuniq_9999</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_360</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_9999</th>\n",
       "      <th>Payment_History_Profile43_mode_30</th>\n",
       "      <th>Payment_History_Profile43_mode_90</th>\n",
       "      <th>Payment_History_Profile43_nuniq_90</th>\n",
       "      <th>Payment_History_Profile43_mode_360</th>\n",
       "      <th>Payment_History_Profile43_nuniq_360</th>\n",
       "      <th>Payment_History_Profile43_mode_9999</th>\n",
       "      <th>Payment_History_Profile43_nuniq_9999</th>\n",
       "      <th>Date_Closed31_nuniq_30</th>\n",
       "      <th>Date_Closed31_maxcount_30</th>\n",
       "      <th>Date_Closed31_max_90</th>\n",
       "      <th>Date_Closed31_min_90</th>\n",
       "      <th>Date_Closed31_mean_90</th>\n",
       "      <th>Date_Closed31_mode_90</th>\n",
       "      <th>Date_Closed31_nuniq_90</th>\n",
       "      <th>Date_Closed31_maxcount_90</th>\n",
       "      <th>Date_Closed31_min_360</th>\n",
       "      <th>Date_Closed31_mode_360</th>\n",
       "      <th>Date_Closed31_nuniq_360</th>\n",
       "      <th>Date_Closed31_maxcount_360</th>\n",
       "      <th>Date_Closed31_max_9999</th>\n",
       "      <th>Date_Closed31_min_9999</th>\n",
       "      <th>Date_Closed31_mean_9999</th>\n",
       "      <th>Date_Closed31_mode_9999</th>\n",
       "      <th>Date_Closed31_nuniq_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_30</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_30</th>\n",
       "      <th>Date_of_Last_Payment40_min_90</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_90</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_90</th>\n",
       "      <th>Date_of_Last_Payment40_max_360</th>\n",
       "      <th>Date_of_Last_Payment40_min_360</th>\n",
       "      <th>Date_of_Last_Payment40_mean_360</th>\n",
       "      <th>Date_of_Last_Payment40_mode_360</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_360</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_360</th>\n",
       "      <th>Date_of_Last_Payment40_max_9999</th>\n",
       "      <th>Date_of_Last_Payment40_min_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mean_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_9999</th>\n",
       "      <th>Date_Reported33_nuniq_30</th>\n",
       "      <th>Date_Reported33_max_90</th>\n",
       "      <th>Date_Reported33_mean_90</th>\n",
       "      <th>Date_Reported33_mode_90</th>\n",
       "      <th>Date_Reported33_nuniq_90</th>\n",
       "      <th>Date_Reported33_maxcount_90</th>\n",
       "      <th>Date_Reported33_max_360</th>\n",
       "      <th>Date_Reported33_mean_360</th>\n",
       "      <th>Date_Reported33_mode_360</th>\n",
       "      <th>Date_Reported33_nuniq_360</th>\n",
       "      <th>Date_Reported33_maxcount_360</th>\n",
       "      <th>Date_Reported33_max_9999</th>\n",
       "      <th>Date_Reported33_mean_9999</th>\n",
       "      <th>Date_Reported33_mode_9999</th>\n",
       "      <th>Date_Reported33_nuniq_9999</th>\n",
       "      <th>Date_Reported33_maxcount_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_30</th>\n",
       "      <th>DateOfAddition34_max_90</th>\n",
       "      <th>DateOfAddition34_mean_90</th>\n",
       "      <th>DateOfAddition34_mode_90</th>\n",
       "      <th>DateOfAddition34_nuniq_90</th>\n",
       "      <th>DateOfAddition34_maxcount_90</th>\n",
       "      <th>DateOfAddition34_max_360</th>\n",
       "      <th>DateOfAddition34_mean_360</th>\n",
       "      <th>DateOfAddition34_mode_360</th>\n",
       "      <th>DateOfAddition34_nuniq_360</th>\n",
       "      <th>DateOfAddition34_maxcount_360</th>\n",
       "      <th>DateOfAddition34_max_9999</th>\n",
       "      <th>DateOfAddition34_mean_9999</th>\n",
       "      <th>DateOfAddition34_mode_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_9999</th>\n",
       "      <th>DateOfAddition34_maxcount_9999</th>\n",
       "      <th>Account_Status34_mode_30</th>\n",
       "      <th>Account_Status34_nuniq_30</th>\n",
       "      <th>Account_Status34_mode_90</th>\n",
       "      <th>Account_Status34_nuniq_90</th>\n",
       "      <th>Account_Status34_mode_360</th>\n",
       "      <th>Account_Status34_nuniq_360</th>\n",
       "      <th>Account_Status34_nuniq_9999</th>\n",
       "      <th>Month50_sum_30</th>\n",
       "      <th>Month50_max_30</th>\n",
       "      <th>Month50_std_30</th>\n",
       "      <th>Month50_sum_90</th>\n",
       "      <th>Month50_mean_90</th>\n",
       "      <th>Month50_max_90</th>\n",
       "      <th>Month50_min_90</th>\n",
       "      <th>Month50_std_90</th>\n",
       "      <th>Month50_sum_360</th>\n",
       "      <th>Month50_min_360</th>\n",
       "      <th>Month50_std_360</th>\n",
       "      <th>Month50_sum_9999</th>\n",
       "      <th>Month50_mean_9999</th>\n",
       "      <th>Month50_max_9999</th>\n",
       "      <th>Month50_min_9999</th>\n",
       "      <th>Month50_std_9999</th>\n",
       "      <th>Days_Past_Due58_max_30</th>\n",
       "      <th>Days_Past_Due58_min_30</th>\n",
       "      <th>Days_Past_Due58_mean_90</th>\n",
       "      <th>Days_Past_Due58_max_90</th>\n",
       "      <th>Days_Past_Due58_min_90</th>\n",
       "      <th>Days_Past_Due58_std_90</th>\n",
       "      <th>Days_Past_Due58_sum_360</th>\n",
       "      <th>Days_Past_Due58_mean_360</th>\n",
       "      <th>Days_Past_Due58_max_360</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_1031_sms</th>\n",
       "      <th>feature_1032_sms</th>\n",
       "      <th>feature_1033_sms</th>\n",
       "      <th>feature_1034_sms</th>\n",
       "      <th>feature_1035_sms</th>\n",
       "      <th>feature_1036_sms</th>\n",
       "      <th>feature_1037_sms</th>\n",
       "      <th>feature_1038_sms</th>\n",
       "      <th>feature_1039_sms</th>\n",
       "      <th>feature_1040_sms</th>\n",
       "      <th>feature_1041_sms</th>\n",
       "      <th>feature_1042_sms</th>\n",
       "      <th>feature_1043_sms</th>\n",
       "      <th>feature_1044_sms</th>\n",
       "      <th>feature_1045_sms</th>\n",
       "      <th>feature_1046_sms</th>\n",
       "      <th>feature_1047_sms</th>\n",
       "      <th>feature_1048_sms</th>\n",
       "      <th>feature_1049_sms</th>\n",
       "      <th>feature_1050_sms</th>\n",
       "      <th>feature_1051_sms</th>\n",
       "      <th>feature_1052_sms</th>\n",
       "      <th>feature_1053_sms</th>\n",
       "      <th>feature_1054_sms</th>\n",
       "      <th>feature_1055_sms</th>\n",
       "      <th>feature_1056_sms</th>\n",
       "      <th>feature_1057_sms</th>\n",
       "      <th>feature_1058_sms</th>\n",
       "      <th>feature_1059_sms</th>\n",
       "      <th>feature_1060_sms</th>\n",
       "      <th>feature_1061_sms</th>\n",
       "      <th>feature_1062_sms</th>\n",
       "      <th>feature_1063_sms</th>\n",
       "      <th>feature_1064_sms</th>\n",
       "      <th>feature_1065_sms</th>\n",
       "      <th>feature_1066_sms</th>\n",
       "      <th>feature_1067_sms</th>\n",
       "      <th>feature_1068_sms</th>\n",
       "      <th>feature_1069_sms</th>\n",
       "      <th>feature_1070_sms</th>\n",
       "      <th>feature_1071_sms</th>\n",
       "      <th>feature_1072_sms</th>\n",
       "      <th>feature_1073_sms</th>\n",
       "      <th>feature_1074_sms</th>\n",
       "      <th>feature_1075_sms</th>\n",
       "      <th>feature_1076_sms</th>\n",
       "      <th>feature_1077_sms</th>\n",
       "      <th>feature_1078_sms</th>\n",
       "      <th>feature_1079_sms</th>\n",
       "      <th>feature_1080_sms</th>\n",
       "      <th>feature_1081_sms</th>\n",
       "      <th>feature_1082_sms</th>\n",
       "      <th>feature_1083_sms</th>\n",
       "      <th>feature_1084_sms</th>\n",
       "      <th>feature_1085_sms</th>\n",
       "      <th>feature_1086_sms</th>\n",
       "      <th>feature_1087_sms</th>\n",
       "      <th>feature_1088_sms</th>\n",
       "      <th>feature_1089_sms</th>\n",
       "      <th>feature_1090_sms</th>\n",
       "      <th>feature_1091_sms</th>\n",
       "      <th>feature_1092_sms</th>\n",
       "      <th>feature_1093_sms</th>\n",
       "      <th>feature_1094_sms</th>\n",
       "      <th>feature_1095_sms</th>\n",
       "      <th>feature_1096_sms</th>\n",
       "      <th>feature_1097_sms</th>\n",
       "      <th>feature_1098_sms</th>\n",
       "      <th>feature_1099_sms</th>\n",
       "      <th>feature_1100_sms</th>\n",
       "      <th>feature_1101_sms</th>\n",
       "      <th>feature_1102_sms</th>\n",
       "      <th>feature_1103_sms</th>\n",
       "      <th>feature_1104_sms</th>\n",
       "      <th>feature_1105_sms</th>\n",
       "      <th>feature_1106_sms</th>\n",
       "      <th>feature_1107_sms</th>\n",
       "      <th>feature_1108_sms</th>\n",
       "      <th>feature_1109_sms</th>\n",
       "      <th>feature_1110_sms</th>\n",
       "      <th>feature_1111_sms</th>\n",
       "      <th>feature_1112_sms</th>\n",
       "      <th>feature_1113_sms</th>\n",
       "      <th>feature_1114_sms</th>\n",
       "      <th>feature_1115_sms</th>\n",
       "      <th>feature_1116_sms</th>\n",
       "      <th>feature_1117_sms</th>\n",
       "      <th>feature_1118_sms</th>\n",
       "      <th>feature_1119_sms</th>\n",
       "      <th>feature_1120_sms</th>\n",
       "      <th>feature_1121_sms</th>\n",
       "      <th>feature_1122_sms</th>\n",
       "      <th>feature_1123_sms</th>\n",
       "      <th>feature_1124_sms</th>\n",
       "      <th>feature_1125_sms</th>\n",
       "      <th>feature_1126_sms</th>\n",
       "      <th>feature_1127_sms</th>\n",
       "      <th>feature_1128_sms</th>\n",
       "      <th>feature_1129_sms</th>\n",
       "      <th>feature_1130_sms</th>\n",
       "      <th>feature_1131_sms</th>\n",
       "      <th>feature_1132_sms</th>\n",
       "      <th>feature_1133_sms</th>\n",
       "      <th>feature_1134_sms</th>\n",
       "      <th>feature_1135_sms</th>\n",
       "      <th>feature_1136_sms</th>\n",
       "      <th>feature_1137_sms</th>\n",
       "      <th>feature_1138_sms</th>\n",
       "      <th>feature_1139_sms</th>\n",
       "      <th>feature_1140_sms</th>\n",
       "      <th>feature_1141_sms</th>\n",
       "      <th>feature_1142_sms</th>\n",
       "      <th>feature_1143_sms</th>\n",
       "      <th>feature_1144_sms</th>\n",
       "      <th>feature_1145_sms</th>\n",
       "      <th>feature_1146_sms</th>\n",
       "      <th>feature_1147_sms</th>\n",
       "      <th>feature_1148_sms</th>\n",
       "      <th>feature_1149_sms</th>\n",
       "      <th>feature_1150_sms</th>\n",
       "      <th>feature_1151_sms</th>\n",
       "      <th>feature_1152_sms</th>\n",
       "      <th>feature_1153_sms</th>\n",
       "      <th>feature_1154_sms</th>\n",
       "      <th>feature_1155_sms</th>\n",
       "      <th>feature_1156_sms</th>\n",
       "      <th>feature_1157_sms</th>\n",
       "      <th>feature_1158_sms</th>\n",
       "      <th>feature_1159_sms</th>\n",
       "      <th>feature_1160_sms</th>\n",
       "      <th>feature_1161_sms</th>\n",
       "      <th>feature_1162_sms</th>\n",
       "      <th>feature_1163_sms</th>\n",
       "      <th>feature_1164_sms</th>\n",
       "      <th>feature_1165_sms</th>\n",
       "      <th>feature_1166_sms</th>\n",
       "      <th>feature_1167_sms</th>\n",
       "      <th>feature_1168_sms</th>\n",
       "      <th>feature_1169_sms</th>\n",
       "      <th>feature_1170_sms</th>\n",
       "      <th>feature_1171_sms</th>\n",
       "      <th>feature_1172_sms</th>\n",
       "      <th>feature_1173_sms</th>\n",
       "      <th>feature_1174_sms</th>\n",
       "      <th>feature_1175_sms</th>\n",
       "      <th>feature_1176_sms</th>\n",
       "      <th>feature_1177_sms</th>\n",
       "      <th>feature_1178_sms</th>\n",
       "      <th>feature_1179_sms</th>\n",
       "      <th>feature_1180_sms</th>\n",
       "      <th>feature_1181_sms</th>\n",
       "      <th>feature_1182_sms</th>\n",
       "      <th>feature_1183_sms</th>\n",
       "      <th>feature_1184_sms</th>\n",
       "      <th>feature_1185_sms</th>\n",
       "      <th>feature_1186_sms</th>\n",
       "      <th>feature_1187_sms</th>\n",
       "      <th>feature_1188_sms</th>\n",
       "      <th>feature_1189_sms</th>\n",
       "      <th>feature_1190_sms</th>\n",
       "      <th>feature_1191_sms</th>\n",
       "      <th>feature_1192_sms</th>\n",
       "      <th>feature_1193_sms</th>\n",
       "      <th>feature_1194_sms</th>\n",
       "      <th>feature_1195_sms</th>\n",
       "      <th>feature_1196_sms</th>\n",
       "      <th>feature_1197_sms</th>\n",
       "      <th>feature_1198_sms</th>\n",
       "      <th>feature_1199_sms</th>\n",
       "      <th>feature_1200_sms</th>\n",
       "      <th>feature_1201_sms</th>\n",
       "      <th>feature_1202_sms</th>\n",
       "      <th>feature_1203_sms</th>\n",
       "      <th>feature_1204_sms</th>\n",
       "      <th>feature_1205_sms</th>\n",
       "      <th>feature_1206_sms</th>\n",
       "      <th>feature_1207_sms</th>\n",
       "      <th>feature_1208_sms</th>\n",
       "      <th>feature_1209_sms</th>\n",
       "      <th>feature_1210_sms</th>\n",
       "      <th>feature_1211_sms</th>\n",
       "      <th>feature_1212_sms</th>\n",
       "      <th>feature_1213_sms</th>\n",
       "      <th>feature_1214_sms</th>\n",
       "      <th>feature_1215_sms</th>\n",
       "      <th>feature_1216_sms</th>\n",
       "      <th>feature_1217_sms</th>\n",
       "      <th>feature_1218_sms</th>\n",
       "      <th>feature_1219_sms</th>\n",
       "      <th>feature_1220_sms</th>\n",
       "      <th>feature_1221_sms</th>\n",
       "      <th>feature_1222_sms</th>\n",
       "      <th>feature_1223_sms</th>\n",
       "      <th>feature_1224_sms</th>\n",
       "      <th>feature_1225_sms</th>\n",
       "      <th>feature_1226_sms</th>\n",
       "      <th>feature_1227_sms</th>\n",
       "      <th>feature_1228_sms</th>\n",
       "      <th>feature_1229_sms</th>\n",
       "      <th>feature_1230_sms</th>\n",
       "      <th>feature_1231_sms</th>\n",
       "      <th>feature_1232_sms</th>\n",
       "      <th>feature_1233_sms</th>\n",
       "      <th>feature_1234_sms</th>\n",
       "      <th>feature_1235_sms</th>\n",
       "      <th>feature_1236_sms</th>\n",
       "      <th>feature_1237_sms</th>\n",
       "      <th>feature_1238_sms</th>\n",
       "      <th>feature_1239_sms</th>\n",
       "      <th>feature_1240_sms</th>\n",
       "      <th>feature_1241_sms</th>\n",
       "      <th>feature_1242_sms</th>\n",
       "      <th>feature_1243_sms</th>\n",
       "      <th>feature_1244_sms</th>\n",
       "      <th>feature_1245_sms</th>\n",
       "      <th>feature_1246_sms</th>\n",
       "      <th>feature_1247_sms</th>\n",
       "      <th>feature_1248_sms</th>\n",
       "      <th>feature_1249_sms</th>\n",
       "      <th>feature_1250_sms</th>\n",
       "      <th>feature_1251_sms</th>\n",
       "      <th>feature_1252_sms</th>\n",
       "      <th>feature_1253_sms</th>\n",
       "      <th>feature_1254_sms</th>\n",
       "      <th>feature_1255_sms</th>\n",
       "      <th>feature_1256_sms</th>\n",
       "      <th>feature_1257_sms</th>\n",
       "      <th>feature_1258_sms</th>\n",
       "      <th>feature_1259_sms</th>\n",
       "      <th>feature_1260_sms</th>\n",
       "      <th>feature_1261_sms</th>\n",
       "      <th>feature_1262_sms</th>\n",
       "      <th>feature_1263_sms</th>\n",
       "      <th>feature_1264_sms</th>\n",
       "      <th>feature_1265_sms</th>\n",
       "      <th>feature_1266_sms</th>\n",
       "      <th>feature_1267_sms</th>\n",
       "      <th>feature_1268_sms</th>\n",
       "      <th>feature_1269_sms</th>\n",
       "      <th>feature_1270_sms</th>\n",
       "      <th>feature_1271_sms</th>\n",
       "      <th>feature_1272_sms</th>\n",
       "      <th>feature_1273_sms</th>\n",
       "      <th>feature_1274_sms</th>\n",
       "      <th>feature_1275_sms</th>\n",
       "      <th>feature_1276_sms</th>\n",
       "      <th>feature_1277_sms</th>\n",
       "      <th>feature_1278_sms</th>\n",
       "      <th>feature_1279_sms</th>\n",
       "      <th>feature_1280_sms</th>\n",
       "      <th>feature_1281_sms</th>\n",
       "      <th>feature_1282_sms</th>\n",
       "      <th>feature_1283_sms</th>\n",
       "      <th>feature_1284_sms</th>\n",
       "      <th>feature_1285_sms</th>\n",
       "      <th>feature_1286_sms</th>\n",
       "      <th>feature_1287_sms</th>\n",
       "      <th>feature_1288_sms</th>\n",
       "      <th>feature_1289_sms</th>\n",
       "      <th>feature_1290_sms</th>\n",
       "      <th>feature_1291_sms</th>\n",
       "      <th>feature_1292_sms</th>\n",
       "      <th>feature_1293_sms</th>\n",
       "      <th>feature_1294_sms</th>\n",
       "      <th>feature_1295_sms</th>\n",
       "      <th>feature_1296_sms</th>\n",
       "      <th>feature_1297_sms</th>\n",
       "      <th>feature_1298_sms</th>\n",
       "      <th>feature_1299_sms</th>\n",
       "      <th>feature_1300_sms</th>\n",
       "      <th>feature_1301_sms</th>\n",
       "      <th>feature_1302_sms</th>\n",
       "      <th>feature_1303_sms</th>\n",
       "      <th>feature_1304_sms</th>\n",
       "      <th>feature_1305_sms</th>\n",
       "      <th>feature_1306_sms</th>\n",
       "      <th>feature_1307_sms</th>\n",
       "      <th>feature_1308_sms</th>\n",
       "      <th>feature_1309_sms</th>\n",
       "      <th>feature_1310_sms</th>\n",
       "      <th>feature_1311_sms</th>\n",
       "      <th>feature_1312_sms</th>\n",
       "      <th>feature_1313_sms</th>\n",
       "      <th>feature_1314_sms</th>\n",
       "      <th>feature_1315_sms</th>\n",
       "      <th>feature_1316_sms</th>\n",
       "      <th>feature_1317_sms</th>\n",
       "      <th>feature_1318_sms</th>\n",
       "      <th>feature_1319_sms</th>\n",
       "      <th>feature_1320_sms</th>\n",
       "      <th>feature_1321_sms</th>\n",
       "      <th>feature_1322_sms</th>\n",
       "      <th>feature_1323_sms</th>\n",
       "      <th>feature_1324_sms</th>\n",
       "      <th>feature_1325_sms</th>\n",
       "      <th>feature_1326_sms</th>\n",
       "      <th>feature_1327_sms</th>\n",
       "      <th>feature_1328_sms</th>\n",
       "      <th>feature_1329_sms</th>\n",
       "      <th>feature_1330_sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>732.0</td>\n",
       "      <td>0.400396</td>\n",
       "      <td>17</td>\n",
       "      <td>6.665722</td>\n",
       "      <td>5.998750</td>\n",
       "      <td>46</td>\n",
       "      <td>6.998800</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>0.363620</td>\n",
       "      <td>59011</td>\n",
       "      <td>22</td>\n",
       "      <td>364464</td>\n",
       "      <td>16</td>\n",
       "      <td>81364</td>\n",
       "      <td>12949</td>\n",
       "      <td>28.486257</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11.397920</td>\n",
       "      <td>65.935065</td>\n",
       "      <td>5.498875</td>\n",
       "      <td>214</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87016.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>13492.000000</td>\n",
       "      <td>604227.0</td>\n",
       "      <td>33568.166667</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>42007.514571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>260.0</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.334615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85432.0</td>\n",
       "      <td>59011.0</td>\n",
       "      <td>16295.000000</td>\n",
       "      <td>224089.0</td>\n",
       "      <td>47740.988110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.40</td>\n",
       "      <td>9.840000</td>\n",
       "      <td>24.35</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.559937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.433437</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217.0</td>\n",
       "      <td>164.500000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1173.500000</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>792.642857</td>\n",
       "      <td>217.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>713.952381</td>\n",
       "      <td>564.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>281.136364</td>\n",
       "      <td>258.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197.0</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>771.045455</td>\n",
       "      <td>197.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>239.0</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.095351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>783</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>905</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>101</td>\n",
       "      <td>9</td>\n",
       "      <td>1227</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>271</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>416</td>\n",
       "      <td>26</td>\n",
       "      <td>91</td>\n",
       "      <td>166</td>\n",
       "      <td>16</td>\n",
       "      <td>2999</td>\n",
       "      <td>173</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>723</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>171</td>\n",
       "      <td>12</td>\n",
       "      <td>1088</td>\n",
       "      <td>49</td>\n",
       "      <td>201</td>\n",
       "      <td>390</td>\n",
       "      <td>42</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>0.045682</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.175182</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.306569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.124088</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.051095</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.036496</td>\n",
       "      <td>42.142857</td>\n",
       "      <td>42.142857</td>\n",
       "      <td>0.098366</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>0.210169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.098305</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>0.105085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.857143</td>\n",
       "      <td>0.376271</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>0.091525</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>38.214286</td>\n",
       "      <td>38.214286</td>\n",
       "      <td>0.178393</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>9.714286</td>\n",
       "      <td>0.254206</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>0.080374</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>4.785714</td>\n",
       "      <td>0.125234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.071429</td>\n",
       "      <td>0.368224</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>0.069159</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.065421</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>37.285714</td>\n",
       "      <td>37.285714</td>\n",
       "      <td>0.261087</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>9.142857</td>\n",
       "      <td>0.245211</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>0.088123</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.809524</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>2.476190</td>\n",
       "      <td>0.066411</td>\n",
       "      <td>3.095238</td>\n",
       "      <td>0.083014</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>30.166667</td>\n",
       "      <td>30.166667</td>\n",
       "      <td>0.301767</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.243094</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>0.081768</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>0.098343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.364641</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>0.111602</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>20.450000</td>\n",
       "      <td>21.910714</td>\n",
       "      <td>0.409136</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>4.516667</td>\n",
       "      <td>0.220864</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>0.079870</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>1.983333</td>\n",
       "      <td>0.096985</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>6.933333</td>\n",
       "      <td>0.339038</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.021190</td>\n",
       "      <td>1.516667</td>\n",
       "      <td>0.074165</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>0.135289</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>2.999</td>\n",
       "      <td>17.335260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.241080</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.057019</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.362788</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.067022</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.130043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.014005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6547</th>\n",
       "      <td>518.0</td>\n",
       "      <td>0.370718</td>\n",
       "      <td>42</td>\n",
       "      <td>34.988670</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>46</td>\n",
       "      <td>11.797840</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>0.107691</td>\n",
       "      <td>201224</td>\n",
       "      <td>22</td>\n",
       "      <td>290622</td>\n",
       "      <td>69</td>\n",
       "      <td>64832</td>\n",
       "      <td>10624</td>\n",
       "      <td>45.977511</td>\n",
       "      <td>30.990003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.244439</td>\n",
       "      <td>138.862138</td>\n",
       "      <td>12.997600</td>\n",
       "      <td>272</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>75</td>\n",
       "      <td>92.908092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98741.0</td>\n",
       "      <td>66750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8805.042136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>543500.0</td>\n",
       "      <td>212000.0</td>\n",
       "      <td>81793.398267</td>\n",
       "      <td>2748243.0</td>\n",
       "      <td>42280.661538</td>\n",
       "      <td>237771.0</td>\n",
       "      <td>50555.892598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.118252</td>\n",
       "      <td>224.0</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.647876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.101317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21779.0</td>\n",
       "      <td>21779.0</td>\n",
       "      <td>8711.600000</td>\n",
       "      <td>164164.0</td>\n",
       "      <td>21030.920771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.00</td>\n",
       "      <td>18.40</td>\n",
       "      <td>32.00</td>\n",
       "      <td>14.50</td>\n",
       "      <td>6.843975</td>\n",
       "      <td>583.80</td>\n",
       "      <td>12.973333</td>\n",
       "      <td>32.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>6.082344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.118252</td>\n",
       "      <td>3.446154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.589107</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>353.0</td>\n",
       "      <td>300.800000</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>709.092308</td>\n",
       "      <td>430.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>504.517241</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>101.40</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>431.246154</td>\n",
       "      <td>303.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>303.0</td>\n",
       "      <td>272.600000</td>\n",
       "      <td>303.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>658.938462</td>\n",
       "      <td>485.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.939072</td>\n",
       "      <td>681.0</td>\n",
       "      <td>10.476923</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.637643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>389.0</td>\n",
       "      <td>77.800000</td>\n",
       "      <td>206.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>568</td>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>184</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>32</td>\n",
       "      <td>83</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>3000</td>\n",
       "      <td>283</td>\n",
       "      <td>291</td>\n",
       "      <td>88</td>\n",
       "      <td>719</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>6</td>\n",
       "      <td>461</td>\n",
       "      <td>141</td>\n",
       "      <td>424</td>\n",
       "      <td>378</td>\n",
       "      <td>35</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.571429</td>\n",
       "      <td>12.571429</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>13.071429</td>\n",
       "      <td>13.071429</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>0.092896</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.109290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.087432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.136612</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.087432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>11.952381</td>\n",
       "      <td>11.952381</td>\n",
       "      <td>0.083667</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.067729</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.390438</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.011952</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.131474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.063745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.619048</td>\n",
       "      <td>0.135458</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.043825</td>\n",
       "      <td>1.380952</td>\n",
       "      <td>0.115538</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.066007</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>0.366337</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>0.125413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.118812</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.052805</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.033003</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>9.466667</td>\n",
       "      <td>9.466667</td>\n",
       "      <td>0.189333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.063380</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.110915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.059859</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.147887</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>1.383333</td>\n",
       "      <td>0.146127</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.040493</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>3.000</td>\n",
       "      <td>10.600707</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.239667</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.070667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.141333</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.011667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>762.0</td>\n",
       "      <td>0.420800</td>\n",
       "      <td>12</td>\n",
       "      <td>2.998002</td>\n",
       "      <td>8.992008</td>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.399920</td>\n",
       "      <td>68568</td>\n",
       "      <td>1</td>\n",
       "      <td>68932</td>\n",
       "      <td>99</td>\n",
       "      <td>364</td>\n",
       "      <td>8226</td>\n",
       "      <td>3.498751</td>\n",
       "      <td>6.994006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.498751</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>4.996004</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>6.994006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>784.400000</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>1568.800000</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1568.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25350.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>6039.172129</td>\n",
       "      <td>25350.0</td>\n",
       "      <td>5070.000000</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>6039.172129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68932.0</td>\n",
       "      <td>68568.0</td>\n",
       "      <td>27391.162791</td>\n",
       "      <td>68568.0</td>\n",
       "      <td>27391.162791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>194.400000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>194.400000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>156.666667</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>154.25</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>154.250000</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>115.2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>115.200000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>182.200000</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>182.200000</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.033150</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.033150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>327</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>464</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>114</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>972</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>21</td>\n",
       "      <td>260</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>2975</td>\n",
       "      <td>167</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1199</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>395</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>102</td>\n",
       "      <td>89</td>\n",
       "      <td>669</td>\n",
       "      <td>162</td>\n",
       "      <td>185</td>\n",
       "      <td>84</td>\n",
       "      <td>36</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>0.045378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>0.281481</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.081481</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>18.357143</td>\n",
       "      <td>18.357143</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>0.268482</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.038911</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.140078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.093385</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.027237</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>0.287938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.027237</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.023346</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>15.571429</td>\n",
       "      <td>15.571429</td>\n",
       "      <td>0.109916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>0.293578</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.051988</td>\n",
       "      <td>2.190476</td>\n",
       "      <td>0.140673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.085627</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>3.952381</td>\n",
       "      <td>0.253823</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.033639</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.061162</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.024465</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>15.466667</td>\n",
       "      <td>15.466667</td>\n",
       "      <td>0.155966</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.233333</td>\n",
       "      <td>0.338362</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.047414</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.023707</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.245690</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.036638</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>0.326723</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.233333</td>\n",
       "      <td>0.384774</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.022634</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>0.115226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.021605</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.267490</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.033951</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>2.975</td>\n",
       "      <td>17.814371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>1.199</td>\n",
       "      <td>0.403025</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.132773</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.029916</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.224874</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.062185</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.028235</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.012101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>746.0</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>27</td>\n",
       "      <td>5.998334</td>\n",
       "      <td>4.498251</td>\n",
       "      <td>46</td>\n",
       "      <td>2.749563</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.599880</td>\n",
       "      <td>47246</td>\n",
       "      <td>0</td>\n",
       "      <td>47246</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>11472</td>\n",
       "      <td>4.998667</td>\n",
       "      <td>3.749313</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.998667</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>2.499250</td>\n",
       "      <td>164</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>13.987013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43490.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>6255.000000</td>\n",
       "      <td>228499.0</td>\n",
       "      <td>45699.800000</td>\n",
       "      <td>85485.0</td>\n",
       "      <td>23840.693366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.545268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>14549.000000</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>12079.789773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.44</td>\n",
       "      <td>15.813333</td>\n",
       "      <td>25.00</td>\n",
       "      <td>9.95</td>\n",
       "      <td>6.578198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.631514</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.0</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>524.200000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>76.00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>197.400000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>161.400000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.0</td>\n",
       "      <td>209.500000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>508.600000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>381</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>441</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>629</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>207</td>\n",
       "      <td>32</td>\n",
       "      <td>71</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1129</td>\n",
       "      <td>265</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>129</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>295</td>\n",
       "      <td>42</td>\n",
       "      <td>168</td>\n",
       "      <td>181</td>\n",
       "      <td>27</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>0.064659</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.714286</td>\n",
       "      <td>21.714286</td>\n",
       "      <td>0.134632</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046053</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.059211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.138158</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>19.571429</td>\n",
       "      <td>19.571429</td>\n",
       "      <td>0.242693</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.018248</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.094891</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.182482</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.054745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>0.394161</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>0.120438</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>18.142857</td>\n",
       "      <td>18.142857</td>\n",
       "      <td>0.337467</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.020997</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.110236</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.196850</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.049869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.404199</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.018373</td>\n",
       "      <td>2.047619</td>\n",
       "      <td>0.112861</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.018373</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>0.390611</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>0.120181</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.024943</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.197279</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.049887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.566667</td>\n",
       "      <td>0.378685</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>0.120181</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>10.483333</td>\n",
       "      <td>10.483333</td>\n",
       "      <td>0.557130</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.138315</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.182830</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.062003</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>0.329094</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.050874</td>\n",
       "      <td>1.183333</td>\n",
       "      <td>0.112878</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.031797</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>1.129</td>\n",
       "      <td>4.260377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.024801</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.023915</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.122232</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.114260</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.052259</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.261293</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.037201</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.148804</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.160319</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.023915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>700.0</td>\n",
       "      <td>0.385723</td>\n",
       "      <td>52</td>\n",
       "      <td>7.748313</td>\n",
       "      <td>12.497126</td>\n",
       "      <td>46</td>\n",
       "      <td>3.666222</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.437473</td>\n",
       "      <td>40878</td>\n",
       "      <td>88</td>\n",
       "      <td>339424</td>\n",
       "      <td>12</td>\n",
       "      <td>298546</td>\n",
       "      <td>11260</td>\n",
       "      <td>20.990005</td>\n",
       "      <td>7.798640</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.999286</td>\n",
       "      <td>52.948052</td>\n",
       "      <td>3.999250</td>\n",
       "      <td>258</td>\n",
       "      <td>62</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>37.963037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>803.666667</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>1797.053298</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1202.818128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>331598.0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>28811.055984</td>\n",
       "      <td>548219.0</td>\n",
       "      <td>34263.687500</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>27368.428373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278210.0</td>\n",
       "      <td>75464.0</td>\n",
       "      <td>29261.683648</td>\n",
       "      <td>75464.0</td>\n",
       "      <td>28188.354776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>62.00</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>42.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.944272</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.942103</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332.0</td>\n",
       "      <td>268.333333</td>\n",
       "      <td>244.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>244.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>523.777778</td>\n",
       "      <td>51.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>69.20</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>285.461538</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>269.625000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.0</td>\n",
       "      <td>246.666667</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>560.937500</td>\n",
       "      <td>242.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>165.0</td>\n",
       "      <td>10.312500</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.310810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>482</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>677</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>40</td>\n",
       "      <td>19</td>\n",
       "      <td>1121</td>\n",
       "      <td>60</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>266</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>16</td>\n",
       "      <td>130</td>\n",
       "      <td>67</td>\n",
       "      <td>27</td>\n",
       "      <td>3000</td>\n",
       "      <td>159</td>\n",
       "      <td>156</td>\n",
       "      <td>57</td>\n",
       "      <td>725</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>1047</td>\n",
       "      <td>52</td>\n",
       "      <td>256</td>\n",
       "      <td>174</td>\n",
       "      <td>79</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>23.142857</td>\n",
       "      <td>23.142857</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>9.285714</td>\n",
       "      <td>0.401235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>0.290123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>22.952381</td>\n",
       "      <td>22.952381</td>\n",
       "      <td>0.160667</td>\n",
       "      <td>1.380952</td>\n",
       "      <td>0.060166</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>0.292531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.029046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>2.095238</td>\n",
       "      <td>0.091286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>0.286307</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>2.809524</td>\n",
       "      <td>0.122407</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.056017</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.018672</td>\n",
       "      <td>22.566667</td>\n",
       "      <td>22.566667</td>\n",
       "      <td>0.225667</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0.060561</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.023634</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>0.262925</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.011817</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.097489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.257016</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.137371</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.059084</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.028065</td>\n",
       "      <td>18.683333</td>\n",
       "      <td>18.683333</td>\n",
       "      <td>0.373667</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.066905</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.022302</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.046387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>0.110616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.266667</td>\n",
       "      <td>0.281891</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.014273</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.115968</td>\n",
       "      <td>1.116667</td>\n",
       "      <td>0.059768</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.024086</td>\n",
       "      <td>3.000</td>\n",
       "      <td>18.867925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.047667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>1.047</td>\n",
       "      <td>0.349000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.026333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1761 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BureauScore  MissingRate  Len_Name  Tel_nuniq  Email_nuniq  \\\n",
       "502         732.0     0.400396        17   6.665722     5.998750   \n",
       "6547        518.0     0.370718        42  34.988670    25.987506   \n",
       "6938        762.0     0.420800        12   2.998002     8.992008   \n",
       "3115        746.0     0.396552        27   5.998334     4.498251   \n",
       "3649        700.0     0.385723        52   7.748313    12.497126   \n",
       "\n",
       "      Len_of_addrs  City_nuniq  Current_State  CreditAccountActive  \\\n",
       "502             46    6.998800             27                    8   \n",
       "6547            46   11.797840             27                    7   \n",
       "6938            46    1.000000             27                    2   \n",
       "3115            46    2.749563             27                    3   \n",
       "3649            46    3.666222             27                    7   \n",
       "\n",
       "      CreditAccountTotal  CreditAccountActivePor  Outstanding_Balance_Secured  \\\n",
       "502                   22                0.363620                        59011   \n",
       "6547                  65                0.107691                       201224   \n",
       "6938                   5                0.399920                        68568   \n",
       "3115                   5                0.599880                        47246   \n",
       "3649                  16                0.437473                        40878   \n",
       "\n",
       "      Outstanding_Balance_UnSecured_Percentage  Outstanding_Balance_All  \\\n",
       "502                                         22                   364464   \n",
       "6547                                        22                   290622   \n",
       "6938                                         1                    68932   \n",
       "3115                                         0                    47246   \n",
       "3649                                        88                   339424   \n",
       "\n",
       "      Outstanding_Balance_Secured_Percentage  Outstanding_Balance_UnSecured  \\\n",
       "502                                       16                          81364   \n",
       "6547                                      69                          64832   \n",
       "6938                                      99                            364   \n",
       "3115                                     100                              0   \n",
       "3649                                      12                         298546   \n",
       "\n",
       "      Diff_dateBirth  State_nuniq  Birth_nuniq  TotalCAPSLast90Days  \\\n",
       "502            12949    28.486257    25.987506                    4   \n",
       "6547           10624    45.977511    30.990003                    1   \n",
       "6938            8226     3.498751     6.994006                    0   \n",
       "3115           11472     4.998667     3.749313                    5   \n",
       "3649           11260    20.990005     7.798640                    3   \n",
       "\n",
       "      TotalCAPSLast7Days  TotalCAPSLast30Days  TotalCAPSLast180Days  \\\n",
       "502                    3                    3                     5   \n",
       "6547                   1                    1                     2   \n",
       "6938                   0                    0                     0   \n",
       "3115                   2                    4                     6   \n",
       "3649                   2                    2                     3   \n",
       "\n",
       "      CAPSLast30Days  CAPSLast7Days  CAPSLast180Days  \\\n",
       "502                0              0                2   \n",
       "6547               0              0                1   \n",
       "6938               0              0                0   \n",
       "3115               2              0                4   \n",
       "3649               1              1                2   \n",
       "\n",
       "      NonCreditCAPSLast180Days  Pin_nuniq   Pan_nuniq  Ident_nuniq  \\\n",
       "502                          3  11.397920   65.935065     5.498875   \n",
       "6547                         1  23.244439  138.862138    12.997600   \n",
       "6938                         0   3.498751   10.990010     4.996004   \n",
       "3115                         2   4.998667   10.990010     2.499250   \n",
       "3649                         1   5.999286   52.948052     3.999250   \n",
       "\n",
       "      Name_nuniq2  Tel_nuniq2  Email_nuniq2  Pan_nuniq2  Account_nuniq2  \\\n",
       "502           214          86            93          14              14   \n",
       "6547          272          44            47          14              14   \n",
       "6938           57          14            25          14              14   \n",
       "3115          164          44            44          14              14   \n",
       "3649          258          62            87          14              14   \n",
       "\n",
       "      Ident_nuniq2  Gender_nuniq  Amount_Past_Due35_sum_30  \\\n",
       "502             60     25.987506                       NaN   \n",
       "6547            75     92.908092                       NaN   \n",
       "6938            15      6.994006                       NaN   \n",
       "3115            30     13.987013                       NaN   \n",
       "3649            60     37.963037                       NaN   \n",
       "\n",
       "      Amount_Past_Due35_min_30  Amount_Past_Due35_sum_90  \\\n",
       "502                        NaN                       NaN   \n",
       "6547                       NaN                       NaN   \n",
       "6938                       NaN                       0.0   \n",
       "3115                       NaN                       NaN   \n",
       "3649                       NaN                       NaN   \n",
       "\n",
       "      Amount_Past_Due35_mean_90  Amount_Past_Due35_max_90  \\\n",
       "502                         NaN                       NaN   \n",
       "6547                        NaN                       NaN   \n",
       "6938                        0.0                       0.0   \n",
       "3115                        NaN                       NaN   \n",
       "3649                        NaN                       NaN   \n",
       "\n",
       "      Amount_Past_Due35_min_90  Amount_Past_Due35_std_90  \\\n",
       "502                        NaN                       NaN   \n",
       "6547                       NaN                       NaN   \n",
       "6938                       0.0                       0.0   \n",
       "3115                       NaN                       NaN   \n",
       "3649                       NaN                       NaN   \n",
       "\n",
       "      Amount_Past_Due35_sum_360  Amount_Past_Due35_mean_360  \\\n",
       "502                         0.0                    0.000000   \n",
       "6547                        0.0                    0.000000   \n",
       "6938                     3922.0                  784.400000   \n",
       "3115                        0.0                    0.000000   \n",
       "3649                     4822.0                  803.666667   \n",
       "\n",
       "      Amount_Past_Due35_max_360  Amount_Past_Due35_std_360  \\\n",
       "502                         0.0                   0.000000   \n",
       "6547                        0.0                   0.000000   \n",
       "6938                     3922.0                1568.800000   \n",
       "3115                        0.0                   0.000000   \n",
       "3649                     4822.0                1797.053298   \n",
       "\n",
       "      Amount_Past_Due35_sum_9999  Amount_Past_Due35_max_9999  \\\n",
       "502                          0.0                         0.0   \n",
       "6547                     98741.0                     66750.0   \n",
       "6938                      3922.0                      3922.0   \n",
       "3115                         0.0                         0.0   \n",
       "3649                      4822.0                      4822.0   \n",
       "\n",
       "      Amount_Past_Due35_min_9999  Amount_Past_Due35_std_9999  \\\n",
       "502                          0.0                    0.000000   \n",
       "6547                         0.0                 8805.042136   \n",
       "6938                         0.0                 1568.800000   \n",
       "3115                         0.0                    0.000000   \n",
       "3649                         0.0                 1202.818128   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_30  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                              NaN   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_min_30  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                              NaN   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_30  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                              NaN   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_90  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                            350.0   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_mean_90  \\\n",
       "502                                                NaN   \n",
       "6547                                               NaN   \n",
       "6938                                             350.0   \n",
       "3115                                               NaN   \n",
       "3649                                               NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_90  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                            350.0   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_min_90  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                            350.0   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                              0.0   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_360  \\\n",
       "502                                            87016.0   \n",
       "6547                                          543500.0   \n",
       "6938                                           25350.0   \n",
       "3115                                           43490.0   \n",
       "3649                                          331598.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_360  \\\n",
       "502                                            57000.0   \n",
       "6547                                          212000.0   \n",
       "6938                                           17000.0   \n",
       "3115                                           28000.0   \n",
       "3649                                           88000.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_360  \\\n",
       "502                                       13492.000000   \n",
       "6547                                      81793.398267   \n",
       "6938                                       6039.172129   \n",
       "3115                                       6255.000000   \n",
       "3649                                      28811.055984   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "502                                            604227.0   \n",
       "6547                                          2748243.0   \n",
       "6938                                            25350.0   \n",
       "3115                                           228499.0   \n",
       "3649                                           548219.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_mean_9999  \\\n",
       "502                                        33568.166667    \n",
       "6547                                       42280.661538    \n",
       "6938                                        5070.000000    \n",
       "3115                                       45699.800000    \n",
       "3649                                       34263.687500    \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "502                                            195000.0   \n",
       "6547                                           237771.0   \n",
       "6938                                            17000.0   \n",
       "3115                                            85485.0   \n",
       "3649                                            88000.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_9999  \\\n",
       "502                                        42007.514571   \n",
       "6547                                       50555.892598   \n",
       "6938                                        6039.172129   \n",
       "3115                                       23840.693366   \n",
       "3649                                       27368.428373   \n",
       "\n",
       "      Terms_Duration34_sum_30  Terms_Duration34_std_30  \\\n",
       "502                       NaN                      NaN   \n",
       "6547                      NaN                      NaN   \n",
       "6938                      NaN                      NaN   \n",
       "3115                      NaN                      NaN   \n",
       "3649                      NaN                      NaN   \n",
       "\n",
       "      Terms_Duration34_sum_90  Terms_Duration34_std_90  \\\n",
       "502                       NaN                      NaN   \n",
       "6547                      NaN                      NaN   \n",
       "6938                      0.0                      NaN   \n",
       "3115                      NaN                      NaN   \n",
       "3649                      NaN                      NaN   \n",
       "\n",
       "      Terms_Duration34_mean_360  Terms_Duration34_max_360  \\\n",
       "502                         4.5                       8.0   \n",
       "6547                        4.8                      13.0   \n",
       "6938                       30.0                      30.0   \n",
       "3115                       11.0                      12.0   \n",
       "3649                       24.0                      24.0   \n",
       "\n",
       "      Terms_Duration34_min_360  Terms_Duration34_std_360  \\\n",
       "502                        1.0                  3.500000   \n",
       "6547                       2.0                  4.118252   \n",
       "6938                      30.0                  0.000000   \n",
       "3115                      10.0                  1.000000   \n",
       "3649                      24.0                  0.000000   \n",
       "\n",
       "      Terms_Duration34_sum_9999  Terms_Duration34_mean_9999  \\\n",
       "502                       260.0                   17.333333   \n",
       "6547                      224.0                    5.600000   \n",
       "6938                       30.0                   30.000000   \n",
       "3115                       58.0                   14.500000   \n",
       "3649                       31.0                   15.500000   \n",
       "\n",
       "      Terms_Duration34_max_9999  Terms_Duration34_min_9999  \\\n",
       "502                        47.0                        1.0   \n",
       "6547                       40.0                        0.0   \n",
       "6938                       30.0                       30.0   \n",
       "3115                       24.0                       10.0   \n",
       "3649                       24.0                        7.0   \n",
       "\n",
       "      Terms_Duration34_std_9999  Payment_Rating34_sum_90  \\\n",
       "502                   17.334615                      NaN   \n",
       "6547                   7.647876                      NaN   \n",
       "6938                   0.000000                      0.0   \n",
       "3115                   5.545268                      NaN   \n",
       "3649                   8.500000                      NaN   \n",
       "\n",
       "      Payment_Rating34_mean_90  Payment_Rating34_max_90  \\\n",
       "502                        NaN                      NaN   \n",
       "6547                       NaN                      NaN   \n",
       "6938                       0.0                      0.0   \n",
       "3115                       NaN                      NaN   \n",
       "3649                       NaN                      NaN   \n",
       "\n",
       "      Payment_Rating34_min_90  Payment_Rating34_std_90  \\\n",
       "502                       NaN                      NaN   \n",
       "6547                      NaN                      NaN   \n",
       "6938                      0.0                      0.0   \n",
       "3115                      NaN                      NaN   \n",
       "3649                      NaN                      NaN   \n",
       "\n",
       "      Payment_Rating34_sum_360  Payment_Rating34_mean_360  \\\n",
       "502                        0.0                        0.0   \n",
       "6547                       0.0                        0.0   \n",
       "6938                       0.0                        0.0   \n",
       "3115                       0.0                        0.0   \n",
       "3649                       0.0                        0.0   \n",
       "\n",
       "      Payment_Rating34_max_360  Payment_Rating34_min_360  \\\n",
       "502                        0.0                       0.0   \n",
       "6547                       0.0                       0.0   \n",
       "6938                       0.0                       0.0   \n",
       "3115                       0.0                       0.0   \n",
       "3649                       0.0                       0.0   \n",
       "\n",
       "      Payment_Rating34_std_360  Payment_Rating34_sum_9999  \\\n",
       "502                        0.0                        0.0   \n",
       "6547                       0.0                       17.0   \n",
       "6938                       0.0                        0.0   \n",
       "3115                       0.0                        0.0   \n",
       "3649                       0.0                        0.0   \n",
       "\n",
       "      Payment_Rating34_mean_9999  Payment_Rating34_max_9999  \\\n",
       "502                     0.000000                        0.0   \n",
       "6547                    0.269841                        6.0   \n",
       "6938                    0.000000                        0.0   \n",
       "3115                    0.000000                        0.0   \n",
       "3649                    0.000000                        0.0   \n",
       "\n",
       "      Payment_Rating34_min_9999  Payment_Rating34_std_9999  \\\n",
       "502                         0.0                   0.000000   \n",
       "6547                        0.0                   1.101317   \n",
       "6938                        0.0                   0.000000   \n",
       "3115                        0.0                   0.000000   \n",
       "3649                        0.0                   0.000000   \n",
       "\n",
       "      Current_Balance35_mean_30  Current_Balance35_min_30  \\\n",
       "502                         NaN                       NaN   \n",
       "6547                        NaN                       NaN   \n",
       "6938                        NaN                       NaN   \n",
       "3115                        NaN                       NaN   \n",
       "3649                        NaN                       NaN   \n",
       "\n",
       "      Current_Balance35_std_30  Current_Balance35_sum_90  \\\n",
       "502                        NaN                       NaN   \n",
       "6547                       NaN                       NaN   \n",
       "6938                       NaN                     364.0   \n",
       "3115                       NaN                       NaN   \n",
       "3649                       NaN                       NaN   \n",
       "\n",
       "      Current_Balance35_mean_90  Current_Balance35_max_90  \\\n",
       "502                         NaN                       NaN   \n",
       "6547                        NaN                       NaN   \n",
       "6938                      364.0                     364.0   \n",
       "3115                        NaN                       NaN   \n",
       "3649                        NaN                       NaN   \n",
       "\n",
       "      Current_Balance35_std_90  Current_Balance35_sum_360  \\\n",
       "502                        NaN                    85432.0   \n",
       "6547                       NaN                    21779.0   \n",
       "6938                       0.0                    68932.0   \n",
       "3115                       NaN                    29098.0   \n",
       "3649                       NaN                   278210.0   \n",
       "\n",
       "      Current_Balance35_max_360  Current_Balance35_std_360  \\\n",
       "502                     59011.0               16295.000000   \n",
       "6547                    21779.0                8711.600000   \n",
       "6938                    68568.0               27391.162791   \n",
       "3115                    29098.0               14549.000000   \n",
       "3649                    75464.0               29261.683648   \n",
       "\n",
       "      Current_Balance35_max_9999  Current_Balance35_std_9999  \\\n",
       "502                     224089.0                47740.988110   \n",
       "6547                    164164.0                21030.920771   \n",
       "6938                     68568.0                27391.162791   \n",
       "3115                     29098.0                12079.789773   \n",
       "3649                     75464.0                28188.354776   \n",
       "\n",
       "      Settlement_Amount37_max_360  Settlement_Amount37_min_360  \\\n",
       "502                           NaN                          NaN   \n",
       "6547                          NaN                          NaN   \n",
       "6938                          0.0                          0.0   \n",
       "3115                          NaN                          NaN   \n",
       "3649                          NaN                          NaN   \n",
       "\n",
       "      Settlement_Amount37_std_360  Settlement_Amount37_sum_9999  \\\n",
       "502                           NaN                           0.0   \n",
       "6547                          NaN                           0.0   \n",
       "6938                          0.0                           0.0   \n",
       "3115                          NaN                           0.0   \n",
       "3649                          NaN                           0.0   \n",
       "\n",
       "      Settlement_Amount37_mean_9999  Settlement_Amount37_max_9999  \\\n",
       "502                             0.0                           0.0   \n",
       "6547                            0.0                           0.0   \n",
       "6938                            0.0                           0.0   \n",
       "3115                            NaN                           NaN   \n",
       "3649                            0.0                           0.0   \n",
       "\n",
       "      Settlement_Amount37_min_9999  Settlement_Amount37_std_9999  \\\n",
       "502                            0.0                           0.0   \n",
       "6547                           0.0                           0.0   \n",
       "6938                           0.0                           0.0   \n",
       "3115                           NaN                           NaN   \n",
       "3649                           0.0                           0.0   \n",
       "\n",
       "      Value_of_Collateral39_std_90  Value_of_Collateral39_std_360  \\\n",
       "502                            NaN                            0.0   \n",
       "6547                           NaN                            NaN   \n",
       "6938                           NaN                            NaN   \n",
       "3115                           NaN                            0.0   \n",
       "3649                           NaN                            0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_sum_360  Written_Off_Amt_Total41_mean_360  \\\n",
       "502                               0.0                               NaN   \n",
       "6547                              0.0                               NaN   \n",
       "6938                              0.0                               0.0   \n",
       "3115                              0.0                               NaN   \n",
       "3649                              0.0                               0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_min_360  Written_Off_Amt_Total41_std_360  \\\n",
       "502                               NaN                              NaN   \n",
       "6547                              NaN                              NaN   \n",
       "6938                              0.0                              0.0   \n",
       "3115                              NaN                              NaN   \n",
       "3649                              0.0                              0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_sum_9999  Written_Off_Amt_Total41_mean_9999  \\\n",
       "502                                0.0                                0.0   \n",
       "6547                               0.0                                0.0   \n",
       "6938                               0.0                                0.0   \n",
       "3115                               0.0                                NaN   \n",
       "3649                               0.0                                0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_max_9999  Written_Off_Amt_Total41_min_9999  \\\n",
       "502                                0.0                               0.0   \n",
       "6547                               0.0                               0.0   \n",
       "6938                               0.0                               0.0   \n",
       "3115                               NaN                               NaN   \n",
       "3649                               0.0                               0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_std_9999  Written_Off_Amt_Principal45_sum_360  \\\n",
       "502                                0.0                                  0.0   \n",
       "6547                               0.0                                  0.0   \n",
       "6938                               0.0                                  0.0   \n",
       "3115                               NaN                                  0.0   \n",
       "3649                               0.0                                  0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_mean_360  \\\n",
       "502                                    NaN   \n",
       "6547                                   NaN   \n",
       "6938                                   0.0   \n",
       "3115                                   NaN   \n",
       "3649                                   NaN   \n",
       "\n",
       "      Written_Off_Amt_Principal45_min_360  \\\n",
       "502                                   NaN   \n",
       "6547                                  NaN   \n",
       "6938                                  0.0   \n",
       "3115                                  NaN   \n",
       "3649                                  NaN   \n",
       "\n",
       "      Written_Off_Amt_Principal45_std_360  \\\n",
       "502                                   NaN   \n",
       "6547                                  NaN   \n",
       "6938                                  0.0   \n",
       "3115                                  NaN   \n",
       "3649                                  NaN   \n",
       "\n",
       "      Written_Off_Amt_Principal45_max_9999  \\\n",
       "502                                    0.0   \n",
       "6547                                   0.0   \n",
       "6938                                   0.0   \n",
       "3115                                   0.0   \n",
       "3649                                   0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_min_9999  Rate_of_Interest36_sum_30  \\\n",
       "502                                    0.0                        NaN   \n",
       "6547                                   0.0                        NaN   \n",
       "6938                                   0.0                        NaN   \n",
       "3115                                   0.0                        NaN   \n",
       "3649                                   0.0                        NaN   \n",
       "\n",
       "      Rate_of_Interest36_std_30  Rate_of_Interest36_sum_90  \\\n",
       "502                         NaN                        NaN   \n",
       "6547                        NaN                        NaN   \n",
       "6938                        NaN                        0.0   \n",
       "3115                        NaN                        NaN   \n",
       "3649                        NaN                        NaN   \n",
       "\n",
       "      Rate_of_Interest36_mean_90  Rate_of_Interest36_max_90  \\\n",
       "502                          NaN                        NaN   \n",
       "6547                         NaN                        NaN   \n",
       "6938                         NaN                        NaN   \n",
       "3115                         NaN                        NaN   \n",
       "3649                         NaN                        NaN   \n",
       "\n",
       "      Rate_of_Interest36_std_90  Rate_of_Interest36_sum_360  \\\n",
       "502                         NaN                        7.40   \n",
       "6547                        NaN                       92.00   \n",
       "6938                        NaN                        0.00   \n",
       "3115                        NaN                        9.95   \n",
       "3649                        NaN                       62.00   \n",
       "\n",
       "      Rate_of_Interest36_mean_360  Rate_of_Interest36_max_360  \\\n",
       "502                          7.40                        7.40   \n",
       "6547                        18.40                       32.00   \n",
       "6938                          NaN                         NaN   \n",
       "3115                         9.95                        9.95   \n",
       "3649                        31.00                       42.00   \n",
       "\n",
       "      Rate_of_Interest36_min_360  Rate_of_Interest36_std_360  \\\n",
       "502                         7.40                    0.000000   \n",
       "6547                       14.50                    6.843975   \n",
       "6938                         NaN                         NaN   \n",
       "3115                        9.95                    0.000000   \n",
       "3649                       20.00                   11.000000   \n",
       "\n",
       "      Rate_of_Interest36_sum_9999  Rate_of_Interest36_mean_9999  \\\n",
       "502                         98.40                      9.840000   \n",
       "6547                       583.80                     12.973333   \n",
       "6938                         0.00                           NaN   \n",
       "3115                        47.44                     15.813333   \n",
       "3649                        62.00                     31.000000   \n",
       "\n",
       "      Rate_of_Interest36_max_9999  Rate_of_Interest36_min_9999  \\\n",
       "502                         24.35                         1.00   \n",
       "6547                        32.00                         1.40   \n",
       "6938                          NaN                          NaN   \n",
       "3115                        25.00                         9.95   \n",
       "3649                        42.00                        20.00   \n",
       "\n",
       "      Rate_of_Interest36_std_9999  Repayment_Tenure36_std_30  \\\n",
       "502                      5.559937                        NaN   \n",
       "6547                     6.082344                        NaN   \n",
       "6938                          NaN                        NaN   \n",
       "3115                     6.578198                        NaN   \n",
       "3649                    11.000000                        NaN   \n",
       "\n",
       "      Repayment_Tenure36_mean_90  Repayment_Tenure36_max_90  \\\n",
       "502                          NaN                        NaN   \n",
       "6547                         NaN                        NaN   \n",
       "6938                         0.0                        0.0   \n",
       "3115                         NaN                        NaN   \n",
       "3649                         NaN                        NaN   \n",
       "\n",
       "      Repayment_Tenure36_min_90  Repayment_Tenure36_std_90  \\\n",
       "502                         NaN                        NaN   \n",
       "6547                        NaN                        NaN   \n",
       "6938                        0.0                        0.0   \n",
       "3115                        NaN                        NaN   \n",
       "3649                        NaN                        NaN   \n",
       "\n",
       "      Repayment_Tenure36_sum_360  Repayment_Tenure36_mean_360  \\\n",
       "502                          9.0                          4.5   \n",
       "6547                        24.0                          4.8   \n",
       "6938                        30.0                          6.0   \n",
       "3115                        22.0                         11.0   \n",
       "3649                        24.0                          4.0   \n",
       "\n",
       "      Repayment_Tenure36_min_360  Repayment_Tenure36_std_360  \\\n",
       "502                          1.0                    3.500000   \n",
       "6547                         2.0                    4.118252   \n",
       "6938                         0.0                   12.000000   \n",
       "3115                        10.0                    1.000000   \n",
       "3649                         0.0                    8.944272   \n",
       "\n",
       "      Repayment_Tenure36_mean_9999  Repayment_Tenure36_min_9999  \\\n",
       "502                      11.818182                          0.0   \n",
       "6547                      3.446154                          0.0   \n",
       "6938                      6.000000                          0.0   \n",
       "3115                     11.600000                          0.0   \n",
       "3649                      1.937500                          0.0   \n",
       "\n",
       "      Repayment_Tenure36_std_9999  Income26_count_360  Income26_std_360  \\\n",
       "502                     16.433437                 2.0               NaN   \n",
       "6547                     6.589107                 5.0               NaN   \n",
       "6938                    12.000000                 5.0               NaN   \n",
       "3115                     7.631514                 2.0               NaN   \n",
       "3649                     5.942103                 6.0               NaN   \n",
       "\n",
       "      Open_Date29_max_30  Open_Date29_min_30  Open_Date29_mean_30  \\\n",
       "502                  NaN                 NaN                  NaN   \n",
       "6547                 NaN                 NaN                  NaN   \n",
       "6938                 NaN                 NaN                  NaN   \n",
       "3115                 NaN                 NaN                  NaN   \n",
       "3649                 NaN                 NaN                  NaN   \n",
       "\n",
       "      Open_Date29_nuniq_30  Open_Date29_maxcount_30  Open_Date29_max_90  \\\n",
       "502                    NaN                      NaN                 NaN   \n",
       "6547                   NaN                      NaN                 NaN   \n",
       "6938                   NaN                      NaN                89.0   \n",
       "3115                   NaN                      NaN                 NaN   \n",
       "3649                   NaN                      NaN                 NaN   \n",
       "\n",
       "      Open_Date29_mean_90  Open_Date29_mode_90  Open_Date29_nuniq_90  \\\n",
       "502                   NaN                  NaN                   NaN   \n",
       "6547                  NaN                  NaN                   NaN   \n",
       "6938                 89.0                 89.0                   1.0   \n",
       "3115                  NaN                  NaN                   NaN   \n",
       "3649                  NaN                  NaN                   NaN   \n",
       "\n",
       "      Open_Date29_maxcount_90  Open_Date29_max_360  Open_Date29_mean_360  \\\n",
       "502                       NaN                217.0            164.500000   \n",
       "6547                      NaN                353.0            300.800000   \n",
       "6938                      1.0                307.0            194.400000   \n",
       "3115                      NaN                304.0            219.000000   \n",
       "3649                      NaN                332.0            268.333333   \n",
       "\n",
       "      Open_Date29_mode_360  Open_Date29_nuniq_360  Open_Date29_maxcount_360  \\\n",
       "502                  112.0                    2.0                       1.0   \n",
       "6547                 212.0                    5.0                       1.0   \n",
       "6938                  89.0                    5.0                       1.0   \n",
       "3115                 134.0                    2.0                       1.0   \n",
       "3649                 244.0                    6.0                       1.0   \n",
       "\n",
       "      Open_Date29_max_9999  Open_Date29_mean_9999  Open_Date29_mode_9999  \\\n",
       "502                 2400.0            1173.500000                 1627.0   \n",
       "6547                1940.0             709.092308                  430.0   \n",
       "6938                 307.0             194.400000                   89.0   \n",
       "3115                1019.0             524.200000                  134.0   \n",
       "3649                1156.0             584.000000                  244.0   \n",
       "\n",
       "      Open_Date29_maxcount_9999  Portfolio_Type34_nuniq_30  \\\n",
       "502                         4.0                        NaN   \n",
       "6547                        3.0                        NaN   \n",
       "6938                        1.0                        NaN   \n",
       "3115                        1.0                        NaN   \n",
       "3649                        1.0                        NaN   \n",
       "\n",
       "      Portfolio_Type34_nuniq_90  Portfolio_Type34_nuniq_360  \\\n",
       "502                         NaN                         1.0   \n",
       "6547                        NaN                         1.0   \n",
       "6938                        1.0                         1.0   \n",
       "3115                        NaN                         1.0   \n",
       "3649                        NaN                         2.0   \n",
       "\n",
       "      Portfolio_Type34_nuniq_9999  Account_Type32_nuniq_30  \\\n",
       "502                           2.0                      NaN   \n",
       "6547                          3.0                      NaN   \n",
       "6938                          1.0                      NaN   \n",
       "3115                          1.0                      NaN   \n",
       "3649                          2.0                      NaN   \n",
       "\n",
       "      Account_Type32_nuniq_90  Account_Type32_nuniq_360  \\\n",
       "502                       NaN                       2.0   \n",
       "6547                      NaN                       2.0   \n",
       "6938                      1.0                       2.0   \n",
       "3115                      NaN                       2.0   \n",
       "3649                      NaN                       4.0   \n",
       "\n",
       "      Account_Type32_nuniq_9999  Occupation_Code35_nuniq_30  \\\n",
       "502                         5.0                         NaN   \n",
       "6547                        8.0                         NaN   \n",
       "6938                        2.0                         NaN   \n",
       "3115                        5.0                         NaN   \n",
       "3649                        4.0                         NaN   \n",
       "\n",
       "      Occupation_Code35_nuniq_90  Occupation_Code35_nuniq_360  \\\n",
       "502                          NaN                          1.0   \n",
       "6547                         NaN                          1.0   \n",
       "6938                         1.0                          1.0   \n",
       "3115                         NaN                          1.0   \n",
       "3649                         NaN                          1.0   \n",
       "\n",
       "      Occupation_Code35_nuniq_9999  AccountHoldertypeCode41_nuniq_90  \\\n",
       "502                            1.0                               NaN   \n",
       "6547                           1.0                               NaN   \n",
       "6938                           1.0                               1.0   \n",
       "3115                           1.0                               NaN   \n",
       "3649                           2.0                               NaN   \n",
       "\n",
       "      AccountHoldertypeCode41_nuniq_360  AccountHoldertypeCode41_nuniq_9999  \\\n",
       "502                                 1.0                                 2.0   \n",
       "6547                                1.0                                 2.0   \n",
       "6938                                1.0                                 1.0   \n",
       "3115                                1.0                                 1.0   \n",
       "3649                                1.0                                 1.0   \n",
       "\n",
       "      Payment_History_Profile43_mode_30  Payment_History_Profile43_mode_90  \\\n",
       "502                                   0                                  0   \n",
       "6547                                  0                                  0   \n",
       "6938                                  0                                  1   \n",
       "3115                                  0                                  0   \n",
       "3649                                  0                                  0   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_90  Payment_History_Profile43_mode_360  \\\n",
       "502                                  NaN                                  36   \n",
       "6547                                 NaN                                  36   \n",
       "6938                                 1.0                                   1   \n",
       "3115                                 NaN                                  36   \n",
       "3649                                 NaN                                  36   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_360  \\\n",
       "502                                   2.0   \n",
       "6547                                  4.0   \n",
       "6938                                  4.0   \n",
       "3115                                  2.0   \n",
       "3649                                  4.0   \n",
       "\n",
       "      Payment_History_Profile43_mode_9999  \\\n",
       "502                                    36   \n",
       "6547                                   36   \n",
       "6938                                    1   \n",
       "3115                                   36   \n",
       "3649                                   36   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_9999  Date_Closed31_nuniq_30  \\\n",
       "502                                   19.0                     NaN   \n",
       "6547                                  30.0                     NaN   \n",
       "6938                                   4.0                     NaN   \n",
       "3115                                   5.0                     NaN   \n",
       "3649                                  12.0                     NaN   \n",
       "\n",
       "      Date_Closed31_maxcount_30  Date_Closed31_max_90  Date_Closed31_min_90  \\\n",
       "502                         NaN                   NaN                   NaN   \n",
       "6547                        NaN                   NaN                   NaN   \n",
       "6938                        NaN                   NaN                   NaN   \n",
       "3115                        NaN                   NaN                   NaN   \n",
       "3649                        NaN                   NaN                   NaN   \n",
       "\n",
       "      Date_Closed31_mean_90  Date_Closed31_mode_90  Date_Closed31_nuniq_90  \\\n",
       "502                     NaN                    NaN                     NaN   \n",
       "6547                    NaN                    NaN                     NaN   \n",
       "6938                    NaN                    0.0                     1.0   \n",
       "3115                    NaN                    NaN                     NaN   \n",
       "3649                    NaN                    NaN                     NaN   \n",
       "\n",
       "      Date_Closed31_maxcount_90  Date_Closed31_min_360  \\\n",
       "502                         NaN                    NaN   \n",
       "6547                        NaN                   30.0   \n",
       "6938                        0.0                   91.0   \n",
       "3115                        NaN                    NaN   \n",
       "3649                        NaN                   74.0   \n",
       "\n",
       "      Date_Closed31_mode_360  Date_Closed31_nuniq_360  \\\n",
       "502                      0.0                      1.0   \n",
       "6547                    30.0                      3.0   \n",
       "6938                    91.0                      4.0   \n",
       "3115                     0.0                      1.0   \n",
       "3649                    74.0                      2.0   \n",
       "\n",
       "      Date_Closed31_maxcount_360  Date_Closed31_max_9999  \\\n",
       "502                          0.0                  1790.0   \n",
       "6547                         3.0                  1327.0   \n",
       "6938                         1.0                   222.0   \n",
       "3115                         0.0                   660.0   \n",
       "3649                         1.0                   939.0   \n",
       "\n",
       "      Date_Closed31_min_9999  Date_Closed31_mean_9999  \\\n",
       "502                    217.0               792.642857   \n",
       "6547                    30.0               504.517241   \n",
       "6938                    91.0               156.666667   \n",
       "3115                   124.0               392.000000   \n",
       "3649                    51.0               523.777778   \n",
       "\n",
       "      Date_Closed31_mode_9999  Date_Closed31_nuniq_9999  \\\n",
       "502                     217.0                      15.0   \n",
       "6547                     30.0                      38.0   \n",
       "6938                     91.0                       4.0   \n",
       "3115                    124.0                       3.0   \n",
       "3649                     51.0                      10.0   \n",
       "\n",
       "      Date_of_Last_Payment40_nuniq_30  Date_of_Last_Payment40_maxcount_30  \\\n",
       "502                               NaN                                 NaN   \n",
       "6547                              NaN                                 NaN   \n",
       "6938                              NaN                                 NaN   \n",
       "3115                              NaN                                 NaN   \n",
       "3649                              NaN                                 NaN   \n",
       "\n",
       "      Date_of_Last_Payment40_min_90  Date_of_Last_Payment40_nuniq_90  \\\n",
       "502                             NaN                              NaN   \n",
       "6547                            NaN                              NaN   \n",
       "6938                            NaN                              1.0   \n",
       "3115                            NaN                              NaN   \n",
       "3649                            NaN                              NaN   \n",
       "\n",
       "      Date_of_Last_Payment40_maxcount_90  Date_of_Last_Payment40_max_360  \\\n",
       "502                                  NaN                            73.0   \n",
       "6547                                 NaN                           212.0   \n",
       "6938                                 0.0                           222.0   \n",
       "3115                                 NaN                           119.0   \n",
       "3649                                 NaN                           100.0   \n",
       "\n",
       "      Date_of_Last_Payment40_min_360  Date_of_Last_Payment40_mean_360  \\\n",
       "502                             73.0                            73.00   \n",
       "6547                            31.0                           101.40   \n",
       "6938                            91.0                           154.25   \n",
       "3115                            33.0                            76.00   \n",
       "3649                            50.0                            69.20   \n",
       "\n",
       "      Date_of_Last_Payment40_mode_360  Date_of_Last_Payment40_nuniq_360  \\\n",
       "502                              73.0                               2.0   \n",
       "6547                             31.0                               3.0   \n",
       "6938                             91.0                               5.0   \n",
       "3115                             33.0                               2.0   \n",
       "3649                             50.0                               6.0   \n",
       "\n",
       "      Date_of_Last_Payment40_maxcount_360  Date_of_Last_Payment40_max_9999  \\\n",
       "502                                   1.0                           1957.0   \n",
       "6547                                  3.0                           1327.0   \n",
       "6938                                  1.0                            222.0   \n",
       "3115                                  1.0                            660.0   \n",
       "3649                                  1.0                            941.0   \n",
       "\n",
       "      Date_of_Last_Payment40_min_9999  Date_of_Last_Payment40_mean_9999  \\\n",
       "502                              73.0                        713.952381   \n",
       "6547                             31.0                        490.000000   \n",
       "6938                             91.0                        154.250000   \n",
       "3115                             33.0                        197.400000   \n",
       "3649                             35.0                        285.461538   \n",
       "\n",
       "      Date_of_Last_Payment40_mode_9999  Date_of_Last_Payment40_maxcount_9999  \\\n",
       "502                              564.0                                   2.0   \n",
       "6547                              31.0                                   8.0   \n",
       "6938                              91.0                                   1.0   \n",
       "3115                              33.0                                   1.0   \n",
       "3649                              53.0                                   2.0   \n",
       "\n",
       "      Date_Reported33_nuniq_30  Date_Reported33_max_90  \\\n",
       "502                        NaN                     NaN   \n",
       "6547                       NaN                     NaN   \n",
       "6938                       NaN                    60.0   \n",
       "3115                       NaN                     NaN   \n",
       "3649                       NaN                     NaN   \n",
       "\n",
       "      Date_Reported33_mean_90  Date_Reported33_mode_90  \\\n",
       "502                       NaN                      NaN   \n",
       "6547                      NaN                      NaN   \n",
       "6938                     60.0                     60.0   \n",
       "3115                      NaN                      NaN   \n",
       "3649                      NaN                      NaN   \n",
       "\n",
       "      Date_Reported33_nuniq_90  Date_Reported33_maxcount_90  \\\n",
       "502                        NaN                          NaN   \n",
       "6547                       NaN                          NaN   \n",
       "6938                       1.0                          1.0   \n",
       "3115                       NaN                          NaN   \n",
       "3649                       NaN                          NaN   \n",
       "\n",
       "      Date_Reported33_max_360  Date_Reported33_mean_360  \\\n",
       "502                      44.0                      44.0   \n",
       "6547                    181.0                      64.8   \n",
       "6938                    213.0                     115.2   \n",
       "3115                     58.0                      42.5   \n",
       "3649                     58.0                      48.0   \n",
       "\n",
       "      Date_Reported33_mode_360  Date_Reported33_nuniq_360  \\\n",
       "502                       44.0                        1.0   \n",
       "6547                      28.0                        3.0   \n",
       "6938                      60.0                        4.0   \n",
       "3115                      27.0                        2.0   \n",
       "3649                      58.0                        2.0   \n",
       "\n",
       "      Date_Reported33_maxcount_360  Date_Reported33_max_9999  \\\n",
       "502                            2.0                     989.0   \n",
       "6547                           3.0                    1854.0   \n",
       "6938                           2.0                     213.0   \n",
       "3115                           1.0                     576.0   \n",
       "3649                           4.0                     912.0   \n",
       "\n",
       "      Date_Reported33_mean_9999  Date_Reported33_mode_9999  \\\n",
       "502                  281.136364                      258.0   \n",
       "6547                 431.246154                      303.0   \n",
       "6938                 115.200000                       60.0   \n",
       "3115                 161.400000                       27.0   \n",
       "3649                 269.625000                       28.0   \n",
       "\n",
       "      Date_Reported33_nuniq_9999  Date_Reported33_maxcount_9999  \\\n",
       "502                         11.0                            5.0   \n",
       "6547                        26.0                           12.0   \n",
       "6938                         4.0                            2.0   \n",
       "3115                         4.0                            2.0   \n",
       "3649                         8.0                            5.0   \n",
       "\n",
       "      DateOfAddition34_nuniq_30  DateOfAddition34_max_90  \\\n",
       "502                         NaN                      NaN   \n",
       "6547                        NaN                      NaN   \n",
       "6938                        NaN                     60.0   \n",
       "3115                        NaN                      NaN   \n",
       "3649                        NaN                      NaN   \n",
       "\n",
       "      DateOfAddition34_mean_90  DateOfAddition34_mode_90  \\\n",
       "502                        NaN                       NaN   \n",
       "6547                       NaN                       NaN   \n",
       "6938                      60.0                      60.0   \n",
       "3115                       NaN                       NaN   \n",
       "3649                       NaN                       NaN   \n",
       "\n",
       "      DateOfAddition34_nuniq_90  DateOfAddition34_maxcount_90  \\\n",
       "502                         NaN                           NaN   \n",
       "6547                        NaN                           NaN   \n",
       "6938                        1.0                           1.0   \n",
       "3115                        NaN                           NaN   \n",
       "3649                        NaN                           NaN   \n",
       "\n",
       "      DateOfAddition34_max_360  DateOfAddition34_mean_360  \\\n",
       "502                      197.0                 151.000000   \n",
       "6547                     303.0                 272.600000   \n",
       "6938                     303.0                 182.200000   \n",
       "3115                     300.0                 209.500000   \n",
       "3649                     301.0                 246.666667   \n",
       "\n",
       "      DateOfAddition34_mode_360  DateOfAddition34_nuniq_360  \\\n",
       "502                       105.0                         2.0   \n",
       "6547                      303.0                         3.0   \n",
       "6938                      213.0                         4.0   \n",
       "3115                      119.0                         2.0   \n",
       "3649                      242.0                         3.0   \n",
       "\n",
       "      DateOfAddition34_maxcount_360  DateOfAddition34_max_9999  \\\n",
       "502                             1.0                     2115.0   \n",
       "6547                            3.0                     1885.0   \n",
       "6938                            2.0                      303.0   \n",
       "3115                            1.0                     1003.0   \n",
       "3649                            4.0                     1154.0   \n",
       "\n",
       "      DateOfAddition34_mean_9999  DateOfAddition34_mode_9999  \\\n",
       "502                   771.045455                       197.0   \n",
       "6547                  658.938462                       485.0   \n",
       "6938                  182.200000                       213.0   \n",
       "3115                  508.600000                       119.0   \n",
       "3649                  560.937500                       242.0   \n",
       "\n",
       "      DateOfAddition34_nuniq_9999  DateOfAddition34_maxcount_9999  \\\n",
       "502                          15.0                             5.0   \n",
       "6547                         27.0                             5.0   \n",
       "6938                          4.0                             2.0   \n",
       "3115                          5.0                             1.0   \n",
       "3649                         12.0                             4.0   \n",
       "\n",
       "      Account_Status34_mode_30  Account_Status34_nuniq_30  \\\n",
       "502                        NaN                        NaN   \n",
       "6547                       NaN                        NaN   \n",
       "6938                       NaN                        NaN   \n",
       "3115                       NaN                        NaN   \n",
       "3649                       NaN                        NaN   \n",
       "\n",
       "      Account_Status34_mode_90  Account_Status34_nuniq_90  \\\n",
       "502                        NaN                        NaN   \n",
       "6547                       NaN                        NaN   \n",
       "6938                      11.0                        1.0   \n",
       "3115                       NaN                        NaN   \n",
       "3649                       NaN                        NaN   \n",
       "\n",
       "      Account_Status34_mode_360  Account_Status34_nuniq_360  \\\n",
       "502                        11.0                         2.0   \n",
       "6547                       13.0                         2.0   \n",
       "6938                       13.0                         2.0   \n",
       "3115                       11.0                         1.0   \n",
       "3649                       11.0                         2.0   \n",
       "\n",
       "      Account_Status34_nuniq_9999  Month50_sum_30  Month50_max_30  \\\n",
       "502                           4.0             NaN             NaN   \n",
       "6547                          8.0             NaN             NaN   \n",
       "6938                          2.0             NaN             NaN   \n",
       "3115                          2.0             NaN             NaN   \n",
       "3649                          2.0             NaN             NaN   \n",
       "\n",
       "      Month50_std_30  Month50_sum_90  Month50_mean_90  Month50_max_90  \\\n",
       "502              NaN             NaN              NaN             NaN   \n",
       "6547             NaN             NaN              NaN             NaN   \n",
       "6938             NaN             8.0              8.0             8.0   \n",
       "3115             NaN             NaN              NaN             NaN   \n",
       "3649             NaN             NaN              NaN             NaN   \n",
       "\n",
       "      Month50_min_90  Month50_std_90  Month50_sum_360  Month50_min_360  \\\n",
       "502              NaN             NaN             20.0             10.0   \n",
       "6547             NaN             NaN             54.0              7.0   \n",
       "6938             8.0             0.0             35.0              3.0   \n",
       "3115             NaN             NaN             19.0              9.0   \n",
       "3649             NaN             NaN             54.0              8.0   \n",
       "\n",
       "      Month50_std_360  Month50_sum_9999  Month50_mean_9999  Month50_max_9999  \\\n",
       "502          0.000000             239.0          10.863636              12.0   \n",
       "6547         1.939072             681.0          10.476923              12.0   \n",
       "6938         3.033150              35.0           7.000000              12.0   \n",
       "3115         0.500000              55.0          11.000000              12.0   \n",
       "3649         1.414214             165.0          10.312500              12.0   \n",
       "\n",
       "      Month50_min_9999  Month50_std_9999  Days_Past_Due58_max_30  \\\n",
       "502                3.0          2.095351                     NaN   \n",
       "6547               1.0          2.637643                     NaN   \n",
       "6938               3.0          3.033150                     NaN   \n",
       "3115               9.0          1.264911                     NaN   \n",
       "3649               4.0          2.310810                     NaN   \n",
       "\n",
       "      Days_Past_Due58_min_30  Days_Past_Due58_mean_90  Days_Past_Due58_max_90  \\\n",
       "502                      NaN                      NaN                     NaN   \n",
       "6547                     NaN                      NaN                     NaN   \n",
       "6938                     NaN                      0.0                     0.0   \n",
       "3115                     NaN                      NaN                     NaN   \n",
       "3649                     NaN                      NaN                     NaN   \n",
       "\n",
       "      Days_Past_Due58_min_90  Days_Past_Due58_std_90  Days_Past_Due58_sum_360  \\\n",
       "502                      NaN                     NaN                      0.0   \n",
       "6547                     NaN                     NaN                    389.0   \n",
       "6938                     0.0                     0.0                     26.0   \n",
       "3115                     NaN                     NaN                      0.0   \n",
       "3649                     NaN                     NaN                     23.0   \n",
       "\n",
       "      Days_Past_Due58_mean_360  Days_Past_Due58_max_360  ...  \\\n",
       "502                   0.000000                      0.0  ...   \n",
       "6547                 77.800000                    206.0  ...   \n",
       "6938                  5.200000                     26.0  ...   \n",
       "3115                  0.000000                      0.0  ...   \n",
       "3649                  3.833333                     22.0  ...   \n",
       "\n",
       "      feature_1031_sms  feature_1032_sms  feature_1033_sms  feature_1034_sms  \\\n",
       "502                  7               783                21                 3   \n",
       "6547                 1               251                21                17   \n",
       "6938                 5               327                21                 0   \n",
       "3115                 6               381                21                 6   \n",
       "3649                 6               482                21                29   \n",
       "\n",
       "      feature_1035_sms  feature_1036_sms  feature_1037_sms  feature_1038_sms  \\\n",
       "502                  4               192                 1                 4   \n",
       "6547                 1                98                 3                 4   \n",
       "6938                 0                96                 2                17   \n",
       "3115                 8                42                 2                 9   \n",
       "3649                10               141                 0                 5   \n",
       "\n",
       "      feature_1039_sms  feature_1040_sms  feature_1041_sms  feature_1042_sms  \\\n",
       "502                 69                 1                 1                87   \n",
       "6547                33                 0                 1                16   \n",
       "6938                46                 0                 1                28   \n",
       "3115                75                 2                 1                19   \n",
       "3649                14                 0                 1                44   \n",
       "\n",
       "      feature_1043_sms  feature_1044_sms  feature_1045_sms  feature_1046_sms  \\\n",
       "502                  0               290                 5                52   \n",
       "6547                 0                34                11                29   \n",
       "6938                 9                83                11                20   \n",
       "3115                 0               154                 7                43   \n",
       "3649                 0               138                 5                59   \n",
       "\n",
       "      feature_1047_sms  feature_1048_sms  feature_1049_sms  feature_1050_sms  \\\n",
       "502                 65                 9               905                30   \n",
       "6547                 2                 2               303                30   \n",
       "6938                 8                 6               464                30   \n",
       "3115                 7                 6               441                30   \n",
       "3649                27                 9               677                30   \n",
       "\n",
       "      feature_1051_sms  feature_1052_sms  feature_1053_sms  feature_1054_sms  \\\n",
       "502                  5                 5               220                 1   \n",
       "6547                20                 3               111                 4   \n",
       "6938                 1                 0               157                 2   \n",
       "3115                 9                 9                53                 2   \n",
       "3649                41                16               178                 3   \n",
       "\n",
       "      feature_1055_sms  feature_1056_sms  feature_1057_sms  feature_1058_sms  \\\n",
       "502                  4                74                 1                 1   \n",
       "6547                 4                38                 0                 1   \n",
       "6938                22                58                 0                 1   \n",
       "3115                11                87                 2                 2   \n",
       "3649                 8                29                 0                 3   \n",
       "\n",
       "      feature_1059_sms  feature_1060_sms  feature_1061_sms  feature_1062_sms  \\\n",
       "502                 89                 0               330                 5   \n",
       "6547                17                 1                36                16   \n",
       "6938                36                11               114                17   \n",
       "3115                22                 0               167                 9   \n",
       "3649                66                 0               174                 7   \n",
       "\n",
       "      feature_1063_sms  feature_1064_sms  feature_1065_sms  feature_1066_sms  \\\n",
       "502                 60               101                 9              1227   \n",
       "6547                39                10                 3               568   \n",
       "6938                24                14                 7               972   \n",
       "3115                53                 9                 6               629   \n",
       "3649                93                40                19              1121   \n",
       "\n",
       "      feature_1067_sms  feature_1068_sms  feature_1069_sms  feature_1070_sms  \\\n",
       "502                 56                 6                 5               271   \n",
       "6547                60                36                 4               184   \n",
       "6938                60                 2                 0               374   \n",
       "3115                60                12                12                87   \n",
       "3649                60                75                25               266   \n",
       "\n",
       "      feature_1071_sms  feature_1072_sms  feature_1073_sms  feature_1074_sms  \\\n",
       "502                  4                 5                98                 1   \n",
       "6547                 7                 7                63                 0   \n",
       "6938                 2                22               112                 0   \n",
       "3115                 2                17               115                 2   \n",
       "3649                 3                13                52                 0   \n",
       "\n",
       "      feature_1075_sms  feature_1076_sms  feature_1077_sms  feature_1078_sms  \\\n",
       "502                  1               119                 2               416   \n",
       "6547                 1                34                 1                84   \n",
       "6938                 2                48                21               260   \n",
       "3115                 2                39                 1               207   \n",
       "3649                 7               124                 0               316   \n",
       "\n",
       "      feature_1079_sms  feature_1080_sms  feature_1081_sms  feature_1082_sms  \\\n",
       "502                 26                91               166                16   \n",
       "6547                32                83                23                 9   \n",
       "6938                36                48                33                12   \n",
       "3115                32                71                20                10   \n",
       "3649                16               130                67                27   \n",
       "\n",
       "      feature_1083_sms  feature_1084_sms  feature_1085_sms  feature_1086_sms  \\\n",
       "502               2999               173                28                 9   \n",
       "6547              3000               283               291                88   \n",
       "6938              2975               167                11                10   \n",
       "3115              1129               265                28                27   \n",
       "3649              3000               159               156                57   \n",
       "\n",
       "      feature_1087_sms  feature_1088_sms  feature_1089_sms  feature_1090_sms  \\\n",
       "502                723                 7                 6               265   \n",
       "6547               719                13                39               212   \n",
       "6938              1199                 2                25               395   \n",
       "3115               138                 3                21               129   \n",
       "3649               725                14                31               143   \n",
       "\n",
       "      feature_1091_sms  feature_1092_sms  feature_1093_sms  feature_1094_sms  \\\n",
       "502                  1                 2               171                12   \n",
       "6547                 0                 3               186                 6   \n",
       "6938                 0                 6               102                89   \n",
       "3115                 2                 3                59                 6   \n",
       "3649                 0                13               252                 1   \n",
       "\n",
       "      feature_1095_sms  feature_1096_sms  feature_1097_sms  feature_1098_sms  \\\n",
       "502               1088                49               201               390   \n",
       "6547               461               141               424               378   \n",
       "6938               669               162               185                84   \n",
       "3115               295                42               168               181   \n",
       "3649              1047                52               256               174   \n",
       "\n",
       "      feature_1099_sms  feature_1100_sms  feature_1101_sms  feature_1102_sms  \\\n",
       "502                 42         45.666667         45.666667          0.045682   \n",
       "6547                35         13.333333         13.333333          0.013333   \n",
       "6938                36         24.000000         24.000000          0.024202   \n",
       "3115                27         24.333333         24.333333          0.064659   \n",
       "3649                79         19.000000         19.000000          0.019000   \n",
       "\n",
       "      feature_1103_sms  feature_1104_sms  feature_1105_sms  feature_1106_sms  \\\n",
       "502           0.333333          0.007299          0.000000          0.000000   \n",
       "6547          0.666667          0.050000          0.333333          0.025000   \n",
       "6938          0.000000          0.000000          0.000000          0.000000   \n",
       "3115          0.333333          0.013699          0.666667          0.027397   \n",
       "3649          2.666667          0.140351          0.666667          0.035088   \n",
       "\n",
       "      feature_1107_sms  feature_1108_sms  feature_1109_sms  feature_1110_sms  \\\n",
       "502           7.000000          0.153285          0.000000          0.000000   \n",
       "6547          4.333333          0.325000          0.000000          0.000000   \n",
       "6938          6.000000          0.250000          0.333333          0.013889   \n",
       "3115          3.333333          0.136986          0.000000          0.000000   \n",
       "3649          6.000000          0.315789          0.000000          0.000000   \n",
       "\n",
       "      feature_1111_sms  feature_1112_sms  feature_1113_sms  feature_1114_sms  \\\n",
       "502           0.000000          0.000000          8.000000          0.175182   \n",
       "6547          1.000000          0.075000          2.333333          0.175000   \n",
       "6938          0.000000          0.000000          3.000000          0.125000   \n",
       "3115          0.333333          0.013699          4.000000          0.164384   \n",
       "3649          0.000000          0.000000          0.333333          0.017544   \n",
       "\n",
       "      feature_1115_sms  feature_1116_sms  feature_1117_sms  feature_1118_sms  \\\n",
       "502           0.333333          0.007299          0.333333          0.007299   \n",
       "6547          0.000000          0.000000          0.000000          0.000000   \n",
       "6938          0.000000          0.000000          0.333333          0.013889   \n",
       "3115          0.000000          0.000000          0.000000          0.000000   \n",
       "3649          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "      feature_1119_sms  feature_1120_sms  feature_1121_sms  feature_1122_sms  \\\n",
       "502           5.000000          0.109489          0.000000          0.000000   \n",
       "6547          2.000000          0.150000          0.000000          0.000000   \n",
       "6938          2.333333          0.097222          0.666667          0.027778   \n",
       "3115          0.666667          0.027397          0.000000          0.000000   \n",
       "3649          1.333333          0.070175          0.000000          0.000000   \n",
       "\n",
       "      feature_1123_sms  feature_1124_sms  feature_1125_sms  feature_1126_sms  \\\n",
       "502          14.000000          0.306569          1.000000          0.021898   \n",
       "6547          1.333333          0.100000          0.000000          0.000000   \n",
       "6938          8.000000          0.333333          0.666667          0.027778   \n",
       "3115         10.666667          0.438356          0.666667          0.027397   \n",
       "3649          4.333333          0.228070          0.000000          0.000000   \n",
       "\n",
       "      feature_1127_sms  feature_1128_sms  feature_1129_sms  feature_1130_sms  \\\n",
       "502           5.666667          0.124088          2.333333          0.051095   \n",
       "6547          1.333333          0.100000          0.000000          0.000000   \n",
       "6938          2.000000          0.083333          0.000000          0.000000   \n",
       "3115          3.333333          0.136986          0.333333          0.013699   \n",
       "3649          0.666667          0.035088          2.333333          0.122807   \n",
       "\n",
       "      feature_1131_sms  feature_1132_sms  feature_1133_sms  feature_1134_sms  \\\n",
       "502           1.666667          0.036496         42.142857         42.142857   \n",
       "6547          0.000000          0.000000         12.571429         12.571429   \n",
       "6938          0.666667          0.027778         19.285714         19.285714   \n",
       "3115          0.000000          0.000000         21.714286         21.714286   \n",
       "3649          0.666667          0.035088         23.142857         23.142857   \n",
       "\n",
       "      feature_1135_sms  feature_1136_sms  feature_1137_sms  feature_1138_sms  \\\n",
       "502           0.098366          0.142857          0.003390          0.142857   \n",
       "6547          0.029333          1.428571          0.113636          0.142857   \n",
       "6938          0.045378          0.000000          0.000000          0.000000   \n",
       "3115          0.134632          0.285714          0.013158          1.000000   \n",
       "3649          0.054000          2.000000          0.086420          0.428571   \n",
       "\n",
       "      feature_1139_sms  feature_1140_sms  feature_1141_sms  feature_1142_sms  \\\n",
       "502           0.003390          8.857143          0.210169          0.000000   \n",
       "6547          0.011364          4.571429          0.363636          0.000000   \n",
       "6938          0.000000          5.000000          0.259259          0.285714   \n",
       "3115          0.046053          2.000000          0.092105          0.285714   \n",
       "3649          0.018519          9.285714          0.401235          0.000000   \n",
       "\n",
       "      feature_1143_sms  feature_1144_sms  feature_1145_sms  feature_1146_sms  \\\n",
       "502           0.000000          0.142857          0.003390          4.142857   \n",
       "6547          0.000000          0.428571          0.034091          1.571429   \n",
       "6938          0.014815          0.571429          0.029630          2.571429   \n",
       "3115          0.013158          0.142857          0.006579          3.571429   \n",
       "3649          0.000000          0.000000          0.000000          0.571429   \n",
       "\n",
       "      feature_1147_sms  feature_1148_sms  feature_1149_sms  feature_1150_sms  \\\n",
       "502           0.098305          0.142857           0.00339          0.142857   \n",
       "6547          0.125000          0.000000           0.00000          0.000000   \n",
       "6938          0.133333          0.000000           0.00000          0.142857   \n",
       "3115          0.164474          0.000000           0.00000          0.142857   \n",
       "3649          0.024691          0.000000           0.00000          0.000000   \n",
       "\n",
       "      feature_1151_sms  feature_1152_sms  feature_1153_sms  feature_1154_sms  \\\n",
       "502           0.003390          4.428571          0.105085          0.000000   \n",
       "6547          0.000000          1.428571          0.113636          0.000000   \n",
       "6938          0.007407          1.714286          0.088889          0.428571   \n",
       "3115          0.006579          1.285714          0.059211          0.000000   \n",
       "3649          0.000000          1.285714          0.055556          0.000000   \n",
       "\n",
       "      feature_1155_sms  feature_1156_sms  feature_1157_sms  feature_1158_sms  \\\n",
       "502           0.000000         15.857143          0.376271          0.714286   \n",
       "6547          0.000000          1.714286          0.136364          0.428571   \n",
       "6938          0.022222          5.428571          0.281481          0.571429   \n",
       "3115          0.000000          8.142857          0.375000          0.285714   \n",
       "3649          0.000000          6.714286          0.290123          0.000000   \n",
       "\n",
       "      feature_1159_sms  feature_1160_sms  feature_1161_sms  feature_1162_sms  \\\n",
       "502           0.016949          3.857143          0.091525          2.857143   \n",
       "6547          0.034091          0.714286          0.056818          0.000000   \n",
       "6938          0.029630          1.571429          0.081481          0.571429   \n",
       "3115          0.013158          3.000000          0.138158          0.714286   \n",
       "3649          0.000000          1.571429          0.067901          1.000000   \n",
       "\n",
       "      feature_1163_sms  feature_1164_sms  feature_1165_sms  feature_1166_sms  \\\n",
       "502           0.067797          0.714286          0.016949         38.214286   \n",
       "6547          0.000000          0.142857          0.011364         13.071429   \n",
       "6938          0.029630          0.428571          0.022222         18.357143   \n",
       "3115          0.032895          0.857143          0.039474         19.571429   \n",
       "3649          0.043210          0.285714          0.012346         24.000000   \n",
       "\n",
       "      feature_1167_sms  feature_1168_sms  feature_1169_sms  feature_1170_sms  \\\n",
       "502          38.214286          0.178393          0.214286          0.005607   \n",
       "6547         13.071429          0.061000          1.214286          0.092896   \n",
       "6938         18.357143          0.086387          0.000000          0.000000   \n",
       "3115         19.571429          0.242693          0.357143          0.018248   \n",
       "3649         24.000000          0.112000          1.428571          0.059524   \n",
       "\n",
       "      feature_1171_sms  feature_1172_sms  feature_1173_sms  feature_1174_sms  \\\n",
       "502           0.071429          0.001869          9.714286          0.254206   \n",
       "6547          0.071429          0.005464          5.142857          0.393443   \n",
       "6938          0.000000          0.000000          4.928571          0.268482   \n",
       "3115          0.500000          0.025547          1.857143          0.094891   \n",
       "3649          0.214286          0.008929          8.285714          0.345238   \n",
       "\n",
       "      feature_1175_sms  feature_1176_sms  feature_1177_sms  feature_1178_sms  \\\n",
       "502           0.071429          0.001869          0.071429          0.001869   \n",
       "6547          0.142857          0.010929          0.285714          0.021858   \n",
       "6938          0.142857          0.007782          0.714286          0.038911   \n",
       "3115          0.142857          0.007299          0.642857          0.032847   \n",
       "3649          0.000000          0.000000          0.071429          0.002976   \n",
       "\n",
       "      feature_1179_sms  feature_1180_sms  feature_1181_sms  feature_1182_sms  \\\n",
       "502           3.071429          0.080374          0.071429          0.001869   \n",
       "6547          1.428571          0.109290          0.000000          0.000000   \n",
       "6938          2.571429          0.140078          0.000000          0.000000   \n",
       "3115          3.571429          0.182482          0.071429          0.003650   \n",
       "3649          0.642857          0.026786          0.000000          0.000000   \n",
       "\n",
       "      feature_1183_sms  feature_1184_sms  feature_1185_sms  feature_1186_sms  \\\n",
       "502           0.071429          0.001869          4.785714          0.125234   \n",
       "6547          0.000000          0.000000          1.142857          0.087432   \n",
       "6938          0.071429          0.003891          1.714286          0.093385   \n",
       "3115          0.071429          0.003650          1.071429          0.054745   \n",
       "3649          0.000000          0.000000          1.857143          0.077381   \n",
       "\n",
       "      feature_1187_sms  feature_1188_sms  feature_1189_sms  feature_1190_sms  \\\n",
       "502                0.0          0.000000         14.071429          0.368224   \n",
       "6547               0.0          0.000000          1.785714          0.136612   \n",
       "6938               0.5          0.027237          5.285714          0.287938   \n",
       "3115               0.0          0.000000          7.714286          0.394161   \n",
       "3649               0.0          0.000000          6.857143          0.285714   \n",
       "\n",
       "      feature_1191_sms  feature_1192_sms  feature_1193_sms  feature_1194_sms  \\\n",
       "502           0.357143          0.009346          2.642857          0.069159   \n",
       "6547          0.642857          0.049180          1.142857          0.087432   \n",
       "6938          0.500000          0.027237          1.142857          0.062257   \n",
       "3115          0.285714          0.014599          2.357143          0.120438   \n",
       "3649          0.071429          0.002976          3.000000          0.125000   \n",
       "\n",
       "      feature_1195_sms  feature_1196_sms  feature_1197_sms  feature_1198_sms  \\\n",
       "502           2.500000          0.065421          0.500000          0.013084   \n",
       "6547          0.000000          0.000000          0.071429          0.005464   \n",
       "6938          0.428571          0.023346          0.357143          0.019455   \n",
       "3115          0.500000          0.025547          0.428571          0.021898   \n",
       "3649          1.142857          0.047619          0.428571          0.017857   \n",
       "\n",
       "      feature_1199_sms  feature_1200_sms  feature_1201_sms  feature_1202_sms  \\\n",
       "502          37.285714         37.285714          0.261087          0.142857   \n",
       "6547         11.952381         11.952381          0.083667          0.809524   \n",
       "6938         15.571429         15.571429          0.109916          0.000000   \n",
       "3115         18.142857         18.142857          0.337467          0.285714   \n",
       "3649         22.952381         22.952381          0.160667          1.380952   \n",
       "\n",
       "      feature_1203_sms  feature_1204_sms  feature_1205_sms  feature_1206_sms  \\\n",
       "502           0.003831          0.190476          0.005109          9.142857   \n",
       "6547          0.067729          0.047619          0.003984          4.666667   \n",
       "6938          0.000000          0.000000          0.000000          4.571429   \n",
       "3115          0.015748          0.380952          0.020997          2.000000   \n",
       "3649          0.060166          0.476190          0.020747          6.714286   \n",
       "\n",
       "      feature_1207_sms  feature_1208_sms  feature_1209_sms  feature_1210_sms  \\\n",
       "502           0.245211          0.047619          0.001277          0.190476   \n",
       "6547          0.390438          0.142857          0.011952          0.190476   \n",
       "6938          0.293578          0.095238          0.006116          0.809524   \n",
       "3115          0.110236          0.095238          0.005249          0.428571   \n",
       "3649          0.292531          0.000000          0.000000          0.238095   \n",
       "\n",
       "      feature_1211_sms  feature_1212_sms  feature_1213_sms  feature_1214_sms  \\\n",
       "502           0.005109          3.285714          0.088123          0.047619   \n",
       "6547          0.015936          1.571429          0.131474          0.000000   \n",
       "6938          0.051988          2.190476          0.140673          0.000000   \n",
       "3115          0.023622          3.571429          0.196850          0.095238   \n",
       "3649          0.010373          0.666667          0.029046          0.000000   \n",
       "\n",
       "      feature_1215_sms  feature_1216_sms  feature_1217_sms  feature_1218_sms  \\\n",
       "502           0.001277          0.047619          0.001277          4.142857   \n",
       "6547          0.000000          0.047619          0.003984          0.761905   \n",
       "6938          0.000000          0.047619          0.003058          1.333333   \n",
       "3115          0.005249          0.047619          0.002625          0.904762   \n",
       "3649          0.000000          0.047619          0.002075          2.095238   \n",
       "\n",
       "      feature_1219_sms  feature_1220_sms  feature_1221_sms  feature_1222_sms  \\\n",
       "502           0.111111          0.000000          0.000000         13.809524   \n",
       "6547          0.063745          0.000000          0.000000          1.619048   \n",
       "6938          0.085627          0.428571          0.027523          3.952381   \n",
       "3115          0.049869          0.000000          0.000000          7.333333   \n",
       "3649          0.091286          0.000000          0.000000          6.571429   \n",
       "\n",
       "      feature_1223_sms  feature_1224_sms  feature_1225_sms  feature_1226_sms  \\\n",
       "502           0.370370          0.238095          0.006386          2.476190   \n",
       "6547          0.135458          0.523810          0.043825          1.380952   \n",
       "6938          0.253823          0.523810          0.033639          0.952381   \n",
       "3115          0.404199          0.333333          0.018373          2.047619   \n",
       "3649          0.286307          0.238095          0.010373          2.809524   \n",
       "\n",
       "      feature_1227_sms  feature_1228_sms  feature_1229_sms  feature_1230_sms  \\\n",
       "502           0.066411          3.095238          0.083014          0.428571   \n",
       "6547          0.115538          0.095238          0.007968          0.095238   \n",
       "6938          0.061162          0.380952          0.024465          0.285714   \n",
       "3115          0.112861          0.333333          0.018373          0.285714   \n",
       "3649          0.122407          1.285714          0.056017          0.428571   \n",
       "\n",
       "      feature_1231_sms  feature_1232_sms  feature_1233_sms  feature_1234_sms  \\\n",
       "502           0.011494         30.166667         30.166667          0.301767   \n",
       "6547          0.007968         10.100000         10.100000          0.101000   \n",
       "6938          0.018349         15.466667         15.466667          0.155966   \n",
       "3115          0.015748         14.700000         14.700000          0.390611   \n",
       "3649          0.018672         22.566667         22.566667          0.225667   \n",
       "\n",
       "      feature_1235_sms  feature_1236_sms  feature_1237_sms  feature_1238_sms  \\\n",
       "502           0.166667          0.005525          0.166667          0.005525   \n",
       "6547          0.666667          0.066007          0.100000          0.009901   \n",
       "6938          0.033333          0.002155          0.000000          0.000000   \n",
       "3115          0.300000          0.020408          0.300000          0.020408   \n",
       "3649          1.366667          0.060561          0.533333          0.023634   \n",
       "\n",
       "      feature_1239_sms  feature_1240_sms  feature_1241_sms  feature_1242_sms  \\\n",
       "502           7.333333          0.243094          0.033333          0.001105   \n",
       "6547          3.700000          0.366337          0.133333          0.013201   \n",
       "6938          5.233333          0.338362          0.066667          0.004310   \n",
       "3115          1.766667          0.120181          0.066667          0.004535   \n",
       "3649          5.933333          0.262925          0.100000          0.004431   \n",
       "\n",
       "      feature_1243_sms  feature_1244_sms  feature_1245_sms  feature_1246_sms  \\\n",
       "502           0.133333          0.004420          2.466667          0.081768   \n",
       "6547          0.133333          0.013201          1.266667          0.125413   \n",
       "6938          0.733333          0.047414          1.933333          0.125000   \n",
       "3115          0.366667          0.024943          2.900000          0.197279   \n",
       "3649          0.266667          0.011817          0.966667          0.042836   \n",
       "\n",
       "      feature_1247_sms  feature_1248_sms  feature_1249_sms  feature_1250_sms  \\\n",
       "502           0.033333          0.001105          0.033333          0.001105   \n",
       "6547          0.000000          0.000000          0.033333          0.003300   \n",
       "6938          0.000000          0.000000          0.033333          0.002155   \n",
       "3115          0.066667          0.004535          0.066667          0.004535   \n",
       "3649          0.000000          0.000000          0.100000          0.004431   \n",
       "\n",
       "      feature_1251_sms  feature_1252_sms  feature_1253_sms  feature_1254_sms  \\\n",
       "502           2.966667          0.098343          0.000000          0.000000   \n",
       "6547          0.566667          0.056106          0.033333          0.003300   \n",
       "6938          1.200000          0.077586          0.366667          0.023707   \n",
       "3115          0.733333          0.049887          0.000000          0.000000   \n",
       "3649          2.200000          0.097489          0.000000          0.000000   \n",
       "\n",
       "      feature_1255_sms  feature_1256_sms  feature_1257_sms  feature_1258_sms  \\\n",
       "502          11.000000          0.364641          0.166667          0.005525   \n",
       "6547          1.200000          0.118812          0.533333          0.052805   \n",
       "6938          3.800000          0.245690          0.566667          0.036638   \n",
       "3115          5.566667          0.378685          0.300000          0.020408   \n",
       "3649          5.800000          0.257016          0.233333          0.010340   \n",
       "\n",
       "      feature_1259_sms  feature_1260_sms  feature_1261_sms  feature_1262_sms  \\\n",
       "502           2.000000          0.066298          3.366667          0.111602   \n",
       "6547          1.300000          0.128713          0.333333          0.033003   \n",
       "6938          0.800000          0.051724          0.466667          0.030172   \n",
       "3115          1.766667          0.120181          0.300000          0.020408   \n",
       "3649          3.100000          0.137371          1.333333          0.059084   \n",
       "\n",
       "      feature_1263_sms  feature_1264_sms  feature_1265_sms  feature_1266_sms  \\\n",
       "502           0.300000          0.009945         20.450000         21.910714   \n",
       "6547          0.100000          0.009901          9.466667          9.466667   \n",
       "6938          0.233333          0.015086         16.200000         16.200000   \n",
       "3115          0.200000          0.013605         10.483333         10.483333   \n",
       "3649          0.633333          0.028065         18.683333         18.683333   \n",
       "\n",
       "      feature_1267_sms  feature_1268_sms  feature_1269_sms  feature_1270_sms  \\\n",
       "502           0.409136          0.100000          0.004890          0.083333   \n",
       "6547          0.189333          0.600000          0.063380          0.066667   \n",
       "6938          0.326723          0.033333          0.002058          0.000000   \n",
       "3115          0.557130          0.200000          0.019078          0.200000   \n",
       "3649          0.373667          1.250000          0.066905          0.416667   \n",
       "\n",
       "      feature_1271_sms  feature_1272_sms  feature_1273_sms  feature_1274_sms  \\\n",
       "502           0.004075          4.516667          0.220864          0.066667   \n",
       "6547          0.007042          3.066667          0.323944          0.116667   \n",
       "6938          0.000000          6.233333          0.384774          0.033333   \n",
       "3115          0.019078          1.450000          0.138315          0.033333   \n",
       "3649          0.022302          4.433333          0.237288          0.050000   \n",
       "\n",
       "      feature_1275_sms  feature_1276_sms  feature_1277_sms  feature_1278_sms  \\\n",
       "502           0.003260          0.083333          0.004075          1.633333   \n",
       "6547          0.012324          0.116667          0.012324          1.050000   \n",
       "6938          0.002058          0.366667          0.022634          1.866667   \n",
       "3115          0.003180          0.283333          0.027027          1.916667   \n",
       "3649          0.002676          0.216667          0.011597          0.866667   \n",
       "\n",
       "      feature_1279_sms  feature_1280_sms  feature_1281_sms  feature_1282_sms  \\\n",
       "502           0.079870          0.016667          0.000815          0.016667   \n",
       "6547          0.110915          0.000000          0.000000          0.016667   \n",
       "6938          0.115226          0.000000          0.000000          0.033333   \n",
       "3115          0.182830          0.033333          0.003180          0.033333   \n",
       "3649          0.046387          0.000000          0.000000          0.116667   \n",
       "\n",
       "      feature_1283_sms  feature_1284_sms  feature_1285_sms  feature_1286_sms  \\\n",
       "502           0.000815          1.983333          0.096985          0.033333   \n",
       "6547          0.001761          0.566667          0.059859          0.016667   \n",
       "6938          0.002058          0.800000          0.049383          0.350000   \n",
       "3115          0.003180          0.650000          0.062003          0.016667   \n",
       "3649          0.006244          2.066667          0.110616          0.000000   \n",
       "\n",
       "      feature_1287_sms  feature_1288_sms  feature_1289_sms  feature_1290_sms  \\\n",
       "502           0.001630          6.933333          0.339038          0.433333   \n",
       "6547          0.001761          1.400000          0.147887          0.533333   \n",
       "6938          0.021605          4.333333          0.267490          0.600000   \n",
       "3115          0.001590          3.450000          0.329094          0.533333   \n",
       "3649          0.000000          5.266667          0.281891          0.266667   \n",
       "\n",
       "      feature_1291_sms  feature_1292_sms  feature_1293_sms  feature_1294_sms  \\\n",
       "502           0.021190          1.516667          0.074165          2.766667   \n",
       "6547          0.056338          1.383333          0.146127          0.383333   \n",
       "6938          0.037037          0.800000          0.049383          0.550000   \n",
       "3115          0.050874          1.183333          0.112878          0.333333   \n",
       "3649          0.014273          2.166667          0.115968          1.116667   \n",
       "\n",
       "      feature_1295_sms  feature_1296_sms  feature_1297_sms  feature_1298_sms  \\\n",
       "502           0.135289          0.266667          0.013040             2.999   \n",
       "6547          0.040493          0.150000          0.015845             3.000   \n",
       "6938          0.033951          0.200000          0.012346             2.975   \n",
       "3115          0.031797          0.166667          0.015898             1.129   \n",
       "3649          0.059768          0.450000          0.024086             3.000   \n",
       "\n",
       "      feature_1299_sms  feature_1300_sms  feature_1301_sms  feature_1302_sms  \\\n",
       "502          17.335260               1.0             0.028          0.009336   \n",
       "6547         10.600707               1.0             0.291          0.097000   \n",
       "6938         17.814371               1.0             0.011          0.003697   \n",
       "3115          4.260377               1.0             0.028          0.024801   \n",
       "3649         18.867925               1.0             0.156          0.052000   \n",
       "\n",
       "      feature_1303_sms  feature_1304_sms  feature_1305_sms  feature_1306_sms  \\\n",
       "502              0.009          0.003001             0.723          0.241080   \n",
       "6547             0.088          0.029333             0.719          0.239667   \n",
       "6938             0.010          0.003361             1.199          0.403025   \n",
       "3115             0.027          0.023915             0.138          0.122232   \n",
       "3649             0.057          0.019000             0.725          0.241667   \n",
       "\n",
       "      feature_1307_sms  feature_1308_sms  feature_1309_sms  feature_1310_sms  \\\n",
       "502              0.007          0.002334             0.006          0.002001   \n",
       "6547             0.013          0.004333             0.039          0.013000   \n",
       "6938             0.002          0.000672             0.025          0.008403   \n",
       "3115             0.003          0.002657             0.021          0.018601   \n",
       "3649             0.014          0.004667             0.031          0.010333   \n",
       "\n",
       "      feature_1311_sms  feature_1312_sms  feature_1313_sms  feature_1314_sms  \\\n",
       "502              0.265          0.088363             0.001          0.000333   \n",
       "6547             0.212          0.070667             0.000          0.000000   \n",
       "6938             0.395          0.132773             0.000          0.000000   \n",
       "3115             0.129          0.114260             0.002          0.001771   \n",
       "3649             0.143          0.047667             0.000          0.000000   \n",
       "\n",
       "      feature_1315_sms  feature_1316_sms  feature_1317_sms  feature_1318_sms  \\\n",
       "502              0.002          0.000667             0.171          0.057019   \n",
       "6547             0.003          0.001000             0.186          0.062000   \n",
       "6938             0.006          0.002017             0.102          0.034286   \n",
       "3115             0.003          0.002657             0.059          0.052259   \n",
       "3649             0.013          0.004333             0.252          0.084000   \n",
       "\n",
       "      feature_1319_sms  feature_1320_sms  feature_1321_sms  feature_1322_sms  \\\n",
       "502              0.012          0.004001             1.088          0.362788   \n",
       "6547             0.006          0.002000             0.461          0.153667   \n",
       "6938             0.089          0.029916             0.669          0.224874   \n",
       "3115             0.006          0.005314             0.295          0.261293   \n",
       "3649             0.001          0.000333             1.047          0.349000   \n",
       "\n",
       "      feature_1323_sms  feature_1324_sms  feature_1325_sms  feature_1326_sms  \\\n",
       "502              0.049          0.016339             0.201          0.067022   \n",
       "6547             0.141          0.047000             0.424          0.141333   \n",
       "6938             0.162          0.054454             0.185          0.062185   \n",
       "3115             0.042          0.037201             0.168          0.148804   \n",
       "3649             0.052          0.017333             0.256          0.085333   \n",
       "\n",
       "      feature_1327_sms  feature_1328_sms  feature_1329_sms  feature_1330_sms  \n",
       "502              0.390          0.130043             0.042          0.014005  \n",
       "6547             0.378          0.126000             0.035          0.011667  \n",
       "6938             0.084          0.028235             0.036          0.012101  \n",
       "3115             0.181          0.160319             0.027          0.023915  \n",
       "3649             0.174          0.058000             0.079          0.026333  \n",
       "\n",
       "[5 rows x 1761 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6136, 1761)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y,oot_x, oot_y,df,final_feas = read_train('./data/filter_feas_df_0403_n_old.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e2712a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayes超参数优化 \n",
    "\n",
    "\n",
    "# from scipy.misc import derivative\n",
    "\n",
    "# def custom_asymmetric_train(y_true, y_pred):\n",
    "#     residual = (y_true - y_pred).astype(\"float\")\n",
    "#     grad = np.where(residual<0, -2*10.0*residual, -2*residual)\n",
    "#     hess = np.where(residual<0, 2*10.0, 2.0)\n",
    "#     return grad, hess\n",
    "\n",
    "# def f1_loss(y, pred):\n",
    "#     beta = 2\n",
    "#     p = 1. / (1 + np.exp(-pred))\n",
    "#     grad = p * ((beta - 1) * y + 1) - beta * y\n",
    "#     hess = ((beta - 1) * y + 1) * p * (1.0 - p)\n",
    " \n",
    "#     return grad, hess\n",
    "\n",
    "# def focal_loss_lgb(y_true, y_pred):\n",
    "#     a,g = 0.25, 1.0\n",
    "#     def fl(x,t):\n",
    "#         p = 1/(1+np.exp(-x))\n",
    "#         return -( a*t + (1-a)*(1-t) ) * (( 1 - ( t*p + (1-t)*(1-p)) )**g) * ( t*np.log(p)+(1-t)*np.log(1-p) )\n",
    "    \n",
    "#     partial_fl = lambda x: fl(x, y_true)\n",
    "#     grad = derivative(partial_fl, y_pred, n=1, dx=1e-6)\n",
    "#     hess = derivative(partial_fl, y_pred, n=2, dx=1e-6)\n",
    "#     return grad, hess\n",
    "# #https://towardsdatascience.com/custom-loss-functions-for-gradient-boosting_type-f79c1b40466d\n",
    "# # https://blog.csdn.net/u013714645/article/details/105285038\n",
    "# # https://towardsdatascience.com/lightgbm-with-the-focal-loss-for-imbalanced-datasets-9836a9ae00ca\n",
    "\n",
    "# def lgb_f2_score(y_true, y_pred):\n",
    "#     _,f2 = find_best_threshold(y_true, y_pred,bins_num=20)  #阈值精度20\n",
    "#     return 'f2', f2, True\n",
    "\n",
    "# clf = LGBMClassifier(num_leaves=lvs,#300 #610\n",
    "#                      boosting_type= 'goss',\n",
    "#                      max_depth=-1,\n",
    "#                      n_estimators=1000,  #200\n",
    "#                      learning_rate=0.01, # 0.01\n",
    "#                      verbose=-1,\n",
    "#                      reg_alpha=1,\n",
    "#                      reg_lambda=1, \n",
    "#                      class_weight=None,\n",
    "#                      subsample=0.7,\n",
    "#                      colsample_bytree=0.7,\n",
    "#                      n_jobs=-1,\n",
    "#                      random_state=2) \n",
    "\n",
    "# clf.set_params(**{\"objective\": focal_loss_lgb})   #focal loss\n",
    "\n",
    "# clf.fit(X_train, y_train,\n",
    "#         eval_set=[(X_valid2, y_valid2)],\n",
    "#         eval_metric=lgb_f2_score,              # f2 eval\n",
    "#         early_stopping_rounds=100,verbose=-1)\n",
    "\n",
    "\n",
    "# oof_prob = clf.predict_proba(X_valid2)#[:, 1]  # fea  # f-c losss no[:, 1] \n",
    "\n",
    "\n",
    "\n",
    "def model_metrics(model, x, y,tp='auc'):\n",
    "    \"\"\" 评估 \"\"\"\n",
    "    # 动态阈值评估 \n",
    "    yprob = model.predict_proba(x)[:,1]\n",
    "    fpr,tpr,_ = roc_curve(y, yprob,pos_label=1)\n",
    "    score = auc(fpr, tpr) \n",
    "    if tp=='ks':\n",
    "        return auc(fpr, tpr),max(tpr-fpr)\n",
    "    return score\n",
    "\n",
    "\n",
    "def bayes_fmin(train_x, test_x, train_y, test_y, eval_iters):\n",
    "    \"\"\"\n",
    "    bayes 优化超参数\n",
    "    \"\"\"\n",
    "    \n",
    "    def lgb_factory(params):\n",
    "        \"\"\"\n",
    "        定义调参目标函数\n",
    "        \"\"\"\n",
    "        fit_params = {\n",
    "            \"boosting_type\":params[\"boosting_type\"],\n",
    "            'max_depth':int(params['max_depth']),\n",
    "            'n_estimators':int(params['n_estimators']),\n",
    "            \"learning_rate\":params[\"learning_rate\"],\n",
    "            \"num_leaves\": int(params[\"num_leaves\"]),\n",
    "            #\"class_weight\":{0:1,  1:float(params['class_weight'])}, \n",
    "            \"class_weight\": params['class_weight'],\n",
    "            \"reg_alpha\":params[\"reg_alpha\"],\n",
    "            \"reg_lambda\":params[\"reg_lambda\"],\n",
    "            'subsample_for_bin':int(params['subsample_for_bin']),            \n",
    "            'subsample':params['subsample'],\n",
    "            \"feature_fraction\":params[\"feature_fraction\"],\n",
    "            \"min_child_samples\":int(params[\"min_child_samples\"]),            \n",
    "            'min_child_weight': params['min_child_weight'],\n",
    "            \"min_split_gain\":params[\"min_split_gain\"]\n",
    "            }\n",
    "        fit_params.update(base_params)\n",
    "        # 模型训练\n",
    "        model=lgb.LGBMClassifier(**fit_params)\n",
    "        model.fit(train_x, train_y,\n",
    "                  eval_set=[(test_x, test_y)],\n",
    "                  eval_metric='auc',   # 'f1'\n",
    "                  early_stopping_rounds=50, #  30round\n",
    "                  verbose=-1)\n",
    "        print('***\\n',fit_params)\n",
    "        # 测试集最小化为目标\n",
    "        metric = model_metrics(model, test_x, test_y)\n",
    "        print(metric)\n",
    "        return {\"loss\": -metric, \"status\":STATUS_OK}\n",
    "\n",
    "    ########start 参数空间1\n",
    "    base_params = {\n",
    "            \"n_jobs\":-1, \n",
    "            \"objective\":'binary',\n",
    "            \"verbose\":-1,\n",
    "            \"random_state\":0        \n",
    "            }\n",
    "    space = {\n",
    "        'max_depth': hp.quniform('max_depth', 2, 22, 1),\n",
    "        'n_estimators': hp.quniform('n_estimators', 10, 2424, 10),\n",
    "        'boosting_type': hp.choice('boosting_type', ['gbdt','dart','goss']),\n",
    "        #'class_weight':hp.uniform('class_weight', 0.005, 300) ,   # None\n",
    "        'class_weight':hp.choice('class_weight', [None,'balanced']),\n",
    "        'num_leaves': hp.quniform('num_leaves', 4, 2424, 8),\n",
    "        'learning_rate': hp.uniform('learning_rate', 1e-4, 1),\n",
    "        'subsample_for_bin': hp.quniform('subsample_for_bin', 10000, 350000, 20000),\n",
    "        'feature_fraction': hp.uniform('feature_fraction', 0.1, 1),\n",
    "        'subsample': hp.uniform('subsample', 0.1, 1), \n",
    "        'min_child_samples': hp.qloguniform('min_child_samples', 0, 10, 1),  \n",
    "        'reg_alpha': hp.uniform('reg_alpha', 0, 10),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 0, 10),\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', -16, 5), \n",
    "        'min_split_gain': hp.uniform('min_split_gain', 0, 10)\n",
    "            }\n",
    "    # 2、优化\n",
    "    best_params = fmin(lgb_factory, space, algo=partial(anneal.suggest,), max_evals=eval_iters, trials=Trials(),return_argmin=True,verbose=-1)\n",
    "    \n",
    "    # 3、优化后取最优参数,规范格式\n",
    "    best_params.update(base_params)\n",
    "    best_params[\"boosting_type\"] = ['gbdt','dart','goss'][int(best_params[\"boosting_type\"])]\n",
    "    best_params['class_weight'] =  [None,'balanced'][int(best_params['class_weight'])]\n",
    "    best_params[\"n_estimators\"] = int(best_params[\"n_estimators\"])\n",
    "    #best_params['class_weight'] = {0:1,  1:float(params['class_weight'])}\n",
    "    best_params[\"min_child_samples\"] = int(best_params[\"min_child_samples\"])\n",
    "    best_params[\"subsample_for_bin\"] = int(best_params[\"subsample_for_bin\"])\n",
    "    best_params[\"num_leaves\"] = int(best_params[\"num_leaves\"])\n",
    "    best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07527650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.19479896257873636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.19479896257873636\n",
      "  0%|          | 0/200 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                    \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 3, 'n_estimators': 1980, 'learning_rate': 0.9852864338838605, 'num_leaves': 1232, 'class_weight': 'balanced', 'reg_alpha': 2.091696002987061, 'reg_lambda': 9.938406128379317, 'subsample_for_bin': 180000, 'subsample': 0.2945655009126482, 'feature_fraction': 0.19479896257873636, 'min_child_samples': 529, 'min_child_weight': 8.391731214846337e-06, 'min_split_gain': 9.854832903115904, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.5842249611370197                                     \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7687536864071366, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7687536864071366\n",
      "  0%|          | 1/200 [00:00<02:08,  1.54trial/s, best loss: -0.5842249611370197]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 970, 'learning_rate': 0.33310161473802635, 'num_leaves': 1448, 'class_weight': 'balanced', 'reg_alpha': 5.5608563655107295, 'reg_lambda': 8.978240404433915, 'subsample_for_bin': 240000, 'subsample': 0.8228691282890405, 'feature_fraction': 0.7687536864071366, 'min_child_samples': 19, 'min_child_weight': 15.766079550370673, 'min_split_gain': 7.848181867192955, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.726866533422163                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.11630692195648884, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.11630692195648884\n",
      "  1%|          | 2/200 [00:04<08:55,  2.71s/trial, best loss: -0.726866533422163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 12, 'n_estimators': 610, 'learning_rate': 0.5033372430295594, 'num_leaves': 1520, 'class_weight': 'balanced', 'reg_alpha': 2.7618382264874564, 'reg_lambda': 2.857281409959361, 'subsample_for_bin': 220000, 'subsample': 0.15907526142453599, 'feature_fraction': 0.11630692195648884, 'min_child_samples': 20, 'min_child_weight': 0.00022771709123439133, 'min_split_gain': 6.4166098616085145, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.6456795469686876                                                               \n",
      "[LightGBM] [Warning] feature_fraction is set=0.37370711890368447, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.37370711890368447\n",
      "  2%|▏         | 3/200 [00:06<07:01,  2.14s/trial, best loss: -0.726866533422163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 1220, 'learning_rate': 0.3504823346695504, 'num_leaves': 656, 'class_weight': 'balanced', 'reg_alpha': 2.9062838699333833, 'reg_lambda': 4.225356036036146, 'subsample_for_bin': 260000, 'subsample': 0.6180087339548825, 'feature_fraction': 0.37370711890368447, 'min_child_samples': 2, 'min_child_weight': 0.25872602677819173, 'min_split_gain': 4.899381504624858, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7213124583610926                                                               \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6845587099836179, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6845587099836179\n",
      "  2%|▏         | 4/200 [00:11<11:02,  3.38s/trial, best loss: -0.726866533422163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 3, 'n_estimators': 1270, 'learning_rate': 0.6286403915027452, 'num_leaves': 968, 'class_weight': None, 'reg_alpha': 4.339606616629066, 'reg_lambda': 2.8927862587873916, 'subsample_for_bin': 240000, 'subsample': 0.46043816260040965, 'feature_fraction': 0.6845587099836179, 'min_child_samples': 249, 'min_child_weight': 1.1175465735294623e-06, 'min_split_gain': 9.067997766154344, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.6672018654230513                                                               \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7296224770039649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7296224770039649\n",
      "  2%|▎         | 5/200 [00:12<07:43,  2.38s/trial, best loss: -0.726866533422163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 860, 'learning_rate': 0.5809220216933484, 'num_leaves': 728, 'class_weight': 'balanced', 'reg_alpha': 8.774070585260539, 'reg_lambda': 8.021061288314236, 'subsample_for_bin': 160000, 'subsample': 0.7365083441864938, 'feature_fraction': 0.7296224770039649, 'min_child_samples': 750, 'min_child_weight': 0.00217822928611883, 'min_split_gain': 4.156041104315096, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.6659427048634243                                                               \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8333533526583996, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8333533526583996\n",
      "  3%|▎         | 6/200 [00:15<08:21,  2.58s/trial, best loss: -0.726866533422163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 14, 'n_estimators': 820, 'learning_rate': 0.6365290988895231, 'num_leaves': 1624, 'class_weight': 'balanced', 'reg_alpha': 6.68680537308898, 'reg_lambda': 9.750494100606875, 'subsample_for_bin': 300000, 'subsample': 0.8283858423493874, 'feature_fraction': 0.8333533526583996, 'min_child_samples': 2, 'min_child_weight': 0.01731944948115363, 'min_split_gain': 8.911382525991424, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7246724405951588                                                               \n",
      "[LightGBM] [Warning] feature_fraction is set=0.9322759973826181, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9322759973826181\n",
      "  4%|▎         | 7/200 [00:18<09:18,  2.89s/trial, best loss: -0.726866533422163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 850, 'learning_rate': 0.08262355304428162, 'num_leaves': 2152, 'class_weight': 'balanced', 'reg_alpha': 7.594002302054639, 'reg_lambda': 9.88552697872026, 'subsample_for_bin': 280000, 'subsample': 0.9510255019021908, 'feature_fraction': 0.9322759973826181, 'min_child_samples': 46, 'min_child_weight': 2.5059427075484955, 'min_split_gain': 6.7371137031920805, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7260515212080836                                                               \n",
      "[LightGBM] [Warning] feature_fraction is set=0.5647122063581109, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5647122063581109\n",
      "  4%|▍         | 8/200 [00:23<11:11,  3.50s/trial, best loss: -0.726866533422163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 17, 'n_estimators': 1580, 'learning_rate': 0.06999806403376876, 'num_leaves': 808, 'class_weight': 'balanced', 'reg_alpha': 5.004730898145903, 'reg_lambda': 7.666669890305705, 'subsample_for_bin': 320000, 'subsample': 0.7927900503857157, 'feature_fraction': 0.5647122063581109, 'min_child_samples': 3, 'min_child_weight': 0.014945677763915822, 'min_split_gain': 8.051086740525589, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7256184765711748                                                               \n",
      "[LightGBM] [Warning] feature_fraction is set=0.36878899137108884, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.36878899137108884\n",
      "  4%|▍         | 9/200 [00:31<15:30,  4.87s/trial, best loss: -0.726866533422163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 14, 'n_estimators': 1320, 'learning_rate': 0.4081847768952718, 'num_leaves': 120, 'class_weight': 'balanced', 'reg_alpha': 5.170138275626156, 'reg_lambda': 2.050319422111263, 'subsample_for_bin': 340000, 'subsample': 0.5286888726530024, 'feature_fraction': 0.36878899137108884, 'min_child_samples': 90, 'min_child_weight': 0.08034370090012231, 'min_split_gain': 2.7735577026752214, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.722356206973129                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.5532568538571038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5532568538571038\n",
      "  5%|▌         | 10/200 [00:37<16:21,  5.16s/trial, best loss: -0.726866533422163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 17, 'n_estimators': 1270, 'learning_rate': 0.3564745463148824, 'num_leaves': 2288, 'class_weight': 'balanced', 'reg_alpha': 5.8818221515722815, 'reg_lambda': 7.097581014458328, 'subsample_for_bin': 320000, 'subsample': 0.969067424860158, 'feature_fraction': 0.5532568538571038, 'min_child_samples': 10, 'min_child_weight': 1.1180893003689625, 'min_split_gain': 9.109293059923846, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7231601154785698                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.9067496769267206, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9067496769267206\n",
      "  6%|▌         | 11/200 [00:43<17:42,  5.62s/trial, best loss: -0.726866533422163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 17, 'n_estimators': 1100, 'learning_rate': 0.45402770910216705, 'num_leaves': 1848, 'class_weight': 'balanced', 'reg_alpha': 8.754040024648154, 'reg_lambda': 9.53304311978967, 'subsample_for_bin': 200000, 'subsample': 0.5890441699519846, 'feature_fraction': 0.9067496769267206, 'min_child_samples': 19, 'min_child_weight': 0.220732301512288, 'min_split_gain': 7.0395901393384035, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7241927603819676                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8306066740748748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8306066740748748\n",
      "  6%|▌         | 12/200 [00:48<16:54,  5.40s/trial, best loss: -0.726866533422163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 21, 'n_estimators': 440, 'learning_rate': 0.4525452455541431, 'num_leaves': 1408, 'class_weight': 'balanced', 'reg_alpha': 6.880676910531465, 'reg_lambda': 7.0647512005505835, 'subsample_for_bin': 160000, 'subsample': 0.8044687960911437, 'feature_fraction': 0.8306066740748748, 'min_child_samples': 152, 'min_child_weight': 37.7133771342842, 'min_split_gain': 7.583095765062531, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7091550077725961                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.9044607817635453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9044607817635453\n",
      "  6%|▋         | 13/200 [00:50<12:58,  4.16s/trial, best loss: -0.726866533422163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 14, 'n_estimators': 680, 'learning_rate': 0.07242116974978882, 'num_leaves': 1976, 'class_weight': 'balanced', 'reg_alpha': 8.894825784142945, 'reg_lambda': 8.476624074762857, 'subsample_for_bin': 300000, 'subsample': 0.8464205682538043, 'feature_fraction': 0.9044607817635453, 'min_child_samples': 23, 'min_child_weight': 0.6014193384034521, 'min_split_gain': 6.095636882063807, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7230313124583612                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8243032316168933, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8243032316168933\n",
      "  7%|▋         | 14/200 [00:54<12:58,  4.18s/trial, best loss: -0.726866533422163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 580, 'learning_rate': 0.2855920231606569, 'num_leaves': 1240, 'class_weight': 'balanced', 'reg_alpha': 6.233104210420613, 'reg_lambda': 7.604236307663832, 'subsample_for_bin': 240000, 'subsample': 0.9805844565269456, 'feature_fraction': 0.8243032316168933, 'min_child_samples': 5, 'min_child_weight': 4.717118190303421, 'min_split_gain': 6.228816662745963, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7278236731068177                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6175474602819021, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6175474602819021\n",
      "  8%|▊         | 15/200 [00:57<11:57,  3.88s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 15, 'n_estimators': 600, 'learning_rate': 0.2350099357395245, 'num_leaves': 1336, 'class_weight': 'balanced', 'reg_alpha': 6.916884266616757, 'reg_lambda': 7.615227416065304, 'subsample_for_bin': 260000, 'subsample': 0.7430406056333367, 'feature_fraction': 0.6175474602819021, 'min_child_samples': 89, 'min_child_weight': 0.0891427502313874, 'min_split_gain': 6.935403611087886, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7244015101043749                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.975501823410721, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.975501823410721\n",
      "  8%|▊         | 16/200 [00:58<09:31,  3.11s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 15, 'n_estimators': 220, 'learning_rate': 0.4199790665835437, 'num_leaves': 912, 'class_weight': 'balanced', 'reg_alpha': 6.724775028551894, 'reg_lambda': 8.823089509036675, 'subsample_for_bin': 240000, 'subsample': 0.6925955266671727, 'feature_fraction': 0.975501823410721, 'min_child_samples': 7, 'min_child_weight': 5.96821147963354, 'min_split_gain': 4.882210875063688, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7273639795691762                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7605379199753781, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7605379199753781\n",
      "  8%|▊         | 17/200 [01:00<08:17,  2.72s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 21, 'n_estimators': 620, 'learning_rate': 0.36804757026514373, 'num_leaves': 960, 'class_weight': 'balanced', 'reg_alpha': 6.398467679155395, 'reg_lambda': 9.013277785599431, 'subsample_for_bin': 280000, 'subsample': 0.8800672402167968, 'feature_fraction': 0.7605379199753781, 'min_child_samples': 6, 'min_child_weight': 16.321935350781054, 'min_split_gain': 6.306282447297181, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7263868532089718                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7061999908448822, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7061999908448822\n",
      "  9%|▉         | 18/200 [01:03<08:10,  2.69s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 20, 'n_estimators': 810, 'learning_rate': 0.2537152504294451, 'num_leaves': 1344, 'class_weight': None, 'reg_alpha': 4.506830530955673, 'reg_lambda': 7.6076359230420865, 'subsample_for_bin': 240000, 'subsample': 0.750183996405033, 'feature_fraction': 0.7061999908448822, 'min_child_samples': 13, 'min_child_weight': 57.24279479095907, 'min_split_gain': 7.061374454756256, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7108560959360426                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7365188118745708, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7365188118745708\n",
      " 10%|▉         | 19/200 [01:04<06:50,  2.27s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 16, 'n_estimators': 730, 'learning_rate': 0.39464121523674967, 'num_leaves': 1136, 'class_weight': 'balanced', 'reg_alpha': 7.342977230133743, 'reg_lambda': 8.52593638048948, 'subsample_for_bin': 220000, 'subsample': 0.95926880732464, 'feature_fraction': 0.7365188118745708, 'min_child_samples': 2, 'min_child_weight': 0.1695544995709687, 'min_split_gain': 7.545947484601711, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7250610703975129                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.969404220383517, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.969404220383517\n",
      " 10%|█         | 20/200 [01:07<07:23,  2.46s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 15, 'n_estimators': 260, 'learning_rate': 0.12489900347264353, 'num_leaves': 1024, 'class_weight': 'balanced', 'reg_alpha': 7.597240491875629, 'reg_lambda': 6.427308565381281, 'subsample_for_bin': 240000, 'subsample': 0.9788300342308518, 'feature_fraction': 0.969404220383517, 'min_child_samples': 1, 'min_child_weight': 0.30876087857274015, 'min_split_gain': 6.797281752421117, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.720759493670886                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8234437349755014, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8234437349755014\n",
      " 10%|█         | 21/200 [01:09<06:45,  2.26s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 17, 'n_estimators': 280, 'learning_rate': 0.4818783144628083, 'num_leaves': 880, 'class_weight': 'balanced', 'reg_alpha': 7.500146478497338, 'reg_lambda': 7.625356579005223, 'subsample_for_bin': 240000, 'subsample': 0.5606488243394896, 'feature_fraction': 0.8234437349755014, 'min_child_samples': 11, 'min_child_weight': 28.305636695370268, 'min_split_gain': 5.940746332737641, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7249011769931156                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8142090417524871, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8142090417524871\n",
      " 11%|█         | 22/200 [01:10<06:02,  2.04s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 16, 'n_estimators': 480, 'learning_rate': 0.24098562744604513, 'num_leaves': 1184, 'class_weight': 'balanced', 'reg_alpha': 6.793070835046112, 'reg_lambda': 9.008963280142025, 'subsample_for_bin': 260000, 'subsample': 0.9185083568235796, 'feature_fraction': 0.8142090417524871, 'min_child_samples': 12, 'min_child_weight': 53.8852947795671, 'min_split_gain': 6.974835643008724, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7149278258938485                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.9180246396659253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9180246396659253\n",
      " 12%|█▏        | 23/200 [01:13<06:14,  2.12s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 14, 'n_estimators': 280, 'learning_rate': 0.38660198438140353, 'num_leaves': 688, 'class_weight': 'balanced', 'reg_alpha': 7.780069528733969, 'reg_lambda': 8.045805425769803, 'subsample_for_bin': 200000, 'subsample': 0.661058749865213, 'feature_fraction': 0.9180246396659253, 'min_child_samples': 3, 'min_child_weight': 3.9078079416904257, 'min_split_gain': 5.876370935069, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7205851654452587                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.9283397576519351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9283397576519351\n",
      " 12%|█▏        | 24/200 [01:13<05:08,  1.75s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 17, 'n_estimators': 230, 'learning_rate': 0.34732378732386504, 'num_leaves': 1320, 'class_weight': 'balanced', 'reg_alpha': 5.964142976337241, 'reg_lambda': 7.9096066611875155, 'subsample_for_bin': 240000, 'subsample': 0.9341537217662778, 'feature_fraction': 0.9283397576519351, 'min_child_samples': 1, 'min_child_weight': 25.42779134522036, 'min_split_gain': 7.258289450197401, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7231978680879414                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6997600063799053, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6997600063799053\n",
      " 12%|█▎        | 25/200 [01:15<05:05,  1.75s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 18, 'n_estimators': 500, 'learning_rate': 0.2659817908608452, 'num_leaves': 1392, 'class_weight': 'balanced', 'reg_alpha': 6.734445765336498, 'reg_lambda': 7.2918621387143725, 'subsample_for_bin': 240000, 'subsample': 0.8100744637541586, 'feature_fraction': 0.6997600063799053, 'min_child_samples': 5, 'min_child_weight': 0.619095347672697, 'min_split_gain': 6.199202191704935, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7203331112591607                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.9257741703075144, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9257741703075144\n",
      " 13%|█▎        | 26/200 [01:16<04:41,  1.62s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 420, 'learning_rate': 0.4691847204988753, 'num_leaves': 752, 'class_weight': 'balanced', 'reg_alpha': 6.960290214125804, 'reg_lambda': 9.538182496821713, 'subsample_for_bin': 200000, 'subsample': 0.7861104810581363, 'feature_fraction': 0.9257741703075144, 'min_child_samples': 2, 'min_child_weight': 1.5056654593108423, 'min_split_gain': 4.247413338969691, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7200621807683767                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8625592272875144, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8625592272875144\n",
      " 14%|█▎        | 27/200 [01:19<05:00,  1.74s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 21, 'n_estimators': 540, 'learning_rate': 0.2674173906983709, 'num_leaves': 1112, 'class_weight': None, 'reg_alpha': 6.5866358979315205, 'reg_lambda': 7.581992519789308, 'subsample_for_bin': 280000, 'subsample': 0.7908540793346995, 'feature_fraction': 0.8625592272875144, 'min_child_samples': 16, 'min_child_weight': 9.90988564943376, 'min_split_gain': 7.177938385498064, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7271729957805907                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7275823087200851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7275823087200851\n",
      " 14%|█▍        | 28/200 [01:21<05:37,  1.96s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 280, 'learning_rate': 0.24373263966915334, 'num_leaves': 1088, 'class_weight': 'balanced', 'reg_alpha': 4.931668352193057, 'reg_lambda': 7.207565589503354, 'subsample_for_bin': 200000, 'subsample': 0.7722430781368412, 'feature_fraction': 0.7275823087200851, 'min_child_samples': 8, 'min_child_weight': 1.7962991105789583, 'min_split_gain': 7.356692234830383, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7270752831445703                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.9380701090795873, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9380701090795873\n",
      " 14%|█▍        | 29/200 [01:23<05:23,  1.89s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 16, 'n_estimators': 330, 'learning_rate': 0.4935073450012957, 'num_leaves': 872, 'class_weight': 'balanced', 'reg_alpha': 7.57755006351069, 'reg_lambda': 9.218635010378561, 'subsample_for_bin': 280000, 'subsample': 0.7933021485639078, 'feature_fraction': 0.9380701090795873, 'min_child_samples': 2, 'min_child_weight': 45.41383381916635, 'min_split_gain': 5.572475870328308, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7103442149677992                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8563705923012167, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8563705923012167\n",
      " 15%|█▌        | 30/200 [01:24<05:13,  1.84s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 400, 'learning_rate': 0.1902393264375724, 'num_leaves': 968, 'class_weight': 'balanced', 'reg_alpha': 5.2891808192589265, 'reg_lambda': 7.511894985503866, 'subsample_for_bin': 200000, 'subsample': 0.9038230033961921, 'feature_fraction': 0.8563705923012167, 'min_child_samples': 14, 'min_child_weight': 2.3389494393558588, 'min_split_gain': 6.3255582452589145, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7270619586942039                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8751448451426475, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8751448451426475\n",
      " 16%|█▌        | 31/200 [01:27<05:24,  1.92s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 19, 'n_estimators': 960, 'learning_rate': 0.2552980310360923, 'num_leaves': 1176, 'class_weight': 'balanced', 'reg_alpha': 6.233817730737725, 'reg_lambda': 8.180621122668171, 'subsample_for_bin': 280000, 'subsample': 0.8786824405564694, 'feature_fraction': 0.8751448451426475, 'min_child_samples': 15, 'min_child_weight': 3.470126901618046, 'min_split_gain': 6.665948964914292, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7234510326449034                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8717757437070474, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8717757437070474\n",
      " 16%|█▌        | 32/200 [01:28<04:46,  1.70s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 630, 'learning_rate': 0.21627444444782154, 'num_leaves': 1264, 'class_weight': None, 'reg_alpha': 5.605656522743246, 'reg_lambda': 8.591509275920737, 'subsample_for_bin': 300000, 'subsample': 0.878934540456602, 'feature_fraction': 0.8717757437070474, 'min_child_samples': 12, 'min_child_weight': 52.07326722122193, 'min_split_gain': 7.0757364933718465, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7150122140795026                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.741269331490626, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.741269331490626\n",
      " 16%|█▋        | 33/200 [01:31<05:43,  2.05s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 340, 'learning_rate': 0.33395581717952105, 'num_leaves': 1152, 'class_weight': 'balanced', 'reg_alpha': 6.766482313181243, 'reg_lambda': 7.49947344386946, 'subsample_for_bin': 280000, 'subsample': 0.8997513903521105, 'feature_fraction': 0.741269331490626, 'min_child_samples': 9, 'min_child_weight': 11.143793694906575, 'min_split_gain': 5.522620718667675, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7246835443037974                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8302849644835566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8302849644835566\n",
      " 17%|█▋        | 34/200 [01:33<05:36,  2.03s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 550, 'learning_rate': 0.17135330316354921, 'num_leaves': 1136, 'class_weight': None, 'reg_alpha': 6.335420626064704, 'reg_lambda': 8.409995359802597, 'subsample_for_bin': 280000, 'subsample': 0.7496881028211577, 'feature_fraction': 0.8302849644835566, 'min_child_samples': 43, 'min_child_weight': 5.938543495889184, 'min_split_gain': 7.901662595061522, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7276460137685987                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8603250606884552, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8603250606884552\n",
      " 18%|█▊        | 35/200 [01:35<05:58,  2.17s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 16, 'n_estimators': 400, 'learning_rate': 0.21653471050255624, 'num_leaves': 1112, 'class_weight': 'balanced', 'reg_alpha': 6.964083529071258, 'reg_lambda': 8.697111419691371, 'subsample_for_bin': 200000, 'subsample': 0.9459577082444771, 'feature_fraction': 0.8603250606884552, 'min_child_samples': 8, 'min_child_weight': 38.449228735945034, 'min_split_gain': 5.914140258548441, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7147768154563624                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7417829595360906, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7417829595360906\n",
      " 18%|█▊        | 36/200 [01:37<05:57,  2.18s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 540, 'learning_rate': 0.13030159282514303, 'num_leaves': 952, 'class_weight': None, 'reg_alpha': 6.040944229596039, 'reg_lambda': 9.1039899965349, 'subsample_for_bin': 300000, 'subsample': 0.827615327703739, 'feature_fraction': 0.7417829595360906, 'min_child_samples': 36, 'min_child_weight': 38.59524735088549, 'min_split_gain': 6.871067808756568, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7236620031090384                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8269813352138748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8269813352138748\n",
      " 18%|█▊        | 37/200 [01:40<06:07,  2.25s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 750, 'learning_rate': 0.08625293804899162, 'num_leaves': 1144, 'class_weight': None, 'reg_alpha': 6.509190607440286, 'reg_lambda': 8.562312935919172, 'subsample_for_bin': 260000, 'subsample': 0.7654154287269765, 'feature_fraction': 0.8269813352138748, 'min_child_samples': 95, 'min_child_weight': 46.4406787397528, 'min_split_gain': 6.9086754465646205, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7150299800133245                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.9163283793794095, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9163283793794095\n",
      " 19%|█▉        | 38/200 [01:44<07:55,  2.94s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 18, 'n_estimators': 590, 'learning_rate': 0.3838603671705739, 'num_leaves': 1112, 'class_weight': 'balanced', 'reg_alpha': 6.425481411871239, 'reg_lambda': 7.918178402920619, 'subsample_for_bin': 260000, 'subsample': 0.8572366326118882, 'feature_fraction': 0.9163283793794095, 'min_child_samples': 11, 'min_child_weight': 1.7356736597153135, 'min_split_gain': 6.311049236833272, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7032900288696424                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7606156190426231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7606156190426231\n",
      " 20%|█▉        | 39/200 [01:46<06:35,  2.46s/trial, best loss: -0.7278236731068177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 610, 'learning_rate': 0.2110531675055364, 'num_leaves': 1160, 'class_weight': 'balanced', 'reg_alpha': 5.419283066299756, 'reg_lambda': 8.071609615567715, 'subsample_for_bin': 260000, 'subsample': 0.9653051369258332, 'feature_fraction': 0.7606156190426231, 'min_child_samples': 10, 'min_child_weight': 0.7930591827188987, 'min_split_gain': 7.235592556795636, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7286475682878082                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6400826256242799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6400826256242799\n",
      " 20%|██        | 40/200 [01:49<06:53,  2.59s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 440, 'learning_rate': 0.3178862290532444, 'num_leaves': 1176, 'class_weight': 'balanced', 'reg_alpha': 5.36473733183888, 'reg_lambda': 7.241510879424052, 'subsample_for_bin': 180000, 'subsample': 0.7391711120965521, 'feature_fraction': 0.6400826256242799, 'min_child_samples': 18, 'min_child_weight': 0.2464651292753259, 'min_split_gain': 6.690891168242965, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7259560293137909                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6831485006902976, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6831485006902976\n",
      " 20%|██        | 41/200 [01:51<06:36,  2.49s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 830, 'learning_rate': 0.14007816327739736, 'num_leaves': 1120, 'class_weight': 'balanced', 'reg_alpha': 6.245794756778935, 'reg_lambda': 8.258475803452509, 'subsample_for_bin': 300000, 'subsample': 0.9880898437791764, 'feature_fraction': 0.6831485006902976, 'min_child_samples': 16, 'min_child_weight': 1.4833427640597523, 'min_split_gain': 7.376263549908257, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7265622918054631                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7854936528218941, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7854936528218941\n",
      " 21%|██        | 42/200 [01:54<07:23,  2.81s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 810, 'learning_rate': 0.17355625399440355, 'num_leaves': 1272, 'class_weight': 'balanced', 'reg_alpha': 6.238178372141007, 'reg_lambda': 7.112115907931014, 'subsample_for_bin': 260000, 'subsample': 0.854357327512276, 'feature_fraction': 0.7854936528218941, 'min_child_samples': 16, 'min_child_weight': 3.7995810076634773, 'min_split_gain': 7.328324796276186, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7285409726848767                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8104209838307044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8104209838307044\n",
      " 22%|██▏       | 43/200 [01:58<07:57,  3.04s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 18, 'n_estimators': 630, 'learning_rate': 0.2965599830522571, 'num_leaves': 1128, 'class_weight': 'balanced', 'reg_alpha': 4.947226278775593, 'reg_lambda': 8.980489506638001, 'subsample_for_bin': 280000, 'subsample': 0.9543163947119743, 'feature_fraction': 0.8104209838307044, 'min_child_samples': 14, 'min_child_weight': 0.1586872574082465, 'min_split_gain': 7.24208871321998, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7258316677770376                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7732067562048703, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7732067562048703\n",
      " 22%|██▏       | 44/200 [01:59<06:34,  2.53s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 21, 'n_estimators': 590, 'learning_rate': 0.14901582826160498, 'num_leaves': 1432, 'class_weight': 'balanced', 'reg_alpha': 5.958471436508864, 'reg_lambda': 7.580339362294131, 'subsample_for_bin': 240000, 'subsample': 0.8324267336909091, 'feature_fraction': 0.7732067562048703, 'min_child_samples': 14, 'min_child_weight': 0.745431715354722, 'min_split_gain': 6.749688484029584, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7265156562291806                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7980302168059608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7980302168059608\n",
      " 22%|██▎       | 45/200 [02:02<06:55,  2.68s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 490, 'learning_rate': 0.14348053503503824, 'num_leaves': 936, 'class_weight': 'balanced', 'reg_alpha': 6.179839881179046, 'reg_lambda': 6.858752185599492, 'subsample_for_bin': 200000, 'subsample': 0.855824772470903, 'feature_fraction': 0.7980302168059608, 'min_child_samples': 28, 'min_child_weight': 15.59263969088632, 'min_split_gain': 5.711910192557471, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.725733955141017                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8140975661283355, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8140975661283355\n",
      " 23%|██▎       | 46/200 [02:06<07:34,  2.95s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 710, 'learning_rate': 0.16049973600756834, 'num_leaves': 1128, 'class_weight': 'balanced', 'reg_alpha': 6.929592327111537, 'reg_lambda': 8.107878490735775, 'subsample_for_bin': 280000, 'subsample': 0.8178093483704443, 'feature_fraction': 0.8140975661283355, 'min_child_samples': 32, 'min_child_weight': 2.5323566584189483, 'min_split_gain': 7.74302835383663, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7255029980013323                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8241619496877077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8241619496877077\n",
      " 24%|██▎       | 47/200 [02:09<07:45,  3.05s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 760, 'learning_rate': 0.1359025902684268, 'num_leaves': 1320, 'class_weight': 'balanced', 'reg_alpha': 7.068601147428798, 'reg_lambda': 7.584146167524368, 'subsample_for_bin': 260000, 'subsample': 0.7841104386646387, 'feature_fraction': 0.8241619496877077, 'min_child_samples': 10, 'min_child_weight': 2.8881390108021474, 'min_split_gain': 6.508524779986816, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7266711081501223                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.706787961340404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.706787961340404\n",
      " 24%|██▍       | 48/200 [02:13<08:13,  3.25s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 440, 'learning_rate': 0.23350864156361772, 'num_leaves': 976, 'class_weight': 'balanced', 'reg_alpha': 5.758769277333918, 'reg_lambda': 7.4319165819197295, 'subsample_for_bin': 240000, 'subsample': 0.9473035738323162, 'feature_fraction': 0.706787961340404, 'min_child_samples': 5, 'min_child_weight': 2.5571095827046593, 'min_split_gain': 7.674673712077078, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7257406173662004                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7686028522584865, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7686028522584865\n",
      " 24%|██▍       | 49/200 [02:15<07:13,  2.87s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 630, 'learning_rate': 0.2558755321311325, 'num_leaves': 1336, 'class_weight': 'balanced', 'reg_alpha': 6.965481903380698, 'reg_lambda': 6.460069472155789, 'subsample_for_bin': 280000, 'subsample': 0.9059154075503171, 'feature_fraction': 0.7686028522584865, 'min_child_samples': 17, 'min_child_weight': 2.2319431917916908, 'min_split_gain': 6.930530926251531, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7248678658671996                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8756041956317582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8756041956317582\n",
      " 25%|██▌       | 50/200 [02:18<07:16,  2.91s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 17, 'n_estimators': 670, 'learning_rate': 0.3479561378065163, 'num_leaves': 1200, 'class_weight': 'balanced', 'reg_alpha': 6.26445214529155, 'reg_lambda': 8.385630175297138, 'subsample_for_bin': 260000, 'subsample': 0.8795175326287356, 'feature_fraction': 0.8756041956317582, 'min_child_samples': 5, 'min_child_weight': 2.3007395091656972, 'min_split_gain': 5.775083542358791, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7279169442593827                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7283027990284552, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7283027990284552\n",
      " 26%|██▌       | 51/200 [02:21<07:27,  3.00s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 580, 'learning_rate': 0.1919732898986048, 'num_leaves': 1352, 'class_weight': 'balanced', 'reg_alpha': 4.7468681157300185, 'reg_lambda': 7.429347752657085, 'subsample_for_bin': 260000, 'subsample': 0.9093241943825279, 'feature_fraction': 0.7283027990284552, 'min_child_samples': 10, 'min_child_weight': 2.438090557985777, 'min_split_gain': 7.346683530688147, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7256295802798134                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8113770903068667, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8113770903068667\n",
      " 26%|██▌       | 52/200 [02:24<07:11,  2.91s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 420, 'learning_rate': 0.24834038779668582, 'num_leaves': 984, 'class_weight': 'balanced', 'reg_alpha': 4.925753997304536, 'reg_lambda': 7.31555924794663, 'subsample_for_bin': 280000, 'subsample': 0.8681594518706383, 'feature_fraction': 0.8113770903068667, 'min_child_samples': 16, 'min_child_weight': 0.1513978349149917, 'min_split_gain': 7.3968628465, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7269487008660893                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.739052009755309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.739052009755309\n",
      " 26%|██▋       | 53/200 [02:26<06:29,  2.65s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 510, 'learning_rate': 0.23391507159935546, 'num_leaves': 1104, 'class_weight': 'balanced', 'reg_alpha': 6.211275503836737, 'reg_lambda': 7.791177485427237, 'subsample_for_bin': 240000, 'subsample': 0.9310765761514517, 'feature_fraction': 0.739052009755309, 'min_child_samples': 12, 'min_child_weight': 0.7282341488023601, 'min_split_gain': 7.8826934786660035, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7255096602265156                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7746063743251342, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7746063743251342\n",
      " 27%|██▋       | 54/200 [02:28<06:11,  2.55s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 640, 'learning_rate': 0.14624600858094744, 'num_leaves': 1056, 'class_weight': 'balanced', 'reg_alpha': 5.33802168597045, 'reg_lambda': 8.764706557583759, 'subsample_for_bin': 240000, 'subsample': 0.9304256829047588, 'feature_fraction': 0.7746063743251342, 'min_child_samples': 6, 'min_child_weight': 0.27004983841480884, 'min_split_gain': 6.9100905390444956, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7254430379746835                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7976045899543309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7976045899543309\n",
      " 28%|██▊       | 55/200 [02:31<06:28,  2.68s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 540, 'learning_rate': 0.15773016122660993, 'num_leaves': 1232, 'class_weight': 'balanced', 'reg_alpha': 5.147820934902368, 'reg_lambda': 8.555512729974263, 'subsample_for_bin': 280000, 'subsample': 0.8937012137176709, 'feature_fraction': 0.7976045899543309, 'min_child_samples': 6, 'min_child_weight': 0.2806095468185356, 'min_split_gain': 7.318901036143547, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7254696868754164                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7796440028279755, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7796440028279755\n",
      " 28%|██▊       | 56/200 [02:34<06:28,  2.70s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 640, 'learning_rate': 0.23738874619993586, 'num_leaves': 1176, 'class_weight': 'balanced', 'reg_alpha': 5.695040094819515, 'reg_lambda': 8.440939852339092, 'subsample_for_bin': 260000, 'subsample': 0.9292062736608915, 'feature_fraction': 0.7796440028279755, 'min_child_samples': 6, 'min_child_weight': 1.0276130522510192, 'min_split_gain': 7.548084752055695, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7255407506107039                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8019145014544703, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8019145014544703\n",
      " 28%|██▊       | 57/200 [02:37<06:33,  2.75s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 750, 'learning_rate': 0.13224277657327008, 'num_leaves': 1208, 'class_weight': 'balanced', 'reg_alpha': 5.713297308387354, 'reg_lambda': 7.445245171702737, 'subsample_for_bin': 260000, 'subsample': 0.8095490321218931, 'feature_fraction': 0.8019145014544703, 'min_child_samples': 18, 'min_child_weight': 0.986506615672526, 'min_split_gain': 7.073029874101263, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.726351321341328                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7806154200912829, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7806154200912829\n",
      " 29%|██▉       | 58/200 [02:40<07:00,  2.96s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 540, 'learning_rate': 0.19383369048676694, 'num_leaves': 1096, 'class_weight': 'balanced', 'reg_alpha': 5.2093885870338, 'reg_lambda': 8.306936274475772, 'subsample_for_bin': 280000, 'subsample': 0.8945156514908521, 'feature_fraction': 0.7806154200912829, 'min_child_samples': 14, 'min_child_weight': 1.2364042735303622, 'min_split_gain': 7.057319312545321, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7271396846546747                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8433156928286023, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8433156928286023\n",
      " 30%|██▉       | 59/200 [02:43<06:35,  2.81s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 680, 'learning_rate': 0.1412619914131851, 'num_leaves': 1376, 'class_weight': 'balanced', 'reg_alpha': 5.577723530229351, 'reg_lambda': 6.741141906762514, 'subsample_for_bin': 280000, 'subsample': 0.8031140778697049, 'feature_fraction': 0.8433156928286023, 'min_child_samples': 14, 'min_child_weight': 1.326039700088812, 'min_split_gain': 7.272084096237286, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7263291139240505                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8270647587611638, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8270647587611638\n",
      " 30%|███       | 60/200 [02:46<06:58,  2.99s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 650, 'learning_rate': 0.15836100281373694, 'num_leaves': 1240, 'class_weight': 'balanced', 'reg_alpha': 5.72320976311928, 'reg_lambda': 7.5237209988040465, 'subsample_for_bin': 240000, 'subsample': 0.8045975433179106, 'feature_fraction': 0.8270647587611638, 'min_child_samples': 26, 'min_child_weight': 6.401083712225111, 'min_split_gain': 7.385968012631011, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7262402842549412                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7674071276923584, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7674071276923584\n",
      " 30%|███       | 61/200 [02:49<06:56,  3.00s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 480, 'learning_rate': 0.1673573719186447, 'num_leaves': 1312, 'class_weight': 'balanced', 'reg_alpha': 6.107061290236741, 'reg_lambda': 7.803709682751465, 'subsample_for_bin': 280000, 'subsample': 0.9561374399618019, 'feature_fraction': 0.7674071276923584, 'min_child_samples': 11, 'min_child_weight': 0.19204584192170274, 'min_split_gain': 7.241736505172792, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7253431045969353                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7078111070778367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7078111070778367\n",
      " 31%|███       | 62/200 [02:52<06:36,  2.87s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 520, 'learning_rate': 0.21835529797787073, 'num_leaves': 1224, 'class_weight': 'balanced', 'reg_alpha': 5.5050387008078925, 'reg_lambda': 7.479874796748108, 'subsample_for_bin': 280000, 'subsample': 0.9169138511753777, 'feature_fraction': 0.7078111070778367, 'min_child_samples': 6, 'min_child_weight': 2.7013006276703004, 'min_split_gain': 7.82170994637341, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7276060404174994                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7258084299489714, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7258084299489714\n",
      " 32%|███▏      | 63/200 [02:54<06:17,  2.75s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 940, 'learning_rate': 0.21251763030158333, 'num_leaves': 1392, 'class_weight': 'balanced', 'reg_alpha': 6.624180201731999, 'reg_lambda': 7.678324613532938, 'subsample_for_bin': 280000, 'subsample': 0.9107449800597267, 'feature_fraction': 0.7258084299489714, 'min_child_samples': 31, 'min_child_weight': 1.012396413852484, 'min_split_gain': 6.79181797945715, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7265667332889185                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8996755716326386, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8996755716326386\n",
      " 32%|███▏      | 64/200 [02:58<07:04,  3.12s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 710, 'learning_rate': 0.29904291732833793, 'num_leaves': 1136, 'class_weight': 'balanced', 'reg_alpha': 5.8057250555646815, 'reg_lambda': 8.191239790304634, 'subsample_for_bin': 260000, 'subsample': 0.8325833597701701, 'feature_fraction': 0.8996755716326386, 'min_child_samples': 3, 'min_child_weight': 4.690304443481687, 'min_split_gain': 5.652031176518177, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7267532755940483                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7414567403147627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7414567403147627\n",
      " 32%|███▎      | 65/200 [03:01<07:10,  3.19s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 710, 'learning_rate': 0.2359256508386033, 'num_leaves': 1360, 'class_weight': 'balanced', 'reg_alpha': 6.741734129038498, 'reg_lambda': 6.643545655700113, 'subsample_for_bin': 240000, 'subsample': 0.8252948663671603, 'feature_fraction': 0.7414567403147627, 'min_child_samples': 14, 'min_child_weight': 2.787716672667599, 'min_split_gain': 6.807759235433578, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7264246058183433                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7414794432157915, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7414794432157915\n",
      " 33%|███▎      | 66/200 [03:05<07:10,  3.21s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 560, 'learning_rate': 0.17033316025389014, 'num_leaves': 1048, 'class_weight': 'balanced', 'reg_alpha': 5.8951829826607245, 'reg_lambda': 7.9566897023363055, 'subsample_for_bin': 280000, 'subsample': 0.9117732449324956, 'feature_fraction': 0.7414794432157915, 'min_child_samples': 17, 'min_child_weight': 2.0385073598836234, 'min_split_gain': 6.766821155861393, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.725616255829447                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7454203049921346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7454203049921346\n",
      " 34%|███▎      | 67/200 [03:07<06:44,  3.04s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 470, 'learning_rate': 0.2181214230810546, 'num_leaves': 1256, 'class_weight': 'balanced', 'reg_alpha': 5.074390467717459, 'reg_lambda': 8.718736109112292, 'subsample_for_bin': 260000, 'subsample': 0.9655102205000471, 'feature_fraction': 0.7454203049921346, 'min_child_samples': 12, 'min_child_weight': 0.5240774079922398, 'min_split_gain': 6.657324635475994, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7270042194092827                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.89615709382577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89615709382577\n",
      " 34%|███▍      | 68/200 [03:10<06:19,  2.88s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 690, 'learning_rate': 0.40939732166262865, 'num_leaves': 1184, 'class_weight': 'balanced', 'reg_alpha': 6.348452880877705, 'reg_lambda': 8.8318363658143, 'subsample_for_bin': 260000, 'subsample': 0.8769559747189583, 'feature_fraction': 0.89615709382577, 'min_child_samples': 4, 'min_child_weight': 1.6649368584084796, 'min_split_gain': 6.176781759625612, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.725371974239396                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.9034855897041989, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9034855897041989\n",
      " 34%|███▍      | 69/200 [03:13<06:28,  2.97s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 540, 'learning_rate': 0.4023699162493407, 'num_leaves': 1320, 'class_weight': 'balanced', 'reg_alpha': 5.663807237873261, 'reg_lambda': 8.132358983390507, 'subsample_for_bin': 260000, 'subsample': 0.8822664766416328, 'feature_fraction': 0.9034855897041989, 'min_child_samples': 5, 'min_child_weight': 2.408240760164462, 'min_split_gain': 6.159577660631712, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7254497001998668                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8405368716656969, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8405368716656969\n",
      " 35%|███▌      | 70/200 [03:16<06:18,  2.91s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 690, 'learning_rate': 0.2105545607497536, 'num_leaves': 1408, 'class_weight': 'balanced', 'reg_alpha': 6.153774050499303, 'reg_lambda': 7.104269990831276, 'subsample_for_bin': 280000, 'subsample': 0.8267884388600114, 'feature_fraction': 0.8405368716656969, 'min_child_samples': 13, 'min_child_weight': 8.83653145369375, 'min_split_gain': 7.627517476828875, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7261914279369309                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7252278220547638, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7252278220547638\n",
      " 36%|███▌      | 71/200 [03:19<06:28,  3.01s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 19, 'n_estimators': 690, 'learning_rate': 0.24595202100275348, 'num_leaves': 1304, 'class_weight': 'balanced', 'reg_alpha': 5.130635206406422, 'reg_lambda': 8.454846163805975, 'subsample_for_bin': 280000, 'subsample': 0.9430147242535863, 'feature_fraction': 0.7252278220547638, 'min_child_samples': 6, 'min_child_weight': 0.46626996870894194, 'min_split_gain': 7.421926385111768, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7204874528092383                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7396170805226806, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7396170805226806\n",
      " 36%|███▌      | 72/200 [03:20<05:18,  2.49s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 670, 'learning_rate': 0.17083383964313942, 'num_leaves': 1040, 'class_weight': 'balanced', 'reg_alpha': 5.490607042728819, 'reg_lambda': 8.18178690046731, 'subsample_for_bin': 260000, 'subsample': 0.9390698902389509, 'feature_fraction': 0.7396170805226806, 'min_child_samples': 7, 'min_child_weight': 0.87371788229222, 'min_split_gain': 6.8690769645790475, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7279746835443038                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7689956136630864, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7689956136630864\n",
      " 36%|███▋      | 73/200 [03:23<05:37,  2.66s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 860, 'learning_rate': 0.1218685093773343, 'num_leaves': 1336, 'class_weight': None, 'reg_alpha': 6.6777762110647405, 'reg_lambda': 7.262062894776681, 'subsample_for_bin': 240000, 'subsample': 0.841913820026744, 'feature_fraction': 0.7689956136630864, 'min_child_samples': 25, 'min_child_weight': 8.340200635028616, 'min_split_gain': 7.683737115533866, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7272285143237842                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.9288612225937192, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9288612225937192\n",
      " 37%|███▋      | 74/200 [03:27<06:19,  3.01s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 550, 'learning_rate': 0.29574643816061075, 'num_leaves': 1224, 'class_weight': 'balanced', 'reg_alpha': 6.798517576655891, 'reg_lambda': 7.840624050540218, 'subsample_for_bin': 240000, 'subsample': 0.8886710579266317, 'feature_fraction': 0.9288612225937192, 'min_child_samples': 6, 'min_child_weight': 2.6273303886795043, 'min_split_gain': 5.342260330800345, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7278525427492782                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7733618563344682, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7733618563344682\n",
      " 38%|███▊      | 75/200 [03:30<06:12,  2.98s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 480, 'learning_rate': 0.23979113078938513, 'num_leaves': 1128, 'class_weight': 'balanced', 'reg_alpha': 5.7543455445158465, 'reg_lambda': 7.830576811101213, 'subsample_for_bin': 280000, 'subsample': 0.9784650062347823, 'feature_fraction': 0.7733618563344682, 'min_child_samples': 12, 'min_child_weight': 1.319860741771053, 'min_split_gain': 6.684854906807839, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7253364423717522                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7397768448167973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7397768448167973\n",
      " 38%|███▊      | 76/200 [03:32<05:46,  2.80s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 640, 'learning_rate': 0.2479395342459556, 'num_leaves': 1248, 'class_weight': 'balanced', 'reg_alpha': 5.9535779941626465, 'reg_lambda': 8.564708602562556, 'subsample_for_bin': 240000, 'subsample': 0.9489755564877954, 'feature_fraction': 0.7397768448167973, 'min_child_samples': 9, 'min_child_weight': 0.30150259552851755, 'min_split_gain': 6.778768333394048, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7255762824783478                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7464884038946659, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7464884038946659\n",
      " 38%|███▊      | 77/200 [03:35<05:47,  2.82s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 800, 'learning_rate': 0.15244869871986805, 'num_leaves': 936, 'class_weight': 'balanced', 'reg_alpha': 4.925080929529488, 'reg_lambda': 8.499259366757482, 'subsample_for_bin': 260000, 'subsample': 0.9106466772543196, 'feature_fraction': 0.7464884038946659, 'min_child_samples': 10, 'min_child_weight': 1.2830567441221021, 'min_split_gain': 6.542730552884344, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7256873195647346                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7912860457476532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7912860457476532\n",
      " 39%|███▉      | 78/200 [03:39<06:09,  3.03s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 500, 'learning_rate': 0.19305719919973208, 'num_leaves': 1240, 'class_weight': 'balanced', 'reg_alpha': 5.775689228959545, 'reg_lambda': 7.82453059526447, 'subsample_for_bin': 260000, 'subsample': 0.9787577582934447, 'feature_fraction': 0.7912860457476532, 'min_child_samples': 14, 'min_child_weight': 2.53470547872465, 'min_split_gain': 7.482702986690767, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7271419053964023                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7472560651543217, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7472560651543217\n",
      " 40%|███▉      | 79/200 [03:41<05:46,  2.86s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 19, 'n_estimators': 590, 'learning_rate': 0.14101894769306372, 'num_leaves': 1072, 'class_weight': 'balanced', 'reg_alpha': 5.0226850675674495, 'reg_lambda': 8.108019034975971, 'subsample_for_bin': 280000, 'subsample': 0.9358662451550672, 'feature_fraction': 0.7472560651543217, 'min_child_samples': 6, 'min_child_weight': 0.5462407276519646, 'min_split_gain': 7.29906499242461, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7173051299133911                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7353503147309854, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7353503147309854\n",
      " 40%|████      | 80/200 [03:43<04:42,  2.35s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 590, 'learning_rate': 0.24376476766027558, 'num_leaves': 1192, 'class_weight': 'balanced', 'reg_alpha': 4.951644979374806, 'reg_lambda': 7.714990517209141, 'subsample_for_bin': 280000, 'subsample': 0.9770326748418993, 'feature_fraction': 0.7353503147309854, 'min_child_samples': 15, 'min_child_weight': 2.0330077447438195, 'min_split_gain': 7.6236226404394705, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7265445258716411                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7241596234572487, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7241596234572487\n",
      " 40%|████      | 81/200 [03:45<04:53,  2.46s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 590, 'learning_rate': 0.19061070849263173, 'num_leaves': 1200, 'class_weight': 'balanced', 'reg_alpha': 5.42049858456041, 'reg_lambda': 8.374847793416432, 'subsample_for_bin': 240000, 'subsample': 0.9203962167145268, 'feature_fraction': 0.7241596234572487, 'min_child_samples': 8, 'min_child_weight': 0.7487842439574505, 'min_split_gain': 7.401561628265203, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7254208305574061                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7784943665533103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7784943665533103\n",
      " 41%|████      | 82/200 [03:48<05:03,  2.57s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 690, 'learning_rate': 0.24166718546776933, 'num_leaves': 1064, 'class_weight': 'balanced', 'reg_alpha': 5.175856990691578, 'reg_lambda': 7.724645211157561, 'subsample_for_bin': 280000, 'subsample': 0.917565978872116, 'feature_fraction': 0.7784943665533103, 'min_child_samples': 7, 'min_child_weight': 0.3672860419726573, 'min_split_gain': 7.220412628433869, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7273084610259827                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7577654639866152, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7577654639866152\n",
      " 42%|████▏     | 83/200 [03:51<05:16,  2.71s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 18, 'n_estimators': 640, 'learning_rate': 0.22109271240845452, 'num_leaves': 1096, 'class_weight': 'balanced', 'reg_alpha': 5.953069295161579, 'reg_lambda': 7.869881148234571, 'subsample_for_bin': 260000, 'subsample': 0.9819680326138778, 'feature_fraction': 0.7577654639866152, 'min_child_samples': 9, 'min_child_weight': 0.5519410062017694, 'min_split_gain': 6.9362367352499525, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7257284032866977                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7531166280693471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7531166280693471\n",
      " 42%|████▏     | 84/200 [03:52<04:19,  2.23s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 550, 'learning_rate': 0.16109519973003364, 'num_leaves': 1128, 'class_weight': 'balanced', 'reg_alpha': 5.764523108644719, 'reg_lambda': 8.242231853113644, 'subsample_for_bin': 240000, 'subsample': 0.9340292955403343, 'feature_fraction': 0.7531166280693471, 'min_child_samples': 6, 'min_child_weight': 1.0369378710794181, 'min_split_gain': 6.718756440782633, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.724805685098823                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7574813949465973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7574813949465973\n",
      " 42%|████▎     | 85/200 [03:55<04:34,  2.39s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 690, 'learning_rate': 0.23389351659924595, 'num_leaves': 1048, 'class_weight': 'balanced', 'reg_alpha': 5.28470849678327, 'reg_lambda': 8.167001140176133, 'subsample_for_bin': 260000, 'subsample': 0.9737848698551772, 'feature_fraction': 0.7574813949465973, 'min_child_samples': 7, 'min_child_weight': 0.521008230158132, 'min_split_gain': 7.12174330579781, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.727845880524095                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8003594941945619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8003594941945619\n",
      " 43%|████▎     | 86/200 [03:59<05:31,  2.91s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 18, 'n_estimators': 630, 'learning_rate': 0.1946368079677425, 'num_leaves': 1248, 'class_weight': 'balanced', 'reg_alpha': 5.218648870732543, 'reg_lambda': 8.430164741349275, 'subsample_for_bin': 260000, 'subsample': 0.9683574514294323, 'feature_fraction': 0.8003594941945619, 'min_child_samples': 10, 'min_child_weight': 0.4513531875205292, 'min_split_gain': 7.717011882114305, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7177992449478126                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154177022152146, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154177022152146\n",
      " 44%|████▎     | 87/200 [04:00<04:38,  2.47s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 640, 'learning_rate': 0.27139672128965586, 'num_leaves': 1304, 'class_weight': 'balanced', 'reg_alpha': 6.71776909104064, 'reg_lambda': 8.087797877643684, 'subsample_for_bin': 240000, 'subsample': 0.9186300651744121, 'feature_fraction': 0.9154177022152146, 'min_child_samples': 5, 'min_child_weight': 3.5256477276023426, 'min_split_gain': 5.849624658838104, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7240683988452142                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6974383403933583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6974383403933583\n",
      " 44%|████▍     | 88/200 [04:05<05:35,  2.99s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 630, 'learning_rate': 0.1401910391473416, 'num_leaves': 1152, 'class_weight': 'balanced', 'reg_alpha': 4.998736124407025, 'reg_lambda': 7.672369440096129, 'subsample_for_bin': 260000, 'subsample': 0.9204503655080414, 'feature_fraction': 0.6974383403933583, 'min_child_samples': 5, 'min_child_weight': 0.6101573344964915, 'min_split_gain': 7.318218505745531, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7259737952476127                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7482823109642361, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482823109642361\n",
      " 44%|████▍     | 89/200 [04:08<05:27,  2.95s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 18, 'n_estimators': 690, 'learning_rate': 0.2212733730125868, 'num_leaves': 1232, 'class_weight': 'balanced', 'reg_alpha': 5.362308385564533, 'reg_lambda': 7.962075520115995, 'subsample_for_bin': 280000, 'subsample': 0.9635101256436174, 'feature_fraction': 0.7482823109642361, 'min_child_samples': 6, 'min_child_weight': 1.2461178470147287, 'min_split_gain': 7.483797416694404, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7164812347324006                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7350144289510849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7350144289510849\n",
      " 45%|████▌     | 90/200 [04:09<04:28,  2.44s/trial, best loss: -0.7286475682878082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 630, 'learning_rate': 0.2322764610405525, 'num_leaves': 1168, 'class_weight': 'balanced', 'reg_alpha': 5.265692435877826, 'reg_lambda': 8.020217604050547, 'subsample_for_bin': 280000, 'subsample': 0.913244373322127, 'feature_fraction': 0.7350144289510849, 'min_child_samples': 8, 'min_child_weight': 0.6031220122160778, 'min_split_gain': 7.288962249180972, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7290850544081724                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7525078439418719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7525078439418719\n",
      " 46%|████▌     | 91/200 [04:12<04:38,  2.55s/trial, best loss: -0.7290850544081724]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 670, 'learning_rate': 0.20779150569009996, 'num_leaves': 1200, 'class_weight': 'balanced', 'reg_alpha': 5.208211866694753, 'reg_lambda': 7.615854409642876, 'subsample_for_bin': 300000, 'subsample': 0.9218812615151245, 'feature_fraction': 0.7525078439418719, 'min_child_samples': 7, 'min_child_weight': 0.21804629273836587, 'min_split_gain': 6.889224463303763, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7285587386186987                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7386352894743135, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7386352894743135\n",
      " 46%|████▌     | 92/200 [04:15<04:52,  2.71s/trial, best loss: -0.7290850544081724]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 680, 'learning_rate': 0.19894496083531454, 'num_leaves': 1128, 'class_weight': 'balanced', 'reg_alpha': 5.696741607400934, 'reg_lambda': 7.141807181692338, 'subsample_for_bin': 300000, 'subsample': 0.9317383066292991, 'feature_fraction': 0.7386352894743135, 'min_child_samples': 5, 'min_child_weight': 0.16558207012166504, 'min_split_gain': 6.8969800581383165, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7255252054186098                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7328594802764481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7328594802764481\n",
      " 46%|████▋     | 93/200 [04:18<05:01,  2.82s/trial, best loss: -0.7290850544081724]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 640, 'learning_rate': 0.1663938262140273, 'num_leaves': 1168, 'class_weight': 'balanced', 'reg_alpha': 5.4819162825785295, 'reg_lambda': 8.20366376653083, 'subsample_for_bin': 260000, 'subsample': 0.9711558759614979, 'feature_fraction': 0.7328594802764481, 'min_child_samples': 9, 'min_child_weight': 0.9185369617705178, 'min_split_gain': 6.919537902080923, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7291627803686431                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7183045262083315, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7183045262083315\n",
      " 47%|████▋     | 94/200 [04:21<05:05,  2.88s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 590, 'learning_rate': 0.2555042073423523, 'num_leaves': 1048, 'class_weight': 'balanced', 'reg_alpha': 5.112951370489803, 'reg_lambda': 8.474657015593976, 'subsample_for_bin': 260000, 'subsample': 0.9648335619700351, 'feature_fraction': 0.7183045262083315, 'min_child_samples': 11, 'min_child_weight': 1.2106177994233456, 'min_split_gain': 7.519254577832372, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7261803242282923                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7141388088632041, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7141388088632041\n",
      " 48%|████▊     | 95/200 [04:23<04:52,  2.79s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 580, 'learning_rate': 0.27137270910325634, 'num_leaves': 1136, 'class_weight': 'balanced', 'reg_alpha': 5.097695198432422, 'reg_lambda': 7.838258943264368, 'subsample_for_bin': 280000, 'subsample': 0.8798187637780593, 'feature_fraction': 0.7141388088632041, 'min_child_samples': 8, 'min_child_weight': 1.1112565875849998, 'min_split_gain': 7.355838864115715, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7278325560737287                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7105957988519969, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7105957988519969\n",
      " 48%|████▊     | 96/200 [04:26<04:42,  2.72s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 650, 'learning_rate': 0.11980095451081946, 'num_leaves': 1104, 'class_weight': 'balanced', 'reg_alpha': 5.662245585626275, 'reg_lambda': 8.13037737299762, 'subsample_for_bin': 240000, 'subsample': 0.9279506543529171, 'feature_fraction': 0.7105957988519969, 'min_child_samples': 11, 'min_child_weight': 0.5248227465838607, 'min_split_gain': 6.743159140068266, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7271152564956695                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7682471157403241, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7682471157403241\n",
      " 48%|████▊     | 97/200 [04:29<04:48,  2.80s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 530, 'learning_rate': 0.1389835630163298, 'num_leaves': 1232, 'class_weight': 'balanced', 'reg_alpha': 5.779389659708754, 'reg_lambda': 8.283207530554165, 'subsample_for_bin': 260000, 'subsample': 0.9764056183342278, 'feature_fraction': 0.7682471157403241, 'min_child_samples': 12, 'min_child_weight': 0.8823560426187717, 'min_split_gain': 6.763999633408588, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7246968687541638                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7924731296997942, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7924731296997942\n",
      " 49%|████▉     | 98/200 [04:32<04:42,  2.77s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 560, 'learning_rate': 0.25660949530436616, 'num_leaves': 1128, 'class_weight': 'balanced', 'reg_alpha': 5.695563261077302, 'reg_lambda': 8.163242675049954, 'subsample_for_bin': 260000, 'subsample': 0.9317389326846627, 'feature_fraction': 0.7924731296997942, 'min_child_samples': 12, 'min_child_weight': 1.2507252744718491, 'min_split_gain': 7.221818950865663, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7257961359093937                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7746843983892588, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7746843983892588\n",
      " 50%|████▉     | 99/200 [04:34<04:34,  2.72s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 580, 'learning_rate': 0.2752522676668334, 'num_leaves': 1248, 'class_weight': 'balanced', 'reg_alpha': 4.90610742996723, 'reg_lambda': 7.987896540749075, 'subsample_for_bin': 280000, 'subsample': 0.9355219020464649, 'feature_fraction': 0.7746843983892588, 'min_child_samples': 8, 'min_child_weight': 0.5883677673994387, 'min_split_gain': 7.149121067023621, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7269753497668222                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7249916830991512, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7249916830991512\n",
      " 50%|█████     | 100/200 [04:37<04:30,  2.70s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 590, 'learning_rate': 0.14945749369745154, 'num_leaves': 1128, 'class_weight': 'balanced', 'reg_alpha': 5.458792082387279, 'reg_lambda': 8.127678767522712, 'subsample_for_bin': 260000, 'subsample': 0.9668717861636336, 'feature_fraction': 0.7249916830991512, 'min_child_samples': 14, 'min_child_weight': 2.1813730345924816, 'min_split_gain': 7.054845113366181, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7259582500555185                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7472489146598563, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7472489146598563\n",
      " 50%|█████     | 101/200 [04:40<04:29,  2.72s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 660, 'learning_rate': 0.20298431038596895, 'num_leaves': 1264, 'class_weight': 'balanced', 'reg_alpha': 5.018018826934608, 'reg_lambda': 7.91375783512355, 'subsample_for_bin': 280000, 'subsample': 0.8845096008690378, 'feature_fraction': 0.7472489146598563, 'min_child_samples': 10, 'min_child_weight': 1.4031528587453193, 'min_split_gain': 7.231470042790604, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7268576504552521                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7964138419697011, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7964138419697011\n",
      " 51%|█████     | 102/200 [04:43<04:34,  2.80s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 650, 'learning_rate': 0.18566923024829468, 'num_leaves': 1080, 'class_weight': 'balanced', 'reg_alpha': 5.6971839498890855, 'reg_lambda': 7.9145157255381795, 'subsample_for_bin': 240000, 'subsample': 0.9848898000969837, 'feature_fraction': 0.7964138419697011, 'min_child_samples': 7, 'min_child_weight': 1.0177411602057944, 'min_split_gain': 6.903512823306842, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7282989118365534                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7601458884562898, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7601458884562898\n",
      " 52%|█████▏    | 103/200 [04:46<04:39,  2.88s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 730, 'learning_rate': 0.18877116324449134, 'num_leaves': 1088, 'class_weight': 'balanced', 'reg_alpha': 4.886110640282332, 'reg_lambda': 8.317260393263478, 'subsample_for_bin': 260000, 'subsample': 0.8754429345534204, 'feature_fraction': 0.7601458884562898, 'min_child_samples': 11, 'min_child_weight': 0.24965075938255474, 'min_split_gain': 7.315361311486521, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7263135687319565                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6994483951727796, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6994483951727796\n",
      " 52%|█████▏    | 104/200 [04:50<05:06,  3.19s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 700, 'learning_rate': 0.21540005860187086, 'num_leaves': 1120, 'class_weight': 'balanced', 'reg_alpha': 5.013359478747755, 'reg_lambda': 8.134030458333456, 'subsample_for_bin': 280000, 'subsample': 0.9444789785429217, 'feature_fraction': 0.6994483951727796, 'min_child_samples': 8, 'min_child_weight': 0.5111941358935351, 'min_split_gain': 7.701909756360685, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7278347768154564                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.73298976956725, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.73298976956725\n",
      " 52%|█████▎    | 105/200 [04:53<04:59,  3.16s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 700, 'learning_rate': 0.20503756636247306, 'num_leaves': 1184, 'class_weight': 'balanced', 'reg_alpha': 5.381846665552622, 'reg_lambda': 8.107638865417492, 'subsample_for_bin': 260000, 'subsample': 0.9375451304413518, 'feature_fraction': 0.73298976956725, 'min_child_samples': 10, 'min_child_weight': 1.4063260937475865, 'min_split_gain': 6.584704432502653, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7291072618254496                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7470902169098622, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7470902169098622\n",
      " 53%|█████▎    | 106/200 [04:56<04:56,  3.15s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 610, 'learning_rate': 0.2418777887963574, 'num_leaves': 1136, 'class_weight': None, 'reg_alpha': 5.150005693121136, 'reg_lambda': 7.822208775893393, 'subsample_for_bin': 260000, 'subsample': 0.914515959479842, 'feature_fraction': 0.7470902169098622, 'min_child_samples': 8, 'min_child_weight': 1.6471914708420377, 'min_split_gain': 6.66637585613043, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7272884743504331                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7098516862474911, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7098516862474911\n",
      " 54%|█████▎    | 107/200 [04:59<04:40,  3.01s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 620, 'learning_rate': 0.12514739389481336, 'num_leaves': 1208, 'class_weight': 'balanced', 'reg_alpha': 5.5044165145838555, 'reg_lambda': 7.850085123616118, 'subsample_for_bin': 260000, 'subsample': 0.9930876940377108, 'feature_fraction': 0.7098516862474911, 'min_child_samples': 9, 'min_child_weight': 1.7461858812598297, 'min_split_gain': 6.56497887241218, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7268176771041528                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7515315779986589, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7515315779986589\n",
      " 54%|█████▍    | 108/200 [05:02<04:41,  3.06s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 18, 'n_estimators': 800, 'learning_rate': 0.23969144082521, 'num_leaves': 1128, 'class_weight': 'balanced', 'reg_alpha': 5.778155947371657, 'reg_lambda': 7.692314003663809, 'subsample_for_bin': 260000, 'subsample': 0.9512460738513768, 'feature_fraction': 0.7515315779986589, 'min_child_samples': 11, 'min_child_weight': 0.946622643520352, 'min_split_gain': 6.504064492517855, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7153320008882966                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7476237191067254, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7476237191067254\n",
      " 55%|█████▍    | 109/200 [05:03<03:51,  2.54s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 610, 'learning_rate': 0.14703668563581632, 'num_leaves': 1136, 'class_weight': 'balanced', 'reg_alpha': 5.325615260328895, 'reg_lambda': 8.46226717954783, 'subsample_for_bin': 260000, 'subsample': 0.9539746932285829, 'feature_fraction': 0.7476237191067254, 'min_child_samples': 7, 'min_child_weight': 1.194622222824237, 'min_split_gain': 6.821761317830866, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7252231845436377                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7314242747051636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7314242747051636\n",
      " 55%|█████▌    | 110/200 [05:06<03:58,  2.65s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 730, 'learning_rate': 0.22629133228668816, 'num_leaves': 1208, 'class_weight': 'balanced', 'reg_alpha': 5.428188282182128, 'reg_lambda': 8.386696222949798, 'subsample_for_bin': 280000, 'subsample': 0.9271780961447935, 'feature_fraction': 0.7314242747051636, 'min_child_samples': 6, 'min_child_weight': 0.26093987724248346, 'min_split_gain': 7.147666050697342, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7263268931823228                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7005325990641571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7005325990641571\n",
      " 56%|█████▌    | 111/200 [05:09<04:06,  2.77s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 540, 'learning_rate': 0.12851469807824467, 'num_leaves': 1144, 'class_weight': 'balanced', 'reg_alpha': 5.743394715743789, 'reg_lambda': 8.580520989276616, 'subsample_for_bin': 260000, 'subsample': 0.975437114829621, 'feature_fraction': 0.7005325990641571, 'min_child_samples': 8, 'min_child_weight': 0.5039014146532994, 'min_split_gain': 7.216576218832074, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7262158560959361                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7082609343802193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7082609343802193\n",
      " 56%|█████▌    | 112/200 [05:12<03:58,  2.72s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 610, 'learning_rate': 0.2149298403149971, 'num_leaves': 1144, 'class_weight': 'balanced', 'reg_alpha': 5.379964579417736, 'reg_lambda': 8.09122243631365, 'subsample_for_bin': 280000, 'subsample': 0.9360225118642325, 'feature_fraction': 0.7082609343802193, 'min_child_samples': 10, 'min_child_weight': 1.468384304750846, 'min_split_gain': 6.209653680741756, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7255029980013324                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7493609601746793, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7493609601746793\n",
      " 56%|█████▋    | 113/200 [05:14<03:57,  2.73s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 780, 'learning_rate': 0.21734908405258319, 'num_leaves': 1160, 'class_weight': 'balanced', 'reg_alpha': 5.672132979195852, 'reg_lambda': 8.038113551013558, 'subsample_for_bin': 240000, 'subsample': 0.942953119622966, 'feature_fraction': 0.7493609601746793, 'min_child_samples': 10, 'min_child_weight': 1.6516334488105138, 'min_split_gain': 6.222357689214143, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.727532755940484                                                                   \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7002383129604929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7002383129604929\n",
      " 57%|█████▋    | 114/200 [05:18<04:12,  2.93s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 580, 'learning_rate': 0.1717433188810102, 'num_leaves': 1192, 'class_weight': 'balanced', 'reg_alpha': 5.193445500372982, 'reg_lambda': 8.008843256828861, 'subsample_for_bin': 260000, 'subsample': 0.9957010436915174, 'feature_fraction': 0.7002383129604929, 'min_child_samples': 6, 'min_child_weight': 0.9154362485936274, 'min_split_gain': 7.1099267417684215, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7267599378192315                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.72494248107116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.72494248107116\n",
      " 57%|█████▊    | 115/200 [05:20<04:01,  2.85s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 690, 'learning_rate': 0.13975114880428255, 'num_leaves': 1160, 'class_weight': 'balanced', 'reg_alpha': 5.78242740322676, 'reg_lambda': 8.582849757742542, 'subsample_for_bin': 260000, 'subsample': 0.9667245738569017, 'feature_fraction': 0.72494248107116, 'min_child_samples': 13, 'min_child_weight': 1.9252281097559498, 'min_split_gain': 7.222990625561478, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7250743948478792                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7523680861084346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7523680861084346\n",
      " 58%|█████▊    | 116/200 [05:23<04:04,  2.91s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 550, 'learning_rate': 0.23239222123104192, 'num_leaves': 1240, 'class_weight': 'balanced', 'reg_alpha': 4.968659529735962, 'reg_lambda': 7.816009538683986, 'subsample_for_bin': 280000, 'subsample': 0.9247577349678531, 'feature_fraction': 0.7523680861084346, 'min_child_samples': 10, 'min_child_weight': 0.8235766609734219, 'min_split_gain': 7.19919844035282, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7267532755940485                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7071832138334349, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7071832138334349\n",
      " 58%|█████▊    | 117/200 [05:26<03:55,  2.84s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 580, 'learning_rate': 0.17532488100993343, 'num_leaves': 1152, 'class_weight': 'balanced', 'reg_alpha': 5.313623387152472, 'reg_lambda': 8.541916226802245, 'subsample_for_bin': 240000, 'subsample': 0.9582325307002821, 'feature_fraction': 0.7071832138334349, 'min_child_samples': 9, 'min_child_weight': 0.8630049295495698, 'min_split_gain': 6.8039153124512355, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7265933821896513                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.712252316455718, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.712252316455718\n",
      " 59%|█████▉    | 118/200 [05:29<03:47,  2.78s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 550, 'learning_rate': 0.2614800270123456, 'num_leaves': 1232, 'class_weight': None, 'reg_alpha': 5.482553390103346, 'reg_lambda': 8.056969465596627, 'subsample_for_bin': 260000, 'subsample': 0.9278588248333579, 'feature_fraction': 0.712252316455718, 'min_child_samples': 10, 'min_child_weight': 0.3803815358904362, 'min_split_gain': 6.927549492269176, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7286386853208973                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.729214889341992, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.729214889341992\n",
      " 60%|█████▉    | 119/200 [05:31<03:40,  2.72s/trial, best loss: -0.7291627803686431]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 530, 'learning_rate': 0.2806287609863823, 'num_leaves': 1208, 'class_weight': None, 'reg_alpha': 5.733664814989965, 'reg_lambda': 8.394873100240178, 'subsample_for_bin': 260000, 'subsample': 0.9235403528062406, 'feature_fraction': 0.729214889341992, 'min_child_samples': 9, 'min_child_weight': 0.3758790274882594, 'min_split_gain': 6.808575359229156, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7306906506773262                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7061550141793932, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7061550141793932\n",
      " 60%|██████    | 120/200 [05:34<03:30,  2.63s/trial, best loss: -0.7306906506773262]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 480, 'learning_rate': 0.30761613879679695, 'num_leaves': 1264, 'class_weight': None, 'reg_alpha': 5.570680495890937, 'reg_lambda': 8.044025573675569, 'subsample_for_bin': 260000, 'subsample': 0.930359633977678, 'feature_fraction': 0.7061550141793932, 'min_child_samples': 6, 'min_child_weight': 0.2456434282895154, 'min_split_gain': 6.765730148330983, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7307483899622476                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7045962853444785, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7045962853444785\n",
      " 60%|██████    | 121/200 [05:36<03:21,  2.55s/trial, best loss: -0.7307483899622476]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 520, 'learning_rate': 0.2816153543997593, 'num_leaves': 1280, 'class_weight': 'balanced', 'reg_alpha': 5.395408952871442, 'reg_lambda': 8.295712020406123, 'subsample_for_bin': 260000, 'subsample': 0.9288673521502507, 'feature_fraction': 0.7045962853444785, 'min_child_samples': 9, 'min_child_weight': 0.377930187458697, 'min_split_gain': 7.015845339678867, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7277259604707972                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6877628181914704, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6877628181914704\n",
      " 61%|██████    | 122/200 [05:39<03:17,  2.53s/trial, best loss: -0.7307483899622476]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 550, 'learning_rate': 0.3309561851060577, 'num_leaves': 1352, 'class_weight': None, 'reg_alpha': 5.292542377939566, 'reg_lambda': 7.808293812307037, 'subsample_for_bin': 260000, 'subsample': 0.94571715038813, 'feature_fraction': 0.6877628181914704, 'min_child_samples': 5, 'min_child_weight': 0.3531898312622484, 'min_split_gain': 6.710146979177786, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.729948922940262                                                                   \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7124865504560968, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7124865504560968\n",
      " 62%|██████▏   | 123/200 [05:41<03:14,  2.52s/trial, best loss: -0.7307483899622476]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 460, 'learning_rate': 0.2958678653064355, 'num_leaves': 1312, 'class_weight': 'balanced', 'reg_alpha': 5.890963111671017, 'reg_lambda': 8.396833299086989, 'subsample_for_bin': 260000, 'subsample': 0.9086595938667384, 'feature_fraction': 0.7124865504560968, 'min_child_samples': 5, 'min_child_weight': 0.3674544377070362, 'min_split_gain': 6.591928525608222, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7272351765489673                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7467307869230255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7467307869230255\n",
      " 62%|██████▏   | 124/200 [05:43<03:08,  2.48s/trial, best loss: -0.7307483899622476]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 460, 'learning_rate': 0.30239444952690175, 'num_leaves': 1256, 'class_weight': None, 'reg_alpha': 5.548096215685814, 'reg_lambda': 8.233720740078523, 'subsample_for_bin': 260000, 'subsample': 0.942543868004781, 'feature_fraction': 0.7467307869230255, 'min_child_samples': 11, 'min_child_weight': 0.34210051743123937, 'min_split_gain': 6.74456790433518, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7309837885853876                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7619879601279839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7619879601279839\n",
      " 62%|██████▎   | 125/200 [05:46<03:00,  2.40s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 480, 'learning_rate': 0.3371732242646723, 'num_leaves': 1184, 'class_weight': None, 'reg_alpha': 5.55981216793428, 'reg_lambda': 8.234183402009261, 'subsample_for_bin': 260000, 'subsample': 0.965270954001852, 'feature_fraction': 0.7619879601279839, 'min_child_samples': 11, 'min_child_weight': 0.1740063176725822, 'min_split_gain': 6.838240136680522, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7271663335554075                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634306613815433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634306613815433\n",
      " 63%|██████▎   | 126/200 [05:48<02:54,  2.36s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 420, 'learning_rate': 0.270748657719948, 'num_leaves': 1224, 'class_weight': None, 'reg_alpha': 5.892737067449316, 'reg_lambda': 8.267921537594958, 'subsample_for_bin': 260000, 'subsample': 0.9624375291664181, 'feature_fraction': 0.7634306613815433, 'min_child_samples': 9, 'min_child_weight': 0.6183812588508648, 'min_split_gain': 6.565200864124379, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7289829002886965                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7159987542951753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7159987542951753\n",
      " 64%|██████▎   | 127/200 [05:50<02:46,  2.29s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 400, 'learning_rate': 0.3011127646284073, 'num_leaves': 1224, 'class_weight': None, 'reg_alpha': 5.608345853371248, 'reg_lambda': 7.915857767697955, 'subsample_for_bin': 260000, 'subsample': 0.9054749841082609, 'feature_fraction': 0.7159987542951753, 'min_child_samples': 4, 'min_child_weight': 0.2150736528473802, 'min_split_gain': 6.645021548235159, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.729189429269376                                                                   \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7282963087107281, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7282963087107281\n",
      " 64%|██████▍   | 128/200 [05:52<02:39,  2.21s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 550, 'learning_rate': 0.318986131981295, 'num_leaves': 1248, 'class_weight': None, 'reg_alpha': 5.6346426673041945, 'reg_lambda': 7.880124939200998, 'subsample_for_bin': 280000, 'subsample': 0.9477696137923977, 'feature_fraction': 0.7282963087107281, 'min_child_samples': 6, 'min_child_weight': 0.17917111040318626, 'min_split_gain': 6.560248198917617, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7267221852098602                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6913713934169904, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6913713934169904\n",
      " 64%|██████▍   | 129/200 [05:55<02:43,  2.31s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 590, 'learning_rate': 0.302392977292168, 'num_leaves': 1400, 'class_weight': None, 'reg_alpha': 5.130551496973587, 'reg_lambda': 7.791555771889124, 'subsample_for_bin': 260000, 'subsample': 0.9666586684973917, 'feature_fraction': 0.6913713934169904, 'min_child_samples': 4, 'min_child_weight': 0.2836225028160129, 'min_split_gain': 6.384078037457992, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7286808794137242                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.751485166185605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.751485166185605\n",
      " 65%|██████▌   | 130/200 [05:57<02:50,  2.43s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 610, 'learning_rate': 0.3116141264124126, 'num_leaves': 1184, 'class_weight': None, 'reg_alpha': 5.488802314059995, 'reg_lambda': 8.354516105064482, 'subsample_for_bin': 280000, 'subsample': 0.8940938577071018, 'feature_fraction': 0.751485166185605, 'min_child_samples': 7, 'min_child_weight': 0.5693389981333026, 'min_split_gain': 6.771641341216713, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7279280479680212                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7224016440192512, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7224016440192512\n",
      " 66%|██████▌   | 131/200 [06:00<02:52,  2.50s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 18, 'n_estimators': 460, 'learning_rate': 0.2919458451900164, 'num_leaves': 1176, 'class_weight': None, 'reg_alpha': 5.540915711664162, 'reg_lambda': 8.455745290783259, 'subsample_for_bin': 260000, 'subsample': 0.9123726045866671, 'feature_fraction': 0.7224016440192512, 'min_child_samples': 10, 'min_child_weight': 0.37090077809495775, 'min_split_gain': 6.935329058764932, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7178481012658229                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7455264038321717, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7455264038321717\n",
      " 66%|██████▌   | 132/200 [06:01<02:26,  2.15s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 480, 'learning_rate': 0.30950986738885533, 'num_leaves': 1280, 'class_weight': None, 'reg_alpha': 5.849480968146571, 'reg_lambda': 8.271017592875152, 'subsample_for_bin': 240000, 'subsample': 0.9284412097659261, 'feature_fraction': 0.7455264038321717, 'min_child_samples': 13, 'min_child_weight': 0.2478516381084418, 'min_split_gain': 6.407956048865668, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.729948922940262                                                                   \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7358427416733789, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7358427416733789\n",
      " 66%|██████▋   | 133/200 [06:04<02:28,  2.22s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 470, 'learning_rate': 0.26915202134627736, 'num_leaves': 1136, 'class_weight': None, 'reg_alpha': 5.825794879312088, 'reg_lambda': 8.217489516829907, 'subsample_for_bin': 260000, 'subsample': 0.9285360083494589, 'feature_fraction': 0.7358427416733789, 'min_child_samples': 8, 'min_child_weight': 0.6355716454016358, 'min_split_gain': 7.087409545215958, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7273861869864535                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6836659226579825, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6836659226579825\n",
      " 67%|██████▋   | 134/200 [06:06<02:26,  2.21s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 430, 'learning_rate': 0.28752592306464503, 'num_leaves': 1280, 'class_weight': None, 'reg_alpha': 5.640158819942709, 'reg_lambda': 8.015347324036012, 'subsample_for_bin': 260000, 'subsample': 0.9420962226256592, 'feature_fraction': 0.6836659226579825, 'min_child_samples': 8, 'min_child_weight': 0.3212021071558496, 'min_split_gain': 6.813575799835806, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7262824783477682                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7198999536032633, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7198999536032633\n",
      " 68%|██████▊   | 135/200 [06:08<02:23,  2.21s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 400, 'learning_rate': 0.33340386203422556, 'num_leaves': 1208, 'class_weight': None, 'reg_alpha': 5.662616536088086, 'reg_lambda': 7.96342877540954, 'subsample_for_bin': 260000, 'subsample': 0.9440101845728937, 'feature_fraction': 0.7198999536032633, 'min_child_samples': 8, 'min_child_weight': 0.19043713860809533, 'min_split_gain': 6.686426993813669, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7288718632023097                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7390379473335282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7390379473335282\n",
      " 68%|██████▊   | 136/200 [06:10<02:17,  2.15s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 470, 'learning_rate': 0.2904521859520226, 'num_leaves': 1312, 'class_weight': None, 'reg_alpha': 5.217510916137062, 'reg_lambda': 8.299672567128457, 'subsample_for_bin': 260000, 'subsample': 0.9352501904346272, 'feature_fraction': 0.7390379473335282, 'min_child_samples': 8, 'min_child_weight': 0.33358351620742177, 'min_split_gain': 6.97883735793563, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7274616922051965                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6902320244858138, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6902320244858138\n",
      " 68%|██████▊   | 137/200 [06:12<02:18,  2.20s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 510, 'learning_rate': 0.2769821125323254, 'num_leaves': 1336, 'class_weight': None, 'reg_alpha': 5.636765000766916, 'reg_lambda': 7.983602443580175, 'subsample_for_bin': 260000, 'subsample': 0.9077314632082576, 'feature_fraction': 0.6902320244858138, 'min_child_samples': 7, 'min_child_weight': 0.27214040152784014, 'min_split_gain': 7.037931928912612, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7281234732400621                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6827641830578483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6827641830578483\n",
      " 69%|██████▉   | 138/200 [06:15<02:21,  2.28s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 490, 'learning_rate': 0.31490669411175926, 'num_leaves': 1216, 'class_weight': None, 'reg_alpha': 5.420280690192547, 'reg_lambda': 8.000879823271857, 'subsample_for_bin': 260000, 'subsample': 0.931233720251398, 'feature_fraction': 0.6827641830578483, 'min_child_samples': 5, 'min_child_weight': 0.4423037863167524, 'min_split_gain': 6.560066487516286, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7285587386186987                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7046550169997661, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7046550169997661\n",
      " 70%|██████▉   | 139/200 [06:17<02:18,  2.28s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 540, 'learning_rate': 0.3316912067977853, 'num_leaves': 1312, 'class_weight': None, 'reg_alpha': 5.379690029982957, 'reg_lambda': 7.743979207135025, 'subsample_for_bin': 260000, 'subsample': 0.9053293779093441, 'feature_fraction': 0.7046550169997661, 'min_child_samples': 8, 'min_child_weight': 0.2554015159612835, 'min_split_gain': 7.022229838264858, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7287852542749278                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6920028936259455, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6920028936259455\n",
      " 70%|███████   | 140/200 [06:20<02:19,  2.33s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 490, 'learning_rate': 0.3305503430257344, 'num_leaves': 1232, 'class_weight': None, 'reg_alpha': 5.47408250388033, 'reg_lambda': 7.735179171940747, 'subsample_for_bin': 260000, 'subsample': 0.9590655443982885, 'feature_fraction': 0.6920028936259455, 'min_child_samples': 6, 'min_child_weight': 0.27914447077310917, 'min_split_gain': 6.794626565817043, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7283877415056629                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7516997190353327, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7516997190353327\n",
      " 70%|███████   | 141/200 [06:22<02:17,  2.33s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 430, 'learning_rate': 0.27714099925804586, 'num_leaves': 1208, 'class_weight': None, 'reg_alpha': 5.698647635770746, 'reg_lambda': 8.111373110480177, 'subsample_for_bin': 240000, 'subsample': 0.9373531245902214, 'feature_fraction': 0.7516997190353327, 'min_child_samples': 18, 'min_child_weight': 0.373261524899217, 'min_split_gain': 6.407180790681345, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7299733510992671                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7745912256833087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7745912256833087\n",
      " 71%|███████   | 142/200 [06:24<02:11,  2.27s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 520, 'learning_rate': 0.31819490395151995, 'num_leaves': 1184, 'class_weight': None, 'reg_alpha': 5.8554148270298825, 'reg_lambda': 8.270442501891235, 'subsample_for_bin': 260000, 'subsample': 0.9135611569636013, 'feature_fraction': 0.7745912256833087, 'min_child_samples': 15, 'min_child_weight': 0.33404533687477556, 'min_split_gain': 6.764254809294778, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7292582722629358                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7419615535046784, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7419615535046784\n",
      " 72%|███████▏  | 143/200 [06:27<02:12,  2.32s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 470, 'learning_rate': 0.3281537822330173, 'num_leaves': 1280, 'class_weight': None, 'reg_alpha': 5.223898202552853, 'reg_lambda': 8.14589890692101, 'subsample_for_bin': 260000, 'subsample': 0.9482972677321766, 'feature_fraction': 0.7419615535046784, 'min_child_samples': 11, 'min_child_weight': 0.27471720420048606, 'min_split_gain': 6.994837526866906, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7293715300910504                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7768394832212651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7768394832212651\n",
      " 72%|███████▏  | 144/200 [06:29<02:08,  2.29s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 450, 'learning_rate': 0.28540134816816004, 'num_leaves': 1160, 'class_weight': None, 'reg_alpha': 5.965486116006875, 'reg_lambda': 7.883055716521824, 'subsample_for_bin': 240000, 'subsample': 0.9165135066554823, 'feature_fraction': 0.7768394832212651, 'min_child_samples': 14, 'min_child_weight': 0.5243697556232434, 'min_split_gain': 6.133789626612016, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7304286031534533                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.746988409221068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.746988409221068\n",
      " 72%|███████▎  | 145/200 [06:31<02:04,  2.27s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 570, 'learning_rate': 0.2884528045044349, 'num_leaves': 1160, 'class_weight': None, 'reg_alpha': 5.413553887033176, 'reg_lambda': 8.214235962203475, 'subsample_for_bin': 260000, 'subsample': 0.911768792948581, 'feature_fraction': 0.746988409221068, 'min_child_samples': 9, 'min_child_weight': 0.7229446137088599, 'min_split_gain': 6.526251281181407, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7288962913613146                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7602100465316632, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7602100465316632\n",
      " 73%|███████▎  | 146/200 [06:34<02:07,  2.36s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 18, 'n_estimators': 460, 'learning_rate': 0.3103058084445184, 'num_leaves': 1184, 'class_weight': None, 'reg_alpha': 5.470244795791924, 'reg_lambda': 8.497314504412149, 'subsample_for_bin': 260000, 'subsample': 0.9294435730859559, 'feature_fraction': 0.7602100465316632, 'min_child_samples': 9, 'min_child_weight': 0.3406837713560024, 'min_split_gain': 6.619731099216623, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.728403286697757                                                                   \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7310720427474809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7310720427474809\n",
      " 74%|███████▎  | 147/200 [06:36<02:03,  2.32s/trial, best loss: -0.7309837885853876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 460, 'learning_rate': 0.31657736971981665, 'num_leaves': 1296, 'class_weight': None, 'reg_alpha': 5.605696640640842, 'reg_lambda': 8.43743379482778, 'subsample_for_bin': 260000, 'subsample': 0.9296224945806827, 'feature_fraction': 0.7310720427474809, 'min_child_samples': 11, 'min_child_weight': 0.2871823116999466, 'min_split_gain': 6.6844900342836615, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.731012658227848                                                                   \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7537594493397958, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7537594493397958\n",
      " 74%|███████▍  | 148/200 [06:38<02:00,  2.31s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 19, 'n_estimators': 390, 'learning_rate': 0.29354726906946, 'num_leaves': 1312, 'class_weight': None, 'reg_alpha': 5.377238746057482, 'reg_lambda': 8.251093038422184, 'subsample_for_bin': 260000, 'subsample': 0.9158234391867476, 'feature_fraction': 0.7537594493397958, 'min_child_samples': 10, 'min_child_weight': 0.25291954994713733, 'min_split_gain': 7.034400104921492, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.716848767488341                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7654837170329897, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7654837170329897\n",
      " 74%|███████▍  | 149/200 [06:39<01:41,  1.99s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 510, 'learning_rate': 0.2825918215490704, 'num_leaves': 1232, 'class_weight': None, 'reg_alpha': 5.463331518618112, 'reg_lambda': 8.535500312476513, 'subsample_for_bin': 260000, 'subsample': 0.9659152054012902, 'feature_fraction': 0.7654837170329897, 'min_child_samples': 14, 'min_child_weight': 0.46130546674565304, 'min_split_gain': 6.592765914191207, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7301709971130357                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7424785610516004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7424785610516004\n",
      " 75%|███████▌  | 150/200 [06:42<01:45,  2.11s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 450, 'learning_rate': 0.3064192775822312, 'num_leaves': 1232, 'class_weight': None, 'reg_alpha': 5.607657508853793, 'reg_lambda': 8.283026003733344, 'subsample_for_bin': 260000, 'subsample': 0.9286191276718597, 'feature_fraction': 0.7424785610516004, 'min_child_samples': 14, 'min_child_weight': 0.18979619440687806, 'min_split_gain': 6.771594597775147, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7283366644459248                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7195161412187248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7195161412187248\n",
      " 76%|███████▌  | 151/200 [06:44<01:45,  2.15s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 460, 'learning_rate': 0.3149930579911388, 'num_leaves': 1248, 'class_weight': None, 'reg_alpha': 5.5887367897572675, 'reg_lambda': 8.480733783121321, 'subsample_for_bin': 260000, 'subsample': 0.9214170213860778, 'feature_fraction': 0.7195161412187248, 'min_child_samples': 11, 'min_child_weight': 0.39990020872639115, 'min_split_gain': 6.972329600781392, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7288629802353985                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7585268736134063, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7585268736134063\n",
      " 76%|███████▌  | 152/200 [06:46<01:44,  2.17s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 520, 'learning_rate': 0.2885725719357477, 'num_leaves': 1296, 'class_weight': None, 'reg_alpha': 5.665916462839775, 'reg_lambda': 8.47045485655239, 'subsample_for_bin': 260000, 'subsample': 0.9438959037062638, 'feature_fraction': 0.7585268736134063, 'min_child_samples': 14, 'min_child_weight': 0.30437360845125727, 'min_split_gain': 6.7383018417145895, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7284077281812126                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7455377136214022, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7455377136214022\n",
      " 76%|███████▋  | 153/200 [06:49<01:45,  2.25s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 450, 'learning_rate': 0.27488366027093797, 'num_leaves': 1304, 'class_weight': None, 'reg_alpha': 5.318127260854789, 'reg_lambda': 8.34578490086067, 'subsample_for_bin': 260000, 'subsample': 0.9529668088934528, 'feature_fraction': 0.7455377136214022, 'min_child_samples': 10, 'min_child_weight': 0.5181564134981702, 'min_split_gain': 6.997643995422038, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7277015323117921                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7262696422258744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7262696422258744\n",
      " 77%|███████▋  | 154/200 [06:51<01:43,  2.25s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 410, 'learning_rate': 0.29360428373577657, 'num_leaves': 1368, 'class_weight': None, 'reg_alpha': 5.9055749638871315, 'reg_lambda': 8.557309218770147, 'subsample_for_bin': 260000, 'subsample': 0.9460685601245152, 'feature_fraction': 0.7262696422258744, 'min_child_samples': 9, 'min_child_weight': 0.4339304442549567, 'min_split_gain': 6.824420463605901, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7294181656673329                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7188892960811475, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7188892960811475\n",
      " 78%|███████▊  | 155/200 [06:53<01:38,  2.20s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 590, 'learning_rate': 0.2848434159687928, 'num_leaves': 1248, 'class_weight': None, 'reg_alpha': 5.923301401011422, 'reg_lambda': 8.16713149613617, 'subsample_for_bin': 260000, 'subsample': 0.9330213732829946, 'feature_fraction': 0.7188892960811475, 'min_child_samples': 8, 'min_child_weight': 0.4464055719708398, 'min_split_gain': 6.777443138389238, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.730379746835443                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7328322943800861, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7328322943800861\n",
      " 78%|███████▊  | 156/200 [06:56<01:42,  2.33s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 530, 'learning_rate': 0.33067546547864896, 'num_leaves': 1296, 'class_weight': None, 'reg_alpha': 5.82973033148652, 'reg_lambda': 8.250248473122696, 'subsample_for_bin': 260000, 'subsample': 0.9266294340500264, 'feature_fraction': 0.7328322943800861, 'min_child_samples': 8, 'min_child_weight': 0.23175313497739744, 'min_split_gain': 6.957939180479702, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7267443926271375                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6883368303969619, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6883368303969619\n",
      " 78%|███████▊  | 157/200 [06:58<01:41,  2.36s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 430, 'learning_rate': 0.32391331700761355, 'num_leaves': 1232, 'class_weight': None, 'reg_alpha': 5.719719381331973, 'reg_lambda': 7.825239516352988, 'subsample_for_bin': 260000, 'subsample': 0.9199324989989622, 'feature_fraction': 0.6883368303969619, 'min_child_samples': 7, 'min_child_weight': 0.14377498754869936, 'min_split_gain': 6.615264070332005, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.728632023095714                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7341093667639139, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7341093667639139\n",
      " 79%|███████▉  | 158/200 [07:00<01:35,  2.28s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 420, 'learning_rate': 0.31115178094409135, 'num_leaves': 1352, 'class_weight': None, 'reg_alpha': 5.821599859120548, 'reg_lambda': 8.505765609640125, 'subsample_for_bin': 260000, 'subsample': 0.9475231898049836, 'feature_fraction': 0.7341093667639139, 'min_child_samples': 9, 'min_child_weight': 0.19453349522031585, 'min_split_gain': 6.558885730691692, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7280257606040417                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7939710154029072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7939710154029072\n",
      " 80%|███████▉  | 159/200 [07:02<01:32,  2.26s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 420, 'learning_rate': 0.3040032145110867, 'num_leaves': 1224, 'class_weight': None, 'reg_alpha': 6.021760541676935, 'reg_lambda': 7.6490055149674205, 'subsample_for_bin': 240000, 'subsample': 0.8933647926304835, 'feature_fraction': 0.7939710154029072, 'min_child_samples': 15, 'min_child_weight': 0.2914448709216873, 'min_split_gain': 6.209230463639228, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7288540972684877                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7379105314042863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7379105314042863\n",
      " 80%|████████  | 160/200 [07:04<01:28,  2.21s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 390, 'learning_rate': 0.3295130640978866, 'num_leaves': 1360, 'class_weight': None, 'reg_alpha': 5.536931769031195, 'reg_lambda': 8.603193223954055, 'subsample_for_bin': 260000, 'subsample': 0.9176925099833986, 'feature_fraction': 0.7379105314042863, 'min_child_samples': 9, 'min_child_weight': 0.191180233398076, 'min_split_gain': 6.789641708215512, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7279569176104819                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7543012170926108, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7543012170926108\n",
      " 80%|████████  | 161/200 [07:07<01:24,  2.18s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 520, 'learning_rate': 0.30316279878316915, 'num_leaves': 1184, 'class_weight': None, 'reg_alpha': 5.833741429311565, 'reg_lambda': 8.474484791036762, 'subsample_for_bin': 260000, 'subsample': 0.9434345023832658, 'feature_fraction': 0.7543012170926108, 'min_child_samples': 10, 'min_child_weight': 0.348529932144083, 'min_split_gain': 6.795367742731206, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7291849877859204                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7606239979727077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7606239979727077\n",
      " 81%|████████  | 162/200 [07:09<01:25,  2.24s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 470, 'learning_rate': 0.3042810815384294, 'num_leaves': 1304, 'class_weight': None, 'reg_alpha': 5.391871061238625, 'reg_lambda': 8.063022480392652, 'subsample_for_bin': 260000, 'subsample': 0.9612819292917785, 'feature_fraction': 0.7606239979727077, 'min_child_samples': 9, 'min_child_weight': 0.4642903046790317, 'min_split_gain': 6.663226141447018, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7288874083944037                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7430311768383125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7430311768383125\n",
      " 82%|████████▏ | 163/200 [07:11<01:24,  2.27s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 400, 'learning_rate': 0.32039648264022347, 'num_leaves': 1344, 'class_weight': None, 'reg_alpha': 5.599859930844228, 'reg_lambda': 8.56327757509897, 'subsample_for_bin': 260000, 'subsample': 0.908715429277648, 'feature_fraction': 0.7430311768383125, 'min_child_samples': 13, 'min_child_weight': 0.4002259696463867, 'min_split_gain': 6.4201407440118325, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7300954918942927                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7289225638543666, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7289225638543666\n",
      " 82%|████████▏ | 164/200 [07:13<01:20,  2.25s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 520, 'learning_rate': 0.30788801568916574, 'num_leaves': 1272, 'class_weight': None, 'reg_alpha': 5.5720339778749315, 'reg_lambda': 8.276766588859923, 'subsample_for_bin': 260000, 'subsample': 0.9180108754984849, 'feature_fraction': 0.7289225638543666, 'min_child_samples': 6, 'min_child_weight': 0.44430941116348527, 'min_split_gain': 6.839948652952754, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.728614257161892                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7069276148012091, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7069276148012091\n",
      " 82%|████████▎ | 165/200 [07:16<01:20,  2.30s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 400, 'learning_rate': 0.32963154079933144, 'num_leaves': 1336, 'class_weight': None, 'reg_alpha': 5.552843835386691, 'reg_lambda': 8.644730610146608, 'subsample_for_bin': 260000, 'subsample': 0.9292674717045141, 'feature_fraction': 0.7069276148012091, 'min_child_samples': 11, 'min_child_weight': 0.469952390257918, 'min_split_gain': 6.605831335231709, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7305351987563845                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.697343206866669, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.697343206866669\n",
      " 83%|████████▎ | 166/200 [07:18<01:16,  2.26s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 500, 'learning_rate': 0.2809166006009169, 'num_leaves': 1248, 'class_weight': None, 'reg_alpha': 5.464485666145354, 'reg_lambda': 8.173117300162433, 'subsample_for_bin': 260000, 'subsample': 0.927070714385722, 'feature_fraction': 0.697343206866669, 'min_child_samples': 5, 'min_child_weight': 0.344901817554179, 'min_split_gain': 7.027192637002446, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.727195203197868                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7523990786000218, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7523990786000218\n",
      " 84%|████████▎ | 167/200 [07:20<01:15,  2.28s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 20, 'n_estimators': 520, 'learning_rate': 0.2797885255863282, 'num_leaves': 1312, 'class_weight': None, 'reg_alpha': 5.681890054776629, 'reg_lambda': 8.448616194135067, 'subsample_for_bin': 260000, 'subsample': 0.9282642172200211, 'feature_fraction': 0.7523990786000218, 'min_child_samples': 9, 'min_child_weight': 0.6149010382296045, 'min_split_gain': 6.768170605462192, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7181745502998                                                                    \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7306102976603988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7306102976603988\n",
      " 84%|████████▍ | 168/200 [07:22<01:03,  1.97s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 450, 'learning_rate': 0.31325540188021284, 'num_leaves': 1256, 'class_weight': None, 'reg_alpha': 5.570283570965616, 'reg_lambda': 8.446787294419156, 'subsample_for_bin': 260000, 'subsample': 0.9413888584813391, 'feature_fraction': 0.7306102976603988, 'min_child_samples': 12, 'min_child_weight': 0.2645626435625974, 'min_split_gain': 6.6600992545396736, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7279702420608483                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7291147879753024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7291147879753024\n",
      " 84%|████████▍ | 169/200 [07:24<01:03,  2.04s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 480, 'learning_rate': 0.29065365102741925, 'num_leaves': 1216, 'class_weight': None, 'reg_alpha': 5.7040145764727646, 'reg_lambda': 8.065121242164514, 'subsample_for_bin': 260000, 'subsample': 0.9154478814615966, 'feature_fraction': 0.7291147879753024, 'min_child_samples': 7, 'min_child_weight': 0.25097421188911817, 'min_split_gain': 6.588789477696177, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7308372196313568                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.691190389146993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.691190389146993\n",
      " 85%|████████▌ | 170/200 [07:26<01:02,  2.10s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 440, 'learning_rate': 0.32614143435269005, 'num_leaves': 1216, 'class_weight': None, 'reg_alpha': 5.388905368208608, 'reg_lambda': 8.189832526173499, 'subsample_for_bin': 260000, 'subsample': 0.9295238150228015, 'feature_fraction': 0.691190389146993, 'min_child_samples': 5, 'min_child_weight': 0.36966470134080703, 'min_split_gain': 6.7062192807925864, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7284343770819454                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7164068671429631, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7164068671429631\n",
      " 86%|████████▌ | 171/200 [07:28<01:00,  2.09s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 480, 'learning_rate': 0.29640823372376707, 'num_leaves': 1264, 'class_weight': None, 'reg_alpha': 5.703968834917799, 'reg_lambda': 7.964920030408524, 'subsample_for_bin': 260000, 'subsample': 0.9420412072807187, 'feature_fraction': 0.7164068671429631, 'min_child_samples': 5, 'min_child_weight': 0.2542388836657173, 'min_split_gain': 6.527314479053451, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.728809682433933                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7272593688423342, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272593688423342\n",
      " 86%|████████▌ | 172/200 [07:30<00:59,  2.14s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 450, 'learning_rate': 0.295460369420547, 'num_leaves': 1328, 'class_weight': None, 'reg_alpha': 5.671799842287619, 'reg_lambda': 8.340598258799634, 'subsample_for_bin': 260000, 'subsample': 0.9049443922433892, 'feature_fraction': 0.7272593688423342, 'min_child_samples': 9, 'min_child_weight': 0.37036470515373, 'min_split_gain': 6.6534307293411095, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7284565844992228                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7399223364934443, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7399223364934443\n",
      " 86%|████████▋ | 173/200 [07:33<00:58,  2.18s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 520, 'learning_rate': 0.32233778749727704, 'num_leaves': 1288, 'class_weight': None, 'reg_alpha': 5.3422213980368465, 'reg_lambda': 8.432807022420592, 'subsample_for_bin': 260000, 'subsample': 0.9089142755777717, 'feature_fraction': 0.7399223364934443, 'min_child_samples': 14, 'min_child_weight': 0.453066922330704, 'min_split_gain': 6.892611782403242, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7301598934043971                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7573160056226412, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7573160056226412\n",
      " 87%|████████▋ | 174/200 [07:35<00:58,  2.25s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 450, 'learning_rate': 0.3084984545661851, 'num_leaves': 1264, 'class_weight': None, 'reg_alpha': 5.724441358579538, 'reg_lambda': 8.443955430665293, 'subsample_for_bin': 260000, 'subsample': 0.9486198915421968, 'feature_fraction': 0.7573160056226412, 'min_child_samples': 13, 'min_child_weight': 0.4269303554031004, 'min_split_gain': 6.613533195530398, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7298711969797913                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7631799163329133, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7631799163329133\n",
      " 88%|████████▊ | 175/200 [07:37<00:56,  2.25s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 470, 'learning_rate': 0.31516301926302115, 'num_leaves': 1312, 'class_weight': None, 'reg_alpha': 5.6800854645419285, 'reg_lambda': 8.275740803309056, 'subsample_for_bin': 260000, 'subsample': 0.9464874507783736, 'feature_fraction': 0.7631799163329133, 'min_child_samples': 12, 'min_child_weight': 0.28478064933442904, 'min_split_gain': 6.898515082766844, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7284477015323119                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7150349841776396, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7150349841776396\n",
      " 88%|████████▊ | 176/200 [07:40<00:54,  2.27s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 21, 'n_estimators': 440, 'learning_rate': 0.3272142138140215, 'num_leaves': 1352, 'class_weight': None, 'reg_alpha': 5.668948505441305, 'reg_lambda': 8.28602103359767, 'subsample_for_bin': 260000, 'subsample': 0.9361677291803961, 'feature_fraction': 0.7150349841776396, 'min_child_samples': 12, 'min_child_weight': 0.3585562242782495, 'min_split_gain': 6.56248158529905, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7294003997335109                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7684312715091868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7684312715091868\n",
      " 88%|████████▊ | 177/200 [07:42<00:51,  2.24s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 420, 'learning_rate': 0.317143057549001, 'num_leaves': 1296, 'class_weight': None, 'reg_alpha': 5.447998526642975, 'reg_lambda': 8.30674295163442, 'subsample_for_bin': 260000, 'subsample': 0.9486803791550391, 'feature_fraction': 0.7684312715091868, 'min_child_samples': 10, 'min_child_weight': 0.3986898688723576, 'min_split_gain': 6.773837195414533, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7277170775038864                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7452896753011155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7452896753011155\n",
      " 89%|████████▉ | 178/200 [07:44<00:48,  2.22s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 500, 'learning_rate': 0.3080854103530922, 'num_leaves': 1248, 'class_weight': None, 'reg_alpha': 5.630922980697801, 'reg_lambda': 8.52459349567416, 'subsample_for_bin': 260000, 'subsample': 0.9259972815835796, 'feature_fraction': 0.7452896753011155, 'min_child_samples': 9, 'min_child_weight': 0.206070869333588, 'min_split_gain': 6.47105675825235, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7284898956251389                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7270893301663705, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7270893301663705\n",
      " 90%|████████▉ | 179/200 [07:46<00:47,  2.26s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 510, 'learning_rate': 0.3306021920770431, 'num_leaves': 1256, 'class_weight': None, 'reg_alpha': 5.691124299122134, 'reg_lambda': 8.290872722987919, 'subsample_for_bin': 260000, 'subsample': 0.9433866360046682, 'feature_fraction': 0.7270893301663705, 'min_child_samples': 10, 'min_child_weight': 0.1971283740888138, 'min_split_gain': 6.63234902773359, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7301732178547634                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7397440350397054, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7397440350397054\n",
      " 90%|█████████ | 180/200 [07:49<00:45,  2.29s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 510, 'learning_rate': 0.31572496435382275, 'num_leaves': 1320, 'class_weight': None, 'reg_alpha': 5.866749638549574, 'reg_lambda': 8.299996688796918, 'subsample_for_bin': 260000, 'subsample': 0.9122932431456293, 'feature_fraction': 0.7397440350397054, 'min_child_samples': 10, 'min_child_weight': 0.18730482965250872, 'min_split_gain': 6.645799057862341, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7290783921829891                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7579137185373144, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7579137185373144\n",
      " 90%|█████████ | 181/200 [07:51<00:44,  2.34s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 520, 'learning_rate': 0.3008206421220437, 'num_leaves': 1216, 'class_weight': None, 'reg_alpha': 5.2346864174077385, 'reg_lambda': 8.399170639395631, 'subsample_for_bin': 260000, 'subsample': 0.9511423648302543, 'feature_fraction': 0.7579137185373144, 'min_child_samples': 12, 'min_child_weight': 0.47420557469881386, 'min_split_gain': 6.614743804420527, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7292538307794804                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7232881126402503, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7232881126402503\n",
      " 91%|█████████ | 182/200 [07:54<00:42,  2.35s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 480, 'learning_rate': 0.31961440508322947, 'num_leaves': 1232, 'class_weight': None, 'reg_alpha': 5.406616741963476, 'reg_lambda': 8.453624458417073, 'subsample_for_bin': 260000, 'subsample': 0.9256268528893552, 'feature_fraction': 0.7232881126402503, 'min_child_samples': 10, 'min_child_weight': 0.18049712113797667, 'min_split_gain': 6.702511267584276, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7290783921829891                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6865701827515324, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6865701827515324\n",
      " 92%|█████████▏| 183/200 [07:56<00:39,  2.34s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 490, 'learning_rate': 0.2829645661804281, 'num_leaves': 1256, 'class_weight': None, 'reg_alpha': 5.642068084315351, 'reg_lambda': 8.116425124516944, 'subsample_for_bin': 260000, 'subsample': 0.9322560875983341, 'feature_fraction': 0.6865701827515324, 'min_child_samples': 7, 'min_child_weight': 0.1618944509214944, 'min_split_gain': 6.747196945787265, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7290095491894293                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7158236298050374, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7158236298050374\n",
      " 92%|█████████▏| 184/200 [07:58<00:37,  2.35s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 460, 'learning_rate': 0.27268648857766253, 'num_leaves': 1232, 'class_weight': None, 'reg_alpha': 5.9125464228632065, 'reg_lambda': 7.896984647291513, 'subsample_for_bin': 260000, 'subsample': 0.9112053443815263, 'feature_fraction': 0.7158236298050374, 'min_child_samples': 8, 'min_child_weight': 0.3749214488283094, 'min_split_gain': 6.70908854661157, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.729644681323562                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7280378730588476, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7280378730588476\n",
      " 92%|█████████▎| 185/200 [08:00<00:34,  2.29s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 500, 'learning_rate': 0.32156160555088925, 'num_leaves': 1288, 'class_weight': None, 'reg_alpha': 5.529442710198782, 'reg_lambda': 8.611408262663213, 'subsample_for_bin': 260000, 'subsample': 0.9100325772356685, 'feature_fraction': 0.7280378730588476, 'min_child_samples': 11, 'min_child_weight': 0.45221533556157756, 'min_split_gain': 6.633780896783396, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7301465689540306                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7102747529077609, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7102747529077609\n",
      " 93%|█████████▎| 186/200 [08:03<00:32,  2.32s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 460, 'learning_rate': 0.30569692650617836, 'num_leaves': 1336, 'class_weight': None, 'reg_alpha': 5.560468306710485, 'reg_lambda': 8.60037574984261, 'subsample_for_bin': 260000, 'subsample': 0.9451358720028291, 'feature_fraction': 0.7102747529077609, 'min_child_samples': 10, 'min_child_weight': 0.2570265167749367, 'min_split_gain': 6.519438522346182, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7285476349100599                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7397027837683333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7397027837683333\n",
      " 94%|█████████▎| 187/200 [08:05<00:30,  2.31s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 450, 'learning_rate': 0.29770701773570474, 'num_leaves': 1320, 'class_weight': None, 'reg_alpha': 5.590846095452004, 'reg_lambda': 8.360923781290204, 'subsample_for_bin': 260000, 'subsample': 0.9173107735239031, 'feature_fraction': 0.7397027837683333, 'min_child_samples': 13, 'min_child_weight': 0.29239287774742456, 'min_split_gain': 6.632578546262346, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7288807461692206                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7129317285110819, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7129317285110819\n",
      " 94%|█████████▍| 188/200 [08:07<00:27,  2.30s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 490, 'learning_rate': 0.293752901054037, 'num_leaves': 1288, 'class_weight': None, 'reg_alpha': 5.573074450412442, 'reg_lambda': 8.37691874889134, 'subsample_for_bin': 260000, 'subsample': 0.9331510422019695, 'feature_fraction': 0.7129317285110819, 'min_child_samples': 12, 'min_child_weight': 0.23744098489971582, 'min_split_gain': 6.846892972758765, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7303308905174328                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7176946906800484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7176946906800484\n",
      " 94%|█████████▍| 189/200 [08:10<00:25,  2.32s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 420, 'learning_rate': 0.29436315858178813, 'num_leaves': 1352, 'class_weight': None, 'reg_alpha': 5.7324056676045005, 'reg_lambda': 8.488811272784107, 'subsample_for_bin': 260000, 'subsample': 0.9184095238145576, 'feature_fraction': 0.7176946906800484, 'min_child_samples': 12, 'min_child_weight': 0.2762475214043298, 'min_split_gain': 6.436281526161383, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7286342438374418                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7344210483426205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7344210483426205\n",
      " 95%|█████████▌| 190/200 [08:12<00:22,  2.28s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 510, 'learning_rate': 0.2922268352546014, 'num_leaves': 1272, 'class_weight': None, 'reg_alpha': 5.54799205278464, 'reg_lambda': 8.533764496862107, 'subsample_for_bin': 260000, 'subsample': 0.9344049826389444, 'feature_fraction': 0.7344210483426205, 'min_child_samples': 12, 'min_child_weight': 0.2139130949952255, 'min_split_gain': 6.52909434979574, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7299733510992672                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7506258849672927, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7506258849672927\n",
      " 96%|█████████▌| 191/200 [08:14<00:20,  2.31s/trial, best loss: -0.731012658227848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 440, 'learning_rate': 0.3042853067972903, 'num_leaves': 1312, 'class_weight': None, 'reg_alpha': 5.67758348331707, 'reg_lambda': 8.283289522274325, 'subsample_for_bin': 260000, 'subsample': 0.929039883905791, 'feature_fraction': 0.7506258849672927, 'min_child_samples': 14, 'min_child_weight': 0.3181454794653195, 'min_split_gain': 6.71254004380025, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7320630690650678                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.743516279621787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.743516279621787\n",
      " 96%|█████████▌| 192/200 [08:18<00:21,  2.68s/trial, best loss: -0.7320630690650678]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 400, 'learning_rate': 0.3035916787877265, 'num_leaves': 1296, 'class_weight': None, 'reg_alpha': 5.845299711186489, 'reg_lambda': 8.475152118526514, 'subsample_for_bin': 260000, 'subsample': 0.9092412376386365, 'feature_fraction': 0.743516279621787, 'min_child_samples': 9, 'min_child_weight': 0.18272328277458852, 'min_split_gain': 6.622458453135342, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7292560515212081                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7258129543916094, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7258129543916094\n",
      " 96%|█████████▋| 193/200 [08:20<00:17,  2.50s/trial, best loss: -0.7320630690650678]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 490, 'learning_rate': 0.2825887061387412, 'num_leaves': 1288, 'class_weight': None, 'reg_alpha': 5.663360171563715, 'reg_lambda': 8.115731589819802, 'subsample_for_bin': 260000, 'subsample': 0.9438144786134346, 'feature_fraction': 0.7258129543916094, 'min_child_samples': 9, 'min_child_weight': 0.544548846941617, 'min_split_gain': 6.960935448641569, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7298156784365979                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7197290460636753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7197290460636753\n",
      " 97%|█████████▋| 194/200 [08:22<00:14,  2.47s/trial, best loss: -0.7320630690650678]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 19, 'n_estimators': 490, 'learning_rate': 0.30540876129124667, 'num_leaves': 1248, 'class_weight': None, 'reg_alpha': 5.563620606256739, 'reg_lambda': 8.060809776982508, 'subsample_for_bin': 260000, 'subsample': 0.9194878497787748, 'feature_fraction': 0.7197290460636753, 'min_child_samples': 8, 'min_child_weight': 0.17834942539957438, 'min_split_gain': 6.676239341276412, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7304730179880081                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7621769618952806, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7621769618952806\n",
      " 98%|█████████▊| 195/200 [08:25<00:12,  2.43s/trial, best loss: -0.7320630690650678]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 420, 'learning_rate': 0.3176001026698281, 'num_leaves': 1352, 'class_weight': None, 'reg_alpha': 5.773724906397115, 'reg_lambda': 8.21938965463668, 'subsample_for_bin': 260000, 'subsample': 0.9497809193024495, 'feature_fraction': 0.7621769618952806, 'min_child_samples': 15, 'min_child_weight': 0.42115608702741386, 'min_split_gain': 6.474763580536398, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7291205862758161                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7350804846291482, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7350804846291482\n",
      " 98%|█████████▊| 196/200 [08:27<00:09,  2.36s/trial, best loss: -0.7320630690650678]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 430, 'learning_rate': 0.3219861273057846, 'num_leaves': 1304, 'class_weight': None, 'reg_alpha': 5.918908642279138, 'reg_lambda': 8.300537776096007, 'subsample_for_bin': 260000, 'subsample': 0.9400096590427933, 'feature_fraction': 0.7350804846291482, 'min_child_samples': 13, 'min_child_weight': 0.2984425474757671, 'min_split_gain': 6.821314340358289, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7294070619586942                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7461966139782832, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7461966139782832\n",
      " 98%|█████████▊| 197/200 [08:29<00:06,  2.32s/trial, best loss: -0.7320630690650678]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 380, 'learning_rate': 0.31263703942581844, 'num_leaves': 1264, 'class_weight': None, 'reg_alpha': 5.611041570580424, 'reg_lambda': 8.411347951879696, 'subsample_for_bin': 260000, 'subsample': 0.9501325171175585, 'feature_fraction': 0.7461966139782832, 'min_child_samples': 13, 'min_child_weight': 0.47301162902893545, 'min_split_gain': 6.913432118413563, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7295491894292694                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.743212983169008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.743212983169008\n",
      " 99%|█████████▉| 198/200 [08:31<00:04,  2.21s/trial, best loss: -0.7320630690650678]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 440, 'learning_rate': 0.3134693053579426, 'num_leaves': 1256, 'class_weight': None, 'reg_alpha': 5.601169137932761, 'reg_lambda': 8.643119267236408, 'subsample_for_bin': 260000, 'subsample': 0.9262825431264942, 'feature_fraction': 0.743212983169008, 'min_child_samples': 12, 'min_child_weight': 0.2602964173705286, 'min_split_gain': 6.844409994638141, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.7288696424605818                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7301289429842135, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7301289429842135\n",
      "100%|█████████▉| 199/200 [08:33<00:02,  2.21s/trial, best loss: -0.7320630690650678]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                                 \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 20, 'n_estimators': 430, 'learning_rate': 0.2849973256262681, 'num_leaves': 1336, 'class_weight': None, 'reg_alpha': 5.517980280300094, 'reg_lambda': 8.153958086857296, 'subsample_for_bin': 260000, 'subsample': 0.9406042573239749, 'feature_fraction': 0.7301289429842135, 'min_child_samples': 14, 'min_child_weight': 0.3635215343640749, 'min_split_gain': 6.703783826539753, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "0.728496557850322                                                                   \n",
      "100%|██████████| 200/200 [08:35<00:00,  2.58s/trial, best loss: -0.7320630690650678]\n",
      "------------best_params------------ {'boosting_type': 'dart', 'class_weight': None, 'feature_fraction': 0.7506258849672927, 'learning_rate': 0.3042853067972903, 'max_depth': 20, 'min_child_samples': 14, 'min_child_weight': 0.3181454794653195, 'min_split_gain': 6.71254004380025, 'n_estimators': 440, 'num_leaves': 1312, 'reg_alpha': 5.67758348331707, 'reg_lambda': 8.283289522274325, 'subsample': 0.929039883905791, 'subsample_for_bin': 260000, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7506258849672927, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7506258849672927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " 0.7745695375891939\n",
      "------------test------------\n",
      " 0.7320630690650678\n",
      "------------oot------------\n",
      " 0.7226682422178199\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 贝叶斯调参 \n",
    "best_params = bayes_fmin(train_x, test_x , train_y, test_y ,200)  \n",
    "\n",
    "\n",
    "print('------------best_params------------',best_params)\n",
    "\n",
    "\n",
    "# 验证\n",
    "clf = LGBMClassifier(**best_params)\n",
    "clf.fit(train_x, train_y,\n",
    "        eval_set=[(test_x,test_y)],\n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=50,verbose=-1)\n",
    "\n",
    "print('------------train------------\\n',model_metrics(clf, train_x,train_y))\n",
    "\n",
    "\n",
    "print('------------test------------\\n',model_metrics(clf, test_x,test_y))\n",
    "\n",
    "print('------------oot------------\\n',model_metrics(clf, oot_x,oot_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27cb97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2909c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x2160 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.7249412064551257, 0.3437111180620721)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>feature_2</td>\n",
       "      <td>13061.886389</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Payment_Rating34_mean_9999</td>\n",
       "      <td>1377.554522</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Highest_Credit_or_Original_Loan_Amount58_sum_9999</td>\n",
       "      <td>1009.247422</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Date_of_Last_Payment40_min_9999</td>\n",
       "      <td>759.438452</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>feature_254</td>\n",
       "      <td>715.694582</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>feature_4</td>\n",
       "      <td>623.478019</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Duesum51_std_360</td>\n",
       "      <td>434.451431</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>feature_645</td>\n",
       "      <td>394.229520</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>feature_32</td>\n",
       "      <td>331.302319</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>feature_253</td>\n",
       "      <td>321.088460</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Duesum51_max_360</td>\n",
       "      <td>308.151719</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>feature_644</td>\n",
       "      <td>269.449621</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>feature_846</td>\n",
       "      <td>260.138779</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>feature_148</td>\n",
       "      <td>257.121878</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>feature_762</td>\n",
       "      <td>223.426090</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Duecount53_std_90</td>\n",
       "      <td>217.413568</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>feature_658</td>\n",
       "      <td>205.895770</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>feature_111</td>\n",
       "      <td>193.393517</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Rate_of_Interest36_mean_90</td>\n",
       "      <td>190.587262</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>feature_545</td>\n",
       "      <td>185.230560</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Amount_Past_Due35_mean_360</td>\n",
       "      <td>181.775678</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>feature_656</td>\n",
       "      <td>178.212499</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>feature_257</td>\n",
       "      <td>177.303842</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Outstanding_Balance_UnSecured</td>\n",
       "      <td>176.731772</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>feature_935</td>\n",
       "      <td>174.633800</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>feature_34</td>\n",
       "      <td>174.568198</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Payment_Rating34_sum_9999</td>\n",
       "      <td>168.967010</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Current_Balance35_max_90</td>\n",
       "      <td>165.969320</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>feature_781</td>\n",
       "      <td>158.203650</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>feature_638</td>\n",
       "      <td>158.180790</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>feature_329</td>\n",
       "      <td>156.483090</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Duesum51_sum_360</td>\n",
       "      <td>145.167169</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>feature_146</td>\n",
       "      <td>142.587532</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Duesum_amt_mean</td>\n",
       "      <td>141.112530</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>feature_12</td>\n",
       "      <td>138.505030</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>feature_701</td>\n",
       "      <td>114.458210</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>feature_659</td>\n",
       "      <td>113.509360</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>feature_484</td>\n",
       "      <td>113.399889</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Highest_Credit_or_Original_Loan_Amount58_max_9999</td>\n",
       "      <td>111.612949</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Days_Past_Due58_max_360</td>\n",
       "      <td>109.348710</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Len_of_addrs</td>\n",
       "      <td>108.089768</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Days_Past_Due58_sum_360</td>\n",
       "      <td>99.542920</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Amount_Financed35_median_9999</td>\n",
       "      <td>96.445220</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Amount_Financed35_mean_90</td>\n",
       "      <td>95.493820</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Outstanding_Balance_All</td>\n",
       "      <td>93.362719</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>feature_780</td>\n",
       "      <td>91.104289</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Duecount53_sum_9999</td>\n",
       "      <td>84.387200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>feature_256</td>\n",
       "      <td>84.140881</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Highest_Credit_or_Original_Loan_Amount58_max_90</td>\n",
       "      <td>81.013479</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>feature_31</td>\n",
       "      <td>78.483191</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Amount_Financed35_std_90</td>\n",
       "      <td>77.516070</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>feature_445</td>\n",
       "      <td>76.084391</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>feature_385</td>\n",
       "      <td>72.488599</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Date_of_Request35_mode_360</td>\n",
       "      <td>68.430410</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Birth_nuniq</td>\n",
       "      <td>67.674050</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>feature_478</td>\n",
       "      <td>65.255010</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Highest_Credit_or_Original_Loan_Amount58_sum_90</td>\n",
       "      <td>64.741380</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>feature_142</td>\n",
       "      <td>63.074401</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>feature_337</td>\n",
       "      <td>61.709049</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Duesum51_mean_360</td>\n",
       "      <td>61.411770</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>feature_105</td>\n",
       "      <td>60.795301</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>feature_642</td>\n",
       "      <td>60.273639</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MissingRate</td>\n",
       "      <td>59.730110</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>feature_255</td>\n",
       "      <td>59.518849</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>feature_252</td>\n",
       "      <td>58.678180</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Date_of_Last_Payment40_mean_360</td>\n",
       "      <td>56.215540</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>feature_405</td>\n",
       "      <td>53.940109</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BureauScore</td>\n",
       "      <td>53.422240</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>feature_399</td>\n",
       "      <td>52.265399</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Terms_Duration34_sum_9999</td>\n",
       "      <td>51.455080</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Days_Past_Due58_mean_9999</td>\n",
       "      <td>48.089790</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Terms_Duration34_std_9999</td>\n",
       "      <td>44.140571</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CreditAccountTotal</td>\n",
       "      <td>43.961660</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>feature_136</td>\n",
       "      <td>43.927729</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>feature_559</td>\n",
       "      <td>39.770130</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>feature_419</td>\n",
       "      <td>39.428170</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>feature_33</td>\n",
       "      <td>38.769629</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Duesum51_mean_9999</td>\n",
       "      <td>37.379090</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Amount_Past_Due35_sum_360</td>\n",
       "      <td>37.042710</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>feature_147</td>\n",
       "      <td>36.110920</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Date_Reported33_mode_360</td>\n",
       "      <td>34.071900</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>feature_263</td>\n",
       "      <td>33.825881</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>feature_643</td>\n",
       "      <td>33.492700</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>feature_141</td>\n",
       "      <td>32.980571</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>feature_498</td>\n",
       "      <td>32.598540</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>feature_459</td>\n",
       "      <td>31.621400</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>feature_71</td>\n",
       "      <td>31.288990</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Date_of_Request35_nuniq_90</td>\n",
       "      <td>28.966369</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>feature_675</td>\n",
       "      <td>28.574770</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Duecount53_max_9999</td>\n",
       "      <td>28.529211</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Date_of_Request35_mode_9999</td>\n",
       "      <td>28.277981</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>feature_734</td>\n",
       "      <td>28.007400</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Duecount53_mean_90</td>\n",
       "      <td>26.514900</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>feature_157</td>\n",
       "      <td>26.098160</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>feature_259</td>\n",
       "      <td>25.579840</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>State_nuniq</td>\n",
       "      <td>24.869420</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>feature_888</td>\n",
       "      <td>23.465610</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Rate_of_Interest36_max_90</td>\n",
       "      <td>22.065900</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>feature_657</td>\n",
       "      <td>21.687940</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>feature_350</td>\n",
       "      <td>20.537549</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Current_Balance35_std_9999</td>\n",
       "      <td>20.255880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>feature_185</td>\n",
       "      <td>20.246480</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Days_Past_Due58_mean_360</td>\n",
       "      <td>20.169220</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>feature_323</td>\n",
       "      <td>19.455680</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>Date_of_Request35_mode_90</td>\n",
       "      <td>19.449110</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>feature_35</td>\n",
       "      <td>19.387600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Portfolio_Type34_nuniq_9999</td>\n",
       "      <td>18.739520</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Payment_Rating34_std_9999</td>\n",
       "      <td>17.279490</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>feature_249</td>\n",
       "      <td>17.275700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Days_Past_Due58_std_360</td>\n",
       "      <td>17.004900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Date_of_Last_Payment40_min_90</td>\n",
       "      <td>16.817600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Date_of_Last_Payment40_min_360</td>\n",
       "      <td>16.432040</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>feature_260</td>\n",
       "      <td>14.968740</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>feature_495</td>\n",
       "      <td>14.845300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>feature_103</td>\n",
       "      <td>14.822590</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>feature_261</td>\n",
       "      <td>14.639709</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Highest_Credit_or_Original_Loan_Amount58_mean_...</td>\n",
       "      <td>14.398540</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>feature_677</td>\n",
       "      <td>14.323880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Date_Reported33_mode_90</td>\n",
       "      <td>14.215400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>feature_454</td>\n",
       "      <td>13.659550</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>feature_636</td>\n",
       "      <td>13.383500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>feature_443</td>\n",
       "      <td>13.380690</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Highest_Credit_or_Original_Loan_Amount58_mean_90</td>\n",
       "      <td>12.846000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>feature_69</td>\n",
       "      <td>11.708900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Repayment_Tenure36_mean_9999</td>\n",
       "      <td>11.064600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Current_Balance_Income_diff</td>\n",
       "      <td>10.798900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Current_Balance35_std_90</td>\n",
       "      <td>10.570500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>feature_140</td>\n",
       "      <td>10.396900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>feature_422</td>\n",
       "      <td>10.182000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Month50_std_360</td>\n",
       "      <td>9.799290</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Highest_Credit_or_Original_Loan_Amount58_std_90</td>\n",
       "      <td>8.987810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>feature_673</td>\n",
       "      <td>8.654370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Payment_Rating34_max_9999</td>\n",
       "      <td>8.528250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>feature_456</td>\n",
       "      <td>8.069830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>feature_702</td>\n",
       "      <td>7.952860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>feature_219</td>\n",
       "      <td>7.817040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Rate_of_Interest36_std_9999</td>\n",
       "      <td>7.790680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Duecount53_min_90</td>\n",
       "      <td>7.783830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>feature_576</td>\n",
       "      <td>7.679940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>feature_149</td>\n",
       "      <td>7.645310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>feature_417</td>\n",
       "      <td>7.464230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>feature_27</td>\n",
       "      <td>7.390040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>feature_351</td>\n",
       "      <td>7.170180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>feature_828</td>\n",
       "      <td>7.094910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>feature_672</td>\n",
       "      <td>7.021550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>feature_518</td>\n",
       "      <td>6.940870</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>feature_28</td>\n",
       "      <td>6.776570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>feature_333</td>\n",
       "      <td>6.629630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>feature_670</td>\n",
       "      <td>6.611660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>feature_442</td>\n",
       "      <td>6.509090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>feature_755</td>\n",
       "      <td>6.472530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>feature_322</td>\n",
       "      <td>6.470860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>feature_418</td>\n",
       "      <td>6.351830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Current_Balance35_max_9999</td>\n",
       "      <td>6.303140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Date_Closed31_nuniq_360</td>\n",
       "      <td>6.226380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>feature_611</td>\n",
       "      <td>6.135210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>feature_558</td>\n",
       "      <td>6.070070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Highest_Credit_or_Original_Loan_Amount58_sum_360</td>\n",
       "      <td>6.046160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>feature_531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>feature_522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>feature_509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>feature_523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>feature_497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>feature_515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>feature_524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>feature_510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>feature_514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>feature_490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>feature_513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>feature_525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>feature_526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>feature_494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>feature_527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>feature_528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>feature_529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>feature_489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>feature_530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>feature_496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>feature_493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>feature_491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>feature_500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>feature_504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>feature_503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>feature_502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>feature_517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>feature_505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>feature_501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>feature_506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>feature_511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>feature_516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>feature_499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>feature_507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>feature_962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>feature_508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>feature_519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>feature_492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>feature_520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>feature_961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>feature_521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>feature_512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                feature          gain  split\n",
       "432                                           feature_2  13061.886389    717\n",
       "91                           Payment_Rating34_mean_9999   1377.554522    153\n",
       "63    Highest_Credit_or_Original_Loan_Amount58_sum_9999   1009.247422    126\n",
       "232                     Date_of_Last_Payment40_min_9999    759.438452     81\n",
       "684                                         feature_254    715.694582     76\n",
       "434                                           feature_4    623.478019     73\n",
       "335                                    Duesum51_std_360    434.451431     49\n",
       "1075                                        feature_645    394.229520     38\n",
       "462                                          feature_32    331.302319     38\n",
       "683                                         feature_253    321.088460     34\n",
       "333                                    Duesum51_max_360    308.151719     35\n",
       "1074                                        feature_644    269.449621     37\n",
       "1276                                        feature_846    260.138779     36\n",
       "578                                         feature_148    257.121878     33\n",
       "1192                                        feature_762    223.426090     31\n",
       "316                                   Duecount53_std_90    217.413568     31\n",
       "1088                                        feature_658    205.895770     26\n",
       "541                                         feature_111    193.393517     21\n",
       "135                          Rate_of_Interest36_mean_90    190.587262     23\n",
       "975                                         feature_545    185.230560     18\n",
       "45                           Amount_Past_Due35_mean_360    181.775678     21\n",
       "1086                                        feature_656    178.212499     19\n",
       "687                                         feature_257    177.303842     20\n",
       "15                        Outstanding_Balance_UnSecured    176.731772     24\n",
       "1365                                        feature_935    174.633800     21\n",
       "464                                          feature_34    174.568198     20\n",
       "90                            Payment_Rating34_sum_9999    168.967010     21\n",
       "100                            Current_Balance35_max_90    165.969320     23\n",
       "1211                                        feature_781    158.203650     20\n",
       "1068                                        feature_638    158.180790     18\n",
       "759                                         feature_329    156.483090     21\n",
       "331                                    Duesum51_sum_360    145.167169     17\n",
       "576                                         feature_146    142.587532      9\n",
       "430                                     Duesum_amt_mean    141.112530     14\n",
       "442                                          feature_12    138.505030     18\n",
       "1131                                        feature_701    114.458210     13\n",
       "1089                                        feature_659    113.509360     12\n",
       "914                                         feature_484    113.399889     16\n",
       "65    Highest_Credit_or_Original_Loan_Amount58_max_9999    111.612949     13\n",
       "299                             Days_Past_Due58_max_360    109.348710     15\n",
       "5                                          Len_of_addrs    108.089768     13\n",
       "297                             Days_Past_Due58_sum_360     99.542920     12\n",
       "364                       Amount_Financed35_median_9999     96.445220     12\n",
       "352                           Amount_Financed35_mean_90     95.493820     14\n",
       "13                              Outstanding_Balance_All     93.362719     11\n",
       "1210                                        feature_780     91.104289     13\n",
       "322                                 Duecount53_sum_9999     84.387200     10\n",
       "686                                         feature_256     84.140881      8\n",
       "57      Highest_Credit_or_Original_Loan_Amount58_max_90     81.013479     11\n",
       "461                                          feature_31     78.483191      9\n",
       "355                            Amount_Financed35_std_90     77.516070     11\n",
       "875                                         feature_445     76.084391     10\n",
       "815                                         feature_385     72.488599      8\n",
       "396                          Date_of_Request35_mode_360     68.430410      8\n",
       "18                                          Birth_nuniq     67.674050      8\n",
       "908                                         feature_478     65.255010     10\n",
       "55      Highest_Credit_or_Original_Loan_Amount58_sum_90     64.741380      9\n",
       "572                                         feature_142     63.074401      7\n",
       "767                                         feature_337     61.709049      9\n",
       "332                                   Duesum51_mean_360     61.411770      8\n",
       "535                                         feature_105     60.795301      3\n",
       "1072                                        feature_642     60.273639      7\n",
       "1                                           MissingRate     59.730110      9\n",
       "685                                         feature_255     59.518849      8\n",
       "682                                         feature_252     58.678180      6\n",
       "227                     Date_of_Last_Payment40_mean_360     56.215540      8\n",
       "835                                         feature_405     53.940109      6\n",
       "0                                           BureauScore     53.422240      7\n",
       "829                                         feature_399     52.265399      5\n",
       "75                            Terms_Duration34_sum_9999     51.455080      7\n",
       "303                           Days_Past_Due58_mean_9999     48.089790      5\n",
       "79                            Terms_Duration34_std_9999     44.140571      6\n",
       "9                                    CreditAccountTotal     43.961660      7\n",
       "566                                         feature_136     43.927729      5\n",
       "989                                         feature_559     39.770130      4\n",
       "849                                         feature_419     39.428170      4\n",
       "463                                          feature_33     38.769629      5\n",
       "337                                  Duesum51_mean_9999     37.379090      3\n",
       "44                            Amount_Past_Due35_sum_360     37.042710      5\n",
       "577                                         feature_147     36.110920      5\n",
       "244                            Date_Reported33_mode_360     34.071900      4\n",
       "693                                         feature_263     33.825881      4\n",
       "1073                                        feature_643     33.492700      4\n",
       "571                                         feature_141     32.980571      4\n",
       "928                                         feature_498     32.598540      5\n",
       "889                                         feature_459     31.621400      4\n",
       "501                                          feature_71     31.288990      3\n",
       "395                          Date_of_Request35_nuniq_90     28.966369      4\n",
       "1105                                        feature_675     28.574770      4\n",
       "324                                 Duecount53_max_9999     28.529211      4\n",
       "398                         Date_of_Request35_mode_9999     28.277981      3\n",
       "1164                                        feature_734     28.007400      4\n",
       "313                                  Duecount53_mean_90     26.514900      4\n",
       "587                                         feature_157     26.098160      3\n",
       "689                                         feature_259     25.579840      3\n",
       "17                                          State_nuniq     24.869420      3\n",
       "1318                                        feature_888     23.465610      3\n",
       "136                           Rate_of_Interest36_max_90     22.065900      3\n",
       "1087                                        feature_657     21.687940      3\n",
       "780                                         feature_350     20.537549      3\n",
       "106                          Current_Balance35_std_9999     20.255880      2\n",
       "615                                         feature_185     20.246480      3\n",
       "298                            Days_Past_Due58_mean_360     20.169220      3\n",
       "753                                         feature_323     19.455680      3\n",
       "394                           Date_of_Request35_mode_90     19.449110      3\n",
       "465                                          feature_35     19.387600      3\n",
       "184                         Portfolio_Type34_nuniq_9999     18.739520      3\n",
       "94                            Payment_Rating34_std_9999     17.279490      2\n",
       "679                                         feature_249     17.275700      2\n",
       "301                             Days_Past_Due58_std_360     17.004900      2\n",
       "222                       Date_of_Last_Payment40_min_90     16.817600      1\n",
       "226                      Date_of_Last_Payment40_min_360     16.432040      2\n",
       "690                                         feature_260     14.968740      2\n",
       "925                                         feature_495     14.845300      1\n",
       "533                                         feature_103     14.822590      2\n",
       "691                                         feature_261     14.639709      2\n",
       "64    Highest_Credit_or_Original_Loan_Amount58_mean_...     14.398540      2\n",
       "1107                                        feature_677     14.323880      2\n",
       "239                             Date_Reported33_mode_90     14.215400      1\n",
       "884                                         feature_454     13.659550      2\n",
       "1066                                        feature_636     13.383500      1\n",
       "873                                         feature_443     13.380690      2\n",
       "56     Highest_Credit_or_Original_Loan_Amount58_mean_90     12.846000      1\n",
       "499                                          feature_69     11.708900      1\n",
       "157                        Repayment_Tenure36_mean_9999     11.064600      1\n",
       "426                         Current_Balance_Income_diff     10.798900      1\n",
       "101                            Current_Balance35_std_90     10.570500      1\n",
       "570                                         feature_140     10.396900      1\n",
       "852                                         feature_422     10.182000      1\n",
       "285                                     Month50_std_360      9.799290      1\n",
       "59      Highest_Credit_or_Original_Loan_Amount58_std_90      8.987810      1\n",
       "1103                                        feature_673      8.654370      1\n",
       "92                            Payment_Rating34_max_9999      8.528250      1\n",
       "886                                         feature_456      8.069830      1\n",
       "1132                                        feature_702      7.952860      1\n",
       "649                                         feature_219      7.817040      1\n",
       "147                         Rate_of_Interest36_std_9999      7.790680      1\n",
       "315                                   Duecount53_min_90      7.783830      1\n",
       "1006                                        feature_576      7.679940      1\n",
       "579                                         feature_149      7.645310      1\n",
       "847                                         feature_417      7.464230      1\n",
       "457                                          feature_27      7.390040      1\n",
       "781                                         feature_351      7.170180      1\n",
       "1258                                        feature_828      7.094910      1\n",
       "1102                                        feature_672      7.021550      1\n",
       "948                                         feature_518      6.940870      1\n",
       "458                                          feature_28      6.776570      1\n",
       "763                                         feature_333      6.629630      1\n",
       "1100                                        feature_670      6.611660      1\n",
       "872                                         feature_442      6.509090      1\n",
       "1185                                        feature_755      6.472530      1\n",
       "752                                         feature_322      6.470860      1\n",
       "848                                         feature_418      6.351830      1\n",
       "105                          Current_Balance35_max_9999      6.303140      1\n",
       "213                             Date_Closed31_nuniq_360      6.226380      1\n",
       "1041                                        feature_611      6.135210      1\n",
       "988                                         feature_558      6.070070      1\n",
       "60     Highest_Credit_or_Original_Loan_Amount58_sum_360      6.046160      1\n",
       "961                                         feature_531      0.000000      0\n",
       "952                                         feature_522      0.000000      0\n",
       "939                                         feature_509      0.000000      0\n",
       "953                                         feature_523      0.000000      0\n",
       "927                                         feature_497      0.000000      0\n",
       "945                                         feature_515      0.000000      0\n",
       "954                                         feature_524      0.000000      0\n",
       "940                                         feature_510      0.000000      0\n",
       "944                                         feature_514      0.000000      0\n",
       "920                                         feature_490      0.000000      0\n",
       "943                                         feature_513      0.000000      0\n",
       "955                                         feature_525      0.000000      0\n",
       "956                                         feature_526      0.000000      0\n",
       "924                                         feature_494      0.000000      0\n",
       "957                                         feature_527      0.000000      0\n",
       "958                                         feature_528      0.000000      0\n",
       "959                                         feature_529      0.000000      0\n",
       "919                                         feature_489      0.000000      0\n",
       "960                                         feature_530      0.000000      0\n",
       "926                                         feature_496      0.000000      0\n",
       "923                                         feature_493      0.000000      0\n",
       "921                                         feature_491      0.000000      0\n",
       "930                                         feature_500      0.000000      0\n",
       "934                                         feature_504      0.000000      0\n",
       "933                                         feature_503      0.000000      0\n",
       "932                                         feature_502      0.000000      0\n",
       "947                                         feature_517      0.000000      0\n",
       "935                                         feature_505      0.000000      0\n",
       "931                                         feature_501      0.000000      0\n",
       "936                                         feature_506      0.000000      0\n",
       "941                                         feature_511      0.000000      0\n",
       "946                                         feature_516      0.000000      0\n",
       "929                                         feature_499      0.000000      0\n",
       "937                                         feature_507      0.000000      0\n",
       "1392                                        feature_962      0.000000      0\n",
       "938                                         feature_508      0.000000      0\n",
       "949                                         feature_519      0.000000      0\n",
       "922                                         feature_492      0.000000      0\n",
       "950                                         feature_520      0.000000      0\n",
       "1391                                        feature_961      0.000000      0\n",
       "951                                         feature_521      0.000000      0\n",
       "942                                         feature_512      0.000000      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "from lightgbm import plot_importance,plot_tree\n",
    "def get_importance(model):\n",
    "    plot_importance(model, max_num_features=100,figsize=(10,30),importance_type='gain')\n",
    "    plt.show()\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': model.booster_.feature_name(),\n",
    "        'gain': model.booster_.feature_importance('gain'),\n",
    "        'split': model.booster_.feature_importance('split')\n",
    "\n",
    "    }).sort_values('gain',ascending=False)\n",
    "    \n",
    "    return feature_importance\n",
    "\n",
    "\n",
    "feature_importance = get_importance(clf)\n",
    "\n",
    "\n",
    "\n",
    "ax = lgb.plot_tree(clf, tree_index=0, figsize=(10, 8), show_info=['split_gain'])\n",
    "plt.show()\n",
    "\n",
    "# graph = lgb.create_tree_digraph(clf, tree_index=0, name='Tree3')\n",
    "# graph.render(view=True)\n",
    "# clf.booster_.dump_model()\n",
    "# feature_importance.to_pickle('./data/feature_importance.pkl')\n",
    "print('------------oot------------\\n',model_metrics(clf, oot_x,oot_y,tp='ks'))\n",
    "feature_importance.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93531546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2947031809327042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2947031809327042\n",
      "------------train------------\n",
      " 0.8057854987245683\n",
      "------------test------------\n",
      " 0.7137819231623364\n",
      "------------oot------------\n",
      " 0.7099665195379928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BureauScore',\n",
       " 'MissingRate',\n",
       " 'Len_Name',\n",
       " 'Tel_nuniq',\n",
       " 'Email_nuniq',\n",
       " 'Len_of_addrs',\n",
       " 'City_nuniq',\n",
       " 'Current_State',\n",
       " 'CreditAccountActive',\n",
       " 'CreditAccountTotal',\n",
       " 'CreditAccountActivePor',\n",
       " 'Outstanding_Balance_Secured',\n",
       " 'Outstanding_Balance_UnSecured_Percentage',\n",
       " 'Outstanding_Balance_All',\n",
       " 'Outstanding_Balance_Secured_Percentage',\n",
       " 'Outstanding_Balance_UnSecured',\n",
       " 'Diff_dateBirth',\n",
       " 'State_nuniq',\n",
       " 'Birth_nuniq',\n",
       " 'TotalCAPSLast90Days',\n",
       " 'TotalCAPSLast7Days',\n",
       " 'TotalCAPSLast30Days',\n",
       " 'TotalCAPSLast180Days',\n",
       " 'CAPSLast30Days',\n",
       " 'CAPSLast7Days',\n",
       " 'CAPSLast180Days',\n",
       " 'NonCreditCAPSLast180Days',\n",
       " 'Pin_nuniq',\n",
       " 'Pan_nuniq',\n",
       " 'Ident_nuniq',\n",
       " 'Name_nuniq2',\n",
       " 'Tel_nuniq2',\n",
       " 'Email_nuniq2',\n",
       " 'Pan_nuniq2',\n",
       " 'Account_nuniq2',\n",
       " 'Ident_nuniq2',\n",
       " 'Gender_nuniq',\n",
       " 'Amount_Past_Due35_sum_30',\n",
       " 'Amount_Past_Due35_min_30',\n",
       " 'Amount_Past_Due35_sum_90',\n",
       " 'Amount_Past_Due35_mean_90',\n",
       " 'Amount_Past_Due35_max_90',\n",
       " 'Amount_Past_Due35_min_90',\n",
       " 'Amount_Past_Due35_std_90',\n",
       " 'Amount_Past_Due35_sum_360',\n",
       " 'Amount_Past_Due35_mean_360',\n",
       " 'Amount_Past_Due35_max_360',\n",
       " 'Amount_Past_Due35_std_360',\n",
       " 'Amount_Past_Due35_sum_9999',\n",
       " 'Amount_Past_Due35_max_9999',\n",
       " 'Amount_Past_Due35_min_9999',\n",
       " 'Amount_Past_Due35_std_9999',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_max_30',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_min_30',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_std_30',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_sum_90',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_mean_90',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_max_90',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_min_90',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_std_90',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_sum_360',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_max_360',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_std_360',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_sum_9999',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_mean_9999',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_max_9999',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_std_9999',\n",
       " 'Terms_Duration34_sum_30',\n",
       " 'Terms_Duration34_std_30',\n",
       " 'Terms_Duration34_sum_90',\n",
       " 'Terms_Duration34_std_90',\n",
       " 'Terms_Duration34_mean_360',\n",
       " 'Terms_Duration34_max_360',\n",
       " 'Terms_Duration34_min_360',\n",
       " 'Terms_Duration34_std_360',\n",
       " 'Terms_Duration34_sum_9999',\n",
       " 'Terms_Duration34_mean_9999',\n",
       " 'Terms_Duration34_max_9999',\n",
       " 'Terms_Duration34_min_9999',\n",
       " 'Terms_Duration34_std_9999',\n",
       " 'Payment_Rating34_sum_90',\n",
       " 'Payment_Rating34_mean_90',\n",
       " 'Payment_Rating34_max_90',\n",
       " 'Payment_Rating34_min_90',\n",
       " 'Payment_Rating34_std_90',\n",
       " 'Payment_Rating34_sum_360',\n",
       " 'Payment_Rating34_mean_360',\n",
       " 'Payment_Rating34_max_360',\n",
       " 'Payment_Rating34_min_360',\n",
       " 'Payment_Rating34_std_360',\n",
       " 'Payment_Rating34_sum_9999',\n",
       " 'Payment_Rating34_mean_9999',\n",
       " 'Payment_Rating34_max_9999',\n",
       " 'Payment_Rating34_min_9999',\n",
       " 'Payment_Rating34_std_9999',\n",
       " 'Current_Balance35_mean_30',\n",
       " 'Current_Balance35_min_30',\n",
       " 'Current_Balance35_std_30',\n",
       " 'Current_Balance35_sum_90',\n",
       " 'Current_Balance35_mean_90',\n",
       " 'Current_Balance35_max_90',\n",
       " 'Current_Balance35_std_90',\n",
       " 'Current_Balance35_sum_360',\n",
       " 'Current_Balance35_max_360',\n",
       " 'Current_Balance35_std_360',\n",
       " 'Current_Balance35_max_9999',\n",
       " 'Current_Balance35_std_9999',\n",
       " 'Settlement_Amount37_max_360',\n",
       " 'Settlement_Amount37_min_360',\n",
       " 'Settlement_Amount37_std_360',\n",
       " 'Settlement_Amount37_sum_9999',\n",
       " 'Settlement_Amount37_mean_9999',\n",
       " 'Settlement_Amount37_max_9999',\n",
       " 'Settlement_Amount37_min_9999',\n",
       " 'Settlement_Amount37_std_9999',\n",
       " 'Value_of_Collateral39_std_90',\n",
       " 'Value_of_Collateral39_std_360',\n",
       " 'Written_Off_Amt_Total41_sum_360',\n",
       " 'Written_Off_Amt_Total41_mean_360',\n",
       " 'Written_Off_Amt_Total41_min_360',\n",
       " 'Written_Off_Amt_Total41_std_360',\n",
       " 'Written_Off_Amt_Total41_sum_9999',\n",
       " 'Written_Off_Amt_Total41_mean_9999',\n",
       " 'Written_Off_Amt_Total41_max_9999',\n",
       " 'Written_Off_Amt_Total41_min_9999',\n",
       " 'Written_Off_Amt_Total41_std_9999',\n",
       " 'Written_Off_Amt_Principal45_sum_360',\n",
       " 'Written_Off_Amt_Principal45_mean_360',\n",
       " 'Written_Off_Amt_Principal45_min_360',\n",
       " 'Written_Off_Amt_Principal45_std_360',\n",
       " 'Written_Off_Amt_Principal45_max_9999',\n",
       " 'Written_Off_Amt_Principal45_min_9999',\n",
       " 'Rate_of_Interest36_sum_30',\n",
       " 'Rate_of_Interest36_std_30',\n",
       " 'Rate_of_Interest36_sum_90',\n",
       " 'Rate_of_Interest36_mean_90',\n",
       " 'Rate_of_Interest36_max_90',\n",
       " 'Rate_of_Interest36_std_90',\n",
       " 'Rate_of_Interest36_sum_360',\n",
       " 'Rate_of_Interest36_mean_360',\n",
       " 'Rate_of_Interest36_max_360',\n",
       " 'Rate_of_Interest36_min_360',\n",
       " 'Rate_of_Interest36_std_360',\n",
       " 'Rate_of_Interest36_sum_9999',\n",
       " 'Rate_of_Interest36_mean_9999',\n",
       " 'Rate_of_Interest36_max_9999',\n",
       " 'Rate_of_Interest36_min_9999',\n",
       " 'Rate_of_Interest36_std_9999',\n",
       " 'Repayment_Tenure36_std_30',\n",
       " 'Repayment_Tenure36_mean_90',\n",
       " 'Repayment_Tenure36_max_90',\n",
       " 'Repayment_Tenure36_min_90',\n",
       " 'Repayment_Tenure36_std_90',\n",
       " 'Repayment_Tenure36_sum_360',\n",
       " 'Repayment_Tenure36_mean_360',\n",
       " 'Repayment_Tenure36_min_360',\n",
       " 'Repayment_Tenure36_std_360',\n",
       " 'Repayment_Tenure36_mean_9999',\n",
       " 'Repayment_Tenure36_min_9999',\n",
       " 'Repayment_Tenure36_std_9999',\n",
       " 'Income26_count_360',\n",
       " 'Income26_std_360',\n",
       " 'Open_Date29_max_30',\n",
       " 'Open_Date29_min_30',\n",
       " 'Open_Date29_mean_30',\n",
       " 'Open_Date29_nuniq_30',\n",
       " 'Open_Date29_maxcount_30',\n",
       " 'Open_Date29_max_90',\n",
       " 'Open_Date29_mean_90',\n",
       " 'Open_Date29_mode_90',\n",
       " 'Open_Date29_nuniq_90',\n",
       " 'Open_Date29_maxcount_90',\n",
       " 'Open_Date29_max_360',\n",
       " 'Open_Date29_mean_360',\n",
       " 'Open_Date29_mode_360',\n",
       " 'Open_Date29_nuniq_360',\n",
       " 'Open_Date29_maxcount_360',\n",
       " 'Open_Date29_max_9999',\n",
       " 'Open_Date29_mean_9999',\n",
       " 'Open_Date29_mode_9999',\n",
       " 'Open_Date29_maxcount_9999',\n",
       " 'Portfolio_Type34_nuniq_30',\n",
       " 'Portfolio_Type34_nuniq_90',\n",
       " 'Portfolio_Type34_nuniq_360',\n",
       " 'Portfolio_Type34_nuniq_9999',\n",
       " 'Account_Type32_nuniq_30',\n",
       " 'Account_Type32_nuniq_90',\n",
       " 'Account_Type32_nuniq_360',\n",
       " 'Account_Type32_nuniq_9999',\n",
       " 'Occupation_Code35_nuniq_30',\n",
       " 'Occupation_Code35_nuniq_90',\n",
       " 'Occupation_Code35_nuniq_360',\n",
       " 'Occupation_Code35_nuniq_9999',\n",
       " 'AccountHoldertypeCode41_nuniq_90',\n",
       " 'AccountHoldertypeCode41_nuniq_360',\n",
       " 'AccountHoldertypeCode41_nuniq_9999',\n",
       " 'Payment_History_Profile43_mode_30',\n",
       " 'Payment_History_Profile43_mode_90',\n",
       " 'Payment_History_Profile43_nuniq_90',\n",
       " 'Payment_History_Profile43_mode_360',\n",
       " 'Payment_History_Profile43_nuniq_360',\n",
       " 'Payment_History_Profile43_mode_9999',\n",
       " 'Payment_History_Profile43_nuniq_9999',\n",
       " 'Date_Closed31_nuniq_30',\n",
       " 'Date_Closed31_maxcount_30',\n",
       " 'Date_Closed31_max_90',\n",
       " 'Date_Closed31_min_90',\n",
       " 'Date_Closed31_mean_90',\n",
       " 'Date_Closed31_mode_90',\n",
       " 'Date_Closed31_nuniq_90',\n",
       " 'Date_Closed31_maxcount_90',\n",
       " 'Date_Closed31_min_360',\n",
       " 'Date_Closed31_mode_360',\n",
       " 'Date_Closed31_nuniq_360',\n",
       " 'Date_Closed31_maxcount_360',\n",
       " 'Date_Closed31_max_9999',\n",
       " 'Date_Closed31_min_9999',\n",
       " 'Date_Closed31_mean_9999',\n",
       " 'Date_Closed31_mode_9999',\n",
       " 'Date_Closed31_nuniq_9999',\n",
       " 'Date_of_Last_Payment40_nuniq_30',\n",
       " 'Date_of_Last_Payment40_maxcount_30',\n",
       " 'Date_of_Last_Payment40_min_90',\n",
       " 'Date_of_Last_Payment40_nuniq_90',\n",
       " 'Date_of_Last_Payment40_maxcount_90',\n",
       " 'Date_of_Last_Payment40_max_360',\n",
       " 'Date_of_Last_Payment40_min_360',\n",
       " 'Date_of_Last_Payment40_mean_360',\n",
       " 'Date_of_Last_Payment40_mode_360',\n",
       " 'Date_of_Last_Payment40_nuniq_360',\n",
       " 'Date_of_Last_Payment40_maxcount_360',\n",
       " 'Date_of_Last_Payment40_max_9999',\n",
       " 'Date_of_Last_Payment40_min_9999',\n",
       " 'Date_of_Last_Payment40_mean_9999',\n",
       " 'Date_of_Last_Payment40_mode_9999',\n",
       " 'Date_of_Last_Payment40_maxcount_9999',\n",
       " 'Date_Reported33_nuniq_30',\n",
       " 'Date_Reported33_max_90',\n",
       " 'Date_Reported33_mean_90',\n",
       " 'Date_Reported33_mode_90',\n",
       " 'Date_Reported33_nuniq_90',\n",
       " 'Date_Reported33_maxcount_90',\n",
       " 'Date_Reported33_max_360',\n",
       " 'Date_Reported33_mean_360',\n",
       " 'Date_Reported33_mode_360',\n",
       " 'Date_Reported33_nuniq_360',\n",
       " 'Date_Reported33_maxcount_360',\n",
       " 'Date_Reported33_max_9999',\n",
       " 'Date_Reported33_mean_9999',\n",
       " 'Date_Reported33_mode_9999',\n",
       " 'Date_Reported33_nuniq_9999',\n",
       " 'Date_Reported33_maxcount_9999',\n",
       " 'DateOfAddition34_nuniq_30',\n",
       " 'DateOfAddition34_max_90',\n",
       " 'DateOfAddition34_mean_90',\n",
       " 'DateOfAddition34_mode_90',\n",
       " 'DateOfAddition34_nuniq_90',\n",
       " 'DateOfAddition34_maxcount_90',\n",
       " 'DateOfAddition34_max_360',\n",
       " 'DateOfAddition34_mean_360',\n",
       " 'DateOfAddition34_mode_360',\n",
       " 'DateOfAddition34_nuniq_360',\n",
       " 'DateOfAddition34_maxcount_360',\n",
       " 'DateOfAddition34_max_9999',\n",
       " 'DateOfAddition34_mean_9999',\n",
       " 'DateOfAddition34_mode_9999',\n",
       " 'DateOfAddition34_nuniq_9999',\n",
       " 'DateOfAddition34_maxcount_9999',\n",
       " 'Account_Status34_mode_30',\n",
       " 'Account_Status34_nuniq_30',\n",
       " 'Account_Status34_mode_90',\n",
       " 'Account_Status34_nuniq_90',\n",
       " 'Account_Status34_mode_360',\n",
       " 'Account_Status34_nuniq_360',\n",
       " 'Account_Status34_nuniq_9999',\n",
       " 'Month50_sum_30',\n",
       " 'Month50_max_30',\n",
       " 'Month50_std_30',\n",
       " 'Month50_sum_90',\n",
       " 'Month50_mean_90',\n",
       " 'Month50_max_90',\n",
       " 'Month50_min_90',\n",
       " 'Month50_std_90',\n",
       " 'Month50_sum_360',\n",
       " 'Month50_min_360',\n",
       " 'Month50_std_360',\n",
       " 'Month50_sum_9999',\n",
       " 'Month50_mean_9999',\n",
       " 'Month50_max_9999',\n",
       " 'Month50_min_9999',\n",
       " 'Month50_std_9999',\n",
       " 'Days_Past_Due58_max_30',\n",
       " 'Days_Past_Due58_min_30',\n",
       " 'Days_Past_Due58_mean_90',\n",
       " 'Days_Past_Due58_max_90',\n",
       " 'Days_Past_Due58_min_90',\n",
       " 'Days_Past_Due58_std_90',\n",
       " 'Days_Past_Due58_sum_360',\n",
       " 'Days_Past_Due58_mean_360',\n",
       " 'Days_Past_Due58_max_360',\n",
       " 'Days_Past_Due58_min_360',\n",
       " 'Days_Past_Due58_std_360',\n",
       " 'Days_Past_Due58_sum_9999',\n",
       " 'Days_Past_Due58_mean_9999',\n",
       " 'Days_Past_Due58_max_9999',\n",
       " 'Days_Past_Due58_min_9999',\n",
       " 'Days_Past_Due58_std_9999',\n",
       " 'Duecount53_sum_30',\n",
       " 'Duecount53_mean_30',\n",
       " 'Duecount53_max_30',\n",
       " 'Duecount53_min_30',\n",
       " 'Duecount53_std_30',\n",
       " 'Duecount53_sum_90',\n",
       " 'Duecount53_mean_90',\n",
       " 'Duecount53_max_90',\n",
       " 'Duecount53_min_90',\n",
       " 'Duecount53_std_90',\n",
       " 'Duecount53_sum_360',\n",
       " 'Duecount53_mean_360',\n",
       " 'Duecount53_max_360',\n",
       " 'Duecount53_min_360',\n",
       " 'Duecount53_std_360',\n",
       " 'Duecount53_sum_9999',\n",
       " 'Duecount53_mean_9999',\n",
       " 'Duecount53_max_9999',\n",
       " 'Duecount53_min_9999',\n",
       " 'Duecount53_std_9999',\n",
       " 'Duesum51_sum_90',\n",
       " 'Duesum51_mean_90',\n",
       " 'Duesum51_min_90',\n",
       " 'Duesum51_std_90',\n",
       " 'Duesum51_sum_360',\n",
       " 'Duesum51_mean_360',\n",
       " 'Duesum51_max_360',\n",
       " 'Duesum51_min_360',\n",
       " 'Duesum51_std_360',\n",
       " 'Duesum51_sum_9999',\n",
       " 'Duesum51_mean_9999',\n",
       " 'Duesum51_max_9999',\n",
       " 'Duesum51_min_9999',\n",
       " 'Duesum51_std_9999',\n",
       " 'Amount_Financed35_count_7',\n",
       " 'Amount_Financed35_std_7',\n",
       " 'Amount_Financed35_count_30',\n",
       " 'Amount_Financed35_sum_30',\n",
       " 'Amount_Financed35_mean_30',\n",
       " 'Amount_Financed35_max_30',\n",
       " 'Amount_Financed35_min_30',\n",
       " 'Amount_Financed35_std_30',\n",
       " 'Amount_Financed35_count_90',\n",
       " 'Amount_Financed35_sum_90',\n",
       " 'Amount_Financed35_median_90',\n",
       " 'Amount_Financed35_mean_90',\n",
       " 'Amount_Financed35_max_90',\n",
       " 'Amount_Financed35_min_90',\n",
       " 'Amount_Financed35_std_90',\n",
       " 'Amount_Financed35_count_360',\n",
       " 'Amount_Financed35_sum_360',\n",
       " 'Amount_Financed35_median_360',\n",
       " 'Amount_Financed35_mean_360',\n",
       " 'Amount_Financed35_max_360',\n",
       " 'Amount_Financed35_min_360',\n",
       " 'Amount_Financed35_std_360',\n",
       " 'Amount_Financed35_sum_9999',\n",
       " 'Amount_Financed35_median_9999',\n",
       " 'Amount_Financed35_mean_9999',\n",
       " 'Amount_Financed35_max_9999',\n",
       " 'Amount_Financed35_min_9999',\n",
       " 'Amount_Financed35_std_9999',\n",
       " 'Duration_Of_Agreement41_min_7',\n",
       " 'Duration_Of_Agreement41_std_7',\n",
       " 'Duration_Of_Agreement41_sum_30',\n",
       " 'Duration_Of_Agreement41_mean_30',\n",
       " 'Duration_Of_Agreement41_max_30',\n",
       " 'Duration_Of_Agreement41_min_30',\n",
       " 'Duration_Of_Agreement41_std_30',\n",
       " 'Duration_Of_Agreement41_sum_90',\n",
       " 'Duration_Of_Agreement41_mean_90',\n",
       " 'Duration_Of_Agreement41_max_90',\n",
       " 'Duration_Of_Agreement41_min_90',\n",
       " 'Duration_Of_Agreement41_std_90',\n",
       " 'Duration_Of_Agreement41_sum_360',\n",
       " 'Duration_Of_Agreement41_mean_360',\n",
       " 'Duration_Of_Agreement41_max_360',\n",
       " 'Duration_Of_Agreement41_min_360',\n",
       " 'Duration_Of_Agreement41_std_360',\n",
       " 'Duration_Of_Agreement41_sum_9999',\n",
       " 'Duration_Of_Agreement41_mean_9999',\n",
       " 'Duration_Of_Agreement41_max_9999',\n",
       " 'Duration_Of_Agreement41_min_9999',\n",
       " 'Duration_Of_Agreement41_std_9999',\n",
       " 'Date_of_Request35_nuniq_7',\n",
       " 'Date_of_Request35_mode_30',\n",
       " 'Date_of_Request35_nuniq_30',\n",
       " 'Date_of_Request35_mode_90',\n",
       " 'Date_of_Request35_nuniq_90',\n",
       " 'Date_of_Request35_mode_360',\n",
       " 'Date_of_Request35_nuniq_360',\n",
       " 'Date_of_Request35_mode_9999',\n",
       " 'Date_of_Request35_nuniq_9999',\n",
       " 'Enquiry_Reason34_nuniq_7',\n",
       " 'Enquiry_Reason34_nuniq_30',\n",
       " 'Enquiry_Reason34_mode_90',\n",
       " 'Enquiry_Reason34_nuniq_90',\n",
       " 'Enquiry_Reason34_nuniq_360',\n",
       " 'Enquiry_Reason34_mode_9999',\n",
       " 'Enquiry_Reason34_nuniq_9999',\n",
       " 'Finance_Purpose35_mode_7',\n",
       " 'Finance_Purpose35_nuniq_7',\n",
       " 'Finance_Purpose35_mode_30',\n",
       " 'Finance_Purpose35_nuniq_30',\n",
       " 'Finance_Purpose35_mode_90',\n",
       " 'Finance_Purpose35_nuniq_90',\n",
       " 'Finance_Purpose35_mode_360',\n",
       " 'Finance_Purpose35_nuniq_360',\n",
       " 'Finance_Purpose35_mode_9999',\n",
       " 'Finance_Purpose35_nuniq_9999',\n",
       " 'Number_of_Major_Credit_Card_Held62_sum_7',\n",
       " 'Number_of_Major_Credit_Card_Held62_sum_9999',\n",
       " 'Income36_sum_9999',\n",
       " 'Marital_Status44_nuniq_7',\n",
       " 'Marital_Status44_nuniq_30',\n",
       " 'Marital_Status44_nuniq_90',\n",
       " 'Marital_Status44_nuniq_360',\n",
       " 'Marital_Status44_nuniq_9999',\n",
       " 'Current_Balance_Income_por',\n",
       " 'Current_Balance_Income_diff',\n",
       " 'CAPSLast180Days_nocrt_por',\n",
       " 'CAPSLast180Days_apply_por',\n",
       " 'Duesum_days_mean',\n",
       " 'Duesum_amt_mean',\n",
       " 'feature_1',\n",
       " 'feature_2',\n",
       " 'feature_3',\n",
       " 'feature_4',\n",
       " 'feature_5',\n",
       " 'feature_6',\n",
       " 'feature_7',\n",
       " 'feature_8',\n",
       " 'feature_9',\n",
       " 'feature_10',\n",
       " 'feature_11',\n",
       " 'feature_12',\n",
       " 'feature_13',\n",
       " 'feature_14',\n",
       " 'feature_15',\n",
       " 'feature_16',\n",
       " 'feature_17',\n",
       " 'feature_18',\n",
       " 'feature_19',\n",
       " 'feature_20',\n",
       " 'feature_21',\n",
       " 'feature_22',\n",
       " 'feature_23',\n",
       " 'feature_24',\n",
       " 'feature_25',\n",
       " 'feature_26',\n",
       " 'feature_27',\n",
       " 'feature_28',\n",
       " 'feature_29',\n",
       " 'feature_30',\n",
       " 'feature_31',\n",
       " 'feature_32',\n",
       " 'feature_33',\n",
       " 'feature_34',\n",
       " 'feature_35',\n",
       " 'feature_36',\n",
       " 'feature_37',\n",
       " 'feature_38',\n",
       " 'feature_39',\n",
       " 'feature_40',\n",
       " 'feature_41',\n",
       " 'feature_42',\n",
       " 'feature_43',\n",
       " 'feature_44',\n",
       " 'feature_45',\n",
       " 'feature_46',\n",
       " 'feature_47',\n",
       " 'feature_48',\n",
       " 'feature_49',\n",
       " 'feature_50',\n",
       " 'feature_51',\n",
       " 'feature_52',\n",
       " 'feature_53',\n",
       " 'feature_54',\n",
       " 'feature_55',\n",
       " 'feature_56',\n",
       " 'feature_57',\n",
       " 'feature_58',\n",
       " 'feature_59',\n",
       " 'feature_60',\n",
       " 'feature_61',\n",
       " 'feature_62',\n",
       " 'feature_63',\n",
       " 'feature_64',\n",
       " 'feature_65',\n",
       " 'feature_66',\n",
       " 'feature_67',\n",
       " 'feature_68',\n",
       " 'feature_69',\n",
       " 'feature_70',\n",
       " 'feature_71',\n",
       " 'feature_72',\n",
       " 'feature_73',\n",
       " 'feature_74',\n",
       " 'feature_75',\n",
       " 'feature_76',\n",
       " 'feature_77',\n",
       " 'feature_78',\n",
       " 'feature_79',\n",
       " 'feature_80',\n",
       " 'feature_81',\n",
       " 'feature_82',\n",
       " 'feature_83',\n",
       " 'feature_84',\n",
       " 'feature_85',\n",
       " 'feature_86',\n",
       " 'feature_87',\n",
       " 'feature_88',\n",
       " 'feature_89',\n",
       " 'feature_90',\n",
       " 'feature_91',\n",
       " 'feature_92',\n",
       " 'feature_93',\n",
       " 'feature_94',\n",
       " 'feature_95',\n",
       " 'feature_96',\n",
       " 'feature_97',\n",
       " 'feature_98',\n",
       " 'feature_99',\n",
       " 'feature_100',\n",
       " 'feature_101',\n",
       " 'feature_102',\n",
       " 'feature_103',\n",
       " 'feature_104',\n",
       " 'feature_105',\n",
       " 'feature_106',\n",
       " 'feature_107',\n",
       " 'feature_108',\n",
       " 'feature_109',\n",
       " 'feature_110',\n",
       " 'feature_111',\n",
       " 'feature_112',\n",
       " 'feature_113',\n",
       " 'feature_114',\n",
       " 'feature_115',\n",
       " 'feature_116',\n",
       " 'feature_117',\n",
       " 'feature_118',\n",
       " 'feature_119',\n",
       " 'feature_120',\n",
       " 'feature_121',\n",
       " 'feature_122',\n",
       " 'feature_123',\n",
       " 'feature_124',\n",
       " 'feature_125',\n",
       " 'feature_126',\n",
       " 'feature_127',\n",
       " 'feature_128',\n",
       " 'feature_129',\n",
       " 'feature_130',\n",
       " 'feature_131',\n",
       " 'feature_132',\n",
       " 'feature_133',\n",
       " 'feature_134',\n",
       " 'feature_135',\n",
       " 'feature_136',\n",
       " 'feature_137',\n",
       " 'feature_138',\n",
       " 'feature_139',\n",
       " 'feature_140',\n",
       " 'feature_141',\n",
       " 'feature_142',\n",
       " 'feature_143',\n",
       " 'feature_144',\n",
       " 'feature_145',\n",
       " 'feature_146',\n",
       " 'feature_147',\n",
       " 'feature_148',\n",
       " 'feature_149',\n",
       " 'feature_150',\n",
       " 'feature_151',\n",
       " 'feature_152',\n",
       " 'feature_153',\n",
       " 'feature_154',\n",
       " 'feature_155',\n",
       " 'feature_156',\n",
       " 'feature_157',\n",
       " 'feature_158',\n",
       " 'feature_159',\n",
       " 'feature_160',\n",
       " 'feature_161',\n",
       " 'feature_162',\n",
       " 'feature_163',\n",
       " 'feature_164',\n",
       " 'feature_165',\n",
       " 'feature_166',\n",
       " 'feature_167',\n",
       " 'feature_168',\n",
       " 'feature_169',\n",
       " 'feature_170',\n",
       " 'feature_171',\n",
       " 'feature_172',\n",
       " 'feature_173',\n",
       " 'feature_174',\n",
       " 'feature_175',\n",
       " 'feature_176',\n",
       " 'feature_177',\n",
       " 'feature_178',\n",
       " 'feature_179',\n",
       " 'feature_180',\n",
       " 'feature_181',\n",
       " 'feature_182',\n",
       " 'feature_183',\n",
       " 'feature_184',\n",
       " 'feature_185',\n",
       " 'feature_186',\n",
       " 'feature_187',\n",
       " 'feature_188',\n",
       " 'feature_189',\n",
       " 'feature_190',\n",
       " 'feature_191',\n",
       " 'feature_192',\n",
       " 'feature_193',\n",
       " 'feature_194',\n",
       " 'feature_195',\n",
       " 'feature_196',\n",
       " 'feature_197',\n",
       " 'feature_198',\n",
       " 'feature_199',\n",
       " 'feature_200',\n",
       " 'feature_201',\n",
       " 'feature_202',\n",
       " 'feature_203',\n",
       " 'feature_204',\n",
       " 'feature_205',\n",
       " 'feature_206',\n",
       " 'feature_207',\n",
       " 'feature_208',\n",
       " 'feature_209',\n",
       " 'feature_210',\n",
       " 'feature_211',\n",
       " 'feature_212',\n",
       " 'feature_213',\n",
       " 'feature_214',\n",
       " 'feature_215',\n",
       " 'feature_216',\n",
       " 'feature_217',\n",
       " 'feature_218',\n",
       " 'feature_219',\n",
       " 'feature_220',\n",
       " 'feature_221',\n",
       " 'feature_222',\n",
       " 'feature_223',\n",
       " 'feature_224',\n",
       " 'feature_225',\n",
       " 'feature_226',\n",
       " 'feature_227',\n",
       " 'feature_228',\n",
       " 'feature_229',\n",
       " 'feature_230',\n",
       " 'feature_231',\n",
       " 'feature_232',\n",
       " 'feature_233',\n",
       " 'feature_234',\n",
       " 'feature_235',\n",
       " 'feature_236',\n",
       " 'feature_237',\n",
       " 'feature_238',\n",
       " 'feature_239',\n",
       " 'feature_240',\n",
       " 'feature_241',\n",
       " 'feature_242',\n",
       " 'feature_243',\n",
       " 'feature_244',\n",
       " 'feature_245',\n",
       " 'feature_246',\n",
       " 'feature_247',\n",
       " 'feature_248',\n",
       " 'feature_249',\n",
       " 'feature_250',\n",
       " 'feature_251',\n",
       " 'feature_252',\n",
       " 'feature_253',\n",
       " 'feature_254',\n",
       " 'feature_255',\n",
       " 'feature_256',\n",
       " 'feature_257',\n",
       " 'feature_258',\n",
       " 'feature_259',\n",
       " 'feature_260',\n",
       " 'feature_261',\n",
       " 'feature_262',\n",
       " 'feature_263',\n",
       " 'feature_264',\n",
       " 'feature_265',\n",
       " 'feature_266',\n",
       " 'feature_267',\n",
       " 'feature_268',\n",
       " 'feature_269',\n",
       " 'feature_270',\n",
       " 'feature_271',\n",
       " 'feature_272',\n",
       " 'feature_273',\n",
       " 'feature_274',\n",
       " 'feature_275',\n",
       " 'feature_276',\n",
       " 'feature_277',\n",
       " 'feature_278',\n",
       " 'feature_279',\n",
       " 'feature_280',\n",
       " 'feature_281',\n",
       " 'feature_282',\n",
       " 'feature_283',\n",
       " 'feature_284',\n",
       " 'feature_285',\n",
       " 'feature_286',\n",
       " 'feature_287',\n",
       " 'feature_288',\n",
       " 'feature_289',\n",
       " 'feature_290',\n",
       " 'feature_291',\n",
       " 'feature_292',\n",
       " 'feature_293',\n",
       " 'feature_294',\n",
       " 'feature_295',\n",
       " 'feature_296',\n",
       " 'feature_297',\n",
       " 'feature_298',\n",
       " 'feature_299',\n",
       " 'feature_300',\n",
       " 'feature_301',\n",
       " 'feature_302',\n",
       " 'feature_303',\n",
       " 'feature_304',\n",
       " 'feature_305',\n",
       " 'feature_306',\n",
       " 'feature_307',\n",
       " 'feature_308',\n",
       " 'feature_309',\n",
       " 'feature_310',\n",
       " 'feature_311',\n",
       " 'feature_312',\n",
       " 'feature_313',\n",
       " 'feature_314',\n",
       " 'feature_315',\n",
       " 'feature_316',\n",
       " 'feature_317',\n",
       " 'feature_318',\n",
       " 'feature_319',\n",
       " 'feature_320',\n",
       " 'feature_321',\n",
       " 'feature_322',\n",
       " 'feature_323',\n",
       " 'feature_324',\n",
       " 'feature_325',\n",
       " 'feature_326',\n",
       " 'feature_327',\n",
       " 'feature_328',\n",
       " 'feature_329',\n",
       " 'feature_330',\n",
       " 'feature_331',\n",
       " 'feature_332',\n",
       " 'feature_333',\n",
       " 'feature_334',\n",
       " 'feature_335',\n",
       " 'feature_336',\n",
       " 'feature_337',\n",
       " 'feature_338',\n",
       " 'feature_339',\n",
       " 'feature_340',\n",
       " 'feature_341',\n",
       " 'feature_342',\n",
       " 'feature_343',\n",
       " 'feature_344',\n",
       " 'feature_345',\n",
       " 'feature_346',\n",
       " 'feature_347',\n",
       " 'feature_348',\n",
       " 'feature_349',\n",
       " 'feature_350',\n",
       " 'feature_351',\n",
       " 'feature_352',\n",
       " 'feature_353',\n",
       " 'feature_354',\n",
       " 'feature_355',\n",
       " 'feature_356',\n",
       " 'feature_357',\n",
       " 'feature_358',\n",
       " 'feature_359',\n",
       " 'feature_360',\n",
       " 'feature_361',\n",
       " 'feature_362',\n",
       " 'feature_363',\n",
       " 'feature_364',\n",
       " 'feature_365',\n",
       " 'feature_366',\n",
       " 'feature_367',\n",
       " 'feature_368',\n",
       " 'feature_369',\n",
       " 'feature_370',\n",
       " 'feature_371',\n",
       " 'feature_372',\n",
       " 'feature_373',\n",
       " 'feature_374',\n",
       " 'feature_375',\n",
       " 'feature_376',\n",
       " 'feature_377',\n",
       " 'feature_378',\n",
       " 'feature_379',\n",
       " 'feature_380',\n",
       " 'feature_381',\n",
       " 'feature_382',\n",
       " 'feature_383',\n",
       " 'feature_384',\n",
       " 'feature_385',\n",
       " 'feature_386',\n",
       " 'feature_387',\n",
       " 'feature_388',\n",
       " 'feature_389',\n",
       " 'feature_390',\n",
       " 'feature_391',\n",
       " 'feature_392',\n",
       " 'feature_393',\n",
       " 'feature_394',\n",
       " 'feature_395',\n",
       " 'feature_396',\n",
       " 'feature_397',\n",
       " 'feature_398',\n",
       " 'feature_399',\n",
       " 'feature_400',\n",
       " 'feature_401',\n",
       " 'feature_402',\n",
       " 'feature_403',\n",
       " 'feature_404',\n",
       " 'feature_405',\n",
       " 'feature_406',\n",
       " 'feature_407',\n",
       " 'feature_408',\n",
       " 'feature_409',\n",
       " 'feature_410',\n",
       " 'feature_411',\n",
       " 'feature_412',\n",
       " 'feature_413',\n",
       " 'feature_414',\n",
       " 'feature_415',\n",
       " 'feature_416',\n",
       " 'feature_417',\n",
       " 'feature_418',\n",
       " 'feature_419',\n",
       " 'feature_420',\n",
       " 'feature_421',\n",
       " 'feature_422',\n",
       " 'feature_423',\n",
       " 'feature_424',\n",
       " 'feature_425',\n",
       " 'feature_426',\n",
       " 'feature_427',\n",
       " 'feature_428',\n",
       " 'feature_429',\n",
       " 'feature_430',\n",
       " 'feature_431',\n",
       " 'feature_432',\n",
       " 'feature_433',\n",
       " 'feature_434',\n",
       " 'feature_435',\n",
       " 'feature_436',\n",
       " 'feature_437',\n",
       " 'feature_438',\n",
       " 'feature_439',\n",
       " 'feature_440',\n",
       " 'feature_441',\n",
       " 'feature_442',\n",
       " 'feature_443',\n",
       " 'feature_444',\n",
       " 'feature_445',\n",
       " 'feature_446',\n",
       " 'feature_447',\n",
       " 'feature_448',\n",
       " 'feature_449',\n",
       " 'feature_450',\n",
       " 'feature_451',\n",
       " 'feature_452',\n",
       " 'feature_453',\n",
       " 'feature_454',\n",
       " 'feature_455',\n",
       " 'feature_456',\n",
       " 'feature_457',\n",
       " 'feature_458',\n",
       " 'feature_459',\n",
       " 'feature_460',\n",
       " 'feature_461',\n",
       " 'feature_462',\n",
       " 'feature_463',\n",
       " 'feature_464',\n",
       " 'feature_465',\n",
       " 'feature_466',\n",
       " 'feature_467',\n",
       " 'feature_468',\n",
       " 'feature_469',\n",
       " 'feature_470',\n",
       " 'feature_471',\n",
       " 'feature_472',\n",
       " 'feature_473',\n",
       " 'feature_474',\n",
       " 'feature_475',\n",
       " 'feature_476',\n",
       " 'feature_477',\n",
       " 'feature_478',\n",
       " 'feature_479',\n",
       " 'feature_480',\n",
       " 'feature_481',\n",
       " 'feature_482',\n",
       " 'feature_483',\n",
       " 'feature_484',\n",
       " 'feature_485',\n",
       " 'feature_486',\n",
       " 'feature_487',\n",
       " 'feature_488',\n",
       " 'feature_489',\n",
       " 'feature_490',\n",
       " 'feature_491',\n",
       " 'feature_492',\n",
       " 'feature_493',\n",
       " 'feature_494',\n",
       " 'feature_495',\n",
       " 'feature_496',\n",
       " 'feature_497',\n",
       " 'feature_498',\n",
       " 'feature_499',\n",
       " 'feature_500',\n",
       " 'feature_501',\n",
       " 'feature_502',\n",
       " 'feature_503',\n",
       " 'feature_504',\n",
       " 'feature_505',\n",
       " 'feature_506',\n",
       " 'feature_507',\n",
       " 'feature_508',\n",
       " 'feature_509',\n",
       " 'feature_510',\n",
       " 'feature_511',\n",
       " 'feature_512',\n",
       " 'feature_513',\n",
       " 'feature_514',\n",
       " 'feature_515',\n",
       " 'feature_516',\n",
       " 'feature_517',\n",
       " 'feature_518',\n",
       " 'feature_519',\n",
       " 'feature_520',\n",
       " 'feature_521',\n",
       " 'feature_522',\n",
       " 'feature_523',\n",
       " 'feature_524',\n",
       " 'feature_525',\n",
       " 'feature_526',\n",
       " 'feature_527',\n",
       " 'feature_528',\n",
       " 'feature_529',\n",
       " 'feature_530',\n",
       " 'feature_531',\n",
       " 'feature_532',\n",
       " 'feature_533',\n",
       " 'feature_534',\n",
       " 'feature_535',\n",
       " 'feature_536',\n",
       " 'feature_537',\n",
       " 'feature_538',\n",
       " 'feature_539',\n",
       " 'feature_540',\n",
       " 'feature_541',\n",
       " 'feature_542',\n",
       " 'feature_543',\n",
       " 'feature_544',\n",
       " 'feature_545',\n",
       " 'feature_546',\n",
       " 'feature_547',\n",
       " 'feature_548',\n",
       " 'feature_549',\n",
       " 'feature_550',\n",
       " 'feature_551',\n",
       " 'feature_552',\n",
       " 'feature_553',\n",
       " 'feature_554',\n",
       " 'feature_555',\n",
       " 'feature_556',\n",
       " 'feature_557',\n",
       " 'feature_558',\n",
       " 'feature_559',\n",
       " 'feature_560',\n",
       " 'feature_561',\n",
       " 'feature_562',\n",
       " 'feature_563',\n",
       " 'feature_564',\n",
       " 'feature_565',\n",
       " 'feature_566',\n",
       " 'feature_567',\n",
       " 'feature_568',\n",
       " 'feature_569',\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params={'boosting_type': 'dart', 'max_depth': 11, 'n_estimators': 1010, 'learning_rate': 0.2896725270248636, 'num_leaves': 1144, 'class_weight': None, 'reg_alpha': 4.215612812184543, 'reg_lambda': 0.44772383819316397, 'subsample_for_bin': 220000, 'subsample': 0.8562357844168368, 'feature_fraction': 0.4775606601751762, 'min_child_samples': 10, 'min_child_weight': 0.00011360202014521585, 'min_split_gain': 6.008916845569482, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "\n",
    "clf = LGBMClassifier(**best_params)\n",
    "clf.fit(train_x, train_y,\n",
    "        eval_set=[(test_x,test_y)],\n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=50,verbose=-1)\n",
    "\n",
    "print('------------train------------\\n',model_metrics(clf, train_x,train_y))\n",
    "\n",
    "\n",
    "print('------------test------------\\n',model_metrics(clf, test_x,test_y))\n",
    "\n",
    "print('------------oot------------\\n',model_metrics(clf, oot_x,oot_y))\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "# pickle.dump(clf, open('./saved_models/SMS_ZX_NSMS.pkl', 'wb'))\n",
    "# pickle.dump(clf, open('./saved_models/ZX_NSMS.pkl', 'wb'))\n",
    "# pickle.dump(clf, open('./saved_models/SMS_NSMS.pkl', 'wb'))\n",
    "\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "# model = pickle.load(open('./saved_models/SMS_ZX_NSMS.pkl', 'rb'))\n",
    "\n",
    "model.feature_name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3622ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66328721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaa77fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "178a1ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1761"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.feature_name_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1bc7bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25791da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "0407######################################################################征信模型v2\n",
    "#### 纯征信nocate\n",
    "best_params= {'boosting_type': 'gbdt', 'max_depth': 11, 'n_estimators': 1730, 'learning_rate': 0.1291868482369266, 'num_leaves': 1584, 'class_weight': None, 'reg_alpha': 4.191420786845277, 'reg_lambda': 8.571864740877707, 'subsample_for_bin': 120000, 'subsample': 0.24917130389729128, 'feature_fraction': 0.2502338763355014, 'min_child_samples': 21, 'min_child_weight': 11.029313629457622, 'min_split_gain': 1.4021163489891033, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "------------oot------------\n",
    " 0.5524426835343319\n",
    "feature\tgain\tsplit\n",
    "232\tDate_of_Last_Payment40_min_9999\t212.067219\t13\n",
    "279\tMonth50_mean_90\t150.353552\t14\n",
    "398\tDate_of_Request35_mode_9999\t107.792249\t25\n",
    "394\tDate_of_Request35_mode_90\t94.797440\t25\n",
    "225\tDate_of_Last_Payment40_max_360\t91.386570\t22\n",
    "\n",
    "####纯非短信\n",
    "{'boosting_type': 'dart', 'max_depth': 9, 'n_estimators': 180, 'learning_rate': 0.5743342145344562, 'num_leaves': 1688, 'class_weight': None, 'reg_alpha': 2.835217636179232, 'reg_lambda': 4.9760732788644075, 'subsample_for_bin': 220000, 'subsample': 0.2568609211119177, 'feature_fraction': 0.3896673716718368, 'min_child_samples': 35, 'min_child_weight': 2.459470973780215, 'min_split_gain': 4.0201798822125765, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "------------train------------\n",
    " 0.7827683736266859\n",
    "------------test------------\n",
    " 0.7191583388851877\n",
    "------------oot------------\n",
    " 0.7104102225466005\n",
    "feature\tgain\tsplit\n",
    "1\tfeature_2\t1818.608220\t94\n",
    "644\tfeature_645\t112.530722\t3\n",
    "761\tfeature_762\t111.568910\t18\n",
    "253\tfeature_254\t92.183211\t13\n",
    "780\tfeature_781\t82.409350\t15\n",
    " \n",
    "####全旧短信模型\n",
    "{'boosting_type': 'dart', 'max_depth': 11, 'n_estimators': 1010, 'learning_rate': 0.2896725270248636, 'num_leaves': 1144, 'class_weight': None, 'reg_alpha': 4.215612812184543, 'reg_lambda': 0.44772383819316397, 'subsample_for_bin': 220000, 'subsample': 0.8562357844168368, 'feature_fraction': 0.4775606601751762, 'min_child_samples': 10, 'min_child_weight': 0.00011360202014521585, 'min_split_gain': 6.008916845569482, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "------------train------------\n",
    " 0.7611966926084524\n",
    "------------test------------\n",
    " 0.7172573839662447\n",
    "------------oot------------\n",
    " 0.7184327899998841\n",
    "feature\tgain\tsplit\n",
    "1\tfeature_2\t1017.962109\t9\n",
    "147\tfeature_148\t63.685699\t1\n",
    "253\tfeature_254\t40.906101\t1\n",
    "644\tfeature_645\t33.428999\t2\n",
    "322\tfeature_323\t26.262199\t1\n",
    "\n",
    "####纯短信模型\n",
    "{'boosting_type': 'goss', 'max_depth': 21, 'n_estimators': 1490, 'learning_rate': 0.21930551278322413, 'num_leaves': 1800, 'class_weight': 'balanced', 'reg_alpha': 8.067758774301975, 'reg_lambda': 5.5502301875718985, 'subsample_for_bin': 120000, 'subsample': 0.45881373515492696, 'feature_fraction': 0.4266373931982871, 'min_child_samples': 380, 'min_child_weight': 0.07111103164297841, 'min_split_gain': 2.3939541961285906, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "------------oot------------\n",
    " 0.5705453028881242\n",
    "feature\tgain\tsplit\n",
    "221\tfeature_1200_sms\t67.078499\t1\n",
    "244\tfeature_1223_sms\t63.761200\t1\n",
    "300\tfeature_1279_sms\t56.925898\t2\n",
    "113\tfeature_1092_sms\t55.080101\t1\n",
    "210\tfeature_1189_sms\t42.302898\t1\n",
    " \n",
    "####征信+非短信\n",
    "{'boosting_type': 'gbdt', 'max_depth': 8, 'n_estimators': 750, 'learning_rate': 0.1296823658012421, 'num_leaves': 688, 'class_weight': 'balanced', 'reg_alpha': 5.074138878618853, 'reg_lambda': 7.598729510431946, 'subsample_for_bin': 180000, 'subsample': 0.6760794529948264, 'feature_fraction': 0.2947031809327042, 'min_child_samples': 16, 'min_child_weight': 0.21358223805839294, 'min_split_gain': 3.873755769678977, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "best_params2={'boosting_type': 'dart', 'max_depth': 11, 'n_estimators': 1010, 'learning_rate': 0.2896725270248636, 'num_leaves': 1144, 'class_weight': None, 'reg_alpha': 4.215612812184543, 'reg_lambda': 0.44772383819316397, 'subsample_for_bin': 220000, 'subsample': 0.8562357844168368, 'feature_fraction': 0.4775606601751762, 'min_child_samples': 10, 'min_child_weight': 0.00011360202014521585, 'min_split_gain': 6.008916845569482, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "------------train------------\n",
    " (0.7757365457020085, 0.40966377198842124)\n",
    "------------test------------\n",
    " (0.727230735065512, 0.35149900066622247)\n",
    "------------oot------------\n",
    " (0.7249412064551257, 0.3437111180620721)\n",
    "feature\tgain\tsplit\n",
    "432\tfeature_2\t13061.886389\t717\n",
    "91\tPayment_Rating34_mean_9999\t1377.554522\t153\n",
    "63\tHighest_Credit_or_Original_Loan_Amount58_sum_9999\t1009.247422\t126\n",
    "232\tDate_of_Last_Payment40_min_9999\t759.438452\t81\n",
    "684\tfeature_254\t715.694582\t76\n",
    " \n",
    "####征信+非短信+删feature2\n",
    "------------oot------------\n",
    " (0.6444050556656125, 0.23184930316616276)\n",
    "###仅feature2\n",
    "------------oot------------\n",
    " 0.6585664801492139\n",
    "\n",
    "####征信+旧模型全量特征\n",
    "{'boosting_type': 'dart', 'class_weight': None, 'feature_fraction': 0.5292621851563598, 'learning_rate': 0.23938665909933876, 'max_depth': 14, 'min_child_samples': 91, 'min_child_weight': 0.13614638467767243, 'min_split_gain': 3.983261344288425, 'n_estimators': 2110, 'num_leaves': 736, 'reg_alpha': 6.683254293882608, 'reg_lambda': 9.003622043307438, 'subsample': 0.8646544005048526, 'subsample_for_bin': 340000, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "------------train------------\n",
    " 0.7969966275001877\n",
    "------------test------------\n",
    " 0.7310259826782145\n",
    "------------oot------------\n",
    " 0.7241094081256734\n",
    "    \tfeature\tgain\tsplit\n",
    "432\tfeature_2\t13278.014326\t1026\n",
    "91\tPayment_Rating34_mean_9999\t2055.987793\t325\n",
    "63\tHighest_Credit_or_Original_Loan_Amount58_sum_9999\t1120.851019\t194\n",
    "684\tfeature_254\t1081.867901\t151\n",
    "434\tfeature_4\t981.386679\t162\n",
    "1666\tfeature_1236_sms\t924.502141\t145\n",
    "232\tDate_of_Last_Payment40_min_9999\t865.378960\t122\n",
    "--focal loss 0.7279370706333484\n",
    "--稀疏增强：0.727281363315145\n",
    "--lgb +cate 0.71 firstnm过拟合\n",
    "--lgb+孤立森林 0.7241719667744064\n",
    "--autoglun 0.7300130909764941 0.3458033573141487\n",
    "--DNN ['bestval, layer_nums, k, norm', 0.6422467822843174, 2, 18, 0.01]\n",
    "--lgb_DNN\n",
    "--transformer(0.6019485860586893, 0.1655510374309248)\n",
    "--tabnet 1 1 7 (0.6177689732272154, 0.18599381364473638)\n",
    "0327######################################################################征信模型v1\n",
    "------------train------------\n",
    " 0.5955648848848103\n",
    "------------test------------\n",
    " 0.6020843981653152\n",
    "------------oot------------\n",
    " 0.5509538161177687   0.5572\n",
    " \n",
    " feature\tgain\tsplit\n",
    "75\tPayment_Rating34_mean_9999\t49.402302\t1\n",
    "17\tOutstanding_Balance_All\t18.478901\t1\n",
    "288\tDuesum51_max_360\t17.084700\t1\n",
    "57\tHighest_Credit_or_Original_Loan_Amount58_sum_9999\t13.311400\t1\n",
    "201\tDate_of_Last_Payment40_min_9999\t13.146600\t1\n",
    "\n",
    "############原短信模型\n",
    "------------train------------\n",
    " 0.7120853595132949\n",
    "------------test------------\n",
    " 0.6249807618958398\n",
    "------------oot------------\n",
    " 0.5929736057969629\n",
    " \n",
    "feature\tgain\tsplit\n",
    "1091\tfeature_1092_sms\t56.609210\t4\n",
    "637\tfeature_638\t52.878950\t3\n",
    "1195\tfeature_1196_sms\t52.133701\t3\n",
    "255\tfeature_256\t50.603701\t2\n",
    "147\tfeature_148\t39.322701\t1\n",
    "\n",
    "############## all feas 征信\n",
    "------------train------------\n",
    " 0.7853083217441518\n",
    "------------test------------\n",
    " 0.6151015121696859\n",
    "------------oot------------\n",
    " 0.5476976322696694\n",
    " \n",
    "feature\tgain\tsplit\n",
    "119\tHighest_Credit_or_Original_Loan_Amount58_sum_9999\t507.115121\t115\n",
    "121\tHighest_Credit_or_Original_Loan_Amount58_max_9999\t380.598070\t94\n",
    "1256\tDuesum_days_mean\t289.224108\t77\n",
    "689\tDate_of_Last_Payment40_min_9999\t287.205211\t74\n",
    "10\tFirst_Name1\t268.579750\t54\n",
    "\n",
    "#### no cate\n",
    "------------train------------\n",
    " 0.6136383342685391\n",
    "------------test------------\n",
    " 0.5851689136991731\n",
    "------------oot------------\n",
    " 0.5700932824995477  0.576\n",
    "\n",
    "feature\tgain\tsplit\n",
    "75\tPayment_Rating34_mean_9999\t58.121599\t2  \n",
    "286\tDuesum51_sum_360\t28.412300\t1\n",
    "57\tHighest_Credit_or_Original_Loan_Amount58_sum_9999\t26.575100\t1\n",
    "187\tDate_Closed31_min_9999\t14.249900\t1\n",
    "18\tOutstanding_Balance_UnSecured\t13.894300\t1\n",
    "201\tDate_of_Last_Payment40_min_9999\t13.299500\t1\n",
    "279\tDuecount53_max_9999\t8.855690\t1\n",
    "21\tBirth_nuniq\t7.208710\t1\n",
    "0\tBureauScore\t0.000000\t0\n",
    "{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'feature_fraction': 0.8627221849600804, 'learning_rate': 0.34384893394376054, 'max_depth': 11, 'min_child_samples': 1198, 'min_child_weight': 0.003952236654749962, 'min_split_gain': 0.05949040934772148, 'n_estimators': 600, 'num_leaves': 688, 'reg_alpha': 3.5594821118603353, 'reg_lambda': 0.602149615246626, 'subsample': 0.8276897177180422, 'subsample_for_bin': 240000, 'n_jobs': -1, 'objective': 'binary', 'silent': True, 'verbose': -1, 'random_state': 0}\n",
    "#### catst cat\n",
    "------------train------------\n",
    " 0.7142082720221239\n",
    "------------test------------\n",
    " 0.6097048242750667\n",
    "------------oot------------\n",
    " 0.5540017953382643\n",
    " \tfeature\tgain\tsplit\n",
    "55\tHighest_Credit_or_Original_Loan_Amount58_sum_9999\t96.336401\t4\n",
    "73\tPayment_Rating34_mean_9999\t85.414260\t6\n",
    "374\tFirst_Name1_cb\t55.024140\t7\n",
    "72\tPayment_Rating34_sum_9999\t44.194199\t1\n",
    "268\tDuecount53_std_90\t43.439360\t4\n",
    " ------------train------------\n",
    " 0.6576732034576184\n",
    "------------test------------\n",
    " 0.596752167506254\n",
    "------------oot------------\n",
    " 0.5608230567852523\n",
    " 55\tHighest_Credit_or_Original_Loan_Amount58_sum_9999\t390.087529\t64\n",
    "20\tOutstanding_Balance_UnSecured\t341.853791\t59\n",
    "73\tPayment_Rating34_mean_9999\t301.705399\t53\n",
    "276\tDuecount53_max_9999\t212.709760\t39\n",
    "72\tPayment_Rating34_sum_9999\t203.015642\t3\n",
    " \n",
    "###征信+全旧特征  \n",
    "------------best_params------------ {'boosting_type': 'dart', 'class_weight': None, 'feature_fraction': 0.991392744378254, 'learning_rate': 0.4510972062848847, 'max_depth': 7, 'min_child_samples': 3, 'min_child_weight': 0.06580338317188161, 'min_split_gain': 3.521483184411901, 'n_estimators': 620, 'num_leaves': 536, 'reg_alpha': 3.7218762172324906, 'reg_lambda': 3.473122296406963, 'subsample': 0.47024140562740857, 'subsample_for_bin': 300000, 'n_jobs': -1, 'objective': 'binary', 'silent': True, 'verbose': -1, 'random_state': 0}\n",
    "------------train------------\n",
    " 0.8271731112970069\n",
    "------------test------------\n",
    " 0.612970887668147\n",
    "------------oot------------2.2%提升\n",
    " 0.6150194039886545\n",
    "\n",
    "66\tPayment_Rating34_mean_9999\t874.495518\t127\n",
    "1552\tfeature_1196_sms\t466.063108\t78\n",
    "49\tHighest_Credit_or_Original_Loan_Amount58_max_9999\t416.588179\t71\n",
    "364\tfeature_8\t414.652489\t60\n",
    "178\tDate_of_Last_Payment40_min_360\t323.697860\t54\n",
    "\n",
    "####征信+非短信\n",
    "{'boosting_type': 'dart', 'class_weight': 'balanced', 'feature_fraction': 0.17995978970954704, 'learning_rate': 0.07690886698935129, 'max_depth': 14, 'min_child_samples': 3, 'min_child_weight': 35.61164739586946, 'min_split_gain': 1.702474867184973, 'n_estimators': 120, 'num_leaves': 1904, 'reg_alpha': 6.286057155945472, 'reg_lambda': 5.4600895052199885, 'subsample': 0.2767001565456063, 'subsample_for_bin': 320000, 'n_jobs': -1, 'objective': 'binary', 'silent': True, 'verbose': -1, 'random_state': 0}\n",
    "------------train------------\n",
    " 0.7832807147506298\n",
    "------------test------------\n",
    " 0.6358589213031557\n",
    "------------oot------------2.1%提升\n",
    " 0.6114492066038413\n",
    " feature\tgain\tsplit\n",
    "610\tfeature_254\t275.991280\t18\n",
    "66\tPayment_Rating34_mean_9999\t246.923480\t23\n",
    "13\tOutstanding_Balance_UnSecured\t207.914050\t16\n",
    "502\tfeature_146\t196.294701\t14\n",
    "358\tfeature_2\t181.366581\t17\n",
    "{'boosting_type': 'dart', 'class_weight': 'balanced', 'feature_fraction': 0.6321724090841454, 'learning_rate': 0.35706456691656796, 'max_depth': 12, 'min_child_samples': 2, 'min_child_weight': 0.002290570255954292, 'min_split_gain': 1.23684757609968, 'n_estimators': 1700, 'num_leaves': 1640, 'reg_alpha': 8.94729123569297, 'reg_lambda': 7.85980599994622, 'subsample': 0.7809264483077517, 'subsample_for_bin': 20000, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "------------train------------\n",
    " 0.8414409134323174\n",
    "------------test------------\n",
    " 0.6170694712311154\n",
    "------------oot------------\n",
    " 0.6172994153204474][base]\n",
    " \n",
    "####纯非短信\n",
    "------------train------------\n",
    " 0.7256212490982487\n",
    "------------test------------\n",
    " 0.6035682530527892\n",
    "------------oot------------\n",
    " 0.6027984749864326\n",
    " \n",
    " ------------train------------\n",
    " 0.6423776717894365\n",
    "------------test------------\n",
    " 0.6160434794366807\n",
    "------------oot------------\n",
    " 0.5935999262750826\n",
    " \n",
    " \tfeature\tgain\tsplit\n",
    "252\tfeature_253\t67.532101\t2\n",
    "255\tfeature_256\t57.024399\t2\n",
    "7\tfeature_8\t38.250450\t4\n",
    "1\tfeature_2\t31.335800\t2\n",
    "3\tfeature_4\t28.566200\t2\n",
    "\n",
    "####纯短信\n",
    "------------train------------\n",
    " 0.6513204252509733\n",
    "------------test------------\n",
    " 0.5819320469286919\n",
    "------------oot------------\n",
    " 0.5721036517726407\n",
    "\tfeature\tgain\tsplit\n",
    "113\tfeature_1092_sms\t30.375099\t2\n",
    "34\tfeature_1013_sms\t22.397099\t2\n",
    "265\tfeature_1244_sms\t19.532010\t2\n",
    "257\tfeature_1236_sms\t17.757660\t2\n",
    "189\tfeature_1168_sms\t11.141960\t2\n",
    "\n",
    "######### 征信+非短信优化验证\n",
    "###ft50-filtert\n",
    " 0.6107017178588373\n",
    "--- ft60-nofilt\n",
    " ------------train------------\n",
    " 0.7776614271344713\n",
    "------------test------------\n",
    " 0.6380635077328068\n",
    "------------oot------------\n",
    " 0.6180195985405197\n",
    "2464\tfeature_2_+_Payment_Rating34_mean_9999\t71.528502\t2\n",
    "2259\tDuesum51_sum_360_+_feature_254\t66.058098\t1\n",
    "2260\tDuesum51_sum_360_+_feature_322\t58.763901\t1\n",
    "3492\tBureauScore_/_feature_254\t56.664170\t2\n",
    "3420\tBirth_nuniq_/_Email_nuniq2\t37.157701\t2\n",
    "--ft60-filter\n",
    " 0.6087835047323888\n",
    "### focal loss+lgb\n",
    "\n",
    "\n",
    "### qcut4+oh + lgb\n",
    "------------oot------------\n",
    " 0.6169734556165758\n",
    "feature\tgain\tsplit\n",
    "66\tPayment_Rating34_mean_9999\t1414.136241\t181\n",
    "501\tfeature_145\t998.096571\t120\n",
    "65\tPayment_Rating34_sum_9999\t925.031363\t123\n",
    "358\tfeature_2\t854.604890\t108\n",
    "16\tBirth_nuniq\t550.947980\t76\n",
    "### 征信+旧特征+qcut4+DNN\n",
    "隐藏层vs神经元数vs norm 1 60 0.01\n",
    "验证集最优结果： 1.0151114463806152 1.0118298530578613\n",
    "------------train------------\n",
    " (0.6183410050043374, 0.1792503681475925)\n",
    "------------test------------\n",
    " (0.6012399560179311, 0.16452676985536663)\n",
    "------------oot------------\n",
    " (0.6188490038603186, 0.17209307088172954)\n",
    " --qcut50 15847cols\n",
    " ['bestval, layer_nums, k, norm', 0.6226751905413662, 1, 22, 0.01]\n",
    "### 征信+旧特征+ DNN\n",
    "oot参与搜索参数： 隐藏层vs神经元数vs norm 1 12 0.01\n",
    "验证集最优结果： 0.6594440937042236 0.6678001284599304\n",
    "------------train------------\n",
    " (0.6623875104578614, 0.2434398723137574)\n",
    "------------test------------\n",
    " (0.6166708957117484, 0.19025966336801153)\n",
    "------------oot------------\n",
    " (0.6311501428420273, 0.21031397940480784)\n",
    " --pytorch_tabular-dnn-transformer纯oot: 0.60\n",
    " --AutoGluon 21models--纯oot:0.6290817493284547 0.21659425013908756\n",
    "{'roc_auc': 0.6290817493284547, 'accuracy': 0.6513274336283186, 'balanced_accuracy': 0.5299661070171786, 'mcc': 0.1139253842762341, 'f1': 0.7786516853932586, 'precision': 0.6581196581196581, 'recall': 0.953232462173315}\n",
    "### 征信+旧特征+LGB+DNN\n",
    "base LGB 0.617 \n",
    "--DNN oot参与搜索参数：['bestval, layer_nums, k, norm', 0.6285083333048902, 1, 40, 0.4]\n",
    "--tabnet  oot参与搜索参数0.59：nd,nd,ns1, 1, 7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bf671d",
   "metadata": {},
   "source": [
    "#### 评分卡分数分布 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08dd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame()\n",
    "res_df['score'] = clf.predict_proba(x)[:,1]*100\n",
    "res_df['y'] = y\n",
    "\n",
    "\n",
    "#分数区间计算\n",
    "score_bin = np.arange(10,100,10)\n",
    "good_total = sum(res_df.y == 0)\n",
    "bad_total = sum(res_df.y == 1)\n",
    "bin_rate = []\n",
    "bad_rate = []\n",
    "ks = []\n",
    "good_num = []\n",
    "bad_num = []\n",
    "for i in range(len(score_bin)-1):\n",
    "    #取出分数区间的样本\n",
    "    if score_bin[i+1] == 61:\n",
    "        index_1 = (res_df.score >= score_bin[i]) & (res_df.score <= score_bin[i+1]) \n",
    "    else:\n",
    "        index_1 = (res_df.score >= score_bin[i]) & (res_df.score < score_bin[i+1]) \n",
    "    res_df_temp = res_df.loc[index_1,['y','score']]\n",
    "    #计算该分数区间的指标\n",
    "    good_num.append(sum(res_df_temp.y==0))\n",
    "    bad_num.append(sum(res_df_temp.y==1))\n",
    "    #区间样本率\n",
    "    bin_rate.append(res_df_temp.shape[0]/res_df.shape[0]*100)\n",
    "    #坏样本率\n",
    "    bad_rate.append(res_df_temp.y.sum()/res_df_temp.shape[0]*100)\n",
    "    #以该分数为注入分数的ks值\n",
    "    ks.append(sum(bad_num[0:i+1])/bad_total - sum(good_num[0:i+1])/good_total )\n",
    "res_df_result = pd.DataFrame({'好信用数量':good_num,'坏信用数量':bad_num,'区间样本率':bin_rate,\n",
    "                            '坏信用率':bad_rate,'KS值(真正率-假正率)':ks},index=zip( (score_bin[1:] -10 ),(score_bin[1:]  )) )\n",
    "print('评分卡10个区间分数统计结果如下：')\n",
    "res_df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ef1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c1edb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2802dde2",
   "metadata": {},
   "source": [
    "#### 暴力加工ft top50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880df4dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "start3\n",
      "['Account_Type32_mode_360vcount', 'Amount_Financed35_mean_90', 'Amount_Past_Due35_max_360', 'Amount_Past_Due35_mean_9999', 'Birth_nuniq', 'BureauScore', 'CAPSLast180Days_nocrt_por', 'Current_Balance35_sum_9999', 'Date_of_Last_Payment40_max_360', 'Date_of_Last_Payment40_mean_360', 'Date_of_Request35_mode_90', 'Date_of_Request35_mode_9999', 'Duecount53_sum_9999', 'Duesum51_max_360', 'Duration_Of_Agreement41_sum_9999', 'Email_nuniq', 'Email_nuniq2', 'Highest_Credit_or_Original_Loan_Amount58_max_9999', 'Highest_Credit_or_Original_Loan_Amount58_std_90', 'Highest_Credit_or_Original_Loan_Amount58_sum_9999', 'Name_nuniq2', 'Outstanding_Balance_UnSecured', 'Payment_Rating34_mean_9999', 'Rate_of_Interest36_min_9999', 'Tel_nuniq2', 'feature_2', 'feature_254', 'feature_322', 'feature_329', 'feature_4', 'feature_407', 'feature_409', 'feature_410', 'feature_638', 'feature_643', 'feature_669', 'feature_700', 'feature_701', 'feature_702', 'feature_710', 'feature_762', 'feature_778', 'feature_779', 'feature_781', 'feature_8', 'feature_804', 'feature_846', 'feature_874', 'feature_888', 'feature_9']\n",
      "Built 6175 features\n",
      "EntitySet scattered to 16 workers in 4 seconds\n",
      "Elapsed: 00:12 | Progress: 100%|██████████\n",
      "(6506, 6175)\n",
      "1246    0.734251\n",
      "6281    0.732211\n",
      "472     0.725835\n",
      "4355    0.671640\n",
      "5275    0.665519\n",
      "          ...   \n",
      "152     0.014665\n",
      "5783    0.014410\n",
      "5733    0.014410\n",
      "1471    0.014282\n",
      "414     0.014155\n",
      "Length: 6506, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "feature_10     0.990317\n",
       "feature_527    0.989702\n",
       "feature_528    0.989702\n",
       "feature_532    0.989702\n",
       "feature_531    0.989702\n",
       "feature_533    0.989548\n",
       "feature_529    0.989548\n",
       "feature_530    0.989394\n",
       "feature_534    0.989394\n",
       "feature_538    0.988933\n",
       "feature_524    0.988933\n",
       "feature_526    0.987396\n",
       "feature_540    0.987396\n",
       "feature_521    0.986474\n",
       "feature_535    0.986474\n",
       "feature_522    0.986013\n",
       "feature_536    0.986013\n",
       "feature_537    0.985706\n",
       "feature_523    0.985706\n",
       "feature_539    0.983861\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single [('feature_7', 1.0), ('feature_13', 1.0), ('feature_14', 1.0), ('feature_17', 1.0), ('feature_264', 1.0), ('feature_265', 1.0), ('feature_266', 1.0), ('feature_267', 1.0), ('feature_268', 1.0), ('feature_269', 1.0), ('feature_270', 1.0), ('feature_271', 1.0), ('feature_327', 1.0), ('feature_328', 1.0), ('feature_338', 1.0), ('feature_339', 1.0), ('feature_341', 1.0), ('feature_342', 1.0), ('feature_361', 1.0), ('feature_362', 1.0)]\n",
      "varance feature_552                                0.0\n",
      "feature_1300_sms                           0.0\n",
      "feature_327                                0.0\n",
      "feature_547                                0.0\n",
      "feature_548                                0.0\n",
      "                                          ... \n",
      "CAPSLast180Days_nocrt_por - feature_804    NaN\n",
      "CAPSLast180Days_nocrt_por - feature_846    NaN\n",
      "CAPSLast180Days_nocrt_por - feature_874    NaN\n",
      "CAPSLast180Days_nocrt_por - feature_888    NaN\n",
      "CAPSLast180Days_nocrt_por - feature_9      NaN\n",
      "Length: 7822, dtype: float64\n",
      "miss_drop 21\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZTElEQVR4nO3deZAc9X338fd3Znf21h5oda2OlUAXkS2E10C4DAgwUVyGOIljEhLZgSjxiXH8pHCRSlzPk0olLsfluMpxItsk2Oax/ZiYQCgM5vQRTgkW3fe5K6320t47s3P8nj9mFq1WWml35+jpnc+ramp6elr9+3bXzGdbv+n+tTnnEBER/wl4XYCIiEyPAlxExKcU4CIiPqUAFxHxKQW4iIhPFeWysdmzZ7vGxsZcNiki4ntbt27tdM7Vj5+f0wBvbGxky5YtuWxSRMT3zOzo+earC0VExKcU4CIiPqUAFxHxKQW4iIhPXTTAzexhM2s3sx1j5tWZ2XNmtj/1XJvdMkVEZLzJHIH/B3DHuHkPAi8455YDL6Rei4hIDl00wJ1zvwS6x82+E3gkNf0IcFdmyxIRkYuZbh/4XOfcydR0GzA3Q/WIiMwo+07187Xn9tHeH874utP+EdMlBxSfcFBxM9tkZlvMbEtHR0e6zYmI+ErzsR6+8cJ+wiOJjK97ugF+yszmA6Se2yda0Dm32TnX5Jxrqq8/50pQEZEZ7aW97QQM5swqyfi6pxvgTwIbU9MbgScyU46IyMzS1hfmPQtrKC0OZnzdkzmN8IfAq8BKM2sxs3uBfwBuM7P9wK2p1yIiMk44mmBOVeaPvmESg1k55+6e4K31Ga5FRGTG6R6McNmcyqysW1diiohkSTga51RfJGtH4ApwEZEs6eiPALBiro7ARUR85a1jpwFYMbcqK+tXgIuIZMmbR7qZVVrE2oU1WVm/AlxEJEtaTg+z+JJyAgHLyvoV4CIiWbLzRB/LZmen/xsU4CIiWRGOxunoj2TtB0xQgIuIZMXoGShzqkqz1oYCXEQkC0ZHH6zPwhgooxTgIiJZ0HJ6GIC5OgIXEfGXo11DAFm7jB4U4CIiWTEQiVFSFCBUlL2YVYCLiGTBQCRGZclFxwtMiwJcRCQLBiMxKksV4CIivjMQjlERUoCLiPjOwY4B5ldn7wwUUICLiGTc0EiMI11DvGdhdVbbUYCLiGTYliPJYWRXzcvOMLKjFOAiIhm2p60PgLWLarLajgJcRCTDWk4PU1VaxPzqsqy2owAXEcmww52D1JQXZ70dBbiISIYd6hhk1bxZWW9HAS4ikkGxeIK2vnBWxwEfpQAXEcmgtr4w8YRjYW151ttSgIuIZFBrahjZhbXZ/QETFOAiIhk1Og54Q40CXETEV0YDfIECXETEX7a39tBQU0ZpcTDrbSnARUQy6GjXEGsasn8KISjARUQyqq03nPUrMEcpwEVEMqQ/HKU/Esv6MLKj0gpwM3vAzHaa2Q4z+6GZ5aZqEZE8NHoj43n5HuBm1gB8Dmhyzq0BgsDHMlWYiIjfvHG4G4DFddm/iAfS70IpAsrMrAgoB06kX5KIiD9ta+mhIhRk7cKanLQ37QB3zrUCXwWOASeBXufcz8cvZ2abzGyLmW3p6OiYfqUiInmu+XgPNyyvJxCwnLSXThdKLXAnsBRYAFSY2T3jl3PObXbONTnnmurr66dfqYhIHhseiXOka4jfWJCbUwghvS6UW4HDzrkO51wU+ClwbWbKEhHxl4FIDCAn44CPSifAjwHXmFm5mRmwHtidmbJERPwlHI0D5OQKzFHp9IG/DjwGvAVsT61rc4bqEhHxFS8CvCidf+yc+1vgbzNUi4iIbw2nArzMD0fgIiJyxvBIKsBDCnAREV8ZfrcLJXexqgAXEcmA/nDyLJSKkrR6pqdEAS4ikgH7T/VjBkvqKnLWpgJcRCQD/t+WFtYtqlEfuIiIn0Ricdr6wty8ck5O21WAi4ikabT/e1ZZ7q7CBAW4iEjaRk8hLM9h9wkowEVE0haJ5f4qTFCAi4ikLRxNAFBSlNtIVYCLiKRp9Ai8REfgIiL+EtERuIiIP0ViCnAREV/yYihZUICLiKRNR+AiIj41eju18lDuBrICBbiISNq6BkYAqKsI5bRdBbiISJq6BiNUlxUTUheKiIi/dA5EmF2Z26NvUICLiKStc2CESypLct6uAlxEJE1dAxHqFeAiIv4SicU50RNm7qzSnLetABcRScMzO9oYjsa5ZVVub+YACnARkbS0nB4GoKmxNudtK8BFRNIwNBIjGLCcX4UJCnARkbQc7RqiIhTEzHLetgJcRCQN21p6eX9jnSdtK8BFRNLQH46yoKbMk7YV4CIi0+Scoz8co6o0t4NYjVKAi4hMUziaIJZwVJUWe9K+AlxEZJr6w1EAfx6Bm1mNmT1mZnvMbLeZ/WamChMRyXdHuoYAqC3P/UBWAOn+2fhn4Bnn3O+ZWQgoz0BNIiK+8PjbrQBcOqfCk/anHeBmVg3cCHwcwDk3AoxkpiwRkfx3qi/M6vmzWDVvliftp9OFshToAP7dzN42s++Y2Tl/hsxsk5ltMbMtHR0daTQnIpJfOgci1FflfhTCUekEeBFwJfAt59w6YBB4cPxCzrnNzrkm51xTfX19Gs2JiOSX7a29LKz15hxwSC/AW4AW59zrqdePkQx0EZEZb9+pfpzDk3HAR007wJ1zbcBxM1uZmrUe2JWRqkRE8tzB9gEAbrt8rmc1pHsWymeBR1NnoBwCPpF+SSIi+W/0FMLG2d6cgQJpBrhzrhloykwpIiL+cax7kEsqQlSWeHMRD+hKTBGRadl9sp9L6ys9rUEBLiIyRZ0DEZqP9/A+D+7CM5YCXERkip7d2QbgyX0wx1KAi4hM0SsHulhQXUrTEh2Bi4j4ytHuQVbOq/LkNmpjKcBFRKbo9GCUugrvLuAZpQAXEZmi7sERasu9uYnDWApwEZEpCEfjDEfj1FZ4Mwb4WApwEZEpOD2UHDW7TgEuIuIv/3OgC4AGj+5EP5YCXERkCrYePU1pcYDrLpvtdSkKcBGRqdjT1sfiunKCAW9PIQQFuIjIpPWHo7x9rMfTIWTHUoCLiEzS09tPAtDUWOdxJUkKcBGRSTrUOQjAjcvz4/aQCnARkUnqG44yu7IkL/q/QQEuIjIpzjl2tPYxv7rU61LepQAXEZmEY91DbG/t5QMr8qP7BBTgIiKT8tax0wB8aO18jys5QwEuIjIJRzqHMMPz26iNpQAXEZmE1p5h5lSVUBzMn9jMn0pERPLUSCzBr/Z38J6Gaq9LOYsCXETkIl7cc4pTfRH+6OolXpdyFgW4iMhFvH28h+Kg5cUAVmMpwEVELiCecLywu501DdWEivIrMvOrGhGRPHOse4gD7QP87pULvS7lHApwEZELGAjHAJg7K3+uwBylABcRuYCBSDLAK0JBjys5lwJcROQCjncPAVBX6f09MMdTgIuITMA5x8P/c5iKUJAldRVel3OOtAPczIJm9raZPZWJgkRE8sWLe9rZ09bP529dQdkM7UK5H9idgfWIiOSVl/d2UFYcZOO1jV6Xcl5pBbiZLQR+G/hOZsoREckPsXiCn+04yfuX1uXd+d+j0q3q68BfAYn0SxERyR//8coROgdG+Mi6Bq9LmdC0A9zMPgS0O+e2XmS5TWa2xcy2dHR0TLc5EZGcevNIN1WlRXx47QKvS5lQOkfg1wEfNrMjwI+AW8zsB+MXcs5tds41Oeea6uvz504WIiIXsqO1j5tWziGQJ/e/PJ9pB7hz7kvOuYXOuUbgY8CLzrl7MlaZiIhHfr2/k9aeYd6bZ8PHjlfkdQEiIvnie68e4altJ3njcDcNNWXclcf935ChAHfOvQy8nIl1iYh44ZWDnfzNEzspDhpfuG0F992wlPJQfh/j5nd1IiI50HJ6iD/57hvMKi3isU9ey4q5VV6XNCn5eXKjiEgO7W8fIJZw/Os97/NNeIMCXESEI52DACytz7/xTi5EAS4iBW0kluD7rx1l+ZxK5uXhmN8XogAXkYL26qEuDnUM8tn1yzHL33O+z0cBLiIF7ZkdJykpCnD75XO9LmXKFOAiUtCOdw+zal4VpcX5N1zsxSjARaRgDUZibDnazZo8v+JyIgpwESlYz+xoIxxNcOcV+X3F5UQU4CJSkF450Mlf/9cOVsytpGlJrdflTIsCXEQKjnOOv//ZbuoqQjx63zV5PeLghSjARaTgnOgNs6O1j482LaK+qsTrcqZNAS4iBedX+5I3l7ll1RyPK0mPAlxECs7rh7uZXRliTcMsr0tJiwJcRApKa88wz+5s44bl9b678nI8BbiIFJT/fucEQyNxPnPLZV6XkjYFuIgUlC1Hulk2u4JL6yu9LiVtCnARKRiJhGPr0dO8z6fnfY+nABeRgvGL/R2cHopy/fLZXpeSEQpwESkI21p6+OQPtlJaHGD9av+NPHg+uiemiBSEB37cTDTu+OYfrqOyZGZEn47ARWTGO9o1yMGOQb54+0ruWDPf63IyRgEuIjPef79zAoAPvXfmhDcowEWkADzRfIL3LqxmUV2516VklAJcRGa0gx0D7G8f4C6fjvl9IQpwEZnRvvDjZgBu8+E9Ly9GAS4iM9aJnmHeaenlI+saZlz3CSjARWQGe2pb8sfLv7jpUo8ryQ4FuIjMSMMjcf7tF4dYNa+KFXOrvC4nKxTgIjIjPbb1OF2DIzxw2wqvS8kaBbiIzDjhaJyvPbcPgBuX13tcTfZMO8DNbJGZvWRmu8xsp5ndn8nCRESma/+pAU4PRflfH1xJWSjodTlZk86AADHgL51zb5lZFbDVzJ5zzu3KUG0iIlMWiyf4ydbjwMw8dXCsaQe4c+4kcDI13W9mu4EGQAEuIp7oHYrylz9p5vnd7dx91WKWz/H/TRsuJCNDcplZI7AOeP08720CNgEsXrw4E82JiJzjuV2neOjx7XQNjvDQhtX82Y3LvC4p69IOcDOrBP4T+Lxzrm/8+865zcBmgKamJpdueyIikPyh8tWDXTy/+xS/2NdBy+lhVs2r4rsb3897FlZ7XV5OpBXgZlZMMrwfdc79NDMliYhcWCLh+Pi/v8Frh7opDwW5/rLZ/MUHLuWjTYsIFRXOyXXTDnAzM+C7wG7n3NcyV5KIyMScc3z6/77Fa4e6ufuqxXz5w5dTUjRzzzS5kHT+VF0H/DFwi5k1px4bMlSXiMh5vbinnZ/taOOeaxbzd3etKdjwhvTOQvk1YBmsRUTkgjoHIvzvp3ax5JJy/uZDv0EwUNgRNDNuDCciBeGBHzdzqi/MD+69uqD6uieiPSAivvD09pP8an8nn1u/nKbGOq/LyQsKcBHJeyOxBP/nqV3UlBdz7/VLvS4nbyjARSSvhaNx/vz7WzjZG+YLt60o6B8tx1OAi0jeSiQcX/zJO7y0t4NP3XQp91y9xOuS8op+xBSRvBSOxvnykzt5attJHrh1BfffutzrkvKOAlxE8s5AJMYffvs1trX0sunGZXxu/WVel5SXFOAiklfiCcffPbWL7a29fP0PruCudQ1el5S3FOAikjcisTgff/hNXj3Uxd1XLVZ4X4QCXETyQu9QlM/+6G1ePdTFQxtWc98NOl3wYhTgIpIXvvrzvfxyXwd//durue+GmT+WdyboNEIR8dwTza18/7Wj3H3VYoX3FOgIXEQ89ZVn9vAvLx9k1bwqvrRhldfl+IoCXEQ88+1fHuJfXj7InVcs4Cu/915dZTlFCnARyalYPMETzSf48ZvHeeNIN1c11vHV319LcVA9ulOlABeRrIvGE7T1htnf3s83XjhA8/EeGmrK+PMPLOOvPriq4Mf1ni4FuIhkhXOO7a29/OsvDvL8rnZG4gkAqkqK+KffX8tHrmwgeWdGmS4FuIhkVGvPMD/d2sLjza0c6hiktDjAH12zmNXzZrGorpy1i6opDyl6MkF7UUTS5pzjhd3t/PCNY7y4tx3n4OqldfzZDcvYsGY+1eXFXpc4IynARWTKYvEEzcd7ONEb5rVDXby0p52TvWGqy4rZ+JuN3Hv9UhbVlXtd5oynABeRSQtH43z9+f1879UjDI3EAQgFA6xfPYdP3Tyb31nXQGWJYiVXtKdFZFIOdgzw6UffYk9bPzcsn81HmxaxYm4Vi+rK1KftEe11EbmorUdPs/HhNygOGo/86VV8YEW91yUJCnAROQ/nHAc7Bnnr6Gle2tvOszvbqK8q4fFPXceCmjKvy5MUBbiIvOtw5yDffOkArxzo5ERvGIC6ihCfuG4pH7+2UeGdZxTgIkJfOMoPXjvKt14+SDga59bVc/nkTZdw7WWzWVJXTpEuc89LCnCRApTsIhnghd3tPL39JO+09AJw88p6vrRhNSvmVnlcoUyGAlykQCQSjuaWHl7e086T75zgSNcQAGsaZnH/+uXcvGoOVyyq8bZImRIFuMgMFIsnaO+P0DkQ4UD7AM3He/j1gU4OdQxiBtdeegn33bCMm1bWs7BWF9z4lQJcJE8kEo7+SIzeoSi9w1F6hkeSz6nXyekz88KxBNFYgmg8wUg8wUgsQTgaZzgaJxxNnLXu8lCQtQtruPf6pWxYM5/aipBHWymZpAAXyaBILM5gJM5AOMZAJMbgSIzBSIzBSJz+8Jkg7gtH6ewf4VR/mNODI/QMR+kbjpJwE6+7tDhAdVkxNWUhqsuKqS4rJhQMECoyioMBioMByoqDlIWCVISKmF0VYm5VKQvrylg+p0pDts5AaQW4md0B/DMQBL7jnPuHjFQlkiGxeIJILPkIR+Op6TiR6NjX53kv9Tw6LxxNvRdLpObHCUfjDETiDESi74b26JCpFxIMGNVlxdRVhJg3q5RFteXUlBdTU1bMrLJiasqTAV1TXpwK7OT80mLdrUbONu0AN7Mg8E3gNqAFeNPMnnTO7cpUcZJ7zjmcg7hzxBPjp5PP8dFlEhMsM/bfvru8I57gnGXiCcdI7EwXQDTuGInFk8+pee8G69igjZ4J23PeiyWIROOEYwniFzqknYRQUYCSogClxUFKzpkOsrA2RGVJFZUlRVSWFiWfU4+KkiDloSIqRueVFlFdVkxFKKhxsCUj0jkCvwo44Jw7BGBmPwLuBDIe4A89vp3XD3cDyYAZddZX0513csLl3VnLu/PPn+C7P5V1ugnrOmuNE6xjim1OY98kUuE7Gs5p5l1WhIIBSoqTgVlSlJwuLQqm5gWorQi9G6hnBexZy03hvdT8UDBAQN0OksfSCfAG4PiY1y3A1eMXMrNNwCaAxYsXT6uhBTVlrBx7Xqqdd/Kso5qz509t+bPXP2aZCddz4eVtgpVPd33nLn/+kJnMegIGgYARMCNolppmzLQRDEDARqcnuYyllgnYuPVz1jJFASNUlOy/LSkKvDudfDZCwYCOVkUmkPUfMZ1zm4HNAE1NTdM6vvv0zZdltCYRkZkgnetjW4FFY14vTM0TEZEcSCfA3wSWm9lSMwsBHwOezExZIiJyMdPuQnHOxczsM8CzJE8jfNg5tzNjlYmIyAWl1QfunHsaeDpDtYiIyBRojEgREZ9SgIuI+JQCXETEpxTgIiI+ZW6i68Wz0ZhZB3B0mv98NtCZwXL8SvvhDO2LJO2HpJm8H5Y45+rHz8xpgKfDzLY455q8rsNr2g9naF8kaT8kFeJ+UBeKiIhPKcBFRHzKTwG+2esC8oT2wxnaF0naD0kFtx980wcuIiJn89MRuIiIjKEAFxHxKV8EuJndYWZ7zeyAmT3odT3ZZmZHzGy7mTWb2ZbUvDoze87M9qeea1Pzzcy+kdo328zsSm+rnz4ze9jM2s1sx5h5U95uM9uYWn6/mW30YlvSNcG++LKZtaY+F81mtmHMe19K7Yu9ZvbBMfN9/d0xs0Vm9pKZ7TKznWZ2f2p+QX4uzuFS90PM1wfJoWoPAsuAEPAOcLnXdWV5m48As8fN+wrwYGr6QeAfU9MbgJ+RvMvaNcDrXtefxnbfCFwJ7JjudgN1wKHUc21qutbrbcvQvvgy8MXzLHt56ntRAixNfV+CM+G7A8wHrkxNVwH7UttbkJ+L8Q8/HIG/e/Nk59wIMHrz5EJzJ/BIavoR4K4x87/nkl4Dasxsvgf1pc0590uge9zsqW73B4HnnHPdzrnTwHPAHVkvPsMm2BcTuRP4kXMu4pw7DBwg+b3x/XfHOXfSOfdWarof2E3yfrwF+bkYzw8Bfr6bJzd4VEuuOODnZrY1dVNogLnOuZOp6TZgbmp6pu+fqW73TN8fn0l1DTw82m1AgewLM2sE1gGvo88F4I8AL0TXO+euBH4L+LSZ3Tj2TZf8P2HBnf9ZqNs9xreAS4ErgJPAP3laTQ6ZWSXwn8DnnXN9Y98r5M+FHwK84G6e7JxrTT23A4+T/K/wqdGukdRze2rxmb5/prrdM3Z/OOdOOefizrkE8G2SnwuY4fvCzIpJhvejzrmfpmbrc4E/Arygbp5sZhVmVjU6DdwO7CC5zaO/nG8EnkhNPwn8SerX92uA3jH/tZwJprrdzwK3m1ltqovh9tQ83xv328bvkPxcQHJffMzMSsxsKbAceIMZ8N0xMwO+C+x2zn1tzFv6XED+n4XizvyyvI/kL+oPeV1Plrd1GcmzBd4Bdo5uL3AJ8AKwH3geqEvNN+CbqX2zHWjyehvS2PYfkuwaiJLso7x3OtsN/CnJH/IOAJ/wersyuC++n9rWbSSDav6Y5R9K7Yu9wG+Nme/r7w5wPcnukW1Ac+qxoVA/F+MfupReRMSn/NCFIiIi56EAFxHxKQW4iIhPKcBFRHxKAS4i4lMKcBERn1KAi4j41P8HA3xrSj+hiqIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_drop 409\n",
      "single_drop 95\n",
      "corr_drop1 3847\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_drop2 0\n",
      "4211 drop_list\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>report_timestamp</th>\n",
       "      <th>BureauScoreConfidLevel</th>\n",
       "      <th>MissingRate</th>\n",
       "      <th>Current_Finance_Purpose</th>\n",
       "      <th>Current_Amount_Financed</th>\n",
       "      <th>Current_Gender_Code</th>\n",
       "      <th>First_Name1</th>\n",
       "      <th>Len_Name</th>\n",
       "      <th>Name_nuniq</th>\n",
       "      <th>Tel_nuniq</th>\n",
       "      <th>IncomeTaxPAN_5</th>\n",
       "      <th>Len_of_addrs</th>\n",
       "      <th>City_nuniq</th>\n",
       "      <th>PinCode3</th>\n",
       "      <th>Current_State</th>\n",
       "      <th>Current_City</th>\n",
       "      <th>CreditAccountActive</th>\n",
       "      <th>CreditAccountActivePor</th>\n",
       "      <th>State_nuniq</th>\n",
       "      <th>TotalCAPSLast90Days</th>\n",
       "      <th>TotalCAPSLast7Days</th>\n",
       "      <th>TotalCAPSLast30Days</th>\n",
       "      <th>TotalCAPSLast180Days</th>\n",
       "      <th>CAPSLast7Days</th>\n",
       "      <th>CAPSLast180Days</th>\n",
       "      <th>Pin_nuniq</th>\n",
       "      <th>Pan_nuniq</th>\n",
       "      <th>Ident_nuniq</th>\n",
       "      <th>Pan_nuniq2</th>\n",
       "      <th>Account_nuniq2</th>\n",
       "      <th>Ident_nuniq2</th>\n",
       "      <th>Gender_nuniq</th>\n",
       "      <th>Amount_Past_Due35_max_30</th>\n",
       "      <th>Amount_Past_Due35_mean_90</th>\n",
       "      <th>Amount_Past_Due35_max_90</th>\n",
       "      <th>Amount_Past_Due35_min_90</th>\n",
       "      <th>Amount_Past_Due35_std_90</th>\n",
       "      <th>Amount_Past_Due35_max_9999</th>\n",
       "      <th>Amount_Past_Due35_min_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_360</th>\n",
       "      <th>Terms_Duration34_std_30</th>\n",
       "      <th>Terms_Duration34_std_90</th>\n",
       "      <th>Terms_Duration34_sum_360</th>\n",
       "      <th>Terms_Duration34_max_360</th>\n",
       "      <th>Terms_Duration34_mean_9999</th>\n",
       "      <th>Terms_Duration34_std_9999</th>\n",
       "      <th>Payment_Rating34_sum_90</th>\n",
       "      <th>Payment_Rating34_mean_90</th>\n",
       "      <th>Payment_Rating34_min_90</th>\n",
       "      <th>Payment_Rating34_std_90</th>\n",
       "      <th>Payment_Rating34_sum_360</th>\n",
       "      <th>Payment_Rating34_mean_360</th>\n",
       "      <th>Payment_Rating34_max_360</th>\n",
       "      <th>Payment_Rating34_min_360</th>\n",
       "      <th>Payment_Rating34_std_360</th>\n",
       "      <th>Payment_Rating34_sum_9999</th>\n",
       "      <th>Payment_Rating34_max_9999</th>\n",
       "      <th>Payment_Rating34_min_9999</th>\n",
       "      <th>Payment_Rating34_std_9999</th>\n",
       "      <th>Current_Balance35_sum_360</th>\n",
       "      <th>Current_Balance35_max_360</th>\n",
       "      <th>Current_Balance35_std_360</th>\n",
       "      <th>Current_Balance35_mean_9999</th>\n",
       "      <th>Settlement_Amount37_mean_360</th>\n",
       "      <th>Settlement_Amount37_std_360</th>\n",
       "      <th>Settlement_Amount37_mean_9999</th>\n",
       "      <th>Settlement_Amount37_max_9999</th>\n",
       "      <th>Settlement_Amount37_min_9999</th>\n",
       "      <th>Value_of_Collateral39_std_90</th>\n",
       "      <th>Value_of_Collateral39_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_360</th>\n",
       "      <th>Written_Off_Amt_Total41_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_max_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_min_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_std_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_std_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_max_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_9999</th>\n",
       "      <th>Rate_of_Interest36_sum_30</th>\n",
       "      <th>Rate_of_Interest36_max_30</th>\n",
       "      <th>Rate_of_Interest36_min_30</th>\n",
       "      <th>Rate_of_Interest36_std_30</th>\n",
       "      <th>Rate_of_Interest36_sum_90</th>\n",
       "      <th>Rate_of_Interest36_mean_90</th>\n",
       "      <th>Rate_of_Interest36_max_90</th>\n",
       "      <th>Rate_of_Interest36_min_90</th>\n",
       "      <th>Rate_of_Interest36_std_90</th>\n",
       "      <th>Rate_of_Interest36_sum_360</th>\n",
       "      <th>Rate_of_Interest36_sum_9999</th>\n",
       "      <th>Rate_of_Interest36_mean_9999</th>\n",
       "      <th>Rate_of_Interest36_max_9999</th>\n",
       "      <th>Rate_of_Interest36_std_9999</th>\n",
       "      <th>Repayment_Tenure36_std_30</th>\n",
       "      <th>Repayment_Tenure36_std_90</th>\n",
       "      <th>Repayment_Tenure36_mean_360</th>\n",
       "      <th>Repayment_Tenure36_min_360</th>\n",
       "      <th>Repayment_Tenure36_std_360</th>\n",
       "      <th>Repayment_Tenure36_sum_9999</th>\n",
       "      <th>Repayment_Tenure36_mean_9999</th>\n",
       "      <th>Repayment_Tenure36_max_9999</th>\n",
       "      <th>Repayment_Tenure36_min_9999</th>\n",
       "      <th>Repayment_Tenure36_std_9999</th>\n",
       "      <th>Income26_count_30</th>\n",
       "      <th>Income26_min_9999</th>\n",
       "      <th>Income26_std_9999</th>\n",
       "      <th>Open_Date29_max_30</th>\n",
       "      <th>Open_Date29_mean_30</th>\n",
       "      <th>Open_Date29_mode_30</th>\n",
       "      <th>Open_Date29_nuniq_30</th>\n",
       "      <th>Open_Date29_maxcount_30</th>\n",
       "      <th>Open_Date29_mode_90</th>\n",
       "      <th>Open_Date29_nuniq_90</th>\n",
       "      <th>Open_Date29_max_360</th>\n",
       "      <th>Open_Date29_mode_360</th>\n",
       "      <th>Open_Date29_maxcount_360</th>\n",
       "      <th>Open_Date29_max_9999</th>\n",
       "      <th>Open_Date29_mean_9999</th>\n",
       "      <th>Open_Date29_mode_9999</th>\n",
       "      <th>Open_Date29_maxcount_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_30</th>\n",
       "      <th>Portfolio_Type34_nuniq_90</th>\n",
       "      <th>Portfolio_Type34_nuniq_360</th>\n",
       "      <th>Portfolio_Type34_mode_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_9999</th>\n",
       "      <th>Account_Type32_mode_30</th>\n",
       "      <th>Account_Type32_nuniq_30</th>\n",
       "      <th>Account_Type32_mode_90</th>\n",
       "      <th>Account_Type32_nuniq_90</th>\n",
       "      <th>Account_Type32_mode_360</th>\n",
       "      <th>Account_Type32_nuniq_360</th>\n",
       "      <th>Account_Type32_mode_9999</th>\n",
       "      <th>Account_Type32_nuniq_9999</th>\n",
       "      <th>Occupation_Code35_nuniq_30</th>\n",
       "      <th>Occupation_Code35_nuniq_90</th>\n",
       "      <th>Occupation_Code35_nuniq_360</th>\n",
       "      <th>CurrencyCode32_mode_360</th>\n",
       "      <th>CurrencyCode32_mode_9999</th>\n",
       "      <th>AccountHoldertypeCode41_mode_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_360</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_9999</th>\n",
       "      <th>Payment_History_Profile43_mode_30</th>\n",
       "      <th>Payment_History_Profile43_mode_90</th>\n",
       "      <th>Payment_History_Profile43_nuniq_90</th>\n",
       "      <th>Payment_History_Profile43_mode_360</th>\n",
       "      <th>Payment_History_Profile43_nuniq_360</th>\n",
       "      <th>Payment_History_Profile43_mode_9999</th>\n",
       "      <th>Payment_History_Profile43_nuniq_9999</th>\n",
       "      <th>Date_Closed31_mode_30</th>\n",
       "      <th>Date_Closed31_nuniq_30</th>\n",
       "      <th>Date_Closed31_maxcount_30</th>\n",
       "      <th>Date_Closed31_max_90</th>\n",
       "      <th>Date_Closed31_min_90</th>\n",
       "      <th>Date_Closed31_mean_90</th>\n",
       "      <th>Date_Closed31_mode_90</th>\n",
       "      <th>Date_Closed31_nuniq_90</th>\n",
       "      <th>Date_Closed31_maxcount_90</th>\n",
       "      <th>Date_Closed31_mode_360</th>\n",
       "      <th>Date_Closed31_nuniq_360</th>\n",
       "      <th>Date_Closed31_maxcount_360</th>\n",
       "      <th>Date_Closed31_mean_9999</th>\n",
       "      <th>Date_Closed31_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_30</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_30</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_90</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_90</th>\n",
       "      <th>Date_of_Last_Payment40_min_360</th>\n",
       "      <th>Date_of_Last_Payment40_mode_360</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_360</th>\n",
       "      <th>Date_of_Last_Payment40_mean_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_9999</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_9999</th>\n",
       "      <th>Date_Reported33_nuniq_30</th>\n",
       "      <th>Date_Reported33_max_90</th>\n",
       "      <th>Date_Reported33_mode_90</th>\n",
       "      <th>Date_Reported33_nuniq_90</th>\n",
       "      <th>Date_Reported33_maxcount_90</th>\n",
       "      <th>Date_Reported33_max_360</th>\n",
       "      <th>Date_Reported33_mean_360</th>\n",
       "      <th>Date_Reported33_mode_360</th>\n",
       "      <th>Date_Reported33_nuniq_360</th>\n",
       "      <th>Date_Reported33_max_9999</th>\n",
       "      <th>Date_Reported33_mode_9999</th>\n",
       "      <th>Date_Reported33_nuniq_9999</th>\n",
       "      <th>Date_Reported33_maxcount_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_30</th>\n",
       "      <th>DateOfAddition34_max_90</th>\n",
       "      <th>DateOfAddition34_mean_90</th>\n",
       "      <th>DateOfAddition34_nuniq_90</th>\n",
       "      <th>DateOfAddition34_maxcount_90</th>\n",
       "      <th>DateOfAddition34_max_360</th>\n",
       "      <th>DateOfAddition34_mean_360</th>\n",
       "      <th>DateOfAddition34_mode_360</th>\n",
       "      <th>DateOfAddition34_maxcount_360</th>\n",
       "      <th>DateOfAddition34_max_9999</th>\n",
       "      <th>DateOfAddition34_min_9999</th>\n",
       "      <th>DateOfAddition34_mode_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_9999</th>\n",
       "      <th>DateOfAddition34_maxcount_9999</th>\n",
       "      <th>Account_Status34_mode_30</th>\n",
       "      <th>Account_Status34_nuniq_30</th>\n",
       "      <th>Account_Status34_mode_90</th>\n",
       "      <th>Account_Status34_nuniq_90</th>\n",
       "      <th>Account_Status34_nuniq_360</th>\n",
       "      <th>Account_Status34_mode_9999</th>\n",
       "      <th>Account_Status34_nuniq_9999</th>\n",
       "      <th>Month50_sum_30</th>\n",
       "      <th>Month50_mean_30</th>\n",
       "      <th>Month50_std_30</th>\n",
       "      <th>Month50_sum_90</th>\n",
       "      <th>Month50_mean_90</th>\n",
       "      <th>Month50_max_90</th>\n",
       "      <th>Month50_std_90</th>\n",
       "      <th>Month50_max_360</th>\n",
       "      <th>Month50_min_360</th>\n",
       "      <th>Month50_mean_9999</th>\n",
       "      <th>Month50_max_9999</th>\n",
       "      <th>Month50_min_9999</th>\n",
       "      <th>Month50_std_9999</th>\n",
       "      <th>Days_Past_Due58_sum_90</th>\n",
       "      <th>Days_Past_Due58_min_90</th>\n",
       "      <th>Days_Past_Due58_std_90</th>\n",
       "      <th>Days_Past_Due58_sum_360</th>\n",
       "      <th>Days_Past_Due58_mean_360</th>\n",
       "      <th>Days_Past_Due58_max_360</th>\n",
       "      <th>Days_Past_Due58_min_360</th>\n",
       "      <th>Days_Past_Due58_std_360</th>\n",
       "      <th>Days_Past_Due58_sum_9999</th>\n",
       "      <th>Days_Past_Due58_max_9999</th>\n",
       "      <th>Days_Past_Due58_min_9999</th>\n",
       "      <th>Days_Past_Due58_std_9999</th>\n",
       "      <th>Duecount53_mean_30</th>\n",
       "      <th>Duecount53_min_30</th>\n",
       "      <th>Duecount53_std_30</th>\n",
       "      <th>Duecount53_sum_90</th>\n",
       "      <th>Duecount53_mean_90</th>\n",
       "      <th>Duecount53_max_90</th>\n",
       "      <th>Duecount53_min_90</th>\n",
       "      <th>Duecount53_std_90</th>\n",
       "      <th>Duecount53_sum_360</th>\n",
       "      <th>Duecount53_mean_360</th>\n",
       "      <th>Duecount53_max_360</th>\n",
       "      <th>Duecount53_min_360</th>\n",
       "      <th>Duecount53_std_360</th>\n",
       "      <th>Duecount53_mean_9999</th>\n",
       "      <th>Duecount53_max_9999</th>\n",
       "      <th>Duecount53_min_9999</th>\n",
       "      <th>Duecount53_std_9999</th>\n",
       "      <th>Duesum51_mean_30</th>\n",
       "      <th>Duesum51_std_30</th>\n",
       "      <th>Duesum51_mean_90</th>\n",
       "      <th>Duesum51_max_90</th>\n",
       "      <th>Duesum51_sum_360</th>\n",
       "      <th>Duesum51_mean_360</th>\n",
       "      <th>Duesum51_min_360</th>\n",
       "      <th>Duesum51_std_360</th>\n",
       "      <th>Duesum51_sum_9999</th>\n",
       "      <th>Duesum51_mean_9999</th>\n",
       "      <th>Duesum51_max_9999</th>\n",
       "      <th>Duesum51_min_9999</th>\n",
       "      <th>Duesum51_std_9999</th>\n",
       "      <th>Amount_Financed35_std_7</th>\n",
       "      <th>Amount_Financed35_max_30</th>\n",
       "      <th>Amount_Financed35_min_30</th>\n",
       "      <th>Amount_Financed35_std_30</th>\n",
       "      <th>Amount_Financed35_count_90</th>\n",
       "      <th>Amount_Financed35_min_90</th>\n",
       "      <th>Amount_Financed35_count_360</th>\n",
       "      <th>Amount_Financed35_sum_360</th>\n",
       "      <th>Amount_Financed35_mean_360</th>\n",
       "      <th>Amount_Financed35_max_360</th>\n",
       "      <th>Amount_Financed35_min_360</th>\n",
       "      <th>Amount_Financed35_count_9999</th>\n",
       "      <th>Amount_Financed35_sum_9999</th>\n",
       "      <th>Amount_Financed35_max_9999</th>\n",
       "      <th>Amount_Financed35_min_9999</th>\n",
       "      <th>Amount_Financed35_std_9999</th>\n",
       "      <th>Duration_Of_Agreement41_std_7</th>\n",
       "      <th>Duration_Of_Agreement41_min_30</th>\n",
       "      <th>Duration_Of_Agreement41_min_90</th>\n",
       "      <th>Duration_Of_Agreement41_mean_360</th>\n",
       "      <th>Duration_Of_Agreement41_max_360</th>\n",
       "      <th>Duration_Of_Agreement41_min_360</th>\n",
       "      <th>Duration_Of_Agreement41_std_360</th>\n",
       "      <th>Duration_Of_Agreement41_mean_9999</th>\n",
       "      <th>Duration_Of_Agreement41_max_9999</th>\n",
       "      <th>Duration_Of_Agreement41_min_9999</th>\n",
       "      <th>Duration_Of_Agreement41_std_9999</th>\n",
       "      <th>Date_of_Request35_mode_7</th>\n",
       "      <th>Date_of_Request35_nuniq_7</th>\n",
       "      <th>Date_of_Request35_nuniq_90</th>\n",
       "      <th>Enquiry_Reason34_nuniq_7</th>\n",
       "      <th>Enquiry_Reason34_mode_30</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_409 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_409 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_409 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_409 * Tel_nuniq2</th>\n",
       "      <th>feature_409 * feature_638</th>\n",
       "      <th>feature_409 * feature_643</th>\n",
       "      <th>feature_409 * feature_701</th>\n",
       "      <th>feature_409 * feature_710</th>\n",
       "      <th>feature_409 * feature_778</th>\n",
       "      <th>feature_409 * feature_781</th>\n",
       "      <th>feature_409 * feature_8</th>\n",
       "      <th>feature_409 * feature_888</th>\n",
       "      <th>feature_410 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_410 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_410 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_410 * Name_nuniq2</th>\n",
       "      <th>feature_410 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_410 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_410 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_410 * Tel_nuniq2</th>\n",
       "      <th>feature_410 * feature_638</th>\n",
       "      <th>feature_410 * feature_643</th>\n",
       "      <th>feature_410 * feature_701</th>\n",
       "      <th>feature_410 * feature_710</th>\n",
       "      <th>feature_410 * feature_778</th>\n",
       "      <th>feature_410 * feature_781</th>\n",
       "      <th>feature_410 * feature_8</th>\n",
       "      <th>feature_410 * feature_888</th>\n",
       "      <th>feature_410 * feature_9</th>\n",
       "      <th>feature_638 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_638 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_638 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_638 * Name_nuniq2</th>\n",
       "      <th>feature_638 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_638 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_638 * Tel_nuniq2</th>\n",
       "      <th>feature_638 * feature_669</th>\n",
       "      <th>feature_638 * feature_701</th>\n",
       "      <th>feature_638 * feature_710</th>\n",
       "      <th>feature_638 * feature_762</th>\n",
       "      <th>feature_638 * feature_781</th>\n",
       "      <th>feature_638 * feature_8</th>\n",
       "      <th>feature_638 * feature_804</th>\n",
       "      <th>feature_638 * feature_846</th>\n",
       "      <th>feature_638 * feature_874</th>\n",
       "      <th>feature_638 * feature_888</th>\n",
       "      <th>feature_643 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_643 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_643 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_643 * Name_nuniq2</th>\n",
       "      <th>feature_643 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_643 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_643 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_643 * Tel_nuniq2</th>\n",
       "      <th>feature_643 * feature_700</th>\n",
       "      <th>feature_643 * feature_701</th>\n",
       "      <th>feature_643 * feature_702</th>\n",
       "      <th>feature_643 * feature_710</th>\n",
       "      <th>feature_643 * feature_778</th>\n",
       "      <th>feature_643 * feature_781</th>\n",
       "      <th>feature_643 * feature_8</th>\n",
       "      <th>feature_669 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_669 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_669 * Name_nuniq2</th>\n",
       "      <th>feature_669 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_669 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_669 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_669 * Tel_nuniq2</th>\n",
       "      <th>feature_669 * feature_710</th>\n",
       "      <th>feature_669 * feature_8</th>\n",
       "      <th>feature_700 * Name_nuniq2</th>\n",
       "      <th>feature_700 * feature_701</th>\n",
       "      <th>feature_700 * feature_779</th>\n",
       "      <th>feature_701 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_701 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_701 * Name_nuniq2</th>\n",
       "      <th>feature_701 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_701 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_701 * Tel_nuniq2</th>\n",
       "      <th>feature_701 * feature_710</th>\n",
       "      <th>feature_701 * feature_762</th>\n",
       "      <th>feature_701 * feature_778</th>\n",
       "      <th>feature_701 * feature_781</th>\n",
       "      <th>feature_701 * feature_888</th>\n",
       "      <th>feature_702 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_702 * Tel_nuniq2</th>\n",
       "      <th>feature_702 * feature_762</th>\n",
       "      <th>feature_702 * feature_778</th>\n",
       "      <th>feature_702 * feature_779</th>\n",
       "      <th>feature_702 * feature_781</th>\n",
       "      <th>feature_702 * feature_888</th>\n",
       "      <th>feature_702 * feature_9</th>\n",
       "      <th>feature_710 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_710 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_710 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_710 * Name_nuniq2</th>\n",
       "      <th>feature_710 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_710 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_710 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_710 * Tel_nuniq2</th>\n",
       "      <th>feature_710 * feature_762</th>\n",
       "      <th>feature_710 * feature_779</th>\n",
       "      <th>feature_710 * feature_8</th>\n",
       "      <th>feature_710 * feature_804</th>\n",
       "      <th>feature_710 * feature_846</th>\n",
       "      <th>feature_710 * feature_874</th>\n",
       "      <th>feature_710 * feature_888</th>\n",
       "      <th>feature_762 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_762 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_762 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_762 * Name_nuniq2</th>\n",
       "      <th>feature_762 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_762 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_762 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_762 * Tel_nuniq2</th>\n",
       "      <th>feature_762 * feature_8</th>\n",
       "      <th>feature_778 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_778 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_778 * Tel_nuniq2</th>\n",
       "      <th>feature_778 * feature_781</th>\n",
       "      <th>feature_778 * feature_888</th>\n",
       "      <th>feature_779 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_779 * Name_nuniq2</th>\n",
       "      <th>feature_779 * feature_888</th>\n",
       "      <th>feature_781 * Name_nuniq2</th>\n",
       "      <th>feature_781 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_781 * Tel_nuniq2</th>\n",
       "      <th>feature_8 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_8 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_8 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_8 * Name_nuniq2</th>\n",
       "      <th>feature_8 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_8 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_8 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_8 * Tel_nuniq2</th>\n",
       "      <th>feature_8 * feature_804</th>\n",
       "      <th>feature_8 * feature_846</th>\n",
       "      <th>feature_8 * feature_874</th>\n",
       "      <th>feature_8 * feature_888</th>\n",
       "      <th>feature_804 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_804 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_804 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_804 * Name_nuniq2</th>\n",
       "      <th>feature_804 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_804 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_804 * Tel_nuniq2</th>\n",
       "      <th>feature_846 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_846 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_846 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_846 * Name_nuniq2</th>\n",
       "      <th>feature_846 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_846 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_846 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_846 * Tel_nuniq2</th>\n",
       "      <th>feature_874 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_874 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_874 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_874 * Name_nuniq2</th>\n",
       "      <th>feature_874 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_874 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_874 * Tel_nuniq2</th>\n",
       "      <th>feature_888 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_888 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_888 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_888 * Name_nuniq2</th>\n",
       "      <th>feature_888 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_888 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_888 * Tel_nuniq2</th>\n",
       "      <th>Account_Type32_mode_360vcount - Payment_Rating34_mean_9999</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_407</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_409</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_410</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_643</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_700</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_701</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_779</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_781</th>\n",
       "      <th>Amount_Past_Due35_max_360 - Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>Amount_Past_Due35_mean_9999 - Date_of_Last_Payment40_max_360</th>\n",
       "      <th>Amount_Past_Due35_mean_9999 - feature_804</th>\n",
       "      <th>Birth_nuniq - Date_of_Request35_mode_90</th>\n",
       "      <th>Birth_nuniq - Email_nuniq</th>\n",
       "      <th>Birth_nuniq - Email_nuniq2</th>\n",
       "      <th>Birth_nuniq - Rate_of_Interest36_min_9999</th>\n",
       "      <th>Birth_nuniq - Tel_nuniq2</th>\n",
       "      <th>Birth_nuniq - feature_254</th>\n",
       "      <th>Birth_nuniq - feature_778</th>\n",
       "      <th>BureauScore - Duecount53_sum_9999</th>\n",
       "      <th>BureauScore - Duesum51_max_360</th>\n",
       "      <th>BureauScore - Duration_Of_Agreement41_sum_9999</th>\n",
       "      <th>BureauScore - Name_nuniq2</th>\n",
       "      <th>BureauScore - feature_2</th>\n",
       "      <th>CAPSLast180Days_nocrt_por - Payment_Rating34_mean_9999</th>\n",
       "      <th>CAPSLast180Days_nocrt_por - feature_4</th>\n",
       "      <th>CAPSLast180Days_nocrt_por - feature_638</th>\n",
       "      <th>CAPSLast180Days_nocrt_por - feature_9</th>\n",
       "      <th>Current_Balance35_sum_9999 - Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>Current_Balance35_sum_9999 - Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>Current_Balance35_sum_9999 - feature_762</th>\n",
       "      <th>Date_of_Last_Payment40_max_360 - Date_of_Request35_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mean_360 - feature_8</th>\n",
       "      <th>Date_of_Request35_mode_90 - Email_nuniq</th>\n",
       "      <th>Date_of_Request35_mode_90 - Email_nuniq2</th>\n",
       "      <th>Date_of_Request35_mode_90 - Name_nuniq2</th>\n",
       "      <th>Date_of_Request35_mode_90 - Rate_of_Interest36_min_9999</th>\n",
       "      <th>Date_of_Request35_mode_90 - Tel_nuniq2</th>\n",
       "      <th>Date_of_Request35_mode_9999 - Duecount53_sum_9999</th>\n",
       "      <th>Date_of_Request35_mode_9999 - Duesum51_max_360</th>\n",
       "      <th>Date_of_Request35_mode_9999 - Duration_Of_Agreement41_sum_9999</th>\n",
       "      <th>Date_of_Request35_mode_9999 - Email_nuniq</th>\n",
       "      <th>Date_of_Request35_mode_9999 - Name_nuniq2</th>\n",
       "      <th>Date_of_Request35_mode_9999 - feature_322</th>\n",
       "      <th>Date_of_Request35_mode_9999 - feature_329</th>\n",
       "      <th>Duecount53_sum_9999 - Duesum51_max_360</th>\n",
       "      <th>Duecount53_sum_9999 - Duration_Of_Agreement41_sum_9999</th>\n",
       "      <th>Duecount53_sum_9999 - Name_nuniq2</th>\n",
       "      <th>Duecount53_sum_9999 - feature_2</th>\n",
       "      <th>Duesum51_max_360 - Duration_Of_Agreement41_sum_9999</th>\n",
       "      <th>Duesum51_max_360 - Name_nuniq2</th>\n",
       "      <th>Duesum51_max_360 - feature_2</th>\n",
       "      <th>Duesum51_max_360 - feature_322</th>\n",
       "      <th>Duesum51_max_360 - feature_329</th>\n",
       "      <th>Duration_Of_Agreement41_sum_9999 - Name_nuniq2</th>\n",
       "      <th>Duration_Of_Agreement41_sum_9999 - feature_2</th>\n",
       "      <th>Duration_Of_Agreement41_sum_9999 - feature_322</th>\n",
       "      <th>Duration_Of_Agreement41_sum_9999 - feature_329</th>\n",
       "      <th>Email_nuniq - Rate_of_Interest36_min_9999</th>\n",
       "      <th>Email_nuniq - Tel_nuniq2</th>\n",
       "      <th>Email_nuniq2 - Name_nuniq2</th>\n",
       "      <th>Email_nuniq2 - Rate_of_Interest36_min_9999</th>\n",
       "      <th>Email_nuniq2 - Tel_nuniq2</th>\n",
       "      <th>Email_nuniq2 - feature_2</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_9999 - Outstanding_Balance_UnSecured</th>\n",
       "      <th>Rate_of_Interest36_min_9999 - Tel_nuniq2</th>\n",
       "      <th>feature_2 - Name_nuniq2</th>\n",
       "      <th>feature_254 - feature_638</th>\n",
       "      <th>feature_254 - feature_710</th>\n",
       "      <th>feature_322 - feature_329</th>\n",
       "      <th>feature_329 - feature_409</th>\n",
       "      <th>feature_4 - Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_4 - feature_638</th>\n",
       "      <th>feature_4 - feature_9</th>\n",
       "      <th>feature_407 - feature_409</th>\n",
       "      <th>feature_407 - feature_410</th>\n",
       "      <th>feature_407 - feature_638</th>\n",
       "      <th>feature_407 - feature_643</th>\n",
       "      <th>feature_407 - feature_700</th>\n",
       "      <th>feature_407 - feature_701</th>\n",
       "      <th>feature_407 - feature_702</th>\n",
       "      <th>feature_407 - feature_778</th>\n",
       "      <th>feature_407 - feature_779</th>\n",
       "      <th>feature_407 - feature_781</th>\n",
       "      <th>feature_409 - feature_410</th>\n",
       "      <th>feature_409 - feature_643</th>\n",
       "      <th>feature_409 - feature_701</th>\n",
       "      <th>feature_409 - feature_702</th>\n",
       "      <th>feature_409 - feature_778</th>\n",
       "      <th>feature_409 - feature_781</th>\n",
       "      <th>feature_410 - Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_410 - feature_643</th>\n",
       "      <th>feature_410 - feature_701</th>\n",
       "      <th>feature_410 - feature_702</th>\n",
       "      <th>feature_410 - feature_778</th>\n",
       "      <th>feature_410 - feature_9</th>\n",
       "      <th>feature_638 - feature_9</th>\n",
       "      <th>feature_643 - feature_702</th>\n",
       "      <th>feature_643 - feature_778</th>\n",
       "      <th>feature_643 - feature_779</th>\n",
       "      <th>feature_643 - feature_781</th>\n",
       "      <th>feature_643 - feature_804</th>\n",
       "      <th>feature_669 - feature_762</th>\n",
       "      <th>feature_700 - feature_701</th>\n",
       "      <th>feature_700 - feature_702</th>\n",
       "      <th>feature_700 - feature_778</th>\n",
       "      <th>feature_700 - feature_781</th>\n",
       "      <th>feature_701 - feature_702</th>\n",
       "      <th>feature_701 - feature_778</th>\n",
       "      <th>feature_701 - feature_781</th>\n",
       "      <th>feature_702 - feature_762</th>\n",
       "      <th>feature_702 - feature_779</th>\n",
       "      <th>feature_702 - feature_781</th>\n",
       "      <th>feature_702 - feature_888</th>\n",
       "      <th>feature_710 - feature_9</th>\n",
       "      <th>feature_762 - Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_762 - feature_804</th>\n",
       "      <th>feature_762 - feature_846</th>\n",
       "      <th>feature_762 - feature_874</th>\n",
       "      <th>feature_762 - feature_888</th>\n",
       "      <th>feature_778 - feature_779</th>\n",
       "      <th>feature_778 - feature_781</th>\n",
       "      <th>feature_778 - feature_874</th>\n",
       "      <th>feature_779 - feature_781</th>\n",
       "      <th>feature_804 - feature_846</th>\n",
       "      <th>feature_804 - feature_888</th>\n",
       "      <th>feature_846 - feature_874</th>\n",
       "      <th>feature_846 - feature_888</th>\n",
       "      <th>feature_874 - Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_874 - feature_888</th>\n",
       "      <th>feature_888 - feature_9</th>\n",
       "      <th>feature_9 - Payment_Rating34_mean_9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAHPO6801A</td>\n",
       "      <td>20220121153515</td>\n",
       "      <td>H</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>1.999889</td>\n",
       "      <td>2.999667</td>\n",
       "      <td>O</td>\n",
       "      <td>46</td>\n",
       "      <td>1.285673</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>9</td>\n",
       "      <td>0.749938</td>\n",
       "      <td>2.599680</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.166139</td>\n",
       "      <td>32.968032</td>\n",
       "      <td>2.999500</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>16.984016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5308000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>135.750000</td>\n",
       "      <td>65.086001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.149919</td>\n",
       "      <td>5146651.0</td>\n",
       "      <td>4371915.0</td>\n",
       "      <td>1.798590e+06</td>\n",
       "      <td>461866.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27173.666667</td>\n",
       "      <td>81521.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38429.367939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49982.0</td>\n",
       "      <td>16660.666667</td>\n",
       "      <td>49982.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>543.0</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.210427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4203.0</td>\n",
       "      <td>1028.750000</td>\n",
       "      <td>888.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>R</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.333333</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.416667</td>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>296.0</td>\n",
       "      <td>250.500000</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>752.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>267.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.132402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>22.166667</td>\n",
       "      <td>55.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.408554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>107.833333</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.475276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1177000.0</td>\n",
       "      <td>294250.000000</td>\n",
       "      <td>867000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1237000.0</td>\n",
       "      <td>867000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330259.049838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.146900</td>\n",
       "      <td>55.200000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.666529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4441000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8304111.0</td>\n",
       "      <td>234</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>45.00</td>\n",
       "      <td>86</td>\n",
       "      <td>0.045234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>423</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>2.018636e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.774596e+06</td>\n",
       "      <td>106.363636</td>\n",
       "      <td>153609.090909</td>\n",
       "      <td>0.165289</td>\n",
       "      <td>20.454545</td>\n",
       "      <td>39.090909</td>\n",
       "      <td>0.240642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268595</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.244755</td>\n",
       "      <td>192.272727</td>\n",
       "      <td>200885.298869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.584814</td>\n",
       "      <td>15286.462036</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>2.035541</td>\n",
       "      <td>3.890145</td>\n",
       "      <td>0.045234</td>\n",
       "      <td>19.134087</td>\n",
       "      <td>123.882353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.818182</td>\n",
       "      <td>0.026860</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.328283</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.038371</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>4441000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8304111.0</td>\n",
       "      <td>234</td>\n",
       "      <td>337940</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>45.00</td>\n",
       "      <td>86</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>423</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>201863.636364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>377459.590909</td>\n",
       "      <td>10.636364</td>\n",
       "      <td>15360.909091</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>2.045455</td>\n",
       "      <td>3.909091</td>\n",
       "      <td>19.227273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>57.333333</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>4613395.0</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>0.036075</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>24.230769</td>\n",
       "      <td>46.307692</td>\n",
       "      <td>1.878543e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.512639e+09</td>\n",
       "      <td>98982</td>\n",
       "      <td>142948620</td>\n",
       "      <td>153.818182</td>\n",
       "      <td>19035.0</td>\n",
       "      <td>36378</td>\n",
       "      <td>10.987013</td>\n",
       "      <td>10.987013</td>\n",
       "      <td>8.240260</td>\n",
       "      <td>27.467532</td>\n",
       "      <td>115350.649351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215691.194805</td>\n",
       "      <td>6.077922</td>\n",
       "      <td>8777.662338</td>\n",
       "      <td>1.168831</td>\n",
       "      <td>2.233766</td>\n",
       "      <td>115350.649351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215691.194805</td>\n",
       "      <td>6.077922</td>\n",
       "      <td>8777.662338</td>\n",
       "      <td>0.009445</td>\n",
       "      <td>1.168831</td>\n",
       "      <td>2.233766</td>\n",
       "      <td>86512.987013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161768.396104</td>\n",
       "      <td>4.558442</td>\n",
       "      <td>6583.246753</td>\n",
       "      <td>0.876623</td>\n",
       "      <td>1.675325</td>\n",
       "      <td>288376.623377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>539227.987013</td>\n",
       "      <td>15.194805</td>\n",
       "      <td>0.023613</td>\n",
       "      <td>2.922078</td>\n",
       "      <td>5.584416</td>\n",
       "      <td>-0.358404</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>-0.449314</td>\n",
       "      <td>-0.524180</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>-0.550324</td>\n",
       "      <td>-0.533230</td>\n",
       "      <td>-4441000.0</td>\n",
       "      <td>4623.916667</td>\n",
       "      <td>4644.890693</td>\n",
       "      <td>-65.500875</td>\n",
       "      <td>-5.497876</td>\n",
       "      <td>-66.500875</td>\n",
       "      <td>-40.500875</td>\n",
       "      <td>-81.500875</td>\n",
       "      <td>-0.500875</td>\n",
       "      <td>3.832459</td>\n",
       "      <td>297.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>329</td>\n",
       "      <td>-2937</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>1101401.0</td>\n",
       "      <td>-2761710.0</td>\n",
       "      <td>5.542401e+06</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-402.000000</td>\n",
       "      <td>60.002999</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-206.0</td>\n",
       "      <td>60.002999</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-3234.0</td>\n",
       "      <td>-276.0</td>\n",
       "      <td>-234.0</td>\n",
       "      <td>-3500.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-3224.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>-35.002999</td>\n",
       "      <td>-76.002999</td>\n",
       "      <td>-163</td>\n",
       "      <td>26.00</td>\n",
       "      <td>-15</td>\n",
       "      <td>-3429</td>\n",
       "      <td>4103060.0</td>\n",
       "      <td>-41.00</td>\n",
       "      <td>3266</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-14</td>\n",
       "      <td>46.00</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>3</td>\n",
       "      <td>-7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>-0.529412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.590909</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.538462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.590909</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.538462</td>\n",
       "      <td>-0.363636</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.590909</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>-10</td>\n",
       "      <td>-0.136364</td>\n",
       "      <td>-0.212121</td>\n",
       "      <td>-0.101010</td>\n",
       "      <td>-0.083916</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>-0.061497</td>\n",
       "      <td>-0.137255</td>\n",
       "      <td>-0.009050</td>\n",
       "      <td>-0.590909</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.538462</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.035354</td>\n",
       "      <td>0.052448</td>\n",
       "      <td>0.525974</td>\n",
       "      <td>-10</td>\n",
       "      <td>-44.954545</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>-0.019481</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.647186</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.038961</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>-0.038961</td>\n",
       "      <td>-8.304111e+06</td>\n",
       "      <td>-0.045455</td>\n",
       "      <td>-10.935065</td>\n",
       "      <td>10.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAIPI5141G</td>\n",
       "      <td>20211116185506</td>\n",
       "      <td>H</td>\n",
       "      <td>0.420485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>14</td>\n",
       "      <td>1.499917</td>\n",
       "      <td>3.498751</td>\n",
       "      <td>I</td>\n",
       "      <td>46</td>\n",
       "      <td>1.333278</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333222</td>\n",
       "      <td>2.999334</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.332556</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>1.499750</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>8.992008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>298700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120251.0</td>\n",
       "      <td>120251.0</td>\n",
       "      <td>6.012550e+04</td>\n",
       "      <td>40083.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15944.000000</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>15944.000000</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>238.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>231.500000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.132034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.887841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450.0</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.132034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10530.379333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>10666.666667</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>233000.0</td>\n",
       "      <td>201000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77739.565216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.076580</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.816846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>308700.0</td>\n",
       "      <td>181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>0.019763</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>2033</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>3.011667e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.145000e+04</td>\n",
       "      <td>30.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.120370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>338.833333</td>\n",
       "      <td>3571.146245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.577075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592885</td>\n",
       "      <td>0.118577</td>\n",
       "      <td>40.177866</td>\n",
       "      <td>116.357143</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.035000e+04</td>\n",
       "      <td>1.543500e+05</td>\n",
       "      <td>90.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.561728</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1084200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1852200.0</td>\n",
       "      <td>1086</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>12198</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>240100.0</td>\n",
       "      <td>140.777778</td>\n",
       "      <td>0.079772</td>\n",
       "      <td>111.384615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.461538</td>\n",
       "      <td>3.673631e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.275871e+08</td>\n",
       "      <td>367973</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60990</td>\n",
       "      <td>52.128205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>208.512821</td>\n",
       "      <td>4633.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7915.384615</td>\n",
       "      <td>4.641026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18533.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31661.538462</td>\n",
       "      <td>18.564103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>0.060880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.105787</td>\n",
       "      <td>-0.581977</td>\n",
       "      <td>-0.439120</td>\n",
       "      <td>-0.716898</td>\n",
       "      <td>-0.554505</td>\n",
       "      <td>-180700.0</td>\n",
       "      <td>-153.000000</td>\n",
       "      <td>-0.025641</td>\n",
       "      <td>-9.501749</td>\n",
       "      <td>1.999000</td>\n",
       "      <td>-40.501749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-25.501749</td>\n",
       "      <td>4.498251</td>\n",
       "      <td>3.623251</td>\n",
       "      <td>748.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>591</td>\n",
       "      <td>-2728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-60449.0</td>\n",
       "      <td>-188449.0</td>\n",
       "      <td>1.202510e+05</td>\n",
       "      <td>139.0</td>\n",
       "      <td>-1880.000000</td>\n",
       "      <td>11.500750</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>11.500750</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-3476.0</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-3500.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>-114.0</td>\n",
       "      <td>-3433.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-27.500750</td>\n",
       "      <td>-136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>-3455</td>\n",
       "      <td>180700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3319</td>\n",
       "      <td>-1</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.708333</td>\n",
       "      <td>-0.611111</td>\n",
       "      <td>-0.448718</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.019763</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.079365</td>\n",
       "      <td>-0.232143</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>-0.222222</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.115385</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>0.106838</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.102564</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.259615</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.162393</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.102564</td>\n",
       "      <td>-3.087000e+05</td>\n",
       "      <td>-0.102564</td>\n",
       "      <td>-8.897436</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAIPZ7980L</td>\n",
       "      <td>20211017185940</td>\n",
       "      <td>H</td>\n",
       "      <td>0.409987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>28</td>\n",
       "      <td>4.454441</td>\n",
       "      <td>8.070924</td>\n",
       "      <td>Z</td>\n",
       "      <td>46</td>\n",
       "      <td>3.999842</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>45</td>\n",
       "      <td>0.542162</td>\n",
       "      <td>26.162473</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>14.544223</td>\n",
       "      <td>112.444278</td>\n",
       "      <td>20.745064</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>145.855145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1446850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.959592</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.258065</td>\n",
       "      <td>13.276143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124020</td>\n",
       "      <td>1006101.0</td>\n",
       "      <td>230787.0</td>\n",
       "      <td>4.062192e+04</td>\n",
       "      <td>56694.951220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.8</td>\n",
       "      <td>33.56</td>\n",
       "      <td>94.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.622449</td>\n",
       "      <td>710.292</td>\n",
       "      <td>827.172</td>\n",
       "      <td>30.636</td>\n",
       "      <td>94.8</td>\n",
       "      <td>19.035488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.641304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.966940</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.084337</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.043676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46200.0</td>\n",
       "      <td>155465.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5048.0</td>\n",
       "      <td>461.120482</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>61.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>269.052632</td>\n",
       "      <td>106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>176.122807</td>\n",
       "      <td>73.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>100.131148</td>\n",
       "      <td>78.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>57.214286</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>129.524590</td>\n",
       "      <td>78.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2543.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>7.785714</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.557875</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.879518</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.730451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2.619048</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.493171</td>\n",
       "      <td>110.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.393263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.257539</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1.950820</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.562115</td>\n",
       "      <td>7.819277</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.668312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.803279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.613549</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.325301</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.279905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34692.298217</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1156010.0</td>\n",
       "      <td>26883.953488</td>\n",
       "      <td>310000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3019520.0</td>\n",
       "      <td>593511.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101655.448885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.191489</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.883857</td>\n",
       "      <td>24.120690</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.028395</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>597688.8</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>1.35</td>\n",
       "      <td>39.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>107.6</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>1.211429e+06</td>\n",
       "      <td>35442.171865</td>\n",
       "      <td>5.062902e+06</td>\n",
       "      <td>634.285714</td>\n",
       "      <td>2.134603e+06</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>4.821429</td>\n",
       "      <td>140.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.47619</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>384.285714</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>7.857143</td>\n",
       "      <td>1696000.0</td>\n",
       "      <td>49619.040611</td>\n",
       "      <td>7088063.0</td>\n",
       "      <td>888</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>6.75</td>\n",
       "      <td>197</td>\n",
       "      <td>0.022333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>5.653333e+05</td>\n",
       "      <td>16539.680204</td>\n",
       "      <td>2.362688e+06</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>996148.000000</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>65.666667</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>179.333333</td>\n",
       "      <td>37875.930521</td>\n",
       "      <td>1108.117532</td>\n",
       "      <td>19.831266</td>\n",
       "      <td>66739.444169</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.150744</td>\n",
       "      <td>4.399504</td>\n",
       "      <td>0.066998</td>\n",
       "      <td>12.014888</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.130667e+06</td>\n",
       "      <td>4.725375e+06</td>\n",
       "      <td>592.00</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>4.5</td>\n",
       "      <td>131.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>45802.191333</td>\n",
       "      <td>181.846154</td>\n",
       "      <td>0.014652</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.043956</td>\n",
       "      <td>10.153846</td>\n",
       "      <td>5088000.0</td>\n",
       "      <td>148857.121833</td>\n",
       "      <td>21264189.0</td>\n",
       "      <td>2664</td>\n",
       "      <td>8965332</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>20.25</td>\n",
       "      <td>591</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>26920.634921</td>\n",
       "      <td>787.603819</td>\n",
       "      <td>112508.936508</td>\n",
       "      <td>14.095238</td>\n",
       "      <td>47435.619048</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>3.126984</td>\n",
       "      <td>8.539683</td>\n",
       "      <td>49619.040611</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>4252837.8</td>\n",
       "      <td>532.800000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>5.062500</td>\n",
       "      <td>147.750000</td>\n",
       "      <td>9.124480e+08</td>\n",
       "      <td>2.669504e+07</td>\n",
       "      <td>3.813378e+09</td>\n",
       "      <td>477744</td>\n",
       "      <td>1607782872</td>\n",
       "      <td>8.406250</td>\n",
       "      <td>3631.5</td>\n",
       "      <td>105986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.079365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.619048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53841.269841</td>\n",
       "      <td>1575.207638</td>\n",
       "      <td>225017.873016</td>\n",
       "      <td>28.190476</td>\n",
       "      <td>94871.238095</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>6.253968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80761.904762</td>\n",
       "      <td>2362.811458</td>\n",
       "      <td>337526.809524</td>\n",
       "      <td>42.285714</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>9.380952</td>\n",
       "      <td>0.704232</td>\n",
       "      <td>0.719857</td>\n",
       "      <td>0.519857</td>\n",
       "      <td>0.005572</td>\n",
       "      <td>0.386524</td>\n",
       "      <td>-0.113476</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.119857</td>\n",
       "      <td>-0.030143</td>\n",
       "      <td>-1694955.0</td>\n",
       "      <td>-264.278689</td>\n",
       "      <td>31.721311</td>\n",
       "      <td>22.491127</td>\n",
       "      <td>5.097206</td>\n",
       "      <td>-88.508873</td>\n",
       "      <td>29.741127</td>\n",
       "      <td>-160.508873</td>\n",
       "      <td>35.491127</td>\n",
       "      <td>35.491127</td>\n",
       "      <td>61.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>-689.0</td>\n",
       "      <td>-178</td>\n",
       "      <td>-2790</td>\n",
       "      <td>0.620739</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-0.363636</td>\n",
       "      <td>-10.363636</td>\n",
       "      <td>2952986.0</td>\n",
       "      <td>-2439077.0</td>\n",
       "      <td>4.648986e+06</td>\n",
       "      <td>-641.0</td>\n",
       "      <td>-418.473684</td>\n",
       "      <td>-17.393921</td>\n",
       "      <td>-111.0</td>\n",
       "      <td>-874.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>883.0</td>\n",
       "      <td>-462.0</td>\n",
       "      <td>905.606079</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>-750.0</td>\n",
       "      <td>-239.0</td>\n",
       "      <td>-2851.0</td>\n",
       "      <td>-1345.0</td>\n",
       "      <td>-834.0</td>\n",
       "      <td>-3446.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>-2101.0</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>24.643921</td>\n",
       "      <td>-165.606079</td>\n",
       "      <td>-763</td>\n",
       "      <td>118.25</td>\n",
       "      <td>-72</td>\n",
       "      <td>-3375</td>\n",
       "      <td>-1292444.0</td>\n",
       "      <td>-190.25</td>\n",
       "      <td>2612</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-999</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>4.984375</td>\n",
       "      <td>4</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.923077</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.514286</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.723077</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>0.698661</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-0.208791</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-10.285714</td>\n",
       "      <td>-10</td>\n",
       "      <td>-0.589744</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.089744</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.256410</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.907204</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.875458</td>\n",
       "      <td>-8</td>\n",
       "      <td>-6.734127</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>-0.015873</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>-0.031746</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.031746</td>\n",
       "      <td>-0.047619</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>-0.015873</td>\n",
       "      <td>-7.088063e+06</td>\n",
       "      <td>-0.047619</td>\n",
       "      <td>-10.952381</td>\n",
       "      <td>10.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AALPF3903A</td>\n",
       "      <td>20220201134326</td>\n",
       "      <td>H</td>\n",
       "      <td>0.341053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>33</td>\n",
       "      <td>12.597680</td>\n",
       "      <td>5.999500</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>3.499583</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>6</td>\n",
       "      <td>0.113205</td>\n",
       "      <td>22.659447</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18.745564</td>\n",
       "      <td>29.971029</td>\n",
       "      <td>13.246938</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>31.484758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77711.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85509.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.545455</td>\n",
       "      <td>31.230415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.486069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8909.075472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3360.363636</td>\n",
       "      <td>36964.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10626.402857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15280.0</td>\n",
       "      <td>2182.857143</td>\n",
       "      <td>15280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.800</td>\n",
       "      <td>10.900</td>\n",
       "      <td>13.8</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>303.0</td>\n",
       "      <td>5.716981</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.089273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>305.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5685.0</td>\n",
       "      <td>1510.981132</td>\n",
       "      <td>696.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1145.893617</td>\n",
       "      <td>630.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1139.510638</td>\n",
       "      <td>630.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2438.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277.0</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2536.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.566038</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.339356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>329.0</td>\n",
       "      <td>109.666667</td>\n",
       "      <td>150.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>57.039947</td>\n",
       "      <td>2918.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.385284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.357023</td>\n",
       "      <td>11.075472</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.513601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>747.0</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>155.563492</td>\n",
       "      <td>81524.0</td>\n",
       "      <td>1538.188679</td>\n",
       "      <td>59071.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8193.472586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>23333.333333</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>184270.332814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.456031</td>\n",
       "      <td>28.777778</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.562840</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97501.5</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>36.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>460.0</td>\n",
       "      <td>0.026923</td>\n",
       "      <td>1.374000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999528e+05</td>\n",
       "      <td>41.100000</td>\n",
       "      <td>1.170018e+05</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.07500</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.207692</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>0.032308</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>1374000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999528.0</td>\n",
       "      <td>411</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>24.00</td>\n",
       "      <td>435</td>\n",
       "      <td>0.086093</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>1.043478</td>\n",
       "      <td>5520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>1.357037e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.876077e+05</td>\n",
       "      <td>40.592593</td>\n",
       "      <td>115557.333333</td>\n",
       "      <td>0.136296</td>\n",
       "      <td>2.370370</td>\n",
       "      <td>42.962963</td>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.200436</td>\n",
       "      <td>1.185185</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.103060</td>\n",
       "      <td>545.185185</td>\n",
       "      <td>13143.487859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.931567</td>\n",
       "      <td>11192.225166</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.229581</td>\n",
       "      <td>4.161148</td>\n",
       "      <td>0.114790</td>\n",
       "      <td>52.803532</td>\n",
       "      <td>66.424242</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.145000e+05</td>\n",
       "      <td>8.332940e+05</td>\n",
       "      <td>34.25</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011538</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.026923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.088235</td>\n",
       "      <td>0.031222</td>\n",
       "      <td>0.468326</td>\n",
       "      <td>0.380515</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.072851</td>\n",
       "      <td>7.441176</td>\n",
       "      <td>1832000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13332704.0</td>\n",
       "      <td>548</td>\n",
       "      <td>1560024</td>\n",
       "      <td>1.840000</td>\n",
       "      <td>32.00</td>\n",
       "      <td>580</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>7360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>21138.461538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153838.892308</td>\n",
       "      <td>6.323077</td>\n",
       "      <td>18000.276923</td>\n",
       "      <td>0.021231</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>6.692308</td>\n",
       "      <td>84.923077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.318462</td>\n",
       "      <td>100.384615</td>\n",
       "      <td>0.240803</td>\n",
       "      <td>0.074556</td>\n",
       "      <td>1874911.5</td>\n",
       "      <td>77.062500</td>\n",
       "      <td>0.060577</td>\n",
       "      <td>47.652174</td>\n",
       "      <td>2.782609</td>\n",
       "      <td>50.434783</td>\n",
       "      <td>8.427200e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.133044e+09</td>\n",
       "      <td>252080</td>\n",
       "      <td>717611040</td>\n",
       "      <td>846.400000</td>\n",
       "      <td>14720.0</td>\n",
       "      <td>266800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.923077</td>\n",
       "      <td>28.307692</td>\n",
       "      <td>198.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21138.461538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153838.892308</td>\n",
       "      <td>6.323077</td>\n",
       "      <td>18000.276923</td>\n",
       "      <td>0.021231</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>6.692308</td>\n",
       "      <td>7046.153846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51279.630769</td>\n",
       "      <td>2.107692</td>\n",
       "      <td>6000.092308</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>2.230769</td>\n",
       "      <td>49323.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>358957.415385</td>\n",
       "      <td>14.753846</td>\n",
       "      <td>0.049538</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>15.615385</td>\n",
       "      <td>-0.399120</td>\n",
       "      <td>-0.081977</td>\n",
       "      <td>-0.189120</td>\n",
       "      <td>-0.239120</td>\n",
       "      <td>-0.235416</td>\n",
       "      <td>-0.423969</td>\n",
       "      <td>-0.189120</td>\n",
       "      <td>-0.501620</td>\n",
       "      <td>-0.286946</td>\n",
       "      <td>-458000.0</td>\n",
       "      <td>2810.679245</td>\n",
       "      <td>2886.679245</td>\n",
       "      <td>14.993336</td>\n",
       "      <td>19.326891</td>\n",
       "      <td>-44.006664</td>\n",
       "      <td>12.993336</td>\n",
       "      <td>-124.006664</td>\n",
       "      <td>17.993336</td>\n",
       "      <td>20.301028</td>\n",
       "      <td>-109.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>341</td>\n",
       "      <td>-3022</td>\n",
       "      <td>-0.460000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>14181.0</td>\n",
       "      <td>-2860995.0</td>\n",
       "      <td>4.721810e+05</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-1779.333333</td>\n",
       "      <td>4.333555</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-131.0</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>-581.0</td>\n",
       "      <td>-353.0</td>\n",
       "      <td>-253.0</td>\n",
       "      <td>4.333555</td>\n",
       "      <td>-131.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>-2913.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>-3141.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>-3241.0</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>-6.333555</td>\n",
       "      <td>-143.333555</td>\n",
       "      <td>-72</td>\n",
       "      <td>57.00</td>\n",
       "      <td>-80</td>\n",
       "      <td>-3435</td>\n",
       "      <td>67994.0</td>\n",
       "      <td>-137.00</td>\n",
       "      <td>3363</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1003</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.540000</td>\n",
       "      <td>2</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.107143</td>\n",
       "      <td>-0.157143</td>\n",
       "      <td>-2.857143</td>\n",
       "      <td>-0.153439</td>\n",
       "      <td>-0.341991</td>\n",
       "      <td>-0.107143</td>\n",
       "      <td>-0.533613</td>\n",
       "      <td>-0.549451</td>\n",
       "      <td>-0.419643</td>\n",
       "      <td>-0.204969</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>-0.046296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.426471</td>\n",
       "      <td>-0.442308</td>\n",
       "      <td>-0.097826</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.376471</td>\n",
       "      <td>-0.392308</td>\n",
       "      <td>-10.700000</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.380174</td>\n",
       "      <td>-0.396011</td>\n",
       "      <td>-0.266204</td>\n",
       "      <td>-0.051530</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>-0.017456</td>\n",
       "      <td>0.234848</td>\n",
       "      <td>-0.191622</td>\n",
       "      <td>-0.207459</td>\n",
       "      <td>0.137022</td>\n",
       "      <td>-0.426471</td>\n",
       "      <td>-0.442308</td>\n",
       "      <td>-0.097826</td>\n",
       "      <td>0.630317</td>\n",
       "      <td>0.113971</td>\n",
       "      <td>0.328645</td>\n",
       "      <td>0.568778</td>\n",
       "      <td>-7</td>\n",
       "      <td>-7.953846</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>-0.061538</td>\n",
       "      <td>0.129808</td>\n",
       "      <td>0.344482</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>0.214674</td>\n",
       "      <td>-0.046154</td>\n",
       "      <td>-0.107692</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>-0.061538</td>\n",
       "      <td>-3.333176e+06</td>\n",
       "      <td>-0.092308</td>\n",
       "      <td>-10.892308</td>\n",
       "      <td>10.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AALPF4279M</td>\n",
       "      <td>20211105155431</td>\n",
       "      <td>H</td>\n",
       "      <td>0.442491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>3.076763</td>\n",
       "      <td>11.994503</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>1.999889</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>12</td>\n",
       "      <td>0.499979</td>\n",
       "      <td>13.995668</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.999000</td>\n",
       "      <td>59.941059</td>\n",
       "      <td>11.994503</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>18.491254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6907.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>586317.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.238430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399653</td>\n",
       "      <td>414804.0</td>\n",
       "      <td>255341.0</td>\n",
       "      <td>5.516924e+04</td>\n",
       "      <td>17571.291667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000</td>\n",
       "      <td>180.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.550095</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.041667</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.668323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>266.541667</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>182.250000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>163.250000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>78.523810</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>144.761905</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.625000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.269591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.977416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.095238</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.974571</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.639005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.959682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>387000.0</td>\n",
       "      <td>48375.000000</td>\n",
       "      <td>310000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>597188.0</td>\n",
       "      <td>310000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83891.500247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.444444</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.596548</td>\n",
       "      <td>16.866667</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.161999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7444.344023</td>\n",
       "      <td>110.215304</td>\n",
       "      <td>6.151603</td>\n",
       "      <td>2150.845481</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.524781</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.239067</td>\n",
       "      <td>150.714286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2749.370853</td>\n",
       "      <td>20.363636</td>\n",
       "      <td>0.039669</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.079339</td>\n",
       "      <td>7.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13927.690909</td>\n",
       "      <td>206.202814</td>\n",
       "      <td>33149.618182</td>\n",
       "      <td>11.509091</td>\n",
       "      <td>4024.036364</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>1.527273</td>\n",
       "      <td>49.090909</td>\n",
       "      <td>945.096231</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>121548.6</td>\n",
       "      <td>42.200000</td>\n",
       "      <td>0.021818</td>\n",
       "      <td>105.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.298069e+08</td>\n",
       "      <td>3.402346e+06</td>\n",
       "      <td>5.469687e+08</td>\n",
       "      <td>189900</td>\n",
       "      <td>66396600</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>25200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.454545</td>\n",
       "      <td>16.363636</td>\n",
       "      <td>98.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18570.254545</td>\n",
       "      <td>274.937085</td>\n",
       "      <td>44199.490909</td>\n",
       "      <td>15.345455</td>\n",
       "      <td>5365.381818</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>1.309091</td>\n",
       "      <td>2.036364</td>\n",
       "      <td>4642.563636</td>\n",
       "      <td>68.734271</td>\n",
       "      <td>11049.872727</td>\n",
       "      <td>3.836364</td>\n",
       "      <td>1341.345455</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>27855.381818</td>\n",
       "      <td>412.405628</td>\n",
       "      <td>66299.236364</td>\n",
       "      <td>23.018182</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>1.963636</td>\n",
       "      <td>3.054545</td>\n",
       "      <td>0.636524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.719857</td>\n",
       "      <td>0.719857</td>\n",
       "      <td>0.719857</td>\n",
       "      <td>0.005572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519857</td>\n",
       "      <td>0.219857</td>\n",
       "      <td>-255341.0</td>\n",
       "      <td>103.791667</td>\n",
       "      <td>287.791667</td>\n",
       "      <td>8.329224</td>\n",
       "      <td>3.331023</td>\n",
       "      <td>-98.670776</td>\n",
       "      <td>-4.670776</td>\n",
       "      <td>-14.670776</td>\n",
       "      <td>11.329224</td>\n",
       "      <td>13.079224</td>\n",
       "      <td>632.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>527</td>\n",
       "      <td>-2762</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>166370.0</td>\n",
       "      <td>-186032.0</td>\n",
       "      <td>4.217109e+05</td>\n",
       "      <td>179.0</td>\n",
       "      <td>-802.222222</td>\n",
       "      <td>-4.998200</td>\n",
       "      <td>-107.0</td>\n",
       "      <td>-206.0</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-248.0</td>\n",
       "      <td>-4.998200</td>\n",
       "      <td>-206.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-147.0</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>-3394.0</td>\n",
       "      <td>-253.0</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>-3500.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-3247.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>-8.001800</td>\n",
       "      <td>-18.001800</td>\n",
       "      <td>-99</td>\n",
       "      <td>94.00</td>\n",
       "      <td>84</td>\n",
       "      <td>-3388</td>\n",
       "      <td>181567.0</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>3289</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1006</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.727273</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.727273</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10</td>\n",
       "      <td>-0.727273</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.012987</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>-10</td>\n",
       "      <td>-17.945455</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>-0.018182</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>-0.054545</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.231818</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.072727</td>\n",
       "      <td>-0.109091</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>-0.036364</td>\n",
       "      <td>-6.077430e+05</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-9.890909</td>\n",
       "      <td>9.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3631 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID report_timestamp BureauScoreConfidLevel  MissingRate  \\\n",
       "0  AAHPO6801A   20220121153515                      H     0.297000   \n",
       "1  AAIPI5141G   20211116185506                      H     0.420485   \n",
       "2  AAIPZ7980L   20211017185940                      H     0.409987   \n",
       "3  AALPF3903A   20220201134326                      H     0.341053   \n",
       "4  AALPF4279M   20211105155431                      H     0.442491   \n",
       "\n",
       "  Current_Finance_Purpose  Current_Amount_Financed Current_Gender_Code  \\\n",
       "0                     NaN                   310000                   1   \n",
       "1                     NaN                   310000                   1   \n",
       "2                     NaN                   310000                   1   \n",
       "3                     NaN                   310000                   1   \n",
       "4                     NaN                   310000                   1   \n",
       "\n",
       "  First_Name1  Len_Name  Name_nuniq  Tel_nuniq IncomeTaxPAN_5  Len_of_addrs  \\\n",
       "0           O        32    1.999889   2.999667              O            46   \n",
       "1           P        14    1.499917   3.498751              I            46   \n",
       "2           C        28    4.454441   8.070924              Z            46   \n",
       "3           P        33   12.597680   5.999500              F            46   \n",
       "4           F        15    3.076763  11.994503              F            46   \n",
       "\n",
       "   City_nuniq PinCode3  Current_State Current_City  CreditAccountActive  \\\n",
       "0    1.285673      422             27       MUMBAI                    9   \n",
       "1    1.333278      422             27       MUMBAI                    1   \n",
       "2    3.999842      422             27       MUMBAI                   45   \n",
       "3    3.499583      422             27       MUMBAI                    6   \n",
       "4    1.999889      422             27       MUMBAI                   12   \n",
       "\n",
       "   CreditAccountActivePor  State_nuniq  TotalCAPSLast90Days  \\\n",
       "0                0.749938     2.599680                   12   \n",
       "1                0.333222     2.999334                    3   \n",
       "2                0.542162    26.162473                   37   \n",
       "3                0.113205    22.659447                    2   \n",
       "4                0.499979    13.995668                    4   \n",
       "\n",
       "   TotalCAPSLast7Days  TotalCAPSLast30Days  TotalCAPSLast180Days  \\\n",
       "0                   9                    9                    12   \n",
       "1                   0                    3                     3   \n",
       "2                  22                   28                    54   \n",
       "3                   1                    1                     2   \n",
       "4                   1                    2                     5   \n",
       "\n",
       "   CAPSLast7Days  CAPSLast180Days  Pin_nuniq   Pan_nuniq  Ident_nuniq  \\\n",
       "0              0                3   4.166139   32.968032     2.999500   \n",
       "1              0                3   3.332556   10.990010     1.499750   \n",
       "2              1               33  14.544223  112.444278    20.745064   \n",
       "3              1                2  18.745564   29.971029    13.246938   \n",
       "4              1                5   6.999000   59.941059    11.994503   \n",
       "\n",
       "   Pan_nuniq2  Account_nuniq2  Ident_nuniq2  Gender_nuniq  \\\n",
       "0          14              14            60     16.984016   \n",
       "1          14              14            30      8.992008   \n",
       "2          28              14            60    145.855145   \n",
       "3          14              14            60     31.484758   \n",
       "4          14              14            30     18.491254   \n",
       "\n",
       "   Amount_Past_Due35_max_30  Amount_Past_Due35_mean_90  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        0.0   \n",
       "3                       NaN                        NaN   \n",
       "4                       NaN                        0.0   \n",
       "\n",
       "   Amount_Past_Due35_max_90  Amount_Past_Due35_min_90  \\\n",
       "0                       NaN                       NaN   \n",
       "1                       NaN                       NaN   \n",
       "2                       0.0                       0.0   \n",
       "3                       NaN                       NaN   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Amount_Past_Due35_std_90  Amount_Past_Due35_max_9999  \\\n",
       "0                       NaN                     44737.0   \n",
       "1                       NaN                         0.0   \n",
       "2                       0.0                      1045.0   \n",
       "3                       NaN                     77711.0   \n",
       "4                       0.0                      6907.0   \n",
       "\n",
       "   Amount_Past_Due35_min_9999  \\\n",
       "0                         0.0   \n",
       "1                         0.0   \n",
       "2                         0.0   \n",
       "3                         0.0   \n",
       "4                         0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_sum_360  Terms_Duration34_std_30  \\\n",
       "0                                         5308000.0                      NaN   \n",
       "1                                          298700.0                      NaN   \n",
       "2                                         1446850.0                      NaN   \n",
       "3                                           85509.0                      NaN   \n",
       "4                                          586317.0                      NaN   \n",
       "\n",
       "   Terms_Duration34_std_90  Terms_Duration34_sum_360  \\\n",
       "0                      NaN                     360.0   \n",
       "1                      NaN                       0.0   \n",
       "2                 1.959592                      61.0   \n",
       "3                      NaN                       6.0   \n",
       "4                 0.000000                      35.0   \n",
       "\n",
       "   Terms_Duration34_max_360  Terms_Duration34_mean_9999  \\\n",
       "0                     180.0                  135.750000   \n",
       "1                       NaN                         NaN   \n",
       "2                      12.0                    8.258065   \n",
       "3                       6.0                   27.545455   \n",
       "4                      13.0                    3.500000   \n",
       "\n",
       "   Terms_Duration34_std_9999  Payment_Rating34_sum_90  \\\n",
       "0                  65.086001                      NaN   \n",
       "1                        NaN                      NaN   \n",
       "2                  13.276143                      0.0   \n",
       "3                  31.230415                      NaN   \n",
       "4                   4.238430                      0.0   \n",
       "\n",
       "   Payment_Rating34_mean_90  Payment_Rating34_min_90  Payment_Rating34_std_90  \\\n",
       "0                       NaN                      NaN                      NaN   \n",
       "1                       NaN                      NaN                      NaN   \n",
       "2                       0.0                      0.0                      0.0   \n",
       "3                       NaN                      NaN                      NaN   \n",
       "4                       0.0                      0.0                      0.0   \n",
       "\n",
       "   Payment_Rating34_sum_360  Payment_Rating34_mean_360  \\\n",
       "0                       0.0                    0.00000   \n",
       "1                       0.0                    0.00000   \n",
       "2                       1.0                    0.02381   \n",
       "3                       0.0                    0.00000   \n",
       "4                       0.0                    0.00000   \n",
       "\n",
       "   Payment_Rating34_max_360  Payment_Rating34_min_360  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       1.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Payment_Rating34_std_360  Payment_Rating34_sum_9999  \\\n",
       "0                  0.000000                        4.0   \n",
       "1                  0.000000                        0.0   \n",
       "2                  0.152455                        1.0   \n",
       "3                  0.000000                       23.0   \n",
       "4                  0.000000                        2.0   \n",
       "\n",
       "   Payment_Rating34_max_9999  Payment_Rating34_min_9999  \\\n",
       "0                        4.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        1.0                        0.0   \n",
       "3                        6.0                        0.0   \n",
       "4                        2.0                        0.0   \n",
       "\n",
       "   Payment_Rating34_std_9999  Current_Balance35_sum_360  \\\n",
       "0                   1.149919                  5146651.0   \n",
       "1                   0.000000                   120251.0   \n",
       "2                   0.124020                  1006101.0   \n",
       "3                   1.486069                        0.0   \n",
       "4                   0.399653                   414804.0   \n",
       "\n",
       "   Current_Balance35_max_360  Current_Balance35_std_360  \\\n",
       "0                  4371915.0               1.798590e+06   \n",
       "1                   120251.0               6.012550e+04   \n",
       "2                   230787.0               4.062192e+04   \n",
       "3                        0.0               0.000000e+00   \n",
       "4                   255341.0               5.516924e+04   \n",
       "\n",
       "   Current_Balance35_mean_9999  Settlement_Amount37_mean_360  \\\n",
       "0                461866.750000                           NaN   \n",
       "1                 40083.666667                           NaN   \n",
       "2                 56694.951220                           0.0   \n",
       "3                  8909.075472                           NaN   \n",
       "4                 17571.291667                           NaN   \n",
       "\n",
       "   Settlement_Amount37_std_360  Settlement_Amount37_mean_9999  \\\n",
       "0                          NaN                        67000.0   \n",
       "1                          NaN                            NaN   \n",
       "2                          0.0                            0.0   \n",
       "3                          NaN                            0.0   \n",
       "4                          NaN                            NaN   \n",
       "\n",
       "   Settlement_Amount37_max_9999  Settlement_Amount37_min_9999  \\\n",
       "0                       67000.0                       67000.0   \n",
       "1                           NaN                           NaN   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           NaN                           NaN   \n",
       "\n",
       "   Value_of_Collateral39_std_90  Value_of_Collateral39_std_360  \\\n",
       "0                           NaN                            NaN   \n",
       "1                           NaN                            NaN   \n",
       "2                           0.0                            0.0   \n",
       "3                           NaN                            NaN   \n",
       "4                           NaN                            NaN   \n",
       "\n",
       "   Written_Off_Amt_Total41_sum_360  Written_Off_Amt_Total41_std_360  \\\n",
       "0                              0.0                              0.0   \n",
       "1                              0.0                              NaN   \n",
       "2                              0.0                              0.0   \n",
       "3                              0.0                              NaN   \n",
       "4                              0.0                              NaN   \n",
       "\n",
       "   Written_Off_Amt_Total41_mean_9999  Written_Off_Amt_Total41_max_9999  \\\n",
       "0                       27173.666667                           81521.0   \n",
       "1                       15944.000000                           15944.0   \n",
       "2                           0.000000                               0.0   \n",
       "3                        3360.363636                           36964.0   \n",
       "4                                NaN                               NaN   \n",
       "\n",
       "   Written_Off_Amt_Total41_min_9999  Written_Off_Amt_Total41_std_9999  \\\n",
       "0                               0.0                      38429.367939   \n",
       "1                           15944.0                          0.000000   \n",
       "2                               0.0                          0.000000   \n",
       "3                               0.0                      10626.402857   \n",
       "4                               NaN                               NaN   \n",
       "\n",
       "   Written_Off_Amt_Principal45_sum_360  Written_Off_Amt_Principal45_min_360  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  NaN   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  NaN   \n",
       "4                                  0.0                                  NaN   \n",
       "\n",
       "   Written_Off_Amt_Principal45_std_360  Written_Off_Amt_Principal45_sum_9999  \\\n",
       "0                                  0.0                               49982.0   \n",
       "1                                  NaN                               15944.0   \n",
       "2                                  0.0                                   0.0   \n",
       "3                                  NaN                               15280.0   \n",
       "4                                  NaN                                   0.0   \n",
       "\n",
       "   Written_Off_Amt_Principal45_mean_9999  \\\n",
       "0                           16660.666667   \n",
       "1                           15944.000000   \n",
       "2                               0.000000   \n",
       "3                            2182.857143   \n",
       "4                                    NaN   \n",
       "\n",
       "   Written_Off_Amt_Principal45_max_9999  Written_Off_Amt_Principal45_min_9999  \\\n",
       "0                               49982.0                                   0.0   \n",
       "1                               15944.0                               15944.0   \n",
       "2                                   0.0                                   0.0   \n",
       "3                               15280.0                                   0.0   \n",
       "4                                   NaN                                   NaN   \n",
       "\n",
       "   Rate_of_Interest36_sum_30  Rate_of_Interest36_max_30  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                        NaN   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   Rate_of_Interest36_min_30  Rate_of_Interest36_std_30  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                        NaN   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   Rate_of_Interest36_sum_90  Rate_of_Interest36_mean_90  \\\n",
       "0                        NaN                         NaN   \n",
       "1                        NaN                         NaN   \n",
       "2                      167.8                       33.56   \n",
       "3                        NaN                         NaN   \n",
       "4                       54.0                       18.00   \n",
       "\n",
       "   Rate_of_Interest36_max_90  Rate_of_Interest36_min_90  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                       94.8                       18.0   \n",
       "3                        NaN                        NaN   \n",
       "4                       18.0                       18.0   \n",
       "\n",
       "   Rate_of_Interest36_std_90  Rate_of_Interest36_sum_360  \\\n",
       "0                        NaN                       0.000   \n",
       "1                        NaN                       0.000   \n",
       "2                  30.622449                     710.292   \n",
       "3                        NaN                       0.000   \n",
       "4                   0.000000                     180.000   \n",
       "\n",
       "   Rate_of_Interest36_sum_9999  Rate_of_Interest36_mean_9999  \\\n",
       "0                       45.000                        45.000   \n",
       "1                        0.000                           NaN   \n",
       "2                      827.172                        30.636   \n",
       "3                       21.800                        10.900   \n",
       "4                      180.000                        18.000   \n",
       "\n",
       "   Rate_of_Interest36_max_9999  Rate_of_Interest36_std_9999  \\\n",
       "0                         45.0                     0.000000   \n",
       "1                          NaN                          NaN   \n",
       "2                         94.8                    19.035488   \n",
       "3                         13.8                     2.900000   \n",
       "4                         18.0                     0.000000   \n",
       "\n",
       "   Repayment_Tenure36_std_30  Repayment_Tenure36_std_90  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                   1.641304   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                   0.489898   \n",
       "\n",
       "   Repayment_Tenure36_mean_360  Repayment_Tenure36_min_360  \\\n",
       "0                   180.000000                       180.0   \n",
       "1                     0.000000                         0.0   \n",
       "2                     1.000000                         0.0   \n",
       "3                     2.000000                         0.0   \n",
       "4                     1.666667                         0.0   \n",
       "\n",
       "   Repayment_Tenure36_std_360  Repayment_Tenure36_sum_9999  \\\n",
       "0                    0.000000                        543.0   \n",
       "1                    0.000000                          0.0   \n",
       "2                    1.966940                        256.0   \n",
       "3                    2.828427                        303.0   \n",
       "4                    3.550095                         49.0   \n",
       "\n",
       "   Repayment_Tenure36_mean_9999  Repayment_Tenure36_max_9999  \\\n",
       "0                     45.250000                        180.0   \n",
       "1                      0.000000                          0.0   \n",
       "2                      3.084337                         60.0   \n",
       "3                      5.716981                         94.0   \n",
       "4                      2.041667                         13.0   \n",
       "\n",
       "   Repayment_Tenure36_min_9999  Repayment_Tenure36_std_9999  \\\n",
       "0                          0.0                    74.210427   \n",
       "1                          0.0                     0.000000   \n",
       "2                          0.0                     9.043676   \n",
       "3                          0.0                    18.089273   \n",
       "4                          0.0                     3.668323   \n",
       "\n",
       "   Income26_count_30  Income26_min_9999  Income26_std_9999  \\\n",
       "0                NaN           480000.0                0.0   \n",
       "1                NaN                NaN                NaN   \n",
       "2                NaN            46200.0           155465.5   \n",
       "3                NaN                NaN                NaN   \n",
       "4                NaN            17000.0            11500.0   \n",
       "\n",
       "   Open_Date29_max_30  Open_Date29_mean_30  Open_Date29_mode_30  \\\n",
       "0                 NaN                  NaN                  NaN   \n",
       "1                 NaN                  NaN                  NaN   \n",
       "2                 NaN                  NaN                  NaN   \n",
       "3                 NaN                  NaN                  NaN   \n",
       "4                 NaN                  NaN                  NaN   \n",
       "\n",
       "   Open_Date29_nuniq_30  Open_Date29_maxcount_30  Open_Date29_mode_90  \\\n",
       "0                   NaN                      NaN                  NaN   \n",
       "1                   NaN                      NaN                  NaN   \n",
       "2                   NaN                      NaN                 78.0   \n",
       "3                   NaN                      NaN                  NaN   \n",
       "4                   NaN                      NaN                 49.0   \n",
       "\n",
       "   Open_Date29_nuniq_90  Open_Date29_max_360  Open_Date29_mode_360  \\\n",
       "0                   NaN                310.0                 192.0   \n",
       "1                   NaN                238.0                 124.0   \n",
       "2                  10.0                326.0                  78.0   \n",
       "3                   NaN                305.0                 302.0   \n",
       "4                   4.0                354.0                  49.0   \n",
       "\n",
       "   Open_Date29_maxcount_360  Open_Date29_max_9999  Open_Date29_mean_9999  \\\n",
       "0                       1.0                4203.0            1028.750000   \n",
       "1                       1.0                 955.0             439.000000   \n",
       "2                       4.0                5048.0             461.120482   \n",
       "3                       2.0                5685.0            1510.981132   \n",
       "4                       2.0                1087.0             266.541667   \n",
       "\n",
       "   Open_Date29_mode_9999  Open_Date29_maxcount_9999  \\\n",
       "0                  888.0                        2.0   \n",
       "1                  124.0                        1.0   \n",
       "2                   78.0                        4.0   \n",
       "3                  696.0                        4.0   \n",
       "4                   49.0                        2.0   \n",
       "\n",
       "   Portfolio_Type34_nuniq_30  Portfolio_Type34_nuniq_90  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                        2.0   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        1.0   \n",
       "\n",
       "   Portfolio_Type34_nuniq_360 Portfolio_Type34_mode_9999  \\\n",
       "0                         2.0                          R   \n",
       "1                         1.0                          I   \n",
       "2                         2.0                          I   \n",
       "3                         1.0                          I   \n",
       "4                         1.0                          I   \n",
       "\n",
       "   Portfolio_Type34_nuniq_9999 Account_Type32_mode_30  \\\n",
       "0                          3.0                    NaN   \n",
       "1                          1.0                    NaN   \n",
       "2                          3.0                    NaN   \n",
       "3                          2.0                    NaN   \n",
       "4                          1.0                    NaN   \n",
       "\n",
       "   Account_Type32_nuniq_30 Account_Type32_mode_90  Account_Type32_nuniq_90  \\\n",
       "0                      NaN                    NaN                      NaN   \n",
       "1                      NaN                    NaN                      NaN   \n",
       "2                      NaN                    5.0                      4.0   \n",
       "3                      NaN                    NaN                      NaN   \n",
       "4                      NaN                    5.0                      2.0   \n",
       "\n",
       "  Account_Type32_mode_360  Account_Type32_nuniq_360 Account_Type32_mode_9999  \\\n",
       "0                     2.0                       2.0                     10.0   \n",
       "1                     7.0                       1.0                      7.0   \n",
       "2                     5.0                       5.0                      5.0   \n",
       "3                     7.0                       2.0                      7.0   \n",
       "4                     5.0                       4.0                      5.0   \n",
       "\n",
       "   Account_Type32_nuniq_9999  Occupation_Code35_nuniq_30  \\\n",
       "0                        6.0                         NaN   \n",
       "1                        2.0                         NaN   \n",
       "2                        9.0                         NaN   \n",
       "3                        6.0                         NaN   \n",
       "4                        4.0                         NaN   \n",
       "\n",
       "   Occupation_Code35_nuniq_90  Occupation_Code35_nuniq_360  \\\n",
       "0                         NaN                          1.0   \n",
       "1                         NaN                          1.0   \n",
       "2                         1.0                          1.0   \n",
       "3                         NaN                          1.0   \n",
       "4                         1.0                          2.0   \n",
       "\n",
       "  CurrencyCode32_mode_360 CurrencyCode32_mode_9999  \\\n",
       "0                     INR                      INR   \n",
       "1                     INR                      INR   \n",
       "2                     INR                      INR   \n",
       "3                     INR                      INR   \n",
       "4                     INR                      INR   \n",
       "\n",
       "  AccountHoldertypeCode41_mode_90  AccountHoldertypeCode41_nuniq_90  \\\n",
       "0                             NaN                               NaN   \n",
       "1                             NaN                               NaN   \n",
       "2                             1.0                               1.0   \n",
       "3                             NaN                               NaN   \n",
       "4                             1.0                               1.0   \n",
       "\n",
       "   AccountHoldertypeCode41_nuniq_360  AccountHoldertypeCode41_nuniq_9999  \\\n",
       "0                                1.0                                 2.0   \n",
       "1                                1.0                                 1.0   \n",
       "2                                1.0                                 2.0   \n",
       "3                                1.0                                 1.0   \n",
       "4                                1.0                                 1.0   \n",
       "\n",
       "   Payment_History_Profile43_mode_30  Payment_History_Profile43_mode_90  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  0   \n",
       "2                                  0                                  1   \n",
       "3                                  0                                  0   \n",
       "4                                  0                                  1   \n",
       "\n",
       "   Payment_History_Profile43_nuniq_90  Payment_History_Profile43_mode_360  \\\n",
       "0                                 NaN                                  36   \n",
       "1                                 NaN                                  36   \n",
       "2                                 2.0                                   1   \n",
       "3                                 NaN                                  36   \n",
       "4                                 1.0                                   1   \n",
       "\n",
       "   Payment_History_Profile43_nuniq_360  Payment_History_Profile43_mode_9999  \\\n",
       "0                                  2.0                                   36   \n",
       "1                                  2.0                                   36   \n",
       "2                                 12.0                                    1   \n",
       "3                                  2.0                                    1   \n",
       "4                                  6.0                                    1   \n",
       "\n",
       "   Payment_History_Profile43_nuniq_9999  Date_Closed31_mode_30  \\\n",
       "0                                  12.0                    NaN   \n",
       "1                                   3.0                    NaN   \n",
       "2                                  27.0                    NaN   \n",
       "3                                  23.0                    NaN   \n",
       "4                                   8.0                    NaN   \n",
       "\n",
       "   Date_Closed31_nuniq_30  Date_Closed31_maxcount_30  Date_Closed31_max_90  \\\n",
       "0                     NaN                        NaN                   NaN   \n",
       "1                     NaN                        NaN                   NaN   \n",
       "2                     NaN                        NaN                  69.0   \n",
       "3                     NaN                        NaN                   NaN   \n",
       "4                     NaN                        NaN                  66.0   \n",
       "\n",
       "   Date_Closed31_min_90  Date_Closed31_mean_90  Date_Closed31_mode_90  \\\n",
       "0                   NaN                    NaN                    NaN   \n",
       "1                   NaN                    NaN                    NaN   \n",
       "2                  54.0                   61.5                   54.0   \n",
       "3                   NaN                    NaN                    NaN   \n",
       "4                  44.0                   55.0                   44.0   \n",
       "\n",
       "   Date_Closed31_nuniq_90  Date_Closed31_maxcount_90  Date_Closed31_mode_360  \\\n",
       "0                     NaN                        NaN                     0.0   \n",
       "1                     NaN                        NaN                   153.0   \n",
       "2                     3.0                        1.0                   106.0   \n",
       "3                     NaN                        NaN                    53.0   \n",
       "4                     3.0                        1.0                    44.0   \n",
       "\n",
       "   Date_Closed31_nuniq_360  Date_Closed31_maxcount_360  \\\n",
       "0                      1.0                         0.0   \n",
       "1                      2.0                         1.0   \n",
       "2                     24.0                         3.0   \n",
       "3                      2.0                         2.0   \n",
       "4                     12.0                         1.0   \n",
       "\n",
       "   Date_Closed31_mean_9999  Date_Closed31_mode_9999  \\\n",
       "0               281.333333                     88.0   \n",
       "1               231.500000                    153.0   \n",
       "2               269.052632                    106.0   \n",
       "3              1145.893617                    630.0   \n",
       "4               182.250000                     44.0   \n",
       "\n",
       "   Date_of_Last_Payment40_nuniq_30  Date_of_Last_Payment40_maxcount_30  \\\n",
       "0                              NaN                                 NaN   \n",
       "1                              NaN                                 NaN   \n",
       "2                              NaN                                 NaN   \n",
       "3                              NaN                                 NaN   \n",
       "4                              NaN                                 NaN   \n",
       "\n",
       "   Date_of_Last_Payment40_nuniq_90  Date_of_Last_Payment40_maxcount_90  \\\n",
       "0                              NaN                                 NaN   \n",
       "1                              NaN                                 NaN   \n",
       "2                              4.0                                 2.0   \n",
       "3                              NaN                                 NaN   \n",
       "4                              4.0                                 2.0   \n",
       "\n",
       "   Date_of_Last_Payment40_min_360  Date_of_Last_Payment40_mode_360  \\\n",
       "0                            21.0                             21.0   \n",
       "1                           153.0                            153.0   \n",
       "2                            54.0                            106.0   \n",
       "3                            53.0                             53.0   \n",
       "4                            34.0                             34.0   \n",
       "\n",
       "   Date_of_Last_Payment40_maxcount_360  Date_of_Last_Payment40_mean_9999  \\\n",
       "0                                  2.0                        129.416667   \n",
       "1                                  1.0                        153.000000   \n",
       "2                                  3.0                        176.122807   \n",
       "3                                  2.0                       1139.510638   \n",
       "4                                  4.0                        163.250000   \n",
       "\n",
       "   Date_of_Last_Payment40_mode_9999  Date_of_Last_Payment40_nuniq_9999  \\\n",
       "0                              46.0                                8.0   \n",
       "1                             153.0                                2.0   \n",
       "2                              73.0                               42.0   \n",
       "3                             630.0                               28.0   \n",
       "4                              34.0                               16.0   \n",
       "\n",
       "   Date_of_Last_Payment40_maxcount_9999  Date_Reported33_nuniq_30  \\\n",
       "0                                   4.0                       NaN   \n",
       "1                                   1.0                       NaN   \n",
       "2                                   4.0                       NaN   \n",
       "3                                   4.0                       NaN   \n",
       "4                                   4.0                       NaN   \n",
       "\n",
       "   Date_Reported33_max_90  Date_Reported33_mode_90  Date_Reported33_nuniq_90  \\\n",
       "0                     NaN                      NaN                       NaN   \n",
       "1                     NaN                      NaN                       NaN   \n",
       "2                    78.0                     47.0                       3.0   \n",
       "3                     NaN                      NaN                       NaN   \n",
       "4                    66.0                     36.0                       2.0   \n",
       "\n",
       "   Date_Reported33_maxcount_90  Date_Reported33_max_360  \\\n",
       "0                          NaN                     21.0   \n",
       "1                          NaN                     77.0   \n",
       "2                          9.0                    269.0   \n",
       "3                          NaN                     32.0   \n",
       "4                          4.0                    158.0   \n",
       "\n",
       "   Date_Reported33_mean_360  Date_Reported33_mode_360  \\\n",
       "0                 21.000000                      21.0   \n",
       "1                 77.000000                      77.0   \n",
       "2                100.131148                      78.0   \n",
       "3                 32.000000                      32.0   \n",
       "4                 78.523810                      66.0   \n",
       "\n",
       "   Date_Reported33_nuniq_360  Date_Reported33_max_9999  \\\n",
       "0                        1.0                     418.0   \n",
       "1                        1.0                     310.0   \n",
       "2                       11.0                    1692.0   \n",
       "3                        1.0                    2438.0   \n",
       "4                        6.0                     889.0   \n",
       "\n",
       "   Date_Reported33_mode_9999  Date_Reported33_nuniq_9999  \\\n",
       "0                       21.0                         7.0   \n",
       "1                       77.0                         2.0   \n",
       "2                       47.0                        22.0   \n",
       "3                      611.0                        24.0   \n",
       "4                       66.0                         8.0   \n",
       "\n",
       "   Date_Reported33_maxcount_9999  DateOfAddition34_nuniq_30  \\\n",
       "0                            6.0                        NaN   \n",
       "1                            2.0                        NaN   \n",
       "2                           22.0                        NaN   \n",
       "3                            9.0                        NaN   \n",
       "4                            8.0                        NaN   \n",
       "\n",
       "   DateOfAddition34_max_90  DateOfAddition34_mean_90  \\\n",
       "0                      NaN                       NaN   \n",
       "1                      NaN                       NaN   \n",
       "2                     78.0                 57.214286   \n",
       "3                      NaN                       NaN   \n",
       "4                     66.0                 42.000000   \n",
       "\n",
       "   DateOfAddition34_nuniq_90  DateOfAddition34_maxcount_90  \\\n",
       "0                        NaN                           NaN   \n",
       "1                        NaN                           NaN   \n",
       "2                        3.0                           8.0   \n",
       "3                        NaN                           NaN   \n",
       "4                        2.0                           4.0   \n",
       "\n",
       "   DateOfAddition34_max_360  DateOfAddition34_mean_360  \\\n",
       "0                     296.0                 250.500000   \n",
       "1                     230.0                 169.000000   \n",
       "2                     300.0                 129.524590   \n",
       "3                     277.0                 175.000000   \n",
       "4                     340.0                 144.761905   \n",
       "\n",
       "   DateOfAddition34_mode_360  DateOfAddition34_maxcount_360  \\\n",
       "0                      205.0                            1.0   \n",
       "1                      108.0                            1.0   \n",
       "2                       78.0                           14.0   \n",
       "3                      124.0                            2.0   \n",
       "4                       97.0                            6.0   \n",
       "\n",
       "   DateOfAddition34_max_9999  DateOfAddition34_min_9999  \\\n",
       "0                     1878.0                      205.0   \n",
       "1                      808.0                      108.0   \n",
       "2                     2543.0                       35.0   \n",
       "3                     2536.0                      124.0   \n",
       "4                     1071.0                       36.0   \n",
       "\n",
       "   DateOfAddition34_mode_9999  DateOfAddition34_nuniq_9999  \\\n",
       "0                       752.0                         11.0   \n",
       "1                       108.0                          3.0   \n",
       "2                        78.0                         29.0   \n",
       "3                       611.0                         26.0   \n",
       "4                        97.0                         11.0   \n",
       "\n",
       "   DateOfAddition34_maxcount_9999  Account_Status34_mode_30  \\\n",
       "0                             2.0                       NaN   \n",
       "1                             1.0                       NaN   \n",
       "2                            14.0                       NaN   \n",
       "3                             9.0                       NaN   \n",
       "4                             6.0                       NaN   \n",
       "\n",
       "   Account_Status34_nuniq_30  Account_Status34_mode_90  \\\n",
       "0                        NaN                       NaN   \n",
       "1                        NaN                       NaN   \n",
       "2                        NaN                      11.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        NaN                      11.0   \n",
       "\n",
       "   Account_Status34_nuniq_90  Account_Status34_nuniq_360  \\\n",
       "0                        NaN                         1.0   \n",
       "1                        NaN                         2.0   \n",
       "2                        3.0                         6.0   \n",
       "3                        NaN                         2.0   \n",
       "4                        2.0                         2.0   \n",
       "\n",
       "  Account_Status34_mode_9999  Account_Status34_nuniq_9999  Month50_sum_30  \\\n",
       "0                         11                          4.0             NaN   \n",
       "1                         13                          2.0             NaN   \n",
       "2                         11                          6.0             NaN   \n",
       "3                         13                          9.0             NaN   \n",
       "4                         13                          3.0             NaN   \n",
       "\n",
       "   Month50_mean_30  Month50_std_30  Month50_sum_90  Month50_mean_90  \\\n",
       "0              NaN             NaN             NaN              NaN   \n",
       "1              NaN             NaN             NaN              NaN   \n",
       "2              NaN             NaN           109.0         7.785714   \n",
       "3              NaN             NaN             NaN              NaN   \n",
       "4              NaN             NaN            44.0         8.800000   \n",
       "\n",
       "   Month50_max_90  Month50_std_90  Month50_max_360  Month50_min_360  \\\n",
       "0             NaN             NaN             12.0             12.0   \n",
       "1             NaN             NaN              8.0              8.0   \n",
       "2             9.0        0.557875             12.0              3.0   \n",
       "3             NaN             NaN             12.0             12.0   \n",
       "4             9.0        0.400000             12.0              5.0   \n",
       "\n",
       "   Month50_mean_9999  Month50_max_9999  Month50_min_9999  Month50_std_9999  \\\n",
       "0          12.000000              12.0              12.0          0.000000   \n",
       "1           9.000000              11.0               8.0          1.414214   \n",
       "2           7.879518              12.0               3.0          2.730451   \n",
       "3           8.566038              12.0               3.0          3.339356   \n",
       "4           8.625000              12.0               5.0          2.269591   \n",
       "\n",
       "   Days_Past_Due58_sum_90  Days_Past_Due58_min_90  Days_Past_Due58_std_90  \\\n",
       "0                     NaN                     NaN                     NaN   \n",
       "1                     NaN                     NaN                     NaN   \n",
       "2                     0.0                     0.0                     0.0   \n",
       "3                     NaN                     NaN                     NaN   \n",
       "4                     0.0                     0.0                     0.0   \n",
       "\n",
       "   Days_Past_Due58_sum_360  Days_Past_Due58_mean_360  Days_Past_Due58_max_360  \\\n",
       "0                      0.0                  0.000000                      0.0   \n",
       "1                      0.0                  0.000000                      0.0   \n",
       "2                    110.0                  2.619048                     54.0   \n",
       "3                    329.0                109.666667                    150.0   \n",
       "4                      0.0                  0.000000                      0.0   \n",
       "\n",
       "   Days_Past_Due58_min_360  Days_Past_Due58_std_360  Days_Past_Due58_sum_9999  \\\n",
       "0                      0.0                 0.000000                     267.0   \n",
       "1                      0.0                 0.000000                     450.0   \n",
       "2                      0.0                11.493171                     110.0   \n",
       "3                     29.0                57.039947                    2918.0   \n",
       "4                      0.0                 0.000000                     114.0   \n",
       "\n",
       "   Days_Past_Due58_max_9999  Days_Past_Due58_min_9999  \\\n",
       "0                     129.0                       0.0   \n",
       "1                     450.0                       0.0   \n",
       "2                      54.0                       0.0   \n",
       "3                     900.0                       0.0   \n",
       "4                      87.0                       0.0   \n",
       "\n",
       "   Days_Past_Due58_std_9999  Duecount53_mean_30  Duecount53_min_30  \\\n",
       "0                 34.132402                 NaN                NaN   \n",
       "1                212.132034                 NaN                NaN   \n",
       "2                  9.393263                 NaN                NaN   \n",
       "3                144.385284                 NaN                NaN   \n",
       "4                 17.977416                 NaN                NaN   \n",
       "\n",
       "   Duecount53_std_30  Duecount53_sum_90  Duecount53_mean_90  \\\n",
       "0                NaN                NaN                 NaN   \n",
       "1                NaN                NaN                 NaN   \n",
       "2                NaN               15.0            1.071429   \n",
       "3                NaN                NaN                 NaN   \n",
       "4                NaN                5.0            1.000000   \n",
       "\n",
       "   Duecount53_max_90  Duecount53_min_90  Duecount53_std_90  \\\n",
       "0                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN   \n",
       "2                2.0                1.0           0.257539   \n",
       "3                NaN                NaN                NaN   \n",
       "4                1.0                1.0           0.000000   \n",
       "\n",
       "   Duecount53_sum_360  Duecount53_mean_360  Duecount53_max_360  \\\n",
       "0                17.0             8.500000                10.0   \n",
       "1                 8.0             4.000000                 6.0   \n",
       "2               119.0             1.950820                 8.0   \n",
       "3                17.0             5.666667                 9.0   \n",
       "4                65.0             3.095238                 9.0   \n",
       "\n",
       "   Duecount53_min_360  Duecount53_std_360  Duecount53_mean_9999  \\\n",
       "0                 7.0            1.500000             22.166667   \n",
       "1                 2.0            2.000000              8.000000   \n",
       "2                 1.0            1.562115              7.819277   \n",
       "3                 4.0            2.357023             11.075472   \n",
       "4                 1.0            2.974571              4.416667   \n",
       "\n",
       "   Duecount53_max_9999  Duecount53_min_9999  Duecount53_std_9999  \\\n",
       "0                 55.0                  7.0            12.408554   \n",
       "1                 16.0                  2.0             5.887841   \n",
       "2                 83.0                  1.0            13.668312   \n",
       "3                 83.0                  1.0            22.513601   \n",
       "4                 33.0                  1.0             6.639005   \n",
       "\n",
       "   Duesum51_mean_30  Duesum51_std_30  Duesum51_mean_90  Duesum51_max_90  \\\n",
       "0               NaN              NaN               NaN              NaN   \n",
       "1               NaN              NaN               NaN              NaN   \n",
       "2               NaN              NaN               0.0              0.0   \n",
       "3               NaN              NaN               NaN              NaN   \n",
       "4               NaN              NaN               0.0              0.0   \n",
       "\n",
       "   Duesum51_sum_360  Duesum51_mean_360  Duesum51_min_360  Duesum51_std_360  \\\n",
       "0               0.0           0.000000               0.0          0.000000   \n",
       "1               0.0           0.000000               0.0          0.000000   \n",
       "2             110.0           1.803279               0.0          9.613549   \n",
       "3             747.0         249.000000              29.0        155.563492   \n",
       "4               0.0           0.000000               0.0          0.000000   \n",
       "\n",
       "   Duesum51_sum_9999  Duesum51_mean_9999  Duesum51_max_9999  \\\n",
       "0             1294.0          107.833333             1085.0   \n",
       "1              450.0          150.000000              450.0   \n",
       "2              110.0            1.325301               54.0   \n",
       "3            81524.0         1538.188679            59071.0   \n",
       "4              140.0            5.833333               87.0   \n",
       "\n",
       "   Duesum51_min_9999  Duesum51_std_9999  Amount_Financed35_std_7  \\\n",
       "0                0.0         295.475276                      NaN   \n",
       "1                0.0         212.132034                      NaN   \n",
       "2                0.0           8.279905                      0.0   \n",
       "3                0.0        8193.472586                      0.0   \n",
       "4                0.0          19.959682                      0.0   \n",
       "\n",
       "   Amount_Financed35_max_30  Amount_Financed35_min_30  \\\n",
       "0                       NaN                       NaN   \n",
       "1                   25000.0                       0.0   \n",
       "2                  100000.0                       0.0   \n",
       "3                   50000.0                   50000.0   \n",
       "4                   50000.0                       0.0   \n",
       "\n",
       "   Amount_Financed35_std_30  Amount_Financed35_count_90  \\\n",
       "0                       NaN                         3.0   \n",
       "1              10530.379333                         3.0   \n",
       "2              34692.298217                        16.0   \n",
       "3                  0.000000                         2.0   \n",
       "4              25000.000000                         4.0   \n",
       "\n",
       "   Amount_Financed35_min_90  Amount_Financed35_count_360  \\\n",
       "0                       0.0                          4.0   \n",
       "1                       0.0                          3.0   \n",
       "2                       0.0                         47.0   \n",
       "3                   10000.0                          3.0   \n",
       "4                       0.0                          9.0   \n",
       "\n",
       "   Amount_Financed35_sum_360  Amount_Financed35_mean_360  \\\n",
       "0                  1177000.0               294250.000000   \n",
       "1                    32000.0                10666.666667   \n",
       "2                  1156010.0                26883.953488   \n",
       "3                    70000.0                23333.333333   \n",
       "4                   387000.0                48375.000000   \n",
       "\n",
       "   Amount_Financed35_max_360  Amount_Financed35_min_360  \\\n",
       "0                   867000.0                        0.0   \n",
       "1                    25000.0                        0.0   \n",
       "2                   310000.0                        0.0   \n",
       "3                    50000.0                    10000.0   \n",
       "4                   310000.0                        0.0   \n",
       "\n",
       "   Amount_Financed35_count_9999  Amount_Financed35_sum_9999  \\\n",
       "0                           5.0                   1237000.0   \n",
       "1                           5.0                    233000.0   \n",
       "2                          58.0                   3019520.0   \n",
       "3                           9.0                    720000.0   \n",
       "4                          15.0                    597188.0   \n",
       "\n",
       "   Amount_Financed35_max_9999  Amount_Financed35_min_9999  \\\n",
       "0                    867000.0                         0.0   \n",
       "1                    201000.0                         0.0   \n",
       "2                    593511.0                         0.0   \n",
       "3                    600000.0                     10000.0   \n",
       "4                    310000.0                         0.0   \n",
       "\n",
       "   Amount_Financed35_std_9999  Duration_Of_Agreement41_std_7  \\\n",
       "0               330259.049838                            NaN   \n",
       "1                77739.565216                            NaN   \n",
       "2               101655.448885                            0.0   \n",
       "3               184270.332814                            0.0   \n",
       "4                83891.500247                            0.0   \n",
       "\n",
       "   Duration_Of_Agreement41_min_30  Duration_Of_Agreement41_min_90  \\\n",
       "0                             NaN                             0.0   \n",
       "1                             1.0                             1.0   \n",
       "2                             0.0                             0.0   \n",
       "3                             1.0                             1.0   \n",
       "4                             0.0                             0.0   \n",
       "\n",
       "   Duration_Of_Agreement41_mean_360  Duration_Of_Agreement41_max_360  \\\n",
       "0                         66.000000                            180.0   \n",
       "1                         18.333333                             48.0   \n",
       "2                         20.191489                            150.0   \n",
       "3                         14.333333                             36.0   \n",
       "4                         19.444444                             48.0   \n",
       "\n",
       "   Duration_Of_Agreement41_min_360  Duration_Of_Agreement41_std_360  \\\n",
       "0                              0.0                        68.146900   \n",
       "1                              1.0                        21.076580   \n",
       "2                              0.0                        31.883857   \n",
       "3                              1.0                        15.456031   \n",
       "4                              0.0                        19.596548   \n",
       "\n",
       "   Duration_Of_Agreement41_mean_9999  Duration_Of_Agreement41_max_9999  \\\n",
       "0                          55.200000                             180.0   \n",
       "1                          13.400000                              48.0   \n",
       "2                          24.120690                             150.0   \n",
       "3                          28.777778                              36.0   \n",
       "4                          16.866667                              48.0   \n",
       "\n",
       "   Duration_Of_Agreement41_min_9999  Duration_Of_Agreement41_std_9999  \\\n",
       "0                               0.0                         64.666529   \n",
       "1                               0.0                         17.816846   \n",
       "2                               0.0                         31.028395   \n",
       "3                               1.0                         13.562840   \n",
       "4                               0.0                         19.161999   \n",
       "\n",
       "   Date_of_Request35_mode_7  Date_of_Request35_nuniq_7  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       1.0                        1.0   \n",
       "3                       6.0                        1.0   \n",
       "4                       5.0                        1.0   \n",
       "\n",
       "   Date_of_Request35_nuniq_90  Enquiry_Reason34_nuniq_7  \\\n",
       "0                         3.0                       NaN   \n",
       "1                         3.0                       NaN   \n",
       "2                        12.0                       1.0   \n",
       "3                         2.0                       1.0   \n",
       "4                         4.0                       1.0   \n",
       "\n",
       "   Enquiry_Reason34_mode_30  ...  feature_409 * Outstanding_Balance_UnSecured  \\\n",
       "0                       NaN  ...                                          0.0   \n",
       "1                      13.0  ...                                          NaN   \n",
       "2                      13.0  ...                                     597688.8   \n",
       "3                      13.0  ...                                      97501.5   \n",
       "4                      13.0  ...                                          0.0   \n",
       "\n",
       "   feature_409 * Payment_Rating34_mean_9999  \\\n",
       "0                                  0.000000   \n",
       "1                                       NaN   \n",
       "2                                  0.003125   \n",
       "3                                  0.115000   \n",
       "4                                  0.000000   \n",
       "\n",
       "   feature_409 * Rate_of_Interest36_min_9999  feature_409 * Tel_nuniq2  \\\n",
       "0                                       0.00                      0.00   \n",
       "1                                        NaN                       NaN   \n",
       "2                                       1.35                     39.40   \n",
       "3                                       2.00                     36.25   \n",
       "4                                       0.00                      0.00   \n",
       "\n",
       "   feature_409 * feature_638  feature_409 * feature_643  \\\n",
       "0                       0.00                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                       0.20                   0.066667   \n",
       "3                       0.75                   0.074074   \n",
       "4                       0.00                   0.000000   \n",
       "\n",
       "   feature_409 * feature_701  feature_409 * feature_710  \\\n",
       "0                   0.000000                        0.0   \n",
       "1                        NaN                        NaN   \n",
       "2                   0.133333                        0.6   \n",
       "3                   0.062500                        1.0   \n",
       "4                        NaN                        0.0   \n",
       "\n",
       "   feature_409 * feature_778  feature_409 * feature_781  \\\n",
       "0                   0.000000                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                   0.200000                   0.150000   \n",
       "3                   0.173077                   0.086957   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_409 * feature_8  feature_409 * feature_888  \\\n",
       "0                      0.0                   0.000000   \n",
       "1                      NaN                        NaN   \n",
       "2                    107.6                   0.009524   \n",
       "3                    460.0                   0.026923   \n",
       "4                      0.0                   0.000000   \n",
       "\n",
       "   feature_410 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                       0.000000e+00                 \n",
       "1                                                NaN                 \n",
       "2                                       1.211429e+06                 \n",
       "3                                       1.374000e+05                 \n",
       "4                                       0.000000e+00                 \n",
       "\n",
       "   feature_410 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                       35442.171865               \n",
       "3                                                NaN               \n",
       "4                                           0.000000               \n",
       "\n",
       "   feature_410 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                       0.000000e+00                 \n",
       "1                                                NaN                 \n",
       "2                                       5.062902e+06                 \n",
       "3                                       9.999528e+05                 \n",
       "4                                       0.000000e+00                 \n",
       "\n",
       "   feature_410 * Name_nuniq2  feature_410 * Outstanding_Balance_UnSecured  \\\n",
       "0                   0.000000                                 0.000000e+00   \n",
       "1                        NaN                                          NaN   \n",
       "2                 634.285714                                 2.134603e+06   \n",
       "3                  41.100000                                 1.170018e+05   \n",
       "4                   0.000000                                 0.000000e+00   \n",
       "\n",
       "   feature_410 * Payment_Rating34_mean_9999  \\\n",
       "0                                  0.000000   \n",
       "1                                       NaN   \n",
       "2                                  0.011161   \n",
       "3                                  0.138000   \n",
       "4                                  0.000000   \n",
       "\n",
       "   feature_410 * Rate_of_Interest36_min_9999  feature_410 * Tel_nuniq2  \\\n",
       "0                                   0.000000                  0.000000   \n",
       "1                                        NaN                       NaN   \n",
       "2                                   4.821429                140.714286   \n",
       "3                                   2.400000                 43.500000   \n",
       "4                                   0.000000                  0.000000   \n",
       "\n",
       "   feature_410 * feature_638  feature_410 * feature_643  \\\n",
       "0                   0.000000                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                   0.714286                   0.238095   \n",
       "3                   0.900000                   0.088889   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_410 * feature_701  feature_410 * feature_710  \\\n",
       "0                    0.00000                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                    0.47619                   2.142857   \n",
       "3                    0.07500                   1.200000   \n",
       "4                        NaN                   0.000000   \n",
       "\n",
       "   feature_410 * feature_778  feature_410 * feature_781  \\\n",
       "0                   0.000000                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                   0.714286                   0.535714   \n",
       "3                   0.207692                   0.104348   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_410 * feature_8  feature_410 * feature_888  \\\n",
       "0                 0.000000                   0.000000   \n",
       "1                      NaN                        NaN   \n",
       "2               384.285714                   0.034014   \n",
       "3               552.000000                   0.032308   \n",
       "4                 0.000000                   0.000000   \n",
       "\n",
       "   feature_410 * feature_9  \\\n",
       "0                 0.000000   \n",
       "1                      NaN   \n",
       "2                 7.857143   \n",
       "3                 3.300000   \n",
       "4                 0.000000   \n",
       "\n",
       "   feature_638 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                          4441000.0                 \n",
       "1                                           180700.0                 \n",
       "2                                          1696000.0                 \n",
       "3                                          1374000.0                 \n",
       "4                                                0.0                 \n",
       "\n",
       "   feature_638 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                       49619.040611               \n",
       "3                                                NaN               \n",
       "4                                           0.000000               \n",
       "\n",
       "   feature_638 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                          8304111.0                 \n",
       "1                                           308700.0                 \n",
       "2                                          7088063.0                 \n",
       "3                                          9999528.0                 \n",
       "4                                                0.0                 \n",
       "\n",
       "   feature_638 * Name_nuniq2  feature_638 * Payment_Rating34_mean_9999  \\\n",
       "0                        234                                  0.363636   \n",
       "1                        181                                  0.000000   \n",
       "2                        888                                  0.015625   \n",
       "3                        411                                  1.380000   \n",
       "4                          0                                  0.000000   \n",
       "\n",
       "   feature_638 * Rate_of_Interest36_min_9999  feature_638 * Tel_nuniq2  \\\n",
       "0                                      45.00                        86   \n",
       "1                                        NaN                        30   \n",
       "2                                       6.75                       197   \n",
       "3                                      24.00                       435   \n",
       "4                                       0.00                         0   \n",
       "\n",
       "   feature_638 * feature_669  feature_638 * feature_701  \\\n",
       "0                   0.045234                   0.000000   \n",
       "1                   0.019763                   0.500000   \n",
       "2                   0.022333                   0.666667   \n",
       "3                   0.086093                   0.750000   \n",
       "4                   0.000000                        NaN   \n",
       "\n",
       "   feature_638 * feature_710  feature_638 * feature_762  \\\n",
       "0                          1                   0.045455   \n",
       "1                          6                   0.000000   \n",
       "2                          3                   0.015873   \n",
       "3                         12                   0.138462   \n",
       "4                          0                   0.000000   \n",
       "\n",
       "   feature_638 * feature_781  feature_638 * feature_8  \\\n",
       "0                   0.538462                      423   \n",
       "1                   0.615385                     2033   \n",
       "2                   0.750000                      538   \n",
       "3                   1.043478                     5520   \n",
       "4                   0.000000                        0   \n",
       "\n",
       "   feature_638 * feature_804  feature_638 * feature_846  \\\n",
       "0                   0.025974                   0.025974   \n",
       "1                   0.025641                   0.000000   \n",
       "2                   0.000000                   0.031746   \n",
       "3                   0.000000                   0.138462   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_638 * feature_874  feature_638 * feature_888  \\\n",
       "0                   0.019481                   0.064935   \n",
       "1                   0.000000                   0.102564   \n",
       "2                   0.000000                   0.047619   \n",
       "3                   0.046154                   0.323077   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_643 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                       2.018636e+06                 \n",
       "1                                       3.011667e+04                 \n",
       "2                                       5.653333e+05                 \n",
       "3                                       1.357037e+05                 \n",
       "4                                       0.000000e+00                 \n",
       "\n",
       "   feature_643 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                       16539.680204               \n",
       "3                                                NaN               \n",
       "4                                           0.000000               \n",
       "\n",
       "   feature_643 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                       3.774596e+06                 \n",
       "1                                       5.145000e+04                 \n",
       "2                                       2.362688e+06                 \n",
       "3                                       9.876077e+05                 \n",
       "4                                       0.000000e+00                 \n",
       "\n",
       "   feature_643 * Name_nuniq2  feature_643 * Outstanding_Balance_UnSecured  \\\n",
       "0                 106.363636                                153609.090909   \n",
       "1                  30.166667                                     0.000000   \n",
       "2                 296.000000                                996148.000000   \n",
       "3                  40.592593                                115557.333333   \n",
       "4                   0.000000                                     0.000000   \n",
       "\n",
       "   feature_643 * Payment_Rating34_mean_9999  \\\n",
       "0                                  0.165289   \n",
       "1                                  0.000000   \n",
       "2                                  0.005208   \n",
       "3                                  0.136296   \n",
       "4                                  0.000000   \n",
       "\n",
       "   feature_643 * Rate_of_Interest36_min_9999  feature_643 * Tel_nuniq2  \\\n",
       "0                                  20.454545                 39.090909   \n",
       "1                                        NaN                  5.000000   \n",
       "2                                   2.250000                 65.666667   \n",
       "3                                   2.370370                 42.962963   \n",
       "4                                   0.000000                  0.000000   \n",
       "\n",
       "   feature_643 * feature_700  feature_643 * feature_701  \\\n",
       "0                   0.240642                   0.000000   \n",
       "1                   0.107143                   0.083333   \n",
       "2                   0.277778                   0.222222   \n",
       "3                   0.143659                   0.074074   \n",
       "4                   0.000000                        NaN   \n",
       "\n",
       "   feature_643 * feature_702  feature_643 * feature_710  \\\n",
       "0                   0.268595                   0.454545   \n",
       "1                   0.120370                   1.000000   \n",
       "2                   0.307692                   1.000000   \n",
       "3                   0.200436                   1.185185   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_643 * feature_778  feature_643 * feature_781  \\\n",
       "0                   0.303030                   0.244755   \n",
       "1                   0.145833                   0.102564   \n",
       "2                   0.333333                   0.250000   \n",
       "3                   0.205128                   0.103060   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_643 * feature_8  \\\n",
       "0               192.272727   \n",
       "1               338.833333   \n",
       "2               179.333333   \n",
       "3               545.185185   \n",
       "4                 0.000000   \n",
       "\n",
       "   feature_669 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                      200885.298869                 \n",
       "1                                        3571.146245                 \n",
       "2                                       37875.930521                 \n",
       "3                                       13143.487859                 \n",
       "4                                        7444.344023                 \n",
       "\n",
       "   feature_669 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                        1108.117532               \n",
       "3                                                NaN               \n",
       "4                                         110.215304               \n",
       "\n",
       "   feature_669 * Name_nuniq2  feature_669 * Outstanding_Balance_UnSecured  \\\n",
       "0                  10.584814                                 15286.462036   \n",
       "1                   3.577075                                     0.000000   \n",
       "2                  19.831266                                 66739.444169   \n",
       "3                   3.931567                                 11192.225166   \n",
       "4                   6.151603                                  2150.845481   \n",
       "\n",
       "   feature_669 * Payment_Rating34_mean_9999  \\\n",
       "0                                  0.016449   \n",
       "1                                  0.000000   \n",
       "2                                  0.000349   \n",
       "3                                  0.013201   \n",
       "4                                  0.002430   \n",
       "\n",
       "   feature_669 * Rate_of_Interest36_min_9999  feature_669 * Tel_nuniq2  \\\n",
       "0                                   2.035541                  3.890145   \n",
       "1                                        NaN                  0.592885   \n",
       "2                                   0.150744                  4.399504   \n",
       "3                                   0.229581                  4.161148   \n",
       "4                                   0.524781                  0.816327   \n",
       "\n",
       "   feature_669 * feature_710  feature_669 * feature_8  \\\n",
       "0                   0.045234                19.134087   \n",
       "1                   0.118577                40.177866   \n",
       "2                   0.066998                12.014888   \n",
       "3                   0.114790                52.803532   \n",
       "4                   0.000000                26.239067   \n",
       "\n",
       "   feature_700 * Name_nuniq2  feature_700 * feature_701  \\\n",
       "0                 123.882353                   0.000000   \n",
       "1                 116.357143                   0.321429   \n",
       "2                 740.000000                   0.555556   \n",
       "3                  66.424242                   0.121212   \n",
       "4                 150.714286                        NaN   \n",
       "\n",
       "   feature_700 * feature_779  \\\n",
       "0                   0.294118   \n",
       "1                   0.500000   \n",
       "2                   0.500000   \n",
       "3                   0.272727   \n",
       "4                   0.142857   \n",
       "\n",
       "   feature_701 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                       0.000000e+00                 \n",
       "1                                       9.035000e+04                 \n",
       "2                                       1.130667e+06                 \n",
       "3                                       1.145000e+05                 \n",
       "4                                                NaN                 \n",
       "\n",
       "   feature_701 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                       0.000000e+00                 \n",
       "1                                       1.543500e+05                 \n",
       "2                                       4.725375e+06                 \n",
       "3                                       8.332940e+05                 \n",
       "4                                                NaN                 \n",
       "\n",
       "   feature_701 * Name_nuniq2  feature_701 * Payment_Rating34_mean_9999  \\\n",
       "0                       0.00                                  0.000000   \n",
       "1                      90.50                                  0.000000   \n",
       "2                     592.00                                  0.010417   \n",
       "3                      34.25                                  0.115000   \n",
       "4                        NaN                                       NaN   \n",
       "\n",
       "   feature_701 * Rate_of_Interest36_min_9999  feature_701 * Tel_nuniq2  \\\n",
       "0                                        0.0                  0.000000   \n",
       "1                                        NaN                 15.000000   \n",
       "2                                        4.5                131.333333   \n",
       "3                                        2.0                 36.250000   \n",
       "4                                        NaN                       NaN   \n",
       "\n",
       "   feature_701 * feature_710  feature_701 * feature_762  \\\n",
       "0                        0.0                   0.000000   \n",
       "1                        3.0                   0.000000   \n",
       "2                        2.0                   0.010582   \n",
       "3                        1.0                   0.011538   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   feature_701 * feature_778  feature_701 * feature_781  \\\n",
       "0                   0.000000                   0.000000   \n",
       "1                   0.437500                   0.307692   \n",
       "2                   0.666667                   0.500000   \n",
       "3                   0.173077                   0.086957   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   feature_701 * feature_888  \\\n",
       "0                   0.000000   \n",
       "1                   0.051282   \n",
       "2                   0.031746   \n",
       "3                   0.026923   \n",
       "4                        NaN   \n",
       "\n",
       "   feature_702 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                       45802.191333               \n",
       "3                                                NaN               \n",
       "4                                        2749.370853               \n",
       "\n",
       "   feature_702 * Tel_nuniq2  feature_702 * feature_762  \\\n",
       "0                 50.818182                   0.026860   \n",
       "1                 21.666667                   0.000000   \n",
       "2                181.846154                   0.014652   \n",
       "3                 98.088235                   0.031222   \n",
       "4                 20.363636                   0.039669   \n",
       "\n",
       "   feature_702 * feature_778  feature_702 * feature_779  \\\n",
       "0                   0.393939                   0.328283   \n",
       "1                   0.631944                   0.561728   \n",
       "2                   0.923077                   0.553846   \n",
       "3                   0.468326                   0.380515   \n",
       "4                   0.181818                   0.145455   \n",
       "\n",
       "   feature_702 * feature_781  feature_702 * feature_888  \\\n",
       "0                   0.318182                   0.038371   \n",
       "1                   0.444444                   0.074074   \n",
       "2                   0.692308                   0.043956   \n",
       "3                   0.235294                   0.072851   \n",
       "4                   0.363636                   0.079339   \n",
       "\n",
       "   feature_702 * feature_9  \\\n",
       "0                 6.500000   \n",
       "1                 6.500000   \n",
       "2                10.153846   \n",
       "3                 7.441176   \n",
       "4                 7.272727   \n",
       "\n",
       "   feature_710 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                          4441000.0                 \n",
       "1                                          1084200.0                 \n",
       "2                                          5088000.0                 \n",
       "3                                          1832000.0                 \n",
       "4                                                0.0                 \n",
       "\n",
       "   feature_710 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                      148857.121833               \n",
       "3                                                NaN               \n",
       "4                                           0.000000               \n",
       "\n",
       "   feature_710 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                          8304111.0                 \n",
       "1                                          1852200.0                 \n",
       "2                                         21264189.0                 \n",
       "3                                         13332704.0                 \n",
       "4                                                0.0                 \n",
       "\n",
       "   feature_710 * Name_nuniq2  feature_710 * Outstanding_Balance_UnSecured  \\\n",
       "0                        234                                       337940   \n",
       "1                       1086                                            0   \n",
       "2                       2664                                      8965332   \n",
       "3                        548                                      1560024   \n",
       "4                          0                                            0   \n",
       "\n",
       "   feature_710 * Payment_Rating34_mean_9999  \\\n",
       "0                                  0.363636   \n",
       "1                                  0.000000   \n",
       "2                                  0.046875   \n",
       "3                                  1.840000   \n",
       "4                                  0.000000   \n",
       "\n",
       "   feature_710 * Rate_of_Interest36_min_9999  feature_710 * Tel_nuniq2  \\\n",
       "0                                      45.00                        86   \n",
       "1                                        NaN                       180   \n",
       "2                                      20.25                       591   \n",
       "3                                      32.00                       580   \n",
       "4                                       0.00                         0   \n",
       "\n",
       "   feature_710 * feature_762  feature_710 * feature_779  \\\n",
       "0                   0.045455                   0.555556   \n",
       "1                   0.000000                   4.666667   \n",
       "2                   0.047619                   1.800000   \n",
       "3                   0.184615                   2.250000   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_710 * feature_8  feature_710 * feature_804  \\\n",
       "0                      423                   0.025974   \n",
       "1                    12198                   0.153846   \n",
       "2                     1614                   0.000000   \n",
       "3                     7360                   0.000000   \n",
       "4                        0                   0.000000   \n",
       "\n",
       "   feature_710 * feature_846  feature_710 * feature_874  \\\n",
       "0                   0.025974                   0.019481   \n",
       "1                   0.000000                   0.000000   \n",
       "2                   0.095238                   0.000000   \n",
       "3                   0.184615                   0.061538   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_710 * feature_888  \\\n",
       "0                   0.064935   \n",
       "1                   0.615385   \n",
       "2                   0.142857   \n",
       "3                   0.430769   \n",
       "4                   0.000000   \n",
       "\n",
       "   feature_762 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                      201863.636364                 \n",
       "1                                           0.000000                 \n",
       "2                                       26920.634921                 \n",
       "3                                       21138.461538                 \n",
       "4                                       13927.690909                 \n",
       "\n",
       "   feature_762 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                         787.603819               \n",
       "3                                                NaN               \n",
       "4                                         206.202814               \n",
       "\n",
       "   feature_762 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                      377459.590909                 \n",
       "1                                           0.000000                 \n",
       "2                                      112508.936508                 \n",
       "3                                      153838.892308                 \n",
       "4                                       33149.618182                 \n",
       "\n",
       "   feature_762 * Name_nuniq2  feature_762 * Outstanding_Balance_UnSecured  \\\n",
       "0                  10.636364                                 15360.909091   \n",
       "1                   0.000000                                     0.000000   \n",
       "2                  14.095238                                 47435.619048   \n",
       "3                   6.323077                                 18000.276923   \n",
       "4                  11.509091                                  4024.036364   \n",
       "\n",
       "   feature_762 * Payment_Rating34_mean_9999  \\\n",
       "0                                  0.016529   \n",
       "1                                  0.000000   \n",
       "2                                  0.000248   \n",
       "3                                  0.021231   \n",
       "4                                  0.004545   \n",
       "\n",
       "   feature_762 * Rate_of_Interest36_min_9999  feature_762 * Tel_nuniq2  \\\n",
       "0                                   2.045455                  3.909091   \n",
       "1                                        NaN                  0.000000   \n",
       "2                                   0.107143                  3.126984   \n",
       "3                                   0.369231                  6.692308   \n",
       "4                                   0.981818                  1.527273   \n",
       "\n",
       "   feature_762 * feature_8  \\\n",
       "0                19.227273   \n",
       "1                 0.000000   \n",
       "2                 8.539683   \n",
       "3                84.923077   \n",
       "4                49.090909   \n",
       "\n",
       "   feature_778 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                       49619.040611               \n",
       "3                                                NaN               \n",
       "4                                         945.096231               \n",
       "\n",
       "   feature_778 * Payment_Rating34_mean_9999  feature_778 * Tel_nuniq2  \\\n",
       "0                                  0.242424                 57.333333   \n",
       "1                                  0.000000                 26.250000   \n",
       "2                                  0.015625                197.000000   \n",
       "3                                  0.318462                100.384615   \n",
       "4                                  0.020833                  7.000000   \n",
       "\n",
       "   feature_778 * feature_781  feature_778 * feature_888  \\\n",
       "0                   0.358974                   0.043290   \n",
       "1                   0.538462                   0.089744   \n",
       "2                   0.750000                   0.047619   \n",
       "3                   0.240803                   0.074556   \n",
       "4                   0.125000                   0.027273   \n",
       "\n",
       "   feature_779 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                          4613395.0                 \n",
       "1                                           240100.0                 \n",
       "2                                          4252837.8                 \n",
       "3                                          1874911.5                 \n",
       "4                                           121548.6                 \n",
       "\n",
       "   feature_779 * Name_nuniq2  feature_779 * feature_888  \\\n",
       "0                 130.000000                   0.036075   \n",
       "1                 140.777778                   0.079772   \n",
       "2                 532.800000                   0.028571   \n",
       "3                  77.062500                   0.060577   \n",
       "4                  42.200000                   0.021818   \n",
       "\n",
       "   feature_781 * Name_nuniq2  feature_781 * Rate_of_Interest36_min_9999  \\\n",
       "0                 126.000000                                  24.230769   \n",
       "1                 111.384615                                        NaN   \n",
       "2                 666.000000                                   5.062500   \n",
       "3                  47.652174                                   2.782609   \n",
       "4                 105.500000                                   9.000000   \n",
       "\n",
       "   feature_781 * Tel_nuniq2  \\\n",
       "0                 46.307692   \n",
       "1                 18.461538   \n",
       "2                147.750000   \n",
       "3                 50.434783   \n",
       "4                 14.000000   \n",
       "\n",
       "   feature_8 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                       1.878543e+09               \n",
       "1                                       3.673631e+08               \n",
       "2                                       9.124480e+08               \n",
       "3                                       8.427200e+08               \n",
       "4                                       2.298069e+08               \n",
       "\n",
       "   feature_8 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN             \n",
       "1                                                NaN             \n",
       "2                                       2.669504e+07             \n",
       "3                                                NaN             \n",
       "4                                       3.402346e+06             \n",
       "\n",
       "   feature_8 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                       3.512639e+09               \n",
       "1                                       6.275871e+08               \n",
       "2                                       3.813378e+09               \n",
       "3                                       6.133044e+09               \n",
       "4                                       5.469687e+08               \n",
       "\n",
       "   feature_8 * Name_nuniq2  feature_8 * Outstanding_Balance_UnSecured  \\\n",
       "0                    98982                                  142948620   \n",
       "1                   367973                                          0   \n",
       "2                   477744                                 1607782872   \n",
       "3                   252080                                  717611040   \n",
       "4                   189900                                   66396600   \n",
       "\n",
       "   feature_8 * Payment_Rating34_mean_9999  \\\n",
       "0                              153.818182   \n",
       "1                                0.000000   \n",
       "2                                8.406250   \n",
       "3                              846.400000   \n",
       "4                               75.000000   \n",
       "\n",
       "   feature_8 * Rate_of_Interest36_min_9999  feature_8 * Tel_nuniq2  \\\n",
       "0                                  19035.0                   36378   \n",
       "1                                      NaN                   60990   \n",
       "2                                   3631.5                  105986   \n",
       "3                                  14720.0                  266800   \n",
       "4                                  16200.0                   25200   \n",
       "\n",
       "   feature_8 * feature_804  feature_8 * feature_846  feature_8 * feature_874  \\\n",
       "0                10.987013                10.987013                 8.240260   \n",
       "1                52.128205                 0.000000                 0.000000   \n",
       "2                 0.000000                17.079365                 0.000000   \n",
       "3                 0.000000                84.923077                28.307692   \n",
       "4                 0.000000                65.454545                16.363636   \n",
       "\n",
       "   feature_8 * feature_888  \\\n",
       "0                27.467532   \n",
       "1               208.512821   \n",
       "2                25.619048   \n",
       "3               198.153846   \n",
       "4                98.181818   \n",
       "\n",
       "   feature_804 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                      115350.649351                 \n",
       "1                                        4633.333333                 \n",
       "2                                           0.000000                 \n",
       "3                                           0.000000                 \n",
       "4                                           0.000000                 \n",
       "\n",
       "   feature_804 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                                0.0               \n",
       "3                                                NaN               \n",
       "4                                                0.0               \n",
       "\n",
       "   feature_804 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                      215691.194805                 \n",
       "1                                        7915.384615                 \n",
       "2                                           0.000000                 \n",
       "3                                           0.000000                 \n",
       "4                                           0.000000                 \n",
       "\n",
       "   feature_804 * Name_nuniq2  feature_804 * Outstanding_Balance_UnSecured  \\\n",
       "0                   6.077922                                  8777.662338   \n",
       "1                   4.641026                                     0.000000   \n",
       "2                   0.000000                                     0.000000   \n",
       "3                   0.000000                                     0.000000   \n",
       "4                   0.000000                                     0.000000   \n",
       "\n",
       "   feature_804 * Rate_of_Interest36_min_9999  feature_804 * Tel_nuniq2  \\\n",
       "0                                   1.168831                  2.233766   \n",
       "1                                        NaN                  0.769231   \n",
       "2                                   0.000000                  0.000000   \n",
       "3                                   0.000000                  0.000000   \n",
       "4                                   0.000000                  0.000000   \n",
       "\n",
       "   feature_846 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                      115350.649351                 \n",
       "1                                           0.000000                 \n",
       "2                                       53841.269841                 \n",
       "3                                       21138.461538                 \n",
       "4                                       18570.254545                 \n",
       "\n",
       "   feature_846 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                        1575.207638               \n",
       "3                                                NaN               \n",
       "4                                         274.937085               \n",
       "\n",
       "   feature_846 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                      215691.194805                 \n",
       "1                                           0.000000                 \n",
       "2                                      225017.873016                 \n",
       "3                                      153838.892308                 \n",
       "4                                       44199.490909                 \n",
       "\n",
       "   feature_846 * Name_nuniq2  feature_846 * Outstanding_Balance_UnSecured  \\\n",
       "0                   6.077922                                  8777.662338   \n",
       "1                   0.000000                                     0.000000   \n",
       "2                  28.190476                                 94871.238095   \n",
       "3                   6.323077                                 18000.276923   \n",
       "4                  15.345455                                  5365.381818   \n",
       "\n",
       "   feature_846 * Payment_Rating34_mean_9999  \\\n",
       "0                                  0.009445   \n",
       "1                                  0.000000   \n",
       "2                                  0.000496   \n",
       "3                                  0.021231   \n",
       "4                                  0.006061   \n",
       "\n",
       "   feature_846 * Rate_of_Interest36_min_9999  feature_846 * Tel_nuniq2  \\\n",
       "0                                   1.168831                  2.233766   \n",
       "1                                        NaN                  0.000000   \n",
       "2                                   0.214286                  6.253968   \n",
       "3                                   0.369231                  6.692308   \n",
       "4                                   1.309091                  2.036364   \n",
       "\n",
       "   feature_874 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                       86512.987013                 \n",
       "1                                           0.000000                 \n",
       "2                                           0.000000                 \n",
       "3                                        7046.153846                 \n",
       "4                                        4642.563636                 \n",
       "\n",
       "   feature_874 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                           0.000000               \n",
       "3                                                NaN               \n",
       "4                                          68.734271               \n",
       "\n",
       "   feature_874 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                      161768.396104                 \n",
       "1                                           0.000000                 \n",
       "2                                           0.000000                 \n",
       "3                                       51279.630769                 \n",
       "4                                       11049.872727                 \n",
       "\n",
       "   feature_874 * Name_nuniq2  feature_874 * Outstanding_Balance_UnSecured  \\\n",
       "0                   4.558442                                  6583.246753   \n",
       "1                   0.000000                                     0.000000   \n",
       "2                   0.000000                                     0.000000   \n",
       "3                   2.107692                                  6000.092308   \n",
       "4                   3.836364                                  1341.345455   \n",
       "\n",
       "   feature_874 * Rate_of_Interest36_min_9999  feature_874 * Tel_nuniq2  \\\n",
       "0                                   0.876623                  1.675325   \n",
       "1                                        NaN                  0.000000   \n",
       "2                                   0.000000                  0.000000   \n",
       "3                                   0.123077                  2.230769   \n",
       "4                                   0.327273                  0.509091   \n",
       "\n",
       "   feature_888 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                      288376.623377                 \n",
       "1                                       18533.333333                 \n",
       "2                                       80761.904762                 \n",
       "3                                       49323.076923                 \n",
       "4                                       27855.381818                 \n",
       "\n",
       "   feature_888 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                        2362.811458               \n",
       "3                                                NaN               \n",
       "4                                         412.405628               \n",
       "\n",
       "   feature_888 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                      539227.987013                 \n",
       "1                                       31661.538462                 \n",
       "2                                      337526.809524                 \n",
       "3                                      358957.415385                 \n",
       "4                                       66299.236364                 \n",
       "\n",
       "   feature_888 * Name_nuniq2  feature_888 * Payment_Rating34_mean_9999  \\\n",
       "0                  15.194805                                  0.023613   \n",
       "1                  18.564103                                  0.000000   \n",
       "2                  42.285714                                  0.000744   \n",
       "3                  14.753846                                  0.049538   \n",
       "4                  23.018182                                  0.009091   \n",
       "\n",
       "   feature_888 * Rate_of_Interest36_min_9999  feature_888 * Tel_nuniq2  \\\n",
       "0                                   2.922078                  5.584416   \n",
       "1                                        NaN                  3.076923   \n",
       "2                                   0.321429                  9.380952   \n",
       "3                                   0.861538                 15.615385   \n",
       "4                                   1.963636                  3.054545   \n",
       "\n",
       "   Account_Type32_mode_360vcount - Payment_Rating34_mean_9999  \\\n",
       "0                                          -0.358404            \n",
       "1                                           0.060880            \n",
       "2                                           0.704232            \n",
       "3                                          -0.399120            \n",
       "4                                           0.636524            \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_407  \\\n",
       "0                                     0.005232   \n",
       "1                                          NaN   \n",
       "2                                     0.719857   \n",
       "3                                    -0.081977   \n",
       "4                                          NaN   \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_409  \\\n",
       "0                                     0.005232   \n",
       "1                                          NaN   \n",
       "2                                     0.519857   \n",
       "3                                    -0.189120   \n",
       "4                                     0.719857   \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_410  \\\n",
       "0                                     0.005232   \n",
       "1                                          NaN   \n",
       "2                                     0.005572   \n",
       "3                                    -0.239120   \n",
       "4                                     0.719857   \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_643  \\\n",
       "0                                    -0.449314   \n",
       "1                                    -0.105787   \n",
       "2                                     0.386524   \n",
       "3                                    -0.235416   \n",
       "4                                     0.719857   \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_700  \\\n",
       "0                                    -0.524180   \n",
       "1                                    -0.581977   \n",
       "2                                    -0.113476   \n",
       "3                                    -0.423969   \n",
       "4                                     0.005572   \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_701  \\\n",
       "0                                     0.005232   \n",
       "1                                    -0.439120   \n",
       "2                                     0.053191   \n",
       "3                                    -0.189120   \n",
       "4                                          NaN   \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_779  \\\n",
       "0                                    -0.550324   \n",
       "1                                    -0.716898   \n",
       "2                                     0.119857   \n",
       "3                                    -0.501620   \n",
       "4                                     0.519857   \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_781  \\\n",
       "0                                    -0.533230   \n",
       "1                                    -0.554505   \n",
       "2                                    -0.030143   \n",
       "3                                    -0.286946   \n",
       "4                                     0.219857   \n",
       "\n",
       "   Amount_Past_Due35_max_360 - Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                         -4441000.0                               \n",
       "1                                          -180700.0                               \n",
       "2                                         -1694955.0                               \n",
       "3                                          -458000.0                               \n",
       "4                                          -255341.0                               \n",
       "\n",
       "   Amount_Past_Due35_mean_9999 - Date_of_Last_Payment40_max_360  \\\n",
       "0                                        4623.916667              \n",
       "1                                        -153.000000              \n",
       "2                                        -264.278689              \n",
       "3                                        2810.679245              \n",
       "4                                         103.791667              \n",
       "\n",
       "   Amount_Past_Due35_mean_9999 - feature_804  \\\n",
       "0                                4644.890693   \n",
       "1                                  -0.025641   \n",
       "2                                  31.721311   \n",
       "3                                2886.679245   \n",
       "4                                 287.791667   \n",
       "\n",
       "   Birth_nuniq - Date_of_Request35_mode_90  Birth_nuniq - Email_nuniq  \\\n",
       "0                               -65.500875                  -5.497876   \n",
       "1                                -9.501749                   1.999000   \n",
       "2                                22.491127                   5.097206   \n",
       "3                                14.993336                  19.326891   \n",
       "4                                 8.329224                   3.331023   \n",
       "\n",
       "   Birth_nuniq - Email_nuniq2  Birth_nuniq - Rate_of_Interest36_min_9999  \\\n",
       "0                  -66.500875                                 -40.500875   \n",
       "1                  -40.501749                                        NaN   \n",
       "2                  -88.508873                                  29.741127   \n",
       "3                  -44.006664                                  12.993336   \n",
       "4                  -98.670776                                  -4.670776   \n",
       "\n",
       "   Birth_nuniq - Tel_nuniq2  Birth_nuniq - feature_254  \\\n",
       "0                -81.500875                  -0.500875   \n",
       "1                -25.501749                   4.498251   \n",
       "2               -160.508873                  35.491127   \n",
       "3               -124.006664                  17.993336   \n",
       "4                -14.670776                  11.329224   \n",
       "\n",
       "   Birth_nuniq - feature_778  BureauScore - Duecount53_sum_9999  \\\n",
       "0                   3.832459                              297.0   \n",
       "1                   3.623251                              748.0   \n",
       "2                  35.491127                               61.0   \n",
       "3                  20.301028                             -109.0   \n",
       "4                  13.079224                              632.0   \n",
       "\n",
       "   BureauScore - Duesum51_max_360  \\\n",
       "0                           563.0   \n",
       "1                           772.0   \n",
       "2                           656.0   \n",
       "3                           119.0   \n",
       "4                           738.0   \n",
       "\n",
       "   BureauScore - Duration_Of_Agreement41_sum_9999  BureauScore - Name_nuniq2  \\\n",
       "0                                           287.0                        329   \n",
       "1                                           705.0                        591   \n",
       "2                                          -689.0                       -178   \n",
       "3                                           219.0                        341   \n",
       "4                                           485.0                        527   \n",
       "\n",
       "   BureauScore - feature_2  \\\n",
       "0                    -2937   \n",
       "1                    -2728   \n",
       "2                    -2790   \n",
       "3                    -3022   \n",
       "4                    -2762   \n",
       "\n",
       "   CAPSLast180Days_nocrt_por - Payment_Rating34_mean_9999  \\\n",
       "0                                           2.636364        \n",
       "1                                           0.000000        \n",
       "2                                           0.620739        \n",
       "3                                          -0.460000        \n",
       "4                                          -0.083333        \n",
       "\n",
       "   CAPSLast180Days_nocrt_por - feature_4  \\\n",
       "0                              -1.000000   \n",
       "1                              -4.000000   \n",
       "2                              -4.363636   \n",
       "3                              -5.000000   \n",
       "4                              -1.000000   \n",
       "\n",
       "   CAPSLast180Days_nocrt_por - feature_638  \\\n",
       "0                                 2.000000   \n",
       "1                                -1.000000   \n",
       "2                                -0.363636   \n",
       "3                                -3.000000   \n",
       "4                                 0.000000   \n",
       "\n",
       "   CAPSLast180Days_nocrt_por - feature_9  \\\n",
       "0                              -8.000000   \n",
       "1                              -9.000000   \n",
       "2                             -10.363636   \n",
       "3                             -11.000000   \n",
       "4                             -10.000000   \n",
       "\n",
       "   Current_Balance35_sum_9999 - Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                          1101401.0                                \n",
       "1                                           -60449.0                                \n",
       "2                                          2952986.0                                \n",
       "3                                            14181.0                                \n",
       "4                                           166370.0                                \n",
       "\n",
       "   Current_Balance35_sum_9999 - Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                         -2761710.0                                \n",
       "1                                          -188449.0                                \n",
       "2                                         -2439077.0                                \n",
       "3                                         -2860995.0                                \n",
       "4                                          -186032.0                                \n",
       "\n",
       "   Current_Balance35_sum_9999 - feature_762  \\\n",
       "0                              5.542401e+06   \n",
       "1                              1.202510e+05   \n",
       "2                              4.648986e+06   \n",
       "3                              4.721810e+05   \n",
       "4                              4.217109e+05   \n",
       "\n",
       "   Date_of_Last_Payment40_max_360 - Date_of_Request35_mode_9999  \\\n",
       "0                                              -49.0              \n",
       "1                                              139.0              \n",
       "2                                             -641.0              \n",
       "3                                               70.0              \n",
       "4                                              179.0              \n",
       "\n",
       "   Date_of_Last_Payment40_mean_360 - feature_8  \\\n",
       "0                                  -402.000000   \n",
       "1                                 -1880.000000   \n",
       "2                                  -418.473684   \n",
       "3                                 -1779.333333   \n",
       "4                                  -802.222222   \n",
       "\n",
       "   Date_of_Request35_mode_90 - Email_nuniq  \\\n",
       "0                                60.002999   \n",
       "1                                11.500750   \n",
       "2                               -17.393921   \n",
       "3                                 4.333555   \n",
       "4                                -4.998200   \n",
       "\n",
       "   Date_of_Request35_mode_90 - Email_nuniq2  \\\n",
       "0                                      -1.0   \n",
       "1                                     -31.0   \n",
       "2                                    -111.0   \n",
       "3                                     -59.0   \n",
       "4                                    -107.0   \n",
       "\n",
       "   Date_of_Request35_mode_90 - Name_nuniq2  \\\n",
       "0                                   -164.0   \n",
       "1                                   -167.0   \n",
       "2                                   -874.0   \n",
       "3                                   -131.0   \n",
       "4                                   -206.0   \n",
       "\n",
       "   Date_of_Request35_mode_90 - Rate_of_Interest36_min_9999  \\\n",
       "0                                              25.00         \n",
       "1                                                NaN         \n",
       "2                                               7.25         \n",
       "3                                              -2.00         \n",
       "4                                             -13.00         \n",
       "\n",
       "   Date_of_Request35_mode_90 - Tel_nuniq2  \\\n",
       "0                                   -16.0   \n",
       "1                                   -16.0   \n",
       "2                                  -183.0   \n",
       "3                                  -139.0   \n",
       "4                                   -23.0   \n",
       "\n",
       "   Date_of_Request35_mode_9999 - Duecount53_sum_9999  \\\n",
       "0                                             -196.0   \n",
       "1                                              -10.0   \n",
       "2                                              288.0   \n",
       "3                                             -581.0   \n",
       "4                                             -101.0   \n",
       "\n",
       "   Date_of_Request35_mode_9999 - Duesum51_max_360  \\\n",
       "0                                            70.0   \n",
       "1                                            14.0   \n",
       "2                                           883.0   \n",
       "3                                          -353.0   \n",
       "4                                             5.0   \n",
       "\n",
       "   Date_of_Request35_mode_9999 - Duration_Of_Agreement41_sum_9999  \\\n",
       "0                                             -206.0                \n",
       "1                                              -53.0                \n",
       "2                                             -462.0                \n",
       "3                                             -253.0                \n",
       "4                                             -248.0                \n",
       "\n",
       "   Date_of_Request35_mode_9999 - Email_nuniq  \\\n",
       "0                                  60.002999   \n",
       "1                                  11.500750   \n",
       "2                                 905.606079   \n",
       "3                                   4.333555   \n",
       "4                                  -4.998200   \n",
       "\n",
       "   Date_of_Request35_mode_9999 - Name_nuniq2  \\\n",
       "0                                     -164.0   \n",
       "1                                     -167.0   \n",
       "2                                       49.0   \n",
       "3                                     -131.0   \n",
       "4                                     -206.0   \n",
       "\n",
       "   Date_of_Request35_mode_9999 - feature_322  \\\n",
       "0                                       38.0   \n",
       "1                                     1013.0   \n",
       "2                                     1936.0   \n",
       "3                                     1005.0   \n",
       "4                                     1004.0   \n",
       "\n",
       "   Date_of_Request35_mode_9999 - feature_329  \\\n",
       "0                                       24.0   \n",
       "1                                     1013.0   \n",
       "2                                      937.0   \n",
       "3                                        2.0   \n",
       "4                                       -2.0   \n",
       "\n",
       "   Duecount53_sum_9999 - Duesum51_max_360  \\\n",
       "0                                   266.0   \n",
       "1                                    24.0   \n",
       "2                                   595.0   \n",
       "3                                   228.0   \n",
       "4                                   106.0   \n",
       "\n",
       "   Duecount53_sum_9999 - Duration_Of_Agreement41_sum_9999  \\\n",
       "0                                              -10.0        \n",
       "1                                              -43.0        \n",
       "2                                             -750.0        \n",
       "3                                              328.0        \n",
       "4                                             -147.0        \n",
       "\n",
       "   Duecount53_sum_9999 - Name_nuniq2  Duecount53_sum_9999 - feature_2  \\\n",
       "0                               32.0                          -3234.0   \n",
       "1                             -157.0                          -3476.0   \n",
       "2                             -239.0                          -2851.0   \n",
       "3                              450.0                          -2913.0   \n",
       "4                             -105.0                          -3394.0   \n",
       "\n",
       "   Duesum51_max_360 - Duration_Of_Agreement41_sum_9999  \\\n",
       "0                                             -276.0     \n",
       "1                                              -67.0     \n",
       "2                                            -1345.0     \n",
       "3                                              100.0     \n",
       "4                                             -253.0     \n",
       "\n",
       "   Duesum51_max_360 - Name_nuniq2  Duesum51_max_360 - feature_2  \\\n",
       "0                          -234.0                       -3500.0   \n",
       "1                          -181.0                       -3500.0   \n",
       "2                          -834.0                       -3446.0   \n",
       "3                           222.0                       -3141.0   \n",
       "4                          -211.0                       -3500.0   \n",
       "\n",
       "   Duesum51_max_360 - feature_322  Duesum51_max_360 - feature_329  \\\n",
       "0                           -32.0                           -46.0   \n",
       "1                           999.0                           999.0   \n",
       "2                          1053.0                            54.0   \n",
       "3                          1358.0                           355.0   \n",
       "4                           999.0                            -7.0   \n",
       "\n",
       "   Duration_Of_Agreement41_sum_9999 - Name_nuniq2  \\\n",
       "0                                            42.0   \n",
       "1                                          -114.0   \n",
       "2                                           511.0   \n",
       "3                                           122.0   \n",
       "4                                            42.0   \n",
       "\n",
       "   Duration_Of_Agreement41_sum_9999 - feature_2  \\\n",
       "0                                       -3224.0   \n",
       "1                                       -3433.0   \n",
       "2                                       -2101.0   \n",
       "3                                       -3241.0   \n",
       "4                                       -3247.0   \n",
       "\n",
       "   Duration_Of_Agreement41_sum_9999 - feature_322  \\\n",
       "0                                           244.0   \n",
       "1                                          1066.0   \n",
       "2                                          2398.0   \n",
       "3                                          1258.0   \n",
       "4                                          1252.0   \n",
       "\n",
       "   Duration_Of_Agreement41_sum_9999 - feature_329  \\\n",
       "0                                           230.0   \n",
       "1                                          1066.0   \n",
       "2                                          1399.0   \n",
       "3                                           255.0   \n",
       "4                                           246.0   \n",
       "\n",
       "   Email_nuniq - Rate_of_Interest36_min_9999  Email_nuniq - Tel_nuniq2  \\\n",
       "0                                 -35.002999                -76.002999   \n",
       "1                                        NaN                -27.500750   \n",
       "2                                  24.643921               -165.606079   \n",
       "3                                  -6.333555               -143.333555   \n",
       "4                                  -8.001800                -18.001800   \n",
       "\n",
       "   Email_nuniq2 - Name_nuniq2  Email_nuniq2 - Rate_of_Interest36_min_9999  \\\n",
       "0                        -163                                       26.00   \n",
       "1                        -136                                         NaN   \n",
       "2                        -763                                      118.25   \n",
       "3                         -72                                       57.00   \n",
       "4                         -99                                       94.00   \n",
       "\n",
       "   Email_nuniq2 - Tel_nuniq2  Email_nuniq2 - feature_2  \\\n",
       "0                        -15                     -3429   \n",
       "1                         15                     -3455   \n",
       "2                        -72                     -3375   \n",
       "3                        -80                     -3435   \n",
       "4                         84                     -3388   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_max_9999 - Outstanding_Balance_UnSecured  \\\n",
       "0                                          4103060.0                                   \n",
       "1                                           180700.0                                   \n",
       "2                                         -1292444.0                                   \n",
       "3                                            67994.0                                   \n",
       "4                                           181567.0                                   \n",
       "\n",
       "   Rate_of_Interest36_min_9999 - Tel_nuniq2  feature_2 - Name_nuniq2  \\\n",
       "0                                    -41.00                     3266   \n",
       "1                                       NaN                     3319   \n",
       "2                                   -190.25                     2612   \n",
       "3                                   -137.00                     3363   \n",
       "4                                    -10.00                     3289   \n",
       "\n",
       "   feature_254 - feature_638  feature_254 - feature_710  \\\n",
       "0                          4                          4   \n",
       "1                         -1                         -6   \n",
       "2                          0                         -2   \n",
       "3                          0                         -1   \n",
       "4                          2                          2   \n",
       "\n",
       "   feature_322 - feature_329  feature_329 - feature_409  \\\n",
       "0                        -14                      46.00   \n",
       "1                          0                        NaN   \n",
       "2                       -999                      -0.20   \n",
       "3                      -1003                       3.75   \n",
       "4                      -1006                       7.00   \n",
       "\n",
       "   feature_4 - Payment_Rating34_mean_9999  feature_4 - feature_638  \\\n",
       "0                                3.636364                        3   \n",
       "1                                4.000000                        3   \n",
       "2                                4.984375                        4   \n",
       "3                                4.540000                        2   \n",
       "4                                0.916667                        1   \n",
       "\n",
       "   feature_4 - feature_9  feature_407 - feature_409  \\\n",
       "0                     -7                   0.000000   \n",
       "1                     -5                        NaN   \n",
       "2                     -6                  -0.200000   \n",
       "3                     -6                  -0.107143   \n",
       "4                     -9                        NaN   \n",
       "\n",
       "   feature_407 - feature_410  feature_407 - feature_638  \\\n",
       "0                   0.000000                  -1.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                  -0.714286                  -1.000000   \n",
       "3                  -0.157143                  -2.857143   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   feature_407 - feature_643  feature_407 - feature_700  \\\n",
       "0                  -0.454545                  -0.529412   \n",
       "1                        NaN                        NaN   \n",
       "2                  -0.333333                  -0.833333   \n",
       "3                  -0.153439                  -0.341991   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   feature_407 - feature_701  feature_407 - feature_702  \\\n",
       "0                   0.000000                  -0.590909   \n",
       "1                        NaN                        NaN   \n",
       "2                  -0.666667                  -0.923077   \n",
       "3                  -0.107143                  -0.533613   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   feature_407 - feature_778  feature_407 - feature_779  \\\n",
       "0                  -0.666667                  -0.555556   \n",
       "1                        NaN                        NaN   \n",
       "2                  -1.000000                  -0.600000   \n",
       "3                  -0.549451                  -0.419643   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   feature_407 - feature_781  feature_409 - feature_410  \\\n",
       "0                  -0.538462                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                  -0.750000                  -0.514286   \n",
       "3                  -0.204969                  -0.050000   \n",
       "4                        NaN                   0.000000   \n",
       "\n",
       "   feature_409 - feature_643  feature_409 - feature_701  \\\n",
       "0                  -0.454545                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                  -0.133333                  -0.466667   \n",
       "3                  -0.046296                   0.000000   \n",
       "4                   0.000000                        NaN   \n",
       "\n",
       "   feature_409 - feature_702  feature_409 - feature_778  \\\n",
       "0                  -0.590909                  -0.666667   \n",
       "1                        NaN                        NaN   \n",
       "2                  -0.723077                  -0.800000   \n",
       "3                  -0.426471                  -0.442308   \n",
       "4                  -0.727273                  -0.250000   \n",
       "\n",
       "   feature_409 - feature_781  feature_410 - Payment_Rating34_mean_9999  \\\n",
       "0                  -0.538462                                 -0.363636   \n",
       "1                        NaN                                       NaN   \n",
       "2                  -0.550000                                  0.698661   \n",
       "3                  -0.097826                                 -0.160000   \n",
       "4                  -0.500000                                 -0.083333   \n",
       "\n",
       "   feature_410 - feature_643  feature_410 - feature_701  \\\n",
       "0                  -0.454545                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                   0.380952                   0.047619   \n",
       "3                   0.003704                   0.050000   \n",
       "4                   0.000000                        NaN   \n",
       "\n",
       "   feature_410 - feature_702  feature_410 - feature_778  \\\n",
       "0                  -0.590909                  -0.666667   \n",
       "1                        NaN                        NaN   \n",
       "2                  -0.208791                  -0.285714   \n",
       "3                  -0.376471                  -0.392308   \n",
       "4                  -0.727273                  -0.250000   \n",
       "\n",
       "   feature_410 - feature_9  feature_638 - feature_9  \\\n",
       "0               -11.000000                      -10   \n",
       "1                      NaN                       -8   \n",
       "2               -10.285714                      -10   \n",
       "3               -10.700000                       -8   \n",
       "4               -10.000000                      -10   \n",
       "\n",
       "   feature_643 - feature_702  feature_643 - feature_778  \\\n",
       "0                  -0.136364                  -0.212121   \n",
       "1                  -0.555556                  -0.708333   \n",
       "2                  -0.589744                  -0.666667   \n",
       "3                  -0.380174                  -0.396011   \n",
       "4                  -0.727273                  -0.250000   \n",
       "\n",
       "   feature_643 - feature_779  feature_643 - feature_781  \\\n",
       "0                  -0.101010                  -0.083916   \n",
       "1                  -0.611111                  -0.448718   \n",
       "2                  -0.266667                  -0.416667   \n",
       "3                  -0.266204                  -0.051530   \n",
       "4                  -0.200000                  -0.500000   \n",
       "\n",
       "   feature_643 - feature_804  feature_669 - feature_762  \\\n",
       "0                   0.428571                  -0.000220   \n",
       "1                   0.141026                   0.019763   \n",
       "2                   0.333333                   0.006459   \n",
       "3                   0.296296                  -0.017456   \n",
       "4                   0.000000                  -0.025391   \n",
       "\n",
       "   feature_700 - feature_701  feature_700 - feature_702  \\\n",
       "0                   0.529412                  -0.061497   \n",
       "1                   0.142857                  -0.079365   \n",
       "2                   0.166667                  -0.089744   \n",
       "3                   0.234848                  -0.191622   \n",
       "4                        NaN                  -0.012987   \n",
       "\n",
       "   feature_700 - feature_778  feature_700 - feature_781  \\\n",
       "0                  -0.137255                  -0.009050   \n",
       "1                  -0.232143                   0.027473   \n",
       "2                  -0.166667                   0.083333   \n",
       "3                  -0.207459                   0.137022   \n",
       "4                   0.464286                   0.214286   \n",
       "\n",
       "   feature_701 - feature_702  feature_701 - feature_778  \\\n",
       "0                  -0.590909                  -0.666667   \n",
       "1                  -0.222222                  -0.375000   \n",
       "2                  -0.256410                  -0.333333   \n",
       "3                  -0.426471                  -0.442308   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   feature_701 - feature_781  feature_702 - feature_762  \\\n",
       "0                  -0.538462                   0.545455   \n",
       "1                  -0.115385                   0.722222   \n",
       "2                  -0.083333                   0.907204   \n",
       "3                  -0.097826                   0.630317   \n",
       "4                        NaN                   0.672727   \n",
       "\n",
       "   feature_702 - feature_779  feature_702 - feature_781  \\\n",
       "0                   0.035354                   0.052448   \n",
       "1                  -0.055556                   0.106838   \n",
       "2                   0.323077                   0.173077   \n",
       "3                   0.113971                   0.328645   \n",
       "4                   0.527273                   0.227273   \n",
       "\n",
       "   feature_702 - feature_888  feature_710 - feature_9  \\\n",
       "0                   0.525974                      -10   \n",
       "1                   0.619658                       -3   \n",
       "2                   0.875458                       -8   \n",
       "3                   0.568778                       -7   \n",
       "4                   0.618182                      -10   \n",
       "\n",
       "   feature_762 - Rate_of_Interest36_min_9999  feature_762 - feature_804  \\\n",
       "0                                 -44.954545                   0.019481   \n",
       "1                                        NaN                  -0.025641   \n",
       "2                                  -6.734127                   0.015873   \n",
       "3                                  -7.953846                   0.046154   \n",
       "4                                 -17.945455                   0.054545   \n",
       "\n",
       "   feature_762 - feature_846  feature_762 - feature_874  \\\n",
       "0                   0.019481                   0.025974   \n",
       "1                   0.000000                   0.000000   \n",
       "2                  -0.015873                   0.015873   \n",
       "3                   0.000000                   0.030769   \n",
       "4                  -0.018182                   0.036364   \n",
       "\n",
       "   feature_762 - feature_888  feature_778 - feature_779  \\\n",
       "0                  -0.019481                   0.111111   \n",
       "1                  -0.102564                   0.097222   \n",
       "2                  -0.031746                   0.400000   \n",
       "3                  -0.061538                   0.129808   \n",
       "4                  -0.054545                   0.050000   \n",
       "\n",
       "   feature_778 - feature_781  feature_778 - feature_874  \\\n",
       "0                   0.128205                   0.647186   \n",
       "1                   0.259615                   0.875000   \n",
       "2                   0.250000                   1.000000   \n",
       "3                   0.344482                   0.676923   \n",
       "4                  -0.250000                   0.231818   \n",
       "\n",
       "   feature_779 - feature_781  feature_804 - feature_846  \\\n",
       "0                   0.017094                   0.000000   \n",
       "1                   0.162393                   0.025641   \n",
       "2                  -0.150000                  -0.031746   \n",
       "3                   0.214674                  -0.046154   \n",
       "4                  -0.300000                  -0.072727   \n",
       "\n",
       "   feature_804 - feature_888  feature_846 - feature_874  \\\n",
       "0                  -0.038961                   0.006494   \n",
       "1                  -0.076923                   0.000000   \n",
       "2                  -0.047619                   0.031746   \n",
       "3                  -0.107692                   0.030769   \n",
       "4                  -0.109091                   0.054545   \n",
       "\n",
       "   feature_846 - feature_888  \\\n",
       "0                  -0.038961   \n",
       "1                  -0.102564   \n",
       "2                  -0.015873   \n",
       "3                  -0.061538   \n",
       "4                  -0.036364   \n",
       "\n",
       "   feature_874 - Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                      -8.304111e+06                 \n",
       "1                                      -3.087000e+05                 \n",
       "2                                      -7.088063e+06                 \n",
       "3                                      -3.333176e+06                 \n",
       "4                                      -6.077430e+05                 \n",
       "\n",
       "   feature_874 - feature_888  feature_888 - feature_9  \\\n",
       "0                  -0.045455               -10.935065   \n",
       "1                  -0.102564                -8.897436   \n",
       "2                  -0.047619               -10.952381   \n",
       "3                  -0.092308               -10.892308   \n",
       "4                  -0.090909                -9.890909   \n",
       "\n",
       "   feature_9 - Payment_Rating34_mean_9999  \n",
       "0                               10.636364  \n",
       "1                                9.000000  \n",
       "2                               10.984375  \n",
       "3                               10.540000  \n",
       "4                                9.916667  \n",
       "\n",
       "[5 rows x 3631 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/top30_tofeaturetools.pkl ok\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%reload_ext autoreload\n",
    "import feas_ft\n",
    "import imp\n",
    "imp.reload(feas_ft)\n",
    "\n",
    "\n",
    "feas_ft.featuretools_topfeas(basedf_file='./data/filter_feas_df32n_old.pkl', importance_file='./data/feature_importance.pkl', catefeas=[],join_key='ID',final_file='./data/top30_tofeaturetools.pkl',topn=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757fc38b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11ea8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f88e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "188ee814",
   "metadata": {},
   "source": [
    "### 原特征+ 等频4分箱onehot+  lgb特征--》3DNN or tabnet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cc9b3932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>report_timestamp</th>\n",
       "      <th>BureauScore</th>\n",
       "      <th>BureauScoreConfidLevel</th>\n",
       "      <th>MissingRate</th>\n",
       "      <th>Current_Finance_Purpose</th>\n",
       "      <th>Current_Amount_Financed</th>\n",
       "      <th>Current_Gender_Code</th>\n",
       "      <th>First_Name1</th>\n",
       "      <th>Len_Name</th>\n",
       "      <th>Name_nuniq</th>\n",
       "      <th>Tel_nuniq</th>\n",
       "      <th>Email_nuniq</th>\n",
       "      <th>IncomeTaxPAN_5</th>\n",
       "      <th>Len_of_addrs</th>\n",
       "      <th>City_nuniq</th>\n",
       "      <th>PinCode3</th>\n",
       "      <th>Current_State</th>\n",
       "      <th>Current_City</th>\n",
       "      <th>CreditAccountActive</th>\n",
       "      <th>CreditAccountActivePor</th>\n",
       "      <th>Outstanding_Balance_UnSecured_Percentage</th>\n",
       "      <th>Outstanding_Balance_UnSecured</th>\n",
       "      <th>Diff_dateBirth</th>\n",
       "      <th>State_nuniq</th>\n",
       "      <th>Birth_nuniq</th>\n",
       "      <th>TotalCAPSLast90Days</th>\n",
       "      <th>TotalCAPSLast7Days</th>\n",
       "      <th>TotalCAPSLast30Days</th>\n",
       "      <th>TotalCAPSLast180Days</th>\n",
       "      <th>CAPSLast7Days</th>\n",
       "      <th>CAPSLast180Days</th>\n",
       "      <th>Pin_nuniq</th>\n",
       "      <th>Pan_nuniq</th>\n",
       "      <th>Ident_nuniq</th>\n",
       "      <th>Name_nuniq2</th>\n",
       "      <th>Tel_nuniq2</th>\n",
       "      <th>Email_nuniq2</th>\n",
       "      <th>Pan_nuniq2</th>\n",
       "      <th>Account_nuniq2</th>\n",
       "      <th>Ident_nuniq2</th>\n",
       "      <th>Gender_nuniq</th>\n",
       "      <th>Amount_Past_Due35_max_30</th>\n",
       "      <th>Amount_Past_Due35_mean_90</th>\n",
       "      <th>Amount_Past_Due35_max_90</th>\n",
       "      <th>Amount_Past_Due35_min_90</th>\n",
       "      <th>Amount_Past_Due35_std_90</th>\n",
       "      <th>Amount_Past_Due35_sum_360</th>\n",
       "      <th>Amount_Past_Due35_max_360</th>\n",
       "      <th>Amount_Past_Due35_min_360</th>\n",
       "      <th>Amount_Past_Due35_std_360</th>\n",
       "      <th>Amount_Past_Due35_mean_9999</th>\n",
       "      <th>Amount_Past_Due35_max_9999</th>\n",
       "      <th>Amount_Past_Due35_min_9999</th>\n",
       "      <th>Amount_Past_Due35_std_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>Terms_Duration34_std_30</th>\n",
       "      <th>Terms_Duration34_std_90</th>\n",
       "      <th>Terms_Duration34_sum_360</th>\n",
       "      <th>Terms_Duration34_max_360</th>\n",
       "      <th>Terms_Duration34_mean_9999</th>\n",
       "      <th>Terms_Duration34_std_9999</th>\n",
       "      <th>Payment_Rating34_sum_90</th>\n",
       "      <th>Payment_Rating34_mean_90</th>\n",
       "      <th>Payment_Rating34_min_90</th>\n",
       "      <th>Payment_Rating34_std_90</th>\n",
       "      <th>Payment_Rating34_sum_360</th>\n",
       "      <th>Payment_Rating34_mean_360</th>\n",
       "      <th>Payment_Rating34_max_360</th>\n",
       "      <th>Payment_Rating34_min_360</th>\n",
       "      <th>Payment_Rating34_std_360</th>\n",
       "      <th>Payment_Rating34_sum_9999</th>\n",
       "      <th>Payment_Rating34_mean_9999</th>\n",
       "      <th>Payment_Rating34_max_9999</th>\n",
       "      <th>Payment_Rating34_min_9999</th>\n",
       "      <th>Payment_Rating34_std_9999</th>\n",
       "      <th>Current_Balance35_sum_360</th>\n",
       "      <th>Current_Balance35_max_360</th>\n",
       "      <th>Current_Balance35_std_360</th>\n",
       "      <th>Current_Balance35_sum_9999</th>\n",
       "      <th>Current_Balance35_mean_9999</th>\n",
       "      <th>Settlement_Amount37_mean_360</th>\n",
       "      <th>Settlement_Amount37_std_360</th>\n",
       "      <th>Settlement_Amount37_mean_9999</th>\n",
       "      <th>Settlement_Amount37_max_9999</th>\n",
       "      <th>Settlement_Amount37_min_9999</th>\n",
       "      <th>Value_of_Collateral39_std_90</th>\n",
       "      <th>Value_of_Collateral39_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_360</th>\n",
       "      <th>Written_Off_Amt_Total41_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_max_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_min_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_std_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_std_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_max_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_9999</th>\n",
       "      <th>Rate_of_Interest36_sum_30</th>\n",
       "      <th>Rate_of_Interest36_max_30</th>\n",
       "      <th>Rate_of_Interest36_min_30</th>\n",
       "      <th>Rate_of_Interest36_std_30</th>\n",
       "      <th>Rate_of_Interest36_sum_90</th>\n",
       "      <th>Rate_of_Interest36_mean_90</th>\n",
       "      <th>Rate_of_Interest36_max_90</th>\n",
       "      <th>Rate_of_Interest36_min_90</th>\n",
       "      <th>Rate_of_Interest36_std_90</th>\n",
       "      <th>Rate_of_Interest36_sum_360</th>\n",
       "      <th>Rate_of_Interest36_sum_9999</th>\n",
       "      <th>Rate_of_Interest36_mean_9999</th>\n",
       "      <th>Rate_of_Interest36_max_9999</th>\n",
       "      <th>Rate_of_Interest36_min_9999</th>\n",
       "      <th>Rate_of_Interest36_std_9999</th>\n",
       "      <th>Repayment_Tenure36_std_30</th>\n",
       "      <th>Repayment_Tenure36_std_90</th>\n",
       "      <th>Repayment_Tenure36_mean_360</th>\n",
       "      <th>Repayment_Tenure36_min_360</th>\n",
       "      <th>Repayment_Tenure36_std_360</th>\n",
       "      <th>Repayment_Tenure36_sum_9999</th>\n",
       "      <th>Repayment_Tenure36_mean_9999</th>\n",
       "      <th>Repayment_Tenure36_max_9999</th>\n",
       "      <th>Repayment_Tenure36_min_9999</th>\n",
       "      <th>Repayment_Tenure36_std_9999</th>\n",
       "      <th>Income26_count_30</th>\n",
       "      <th>Income26_std_90</th>\n",
       "      <th>Income26_min_9999</th>\n",
       "      <th>Income26_std_9999</th>\n",
       "      <th>Open_Date29_max_30</th>\n",
       "      <th>Open_Date29_mean_30</th>\n",
       "      <th>Open_Date29_mode_30</th>\n",
       "      <th>Open_Date29_nuniq_30</th>\n",
       "      <th>Open_Date29_maxcount_30</th>\n",
       "      <th>Open_Date29_mode_90</th>\n",
       "      <th>Open_Date29_nuniq_90</th>\n",
       "      <th>Open_Date29_max_360</th>\n",
       "      <th>Open_Date29_mode_360</th>\n",
       "      <th>Open_Date29_maxcount_360</th>\n",
       "      <th>Open_Date29_max_9999</th>\n",
       "      <th>Open_Date29_mean_9999</th>\n",
       "      <th>Open_Date29_mode_9999</th>\n",
       "      <th>Open_Date29_maxcount_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_30</th>\n",
       "      <th>Portfolio_Type34_nuniq_90</th>\n",
       "      <th>Portfolio_Type34_nuniq_360</th>\n",
       "      <th>Portfolio_Type34_mode_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_9999</th>\n",
       "      <th>Account_Type32_mode_30</th>\n",
       "      <th>Account_Type32_nuniq_30</th>\n",
       "      <th>Account_Type32_mode_90</th>\n",
       "      <th>Account_Type32_nuniq_90</th>\n",
       "      <th>Account_Type32_mode_360</th>\n",
       "      <th>Account_Type32_nuniq_360</th>\n",
       "      <th>Account_Type32_mode_9999</th>\n",
       "      <th>Account_Type32_nuniq_9999</th>\n",
       "      <th>Occupation_Code35_nuniq_30</th>\n",
       "      <th>Occupation_Code35_nuniq_90</th>\n",
       "      <th>Occupation_Code35_nuniq_360</th>\n",
       "      <th>CurrencyCode32_mode_360</th>\n",
       "      <th>CurrencyCode32_mode_9999</th>\n",
       "      <th>AccountHoldertypeCode41_mode_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_360</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_9999</th>\n",
       "      <th>Payment_History_Profile43_mode_30</th>\n",
       "      <th>Payment_History_Profile43_mode_90</th>\n",
       "      <th>Payment_History_Profile43_nuniq_90</th>\n",
       "      <th>Payment_History_Profile43_mode_360</th>\n",
       "      <th>Payment_History_Profile43_nuniq_360</th>\n",
       "      <th>Payment_History_Profile43_mode_9999</th>\n",
       "      <th>Payment_History_Profile43_nuniq_9999</th>\n",
       "      <th>Date_Closed31_mode_30</th>\n",
       "      <th>Date_Closed31_nuniq_30</th>\n",
       "      <th>Date_Closed31_maxcount_30</th>\n",
       "      <th>Date_Closed31_max_90</th>\n",
       "      <th>Date_Closed31_min_90</th>\n",
       "      <th>Date_Closed31_mean_90</th>\n",
       "      <th>Date_Closed31_mode_90</th>\n",
       "      <th>Date_Closed31_nuniq_90</th>\n",
       "      <th>Date_Closed31_maxcount_90</th>\n",
       "      <th>Date_Closed31_mode_360</th>\n",
       "      <th>Date_Closed31_nuniq_360</th>\n",
       "      <th>Date_Closed31_maxcount_360</th>\n",
       "      <th>Date_Closed31_mean_9999</th>\n",
       "      <th>Date_Closed31_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_30</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_30</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_90</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_90</th>\n",
       "      <th>Date_of_Last_Payment40_max_360</th>\n",
       "      <th>Date_of_Last_Payment40_min_360</th>\n",
       "      <th>Date_of_Last_Payment40_mean_360</th>\n",
       "      <th>Date_of_Last_Payment40_mode_360</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_360</th>\n",
       "      <th>Date_of_Last_Payment40_max_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mean_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_9999</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_9999</th>\n",
       "      <th>Date_Reported33_nuniq_30</th>\n",
       "      <th>Date_Reported33_max_90</th>\n",
       "      <th>Date_Reported33_mode_90</th>\n",
       "      <th>Date_Reported33_nuniq_90</th>\n",
       "      <th>Date_Reported33_maxcount_90</th>\n",
       "      <th>Date_Reported33_max_360</th>\n",
       "      <th>Date_Reported33_mean_360</th>\n",
       "      <th>Date_Reported33_mode_360</th>\n",
       "      <th>Date_Reported33_nuniq_360</th>\n",
       "      <th>Date_Reported33_max_9999</th>\n",
       "      <th>Date_Reported33_mode_9999</th>\n",
       "      <th>Date_Reported33_nuniq_9999</th>\n",
       "      <th>Date_Reported33_maxcount_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_30</th>\n",
       "      <th>DateOfAddition34_max_90</th>\n",
       "      <th>DateOfAddition34_mean_90</th>\n",
       "      <th>DateOfAddition34_nuniq_90</th>\n",
       "      <th>DateOfAddition34_maxcount_90</th>\n",
       "      <th>DateOfAddition34_max_360</th>\n",
       "      <th>DateOfAddition34_mean_360</th>\n",
       "      <th>DateOfAddition34_mode_360</th>\n",
       "      <th>DateOfAddition34_maxcount_360</th>\n",
       "      <th>DateOfAddition34_max_9999</th>\n",
       "      <th>DateOfAddition34_min_9999</th>\n",
       "      <th>DateOfAddition34_mode_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_9999</th>\n",
       "      <th>DateOfAddition34_maxcount_9999</th>\n",
       "      <th>Account_Status34_mode_30</th>\n",
       "      <th>Account_Status34_nuniq_30</th>\n",
       "      <th>Account_Status34_mode_90</th>\n",
       "      <th>Account_Status34_nuniq_90</th>\n",
       "      <th>Account_Status34_nuniq_360</th>\n",
       "      <th>Account_Status34_mode_9999</th>\n",
       "      <th>Account_Status34_nuniq_9999</th>\n",
       "      <th>Month50_sum_30</th>\n",
       "      <th>Month50_mean_30</th>\n",
       "      <th>Month50_std_30</th>\n",
       "      <th>Month50_sum_90</th>\n",
       "      <th>Month50_mean_90</th>\n",
       "      <th>Month50_max_90</th>\n",
       "      <th>Month50_std_90</th>\n",
       "      <th>Month50_max_360</th>\n",
       "      <th>Month50_min_360</th>\n",
       "      <th>Month50_mean_9999</th>\n",
       "      <th>Month50_max_9999</th>\n",
       "      <th>Month50_min_9999</th>\n",
       "      <th>Month50_std_9999</th>\n",
       "      <th>Days_Past_Due58_sum_90</th>\n",
       "      <th>Days_Past_Due58_min_90</th>\n",
       "      <th>Days_Past_Due58_std_90</th>\n",
       "      <th>Days_Past_Due58_sum_360</th>\n",
       "      <th>Days_Past_Due58_mean_360</th>\n",
       "      <th>Days_Past_Due58_max_360</th>\n",
       "      <th>Days_Past_Due58_min_360</th>\n",
       "      <th>Days_Past_Due58_std_360</th>\n",
       "      <th>Days_Past_Due58_sum_9999</th>\n",
       "      <th>Days_Past_Due58_max_9999</th>\n",
       "      <th>Days_Past_Due58_min_9999</th>\n",
       "      <th>Days_Past_Due58_std_9999</th>\n",
       "      <th>Duecount53_mean_30</th>\n",
       "      <th>Duecount53_min_30</th>\n",
       "      <th>Duecount53_std_30</th>\n",
       "      <th>Duecount53_sum_90</th>\n",
       "      <th>Duecount53_mean_90</th>\n",
       "      <th>Duecount53_max_90</th>\n",
       "      <th>Duecount53_min_90</th>\n",
       "      <th>Duecount53_std_90</th>\n",
       "      <th>Duecount53_sum_360</th>\n",
       "      <th>Duecount53_mean_360</th>\n",
       "      <th>Duecount53_max_360</th>\n",
       "      <th>Duecount53_min_360</th>\n",
       "      <th>Duecount53_std_360</th>\n",
       "      <th>Duecount53_sum_9999</th>\n",
       "      <th>Duecount53_mean_9999</th>\n",
       "      <th>Duecount53_max_9999</th>\n",
       "      <th>Duecount53_min_9999</th>\n",
       "      <th>Duecount53_std_9999</th>\n",
       "      <th>Duesum51_mean_30</th>\n",
       "      <th>Duesum51_std_30</th>\n",
       "      <th>Duesum51_mean_90</th>\n",
       "      <th>Duesum51_max_90</th>\n",
       "      <th>Duesum51_sum_360</th>\n",
       "      <th>Duesum51_mean_360</th>\n",
       "      <th>Duesum51_max_360</th>\n",
       "      <th>Duesum51_min_360</th>\n",
       "      <th>Duesum51_std_360</th>\n",
       "      <th>Duesum51_sum_9999</th>\n",
       "      <th>Duesum51_mean_9999</th>\n",
       "      <th>Duesum51_max_9999</th>\n",
       "      <th>Duesum51_min_9999</th>\n",
       "      <th>Duesum51_std_9999</th>\n",
       "      <th>Amount_Financed35_std_7</th>\n",
       "      <th>Amount_Financed35_max_30</th>\n",
       "      <th>Amount_Financed35_min_30</th>\n",
       "      <th>Amount_Financed35_std_30</th>\n",
       "      <th>Amount_Financed35_count_90</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_1034_sms</th>\n",
       "      <th>feature_1035_sms</th>\n",
       "      <th>feature_1036_sms</th>\n",
       "      <th>feature_1037_sms</th>\n",
       "      <th>feature_1038_sms</th>\n",
       "      <th>feature_1039_sms</th>\n",
       "      <th>feature_1040_sms</th>\n",
       "      <th>feature_1041_sms</th>\n",
       "      <th>feature_1042_sms</th>\n",
       "      <th>feature_1043_sms</th>\n",
       "      <th>feature_1044_sms</th>\n",
       "      <th>feature_1045_sms</th>\n",
       "      <th>feature_1046_sms</th>\n",
       "      <th>feature_1047_sms</th>\n",
       "      <th>feature_1048_sms</th>\n",
       "      <th>feature_1049_sms</th>\n",
       "      <th>feature_1050_sms</th>\n",
       "      <th>feature_1051_sms</th>\n",
       "      <th>feature_1052_sms</th>\n",
       "      <th>feature_1053_sms</th>\n",
       "      <th>feature_1054_sms</th>\n",
       "      <th>feature_1055_sms</th>\n",
       "      <th>feature_1056_sms</th>\n",
       "      <th>feature_1057_sms</th>\n",
       "      <th>feature_1058_sms</th>\n",
       "      <th>feature_1059_sms</th>\n",
       "      <th>feature_1060_sms</th>\n",
       "      <th>feature_1061_sms</th>\n",
       "      <th>feature_1062_sms</th>\n",
       "      <th>feature_1063_sms</th>\n",
       "      <th>feature_1064_sms</th>\n",
       "      <th>feature_1065_sms</th>\n",
       "      <th>feature_1066_sms</th>\n",
       "      <th>feature_1067_sms</th>\n",
       "      <th>feature_1068_sms</th>\n",
       "      <th>feature_1069_sms</th>\n",
       "      <th>feature_1070_sms</th>\n",
       "      <th>feature_1071_sms</th>\n",
       "      <th>feature_1072_sms</th>\n",
       "      <th>feature_1073_sms</th>\n",
       "      <th>feature_1074_sms</th>\n",
       "      <th>feature_1075_sms</th>\n",
       "      <th>feature_1076_sms</th>\n",
       "      <th>feature_1077_sms</th>\n",
       "      <th>feature_1078_sms</th>\n",
       "      <th>feature_1079_sms</th>\n",
       "      <th>feature_1080_sms</th>\n",
       "      <th>feature_1081_sms</th>\n",
       "      <th>feature_1082_sms</th>\n",
       "      <th>feature_1083_sms</th>\n",
       "      <th>feature_1084_sms</th>\n",
       "      <th>feature_1085_sms</th>\n",
       "      <th>feature_1086_sms</th>\n",
       "      <th>feature_1087_sms</th>\n",
       "      <th>feature_1088_sms</th>\n",
       "      <th>feature_1089_sms</th>\n",
       "      <th>feature_1090_sms</th>\n",
       "      <th>feature_1091_sms</th>\n",
       "      <th>feature_1092_sms</th>\n",
       "      <th>feature_1093_sms</th>\n",
       "      <th>feature_1094_sms</th>\n",
       "      <th>feature_1095_sms</th>\n",
       "      <th>feature_1096_sms</th>\n",
       "      <th>feature_1097_sms</th>\n",
       "      <th>feature_1098_sms</th>\n",
       "      <th>feature_1099_sms</th>\n",
       "      <th>feature_1100_sms</th>\n",
       "      <th>feature_1101_sms</th>\n",
       "      <th>feature_1102_sms</th>\n",
       "      <th>feature_1103_sms</th>\n",
       "      <th>feature_1104_sms</th>\n",
       "      <th>feature_1105_sms</th>\n",
       "      <th>feature_1106_sms</th>\n",
       "      <th>feature_1107_sms</th>\n",
       "      <th>feature_1108_sms</th>\n",
       "      <th>feature_1109_sms</th>\n",
       "      <th>feature_1110_sms</th>\n",
       "      <th>feature_1111_sms</th>\n",
       "      <th>feature_1112_sms</th>\n",
       "      <th>feature_1113_sms</th>\n",
       "      <th>feature_1114_sms</th>\n",
       "      <th>feature_1115_sms</th>\n",
       "      <th>feature_1116_sms</th>\n",
       "      <th>feature_1117_sms</th>\n",
       "      <th>feature_1118_sms</th>\n",
       "      <th>feature_1119_sms</th>\n",
       "      <th>feature_1120_sms</th>\n",
       "      <th>feature_1121_sms</th>\n",
       "      <th>feature_1122_sms</th>\n",
       "      <th>feature_1123_sms</th>\n",
       "      <th>feature_1124_sms</th>\n",
       "      <th>feature_1125_sms</th>\n",
       "      <th>feature_1126_sms</th>\n",
       "      <th>feature_1127_sms</th>\n",
       "      <th>feature_1128_sms</th>\n",
       "      <th>feature_1129_sms</th>\n",
       "      <th>feature_1130_sms</th>\n",
       "      <th>feature_1131_sms</th>\n",
       "      <th>feature_1132_sms</th>\n",
       "      <th>feature_1133_sms</th>\n",
       "      <th>feature_1134_sms</th>\n",
       "      <th>feature_1135_sms</th>\n",
       "      <th>feature_1136_sms</th>\n",
       "      <th>feature_1137_sms</th>\n",
       "      <th>feature_1138_sms</th>\n",
       "      <th>feature_1139_sms</th>\n",
       "      <th>feature_1140_sms</th>\n",
       "      <th>feature_1141_sms</th>\n",
       "      <th>feature_1142_sms</th>\n",
       "      <th>feature_1143_sms</th>\n",
       "      <th>feature_1144_sms</th>\n",
       "      <th>feature_1145_sms</th>\n",
       "      <th>feature_1146_sms</th>\n",
       "      <th>feature_1147_sms</th>\n",
       "      <th>feature_1148_sms</th>\n",
       "      <th>feature_1149_sms</th>\n",
       "      <th>feature_1150_sms</th>\n",
       "      <th>feature_1151_sms</th>\n",
       "      <th>feature_1152_sms</th>\n",
       "      <th>feature_1153_sms</th>\n",
       "      <th>feature_1154_sms</th>\n",
       "      <th>feature_1155_sms</th>\n",
       "      <th>feature_1156_sms</th>\n",
       "      <th>feature_1157_sms</th>\n",
       "      <th>feature_1158_sms</th>\n",
       "      <th>feature_1159_sms</th>\n",
       "      <th>feature_1160_sms</th>\n",
       "      <th>feature_1161_sms</th>\n",
       "      <th>feature_1162_sms</th>\n",
       "      <th>feature_1163_sms</th>\n",
       "      <th>feature_1164_sms</th>\n",
       "      <th>feature_1165_sms</th>\n",
       "      <th>feature_1166_sms</th>\n",
       "      <th>feature_1167_sms</th>\n",
       "      <th>feature_1168_sms</th>\n",
       "      <th>feature_1169_sms</th>\n",
       "      <th>feature_1170_sms</th>\n",
       "      <th>feature_1171_sms</th>\n",
       "      <th>feature_1172_sms</th>\n",
       "      <th>feature_1173_sms</th>\n",
       "      <th>feature_1174_sms</th>\n",
       "      <th>feature_1175_sms</th>\n",
       "      <th>feature_1176_sms</th>\n",
       "      <th>feature_1177_sms</th>\n",
       "      <th>feature_1178_sms</th>\n",
       "      <th>feature_1179_sms</th>\n",
       "      <th>feature_1180_sms</th>\n",
       "      <th>feature_1181_sms</th>\n",
       "      <th>feature_1182_sms</th>\n",
       "      <th>feature_1183_sms</th>\n",
       "      <th>feature_1184_sms</th>\n",
       "      <th>feature_1185_sms</th>\n",
       "      <th>feature_1186_sms</th>\n",
       "      <th>feature_1187_sms</th>\n",
       "      <th>feature_1188_sms</th>\n",
       "      <th>feature_1189_sms</th>\n",
       "      <th>feature_1190_sms</th>\n",
       "      <th>feature_1191_sms</th>\n",
       "      <th>feature_1192_sms</th>\n",
       "      <th>feature_1193_sms</th>\n",
       "      <th>feature_1194_sms</th>\n",
       "      <th>feature_1195_sms</th>\n",
       "      <th>feature_1196_sms</th>\n",
       "      <th>feature_1197_sms</th>\n",
       "      <th>feature_1198_sms</th>\n",
       "      <th>feature_1199_sms</th>\n",
       "      <th>feature_1200_sms</th>\n",
       "      <th>feature_1201_sms</th>\n",
       "      <th>feature_1202_sms</th>\n",
       "      <th>feature_1203_sms</th>\n",
       "      <th>feature_1204_sms</th>\n",
       "      <th>feature_1205_sms</th>\n",
       "      <th>feature_1206_sms</th>\n",
       "      <th>feature_1207_sms</th>\n",
       "      <th>feature_1208_sms</th>\n",
       "      <th>feature_1209_sms</th>\n",
       "      <th>feature_1210_sms</th>\n",
       "      <th>feature_1211_sms</th>\n",
       "      <th>feature_1212_sms</th>\n",
       "      <th>feature_1213_sms</th>\n",
       "      <th>feature_1214_sms</th>\n",
       "      <th>feature_1215_sms</th>\n",
       "      <th>feature_1216_sms</th>\n",
       "      <th>feature_1217_sms</th>\n",
       "      <th>feature_1218_sms</th>\n",
       "      <th>feature_1219_sms</th>\n",
       "      <th>feature_1220_sms</th>\n",
       "      <th>feature_1221_sms</th>\n",
       "      <th>feature_1222_sms</th>\n",
       "      <th>feature_1223_sms</th>\n",
       "      <th>feature_1224_sms</th>\n",
       "      <th>feature_1225_sms</th>\n",
       "      <th>feature_1226_sms</th>\n",
       "      <th>feature_1227_sms</th>\n",
       "      <th>feature_1228_sms</th>\n",
       "      <th>feature_1229_sms</th>\n",
       "      <th>feature_1230_sms</th>\n",
       "      <th>feature_1231_sms</th>\n",
       "      <th>feature_1232_sms</th>\n",
       "      <th>feature_1233_sms</th>\n",
       "      <th>feature_1234_sms</th>\n",
       "      <th>feature_1235_sms</th>\n",
       "      <th>feature_1236_sms</th>\n",
       "      <th>feature_1237_sms</th>\n",
       "      <th>feature_1238_sms</th>\n",
       "      <th>feature_1239_sms</th>\n",
       "      <th>feature_1240_sms</th>\n",
       "      <th>feature_1241_sms</th>\n",
       "      <th>feature_1242_sms</th>\n",
       "      <th>feature_1243_sms</th>\n",
       "      <th>feature_1244_sms</th>\n",
       "      <th>feature_1245_sms</th>\n",
       "      <th>feature_1246_sms</th>\n",
       "      <th>feature_1247_sms</th>\n",
       "      <th>feature_1248_sms</th>\n",
       "      <th>feature_1249_sms</th>\n",
       "      <th>feature_1250_sms</th>\n",
       "      <th>feature_1251_sms</th>\n",
       "      <th>feature_1252_sms</th>\n",
       "      <th>feature_1253_sms</th>\n",
       "      <th>feature_1254_sms</th>\n",
       "      <th>feature_1255_sms</th>\n",
       "      <th>feature_1256_sms</th>\n",
       "      <th>feature_1257_sms</th>\n",
       "      <th>feature_1258_sms</th>\n",
       "      <th>feature_1259_sms</th>\n",
       "      <th>feature_1260_sms</th>\n",
       "      <th>feature_1261_sms</th>\n",
       "      <th>feature_1262_sms</th>\n",
       "      <th>feature_1263_sms</th>\n",
       "      <th>feature_1264_sms</th>\n",
       "      <th>feature_1265_sms</th>\n",
       "      <th>feature_1266_sms</th>\n",
       "      <th>feature_1267_sms</th>\n",
       "      <th>feature_1268_sms</th>\n",
       "      <th>feature_1269_sms</th>\n",
       "      <th>feature_1270_sms</th>\n",
       "      <th>feature_1271_sms</th>\n",
       "      <th>feature_1272_sms</th>\n",
       "      <th>feature_1273_sms</th>\n",
       "      <th>feature_1274_sms</th>\n",
       "      <th>feature_1275_sms</th>\n",
       "      <th>feature_1276_sms</th>\n",
       "      <th>feature_1277_sms</th>\n",
       "      <th>feature_1278_sms</th>\n",
       "      <th>feature_1279_sms</th>\n",
       "      <th>feature_1280_sms</th>\n",
       "      <th>feature_1281_sms</th>\n",
       "      <th>feature_1282_sms</th>\n",
       "      <th>feature_1283_sms</th>\n",
       "      <th>feature_1284_sms</th>\n",
       "      <th>feature_1285_sms</th>\n",
       "      <th>feature_1286_sms</th>\n",
       "      <th>feature_1287_sms</th>\n",
       "      <th>feature_1288_sms</th>\n",
       "      <th>feature_1289_sms</th>\n",
       "      <th>feature_1290_sms</th>\n",
       "      <th>feature_1291_sms</th>\n",
       "      <th>feature_1292_sms</th>\n",
       "      <th>feature_1293_sms</th>\n",
       "      <th>feature_1294_sms</th>\n",
       "      <th>feature_1295_sms</th>\n",
       "      <th>feature_1296_sms</th>\n",
       "      <th>feature_1297_sms</th>\n",
       "      <th>feature_1298_sms</th>\n",
       "      <th>feature_1299_sms</th>\n",
       "      <th>feature_1300_sms</th>\n",
       "      <th>feature_1301_sms</th>\n",
       "      <th>feature_1302_sms</th>\n",
       "      <th>feature_1303_sms</th>\n",
       "      <th>feature_1304_sms</th>\n",
       "      <th>feature_1305_sms</th>\n",
       "      <th>feature_1306_sms</th>\n",
       "      <th>feature_1307_sms</th>\n",
       "      <th>feature_1308_sms</th>\n",
       "      <th>feature_1309_sms</th>\n",
       "      <th>feature_1310_sms</th>\n",
       "      <th>feature_1311_sms</th>\n",
       "      <th>feature_1312_sms</th>\n",
       "      <th>feature_1313_sms</th>\n",
       "      <th>feature_1314_sms</th>\n",
       "      <th>feature_1315_sms</th>\n",
       "      <th>feature_1316_sms</th>\n",
       "      <th>feature_1317_sms</th>\n",
       "      <th>feature_1318_sms</th>\n",
       "      <th>feature_1319_sms</th>\n",
       "      <th>feature_1320_sms</th>\n",
       "      <th>feature_1321_sms</th>\n",
       "      <th>feature_1322_sms</th>\n",
       "      <th>feature_1323_sms</th>\n",
       "      <th>feature_1324_sms</th>\n",
       "      <th>feature_1325_sms</th>\n",
       "      <th>feature_1326_sms</th>\n",
       "      <th>feature_1327_sms</th>\n",
       "      <th>feature_1328_sms</th>\n",
       "      <th>feature_1329_sms</th>\n",
       "      <th>feature_1330_sms</th>\n",
       "      <th>order_id</th>\n",
       "      <th>pan</th>\n",
       "      <th>label_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAHPO6801A</td>\n",
       "      <td>20220121153515</td>\n",
       "      <td>563</td>\n",
       "      <td>H</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>1.999889</td>\n",
       "      <td>2.999667</td>\n",
       "      <td>9.997001</td>\n",
       "      <td>O</td>\n",
       "      <td>46</td>\n",
       "      <td>1.285673</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>9</td>\n",
       "      <td>0.749938</td>\n",
       "      <td>6</td>\n",
       "      <td>337940</td>\n",
       "      <td>16826</td>\n",
       "      <td>2.599680</td>\n",
       "      <td>4.499125</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.166139</td>\n",
       "      <td>32.968032</td>\n",
       "      <td>2.999500</td>\n",
       "      <td>234</td>\n",
       "      <td>86</td>\n",
       "      <td>71</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>16.984016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4644.916667</td>\n",
       "      <td>44737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12262.508447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5308000.0</td>\n",
       "      <td>8304111.0</td>\n",
       "      <td>4441000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>135.750000</td>\n",
       "      <td>65.086001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.149919</td>\n",
       "      <td>5146651.0</td>\n",
       "      <td>4371915.0</td>\n",
       "      <td>1.798590e+06</td>\n",
       "      <td>5542401.0</td>\n",
       "      <td>461866.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27173.666667</td>\n",
       "      <td>81521.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38429.367939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49982.0</td>\n",
       "      <td>16660.666667</td>\n",
       "      <td>49982.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>543.0</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.210427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4203.0</td>\n",
       "      <td>1028.750000</td>\n",
       "      <td>888.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>R</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.333333</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>129.416667</td>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>296.0</td>\n",
       "      <td>250.500000</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>752.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>267.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.132402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>266.0</td>\n",
       "      <td>22.166667</td>\n",
       "      <td>55.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.408554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>107.833333</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.475276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>23</td>\n",
       "      <td>215</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1076</td>\n",
       "      <td>30</td>\n",
       "      <td>117</td>\n",
       "      <td>31</td>\n",
       "      <td>299</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>108</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1510</td>\n",
       "      <td>54</td>\n",
       "      <td>185</td>\n",
       "      <td>42</td>\n",
       "      <td>429</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>154</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>4</td>\n",
       "      <td>204</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3000</td>\n",
       "      <td>269</td>\n",
       "      <td>230</td>\n",
       "      <td>55</td>\n",
       "      <td>1019</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>184</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>715</td>\n",
       "      <td>61</td>\n",
       "      <td>369</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>38.666667</td>\n",
       "      <td>38.666667</td>\n",
       "      <td>0.038667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>0.267241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.112069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.032143</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.857143</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>0.117857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>0.170333</td>\n",
       "      <td>3.357143</td>\n",
       "      <td>0.091977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>11.071429</td>\n",
       "      <td>0.303327</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.113503</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>0.072407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.214286</td>\n",
       "      <td>0.225049</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>3.642857</td>\n",
       "      <td>0.099804</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>34.761905</td>\n",
       "      <td>34.761905</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>3.238095</td>\n",
       "      <td>0.093151</td>\n",
       "      <td>1.095238</td>\n",
       "      <td>0.031507</td>\n",
       "      <td>10.238095</td>\n",
       "      <td>0.294521</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.026027</td>\n",
       "      <td>3.619048</td>\n",
       "      <td>0.104110</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>2.619048</td>\n",
       "      <td>0.075342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.380952</td>\n",
       "      <td>0.212329</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>4.476190</td>\n",
       "      <td>0.128767</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>35.866667</td>\n",
       "      <td>35.866667</td>\n",
       "      <td>0.358667</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.108736</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.028810</td>\n",
       "      <td>9.966667</td>\n",
       "      <td>0.277881</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.100372</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.008364</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.064126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.133333</td>\n",
       "      <td>0.226766</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.139405</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.002788</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>25.166667</td>\n",
       "      <td>27.962963</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>0.122517</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.027815</td>\n",
       "      <td>7.150000</td>\n",
       "      <td>0.284106</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>0.101987</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.433333</td>\n",
       "      <td>0.215894</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.135099</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>3.000</td>\n",
       "      <td>11.152416</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>1.019</td>\n",
       "      <td>0.339667</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.014667</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.061333</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.238333</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.020333</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>XQDI8W8E</td>\n",
       "      <td>AAHPO6801A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAIPI5141G</td>\n",
       "      <td>20211116185506</td>\n",
       "      <td>772</td>\n",
       "      <td>H</td>\n",
       "      <td>0.420485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>14</td>\n",
       "      <td>1.499917</td>\n",
       "      <td>3.498751</td>\n",
       "      <td>2.499250</td>\n",
       "      <td>I</td>\n",
       "      <td>46</td>\n",
       "      <td>1.333278</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16178</td>\n",
       "      <td>2.999334</td>\n",
       "      <td>4.498251</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.332556</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>1.499750</td>\n",
       "      <td>181</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>8.992008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298700.0</td>\n",
       "      <td>308700.0</td>\n",
       "      <td>180700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120251.0</td>\n",
       "      <td>120251.0</td>\n",
       "      <td>6.012550e+04</td>\n",
       "      <td>120251.0</td>\n",
       "      <td>40083.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15944.000000</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>15944.000000</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>238.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>231.500000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.132034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.887841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450.0</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.132034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10530.379333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>75</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>653</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>14</td>\n",
       "      <td>62</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>70</td>\n",
       "      <td>56</td>\n",
       "      <td>1395</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>232</td>\n",
       "      <td>33</td>\n",
       "      <td>151</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "      <td>145</td>\n",
       "      <td>126</td>\n",
       "      <td>3000</td>\n",
       "      <td>100</td>\n",
       "      <td>158</td>\n",
       "      <td>77</td>\n",
       "      <td>638</td>\n",
       "      <td>49</td>\n",
       "      <td>226</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>303</td>\n",
       "      <td>9</td>\n",
       "      <td>678</td>\n",
       "      <td>14</td>\n",
       "      <td>132</td>\n",
       "      <td>292</td>\n",
       "      <td>208</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>0.029667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.056180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.224719</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>23.571429</td>\n",
       "      <td>23.571429</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>0.115152</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042424</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>0.096970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>0.103030</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>20.714286</td>\n",
       "      <td>20.714286</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>0.065517</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.020690</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>1.642857</td>\n",
       "      <td>0.079310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>0.196552</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>2.071429</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>0.127586</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>0.113793</td>\n",
       "      <td>21.571429</td>\n",
       "      <td>21.571429</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.052980</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.041943</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.165563</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.086093</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.022075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>2.238095</td>\n",
       "      <td>0.103753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.904762</td>\n",
       "      <td>0.181015</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>2.047619</td>\n",
       "      <td>0.094923</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>2.238095</td>\n",
       "      <td>0.103753</td>\n",
       "      <td>21.766667</td>\n",
       "      <td>21.766667</td>\n",
       "      <td>0.217667</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.055130</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.041348</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.188361</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>0.094946</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.026034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.105666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.179173</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.088821</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.107198</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>0.085758</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.035842</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>0.166308</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>2.516667</td>\n",
       "      <td>0.108244</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.026523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>2.516667</td>\n",
       "      <td>0.108244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>0.195699</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>1.616667</td>\n",
       "      <td>0.069534</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>0.103943</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.090323</td>\n",
       "      <td>3.000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.052667</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.212667</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.016333</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.075333</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.226000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.097333</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.069333</td>\n",
       "      <td>NKNSPUYG</td>\n",
       "      <td>AAIPI5141G</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAIPZ7980L</td>\n",
       "      <td>20211017185940</td>\n",
       "      <td>710</td>\n",
       "      <td>H</td>\n",
       "      <td>0.409987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>28</td>\n",
       "      <td>4.454441</td>\n",
       "      <td>8.070924</td>\n",
       "      <td>31.393921</td>\n",
       "      <td>Z</td>\n",
       "      <td>46</td>\n",
       "      <td>3.999842</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>45</td>\n",
       "      <td>0.542162</td>\n",
       "      <td>64</td>\n",
       "      <td>2988444</td>\n",
       "      <td>12875</td>\n",
       "      <td>26.162473</td>\n",
       "      <td>36.491127</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>14.544223</td>\n",
       "      <td>112.444278</td>\n",
       "      <td>20.745064</td>\n",
       "      <td>888</td>\n",
       "      <td>197</td>\n",
       "      <td>125</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>145.855145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.051105</td>\n",
       "      <td>31.721311</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.861371</td>\n",
       "      <td>49619.040611</td>\n",
       "      <td>1446850.0</td>\n",
       "      <td>7088063.0</td>\n",
       "      <td>1696000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.959592</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.258065</td>\n",
       "      <td>13.276143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124020</td>\n",
       "      <td>1006101.0</td>\n",
       "      <td>230787.0</td>\n",
       "      <td>4.062192e+04</td>\n",
       "      <td>4648986.0</td>\n",
       "      <td>56694.951220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.8</td>\n",
       "      <td>33.56</td>\n",
       "      <td>94.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.622449</td>\n",
       "      <td>710.292</td>\n",
       "      <td>827.172</td>\n",
       "      <td>30.636</td>\n",
       "      <td>94.8</td>\n",
       "      <td>6.75</td>\n",
       "      <td>19.035488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.641304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.966940</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.084337</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.043676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46200.0</td>\n",
       "      <td>155465.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5048.0</td>\n",
       "      <td>461.120482</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>61.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>269.052632</td>\n",
       "      <td>106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>119.526316</td>\n",
       "      <td>106.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>176.122807</td>\n",
       "      <td>73.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>100.131148</td>\n",
       "      <td>78.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>57.214286</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>129.524590</td>\n",
       "      <td>78.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2543.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>7.785714</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.557875</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.879518</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.730451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2.619048</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.493171</td>\n",
       "      <td>110.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.393263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.257539</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1.950820</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.562115</td>\n",
       "      <td>649.0</td>\n",
       "      <td>7.819277</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.668312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.803279</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.613549</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.325301</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.279905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34692.298217</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>641</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>6</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>886</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>216</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>225</td>\n",
       "      <td>9</td>\n",
       "      <td>102</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1931</td>\n",
       "      <td>400</td>\n",
       "      <td>73</td>\n",
       "      <td>49</td>\n",
       "      <td>551</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>208</td>\n",
       "      <td>5</td>\n",
       "      <td>518</td>\n",
       "      <td>163</td>\n",
       "      <td>171</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>0.044537</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>23.857143</td>\n",
       "      <td>23.857143</td>\n",
       "      <td>0.086484</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.065868</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.047904</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>0.245509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.107784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.428571</td>\n",
       "      <td>0.269461</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.149701</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>24.285714</td>\n",
       "      <td>24.285714</td>\n",
       "      <td>0.176075</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.123529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>0.311765</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>2.928571</td>\n",
       "      <td>0.120588</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>23.238095</td>\n",
       "      <td>23.238095</td>\n",
       "      <td>0.252719</td>\n",
       "      <td>1.619048</td>\n",
       "      <td>0.069672</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.186475</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.014344</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.122951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>0.104508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.809524</td>\n",
       "      <td>0.293033</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.012295</td>\n",
       "      <td>2.809524</td>\n",
       "      <td>0.120902</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006148</td>\n",
       "      <td>21.366667</td>\n",
       "      <td>21.366667</td>\n",
       "      <td>0.331952</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0.063963</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.045242</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>0.173167</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.015601</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>0.120125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>0.138846</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.00156</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>0.288612</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.009360</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>0.120125</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>14.766667</td>\n",
       "      <td>15.275862</td>\n",
       "      <td>0.458830</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.059819</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.044018</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.243792</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.011287</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.101580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.011287</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.128668</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>0.253950</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.010158</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.115124</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.010158</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>1.931</td>\n",
       "      <td>4.827500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.037804</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.025375</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.285344</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.008286</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.071983</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.009839</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.107716</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.268255</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.084412</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.088555</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>3WXC1GIM</td>\n",
       "      <td>AAIPZ7980L</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AALPF3903A</td>\n",
       "      <td>20220201134326</td>\n",
       "      <td>478</td>\n",
       "      <td>H</td>\n",
       "      <td>0.341053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>33</td>\n",
       "      <td>12.597680</td>\n",
       "      <td>5.999500</td>\n",
       "      <td>1.666445</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>3.499583</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>6</td>\n",
       "      <td>0.113205</td>\n",
       "      <td>83</td>\n",
       "      <td>390006</td>\n",
       "      <td>13095</td>\n",
       "      <td>22.659447</td>\n",
       "      <td>20.993336</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18.745564</td>\n",
       "      <td>29.971029</td>\n",
       "      <td>13.246938</td>\n",
       "      <td>137</td>\n",
       "      <td>145</td>\n",
       "      <td>65</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>31.484758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2886.679245</td>\n",
       "      <td>77711.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12215.442972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85509.0</td>\n",
       "      <td>3333176.0</td>\n",
       "      <td>458000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.545455</td>\n",
       "      <td>31.230415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.486069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>472181.0</td>\n",
       "      <td>8909.075472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3360.363636</td>\n",
       "      <td>36964.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10626.402857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15280.0</td>\n",
       "      <td>2182.857143</td>\n",
       "      <td>15280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.800</td>\n",
       "      <td>10.900</td>\n",
       "      <td>13.8</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>303.0</td>\n",
       "      <td>5.716981</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.089273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>305.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5685.0</td>\n",
       "      <td>1510.981132</td>\n",
       "      <td>696.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1145.893617</td>\n",
       "      <td>630.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3918.0</td>\n",
       "      <td>1139.510638</td>\n",
       "      <td>630.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2438.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277.0</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2536.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.566038</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.339356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>329.0</td>\n",
       "      <td>109.666667</td>\n",
       "      <td>150.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>57.039947</td>\n",
       "      <td>2918.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.385284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.357023</td>\n",
       "      <td>587.0</td>\n",
       "      <td>11.075472</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.513601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>747.0</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>359.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>155.563492</td>\n",
       "      <td>81524.0</td>\n",
       "      <td>1538.188679</td>\n",
       "      <td>59071.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8193.472586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>142</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>906</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>201</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>6</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>1182</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>369</td>\n",
       "      <td>14</td>\n",
       "      <td>85</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>1182</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>369</td>\n",
       "      <td>14</td>\n",
       "      <td>85</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>0.100677</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.184874</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0.319328</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>36.428571</td>\n",
       "      <td>36.428571</td>\n",
       "      <td>0.215736</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.714286</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>40.642857</td>\n",
       "      <td>40.642857</td>\n",
       "      <td>0.481387</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>0.029877</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.010545</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>0.156415</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.172232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>0.130053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.571429</td>\n",
       "      <td>0.333919</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>3.785714</td>\n",
       "      <td>0.093146</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.035149</td>\n",
       "      <td>34.619048</td>\n",
       "      <td>34.619048</td>\n",
       "      <td>0.615059</td>\n",
       "      <td>1.095238</td>\n",
       "      <td>0.031637</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>6.761905</td>\n",
       "      <td>0.195323</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>4.809524</td>\n",
       "      <td>0.138927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.095238</td>\n",
       "      <td>0.147180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.238095</td>\n",
       "      <td>0.324622</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.006878</td>\n",
       "      <td>2.809524</td>\n",
       "      <td>0.081155</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.026135</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.033012</td>\n",
       "      <td>30.200000</td>\n",
       "      <td>30.200000</td>\n",
       "      <td>0.766497</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.032009</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>0.221854</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>0.118102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.143488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0.320088</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.077263</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.029801</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.030905</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>26.266667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.036379</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.010998</td>\n",
       "      <td>5.016667</td>\n",
       "      <td>0.254653</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>0.094755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>0.134518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.150000</td>\n",
       "      <td>0.312183</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.011844</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>0.071912</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.034687</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.028765</td>\n",
       "      <td>1.182</td>\n",
       "      <td>26.266667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.036379</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010998</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.254653</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.094755</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.134518</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.312183</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.011844</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.071912</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.034687</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028765</td>\n",
       "      <td>OYD0NERZ</td>\n",
       "      <td>AALPF3903A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AALPF4279M</td>\n",
       "      <td>20211105155431</td>\n",
       "      <td>738</td>\n",
       "      <td>H</td>\n",
       "      <td>0.442491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>3.076763</td>\n",
       "      <td>11.994503</td>\n",
       "      <td>9.998200</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>1.999889</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>12</td>\n",
       "      <td>0.499979</td>\n",
       "      <td>17</td>\n",
       "      <td>73774</td>\n",
       "      <td>14940</td>\n",
       "      <td>13.995668</td>\n",
       "      <td>13.329224</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.999000</td>\n",
       "      <td>59.941059</td>\n",
       "      <td>11.994503</td>\n",
       "      <td>211</td>\n",
       "      <td>28</td>\n",
       "      <td>112</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>18.491254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>287.791667</td>\n",
       "      <td>6907.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1380.200347</td>\n",
       "      <td>3780.384922</td>\n",
       "      <td>586317.0</td>\n",
       "      <td>607743.0</td>\n",
       "      <td>255341.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.238430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399653</td>\n",
       "      <td>414804.0</td>\n",
       "      <td>255341.0</td>\n",
       "      <td>5.516924e+04</td>\n",
       "      <td>421711.0</td>\n",
       "      <td>17571.291667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000</td>\n",
       "      <td>180.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.550095</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.041667</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.668323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>266.541667</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>182.250000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>97.777778</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>163.250000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>78.523810</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>144.761905</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.625000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.269591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.977416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.095238</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.974571</td>\n",
       "      <td>106.0</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.639005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.959682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>141</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>628</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2912</td>\n",
       "      <td>168</td>\n",
       "      <td>144</td>\n",
       "      <td>84</td>\n",
       "      <td>807</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>425</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "      <td>895</td>\n",
       "      <td>17</td>\n",
       "      <td>208</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.619048</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.011676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>10.846154</td>\n",
       "      <td>0.048420</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0.290780</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.099291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.099291</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>10.466667</td>\n",
       "      <td>14.604651</td>\n",
       "      <td>0.215659</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.017516</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.318471</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.009554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>0.140127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>0.103503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.016667</td>\n",
       "      <td>0.288217</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>2.912</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.049451</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.277129</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.145948</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.063874</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.307349</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.005838</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.029876</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>U67MOCC1</td>\n",
       "      <td>AALPF4279M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1717 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID report_timestamp  BureauScore BureauScoreConfidLevel  \\\n",
       "0  AAHPO6801A   20220121153515          563                      H   \n",
       "1  AAIPI5141G   20211116185506          772                      H   \n",
       "2  AAIPZ7980L   20211017185940          710                      H   \n",
       "3  AALPF3903A   20220201134326          478                      H   \n",
       "4  AALPF4279M   20211105155431          738                      H   \n",
       "\n",
       "   MissingRate Current_Finance_Purpose  Current_Amount_Financed  \\\n",
       "0     0.297000                     NaN                   310000   \n",
       "1     0.420485                     NaN                   310000   \n",
       "2     0.409987                     NaN                   310000   \n",
       "3     0.341053                     NaN                   310000   \n",
       "4     0.442491                     NaN                   310000   \n",
       "\n",
       "  Current_Gender_Code First_Name1  Len_Name  Name_nuniq  Tel_nuniq  \\\n",
       "0                   1           O        32    1.999889   2.999667   \n",
       "1                   1           P        14    1.499917   3.498751   \n",
       "2                   1           C        28    4.454441   8.070924   \n",
       "3                   1           P        33   12.597680   5.999500   \n",
       "4                   1           F        15    3.076763  11.994503   \n",
       "\n",
       "   Email_nuniq IncomeTaxPAN_5  Len_of_addrs  City_nuniq PinCode3  \\\n",
       "0     9.997001              O            46    1.285673      422   \n",
       "1     2.499250              I            46    1.333278      422   \n",
       "2    31.393921              Z            46    3.999842      422   \n",
       "3     1.666445              F            46    3.499583      422   \n",
       "4     9.998200              F            46    1.999889      422   \n",
       "\n",
       "   Current_State Current_City  CreditAccountActive  CreditAccountActivePor  \\\n",
       "0             27       MUMBAI                    9                0.749938   \n",
       "1             27       MUMBAI                    1                0.333222   \n",
       "2             27       MUMBAI                   45                0.542162   \n",
       "3             27       MUMBAI                    6                0.113205   \n",
       "4             27       MUMBAI                   12                0.499979   \n",
       "\n",
       "   Outstanding_Balance_UnSecured_Percentage  Outstanding_Balance_UnSecured  \\\n",
       "0                                         6                         337940   \n",
       "1                                         0                              0   \n",
       "2                                        64                        2988444   \n",
       "3                                        83                         390006   \n",
       "4                                        17                          73774   \n",
       "\n",
       "   Diff_dateBirth  State_nuniq  Birth_nuniq  TotalCAPSLast90Days  \\\n",
       "0           16826     2.599680     4.499125                   12   \n",
       "1           16178     2.999334     4.498251                    3   \n",
       "2           12875    26.162473    36.491127                   37   \n",
       "3           13095    22.659447    20.993336                    2   \n",
       "4           14940    13.995668    13.329224                    4   \n",
       "\n",
       "   TotalCAPSLast7Days  TotalCAPSLast30Days  TotalCAPSLast180Days  \\\n",
       "0                   9                    9                    12   \n",
       "1                   0                    3                     3   \n",
       "2                  22                   28                    54   \n",
       "3                   1                    1                     2   \n",
       "4                   1                    2                     5   \n",
       "\n",
       "   CAPSLast7Days  CAPSLast180Days  Pin_nuniq   Pan_nuniq  Ident_nuniq  \\\n",
       "0              0                3   4.166139   32.968032     2.999500   \n",
       "1              0                3   3.332556   10.990010     1.499750   \n",
       "2              1               33  14.544223  112.444278    20.745064   \n",
       "3              1                2  18.745564   29.971029    13.246938   \n",
       "4              1                5   6.999000   59.941059    11.994503   \n",
       "\n",
       "   Name_nuniq2  Tel_nuniq2  Email_nuniq2  Pan_nuniq2  Account_nuniq2  \\\n",
       "0          234          86            71          14              14   \n",
       "1          181          30            45          14              14   \n",
       "2          888         197           125          28              14   \n",
       "3          137         145            65          14              14   \n",
       "4          211          28           112          14              14   \n",
       "\n",
       "   Ident_nuniq2  Gender_nuniq  Amount_Past_Due35_max_30  \\\n",
       "0            60     16.984016                       NaN   \n",
       "1            30      8.992008                       NaN   \n",
       "2            60    145.855145                       NaN   \n",
       "3            60     31.484758                       NaN   \n",
       "4            30     18.491254                       NaN   \n",
       "\n",
       "   Amount_Past_Due35_mean_90  Amount_Past_Due35_max_90  \\\n",
       "0                        NaN                       NaN   \n",
       "1                        NaN                       NaN   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   Amount_Past_Due35_min_90  Amount_Past_Due35_std_90  \\\n",
       "0                       NaN                       NaN   \n",
       "1                       NaN                       NaN   \n",
       "2                       0.0                       0.0   \n",
       "3                       NaN                       NaN   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Amount_Past_Due35_sum_360  Amount_Past_Due35_max_360  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                     1935.0                     1045.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Amount_Past_Due35_min_360  Amount_Past_Due35_std_360  \\\n",
       "0                        0.0                   0.000000   \n",
       "1                        0.0                   0.000000   \n",
       "2                        0.0                 200.051105   \n",
       "3                        0.0                   0.000000   \n",
       "4                        0.0                   0.000000   \n",
       "\n",
       "   Amount_Past_Due35_mean_9999  Amount_Past_Due35_max_9999  \\\n",
       "0                  4644.916667                     44737.0   \n",
       "1                     0.000000                         0.0   \n",
       "2                    31.721311                      1045.0   \n",
       "3                  2886.679245                     77711.0   \n",
       "4                   287.791667                      6907.0   \n",
       "\n",
       "   Amount_Past_Due35_min_9999  Amount_Past_Due35_std_9999  \\\n",
       "0                         0.0                12262.508447   \n",
       "1                         0.0                    0.000000   \n",
       "2                         0.0                  172.861371   \n",
       "3                         0.0                12215.442972   \n",
       "4                         0.0                 1380.200347   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                     49619.040611   \n",
       "3                                              NaN   \n",
       "4                                      3780.384922   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_sum_360  \\\n",
       "0                                         5308000.0   \n",
       "1                                          298700.0   \n",
       "2                                         1446850.0   \n",
       "3                                           85509.0   \n",
       "4                                          586317.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                          8304111.0   \n",
       "1                                           308700.0   \n",
       "2                                          7088063.0   \n",
       "3                                          3333176.0   \n",
       "4                                           607743.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_max_9999  Terms_Duration34_std_30  \\\n",
       "0                                          4441000.0                      NaN   \n",
       "1                                           180700.0                      NaN   \n",
       "2                                          1696000.0                      NaN   \n",
       "3                                           458000.0                      NaN   \n",
       "4                                           255341.0                      NaN   \n",
       "\n",
       "   Terms_Duration34_std_90  Terms_Duration34_sum_360  \\\n",
       "0                      NaN                     360.0   \n",
       "1                      NaN                       0.0   \n",
       "2                 1.959592                      61.0   \n",
       "3                      NaN                       6.0   \n",
       "4                 0.000000                      35.0   \n",
       "\n",
       "   Terms_Duration34_max_360  Terms_Duration34_mean_9999  \\\n",
       "0                     180.0                  135.750000   \n",
       "1                       NaN                         NaN   \n",
       "2                      12.0                    8.258065   \n",
       "3                       6.0                   27.545455   \n",
       "4                      13.0                    3.500000   \n",
       "\n",
       "   Terms_Duration34_std_9999  Payment_Rating34_sum_90  \\\n",
       "0                  65.086001                      NaN   \n",
       "1                        NaN                      NaN   \n",
       "2                  13.276143                      0.0   \n",
       "3                  31.230415                      NaN   \n",
       "4                   4.238430                      0.0   \n",
       "\n",
       "   Payment_Rating34_mean_90  Payment_Rating34_min_90  Payment_Rating34_std_90  \\\n",
       "0                       NaN                      NaN                      NaN   \n",
       "1                       NaN                      NaN                      NaN   \n",
       "2                       0.0                      0.0                      0.0   \n",
       "3                       NaN                      NaN                      NaN   \n",
       "4                       0.0                      0.0                      0.0   \n",
       "\n",
       "   Payment_Rating34_sum_360  Payment_Rating34_mean_360  \\\n",
       "0                       0.0                    0.00000   \n",
       "1                       0.0                    0.00000   \n",
       "2                       1.0                    0.02381   \n",
       "3                       0.0                    0.00000   \n",
       "4                       0.0                    0.00000   \n",
       "\n",
       "   Payment_Rating34_max_360  Payment_Rating34_min_360  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       1.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Payment_Rating34_std_360  Payment_Rating34_sum_9999  \\\n",
       "0                  0.000000                        4.0   \n",
       "1                  0.000000                        0.0   \n",
       "2                  0.152455                        1.0   \n",
       "3                  0.000000                       23.0   \n",
       "4                  0.000000                        2.0   \n",
       "\n",
       "   Payment_Rating34_mean_9999  Payment_Rating34_max_9999  \\\n",
       "0                    0.363636                        4.0   \n",
       "1                    0.000000                        0.0   \n",
       "2                    0.015625                        1.0   \n",
       "3                    0.460000                        6.0   \n",
       "4                    0.083333                        2.0   \n",
       "\n",
       "   Payment_Rating34_min_9999  Payment_Rating34_std_9999  \\\n",
       "0                        0.0                   1.149919   \n",
       "1                        0.0                   0.000000   \n",
       "2                        0.0                   0.124020   \n",
       "3                        0.0                   1.486069   \n",
       "4                        0.0                   0.399653   \n",
       "\n",
       "   Current_Balance35_sum_360  Current_Balance35_max_360  \\\n",
       "0                  5146651.0                  4371915.0   \n",
       "1                   120251.0                   120251.0   \n",
       "2                  1006101.0                   230787.0   \n",
       "3                        0.0                        0.0   \n",
       "4                   414804.0                   255341.0   \n",
       "\n",
       "   Current_Balance35_std_360  Current_Balance35_sum_9999  \\\n",
       "0               1.798590e+06                   5542401.0   \n",
       "1               6.012550e+04                    120251.0   \n",
       "2               4.062192e+04                   4648986.0   \n",
       "3               0.000000e+00                    472181.0   \n",
       "4               5.516924e+04                    421711.0   \n",
       "\n",
       "   Current_Balance35_mean_9999  Settlement_Amount37_mean_360  \\\n",
       "0                461866.750000                           NaN   \n",
       "1                 40083.666667                           NaN   \n",
       "2                 56694.951220                           0.0   \n",
       "3                  8909.075472                           NaN   \n",
       "4                 17571.291667                           NaN   \n",
       "\n",
       "   Settlement_Amount37_std_360  Settlement_Amount37_mean_9999  \\\n",
       "0                          NaN                        67000.0   \n",
       "1                          NaN                            NaN   \n",
       "2                          0.0                            0.0   \n",
       "3                          NaN                            0.0   \n",
       "4                          NaN                            NaN   \n",
       "\n",
       "   Settlement_Amount37_max_9999  Settlement_Amount37_min_9999  \\\n",
       "0                       67000.0                       67000.0   \n",
       "1                           NaN                           NaN   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           NaN                           NaN   \n",
       "\n",
       "   Value_of_Collateral39_std_90  Value_of_Collateral39_std_360  \\\n",
       "0                           NaN                            NaN   \n",
       "1                           NaN                            NaN   \n",
       "2                           0.0                            0.0   \n",
       "3                           NaN                            NaN   \n",
       "4                           NaN                            NaN   \n",
       "\n",
       "   Written_Off_Amt_Total41_sum_360  Written_Off_Amt_Total41_std_360  \\\n",
       "0                              0.0                              0.0   \n",
       "1                              0.0                              NaN   \n",
       "2                              0.0                              0.0   \n",
       "3                              0.0                              NaN   \n",
       "4                              0.0                              NaN   \n",
       "\n",
       "   Written_Off_Amt_Total41_mean_9999  Written_Off_Amt_Total41_max_9999  \\\n",
       "0                       27173.666667                           81521.0   \n",
       "1                       15944.000000                           15944.0   \n",
       "2                           0.000000                               0.0   \n",
       "3                        3360.363636                           36964.0   \n",
       "4                                NaN                               NaN   \n",
       "\n",
       "   Written_Off_Amt_Total41_min_9999  Written_Off_Amt_Total41_std_9999  \\\n",
       "0                               0.0                      38429.367939   \n",
       "1                           15944.0                          0.000000   \n",
       "2                               0.0                          0.000000   \n",
       "3                               0.0                      10626.402857   \n",
       "4                               NaN                               NaN   \n",
       "\n",
       "   Written_Off_Amt_Principal45_sum_360  Written_Off_Amt_Principal45_min_360  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  NaN   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  NaN   \n",
       "4                                  0.0                                  NaN   \n",
       "\n",
       "   Written_Off_Amt_Principal45_std_360  Written_Off_Amt_Principal45_sum_9999  \\\n",
       "0                                  0.0                               49982.0   \n",
       "1                                  NaN                               15944.0   \n",
       "2                                  0.0                                   0.0   \n",
       "3                                  NaN                               15280.0   \n",
       "4                                  NaN                                   0.0   \n",
       "\n",
       "   Written_Off_Amt_Principal45_mean_9999  \\\n",
       "0                           16660.666667   \n",
       "1                           15944.000000   \n",
       "2                               0.000000   \n",
       "3                            2182.857143   \n",
       "4                                    NaN   \n",
       "\n",
       "   Written_Off_Amt_Principal45_max_9999  Written_Off_Amt_Principal45_min_9999  \\\n",
       "0                               49982.0                                   0.0   \n",
       "1                               15944.0                               15944.0   \n",
       "2                                   0.0                                   0.0   \n",
       "3                               15280.0                                   0.0   \n",
       "4                                   NaN                                   NaN   \n",
       "\n",
       "   Rate_of_Interest36_sum_30  Rate_of_Interest36_max_30  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                        NaN   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   Rate_of_Interest36_min_30  Rate_of_Interest36_std_30  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                        NaN   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   Rate_of_Interest36_sum_90  Rate_of_Interest36_mean_90  \\\n",
       "0                        NaN                         NaN   \n",
       "1                        NaN                         NaN   \n",
       "2                      167.8                       33.56   \n",
       "3                        NaN                         NaN   \n",
       "4                       54.0                       18.00   \n",
       "\n",
       "   Rate_of_Interest36_max_90  Rate_of_Interest36_min_90  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                       94.8                       18.0   \n",
       "3                        NaN                        NaN   \n",
       "4                       18.0                       18.0   \n",
       "\n",
       "   Rate_of_Interest36_std_90  Rate_of_Interest36_sum_360  \\\n",
       "0                        NaN                       0.000   \n",
       "1                        NaN                       0.000   \n",
       "2                  30.622449                     710.292   \n",
       "3                        NaN                       0.000   \n",
       "4                   0.000000                     180.000   \n",
       "\n",
       "   Rate_of_Interest36_sum_9999  Rate_of_Interest36_mean_9999  \\\n",
       "0                       45.000                        45.000   \n",
       "1                        0.000                           NaN   \n",
       "2                      827.172                        30.636   \n",
       "3                       21.800                        10.900   \n",
       "4                      180.000                        18.000   \n",
       "\n",
       "   Rate_of_Interest36_max_9999  Rate_of_Interest36_min_9999  \\\n",
       "0                         45.0                        45.00   \n",
       "1                          NaN                          NaN   \n",
       "2                         94.8                         6.75   \n",
       "3                         13.8                         8.00   \n",
       "4                         18.0                        18.00   \n",
       "\n",
       "   Rate_of_Interest36_std_9999  Repayment_Tenure36_std_30  \\\n",
       "0                     0.000000                        NaN   \n",
       "1                          NaN                        NaN   \n",
       "2                    19.035488                        NaN   \n",
       "3                     2.900000                        NaN   \n",
       "4                     0.000000                        NaN   \n",
       "\n",
       "   Repayment_Tenure36_std_90  Repayment_Tenure36_mean_360  \\\n",
       "0                        NaN                   180.000000   \n",
       "1                        NaN                     0.000000   \n",
       "2                   1.641304                     1.000000   \n",
       "3                        NaN                     2.000000   \n",
       "4                   0.489898                     1.666667   \n",
       "\n",
       "   Repayment_Tenure36_min_360  Repayment_Tenure36_std_360  \\\n",
       "0                       180.0                    0.000000   \n",
       "1                         0.0                    0.000000   \n",
       "2                         0.0                    1.966940   \n",
       "3                         0.0                    2.828427   \n",
       "4                         0.0                    3.550095   \n",
       "\n",
       "   Repayment_Tenure36_sum_9999  Repayment_Tenure36_mean_9999  \\\n",
       "0                        543.0                     45.250000   \n",
       "1                          0.0                      0.000000   \n",
       "2                        256.0                      3.084337   \n",
       "3                        303.0                      5.716981   \n",
       "4                         49.0                      2.041667   \n",
       "\n",
       "   Repayment_Tenure36_max_9999  Repayment_Tenure36_min_9999  \\\n",
       "0                        180.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                         60.0                          0.0   \n",
       "3                         94.0                          0.0   \n",
       "4                         13.0                          0.0   \n",
       "\n",
       "   Repayment_Tenure36_std_9999  Income26_count_30  Income26_std_90  \\\n",
       "0                    74.210427                NaN              NaN   \n",
       "1                     0.000000                NaN              NaN   \n",
       "2                     9.043676                NaN              NaN   \n",
       "3                    18.089273                NaN              NaN   \n",
       "4                     3.668323                NaN              NaN   \n",
       "\n",
       "   Income26_min_9999  Income26_std_9999  Open_Date29_max_30  \\\n",
       "0           480000.0                0.0                 NaN   \n",
       "1                NaN                NaN                 NaN   \n",
       "2            46200.0           155465.5                 NaN   \n",
       "3                NaN                NaN                 NaN   \n",
       "4            17000.0            11500.0                 NaN   \n",
       "\n",
       "   Open_Date29_mean_30  Open_Date29_mode_30  Open_Date29_nuniq_30  \\\n",
       "0                  NaN                  NaN                   NaN   \n",
       "1                  NaN                  NaN                   NaN   \n",
       "2                  NaN                  NaN                   NaN   \n",
       "3                  NaN                  NaN                   NaN   \n",
       "4                  NaN                  NaN                   NaN   \n",
       "\n",
       "   Open_Date29_maxcount_30  Open_Date29_mode_90  Open_Date29_nuniq_90  \\\n",
       "0                      NaN                  NaN                   NaN   \n",
       "1                      NaN                  NaN                   NaN   \n",
       "2                      NaN                 78.0                  10.0   \n",
       "3                      NaN                  NaN                   NaN   \n",
       "4                      NaN                 49.0                   4.0   \n",
       "\n",
       "   Open_Date29_max_360  Open_Date29_mode_360  Open_Date29_maxcount_360  \\\n",
       "0                310.0                 192.0                       1.0   \n",
       "1                238.0                 124.0                       1.0   \n",
       "2                326.0                  78.0                       4.0   \n",
       "3                305.0                 302.0                       2.0   \n",
       "4                354.0                  49.0                       2.0   \n",
       "\n",
       "   Open_Date29_max_9999  Open_Date29_mean_9999  Open_Date29_mode_9999  \\\n",
       "0                4203.0            1028.750000                  888.0   \n",
       "1                 955.0             439.000000                  124.0   \n",
       "2                5048.0             461.120482                   78.0   \n",
       "3                5685.0            1510.981132                  696.0   \n",
       "4                1087.0             266.541667                   49.0   \n",
       "\n",
       "   Open_Date29_maxcount_9999  Portfolio_Type34_nuniq_30  \\\n",
       "0                        2.0                        NaN   \n",
       "1                        1.0                        NaN   \n",
       "2                        4.0                        NaN   \n",
       "3                        4.0                        NaN   \n",
       "4                        2.0                        NaN   \n",
       "\n",
       "   Portfolio_Type34_nuniq_90  Portfolio_Type34_nuniq_360  \\\n",
       "0                        NaN                         2.0   \n",
       "1                        NaN                         1.0   \n",
       "2                        2.0                         2.0   \n",
       "3                        NaN                         1.0   \n",
       "4                        1.0                         1.0   \n",
       "\n",
       "  Portfolio_Type34_mode_9999  Portfolio_Type34_nuniq_9999  \\\n",
       "0                          R                          3.0   \n",
       "1                          I                          1.0   \n",
       "2                          I                          3.0   \n",
       "3                          I                          2.0   \n",
       "4                          I                          1.0   \n",
       "\n",
       "  Account_Type32_mode_30  Account_Type32_nuniq_30 Account_Type32_mode_90  \\\n",
       "0                    NaN                      NaN                    NaN   \n",
       "1                    NaN                      NaN                    NaN   \n",
       "2                    NaN                      NaN                    5.0   \n",
       "3                    NaN                      NaN                    NaN   \n",
       "4                    NaN                      NaN                    5.0   \n",
       "\n",
       "   Account_Type32_nuniq_90 Account_Type32_mode_360  Account_Type32_nuniq_360  \\\n",
       "0                      NaN                     2.0                       2.0   \n",
       "1                      NaN                     7.0                       1.0   \n",
       "2                      4.0                     5.0                       5.0   \n",
       "3                      NaN                     7.0                       2.0   \n",
       "4                      2.0                     5.0                       4.0   \n",
       "\n",
       "  Account_Type32_mode_9999  Account_Type32_nuniq_9999  \\\n",
       "0                     10.0                        6.0   \n",
       "1                      7.0                        2.0   \n",
       "2                      5.0                        9.0   \n",
       "3                      7.0                        6.0   \n",
       "4                      5.0                        4.0   \n",
       "\n",
       "   Occupation_Code35_nuniq_30  Occupation_Code35_nuniq_90  \\\n",
       "0                         NaN                         NaN   \n",
       "1                         NaN                         NaN   \n",
       "2                         NaN                         1.0   \n",
       "3                         NaN                         NaN   \n",
       "4                         NaN                         1.0   \n",
       "\n",
       "   Occupation_Code35_nuniq_360 CurrencyCode32_mode_360  \\\n",
       "0                          1.0                     INR   \n",
       "1                          1.0                     INR   \n",
       "2                          1.0                     INR   \n",
       "3                          1.0                     INR   \n",
       "4                          2.0                     INR   \n",
       "\n",
       "  CurrencyCode32_mode_9999 AccountHoldertypeCode41_mode_90  \\\n",
       "0                      INR                             NaN   \n",
       "1                      INR                             NaN   \n",
       "2                      INR                             1.0   \n",
       "3                      INR                             NaN   \n",
       "4                      INR                             1.0   \n",
       "\n",
       "   AccountHoldertypeCode41_nuniq_90  AccountHoldertypeCode41_nuniq_360  \\\n",
       "0                               NaN                                1.0   \n",
       "1                               NaN                                1.0   \n",
       "2                               1.0                                1.0   \n",
       "3                               NaN                                1.0   \n",
       "4                               1.0                                1.0   \n",
       "\n",
       "   AccountHoldertypeCode41_nuniq_9999  Payment_History_Profile43_mode_30  \\\n",
       "0                                 2.0                                  0   \n",
       "1                                 1.0                                  0   \n",
       "2                                 2.0                                  0   \n",
       "3                                 1.0                                  0   \n",
       "4                                 1.0                                  0   \n",
       "\n",
       "   Payment_History_Profile43_mode_90  Payment_History_Profile43_nuniq_90  \\\n",
       "0                                  0                                 NaN   \n",
       "1                                  0                                 NaN   \n",
       "2                                  1                                 2.0   \n",
       "3                                  0                                 NaN   \n",
       "4                                  1                                 1.0   \n",
       "\n",
       "   Payment_History_Profile43_mode_360  Payment_History_Profile43_nuniq_360  \\\n",
       "0                                  36                                  2.0   \n",
       "1                                  36                                  2.0   \n",
       "2                                   1                                 12.0   \n",
       "3                                  36                                  2.0   \n",
       "4                                   1                                  6.0   \n",
       "\n",
       "   Payment_History_Profile43_mode_9999  Payment_History_Profile43_nuniq_9999  \\\n",
       "0                                   36                                  12.0   \n",
       "1                                   36                                   3.0   \n",
       "2                                    1                                  27.0   \n",
       "3                                    1                                  23.0   \n",
       "4                                    1                                   8.0   \n",
       "\n",
       "   Date_Closed31_mode_30  Date_Closed31_nuniq_30  Date_Closed31_maxcount_30  \\\n",
       "0                    NaN                     NaN                        NaN   \n",
       "1                    NaN                     NaN                        NaN   \n",
       "2                    NaN                     NaN                        NaN   \n",
       "3                    NaN                     NaN                        NaN   \n",
       "4                    NaN                     NaN                        NaN   \n",
       "\n",
       "   Date_Closed31_max_90  Date_Closed31_min_90  Date_Closed31_mean_90  \\\n",
       "0                   NaN                   NaN                    NaN   \n",
       "1                   NaN                   NaN                    NaN   \n",
       "2                  69.0                  54.0                   61.5   \n",
       "3                   NaN                   NaN                    NaN   \n",
       "4                  66.0                  44.0                   55.0   \n",
       "\n",
       "   Date_Closed31_mode_90  Date_Closed31_nuniq_90  Date_Closed31_maxcount_90  \\\n",
       "0                    NaN                     NaN                        NaN   \n",
       "1                    NaN                     NaN                        NaN   \n",
       "2                   54.0                     3.0                        1.0   \n",
       "3                    NaN                     NaN                        NaN   \n",
       "4                   44.0                     3.0                        1.0   \n",
       "\n",
       "   Date_Closed31_mode_360  Date_Closed31_nuniq_360  \\\n",
       "0                     0.0                      1.0   \n",
       "1                   153.0                      2.0   \n",
       "2                   106.0                     24.0   \n",
       "3                    53.0                      2.0   \n",
       "4                    44.0                     12.0   \n",
       "\n",
       "   Date_Closed31_maxcount_360  Date_Closed31_mean_9999  \\\n",
       "0                         0.0               281.333333   \n",
       "1                         1.0               231.500000   \n",
       "2                         3.0               269.052632   \n",
       "3                         2.0              1145.893617   \n",
       "4                         1.0               182.250000   \n",
       "\n",
       "   Date_Closed31_mode_9999  Date_of_Last_Payment40_nuniq_30  \\\n",
       "0                     88.0                              NaN   \n",
       "1                    153.0                              NaN   \n",
       "2                    106.0                              NaN   \n",
       "3                    630.0                              NaN   \n",
       "4                     44.0                              NaN   \n",
       "\n",
       "   Date_of_Last_Payment40_maxcount_30  Date_of_Last_Payment40_nuniq_90  \\\n",
       "0                                 NaN                              NaN   \n",
       "1                                 NaN                              NaN   \n",
       "2                                 NaN                              4.0   \n",
       "3                                 NaN                              NaN   \n",
       "4                                 NaN                              4.0   \n",
       "\n",
       "   Date_of_Last_Payment40_maxcount_90  Date_of_Last_Payment40_max_360  \\\n",
       "0                                 NaN                            21.0   \n",
       "1                                 NaN                           153.0   \n",
       "2                                 2.0                           296.0   \n",
       "3                                 NaN                            76.0   \n",
       "4                                 2.0                           184.0   \n",
       "\n",
       "   Date_of_Last_Payment40_min_360  Date_of_Last_Payment40_mean_360  \\\n",
       "0                            21.0                        21.000000   \n",
       "1                           153.0                       153.000000   \n",
       "2                            54.0                       119.526316   \n",
       "3                            53.0                        60.666667   \n",
       "4                            34.0                        97.777778   \n",
       "\n",
       "   Date_of_Last_Payment40_mode_360  Date_of_Last_Payment40_maxcount_360  \\\n",
       "0                             21.0                                  2.0   \n",
       "1                            153.0                                  1.0   \n",
       "2                            106.0                                  3.0   \n",
       "3                             53.0                                  2.0   \n",
       "4                             34.0                                  4.0   \n",
       "\n",
       "   Date_of_Last_Payment40_max_9999  Date_of_Last_Payment40_mean_9999  \\\n",
       "0                            461.0                        129.416667   \n",
       "1                            153.0                        153.000000   \n",
       "2                           1716.0                        176.122807   \n",
       "3                           3918.0                       1139.510638   \n",
       "4                            901.0                        163.250000   \n",
       "\n",
       "   Date_of_Last_Payment40_mode_9999  Date_of_Last_Payment40_nuniq_9999  \\\n",
       "0                              46.0                                8.0   \n",
       "1                             153.0                                2.0   \n",
       "2                              73.0                               42.0   \n",
       "3                             630.0                               28.0   \n",
       "4                              34.0                               16.0   \n",
       "\n",
       "   Date_of_Last_Payment40_maxcount_9999  Date_Reported33_nuniq_30  \\\n",
       "0                                   4.0                       NaN   \n",
       "1                                   1.0                       NaN   \n",
       "2                                   4.0                       NaN   \n",
       "3                                   4.0                       NaN   \n",
       "4                                   4.0                       NaN   \n",
       "\n",
       "   Date_Reported33_max_90  Date_Reported33_mode_90  Date_Reported33_nuniq_90  \\\n",
       "0                     NaN                      NaN                       NaN   \n",
       "1                     NaN                      NaN                       NaN   \n",
       "2                    78.0                     47.0                       3.0   \n",
       "3                     NaN                      NaN                       NaN   \n",
       "4                    66.0                     36.0                       2.0   \n",
       "\n",
       "   Date_Reported33_maxcount_90  Date_Reported33_max_360  \\\n",
       "0                          NaN                     21.0   \n",
       "1                          NaN                     77.0   \n",
       "2                          9.0                    269.0   \n",
       "3                          NaN                     32.0   \n",
       "4                          4.0                    158.0   \n",
       "\n",
       "   Date_Reported33_mean_360  Date_Reported33_mode_360  \\\n",
       "0                 21.000000                      21.0   \n",
       "1                 77.000000                      77.0   \n",
       "2                100.131148                      78.0   \n",
       "3                 32.000000                      32.0   \n",
       "4                 78.523810                      66.0   \n",
       "\n",
       "   Date_Reported33_nuniq_360  Date_Reported33_max_9999  \\\n",
       "0                        1.0                     418.0   \n",
       "1                        1.0                     310.0   \n",
       "2                       11.0                    1692.0   \n",
       "3                        1.0                    2438.0   \n",
       "4                        6.0                     889.0   \n",
       "\n",
       "   Date_Reported33_mode_9999  Date_Reported33_nuniq_9999  \\\n",
       "0                       21.0                         7.0   \n",
       "1                       77.0                         2.0   \n",
       "2                       47.0                        22.0   \n",
       "3                      611.0                        24.0   \n",
       "4                       66.0                         8.0   \n",
       "\n",
       "   Date_Reported33_maxcount_9999  DateOfAddition34_nuniq_30  \\\n",
       "0                            6.0                        NaN   \n",
       "1                            2.0                        NaN   \n",
       "2                           22.0                        NaN   \n",
       "3                            9.0                        NaN   \n",
       "4                            8.0                        NaN   \n",
       "\n",
       "   DateOfAddition34_max_90  DateOfAddition34_mean_90  \\\n",
       "0                      NaN                       NaN   \n",
       "1                      NaN                       NaN   \n",
       "2                     78.0                 57.214286   \n",
       "3                      NaN                       NaN   \n",
       "4                     66.0                 42.000000   \n",
       "\n",
       "   DateOfAddition34_nuniq_90  DateOfAddition34_maxcount_90  \\\n",
       "0                        NaN                           NaN   \n",
       "1                        NaN                           NaN   \n",
       "2                        3.0                           8.0   \n",
       "3                        NaN                           NaN   \n",
       "4                        2.0                           4.0   \n",
       "\n",
       "   DateOfAddition34_max_360  DateOfAddition34_mean_360  \\\n",
       "0                     296.0                 250.500000   \n",
       "1                     230.0                 169.000000   \n",
       "2                     300.0                 129.524590   \n",
       "3                     277.0                 175.000000   \n",
       "4                     340.0                 144.761905   \n",
       "\n",
       "   DateOfAddition34_mode_360  DateOfAddition34_maxcount_360  \\\n",
       "0                      205.0                            1.0   \n",
       "1                      108.0                            1.0   \n",
       "2                       78.0                           14.0   \n",
       "3                      124.0                            2.0   \n",
       "4                       97.0                            6.0   \n",
       "\n",
       "   DateOfAddition34_max_9999  DateOfAddition34_min_9999  \\\n",
       "0                     1878.0                      205.0   \n",
       "1                      808.0                      108.0   \n",
       "2                     2543.0                       35.0   \n",
       "3                     2536.0                      124.0   \n",
       "4                     1071.0                       36.0   \n",
       "\n",
       "   DateOfAddition34_mode_9999  DateOfAddition34_nuniq_9999  \\\n",
       "0                       752.0                         11.0   \n",
       "1                       108.0                          3.0   \n",
       "2                        78.0                         29.0   \n",
       "3                       611.0                         26.0   \n",
       "4                        97.0                         11.0   \n",
       "\n",
       "   DateOfAddition34_maxcount_9999  Account_Status34_mode_30  \\\n",
       "0                             2.0                       NaN   \n",
       "1                             1.0                       NaN   \n",
       "2                            14.0                       NaN   \n",
       "3                             9.0                       NaN   \n",
       "4                             6.0                       NaN   \n",
       "\n",
       "   Account_Status34_nuniq_30  Account_Status34_mode_90  \\\n",
       "0                        NaN                       NaN   \n",
       "1                        NaN                       NaN   \n",
       "2                        NaN                      11.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        NaN                      11.0   \n",
       "\n",
       "   Account_Status34_nuniq_90  Account_Status34_nuniq_360  \\\n",
       "0                        NaN                         1.0   \n",
       "1                        NaN                         2.0   \n",
       "2                        3.0                         6.0   \n",
       "3                        NaN                         2.0   \n",
       "4                        2.0                         2.0   \n",
       "\n",
       "  Account_Status34_mode_9999  Account_Status34_nuniq_9999  Month50_sum_30  \\\n",
       "0                         11                          4.0             NaN   \n",
       "1                         13                          2.0             NaN   \n",
       "2                         11                          6.0             NaN   \n",
       "3                         13                          9.0             NaN   \n",
       "4                         13                          3.0             NaN   \n",
       "\n",
       "   Month50_mean_30  Month50_std_30  Month50_sum_90  Month50_mean_90  \\\n",
       "0              NaN             NaN             NaN              NaN   \n",
       "1              NaN             NaN             NaN              NaN   \n",
       "2              NaN             NaN           109.0         7.785714   \n",
       "3              NaN             NaN             NaN              NaN   \n",
       "4              NaN             NaN            44.0         8.800000   \n",
       "\n",
       "   Month50_max_90  Month50_std_90  Month50_max_360  Month50_min_360  \\\n",
       "0             NaN             NaN             12.0             12.0   \n",
       "1             NaN             NaN              8.0              8.0   \n",
       "2             9.0        0.557875             12.0              3.0   \n",
       "3             NaN             NaN             12.0             12.0   \n",
       "4             9.0        0.400000             12.0              5.0   \n",
       "\n",
       "   Month50_mean_9999  Month50_max_9999  Month50_min_9999  Month50_std_9999  \\\n",
       "0          12.000000              12.0              12.0          0.000000   \n",
       "1           9.000000              11.0               8.0          1.414214   \n",
       "2           7.879518              12.0               3.0          2.730451   \n",
       "3           8.566038              12.0               3.0          3.339356   \n",
       "4           8.625000              12.0               5.0          2.269591   \n",
       "\n",
       "   Days_Past_Due58_sum_90  Days_Past_Due58_min_90  Days_Past_Due58_std_90  \\\n",
       "0                     NaN                     NaN                     NaN   \n",
       "1                     NaN                     NaN                     NaN   \n",
       "2                     0.0                     0.0                     0.0   \n",
       "3                     NaN                     NaN                     NaN   \n",
       "4                     0.0                     0.0                     0.0   \n",
       "\n",
       "   Days_Past_Due58_sum_360  Days_Past_Due58_mean_360  Days_Past_Due58_max_360  \\\n",
       "0                      0.0                  0.000000                      0.0   \n",
       "1                      0.0                  0.000000                      0.0   \n",
       "2                    110.0                  2.619048                     54.0   \n",
       "3                    329.0                109.666667                    150.0   \n",
       "4                      0.0                  0.000000                      0.0   \n",
       "\n",
       "   Days_Past_Due58_min_360  Days_Past_Due58_std_360  Days_Past_Due58_sum_9999  \\\n",
       "0                      0.0                 0.000000                     267.0   \n",
       "1                      0.0                 0.000000                     450.0   \n",
       "2                      0.0                11.493171                     110.0   \n",
       "3                     29.0                57.039947                    2918.0   \n",
       "4                      0.0                 0.000000                     114.0   \n",
       "\n",
       "   Days_Past_Due58_max_9999  Days_Past_Due58_min_9999  \\\n",
       "0                     129.0                       0.0   \n",
       "1                     450.0                       0.0   \n",
       "2                      54.0                       0.0   \n",
       "3                     900.0                       0.0   \n",
       "4                      87.0                       0.0   \n",
       "\n",
       "   Days_Past_Due58_std_9999  Duecount53_mean_30  Duecount53_min_30  \\\n",
       "0                 34.132402                 NaN                NaN   \n",
       "1                212.132034                 NaN                NaN   \n",
       "2                  9.393263                 NaN                NaN   \n",
       "3                144.385284                 NaN                NaN   \n",
       "4                 17.977416                 NaN                NaN   \n",
       "\n",
       "   Duecount53_std_30  Duecount53_sum_90  Duecount53_mean_90  \\\n",
       "0                NaN                NaN                 NaN   \n",
       "1                NaN                NaN                 NaN   \n",
       "2                NaN               15.0            1.071429   \n",
       "3                NaN                NaN                 NaN   \n",
       "4                NaN                5.0            1.000000   \n",
       "\n",
       "   Duecount53_max_90  Duecount53_min_90  Duecount53_std_90  \\\n",
       "0                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN   \n",
       "2                2.0                1.0           0.257539   \n",
       "3                NaN                NaN                NaN   \n",
       "4                1.0                1.0           0.000000   \n",
       "\n",
       "   Duecount53_sum_360  Duecount53_mean_360  Duecount53_max_360  \\\n",
       "0                17.0             8.500000                10.0   \n",
       "1                 8.0             4.000000                 6.0   \n",
       "2               119.0             1.950820                 8.0   \n",
       "3                17.0             5.666667                 9.0   \n",
       "4                65.0             3.095238                 9.0   \n",
       "\n",
       "   Duecount53_min_360  Duecount53_std_360  Duecount53_sum_9999  \\\n",
       "0                 7.0            1.500000                266.0   \n",
       "1                 2.0            2.000000                 24.0   \n",
       "2                 1.0            1.562115                649.0   \n",
       "3                 4.0            2.357023                587.0   \n",
       "4                 1.0            2.974571                106.0   \n",
       "\n",
       "   Duecount53_mean_9999  Duecount53_max_9999  Duecount53_min_9999  \\\n",
       "0             22.166667                 55.0                  7.0   \n",
       "1              8.000000                 16.0                  2.0   \n",
       "2              7.819277                 83.0                  1.0   \n",
       "3             11.075472                 83.0                  1.0   \n",
       "4              4.416667                 33.0                  1.0   \n",
       "\n",
       "   Duecount53_std_9999  Duesum51_mean_30  Duesum51_std_30  Duesum51_mean_90  \\\n",
       "0            12.408554               NaN              NaN               NaN   \n",
       "1             5.887841               NaN              NaN               NaN   \n",
       "2            13.668312               NaN              NaN               0.0   \n",
       "3            22.513601               NaN              NaN               NaN   \n",
       "4             6.639005               NaN              NaN               0.0   \n",
       "\n",
       "   Duesum51_max_90  Duesum51_sum_360  Duesum51_mean_360  Duesum51_max_360  \\\n",
       "0              NaN               0.0           0.000000               0.0   \n",
       "1              NaN               0.0           0.000000               0.0   \n",
       "2              0.0             110.0           1.803279              54.0   \n",
       "3              NaN             747.0         249.000000             359.0   \n",
       "4              0.0               0.0           0.000000               0.0   \n",
       "\n",
       "   Duesum51_min_360  Duesum51_std_360  Duesum51_sum_9999  Duesum51_mean_9999  \\\n",
       "0               0.0          0.000000             1294.0          107.833333   \n",
       "1               0.0          0.000000              450.0          150.000000   \n",
       "2               0.0          9.613549              110.0            1.325301   \n",
       "3              29.0        155.563492            81524.0         1538.188679   \n",
       "4               0.0          0.000000              140.0            5.833333   \n",
       "\n",
       "   Duesum51_max_9999  Duesum51_min_9999  Duesum51_std_9999  \\\n",
       "0             1085.0                0.0         295.475276   \n",
       "1              450.0                0.0         212.132034   \n",
       "2               54.0                0.0           8.279905   \n",
       "3            59071.0                0.0        8193.472586   \n",
       "4               87.0                0.0          19.959682   \n",
       "\n",
       "   Amount_Financed35_std_7  Amount_Financed35_max_30  \\\n",
       "0                      NaN                       NaN   \n",
       "1                      NaN                   25000.0   \n",
       "2                      0.0                  100000.0   \n",
       "3                      0.0                   50000.0   \n",
       "4                      0.0                   50000.0   \n",
       "\n",
       "   Amount_Financed35_min_30  Amount_Financed35_std_30  \\\n",
       "0                       NaN                       NaN   \n",
       "1                       0.0              10530.379333   \n",
       "2                       0.0              34692.298217   \n",
       "3                   50000.0                  0.000000   \n",
       "4                       0.0              25000.000000   \n",
       "\n",
       "   Amount_Financed35_count_90  ...  feature_1034_sms  feature_1035_sms  \\\n",
       "0                         3.0  ...                68                23   \n",
       "1                         3.0  ...                24                19   \n",
       "2                        16.0  ...                34                24   \n",
       "3                         2.0  ...                23                 6   \n",
       "4                         4.0  ...                 0                 0   \n",
       "\n",
       "   feature_1036_sms  feature_1037_sms  feature_1038_sms  feature_1039_sms  \\\n",
       "0               215                 7                19                76   \n",
       "1                75                 9                39                10   \n",
       "2                91                 2                 7                60   \n",
       "3               142                 3                 1               101   \n",
       "4                11                 1                 0                 0   \n",
       "\n",
       "   feature_1040_sms  feature_1041_sms  feature_1042_sms  feature_1043_sms  \\\n",
       "0                 9                 1                55                 0   \n",
       "1                 0                 2                47                 0   \n",
       "2                 0                 4                51                 0   \n",
       "3                 0                 0               107                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   feature_1044_sms  feature_1045_sms  feature_1046_sms  feature_1047_sms  \\\n",
       "0               155                 2                94                 1   \n",
       "1                82                 2                43                54   \n",
       "2               143                 6                59                 4   \n",
       "3               236                 5                59                19   \n",
       "4                 4                 0                 2                13   \n",
       "\n",
       "   feature_1048_sms  feature_1049_sms  feature_1050_sms  feature_1051_sms  \\\n",
       "0                 3              1076                30               117   \n",
       "1                47               653                30                36   \n",
       "2                 3               641                30                41   \n",
       "3                24               906                30                29   \n",
       "4                 3               141                13                 1   \n",
       "\n",
       "   feature_1052_sms  feature_1053_sms  feature_1054_sms  feature_1055_sms  \\\n",
       "0                31               299                 8                27   \n",
       "1                27               123                14                62   \n",
       "2                29               111                 2                10   \n",
       "3                 9               201                 4                 2   \n",
       "4                 9                41                 2                 0   \n",
       "\n",
       "   feature_1056_sms  feature_1057_sms  feature_1058_sms  feature_1059_sms  \\\n",
       "0               108                 9                 2                69   \n",
       "1                17                 0                 2                69   \n",
       "2                77                 0                 5                89   \n",
       "3               107                 0                 0               130   \n",
       "4                21                 0                 0                14   \n",
       "\n",
       "   feature_1060_sms  feature_1061_sms  feature_1062_sms  feature_1063_sms  \\\n",
       "0                 0               244                 2               150   \n",
       "1                 0               117                 2                58   \n",
       "2                 1               185                 6                77   \n",
       "3                 0               290                 6                70   \n",
       "4                 0                28                 1                 6   \n",
       "\n",
       "   feature_1064_sms  feature_1065_sms  feature_1066_sms  feature_1067_sms  \\\n",
       "0                 3                 4              1510                54   \n",
       "1                70                56              1395                60   \n",
       "2                 5                 3               886                58   \n",
       "3                27                28              1182                45   \n",
       "4                14                 4               628                43   \n",
       "\n",
       "   feature_1068_sms  feature_1069_sms  feature_1070_sms  feature_1071_sms  \\\n",
       "0               185                42               429                10   \n",
       "1                90                50               232                33   \n",
       "2                53                39               216                 2   \n",
       "3                43                13               301                 5   \n",
       "4                 3                11               200                 6   \n",
       "\n",
       "   feature_1072_sms  feature_1073_sms  feature_1074_sms  feature_1075_sms  \\\n",
       "0                30               154                10                 3   \n",
       "1               151                37                 0                 3   \n",
       "2                10                90                 0                10   \n",
       "3                 3               112                 0                 0   \n",
       "4                 0                88                 0                 1   \n",
       "\n",
       "   feature_1076_sms  feature_1077_sms  feature_1078_sms  feature_1079_sms  \\\n",
       "0               100                 0               326                 4   \n",
       "1               151                 0               273                 7   \n",
       "2               114                 2               225                 9   \n",
       "3               159                 0               369                14   \n",
       "4                65                 0               181                 5   \n",
       "\n",
       "   feature_1080_sms  feature_1081_sms  feature_1082_sms  feature_1083_sms  \\\n",
       "0               204                 4                 6              3000   \n",
       "1                97               145               126              3000   \n",
       "2               102                 9                 5              1931   \n",
       "3                85                41                34              1182   \n",
       "4                40                24                 4              2912   \n",
       "\n",
       "   feature_1084_sms  feature_1085_sms  feature_1086_sms  feature_1087_sms  \\\n",
       "0               269               230                55              1019   \n",
       "1               100               158                77               638   \n",
       "2               400                73                49               551   \n",
       "3                45                43                13               301   \n",
       "4               168               144                84               807   \n",
       "\n",
       "   feature_1088_sms  feature_1089_sms  feature_1090_sms  feature_1091_sms  \\\n",
       "0                11                44               184                12   \n",
       "1                49               226               201                 0   \n",
       "2                 4                16               139                 0   \n",
       "3                 5                 3               112                 0   \n",
       "4                21                 6               425                 1   \n",
       "\n",
       "   feature_1092_sms  feature_1093_sms  feature_1094_sms  feature_1095_sms  \\\n",
       "0                 9               243                 0               715   \n",
       "1                15               303                 9               678   \n",
       "2                19               208                 5               518   \n",
       "3                 0               159                 0               369   \n",
       "4                13               186                 2               895   \n",
       "\n",
       "   feature_1096_sms  feature_1097_sms  feature_1098_sms  feature_1099_sms  \\\n",
       "0                61               369                32                13   \n",
       "1                14               132               292               208   \n",
       "2               163               171                 9                 5   \n",
       "3                14                85                41                34   \n",
       "4                17               208                87                15   \n",
       "\n",
       "   feature_1100_sms  feature_1101_sms  feature_1102_sms  feature_1103_sms  \\\n",
       "0         38.666667         38.666667          0.038667          1.666667   \n",
       "1         29.666667         29.666667          0.029667          1.000000   \n",
       "2         28.666667         28.666667          0.044537          2.333333   \n",
       "3         39.666667         39.666667          0.100677          2.333333   \n",
       "4          0.000000               NaN          0.000000          0.000000   \n",
       "\n",
       "   feature_1104_sms  feature_1105_sms  feature_1106_sms  feature_1107_sms  \\\n",
       "0          0.043103          1.666667          0.043103         10.333333   \n",
       "1          0.033708          2.000000          0.067416          2.666667   \n",
       "2          0.081395          2.000000          0.069767          9.333333   \n",
       "3          0.058824          0.666667          0.016807          7.333333   \n",
       "4               NaN          0.000000               NaN          0.000000   \n",
       "\n",
       "   feature_1108_sms  feature_1109_sms  feature_1110_sms  feature_1111_sms  \\\n",
       "0          0.267241          0.000000          0.000000          1.000000   \n",
       "1          0.089888          1.000000          0.033708          1.333333   \n",
       "2          0.325581          0.000000          0.000000          0.000000   \n",
       "3          0.184874          0.333333          0.008403          0.000000   \n",
       "4               NaN          0.000000               NaN          0.000000   \n",
       "\n",
       "   feature_1112_sms  feature_1113_sms  feature_1114_sms  feature_1115_sms  \\\n",
       "0          0.025862          5.666667          0.146552          0.333333   \n",
       "1          0.044944          1.666667          0.056180          0.000000   \n",
       "2          0.000000          2.333333          0.081395          0.000000   \n",
       "3          0.000000         10.000000          0.252101          0.000000   \n",
       "4               NaN          0.000000               NaN          0.000000   \n",
       "\n",
       "   feature_1116_sms  feature_1117_sms  feature_1118_sms  feature_1119_sms  \\\n",
       "0          0.008621          0.000000          0.000000          1.333333   \n",
       "1          0.000000          0.333333          0.011236          4.333333   \n",
       "2          0.000000          0.000000          0.000000          1.333333   \n",
       "3          0.000000          0.000000          0.000000          1.333333   \n",
       "4               NaN          0.000000               NaN          0.000000   \n",
       "\n",
       "   feature_1120_sms  feature_1121_sms  feature_1122_sms  feature_1123_sms  \\\n",
       "0          0.034483               0.0               0.0         12.000000   \n",
       "1          0.146067               0.0               0.0          6.666667   \n",
       "2          0.046512               0.0               0.0          6.666667   \n",
       "3          0.033613               0.0               0.0         12.666667   \n",
       "4               NaN               0.0               NaN          0.000000   \n",
       "\n",
       "   feature_1124_sms  feature_1125_sms  feature_1126_sms  feature_1127_sms  \\\n",
       "0          0.310345          0.000000          0.000000          4.333333   \n",
       "1          0.224719          0.333333          0.011236          2.000000   \n",
       "2          0.232558          0.333333          0.011628          3.333333   \n",
       "3          0.319328          0.333333          0.008403          2.666667   \n",
       "4               NaN          0.000000               NaN          0.000000   \n",
       "\n",
       "   feature_1128_sms  feature_1129_sms  feature_1130_sms  feature_1131_sms  \\\n",
       "0          0.112069          0.000000          0.000000          0.000000   \n",
       "1          0.067416          2.666667          0.089888          3.666667   \n",
       "2          0.116279          0.666667          0.023256          0.333333   \n",
       "3          0.067227          1.000000          0.025210          1.000000   \n",
       "4               NaN          0.000000               NaN          0.000000   \n",
       "\n",
       "   feature_1132_sms  feature_1133_sms  feature_1134_sms  feature_1135_sms  \\\n",
       "0          0.000000         40.000000         40.000000          0.093333   \n",
       "1          0.123596         23.571429         23.571429          0.055000   \n",
       "2          0.011628         23.857143         23.857143          0.086484   \n",
       "3          0.025210         36.428571         36.428571          0.215736   \n",
       "4               NaN          1.000000          7.000000          0.002404   \n",
       "\n",
       "   feature_1136_sms  feature_1137_sms  feature_1138_sms  feature_1139_sms  \\\n",
       "0          2.857143          0.071429          1.285714          0.032143   \n",
       "1          0.714286          0.030303          1.142857          0.048485   \n",
       "2          1.571429          0.065868          1.142857          0.047904   \n",
       "3          1.714286          0.047059          0.714286          0.019608   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1140_sms  feature_1141_sms  feature_1142_sms  feature_1143_sms  \\\n",
       "0         11.142857          0.278571          0.428571          0.010714   \n",
       "1          2.714286          0.115152          0.428571          0.018182   \n",
       "2          5.857143          0.245509          0.000000          0.000000   \n",
       "3          5.857143          0.160784          0.285714          0.007843   \n",
       "4          0.714286          0.714286          0.000000          0.000000   \n",
       "\n",
       "   feature_1144_sms  feature_1145_sms  feature_1146_sms  feature_1147_sms  \\\n",
       "0          1.000000          0.025000          4.285714          0.107143   \n",
       "1          1.000000          0.042424          0.714286          0.030303   \n",
       "2          0.428571          0.017964          2.571429          0.107784   \n",
       "3          0.000000          0.000000          8.714286          0.239216   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1148_sms  feature_1149_sms  feature_1150_sms  feature_1151_sms  \\\n",
       "0          0.571429          0.014286          0.142857          0.003571   \n",
       "1          0.000000          0.000000          0.142857          0.006061   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.000000          0.000000          0.000000          0.000000   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1152_sms  feature_1153_sms  feature_1154_sms  feature_1155_sms  \\\n",
       "0          2.142857          0.053571               0.0               0.0   \n",
       "1          2.285714          0.096970               0.0               0.0   \n",
       "2          1.000000          0.041916               0.0               0.0   \n",
       "3          2.000000          0.054902               0.0               0.0   \n",
       "4          0.000000          0.000000               0.0               0.0   \n",
       "\n",
       "   feature_1156_sms  feature_1157_sms  feature_1158_sms  feature_1159_sms  \\\n",
       "0         10.857143          0.271429          0.142857          0.003571   \n",
       "1          6.285714          0.266667          0.285714          0.012121   \n",
       "2          6.428571          0.269461          0.428571          0.017964   \n",
       "3         11.428571          0.313725          0.142857          0.003922   \n",
       "4          0.285714          0.285714          0.000000          0.000000   \n",
       "\n",
       "   feature_1160_sms  feature_1161_sms  feature_1162_sms  feature_1163_sms  \\\n",
       "0          4.714286          0.117857          0.000000          0.000000   \n",
       "1          2.571429          0.109091          2.428571          0.103030   \n",
       "2          3.571429          0.149701          0.428571          0.017964   \n",
       "3          2.571429          0.070588          0.857143          0.023529   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1164_sms  feature_1165_sms  feature_1166_sms  feature_1167_sms  \\\n",
       "0          0.285714          0.007143         36.500000         36.500000   \n",
       "1          2.857143          0.121212         20.714286         20.714286   \n",
       "2          0.428571          0.017964         24.285714         24.285714   \n",
       "3          2.142857          0.058824         40.642857         40.642857   \n",
       "4          0.000000          0.000000          0.928571          6.500000   \n",
       "\n",
       "   feature_1168_sms  feature_1169_sms  feature_1170_sms  feature_1171_sms  \\\n",
       "0          0.170333          3.357143          0.091977          1.000000   \n",
       "1          0.096667          1.357143          0.065517          0.714286   \n",
       "2          0.176075          1.428571          0.058824          1.214286   \n",
       "3          0.481387          1.214286          0.029877          0.428571   \n",
       "4          0.004464          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1172_sms  feature_1173_sms  feature_1174_sms  feature_1175_sms  \\\n",
       "0          0.027397         11.071429          0.303327          0.357143   \n",
       "1          0.034483          3.571429          0.172414          0.428571   \n",
       "2          0.050000          4.857143          0.200000          0.071429   \n",
       "3          0.010545          6.357143          0.156415          0.214286   \n",
       "4          0.000000          0.714286          0.769231          0.000000   \n",
       "\n",
       "   feature_1176_sms  feature_1177_sms  feature_1178_sms  feature_1179_sms  \\\n",
       "0          0.009785          0.785714          0.021526          4.142857   \n",
       "1          0.020690          1.071429          0.051724          0.500000   \n",
       "2          0.002941          0.428571          0.017647          3.000000   \n",
       "3          0.005272          0.071429          0.001757          7.000000   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1180_sms  feature_1181_sms  feature_1182_sms  feature_1183_sms  \\\n",
       "0          0.113503          0.642857          0.017613          0.071429   \n",
       "1          0.024138          0.000000          0.000000          0.142857   \n",
       "2          0.123529          0.000000          0.000000          0.285714   \n",
       "3          0.172232          0.000000          0.000000          0.000000   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1184_sms  feature_1185_sms  feature_1186_sms  feature_1187_sms  \\\n",
       "0          0.001957          2.642857          0.072407               0.0   \n",
       "1          0.006897          1.642857          0.079310               0.0   \n",
       "2          0.011765          1.714286          0.070588               0.0   \n",
       "3          0.000000          5.285714          0.130053               0.0   \n",
       "4          0.000000          0.000000          0.000000               0.0   \n",
       "\n",
       "   feature_1188_sms  feature_1189_sms  feature_1190_sms  feature_1191_sms  \\\n",
       "0               0.0          8.214286          0.225049          0.142857   \n",
       "1               0.0          4.071429          0.196552          0.142857   \n",
       "2               0.0          7.571429          0.311765          0.285714   \n",
       "3               0.0         13.571429          0.333919          0.285714   \n",
       "4               0.0          0.214286          0.230769          0.000000   \n",
       "\n",
       "   feature_1192_sms  feature_1193_sms  feature_1194_sms  feature_1195_sms  \\\n",
       "0          0.003914          3.642857          0.099804          0.071429   \n",
       "1          0.006897          2.071429          0.100000          2.642857   \n",
       "2          0.011765          2.928571          0.120588          0.285714   \n",
       "3          0.007030          3.785714          0.093146          0.928571   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1196_sms  feature_1197_sms  feature_1198_sms  feature_1199_sms  \\\n",
       "0          0.001957          0.214286          0.005871         34.761905   \n",
       "1          0.127586          2.357143          0.113793         21.571429   \n",
       "2          0.011765          0.214286          0.008824         23.238095   \n",
       "3          0.022847          1.428571          0.035149         34.619048   \n",
       "4          0.000000          0.000000          0.000000          1.619048   \n",
       "\n",
       "   feature_1200_sms  feature_1201_sms  feature_1202_sms  feature_1203_sms  \\\n",
       "0         34.761905          0.243333          3.238095          0.093151   \n",
       "1         21.571429          0.151000          1.142857          0.052980   \n",
       "2         23.238095          0.252719          1.619048          0.069672   \n",
       "3         34.619048          0.615059          1.095238          0.031637   \n",
       "4          5.666667          0.011676          0.000000          0.000000   \n",
       "\n",
       "   feature_1204_sms  feature_1205_sms  feature_1206_sms  feature_1207_sms  \\\n",
       "0          1.095238          0.031507         10.238095          0.294521   \n",
       "1          0.904762          0.041943          3.571429          0.165563   \n",
       "2          1.142857          0.049180          4.333333          0.186475   \n",
       "3          0.285714          0.008253          6.761905          0.195323   \n",
       "4          0.000000          0.000000          0.523810          0.323529   \n",
       "\n",
       "   feature_1208_sms  feature_1209_sms  feature_1210_sms  feature_1211_sms  \\\n",
       "0          0.333333          0.009589          0.904762          0.026027   \n",
       "1          0.428571          0.019868          1.857143          0.086093   \n",
       "2          0.095238          0.004098          0.333333          0.014344   \n",
       "3          0.142857          0.004127          0.047619          0.001376   \n",
       "4          0.047619          0.029412          0.000000          0.000000   \n",
       "\n",
       "   feature_1212_sms  feature_1213_sms  feature_1214_sms  feature_1215_sms  \\\n",
       "0          3.619048          0.104110          0.428571          0.012329   \n",
       "1          0.476190          0.022075          0.000000          0.000000   \n",
       "2          2.857143          0.122951          0.000000          0.000000   \n",
       "3          4.809524          0.138927          0.000000          0.000000   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1216_sms  feature_1217_sms  feature_1218_sms  feature_1219_sms  \\\n",
       "0          0.047619          0.001370          2.619048          0.075342   \n",
       "1          0.095238          0.004415          2.238095          0.103753   \n",
       "2          0.190476          0.008197          2.428571          0.104508   \n",
       "3          0.000000          0.000000          5.095238          0.147180   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1220_sms  feature_1221_sms  feature_1222_sms  feature_1223_sms  \\\n",
       "0               0.0               0.0          7.380952          0.212329   \n",
       "1               0.0               0.0          3.904762          0.181015   \n",
       "2               0.0               0.0          6.809524          0.293033   \n",
       "3               0.0               0.0         11.238095          0.324622   \n",
       "4               0.0               0.0          0.190476          0.117647   \n",
       "\n",
       "   feature_1224_sms  feature_1225_sms  feature_1226_sms  feature_1227_sms  \\\n",
       "0          0.095238          0.002740          4.476190          0.128767   \n",
       "1          0.095238          0.004415          2.047619          0.094923   \n",
       "2          0.285714          0.012295          2.809524          0.120902   \n",
       "3          0.238095          0.006878          2.809524          0.081155   \n",
       "4          0.000000          0.000000          0.095238          0.058824   \n",
       "\n",
       "   feature_1228_sms  feature_1229_sms  feature_1230_sms  feature_1231_sms  \\\n",
       "0          0.047619          0.001370          0.142857          0.004110   \n",
       "1          2.571429          0.119205          2.238095          0.103753   \n",
       "2          0.190476          0.008197          0.142857          0.006148   \n",
       "3          0.904762          0.026135          1.142857          0.033012   \n",
       "4          0.619048          0.382353          0.142857          0.088235   \n",
       "\n",
       "   feature_1232_sms  feature_1233_sms  feature_1234_sms  feature_1235_sms  \\\n",
       "0         35.866667         35.866667          0.358667          3.900000   \n",
       "1         21.766667         21.766667          0.217667          1.200000   \n",
       "2         21.366667         21.366667          0.331952          1.366667   \n",
       "3         30.200000         30.200000          0.766497          0.966667   \n",
       "4          4.700000         10.846154          0.048420          0.033333   \n",
       "\n",
       "   feature_1236_sms  feature_1237_sms  feature_1238_sms  feature_1239_sms  \\\n",
       "0          0.108736          1.033333          0.028810          9.966667   \n",
       "1          0.055130          0.900000          0.041348          4.100000   \n",
       "2          0.063963          0.966667          0.045242          3.700000   \n",
       "3          0.032009          0.300000          0.009934          6.700000   \n",
       "4          0.007092          0.300000          0.063830          1.366667   \n",
       "\n",
       "   feature_1240_sms  feature_1241_sms  feature_1242_sms  feature_1243_sms  \\\n",
       "0          0.277881          0.266667          0.007435          0.900000   \n",
       "1          0.188361          0.466667          0.021440          2.066667   \n",
       "2          0.173167          0.066667          0.003120          0.333333   \n",
       "3          0.221854          0.133333          0.004415          0.066667   \n",
       "4          0.290780          0.066667          0.014184          0.000000   \n",
       "\n",
       "   feature_1244_sms  feature_1245_sms  feature_1246_sms  feature_1247_sms  \\\n",
       "0          0.025093          3.600000          0.100372               0.3   \n",
       "1          0.094946          0.566667          0.026034               0.0   \n",
       "2          0.015601          2.566667          0.120125               0.0   \n",
       "3          0.002208          3.566667          0.118102               0.0   \n",
       "4          0.000000          0.700000          0.148936               0.0   \n",
       "\n",
       "   feature_1248_sms  feature_1249_sms  feature_1250_sms  feature_1251_sms  \\\n",
       "0          0.008364          0.066667          0.001859          2.300000   \n",
       "1          0.000000          0.066667          0.003063          2.300000   \n",
       "2          0.000000          0.166667          0.007800          2.966667   \n",
       "3          0.000000          0.000000          0.000000          4.333333   \n",
       "4          0.000000          0.000000          0.000000          0.466667   \n",
       "\n",
       "   feature_1252_sms  feature_1253_sms  feature_1254_sms  feature_1255_sms  \\\n",
       "0          0.064126          0.000000           0.00000          8.133333   \n",
       "1          0.105666          0.000000           0.00000          3.900000   \n",
       "2          0.138846          0.033333           0.00156          6.166667   \n",
       "3          0.143488          0.000000           0.00000          9.666667   \n",
       "4          0.099291          0.000000           0.00000          0.933333   \n",
       "\n",
       "   feature_1256_sms  feature_1257_sms  feature_1258_sms  feature_1259_sms  \\\n",
       "0          0.226766          0.066667          0.001859          5.000000   \n",
       "1          0.179173          0.066667          0.003063          1.933333   \n",
       "2          0.288612          0.200000          0.009360          2.566667   \n",
       "3          0.320088          0.200000          0.006623          2.333333   \n",
       "4          0.198582          0.033333          0.007092          0.200000   \n",
       "\n",
       "   feature_1260_sms  feature_1261_sms  feature_1262_sms  feature_1263_sms  \\\n",
       "0          0.139405          0.100000          0.002788          0.133333   \n",
       "1          0.088821          2.333333          0.107198          1.866667   \n",
       "2          0.120125          0.166667          0.007800          0.100000   \n",
       "3          0.077263          0.900000          0.029801          0.933333   \n",
       "4          0.042553          0.466667          0.099291          0.133333   \n",
       "\n",
       "   feature_1264_sms  feature_1265_sms  feature_1266_sms  feature_1267_sms  \\\n",
       "0          0.003717         25.166667         27.962963          0.503333   \n",
       "1          0.085758         23.250000         23.250000          0.465000   \n",
       "2          0.004680         14.766667         15.275862          0.458830   \n",
       "3          0.030905         19.700000         26.266667          1.000000   \n",
       "4          0.028369         10.466667         14.604651          0.215659   \n",
       "\n",
       "   feature_1268_sms  feature_1269_sms  feature_1270_sms  feature_1271_sms  \\\n",
       "0          3.083333          0.122517          0.700000          0.027815   \n",
       "1          1.500000          0.064516          0.833333          0.035842   \n",
       "2          0.883333          0.059819          0.650000          0.044018   \n",
       "3          0.716667          0.036379          0.216667          0.010998   \n",
       "4          0.050000          0.004777          0.183333          0.017516   \n",
       "\n",
       "   feature_1272_sms  feature_1273_sms  feature_1274_sms  feature_1275_sms  \\\n",
       "0          7.150000          0.284106          0.166667          0.006623   \n",
       "1          3.866667          0.166308          0.550000          0.023656   \n",
       "2          3.600000          0.243792          0.033333          0.002257   \n",
       "3          5.016667          0.254653          0.083333          0.004230   \n",
       "4          3.333333          0.318471          0.100000          0.009554   \n",
       "\n",
       "   feature_1276_sms  feature_1277_sms  feature_1278_sms  feature_1279_sms  \\\n",
       "0          0.500000          0.019868          2.566667          0.101987   \n",
       "1          2.516667          0.108244          0.616667          0.026523   \n",
       "2          0.166667          0.011287          1.500000          0.101580   \n",
       "3          0.050000          0.002538          1.866667          0.094755   \n",
       "4          0.000000          0.000000          1.466667          0.140127   \n",
       "\n",
       "   feature_1280_sms  feature_1281_sms  feature_1282_sms  feature_1283_sms  \\\n",
       "0          0.166667          0.006623          0.050000          0.001987   \n",
       "1          0.000000          0.000000          0.050000          0.002151   \n",
       "2          0.000000          0.000000          0.166667          0.011287   \n",
       "3          0.000000          0.000000          0.000000          0.000000   \n",
       "4          0.000000          0.000000          0.016667          0.001592   \n",
       "\n",
       "   feature_1284_sms  feature_1285_sms  feature_1286_sms  feature_1287_sms  \\\n",
       "0          1.666667          0.066225          0.000000          0.000000   \n",
       "1          2.516667          0.108244          0.000000          0.000000   \n",
       "2          1.900000          0.128668          0.033333          0.002257   \n",
       "3          2.650000          0.134518          0.000000          0.000000   \n",
       "4          1.083333          0.103503          0.000000          0.000000   \n",
       "\n",
       "   feature_1288_sms  feature_1289_sms  feature_1290_sms  feature_1291_sms  \\\n",
       "0          5.433333          0.215894          0.066667          0.002649   \n",
       "1          4.550000          0.195699          0.116667          0.005018   \n",
       "2          3.750000          0.253950          0.150000          0.010158   \n",
       "3          6.150000          0.312183          0.233333          0.011844   \n",
       "4          3.016667          0.288217          0.083333          0.007962   \n",
       "\n",
       "   feature_1292_sms  feature_1293_sms  feature_1294_sms  feature_1295_sms  \\\n",
       "0          3.400000          0.135099          0.066667          0.002649   \n",
       "1          1.616667          0.069534          2.416667          0.103943   \n",
       "2          1.700000          0.115124          0.150000          0.010158   \n",
       "3          1.416667          0.071912          0.683333          0.034687   \n",
       "4          0.666667          0.063694          0.400000          0.038217   \n",
       "\n",
       "   feature_1296_sms  feature_1297_sms  feature_1298_sms  feature_1299_sms  \\\n",
       "0          0.100000          0.003974             3.000         11.152416   \n",
       "1          2.100000          0.090323             3.000         30.000000   \n",
       "2          0.083333          0.005643             1.931          4.827500   \n",
       "3          0.566667          0.028765             1.182         26.266667   \n",
       "4          0.066667          0.006369             2.912         17.333333   \n",
       "\n",
       "   feature_1300_sms  feature_1301_sms  feature_1302_sms  feature_1303_sms  \\\n",
       "0               1.0             0.230          0.076667             0.055   \n",
       "1               1.0             0.158          0.052667             0.077   \n",
       "2               1.0             0.073          0.037804             0.049   \n",
       "3               1.0             0.043          0.036379             0.013   \n",
       "4               1.0             0.144          0.049451             0.084   \n",
       "\n",
       "   feature_1304_sms  feature_1305_sms  feature_1306_sms  feature_1307_sms  \\\n",
       "0          0.018333             1.019          0.339667             0.011   \n",
       "1          0.025667             0.638          0.212667             0.049   \n",
       "2          0.025375             0.551          0.285344             0.004   \n",
       "3          0.010998             0.301          0.254653             0.005   \n",
       "4          0.028846             0.807          0.277129             0.021   \n",
       "\n",
       "   feature_1308_sms  feature_1309_sms  feature_1310_sms  feature_1311_sms  \\\n",
       "0          0.003667             0.044          0.014667             0.184   \n",
       "1          0.016333             0.226          0.075333             0.201   \n",
       "2          0.002071             0.016          0.008286             0.139   \n",
       "3          0.004230             0.003          0.002538             0.112   \n",
       "4          0.007212             0.006          0.002060             0.425   \n",
       "\n",
       "   feature_1312_sms  feature_1313_sms  feature_1314_sms  feature_1315_sms  \\\n",
       "0          0.061333             0.012          0.004000             0.009   \n",
       "1          0.067000             0.000          0.000000             0.015   \n",
       "2          0.071983             0.000          0.000000             0.019   \n",
       "3          0.094755             0.000          0.000000             0.000   \n",
       "4          0.145948             0.001          0.000343             0.013   \n",
       "\n",
       "   feature_1316_sms  feature_1317_sms  feature_1318_sms  feature_1319_sms  \\\n",
       "0          0.003000             0.243          0.081000             0.000   \n",
       "1          0.005000             0.303          0.101000             0.009   \n",
       "2          0.009839             0.208          0.107716             0.005   \n",
       "3          0.000000             0.159          0.134518             0.000   \n",
       "4          0.004464             0.186          0.063874             0.002   \n",
       "\n",
       "   feature_1320_sms  feature_1321_sms  feature_1322_sms  feature_1323_sms  \\\n",
       "0          0.000000             0.715          0.238333             0.061   \n",
       "1          0.003000             0.678          0.226000             0.014   \n",
       "2          0.002589             0.518          0.268255             0.163   \n",
       "3          0.000000             0.369          0.312183             0.014   \n",
       "4          0.000687             0.895          0.307349             0.017   \n",
       "\n",
       "   feature_1324_sms  feature_1325_sms  feature_1326_sms  feature_1327_sms  \\\n",
       "0          0.020333             0.369          0.123000             0.032   \n",
       "1          0.004667             0.132          0.044000             0.292   \n",
       "2          0.084412             0.171          0.088555             0.009   \n",
       "3          0.011844             0.085          0.071912             0.041   \n",
       "4          0.005838             0.208          0.071429             0.087   \n",
       "\n",
       "   feature_1328_sms  feature_1329_sms  feature_1330_sms  order_id         pan  \\\n",
       "0          0.010667             0.013          0.004333  XQDI8W8E  AAHPO6801A   \n",
       "1          0.097333             0.208          0.069333  NKNSPUYG  AAIPI5141G   \n",
       "2          0.004661             0.005          0.002589  3WXC1GIM  AAIPZ7980L   \n",
       "3          0.034687             0.034          0.028765  OYD0NERZ  AALPF3903A   \n",
       "4          0.029876             0.015          0.005151  U67MOCC1  AALPF4279M   \n",
       "\n",
       "   label_y  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 1717 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e831527f",
   "metadata": {},
   "source": [
    "##### 验证神经网络模型，取开头代码的逻辑 加工出trainx ootx，如下训练神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989d8bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9123, 9071)\n",
      "1.0    5631\n",
      "0.0    2040\n",
      "Name: label, dtype: int64\n",
      "1.0    1035\n",
      "0.0     417\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BureauScore</th>\n",
       "      <th>MissingRate</th>\n",
       "      <th>Len_Name</th>\n",
       "      <th>Tel_nuniq</th>\n",
       "      <th>Email_nuniq</th>\n",
       "      <th>Len_of_addrs</th>\n",
       "      <th>City_nuniq</th>\n",
       "      <th>Current_State</th>\n",
       "      <th>CreditAccountActive</th>\n",
       "      <th>CreditAccountTotal</th>\n",
       "      <th>CreditAccountActivePor</th>\n",
       "      <th>Outstanding_Balance_Secured</th>\n",
       "      <th>Outstanding_Balance_UnSecured_Percentage</th>\n",
       "      <th>Outstanding_Balance_All</th>\n",
       "      <th>Outstanding_Balance_Secured_Percentage</th>\n",
       "      <th>Outstanding_Balance_UnSecured</th>\n",
       "      <th>Diff_dateBirth</th>\n",
       "      <th>State_nuniq</th>\n",
       "      <th>Birth_nuniq</th>\n",
       "      <th>TotalCAPSLast90Days</th>\n",
       "      <th>TotalCAPSLast7Days</th>\n",
       "      <th>TotalCAPSLast30Days</th>\n",
       "      <th>TotalCAPSLast180Days</th>\n",
       "      <th>CAPSLast30Days</th>\n",
       "      <th>CAPSLast7Days</th>\n",
       "      <th>CAPSLast180Days</th>\n",
       "      <th>NonCreditCAPSLast180Days</th>\n",
       "      <th>Pin_nuniq</th>\n",
       "      <th>Pan_nuniq</th>\n",
       "      <th>Ident_nuniq</th>\n",
       "      <th>Name_nuniq2</th>\n",
       "      <th>Tel_nuniq2</th>\n",
       "      <th>Email_nuniq2</th>\n",
       "      <th>Pan_nuniq2</th>\n",
       "      <th>Account_nuniq2</th>\n",
       "      <th>Ident_nuniq2</th>\n",
       "      <th>Gender_nuniq</th>\n",
       "      <th>Amount_Past_Due35_sum_30</th>\n",
       "      <th>Amount_Past_Due35_min_30</th>\n",
       "      <th>Amount_Past_Due35_sum_90</th>\n",
       "      <th>Amount_Past_Due35_mean_90</th>\n",
       "      <th>Amount_Past_Due35_max_90</th>\n",
       "      <th>Amount_Past_Due35_min_90</th>\n",
       "      <th>Amount_Past_Due35_std_90</th>\n",
       "      <th>Amount_Past_Due35_sum_360</th>\n",
       "      <th>Amount_Past_Due35_mean_360</th>\n",
       "      <th>Amount_Past_Due35_max_360</th>\n",
       "      <th>Amount_Past_Due35_std_360</th>\n",
       "      <th>Amount_Past_Due35_sum_9999</th>\n",
       "      <th>Amount_Past_Due35_max_9999</th>\n",
       "      <th>Amount_Past_Due35_min_9999</th>\n",
       "      <th>Amount_Past_Due35_std_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_9999</th>\n",
       "      <th>Terms_Duration34_sum_30</th>\n",
       "      <th>Terms_Duration34_std_30</th>\n",
       "      <th>Terms_Duration34_sum_90</th>\n",
       "      <th>Terms_Duration34_std_90</th>\n",
       "      <th>Terms_Duration34_mean_360</th>\n",
       "      <th>Terms_Duration34_max_360</th>\n",
       "      <th>Terms_Duration34_min_360</th>\n",
       "      <th>Terms_Duration34_std_360</th>\n",
       "      <th>Terms_Duration34_sum_9999</th>\n",
       "      <th>Terms_Duration34_mean_9999</th>\n",
       "      <th>Terms_Duration34_max_9999</th>\n",
       "      <th>Terms_Duration34_min_9999</th>\n",
       "      <th>Terms_Duration34_std_9999</th>\n",
       "      <th>Payment_Rating34_sum_90</th>\n",
       "      <th>Payment_Rating34_mean_90</th>\n",
       "      <th>Payment_Rating34_max_90</th>\n",
       "      <th>Payment_Rating34_min_90</th>\n",
       "      <th>Payment_Rating34_std_90</th>\n",
       "      <th>Payment_Rating34_sum_360</th>\n",
       "      <th>Payment_Rating34_mean_360</th>\n",
       "      <th>Payment_Rating34_max_360</th>\n",
       "      <th>Payment_Rating34_min_360</th>\n",
       "      <th>Payment_Rating34_std_360</th>\n",
       "      <th>Payment_Rating34_sum_9999</th>\n",
       "      <th>Payment_Rating34_mean_9999</th>\n",
       "      <th>Payment_Rating34_max_9999</th>\n",
       "      <th>Payment_Rating34_min_9999</th>\n",
       "      <th>Payment_Rating34_std_9999</th>\n",
       "      <th>Current_Balance35_mean_30</th>\n",
       "      <th>Current_Balance35_min_30</th>\n",
       "      <th>Current_Balance35_std_30</th>\n",
       "      <th>Current_Balance35_sum_90</th>\n",
       "      <th>Current_Balance35_mean_90</th>\n",
       "      <th>Current_Balance35_max_90</th>\n",
       "      <th>Current_Balance35_std_90</th>\n",
       "      <th>Current_Balance35_sum_360</th>\n",
       "      <th>Current_Balance35_max_360</th>\n",
       "      <th>Current_Balance35_std_360</th>\n",
       "      <th>Current_Balance35_max_9999</th>\n",
       "      <th>Current_Balance35_std_9999</th>\n",
       "      <th>Settlement_Amount37_max_360</th>\n",
       "      <th>Settlement_Amount37_min_360</th>\n",
       "      <th>Settlement_Amount37_std_360</th>\n",
       "      <th>Settlement_Amount37_sum_9999</th>\n",
       "      <th>Settlement_Amount37_mean_9999</th>\n",
       "      <th>Settlement_Amount37_max_9999</th>\n",
       "      <th>Settlement_Amount37_min_9999</th>\n",
       "      <th>Settlement_Amount37_std_9999</th>\n",
       "      <th>Value_of_Collateral39_std_90</th>\n",
       "      <th>Value_of_Collateral39_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_360</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_360</th>\n",
       "      <th>Written_Off_Amt_Total41_min_360</th>\n",
       "      <th>Written_Off_Amt_Total41_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_max_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_min_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_std_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_mean_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_std_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_max_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_9999</th>\n",
       "      <th>Rate_of_Interest36_sum_30</th>\n",
       "      <th>Rate_of_Interest36_std_30</th>\n",
       "      <th>Rate_of_Interest36_sum_90</th>\n",
       "      <th>Rate_of_Interest36_mean_90</th>\n",
       "      <th>Rate_of_Interest36_max_90</th>\n",
       "      <th>Rate_of_Interest36_std_90</th>\n",
       "      <th>Rate_of_Interest36_sum_360</th>\n",
       "      <th>Rate_of_Interest36_mean_360</th>\n",
       "      <th>Rate_of_Interest36_max_360</th>\n",
       "      <th>Rate_of_Interest36_min_360</th>\n",
       "      <th>Rate_of_Interest36_std_360</th>\n",
       "      <th>Rate_of_Interest36_sum_9999</th>\n",
       "      <th>Rate_of_Interest36_mean_9999</th>\n",
       "      <th>Rate_of_Interest36_max_9999</th>\n",
       "      <th>Rate_of_Interest36_min_9999</th>\n",
       "      <th>Rate_of_Interest36_std_9999</th>\n",
       "      <th>Repayment_Tenure36_std_30</th>\n",
       "      <th>Repayment_Tenure36_mean_90</th>\n",
       "      <th>Repayment_Tenure36_max_90</th>\n",
       "      <th>Repayment_Tenure36_min_90</th>\n",
       "      <th>Repayment_Tenure36_std_90</th>\n",
       "      <th>Repayment_Tenure36_sum_360</th>\n",
       "      <th>Repayment_Tenure36_mean_360</th>\n",
       "      <th>Repayment_Tenure36_min_360</th>\n",
       "      <th>Repayment_Tenure36_std_360</th>\n",
       "      <th>Repayment_Tenure36_mean_9999</th>\n",
       "      <th>Repayment_Tenure36_min_9999</th>\n",
       "      <th>Repayment_Tenure36_std_9999</th>\n",
       "      <th>Income26_count_360</th>\n",
       "      <th>Income26_std_360</th>\n",
       "      <th>Open_Date29_max_30</th>\n",
       "      <th>Open_Date29_min_30</th>\n",
       "      <th>Open_Date29_mean_30</th>\n",
       "      <th>Open_Date29_nuniq_30</th>\n",
       "      <th>Open_Date29_maxcount_30</th>\n",
       "      <th>Open_Date29_max_90</th>\n",
       "      <th>Open_Date29_mean_90</th>\n",
       "      <th>Open_Date29_mode_90</th>\n",
       "      <th>Open_Date29_nuniq_90</th>\n",
       "      <th>Open_Date29_maxcount_90</th>\n",
       "      <th>Open_Date29_max_360</th>\n",
       "      <th>Open_Date29_mean_360</th>\n",
       "      <th>Open_Date29_mode_360</th>\n",
       "      <th>Open_Date29_nuniq_360</th>\n",
       "      <th>Open_Date29_maxcount_360</th>\n",
       "      <th>Open_Date29_max_9999</th>\n",
       "      <th>Open_Date29_mean_9999</th>\n",
       "      <th>Open_Date29_mode_9999</th>\n",
       "      <th>Open_Date29_maxcount_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_30</th>\n",
       "      <th>Portfolio_Type34_nuniq_90</th>\n",
       "      <th>Portfolio_Type34_nuniq_360</th>\n",
       "      <th>Portfolio_Type34_nuniq_9999</th>\n",
       "      <th>Account_Type32_nuniq_30</th>\n",
       "      <th>Account_Type32_nuniq_90</th>\n",
       "      <th>Account_Type32_nuniq_360</th>\n",
       "      <th>Account_Type32_nuniq_9999</th>\n",
       "      <th>Occupation_Code35_nuniq_30</th>\n",
       "      <th>Occupation_Code35_nuniq_90</th>\n",
       "      <th>Occupation_Code35_nuniq_360</th>\n",
       "      <th>Occupation_Code35_nuniq_9999</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_360</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_9999</th>\n",
       "      <th>Payment_History_Profile43_mode_30</th>\n",
       "      <th>Payment_History_Profile43_mode_90</th>\n",
       "      <th>Payment_History_Profile43_nuniq_90</th>\n",
       "      <th>Payment_History_Profile43_mode_360</th>\n",
       "      <th>Payment_History_Profile43_nuniq_360</th>\n",
       "      <th>Payment_History_Profile43_mode_9999</th>\n",
       "      <th>Payment_History_Profile43_nuniq_9999</th>\n",
       "      <th>Date_Closed31_nuniq_30</th>\n",
       "      <th>Date_Closed31_maxcount_30</th>\n",
       "      <th>Date_Closed31_max_90</th>\n",
       "      <th>Date_Closed31_min_90</th>\n",
       "      <th>Date_Closed31_mean_90</th>\n",
       "      <th>Date_Closed31_mode_90</th>\n",
       "      <th>Date_Closed31_nuniq_90</th>\n",
       "      <th>Date_Closed31_maxcount_90</th>\n",
       "      <th>Date_Closed31_min_360</th>\n",
       "      <th>Date_Closed31_mode_360</th>\n",
       "      <th>Date_Closed31_nuniq_360</th>\n",
       "      <th>Date_Closed31_maxcount_360</th>\n",
       "      <th>Date_Closed31_max_9999</th>\n",
       "      <th>Date_Closed31_min_9999</th>\n",
       "      <th>Date_Closed31_mean_9999</th>\n",
       "      <th>Date_Closed31_mode_9999</th>\n",
       "      <th>Date_Closed31_nuniq_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_30</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_30</th>\n",
       "      <th>Date_of_Last_Payment40_min_90</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_90</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_90</th>\n",
       "      <th>Date_of_Last_Payment40_max_360</th>\n",
       "      <th>Date_of_Last_Payment40_min_360</th>\n",
       "      <th>Date_of_Last_Payment40_mean_360</th>\n",
       "      <th>Date_of_Last_Payment40_mode_360</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_360</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_360</th>\n",
       "      <th>Date_of_Last_Payment40_max_9999</th>\n",
       "      <th>Date_of_Last_Payment40_min_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mean_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_9999</th>\n",
       "      <th>Date_Reported33_nuniq_30</th>\n",
       "      <th>Date_Reported33_max_90</th>\n",
       "      <th>Date_Reported33_mean_90</th>\n",
       "      <th>Date_Reported33_mode_90</th>\n",
       "      <th>Date_Reported33_nuniq_90</th>\n",
       "      <th>Date_Reported33_maxcount_90</th>\n",
       "      <th>Date_Reported33_max_360</th>\n",
       "      <th>Date_Reported33_mean_360</th>\n",
       "      <th>Date_Reported33_mode_360</th>\n",
       "      <th>Date_Reported33_nuniq_360</th>\n",
       "      <th>Date_Reported33_maxcount_360</th>\n",
       "      <th>Date_Reported33_max_9999</th>\n",
       "      <th>Date_Reported33_mean_9999</th>\n",
       "      <th>Date_Reported33_mode_9999</th>\n",
       "      <th>Date_Reported33_nuniq_9999</th>\n",
       "      <th>Date_Reported33_maxcount_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_30</th>\n",
       "      <th>DateOfAddition34_max_90</th>\n",
       "      <th>DateOfAddition34_mean_90</th>\n",
       "      <th>DateOfAddition34_mode_90</th>\n",
       "      <th>DateOfAddition34_nuniq_90</th>\n",
       "      <th>DateOfAddition34_maxcount_90</th>\n",
       "      <th>DateOfAddition34_max_360</th>\n",
       "      <th>DateOfAddition34_mean_360</th>\n",
       "      <th>DateOfAddition34_mode_360</th>\n",
       "      <th>DateOfAddition34_nuniq_360</th>\n",
       "      <th>DateOfAddition34_maxcount_360</th>\n",
       "      <th>DateOfAddition34_max_9999</th>\n",
       "      <th>DateOfAddition34_mean_9999</th>\n",
       "      <th>DateOfAddition34_mode_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_9999</th>\n",
       "      <th>DateOfAddition34_maxcount_9999</th>\n",
       "      <th>Account_Status34_mode_30</th>\n",
       "      <th>Account_Status34_nuniq_30</th>\n",
       "      <th>Account_Status34_mode_90</th>\n",
       "      <th>Account_Status34_nuniq_90</th>\n",
       "      <th>Account_Status34_mode_360</th>\n",
       "      <th>Account_Status34_nuniq_360</th>\n",
       "      <th>Account_Status34_nuniq_9999</th>\n",
       "      <th>Month50_sum_30</th>\n",
       "      <th>Month50_max_30</th>\n",
       "      <th>Month50_std_30</th>\n",
       "      <th>Month50_sum_90</th>\n",
       "      <th>Month50_mean_90</th>\n",
       "      <th>Month50_max_90</th>\n",
       "      <th>Month50_min_90</th>\n",
       "      <th>Month50_std_90</th>\n",
       "      <th>Month50_sum_360</th>\n",
       "      <th>Month50_min_360</th>\n",
       "      <th>Month50_std_360</th>\n",
       "      <th>Month50_sum_9999</th>\n",
       "      <th>Month50_mean_9999</th>\n",
       "      <th>Month50_max_9999</th>\n",
       "      <th>Month50_min_9999</th>\n",
       "      <th>Month50_std_9999</th>\n",
       "      <th>Days_Past_Due58_max_30</th>\n",
       "      <th>Days_Past_Due58_min_30</th>\n",
       "      <th>Days_Past_Due58_mean_90</th>\n",
       "      <th>Days_Past_Due58_max_90</th>\n",
       "      <th>Days_Past_Due58_min_90</th>\n",
       "      <th>Days_Past_Due58_std_90</th>\n",
       "      <th>Days_Past_Due58_sum_360</th>\n",
       "      <th>Days_Past_Due58_mean_360</th>\n",
       "      <th>Days_Past_Due58_max_360</th>\n",
       "      <th>...</th>\n",
       "      <th>948707_lgb</th>\n",
       "      <th>949440_lgb</th>\n",
       "      <th>949441_lgb</th>\n",
       "      <th>949442_lgb</th>\n",
       "      <th>949443_lgb</th>\n",
       "      <th>949444_lgb</th>\n",
       "      <th>950176_lgb</th>\n",
       "      <th>950177_lgb</th>\n",
       "      <th>950178_lgb</th>\n",
       "      <th>950179_lgb</th>\n",
       "      <th>950180_lgb</th>\n",
       "      <th>950181_lgb</th>\n",
       "      <th>950182_lgb</th>\n",
       "      <th>950912_lgb</th>\n",
       "      <th>950913_lgb</th>\n",
       "      <th>950914_lgb</th>\n",
       "      <th>950915_lgb</th>\n",
       "      <th>950916_lgb</th>\n",
       "      <th>951648_lgb</th>\n",
       "      <th>951649_lgb</th>\n",
       "      <th>951650_lgb</th>\n",
       "      <th>951651_lgb</th>\n",
       "      <th>951652_lgb</th>\n",
       "      <th>952384_lgb</th>\n",
       "      <th>952385_lgb</th>\n",
       "      <th>952386_lgb</th>\n",
       "      <th>952387_lgb</th>\n",
       "      <th>953120_lgb</th>\n",
       "      <th>953121_lgb</th>\n",
       "      <th>953122_lgb</th>\n",
       "      <th>953123_lgb</th>\n",
       "      <th>953856_lgb</th>\n",
       "      <th>953857_lgb</th>\n",
       "      <th>953858_lgb</th>\n",
       "      <th>953859_lgb</th>\n",
       "      <th>954592_lgb</th>\n",
       "      <th>954593_lgb</th>\n",
       "      <th>954594_lgb</th>\n",
       "      <th>955328_lgb</th>\n",
       "      <th>955329_lgb</th>\n",
       "      <th>955330_lgb</th>\n",
       "      <th>955331_lgb</th>\n",
       "      <th>955332_lgb</th>\n",
       "      <th>956064_lgb</th>\n",
       "      <th>956065_lgb</th>\n",
       "      <th>956066_lgb</th>\n",
       "      <th>956067_lgb</th>\n",
       "      <th>956068_lgb</th>\n",
       "      <th>956069_lgb</th>\n",
       "      <th>956800_lgb</th>\n",
       "      <th>956801_lgb</th>\n",
       "      <th>957536_lgb</th>\n",
       "      <th>957537_lgb</th>\n",
       "      <th>957538_lgb</th>\n",
       "      <th>957539_lgb</th>\n",
       "      <th>958272_lgb</th>\n",
       "      <th>958273_lgb</th>\n",
       "      <th>958274_lgb</th>\n",
       "      <th>958275_lgb</th>\n",
       "      <th>959008_lgb</th>\n",
       "      <th>959009_lgb</th>\n",
       "      <th>959010_lgb</th>\n",
       "      <th>959744_lgb</th>\n",
       "      <th>959745_lgb</th>\n",
       "      <th>959746_lgb</th>\n",
       "      <th>959747_lgb</th>\n",
       "      <th>959748_lgb</th>\n",
       "      <th>959749_lgb</th>\n",
       "      <th>959750_lgb</th>\n",
       "      <th>960480_lgb</th>\n",
       "      <th>960481_lgb</th>\n",
       "      <th>960482_lgb</th>\n",
       "      <th>960483_lgb</th>\n",
       "      <th>960484_lgb</th>\n",
       "      <th>960485_lgb</th>\n",
       "      <th>961216_lgb</th>\n",
       "      <th>961217_lgb</th>\n",
       "      <th>961218_lgb</th>\n",
       "      <th>961219_lgb</th>\n",
       "      <th>961220_lgb</th>\n",
       "      <th>961952_lgb</th>\n",
       "      <th>961953_lgb</th>\n",
       "      <th>961954_lgb</th>\n",
       "      <th>961955_lgb</th>\n",
       "      <th>961956_lgb</th>\n",
       "      <th>961957_lgb</th>\n",
       "      <th>962688_lgb</th>\n",
       "      <th>962689_lgb</th>\n",
       "      <th>962690_lgb</th>\n",
       "      <th>963424_lgb</th>\n",
       "      <th>963425_lgb</th>\n",
       "      <th>963426_lgb</th>\n",
       "      <th>963427_lgb</th>\n",
       "      <th>964160_lgb</th>\n",
       "      <th>964161_lgb</th>\n",
       "      <th>964162_lgb</th>\n",
       "      <th>964163_lgb</th>\n",
       "      <th>964896_lgb</th>\n",
       "      <th>964897_lgb</th>\n",
       "      <th>964898_lgb</th>\n",
       "      <th>965632_lgb</th>\n",
       "      <th>965633_lgb</th>\n",
       "      <th>965634_lgb</th>\n",
       "      <th>966368_lgb</th>\n",
       "      <th>966369_lgb</th>\n",
       "      <th>966370_lgb</th>\n",
       "      <th>966371_lgb</th>\n",
       "      <th>966372_lgb</th>\n",
       "      <th>967104_lgb</th>\n",
       "      <th>967105_lgb</th>\n",
       "      <th>967106_lgb</th>\n",
       "      <th>967107_lgb</th>\n",
       "      <th>967108_lgb</th>\n",
       "      <th>967109_lgb</th>\n",
       "      <th>967110_lgb</th>\n",
       "      <th>967840_lgb</th>\n",
       "      <th>967841_lgb</th>\n",
       "      <th>967842_lgb</th>\n",
       "      <th>968576_lgb</th>\n",
       "      <th>968577_lgb</th>\n",
       "      <th>968578_lgb</th>\n",
       "      <th>968579_lgb</th>\n",
       "      <th>969312_lgb</th>\n",
       "      <th>969313_lgb</th>\n",
       "      <th>969314_lgb</th>\n",
       "      <th>969315_lgb</th>\n",
       "      <th>970048_lgb</th>\n",
       "      <th>970049_lgb</th>\n",
       "      <th>970050_lgb</th>\n",
       "      <th>970051_lgb</th>\n",
       "      <th>970784_lgb</th>\n",
       "      <th>970785_lgb</th>\n",
       "      <th>970786_lgb</th>\n",
       "      <th>970787_lgb</th>\n",
       "      <th>970788_lgb</th>\n",
       "      <th>971520_lgb</th>\n",
       "      <th>971521_lgb</th>\n",
       "      <th>971522_lgb</th>\n",
       "      <th>971523_lgb</th>\n",
       "      <th>971524_lgb</th>\n",
       "      <th>971525_lgb</th>\n",
       "      <th>971526_lgb</th>\n",
       "      <th>972256_lgb</th>\n",
       "      <th>972257_lgb</th>\n",
       "      <th>972258_lgb</th>\n",
       "      <th>972259_lgb</th>\n",
       "      <th>972260_lgb</th>\n",
       "      <th>972261_lgb</th>\n",
       "      <th>972992_lgb</th>\n",
       "      <th>972993_lgb</th>\n",
       "      <th>972994_lgb</th>\n",
       "      <th>972995_lgb</th>\n",
       "      <th>973728_lgb</th>\n",
       "      <th>973729_lgb</th>\n",
       "      <th>973730_lgb</th>\n",
       "      <th>973731_lgb</th>\n",
       "      <th>973732_lgb</th>\n",
       "      <th>973733_lgb</th>\n",
       "      <th>973734_lgb</th>\n",
       "      <th>974464_lgb</th>\n",
       "      <th>974465_lgb</th>\n",
       "      <th>974466_lgb</th>\n",
       "      <th>974467_lgb</th>\n",
       "      <th>974468_lgb</th>\n",
       "      <th>974469_lgb</th>\n",
       "      <th>974470_lgb</th>\n",
       "      <th>975200_lgb</th>\n",
       "      <th>975201_lgb</th>\n",
       "      <th>975936_lgb</th>\n",
       "      <th>975937_lgb</th>\n",
       "      <th>975938_lgb</th>\n",
       "      <th>975939_lgb</th>\n",
       "      <th>976672_lgb</th>\n",
       "      <th>976673_lgb</th>\n",
       "      <th>976674_lgb</th>\n",
       "      <th>976675_lgb</th>\n",
       "      <th>976676_lgb</th>\n",
       "      <th>976677_lgb</th>\n",
       "      <th>977408_lgb</th>\n",
       "      <th>977409_lgb</th>\n",
       "      <th>977410_lgb</th>\n",
       "      <th>977411_lgb</th>\n",
       "      <th>977412_lgb</th>\n",
       "      <th>978144_lgb</th>\n",
       "      <th>978145_lgb</th>\n",
       "      <th>978146_lgb</th>\n",
       "      <th>978147_lgb</th>\n",
       "      <th>978880_lgb</th>\n",
       "      <th>978881_lgb</th>\n",
       "      <th>978882_lgb</th>\n",
       "      <th>978883_lgb</th>\n",
       "      <th>979616_lgb</th>\n",
       "      <th>979617_lgb</th>\n",
       "      <th>980352_lgb</th>\n",
       "      <th>980353_lgb</th>\n",
       "      <th>980354_lgb</th>\n",
       "      <th>980355_lgb</th>\n",
       "      <th>981088_lgb</th>\n",
       "      <th>981089_lgb</th>\n",
       "      <th>981090_lgb</th>\n",
       "      <th>981091_lgb</th>\n",
       "      <th>981092_lgb</th>\n",
       "      <th>981824_lgb</th>\n",
       "      <th>981825_lgb</th>\n",
       "      <th>981826_lgb</th>\n",
       "      <th>981827_lgb</th>\n",
       "      <th>982560_lgb</th>\n",
       "      <th>982561_lgb</th>\n",
       "      <th>982562_lgb</th>\n",
       "      <th>983296_lgb</th>\n",
       "      <th>983297_lgb</th>\n",
       "      <th>983298_lgb</th>\n",
       "      <th>983299_lgb</th>\n",
       "      <th>983300_lgb</th>\n",
       "      <th>983301_lgb</th>\n",
       "      <th>984032_lgb</th>\n",
       "      <th>984033_lgb</th>\n",
       "      <th>984034_lgb</th>\n",
       "      <th>984768_lgb</th>\n",
       "      <th>984769_lgb</th>\n",
       "      <th>984770_lgb</th>\n",
       "      <th>985504_lgb</th>\n",
       "      <th>985505_lgb</th>\n",
       "      <th>985506_lgb</th>\n",
       "      <th>985507_lgb</th>\n",
       "      <th>985508_lgb</th>\n",
       "      <th>986240_lgb</th>\n",
       "      <th>986241_lgb</th>\n",
       "      <th>986242_lgb</th>\n",
       "      <th>986976_lgb</th>\n",
       "      <th>986977_lgb</th>\n",
       "      <th>986978_lgb</th>\n",
       "      <th>987712_lgb</th>\n",
       "      <th>987713_lgb</th>\n",
       "      <th>987714_lgb</th>\n",
       "      <th>987715_lgb</th>\n",
       "      <th>987716_lgb</th>\n",
       "      <th>988448_lgb</th>\n",
       "      <th>988449_lgb</th>\n",
       "      <th>988450_lgb</th>\n",
       "      <th>988451_lgb</th>\n",
       "      <th>989184_lgb</th>\n",
       "      <th>989185_lgb</th>\n",
       "      <th>989186_lgb</th>\n",
       "      <th>989187_lgb</th>\n",
       "      <th>989920_lgb</th>\n",
       "      <th>989921_lgb</th>\n",
       "      <th>989922_lgb</th>\n",
       "      <th>989923_lgb</th>\n",
       "      <th>989924_lgb</th>\n",
       "      <th>989925_lgb</th>\n",
       "      <th>990656_lgb</th>\n",
       "      <th>990657_lgb</th>\n",
       "      <th>990658_lgb</th>\n",
       "      <th>990659_lgb</th>\n",
       "      <th>991392_lgb</th>\n",
       "      <th>991393_lgb</th>\n",
       "      <th>991394_lgb</th>\n",
       "      <th>991395_lgb</th>\n",
       "      <th>992128_lgb</th>\n",
       "      <th>992129_lgb</th>\n",
       "      <th>992130_lgb</th>\n",
       "      <th>992864_lgb</th>\n",
       "      <th>992865_lgb</th>\n",
       "      <th>992866_lgb</th>\n",
       "      <th>992867_lgb</th>\n",
       "      <th>993600_lgb</th>\n",
       "      <th>993601_lgb</th>\n",
       "      <th>993602_lgb</th>\n",
       "      <th>993603_lgb</th>\n",
       "      <th>994336_lgb</th>\n",
       "      <th>994337_lgb</th>\n",
       "      <th>994338_lgb</th>\n",
       "      <th>994339_lgb</th>\n",
       "      <th>995072_lgb</th>\n",
       "      <th>995073_lgb</th>\n",
       "      <th>995074_lgb</th>\n",
       "      <th>995075_lgb</th>\n",
       "      <th>995076_lgb</th>\n",
       "      <th>995808_lgb</th>\n",
       "      <th>995809_lgb</th>\n",
       "      <th>995810_lgb</th>\n",
       "      <th>995811_lgb</th>\n",
       "      <th>995812_lgb</th>\n",
       "      <th>996544_lgb</th>\n",
       "      <th>996545_lgb</th>\n",
       "      <th>996546_lgb</th>\n",
       "      <th>997280_lgb</th>\n",
       "      <th>997281_lgb</th>\n",
       "      <th>997282_lgb</th>\n",
       "      <th>997283_lgb</th>\n",
       "      <th>997284_lgb</th>\n",
       "      <th>998016_lgb</th>\n",
       "      <th>998017_lgb</th>\n",
       "      <th>998018_lgb</th>\n",
       "      <th>998019_lgb</th>\n",
       "      <th>998752_lgb</th>\n",
       "      <th>998753_lgb</th>\n",
       "      <th>998754_lgb</th>\n",
       "      <th>998755_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>732.0</td>\n",
       "      <td>0.400396</td>\n",
       "      <td>17</td>\n",
       "      <td>6.665722</td>\n",
       "      <td>5.998750</td>\n",
       "      <td>46</td>\n",
       "      <td>6.998800</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>0.363620</td>\n",
       "      <td>59011</td>\n",
       "      <td>22</td>\n",
       "      <td>364464</td>\n",
       "      <td>16</td>\n",
       "      <td>81364</td>\n",
       "      <td>12949</td>\n",
       "      <td>28.486257</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11.397920</td>\n",
       "      <td>65.935065</td>\n",
       "      <td>5.498875</td>\n",
       "      <td>214</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87016.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>13492.000000</td>\n",
       "      <td>604227.0</td>\n",
       "      <td>33568.166667</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>42007.514571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>260.0</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.334615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85432.0</td>\n",
       "      <td>59011.0</td>\n",
       "      <td>16295.000000</td>\n",
       "      <td>224089.0</td>\n",
       "      <td>47740.988110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.40</td>\n",
       "      <td>9.840000</td>\n",
       "      <td>24.35</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.559937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.433437</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>164.500000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1173.500000</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>792.642857</td>\n",
       "      <td>217.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>713.952381</td>\n",
       "      <td>564.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>281.136364</td>\n",
       "      <td>258.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>771.045455</td>\n",
       "      <td>197.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>239.0</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.095351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6547</th>\n",
       "      <td>518.0</td>\n",
       "      <td>0.370718</td>\n",
       "      <td>42</td>\n",
       "      <td>34.988670</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>46</td>\n",
       "      <td>11.797840</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>0.107691</td>\n",
       "      <td>201224</td>\n",
       "      <td>22</td>\n",
       "      <td>290622</td>\n",
       "      <td>69</td>\n",
       "      <td>64832</td>\n",
       "      <td>10624</td>\n",
       "      <td>45.977511</td>\n",
       "      <td>30.990003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.244439</td>\n",
       "      <td>138.862138</td>\n",
       "      <td>12.997600</td>\n",
       "      <td>272</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>75</td>\n",
       "      <td>92.908092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98741.0</td>\n",
       "      <td>66750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8805.042136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>543500.0</td>\n",
       "      <td>212000.0</td>\n",
       "      <td>81793.398267</td>\n",
       "      <td>2748243.0</td>\n",
       "      <td>42280.661538</td>\n",
       "      <td>237771.0</td>\n",
       "      <td>50555.892598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.118252</td>\n",
       "      <td>224.0</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.647876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.101317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21779.0</td>\n",
       "      <td>21779.0</td>\n",
       "      <td>8711.600000</td>\n",
       "      <td>164164.0</td>\n",
       "      <td>21030.920771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.00</td>\n",
       "      <td>18.40</td>\n",
       "      <td>32.00</td>\n",
       "      <td>14.50</td>\n",
       "      <td>6.843975</td>\n",
       "      <td>583.80</td>\n",
       "      <td>12.973333</td>\n",
       "      <td>32.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>6.082344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.118252</td>\n",
       "      <td>3.446154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.589107</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>300.800000</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>709.092308</td>\n",
       "      <td>430.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>504.517241</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>101.40</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>431.246154</td>\n",
       "      <td>303.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>272.600000</td>\n",
       "      <td>303.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>658.938462</td>\n",
       "      <td>485.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.939072</td>\n",
       "      <td>681.0</td>\n",
       "      <td>10.476923</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.637643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>77.800000</td>\n",
       "      <td>206.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>762.0</td>\n",
       "      <td>0.420800</td>\n",
       "      <td>12</td>\n",
       "      <td>2.998002</td>\n",
       "      <td>8.992008</td>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.399920</td>\n",
       "      <td>68568</td>\n",
       "      <td>1</td>\n",
       "      <td>68932</td>\n",
       "      <td>99</td>\n",
       "      <td>364</td>\n",
       "      <td>8226</td>\n",
       "      <td>3.498751</td>\n",
       "      <td>6.994006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.498751</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>4.996004</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>6.994006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>784.400000</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>1568.800000</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1568.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25350.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>6039.172129</td>\n",
       "      <td>25350.0</td>\n",
       "      <td>5070.000000</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>6039.172129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68932.0</td>\n",
       "      <td>68568.0</td>\n",
       "      <td>27391.162791</td>\n",
       "      <td>68568.0</td>\n",
       "      <td>27391.162791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>194.400000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>194.400000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>156.666667</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>154.25</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>154.250000</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>115.2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>115.200000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>182.200000</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>182.200000</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.033150</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.033150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>746.0</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>27</td>\n",
       "      <td>5.998334</td>\n",
       "      <td>4.498251</td>\n",
       "      <td>46</td>\n",
       "      <td>2.749563</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.599880</td>\n",
       "      <td>47246</td>\n",
       "      <td>0</td>\n",
       "      <td>47246</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>11472</td>\n",
       "      <td>4.998667</td>\n",
       "      <td>3.749313</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.998667</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>2.499250</td>\n",
       "      <td>164</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>13.987013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43490.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>6255.000000</td>\n",
       "      <td>228499.0</td>\n",
       "      <td>45699.800000</td>\n",
       "      <td>85485.0</td>\n",
       "      <td>23840.693366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.545268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>14549.000000</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>12079.789773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.44</td>\n",
       "      <td>15.813333</td>\n",
       "      <td>25.00</td>\n",
       "      <td>9.95</td>\n",
       "      <td>6.578198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.631514</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>524.200000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>76.00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>197.400000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>161.400000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>209.500000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>508.600000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>700.0</td>\n",
       "      <td>0.385723</td>\n",
       "      <td>52</td>\n",
       "      <td>7.748313</td>\n",
       "      <td>12.497126</td>\n",
       "      <td>46</td>\n",
       "      <td>3.666222</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.437473</td>\n",
       "      <td>40878</td>\n",
       "      <td>88</td>\n",
       "      <td>339424</td>\n",
       "      <td>12</td>\n",
       "      <td>298546</td>\n",
       "      <td>11260</td>\n",
       "      <td>20.990005</td>\n",
       "      <td>7.798640</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.999286</td>\n",
       "      <td>52.948052</td>\n",
       "      <td>3.999250</td>\n",
       "      <td>258</td>\n",
       "      <td>62</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>37.963037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>803.666667</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>1797.053298</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1202.818128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>331598.0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>28811.055984</td>\n",
       "      <td>548219.0</td>\n",
       "      <td>34263.687500</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>27368.428373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278210.0</td>\n",
       "      <td>75464.0</td>\n",
       "      <td>29261.683648</td>\n",
       "      <td>75464.0</td>\n",
       "      <td>28188.354776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>62.00</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>42.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.944272</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.942103</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>268.333333</td>\n",
       "      <td>244.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>244.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>523.777778</td>\n",
       "      <td>51.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>69.20</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>285.461538</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>269.625000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>246.666667</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>560.937500</td>\n",
       "      <td>242.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>165.0</td>\n",
       "      <td>10.312500</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.310810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9030 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BureauScore  MissingRate  Len_Name  Tel_nuniq  Email_nuniq  \\\n",
       "502         732.0     0.400396        17   6.665722     5.998750   \n",
       "6547        518.0     0.370718        42  34.988670    25.987506   \n",
       "6938        762.0     0.420800        12   2.998002     8.992008   \n",
       "3115        746.0     0.396552        27   5.998334     4.498251   \n",
       "3649        700.0     0.385723        52   7.748313    12.497126   \n",
       "\n",
       "      Len_of_addrs  City_nuniq  Current_State  CreditAccountActive  \\\n",
       "502             46    6.998800             27                    8   \n",
       "6547            46   11.797840             27                    7   \n",
       "6938            46    1.000000             27                    2   \n",
       "3115            46    2.749563             27                    3   \n",
       "3649            46    3.666222             27                    7   \n",
       "\n",
       "      CreditAccountTotal  CreditAccountActivePor  Outstanding_Balance_Secured  \\\n",
       "502                   22                0.363620                        59011   \n",
       "6547                  65                0.107691                       201224   \n",
       "6938                   5                0.399920                        68568   \n",
       "3115                   5                0.599880                        47246   \n",
       "3649                  16                0.437473                        40878   \n",
       "\n",
       "      Outstanding_Balance_UnSecured_Percentage  Outstanding_Balance_All  \\\n",
       "502                                         22                   364464   \n",
       "6547                                        22                   290622   \n",
       "6938                                         1                    68932   \n",
       "3115                                         0                    47246   \n",
       "3649                                        88                   339424   \n",
       "\n",
       "      Outstanding_Balance_Secured_Percentage  Outstanding_Balance_UnSecured  \\\n",
       "502                                       16                          81364   \n",
       "6547                                      69                          64832   \n",
       "6938                                      99                            364   \n",
       "3115                                     100                              0   \n",
       "3649                                      12                         298546   \n",
       "\n",
       "      Diff_dateBirth  State_nuniq  Birth_nuniq  TotalCAPSLast90Days  \\\n",
       "502            12949    28.486257    25.987506                    4   \n",
       "6547           10624    45.977511    30.990003                    1   \n",
       "6938            8226     3.498751     6.994006                    0   \n",
       "3115           11472     4.998667     3.749313                    5   \n",
       "3649           11260    20.990005     7.798640                    3   \n",
       "\n",
       "      TotalCAPSLast7Days  TotalCAPSLast30Days  TotalCAPSLast180Days  \\\n",
       "502                    3                    3                     5   \n",
       "6547                   1                    1                     2   \n",
       "6938                   0                    0                     0   \n",
       "3115                   2                    4                     6   \n",
       "3649                   2                    2                     3   \n",
       "\n",
       "      CAPSLast30Days  CAPSLast7Days  CAPSLast180Days  \\\n",
       "502                0              0                2   \n",
       "6547               0              0                1   \n",
       "6938               0              0                0   \n",
       "3115               2              0                4   \n",
       "3649               1              1                2   \n",
       "\n",
       "      NonCreditCAPSLast180Days  Pin_nuniq   Pan_nuniq  Ident_nuniq  \\\n",
       "502                          3  11.397920   65.935065     5.498875   \n",
       "6547                         1  23.244439  138.862138    12.997600   \n",
       "6938                         0   3.498751   10.990010     4.996004   \n",
       "3115                         2   4.998667   10.990010     2.499250   \n",
       "3649                         1   5.999286   52.948052     3.999250   \n",
       "\n",
       "      Name_nuniq2  Tel_nuniq2  Email_nuniq2  Pan_nuniq2  Account_nuniq2  \\\n",
       "502           214          86            93          14              14   \n",
       "6547          272          44            47          14              14   \n",
       "6938           57          14            25          14              14   \n",
       "3115          164          44            44          14              14   \n",
       "3649          258          62            87          14              14   \n",
       "\n",
       "      Ident_nuniq2  Gender_nuniq  Amount_Past_Due35_sum_30  \\\n",
       "502             60     25.987506                       0.0   \n",
       "6547            75     92.908092                       0.0   \n",
       "6938            15      6.994006                       0.0   \n",
       "3115            30     13.987013                       0.0   \n",
       "3649            60     37.963037                       0.0   \n",
       "\n",
       "      Amount_Past_Due35_min_30  Amount_Past_Due35_sum_90  \\\n",
       "502                        0.0                       0.0   \n",
       "6547                       0.0                       0.0   \n",
       "6938                       0.0                       0.0   \n",
       "3115                       0.0                       0.0   \n",
       "3649                       0.0                       0.0   \n",
       "\n",
       "      Amount_Past_Due35_mean_90  Amount_Past_Due35_max_90  \\\n",
       "502                         0.0                       0.0   \n",
       "6547                        0.0                       0.0   \n",
       "6938                        0.0                       0.0   \n",
       "3115                        0.0                       0.0   \n",
       "3649                        0.0                       0.0   \n",
       "\n",
       "      Amount_Past_Due35_min_90  Amount_Past_Due35_std_90  \\\n",
       "502                        0.0                       0.0   \n",
       "6547                       0.0                       0.0   \n",
       "6938                       0.0                       0.0   \n",
       "3115                       0.0                       0.0   \n",
       "3649                       0.0                       0.0   \n",
       "\n",
       "      Amount_Past_Due35_sum_360  Amount_Past_Due35_mean_360  \\\n",
       "502                         0.0                    0.000000   \n",
       "6547                        0.0                    0.000000   \n",
       "6938                     3922.0                  784.400000   \n",
       "3115                        0.0                    0.000000   \n",
       "3649                     4822.0                  803.666667   \n",
       "\n",
       "      Amount_Past_Due35_max_360  Amount_Past_Due35_std_360  \\\n",
       "502                         0.0                   0.000000   \n",
       "6547                        0.0                   0.000000   \n",
       "6938                     3922.0                1568.800000   \n",
       "3115                        0.0                   0.000000   \n",
       "3649                     4822.0                1797.053298   \n",
       "\n",
       "      Amount_Past_Due35_sum_9999  Amount_Past_Due35_max_9999  \\\n",
       "502                          0.0                         0.0   \n",
       "6547                     98741.0                     66750.0   \n",
       "6938                      3922.0                      3922.0   \n",
       "3115                         0.0                         0.0   \n",
       "3649                      4822.0                      4822.0   \n",
       "\n",
       "      Amount_Past_Due35_min_9999  Amount_Past_Due35_std_9999  \\\n",
       "502                          0.0                    0.000000   \n",
       "6547                         0.0                 8805.042136   \n",
       "6938                         0.0                 1568.800000   \n",
       "3115                         0.0                    0.000000   \n",
       "3649                         0.0                 1202.818128   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_30  \\\n",
       "502                                               0.0   \n",
       "6547                                              0.0   \n",
       "6938                                              0.0   \n",
       "3115                                              0.0   \n",
       "3649                                              0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_min_30  \\\n",
       "502                                               0.0   \n",
       "6547                                              0.0   \n",
       "6938                                              0.0   \n",
       "3115                                              0.0   \n",
       "3649                                              0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_30  \\\n",
       "502                                               0.0   \n",
       "6547                                              0.0   \n",
       "6938                                              0.0   \n",
       "3115                                              0.0   \n",
       "3649                                              0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_90  \\\n",
       "502                                               0.0   \n",
       "6547                                              0.0   \n",
       "6938                                            350.0   \n",
       "3115                                              0.0   \n",
       "3649                                              0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_mean_90  \\\n",
       "502                                                0.0   \n",
       "6547                                               0.0   \n",
       "6938                                             350.0   \n",
       "3115                                               0.0   \n",
       "3649                                               0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_90  \\\n",
       "502                                               0.0   \n",
       "6547                                              0.0   \n",
       "6938                                            350.0   \n",
       "3115                                              0.0   \n",
       "3649                                              0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_min_90  \\\n",
       "502                                               0.0   \n",
       "6547                                              0.0   \n",
       "6938                                            350.0   \n",
       "3115                                              0.0   \n",
       "3649                                              0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "502                                               0.0   \n",
       "6547                                              0.0   \n",
       "6938                                              0.0   \n",
       "3115                                              0.0   \n",
       "3649                                              0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_360  \\\n",
       "502                                            87016.0   \n",
       "6547                                          543500.0   \n",
       "6938                                           25350.0   \n",
       "3115                                           43490.0   \n",
       "3649                                          331598.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_360  \\\n",
       "502                                            57000.0   \n",
       "6547                                          212000.0   \n",
       "6938                                           17000.0   \n",
       "3115                                           28000.0   \n",
       "3649                                           88000.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_360  \\\n",
       "502                                       13492.000000   \n",
       "6547                                      81793.398267   \n",
       "6938                                       6039.172129   \n",
       "3115                                       6255.000000   \n",
       "3649                                      28811.055984   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "502                                            604227.0   \n",
       "6547                                          2748243.0   \n",
       "6938                                            25350.0   \n",
       "3115                                           228499.0   \n",
       "3649                                           548219.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_mean_9999  \\\n",
       "502                                        33568.166667    \n",
       "6547                                       42280.661538    \n",
       "6938                                        5070.000000    \n",
       "3115                                       45699.800000    \n",
       "3649                                       34263.687500    \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "502                                            195000.0   \n",
       "6547                                           237771.0   \n",
       "6938                                            17000.0   \n",
       "3115                                            85485.0   \n",
       "3649                                            88000.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_9999  \\\n",
       "502                                        42007.514571   \n",
       "6547                                       50555.892598   \n",
       "6938                                        6039.172129   \n",
       "3115                                       23840.693366   \n",
       "3649                                       27368.428373   \n",
       "\n",
       "      Terms_Duration34_sum_30  Terms_Duration34_std_30  \\\n",
       "502                       0.0                      0.0   \n",
       "6547                      0.0                      0.0   \n",
       "6938                      0.0                      0.0   \n",
       "3115                      0.0                      0.0   \n",
       "3649                      0.0                      0.0   \n",
       "\n",
       "      Terms_Duration34_sum_90  Terms_Duration34_std_90  \\\n",
       "502                       0.0                      0.0   \n",
       "6547                      0.0                      0.0   \n",
       "6938                      0.0                      0.0   \n",
       "3115                      0.0                      0.0   \n",
       "3649                      0.0                      0.0   \n",
       "\n",
       "      Terms_Duration34_mean_360  Terms_Duration34_max_360  \\\n",
       "502                         4.5                       8.0   \n",
       "6547                        4.8                      13.0   \n",
       "6938                       30.0                      30.0   \n",
       "3115                       11.0                      12.0   \n",
       "3649                       24.0                      24.0   \n",
       "\n",
       "      Terms_Duration34_min_360  Terms_Duration34_std_360  \\\n",
       "502                        1.0                  3.500000   \n",
       "6547                       2.0                  4.118252   \n",
       "6938                      30.0                  0.000000   \n",
       "3115                      10.0                  1.000000   \n",
       "3649                      24.0                  0.000000   \n",
       "\n",
       "      Terms_Duration34_sum_9999  Terms_Duration34_mean_9999  \\\n",
       "502                       260.0                   17.333333   \n",
       "6547                      224.0                    5.600000   \n",
       "6938                       30.0                   30.000000   \n",
       "3115                       58.0                   14.500000   \n",
       "3649                       31.0                   15.500000   \n",
       "\n",
       "      Terms_Duration34_max_9999  Terms_Duration34_min_9999  \\\n",
       "502                        47.0                        1.0   \n",
       "6547                       40.0                        0.0   \n",
       "6938                       30.0                       30.0   \n",
       "3115                       24.0                       10.0   \n",
       "3649                       24.0                        7.0   \n",
       "\n",
       "      Terms_Duration34_std_9999  Payment_Rating34_sum_90  \\\n",
       "502                   17.334615                      0.0   \n",
       "6547                   7.647876                      0.0   \n",
       "6938                   0.000000                      0.0   \n",
       "3115                   5.545268                      0.0   \n",
       "3649                   8.500000                      0.0   \n",
       "\n",
       "      Payment_Rating34_mean_90  Payment_Rating34_max_90  \\\n",
       "502                        0.0                      0.0   \n",
       "6547                       0.0                      0.0   \n",
       "6938                       0.0                      0.0   \n",
       "3115                       0.0                      0.0   \n",
       "3649                       0.0                      0.0   \n",
       "\n",
       "      Payment_Rating34_min_90  Payment_Rating34_std_90  \\\n",
       "502                       0.0                      0.0   \n",
       "6547                      0.0                      0.0   \n",
       "6938                      0.0                      0.0   \n",
       "3115                      0.0                      0.0   \n",
       "3649                      0.0                      0.0   \n",
       "\n",
       "      Payment_Rating34_sum_360  Payment_Rating34_mean_360  \\\n",
       "502                        0.0                        0.0   \n",
       "6547                       0.0                        0.0   \n",
       "6938                       0.0                        0.0   \n",
       "3115                       0.0                        0.0   \n",
       "3649                       0.0                        0.0   \n",
       "\n",
       "      Payment_Rating34_max_360  Payment_Rating34_min_360  \\\n",
       "502                        0.0                       0.0   \n",
       "6547                       0.0                       0.0   \n",
       "6938                       0.0                       0.0   \n",
       "3115                       0.0                       0.0   \n",
       "3649                       0.0                       0.0   \n",
       "\n",
       "      Payment_Rating34_std_360  Payment_Rating34_sum_9999  \\\n",
       "502                        0.0                        0.0   \n",
       "6547                       0.0                       17.0   \n",
       "6938                       0.0                        0.0   \n",
       "3115                       0.0                        0.0   \n",
       "3649                       0.0                        0.0   \n",
       "\n",
       "      Payment_Rating34_mean_9999  Payment_Rating34_max_9999  \\\n",
       "502                     0.000000                        0.0   \n",
       "6547                    0.269841                        6.0   \n",
       "6938                    0.000000                        0.0   \n",
       "3115                    0.000000                        0.0   \n",
       "3649                    0.000000                        0.0   \n",
       "\n",
       "      Payment_Rating34_min_9999  Payment_Rating34_std_9999  \\\n",
       "502                         0.0                   0.000000   \n",
       "6547                        0.0                   1.101317   \n",
       "6938                        0.0                   0.000000   \n",
       "3115                        0.0                   0.000000   \n",
       "3649                        0.0                   0.000000   \n",
       "\n",
       "      Current_Balance35_mean_30  Current_Balance35_min_30  \\\n",
       "502                         0.0                       0.0   \n",
       "6547                        0.0                       0.0   \n",
       "6938                        0.0                       0.0   \n",
       "3115                        0.0                       0.0   \n",
       "3649                        0.0                       0.0   \n",
       "\n",
       "      Current_Balance35_std_30  Current_Balance35_sum_90  \\\n",
       "502                        0.0                       0.0   \n",
       "6547                       0.0                       0.0   \n",
       "6938                       0.0                     364.0   \n",
       "3115                       0.0                       0.0   \n",
       "3649                       0.0                       0.0   \n",
       "\n",
       "      Current_Balance35_mean_90  Current_Balance35_max_90  \\\n",
       "502                         0.0                       0.0   \n",
       "6547                        0.0                       0.0   \n",
       "6938                      364.0                     364.0   \n",
       "3115                        0.0                       0.0   \n",
       "3649                        0.0                       0.0   \n",
       "\n",
       "      Current_Balance35_std_90  Current_Balance35_sum_360  \\\n",
       "502                        0.0                    85432.0   \n",
       "6547                       0.0                    21779.0   \n",
       "6938                       0.0                    68932.0   \n",
       "3115                       0.0                    29098.0   \n",
       "3649                       0.0                   278210.0   \n",
       "\n",
       "      Current_Balance35_max_360  Current_Balance35_std_360  \\\n",
       "502                     59011.0               16295.000000   \n",
       "6547                    21779.0                8711.600000   \n",
       "6938                    68568.0               27391.162791   \n",
       "3115                    29098.0               14549.000000   \n",
       "3649                    75464.0               29261.683648   \n",
       "\n",
       "      Current_Balance35_max_9999  Current_Balance35_std_9999  \\\n",
       "502                     224089.0                47740.988110   \n",
       "6547                    164164.0                21030.920771   \n",
       "6938                     68568.0                27391.162791   \n",
       "3115                     29098.0                12079.789773   \n",
       "3649                     75464.0                28188.354776   \n",
       "\n",
       "      Settlement_Amount37_max_360  Settlement_Amount37_min_360  \\\n",
       "502                           0.0                          0.0   \n",
       "6547                          0.0                          0.0   \n",
       "6938                          0.0                          0.0   \n",
       "3115                          0.0                          0.0   \n",
       "3649                          0.0                          0.0   \n",
       "\n",
       "      Settlement_Amount37_std_360  Settlement_Amount37_sum_9999  \\\n",
       "502                           0.0                           0.0   \n",
       "6547                          0.0                           0.0   \n",
       "6938                          0.0                           0.0   \n",
       "3115                          0.0                           0.0   \n",
       "3649                          0.0                           0.0   \n",
       "\n",
       "      Settlement_Amount37_mean_9999  Settlement_Amount37_max_9999  \\\n",
       "502                             0.0                           0.0   \n",
       "6547                            0.0                           0.0   \n",
       "6938                            0.0                           0.0   \n",
       "3115                            0.0                           0.0   \n",
       "3649                            0.0                           0.0   \n",
       "\n",
       "      Settlement_Amount37_min_9999  Settlement_Amount37_std_9999  \\\n",
       "502                            0.0                           0.0   \n",
       "6547                           0.0                           0.0   \n",
       "6938                           0.0                           0.0   \n",
       "3115                           0.0                           0.0   \n",
       "3649                           0.0                           0.0   \n",
       "\n",
       "      Value_of_Collateral39_std_90  Value_of_Collateral39_std_360  \\\n",
       "502                            0.0                            0.0   \n",
       "6547                           0.0                            0.0   \n",
       "6938                           0.0                            0.0   \n",
       "3115                           0.0                            0.0   \n",
       "3649                           0.0                            0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_sum_360  Written_Off_Amt_Total41_mean_360  \\\n",
       "502                               0.0                               0.0   \n",
       "6547                              0.0                               0.0   \n",
       "6938                              0.0                               0.0   \n",
       "3115                              0.0                               0.0   \n",
       "3649                              0.0                               0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_min_360  Written_Off_Amt_Total41_std_360  \\\n",
       "502                               0.0                              0.0   \n",
       "6547                              0.0                              0.0   \n",
       "6938                              0.0                              0.0   \n",
       "3115                              0.0                              0.0   \n",
       "3649                              0.0                              0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_sum_9999  Written_Off_Amt_Total41_mean_9999  \\\n",
       "502                                0.0                                0.0   \n",
       "6547                               0.0                                0.0   \n",
       "6938                               0.0                                0.0   \n",
       "3115                               0.0                                0.0   \n",
       "3649                               0.0                                0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_max_9999  Written_Off_Amt_Total41_min_9999  \\\n",
       "502                                0.0                               0.0   \n",
       "6547                               0.0                               0.0   \n",
       "6938                               0.0                               0.0   \n",
       "3115                               0.0                               0.0   \n",
       "3649                               0.0                               0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_std_9999  Written_Off_Amt_Principal45_sum_360  \\\n",
       "502                                0.0                                  0.0   \n",
       "6547                               0.0                                  0.0   \n",
       "6938                               0.0                                  0.0   \n",
       "3115                               0.0                                  0.0   \n",
       "3649                               0.0                                  0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_mean_360  \\\n",
       "502                                    0.0   \n",
       "6547                                   0.0   \n",
       "6938                                   0.0   \n",
       "3115                                   0.0   \n",
       "3649                                   0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_min_360  \\\n",
       "502                                   0.0   \n",
       "6547                                  0.0   \n",
       "6938                                  0.0   \n",
       "3115                                  0.0   \n",
       "3649                                  0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_std_360  \\\n",
       "502                                   0.0   \n",
       "6547                                  0.0   \n",
       "6938                                  0.0   \n",
       "3115                                  0.0   \n",
       "3649                                  0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_max_9999  \\\n",
       "502                                    0.0   \n",
       "6547                                   0.0   \n",
       "6938                                   0.0   \n",
       "3115                                   0.0   \n",
       "3649                                   0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_min_9999  Rate_of_Interest36_sum_30  \\\n",
       "502                                    0.0                        0.0   \n",
       "6547                                   0.0                        0.0   \n",
       "6938                                   0.0                        0.0   \n",
       "3115                                   0.0                        0.0   \n",
       "3649                                   0.0                        0.0   \n",
       "\n",
       "      Rate_of_Interest36_std_30  Rate_of_Interest36_sum_90  \\\n",
       "502                         0.0                        0.0   \n",
       "6547                        0.0                        0.0   \n",
       "6938                        0.0                        0.0   \n",
       "3115                        0.0                        0.0   \n",
       "3649                        0.0                        0.0   \n",
       "\n",
       "      Rate_of_Interest36_mean_90  Rate_of_Interest36_max_90  \\\n",
       "502                          0.0                        0.0   \n",
       "6547                         0.0                        0.0   \n",
       "6938                         0.0                        0.0   \n",
       "3115                         0.0                        0.0   \n",
       "3649                         0.0                        0.0   \n",
       "\n",
       "      Rate_of_Interest36_std_90  Rate_of_Interest36_sum_360  \\\n",
       "502                         0.0                        7.40   \n",
       "6547                        0.0                       92.00   \n",
       "6938                        0.0                        0.00   \n",
       "3115                        0.0                        9.95   \n",
       "3649                        0.0                       62.00   \n",
       "\n",
       "      Rate_of_Interest36_mean_360  Rate_of_Interest36_max_360  \\\n",
       "502                          7.40                        7.40   \n",
       "6547                        18.40                       32.00   \n",
       "6938                         0.00                        0.00   \n",
       "3115                         9.95                        9.95   \n",
       "3649                        31.00                       42.00   \n",
       "\n",
       "      Rate_of_Interest36_min_360  Rate_of_Interest36_std_360  \\\n",
       "502                         7.40                    0.000000   \n",
       "6547                       14.50                    6.843975   \n",
       "6938                        0.00                    0.000000   \n",
       "3115                        9.95                    0.000000   \n",
       "3649                       20.00                   11.000000   \n",
       "\n",
       "      Rate_of_Interest36_sum_9999  Rate_of_Interest36_mean_9999  \\\n",
       "502                         98.40                      9.840000   \n",
       "6547                       583.80                     12.973333   \n",
       "6938                         0.00                      0.000000   \n",
       "3115                        47.44                     15.813333   \n",
       "3649                        62.00                     31.000000   \n",
       "\n",
       "      Rate_of_Interest36_max_9999  Rate_of_Interest36_min_9999  \\\n",
       "502                         24.35                         1.00   \n",
       "6547                        32.00                         1.40   \n",
       "6938                         0.00                         0.00   \n",
       "3115                        25.00                         9.95   \n",
       "3649                        42.00                        20.00   \n",
       "\n",
       "      Rate_of_Interest36_std_9999  Repayment_Tenure36_std_30  \\\n",
       "502                      5.559937                        0.0   \n",
       "6547                     6.082344                        0.0   \n",
       "6938                     0.000000                        0.0   \n",
       "3115                     6.578198                        0.0   \n",
       "3649                    11.000000                        0.0   \n",
       "\n",
       "      Repayment_Tenure36_mean_90  Repayment_Tenure36_max_90  \\\n",
       "502                          0.0                        0.0   \n",
       "6547                         0.0                        0.0   \n",
       "6938                         0.0                        0.0   \n",
       "3115                         0.0                        0.0   \n",
       "3649                         0.0                        0.0   \n",
       "\n",
       "      Repayment_Tenure36_min_90  Repayment_Tenure36_std_90  \\\n",
       "502                         0.0                        0.0   \n",
       "6547                        0.0                        0.0   \n",
       "6938                        0.0                        0.0   \n",
       "3115                        0.0                        0.0   \n",
       "3649                        0.0                        0.0   \n",
       "\n",
       "      Repayment_Tenure36_sum_360  Repayment_Tenure36_mean_360  \\\n",
       "502                          9.0                          4.5   \n",
       "6547                        24.0                          4.8   \n",
       "6938                        30.0                          6.0   \n",
       "3115                        22.0                         11.0   \n",
       "3649                        24.0                          4.0   \n",
       "\n",
       "      Repayment_Tenure36_min_360  Repayment_Tenure36_std_360  \\\n",
       "502                          1.0                    3.500000   \n",
       "6547                         2.0                    4.118252   \n",
       "6938                         0.0                   12.000000   \n",
       "3115                        10.0                    1.000000   \n",
       "3649                         0.0                    8.944272   \n",
       "\n",
       "      Repayment_Tenure36_mean_9999  Repayment_Tenure36_min_9999  \\\n",
       "502                      11.818182                          0.0   \n",
       "6547                      3.446154                          0.0   \n",
       "6938                      6.000000                          0.0   \n",
       "3115                     11.600000                          0.0   \n",
       "3649                      1.937500                          0.0   \n",
       "\n",
       "      Repayment_Tenure36_std_9999  Income26_count_360  Income26_std_360  \\\n",
       "502                     16.433437                 2.0               0.0   \n",
       "6547                     6.589107                 5.0               0.0   \n",
       "6938                    12.000000                 5.0               0.0   \n",
       "3115                     7.631514                 2.0               0.0   \n",
       "3649                     5.942103                 6.0               0.0   \n",
       "\n",
       "      Open_Date29_max_30  Open_Date29_min_30  Open_Date29_mean_30  \\\n",
       "502                  0.0                 0.0                  0.0   \n",
       "6547                 0.0                 0.0                  0.0   \n",
       "6938                 0.0                 0.0                  0.0   \n",
       "3115                 0.0                 0.0                  0.0   \n",
       "3649                 0.0                 0.0                  0.0   \n",
       "\n",
       "      Open_Date29_nuniq_30  Open_Date29_maxcount_30  Open_Date29_max_90  \\\n",
       "502                    0.0                      0.0                 0.0   \n",
       "6547                   0.0                      0.0                 0.0   \n",
       "6938                   0.0                      0.0                89.0   \n",
       "3115                   0.0                      0.0                 0.0   \n",
       "3649                   0.0                      0.0                 0.0   \n",
       "\n",
       "      Open_Date29_mean_90  Open_Date29_mode_90  Open_Date29_nuniq_90  \\\n",
       "502                   0.0                  0.0                   0.0   \n",
       "6547                  0.0                  0.0                   0.0   \n",
       "6938                 89.0                 89.0                   1.0   \n",
       "3115                  0.0                  0.0                   0.0   \n",
       "3649                  0.0                  0.0                   0.0   \n",
       "\n",
       "      Open_Date29_maxcount_90  Open_Date29_max_360  Open_Date29_mean_360  \\\n",
       "502                       0.0                217.0            164.500000   \n",
       "6547                      0.0                353.0            300.800000   \n",
       "6938                      1.0                307.0            194.400000   \n",
       "3115                      0.0                304.0            219.000000   \n",
       "3649                      0.0                332.0            268.333333   \n",
       "\n",
       "      Open_Date29_mode_360  Open_Date29_nuniq_360  Open_Date29_maxcount_360  \\\n",
       "502                  112.0                    2.0                       1.0   \n",
       "6547                 212.0                    5.0                       1.0   \n",
       "6938                  89.0                    5.0                       1.0   \n",
       "3115                 134.0                    2.0                       1.0   \n",
       "3649                 244.0                    6.0                       1.0   \n",
       "\n",
       "      Open_Date29_max_9999  Open_Date29_mean_9999  Open_Date29_mode_9999  \\\n",
       "502                 2400.0            1173.500000                 1627.0   \n",
       "6547                1940.0             709.092308                  430.0   \n",
       "6938                 307.0             194.400000                   89.0   \n",
       "3115                1019.0             524.200000                  134.0   \n",
       "3649                1156.0             584.000000                  244.0   \n",
       "\n",
       "      Open_Date29_maxcount_9999  Portfolio_Type34_nuniq_30  \\\n",
       "502                         4.0                        0.0   \n",
       "6547                        3.0                        0.0   \n",
       "6938                        1.0                        0.0   \n",
       "3115                        1.0                        0.0   \n",
       "3649                        1.0                        0.0   \n",
       "\n",
       "      Portfolio_Type34_nuniq_90  Portfolio_Type34_nuniq_360  \\\n",
       "502                         0.0                         1.0   \n",
       "6547                        0.0                         1.0   \n",
       "6938                        1.0                         1.0   \n",
       "3115                        0.0                         1.0   \n",
       "3649                        0.0                         2.0   \n",
       "\n",
       "      Portfolio_Type34_nuniq_9999  Account_Type32_nuniq_30  \\\n",
       "502                           2.0                      0.0   \n",
       "6547                          3.0                      0.0   \n",
       "6938                          1.0                      0.0   \n",
       "3115                          1.0                      0.0   \n",
       "3649                          2.0                      0.0   \n",
       "\n",
       "      Account_Type32_nuniq_90  Account_Type32_nuniq_360  \\\n",
       "502                       0.0                       2.0   \n",
       "6547                      0.0                       2.0   \n",
       "6938                      1.0                       2.0   \n",
       "3115                      0.0                       2.0   \n",
       "3649                      0.0                       4.0   \n",
       "\n",
       "      Account_Type32_nuniq_9999  Occupation_Code35_nuniq_30  \\\n",
       "502                         5.0                         0.0   \n",
       "6547                        8.0                         0.0   \n",
       "6938                        2.0                         0.0   \n",
       "3115                        5.0                         0.0   \n",
       "3649                        4.0                         0.0   \n",
       "\n",
       "      Occupation_Code35_nuniq_90  Occupation_Code35_nuniq_360  \\\n",
       "502                          0.0                          1.0   \n",
       "6547                         0.0                          1.0   \n",
       "6938                         1.0                          1.0   \n",
       "3115                         0.0                          1.0   \n",
       "3649                         0.0                          1.0   \n",
       "\n",
       "      Occupation_Code35_nuniq_9999  AccountHoldertypeCode41_nuniq_90  \\\n",
       "502                            1.0                               0.0   \n",
       "6547                           1.0                               0.0   \n",
       "6938                           1.0                               1.0   \n",
       "3115                           1.0                               0.0   \n",
       "3649                           2.0                               0.0   \n",
       "\n",
       "      AccountHoldertypeCode41_nuniq_360  AccountHoldertypeCode41_nuniq_9999  \\\n",
       "502                                 1.0                                 2.0   \n",
       "6547                                1.0                                 2.0   \n",
       "6938                                1.0                                 1.0   \n",
       "3115                                1.0                                 1.0   \n",
       "3649                                1.0                                 1.0   \n",
       "\n",
       "      Payment_History_Profile43_mode_30  Payment_History_Profile43_mode_90  \\\n",
       "502                                   0                                  0   \n",
       "6547                                  0                                  0   \n",
       "6938                                  0                                  1   \n",
       "3115                                  0                                  0   \n",
       "3649                                  0                                  0   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_90  Payment_History_Profile43_mode_360  \\\n",
       "502                                  0.0                                  36   \n",
       "6547                                 0.0                                  36   \n",
       "6938                                 1.0                                   1   \n",
       "3115                                 0.0                                  36   \n",
       "3649                                 0.0                                  36   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_360  \\\n",
       "502                                   2.0   \n",
       "6547                                  4.0   \n",
       "6938                                  4.0   \n",
       "3115                                  2.0   \n",
       "3649                                  4.0   \n",
       "\n",
       "      Payment_History_Profile43_mode_9999  \\\n",
       "502                                    36   \n",
       "6547                                   36   \n",
       "6938                                    1   \n",
       "3115                                   36   \n",
       "3649                                   36   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_9999  Date_Closed31_nuniq_30  \\\n",
       "502                                   19.0                     0.0   \n",
       "6547                                  30.0                     0.0   \n",
       "6938                                   4.0                     0.0   \n",
       "3115                                   5.0                     0.0   \n",
       "3649                                  12.0                     0.0   \n",
       "\n",
       "      Date_Closed31_maxcount_30  Date_Closed31_max_90  Date_Closed31_min_90  \\\n",
       "502                         0.0                   0.0                   0.0   \n",
       "6547                        0.0                   0.0                   0.0   \n",
       "6938                        0.0                   0.0                   0.0   \n",
       "3115                        0.0                   0.0                   0.0   \n",
       "3649                        0.0                   0.0                   0.0   \n",
       "\n",
       "      Date_Closed31_mean_90  Date_Closed31_mode_90  Date_Closed31_nuniq_90  \\\n",
       "502                     0.0                    0.0                     0.0   \n",
       "6547                    0.0                    0.0                     0.0   \n",
       "6938                    0.0                    0.0                     1.0   \n",
       "3115                    0.0                    0.0                     0.0   \n",
       "3649                    0.0                    0.0                     0.0   \n",
       "\n",
       "      Date_Closed31_maxcount_90  Date_Closed31_min_360  \\\n",
       "502                         0.0                    0.0   \n",
       "6547                        0.0                   30.0   \n",
       "6938                        0.0                   91.0   \n",
       "3115                        0.0                    0.0   \n",
       "3649                        0.0                   74.0   \n",
       "\n",
       "      Date_Closed31_mode_360  Date_Closed31_nuniq_360  \\\n",
       "502                      0.0                      1.0   \n",
       "6547                    30.0                      3.0   \n",
       "6938                    91.0                      4.0   \n",
       "3115                     0.0                      1.0   \n",
       "3649                    74.0                      2.0   \n",
       "\n",
       "      Date_Closed31_maxcount_360  Date_Closed31_max_9999  \\\n",
       "502                          0.0                  1790.0   \n",
       "6547                         3.0                  1327.0   \n",
       "6938                         1.0                   222.0   \n",
       "3115                         0.0                   660.0   \n",
       "3649                         1.0                   939.0   \n",
       "\n",
       "      Date_Closed31_min_9999  Date_Closed31_mean_9999  \\\n",
       "502                    217.0               792.642857   \n",
       "6547                    30.0               504.517241   \n",
       "6938                    91.0               156.666667   \n",
       "3115                   124.0               392.000000   \n",
       "3649                    51.0               523.777778   \n",
       "\n",
       "      Date_Closed31_mode_9999  Date_Closed31_nuniq_9999  \\\n",
       "502                     217.0                      15.0   \n",
       "6547                     30.0                      38.0   \n",
       "6938                     91.0                       4.0   \n",
       "3115                    124.0                       3.0   \n",
       "3649                     51.0                      10.0   \n",
       "\n",
       "      Date_of_Last_Payment40_nuniq_30  Date_of_Last_Payment40_maxcount_30  \\\n",
       "502                               0.0                                 0.0   \n",
       "6547                              0.0                                 0.0   \n",
       "6938                              0.0                                 0.0   \n",
       "3115                              0.0                                 0.0   \n",
       "3649                              0.0                                 0.0   \n",
       "\n",
       "      Date_of_Last_Payment40_min_90  Date_of_Last_Payment40_nuniq_90  \\\n",
       "502                             0.0                              0.0   \n",
       "6547                            0.0                              0.0   \n",
       "6938                            0.0                              1.0   \n",
       "3115                            0.0                              0.0   \n",
       "3649                            0.0                              0.0   \n",
       "\n",
       "      Date_of_Last_Payment40_maxcount_90  Date_of_Last_Payment40_max_360  \\\n",
       "502                                  0.0                            73.0   \n",
       "6547                                 0.0                           212.0   \n",
       "6938                                 0.0                           222.0   \n",
       "3115                                 0.0                           119.0   \n",
       "3649                                 0.0                           100.0   \n",
       "\n",
       "      Date_of_Last_Payment40_min_360  Date_of_Last_Payment40_mean_360  \\\n",
       "502                             73.0                            73.00   \n",
       "6547                            31.0                           101.40   \n",
       "6938                            91.0                           154.25   \n",
       "3115                            33.0                            76.00   \n",
       "3649                            50.0                            69.20   \n",
       "\n",
       "      Date_of_Last_Payment40_mode_360  Date_of_Last_Payment40_nuniq_360  \\\n",
       "502                              73.0                               2.0   \n",
       "6547                             31.0                               3.0   \n",
       "6938                             91.0                               5.0   \n",
       "3115                             33.0                               2.0   \n",
       "3649                             50.0                               6.0   \n",
       "\n",
       "      Date_of_Last_Payment40_maxcount_360  Date_of_Last_Payment40_max_9999  \\\n",
       "502                                   1.0                           1957.0   \n",
       "6547                                  3.0                           1327.0   \n",
       "6938                                  1.0                            222.0   \n",
       "3115                                  1.0                            660.0   \n",
       "3649                                  1.0                            941.0   \n",
       "\n",
       "      Date_of_Last_Payment40_min_9999  Date_of_Last_Payment40_mean_9999  \\\n",
       "502                              73.0                        713.952381   \n",
       "6547                             31.0                        490.000000   \n",
       "6938                             91.0                        154.250000   \n",
       "3115                             33.0                        197.400000   \n",
       "3649                             35.0                        285.461538   \n",
       "\n",
       "      Date_of_Last_Payment40_mode_9999  Date_of_Last_Payment40_maxcount_9999  \\\n",
       "502                              564.0                                   2.0   \n",
       "6547                              31.0                                   8.0   \n",
       "6938                              91.0                                   1.0   \n",
       "3115                              33.0                                   1.0   \n",
       "3649                              53.0                                   2.0   \n",
       "\n",
       "      Date_Reported33_nuniq_30  Date_Reported33_max_90  \\\n",
       "502                        0.0                     0.0   \n",
       "6547                       0.0                     0.0   \n",
       "6938                       0.0                    60.0   \n",
       "3115                       0.0                     0.0   \n",
       "3649                       0.0                     0.0   \n",
       "\n",
       "      Date_Reported33_mean_90  Date_Reported33_mode_90  \\\n",
       "502                       0.0                      0.0   \n",
       "6547                      0.0                      0.0   \n",
       "6938                     60.0                     60.0   \n",
       "3115                      0.0                      0.0   \n",
       "3649                      0.0                      0.0   \n",
       "\n",
       "      Date_Reported33_nuniq_90  Date_Reported33_maxcount_90  \\\n",
       "502                        0.0                          0.0   \n",
       "6547                       0.0                          0.0   \n",
       "6938                       1.0                          1.0   \n",
       "3115                       0.0                          0.0   \n",
       "3649                       0.0                          0.0   \n",
       "\n",
       "      Date_Reported33_max_360  Date_Reported33_mean_360  \\\n",
       "502                      44.0                      44.0   \n",
       "6547                    181.0                      64.8   \n",
       "6938                    213.0                     115.2   \n",
       "3115                     58.0                      42.5   \n",
       "3649                     58.0                      48.0   \n",
       "\n",
       "      Date_Reported33_mode_360  Date_Reported33_nuniq_360  \\\n",
       "502                       44.0                        1.0   \n",
       "6547                      28.0                        3.0   \n",
       "6938                      60.0                        4.0   \n",
       "3115                      27.0                        2.0   \n",
       "3649                      58.0                        2.0   \n",
       "\n",
       "      Date_Reported33_maxcount_360  Date_Reported33_max_9999  \\\n",
       "502                            2.0                     989.0   \n",
       "6547                           3.0                    1854.0   \n",
       "6938                           2.0                     213.0   \n",
       "3115                           1.0                     576.0   \n",
       "3649                           4.0                     912.0   \n",
       "\n",
       "      Date_Reported33_mean_9999  Date_Reported33_mode_9999  \\\n",
       "502                  281.136364                      258.0   \n",
       "6547                 431.246154                      303.0   \n",
       "6938                 115.200000                       60.0   \n",
       "3115                 161.400000                       27.0   \n",
       "3649                 269.625000                       28.0   \n",
       "\n",
       "      Date_Reported33_nuniq_9999  Date_Reported33_maxcount_9999  \\\n",
       "502                         11.0                            5.0   \n",
       "6547                        26.0                           12.0   \n",
       "6938                         4.0                            2.0   \n",
       "3115                         4.0                            2.0   \n",
       "3649                         8.0                            5.0   \n",
       "\n",
       "      DateOfAddition34_nuniq_30  DateOfAddition34_max_90  \\\n",
       "502                         0.0                      0.0   \n",
       "6547                        0.0                      0.0   \n",
       "6938                        0.0                     60.0   \n",
       "3115                        0.0                      0.0   \n",
       "3649                        0.0                      0.0   \n",
       "\n",
       "      DateOfAddition34_mean_90  DateOfAddition34_mode_90  \\\n",
       "502                        0.0                       0.0   \n",
       "6547                       0.0                       0.0   \n",
       "6938                      60.0                      60.0   \n",
       "3115                       0.0                       0.0   \n",
       "3649                       0.0                       0.0   \n",
       "\n",
       "      DateOfAddition34_nuniq_90  DateOfAddition34_maxcount_90  \\\n",
       "502                         0.0                           0.0   \n",
       "6547                        0.0                           0.0   \n",
       "6938                        1.0                           1.0   \n",
       "3115                        0.0                           0.0   \n",
       "3649                        0.0                           0.0   \n",
       "\n",
       "      DateOfAddition34_max_360  DateOfAddition34_mean_360  \\\n",
       "502                      197.0                 151.000000   \n",
       "6547                     303.0                 272.600000   \n",
       "6938                     303.0                 182.200000   \n",
       "3115                     300.0                 209.500000   \n",
       "3649                     301.0                 246.666667   \n",
       "\n",
       "      DateOfAddition34_mode_360  DateOfAddition34_nuniq_360  \\\n",
       "502                       105.0                         2.0   \n",
       "6547                      303.0                         3.0   \n",
       "6938                      213.0                         4.0   \n",
       "3115                      119.0                         2.0   \n",
       "3649                      242.0                         3.0   \n",
       "\n",
       "      DateOfAddition34_maxcount_360  DateOfAddition34_max_9999  \\\n",
       "502                             1.0                     2115.0   \n",
       "6547                            3.0                     1885.0   \n",
       "6938                            2.0                      303.0   \n",
       "3115                            1.0                     1003.0   \n",
       "3649                            4.0                     1154.0   \n",
       "\n",
       "      DateOfAddition34_mean_9999  DateOfAddition34_mode_9999  \\\n",
       "502                   771.045455                       197.0   \n",
       "6547                  658.938462                       485.0   \n",
       "6938                  182.200000                       213.0   \n",
       "3115                  508.600000                       119.0   \n",
       "3649                  560.937500                       242.0   \n",
       "\n",
       "      DateOfAddition34_nuniq_9999  DateOfAddition34_maxcount_9999  \\\n",
       "502                          15.0                             5.0   \n",
       "6547                         27.0                             5.0   \n",
       "6938                          4.0                             2.0   \n",
       "3115                          5.0                             1.0   \n",
       "3649                         12.0                             4.0   \n",
       "\n",
       "      Account_Status34_mode_30  Account_Status34_nuniq_30  \\\n",
       "502                        0.0                        0.0   \n",
       "6547                       0.0                        0.0   \n",
       "6938                       0.0                        0.0   \n",
       "3115                       0.0                        0.0   \n",
       "3649                       0.0                        0.0   \n",
       "\n",
       "      Account_Status34_mode_90  Account_Status34_nuniq_90  \\\n",
       "502                        0.0                        0.0   \n",
       "6547                       0.0                        0.0   \n",
       "6938                      11.0                        1.0   \n",
       "3115                       0.0                        0.0   \n",
       "3649                       0.0                        0.0   \n",
       "\n",
       "      Account_Status34_mode_360  Account_Status34_nuniq_360  \\\n",
       "502                        11.0                         2.0   \n",
       "6547                       13.0                         2.0   \n",
       "6938                       13.0                         2.0   \n",
       "3115                       11.0                         1.0   \n",
       "3649                       11.0                         2.0   \n",
       "\n",
       "      Account_Status34_nuniq_9999  Month50_sum_30  Month50_max_30  \\\n",
       "502                           4.0             0.0             0.0   \n",
       "6547                          8.0             0.0             0.0   \n",
       "6938                          2.0             0.0             0.0   \n",
       "3115                          2.0             0.0             0.0   \n",
       "3649                          2.0             0.0             0.0   \n",
       "\n",
       "      Month50_std_30  Month50_sum_90  Month50_mean_90  Month50_max_90  \\\n",
       "502              0.0             0.0              0.0             0.0   \n",
       "6547             0.0             0.0              0.0             0.0   \n",
       "6938             0.0             8.0              8.0             8.0   \n",
       "3115             0.0             0.0              0.0             0.0   \n",
       "3649             0.0             0.0              0.0             0.0   \n",
       "\n",
       "      Month50_min_90  Month50_std_90  Month50_sum_360  Month50_min_360  \\\n",
       "502              0.0             0.0             20.0             10.0   \n",
       "6547             0.0             0.0             54.0              7.0   \n",
       "6938             8.0             0.0             35.0              3.0   \n",
       "3115             0.0             0.0             19.0              9.0   \n",
       "3649             0.0             0.0             54.0              8.0   \n",
       "\n",
       "      Month50_std_360  Month50_sum_9999  Month50_mean_9999  Month50_max_9999  \\\n",
       "502          0.000000             239.0          10.863636              12.0   \n",
       "6547         1.939072             681.0          10.476923              12.0   \n",
       "6938         3.033150              35.0           7.000000              12.0   \n",
       "3115         0.500000              55.0          11.000000              12.0   \n",
       "3649         1.414214             165.0          10.312500              12.0   \n",
       "\n",
       "      Month50_min_9999  Month50_std_9999  Days_Past_Due58_max_30  \\\n",
       "502                3.0          2.095351                     0.0   \n",
       "6547               1.0          2.637643                     0.0   \n",
       "6938               3.0          3.033150                     0.0   \n",
       "3115               9.0          1.264911                     0.0   \n",
       "3649               4.0          2.310810                     0.0   \n",
       "\n",
       "      Days_Past_Due58_min_30  Days_Past_Due58_mean_90  Days_Past_Due58_max_90  \\\n",
       "502                      0.0                      0.0                     0.0   \n",
       "6547                     0.0                      0.0                     0.0   \n",
       "6938                     0.0                      0.0                     0.0   \n",
       "3115                     0.0                      0.0                     0.0   \n",
       "3649                     0.0                      0.0                     0.0   \n",
       "\n",
       "      Days_Past_Due58_min_90  Days_Past_Due58_std_90  Days_Past_Due58_sum_360  \\\n",
       "502                      0.0                     0.0                      0.0   \n",
       "6547                     0.0                     0.0                    389.0   \n",
       "6938                     0.0                     0.0                     26.0   \n",
       "3115                     0.0                     0.0                      0.0   \n",
       "3649                     0.0                     0.0                     23.0   \n",
       "\n",
       "      Days_Past_Due58_mean_360  Days_Past_Due58_max_360  ...  948707_lgb  \\\n",
       "502                   0.000000                      0.0  ...           0   \n",
       "6547                 77.800000                    206.0  ...           0   \n",
       "6938                  5.200000                     26.0  ...           0   \n",
       "3115                  0.000000                      0.0  ...           0   \n",
       "3649                  3.833333                     22.0  ...           0   \n",
       "\n",
       "      949440_lgb  949441_lgb  949442_lgb  949443_lgb  949444_lgb  950176_lgb  \\\n",
       "502            0           0           1           0           0           1   \n",
       "6547           1           0           0           0           0           0   \n",
       "6938           1           0           0           0           0           0   \n",
       "3115           1           0           0           0           0           1   \n",
       "3649           0           0           1           0           0           1   \n",
       "\n",
       "      950177_lgb  950178_lgb  950179_lgb  950180_lgb  950181_lgb  950182_lgb  \\\n",
       "502            0           0           0           0           0           0   \n",
       "6547           0           0           1           0           0           0   \n",
       "6938           0           0           0           1           0           0   \n",
       "3115           0           0           0           0           0           0   \n",
       "3649           0           0           0           0           0           0   \n",
       "\n",
       "      950912_lgb  950913_lgb  950914_lgb  950915_lgb  950916_lgb  951648_lgb  \\\n",
       "502            1           0           0           0           0           0   \n",
       "6547           1           0           0           0           0           0   \n",
       "6938           0           0           1           0           0           0   \n",
       "3115           1           0           0           0           0           0   \n",
       "3649           0           0           0           1           0           1   \n",
       "\n",
       "      951649_lgb  951650_lgb  951651_lgb  951652_lgb  952384_lgb  952385_lgb  \\\n",
       "502            1           0           0           0           0           1   \n",
       "6547           0           1           0           0           0           0   \n",
       "6938           0           0           1           0           0           0   \n",
       "3115           1           0           0           0           0           1   \n",
       "3649           0           0           0           0           0           0   \n",
       "\n",
       "      952386_lgb  952387_lgb  953120_lgb  953121_lgb  953122_lgb  953123_lgb  \\\n",
       "502            0           0           0           0           0           1   \n",
       "6547           1           0           1           0           0           0   \n",
       "6938           1           0           0           0           0           1   \n",
       "3115           0           0           0           0           0           1   \n",
       "3649           0           1           0           0           1           0   \n",
       "\n",
       "      953856_lgb  953857_lgb  953858_lgb  953859_lgb  954592_lgb  954593_lgb  \\\n",
       "502            1           0           0           0           1           0   \n",
       "6547           0           0           1           0           0           0   \n",
       "6938           1           0           0           0           1           0   \n",
       "3115           1           0           0           0           1           0   \n",
       "3649           0           0           1           0           0           0   \n",
       "\n",
       "      954594_lgb  955328_lgb  955329_lgb  955330_lgb  955331_lgb  955332_lgb  \\\n",
       "502            0           1           0           0           0           0   \n",
       "6547           1           1           0           0           0           0   \n",
       "6938           0           1           0           0           0           0   \n",
       "3115           0           0           0           1           0           0   \n",
       "3649           1           1           0           0           0           0   \n",
       "\n",
       "      956064_lgb  956065_lgb  956066_lgb  956067_lgb  956068_lgb  956069_lgb  \\\n",
       "502            0           1           0           0           0           0   \n",
       "6547           0           0           1           0           0           0   \n",
       "6938           1           0           0           0           0           0   \n",
       "3115           0           1           0           0           0           0   \n",
       "3649           1           0           0           0           0           0   \n",
       "\n",
       "      956800_lgb  956801_lgb  957536_lgb  957537_lgb  957538_lgb  957539_lgb  \\\n",
       "502            1           0           1           0           0           0   \n",
       "6547           0           1           0           1           0           0   \n",
       "6938           1           0           0           1           0           0   \n",
       "3115           1           0           0           0           0           1   \n",
       "3649           0           1           0           0           0           1   \n",
       "\n",
       "      958272_lgb  958273_lgb  958274_lgb  958275_lgb  959008_lgb  959009_lgb  \\\n",
       "502            0           0           0           1           0           1   \n",
       "6547           0           0           0           1           1           0   \n",
       "6938           0           1           0           0           0           1   \n",
       "3115           0           0           0           1           0           1   \n",
       "3649           0           0           0           1           0           0   \n",
       "\n",
       "      959010_lgb  959744_lgb  959745_lgb  959746_lgb  959747_lgb  959748_lgb  \\\n",
       "502            0           0           1           0           0           0   \n",
       "6547           0           0           1           0           0           0   \n",
       "6938           0           0           0           0           0           0   \n",
       "3115           0           0           0           0           1           0   \n",
       "3649           1           0           0           0           0           0   \n",
       "\n",
       "      959749_lgb  959750_lgb  960480_lgb  960481_lgb  960482_lgb  960483_lgb  \\\n",
       "502            0           0           0           0           1           0   \n",
       "6547           0           0           0           0           1           0   \n",
       "6938           1           0           0           0           0           0   \n",
       "3115           0           0           0           1           0           0   \n",
       "3649           1           0           0           1           0           0   \n",
       "\n",
       "      960484_lgb  960485_lgb  961216_lgb  961217_lgb  961218_lgb  961219_lgb  \\\n",
       "502            0           0           0           1           0           0   \n",
       "6547           0           0           0           1           0           0   \n",
       "6938           1           0           0           0           0           1   \n",
       "3115           0           0           1           0           0           0   \n",
       "3649           0           0           0           1           0           0   \n",
       "\n",
       "      961220_lgb  961952_lgb  961953_lgb  961954_lgb  961955_lgb  961956_lgb  \\\n",
       "502            0           0           0           0           0           1   \n",
       "6547           0           0           0           1           0           0   \n",
       "6938           0           0           0           0           0           1   \n",
       "3115           0           1           0           0           0           0   \n",
       "3649           0           0           0           1           0           0   \n",
       "\n",
       "      961957_lgb  962688_lgb  962689_lgb  962690_lgb  963424_lgb  963425_lgb  \\\n",
       "502            0           0           1           0           0           0   \n",
       "6547           0           0           1           0           1           0   \n",
       "6938           0           0           0           1           1           0   \n",
       "3115           0           0           1           0           1           0   \n",
       "3649           0           0           1           0           0           0   \n",
       "\n",
       "      963426_lgb  963427_lgb  964160_lgb  964161_lgb  964162_lgb  964163_lgb  \\\n",
       "502            0           1           0           0           0           1   \n",
       "6547           0           0           1           0           0           0   \n",
       "6938           0           0           0           1           0           0   \n",
       "3115           0           0           1           0           0           0   \n",
       "3649           1           0           1           0           0           0   \n",
       "\n",
       "      964896_lgb  964897_lgb  964898_lgb  965632_lgb  965633_lgb  965634_lgb  \\\n",
       "502            1           0           0           0           1           0   \n",
       "6547           0           0           1           1           0           0   \n",
       "6938           1           0           0           0           1           0   \n",
       "3115           1           0           0           0           1           0   \n",
       "3649           0           0           1           0           0           1   \n",
       "\n",
       "      966368_lgb  966369_lgb  966370_lgb  966371_lgb  966372_lgb  967104_lgb  \\\n",
       "502            0           0           1           0           0           0   \n",
       "6547           0           0           1           0           0           0   \n",
       "6938           1           0           0           0           0           0   \n",
       "3115           0           0           1           0           0           0   \n",
       "3649           0           0           0           1           0           0   \n",
       "\n",
       "      967105_lgb  967106_lgb  967107_lgb  967108_lgb  967109_lgb  967110_lgb  \\\n",
       "502            0           0           0           0           1           0   \n",
       "6547           0           0           0           0           1           0   \n",
       "6938           0           0           1           0           0           0   \n",
       "3115           0           0           0           1           0           0   \n",
       "3649           0           0           1           0           0           0   \n",
       "\n",
       "      967840_lgb  967841_lgb  967842_lgb  968576_lgb  968577_lgb  968578_lgb  \\\n",
       "502            0           0           1           0           0           1   \n",
       "6547           0           1           0           0           0           1   \n",
       "6938           0           1           0           1           0           0   \n",
       "3115           0           1           0           0           0           1   \n",
       "3649           0           0           1           0           0           1   \n",
       "\n",
       "      968579_lgb  969312_lgb  969313_lgb  969314_lgb  969315_lgb  970048_lgb  \\\n",
       "502            0           1           0           0           0           0   \n",
       "6547           0           0           1           0           0           1   \n",
       "6938           0           0           1           0           0           0   \n",
       "3115           0           1           0           0           0           0   \n",
       "3649           0           0           0           0           1           0   \n",
       "\n",
       "      970049_lgb  970050_lgb  970051_lgb  970784_lgb  970785_lgb  970786_lgb  \\\n",
       "502            0           0           1           0           0           1   \n",
       "6547           0           0           0           0           0           0   \n",
       "6938           0           0           1           0           1           0   \n",
       "3115           0           0           1           0           1           0   \n",
       "3649           0           1           0           0           1           0   \n",
       "\n",
       "      970787_lgb  970788_lgb  971520_lgb  971521_lgb  971522_lgb  971523_lgb  \\\n",
       "502            0           0           0           0           0           1   \n",
       "6547           0           1           0           0           0           0   \n",
       "6938           0           0           0           1           0           0   \n",
       "3115           0           0           0           1           0           0   \n",
       "3649           0           0           1           0           0           0   \n",
       "\n",
       "      971524_lgb  971525_lgb  971526_lgb  972256_lgb  972257_lgb  972258_lgb  \\\n",
       "502            0           0           0           0           0           0   \n",
       "6547           0           0           1           0           0           1   \n",
       "6938           0           0           0           0           0           1   \n",
       "3115           0           0           0           1           0           0   \n",
       "3649           0           0           0           0           0           1   \n",
       "\n",
       "      972259_lgb  972260_lgb  972261_lgb  972992_lgb  972993_lgb  972994_lgb  \\\n",
       "502            0           1           0           0           0           1   \n",
       "6547           0           0           0           0           0           1   \n",
       "6938           0           0           0           1           0           0   \n",
       "3115           0           0           0           0           0           1   \n",
       "3649           0           0           0           0           0           1   \n",
       "\n",
       "      972995_lgb  973728_lgb  973729_lgb  973730_lgb  973731_lgb  973732_lgb  \\\n",
       "502            0           0           0           0           0           0   \n",
       "6547           0           0           0           0           0           0   \n",
       "6938           0           0           0           0           1           0   \n",
       "3115           0           0           0           0           1           0   \n",
       "3649           0           0           0           0           1           0   \n",
       "\n",
       "      973733_lgb  973734_lgb  974464_lgb  974465_lgb  974466_lgb  974467_lgb  \\\n",
       "502            0           1           0           0           0           0   \n",
       "6547           0           1           0           0           0           0   \n",
       "6938           0           0           0           0           1           0   \n",
       "3115           0           0           0           0           0           0   \n",
       "3649           0           0           0           0           0           0   \n",
       "\n",
       "      974468_lgb  974469_lgb  974470_lgb  975200_lgb  975201_lgb  975936_lgb  \\\n",
       "502            1           0           0           0           1           0   \n",
       "6547           0           1           0           0           1           0   \n",
       "6938           0           0           0           1           0           0   \n",
       "3115           1           0           0           1           0           1   \n",
       "3649           0           1           0           1           0           0   \n",
       "\n",
       "      975937_lgb  975938_lgb  975939_lgb  976672_lgb  976673_lgb  976674_lgb  \\\n",
       "502            0           0           1           0           1           0   \n",
       "6547           0           1           0           0           1           0   \n",
       "6938           0           0           1           0           0           0   \n",
       "3115           0           0           0           0           0           0   \n",
       "3649           0           1           0           0           0           0   \n",
       "\n",
       "      976675_lgb  976676_lgb  976677_lgb  977408_lgb  977409_lgb  977410_lgb  \\\n",
       "502            0           0           0           0           0           0   \n",
       "6547           0           0           0           0           0           0   \n",
       "6938           0           0           1           0           0           1   \n",
       "3115           1           0           0           0           0           1   \n",
       "3649           0           0           1           0           0           0   \n",
       "\n",
       "      977411_lgb  977412_lgb  978144_lgb  978145_lgb  978146_lgb  978147_lgb  \\\n",
       "502            0           1           0           0           1           0   \n",
       "6547           1           0           1           0           0           0   \n",
       "6938           0           0           1           0           0           0   \n",
       "3115           0           0           1           0           0           0   \n",
       "3649           1           0           0           0           1           0   \n",
       "\n",
       "      978880_lgb  978881_lgb  978882_lgb  978883_lgb  979616_lgb  979617_lgb  \\\n",
       "502            0           0           1           0           1           0   \n",
       "6547           0           0           1           0           0           1   \n",
       "6938           0           1           0           0           0           1   \n",
       "3115           0           1           0           0           1           0   \n",
       "3649           0           1           0           0           1           0   \n",
       "\n",
       "      980352_lgb  980353_lgb  980354_lgb  980355_lgb  981088_lgb  981089_lgb  \\\n",
       "502            0           0           1           0           0           0   \n",
       "6547           0           0           0           1           0           0   \n",
       "6938           1           0           0           0           1           0   \n",
       "3115           1           0           0           0           1           0   \n",
       "3649           1           0           0           0           0           0   \n",
       "\n",
       "      981090_lgb  981091_lgb  981092_lgb  981824_lgb  981825_lgb  981826_lgb  \\\n",
       "502            0           0           1           1           0           0   \n",
       "6547           0           1           0           1           0           0   \n",
       "6938           0           0           0           0           0           0   \n",
       "3115           0           0           0           1           0           0   \n",
       "3649           0           1           0           1           0           0   \n",
       "\n",
       "      981827_lgb  982560_lgb  982561_lgb  982562_lgb  983296_lgb  983297_lgb  \\\n",
       "502            0           1           0           0           0           1   \n",
       "6547           0           1           0           0           0           1   \n",
       "6938           1           0           0           1           0           0   \n",
       "3115           0           1           0           0           0           0   \n",
       "3649           0           0           0           1           1           0   \n",
       "\n",
       "      983298_lgb  983299_lgb  983300_lgb  983301_lgb  984032_lgb  984033_lgb  \\\n",
       "502            0           0           0           0           1           0   \n",
       "6547           0           0           0           0           1           0   \n",
       "6938           0           1           0           0           1           0   \n",
       "3115           0           1           0           0           1           0   \n",
       "3649           0           0           0           0           1           0   \n",
       "\n",
       "      984034_lgb  984768_lgb  984769_lgb  984770_lgb  985504_lgb  985505_lgb  \\\n",
       "502            0           0           0           1           0           0   \n",
       "6547           0           0           0           1           0           0   \n",
       "6938           0           0           0           1           0           0   \n",
       "3115           0           0           0           1           0           0   \n",
       "3649           0           0           0           1           0           0   \n",
       "\n",
       "      985506_lgb  985507_lgb  985508_lgb  986240_lgb  986241_lgb  986242_lgb  \\\n",
       "502            0           1           0           1           0           0   \n",
       "6547           1           0           0           0           0           1   \n",
       "6938           1           0           0           1           0           0   \n",
       "3115           1           0           0           1           0           0   \n",
       "3649           0           1           0           0           0           1   \n",
       "\n",
       "      986976_lgb  986977_lgb  986978_lgb  987712_lgb  987713_lgb  987714_lgb  \\\n",
       "502            1           0           0           0           0           0   \n",
       "6547           1           0           0           1           0           0   \n",
       "6938           0           0           1           1           0           0   \n",
       "3115           1           0           0           0           0           1   \n",
       "3649           0           0           1           0           0           1   \n",
       "\n",
       "      987715_lgb  987716_lgb  988448_lgb  988449_lgb  988450_lgb  988451_lgb  \\\n",
       "502            1           0           0           0           1           0   \n",
       "6547           0           0           1           0           0           0   \n",
       "6938           0           0           0           0           0           1   \n",
       "3115           0           0           1           0           0           0   \n",
       "3649           0           0           0           0           1           0   \n",
       "\n",
       "      989184_lgb  989185_lgb  989186_lgb  989187_lgb  989920_lgb  989921_lgb  \\\n",
       "502            1           0           0           0           0           0   \n",
       "6547           0           0           0           1           1           0   \n",
       "6938           0           0           1           0           1           0   \n",
       "3115           1           0           0           0           1           0   \n",
       "3649           0           0           0           1           0           0   \n",
       "\n",
       "      989922_lgb  989923_lgb  989924_lgb  989925_lgb  990656_lgb  990657_lgb  \\\n",
       "502            0           0           0           1           0           0   \n",
       "6547           0           0           0           0           0           0   \n",
       "6938           0           0           0           0           0           0   \n",
       "3115           0           0           0           0           0           0   \n",
       "3649           0           0           1           0           0           0   \n",
       "\n",
       "      990658_lgb  990659_lgb  991392_lgb  991393_lgb  991394_lgb  991395_lgb  \\\n",
       "502            1           0           1           0           0           0   \n",
       "6547           1           0           0           0           0           1   \n",
       "6938           1           0           0           0           1           0   \n",
       "3115           1           0           1           0           0           0   \n",
       "3649           1           0           0           0           0           1   \n",
       "\n",
       "      992128_lgb  992129_lgb  992130_lgb  992864_lgb  992865_lgb  992866_lgb  \\\n",
       "502            1           0           0           1           0           0   \n",
       "6547           0           0           1           0           0           1   \n",
       "6938           1           0           0           1           0           0   \n",
       "3115           1           0           0           1           0           0   \n",
       "3649           0           0           1           0           0           1   \n",
       "\n",
       "      992867_lgb  993600_lgb  993601_lgb  993602_lgb  993603_lgb  994336_lgb  \\\n",
       "502            0           1           0           0           0           1   \n",
       "6547           0           1           0           0           0           1   \n",
       "6938           0           0           0           0           1           1   \n",
       "3115           0           1           0           0           0           1   \n",
       "3649           0           0           0           0           1           1   \n",
       "\n",
       "      994337_lgb  994338_lgb  994339_lgb  995072_lgb  995073_lgb  995074_lgb  \\\n",
       "502            0           0           0           0           0           0   \n",
       "6547           0           0           0           0           1           0   \n",
       "6938           0           0           0           0           1           0   \n",
       "3115           0           0           0           0           0           0   \n",
       "3649           0           0           0           0           0           0   \n",
       "\n",
       "      995075_lgb  995076_lgb  995808_lgb  995809_lgb  995810_lgb  995811_lgb  \\\n",
       "502            1           0           1           0           0           0   \n",
       "6547           0           0           0           0           1           0   \n",
       "6938           0           0           0           0           1           0   \n",
       "3115           1           0           1           0           0           0   \n",
       "3649           1           0           0           0           1           0   \n",
       "\n",
       "      995812_lgb  996544_lgb  996545_lgb  996546_lgb  997280_lgb  997281_lgb  \\\n",
       "502            0           1           0           0           0           0   \n",
       "6547           0           0           0           1           0           0   \n",
       "6938           0           0           0           1           0           0   \n",
       "3115           0           1           0           0           0           0   \n",
       "3649           0           0           0           1           0           0   \n",
       "\n",
       "      997282_lgb  997283_lgb  997284_lgb  998016_lgb  998017_lgb  998018_lgb  \\\n",
       "502            0           1           0           0           0           0   \n",
       "6547           1           0           0           0           0           1   \n",
       "6938           1           0           0           1           0           0   \n",
       "3115           1           0           0           0           0           0   \n",
       "3649           0           1           0           1           0           0   \n",
       "\n",
       "      998019_lgb  998752_lgb  998753_lgb  998754_lgb  998755_lgb  \n",
       "502            1           0           0           1           0  \n",
       "6547           0           1           0           0           0  \n",
       "6938           0           1           0           0           0  \n",
       "3115           1           1           0           0           0  \n",
       "3649           0           0           0           0           1  \n",
       "\n",
       "[5 rows x 9030 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6136, 9030)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BureauScore</th>\n",
       "      <th>MissingRate</th>\n",
       "      <th>Len_Name</th>\n",
       "      <th>Tel_nuniq</th>\n",
       "      <th>Email_nuniq</th>\n",
       "      <th>Len_of_addrs</th>\n",
       "      <th>City_nuniq</th>\n",
       "      <th>Current_State</th>\n",
       "      <th>CreditAccountActive</th>\n",
       "      <th>CreditAccountTotal</th>\n",
       "      <th>CreditAccountActivePor</th>\n",
       "      <th>Outstanding_Balance_Secured</th>\n",
       "      <th>Outstanding_Balance_UnSecured_Percentage</th>\n",
       "      <th>Outstanding_Balance_All</th>\n",
       "      <th>Outstanding_Balance_Secured_Percentage</th>\n",
       "      <th>Outstanding_Balance_UnSecured</th>\n",
       "      <th>Diff_dateBirth</th>\n",
       "      <th>State_nuniq</th>\n",
       "      <th>Birth_nuniq</th>\n",
       "      <th>TotalCAPSLast90Days</th>\n",
       "      <th>TotalCAPSLast7Days</th>\n",
       "      <th>TotalCAPSLast30Days</th>\n",
       "      <th>TotalCAPSLast180Days</th>\n",
       "      <th>CAPSLast30Days</th>\n",
       "      <th>CAPSLast7Days</th>\n",
       "      <th>CAPSLast180Days</th>\n",
       "      <th>NonCreditCAPSLast180Days</th>\n",
       "      <th>Pin_nuniq</th>\n",
       "      <th>Pan_nuniq</th>\n",
       "      <th>Ident_nuniq</th>\n",
       "      <th>Name_nuniq2</th>\n",
       "      <th>Tel_nuniq2</th>\n",
       "      <th>Email_nuniq2</th>\n",
       "      <th>Pan_nuniq2</th>\n",
       "      <th>Account_nuniq2</th>\n",
       "      <th>Ident_nuniq2</th>\n",
       "      <th>Gender_nuniq</th>\n",
       "      <th>Amount_Past_Due35_sum_30</th>\n",
       "      <th>Amount_Past_Due35_min_30</th>\n",
       "      <th>Amount_Past_Due35_sum_90</th>\n",
       "      <th>Amount_Past_Due35_mean_90</th>\n",
       "      <th>Amount_Past_Due35_max_90</th>\n",
       "      <th>Amount_Past_Due35_min_90</th>\n",
       "      <th>Amount_Past_Due35_std_90</th>\n",
       "      <th>Amount_Past_Due35_sum_360</th>\n",
       "      <th>Amount_Past_Due35_mean_360</th>\n",
       "      <th>Amount_Past_Due35_max_360</th>\n",
       "      <th>Amount_Past_Due35_std_360</th>\n",
       "      <th>Amount_Past_Due35_sum_9999</th>\n",
       "      <th>Amount_Past_Due35_max_9999</th>\n",
       "      <th>Amount_Past_Due35_min_9999</th>\n",
       "      <th>Amount_Past_Due35_std_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_9999</th>\n",
       "      <th>Terms_Duration34_sum_30</th>\n",
       "      <th>Terms_Duration34_std_30</th>\n",
       "      <th>Terms_Duration34_sum_90</th>\n",
       "      <th>Terms_Duration34_std_90</th>\n",
       "      <th>Terms_Duration34_mean_360</th>\n",
       "      <th>Terms_Duration34_max_360</th>\n",
       "      <th>Terms_Duration34_min_360</th>\n",
       "      <th>Terms_Duration34_std_360</th>\n",
       "      <th>Terms_Duration34_sum_9999</th>\n",
       "      <th>Terms_Duration34_mean_9999</th>\n",
       "      <th>Terms_Duration34_max_9999</th>\n",
       "      <th>Terms_Duration34_min_9999</th>\n",
       "      <th>Terms_Duration34_std_9999</th>\n",
       "      <th>Payment_Rating34_sum_90</th>\n",
       "      <th>Payment_Rating34_mean_90</th>\n",
       "      <th>Payment_Rating34_max_90</th>\n",
       "      <th>Payment_Rating34_min_90</th>\n",
       "      <th>Payment_Rating34_std_90</th>\n",
       "      <th>Payment_Rating34_sum_360</th>\n",
       "      <th>Payment_Rating34_mean_360</th>\n",
       "      <th>Payment_Rating34_max_360</th>\n",
       "      <th>Payment_Rating34_min_360</th>\n",
       "      <th>Payment_Rating34_std_360</th>\n",
       "      <th>Payment_Rating34_sum_9999</th>\n",
       "      <th>Payment_Rating34_mean_9999</th>\n",
       "      <th>Payment_Rating34_max_9999</th>\n",
       "      <th>Payment_Rating34_min_9999</th>\n",
       "      <th>Payment_Rating34_std_9999</th>\n",
       "      <th>Current_Balance35_mean_30</th>\n",
       "      <th>Current_Balance35_min_30</th>\n",
       "      <th>Current_Balance35_std_30</th>\n",
       "      <th>Current_Balance35_sum_90</th>\n",
       "      <th>Current_Balance35_mean_90</th>\n",
       "      <th>Current_Balance35_max_90</th>\n",
       "      <th>Current_Balance35_std_90</th>\n",
       "      <th>Current_Balance35_sum_360</th>\n",
       "      <th>Current_Balance35_max_360</th>\n",
       "      <th>Current_Balance35_std_360</th>\n",
       "      <th>Current_Balance35_max_9999</th>\n",
       "      <th>Current_Balance35_std_9999</th>\n",
       "      <th>Settlement_Amount37_max_360</th>\n",
       "      <th>Settlement_Amount37_min_360</th>\n",
       "      <th>Settlement_Amount37_std_360</th>\n",
       "      <th>Settlement_Amount37_sum_9999</th>\n",
       "      <th>Settlement_Amount37_mean_9999</th>\n",
       "      <th>Settlement_Amount37_max_9999</th>\n",
       "      <th>Settlement_Amount37_min_9999</th>\n",
       "      <th>Settlement_Amount37_std_9999</th>\n",
       "      <th>Value_of_Collateral39_std_90</th>\n",
       "      <th>Value_of_Collateral39_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_360</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_360</th>\n",
       "      <th>Written_Off_Amt_Total41_min_360</th>\n",
       "      <th>Written_Off_Amt_Total41_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_max_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_min_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_std_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_mean_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_std_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_max_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_9999</th>\n",
       "      <th>Rate_of_Interest36_sum_30</th>\n",
       "      <th>Rate_of_Interest36_std_30</th>\n",
       "      <th>Rate_of_Interest36_sum_90</th>\n",
       "      <th>Rate_of_Interest36_mean_90</th>\n",
       "      <th>Rate_of_Interest36_max_90</th>\n",
       "      <th>Rate_of_Interest36_std_90</th>\n",
       "      <th>Rate_of_Interest36_sum_360</th>\n",
       "      <th>Rate_of_Interest36_mean_360</th>\n",
       "      <th>Rate_of_Interest36_max_360</th>\n",
       "      <th>Rate_of_Interest36_min_360</th>\n",
       "      <th>Rate_of_Interest36_std_360</th>\n",
       "      <th>Rate_of_Interest36_sum_9999</th>\n",
       "      <th>Rate_of_Interest36_mean_9999</th>\n",
       "      <th>Rate_of_Interest36_max_9999</th>\n",
       "      <th>Rate_of_Interest36_min_9999</th>\n",
       "      <th>Rate_of_Interest36_std_9999</th>\n",
       "      <th>Repayment_Tenure36_std_30</th>\n",
       "      <th>Repayment_Tenure36_mean_90</th>\n",
       "      <th>Repayment_Tenure36_max_90</th>\n",
       "      <th>Repayment_Tenure36_min_90</th>\n",
       "      <th>Repayment_Tenure36_std_90</th>\n",
       "      <th>Repayment_Tenure36_sum_360</th>\n",
       "      <th>Repayment_Tenure36_mean_360</th>\n",
       "      <th>Repayment_Tenure36_min_360</th>\n",
       "      <th>Repayment_Tenure36_std_360</th>\n",
       "      <th>Repayment_Tenure36_mean_9999</th>\n",
       "      <th>Repayment_Tenure36_min_9999</th>\n",
       "      <th>Repayment_Tenure36_std_9999</th>\n",
       "      <th>Income26_count_360</th>\n",
       "      <th>Income26_std_360</th>\n",
       "      <th>Open_Date29_max_30</th>\n",
       "      <th>Open_Date29_min_30</th>\n",
       "      <th>Open_Date29_mean_30</th>\n",
       "      <th>Open_Date29_nuniq_30</th>\n",
       "      <th>Open_Date29_maxcount_30</th>\n",
       "      <th>Open_Date29_max_90</th>\n",
       "      <th>Open_Date29_mean_90</th>\n",
       "      <th>Open_Date29_mode_90</th>\n",
       "      <th>Open_Date29_nuniq_90</th>\n",
       "      <th>Open_Date29_maxcount_90</th>\n",
       "      <th>Open_Date29_max_360</th>\n",
       "      <th>Open_Date29_mean_360</th>\n",
       "      <th>Open_Date29_mode_360</th>\n",
       "      <th>Open_Date29_nuniq_360</th>\n",
       "      <th>Open_Date29_maxcount_360</th>\n",
       "      <th>Open_Date29_max_9999</th>\n",
       "      <th>Open_Date29_mean_9999</th>\n",
       "      <th>Open_Date29_mode_9999</th>\n",
       "      <th>Open_Date29_maxcount_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_30</th>\n",
       "      <th>Portfolio_Type34_nuniq_90</th>\n",
       "      <th>Portfolio_Type34_nuniq_360</th>\n",
       "      <th>Portfolio_Type34_nuniq_9999</th>\n",
       "      <th>Account_Type32_nuniq_30</th>\n",
       "      <th>Account_Type32_nuniq_90</th>\n",
       "      <th>Account_Type32_nuniq_360</th>\n",
       "      <th>Account_Type32_nuniq_9999</th>\n",
       "      <th>Occupation_Code35_nuniq_30</th>\n",
       "      <th>Occupation_Code35_nuniq_90</th>\n",
       "      <th>Occupation_Code35_nuniq_360</th>\n",
       "      <th>Occupation_Code35_nuniq_9999</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_360</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_9999</th>\n",
       "      <th>Payment_History_Profile43_mode_30</th>\n",
       "      <th>Payment_History_Profile43_mode_90</th>\n",
       "      <th>Payment_History_Profile43_nuniq_90</th>\n",
       "      <th>Payment_History_Profile43_mode_360</th>\n",
       "      <th>Payment_History_Profile43_nuniq_360</th>\n",
       "      <th>Payment_History_Profile43_mode_9999</th>\n",
       "      <th>Payment_History_Profile43_nuniq_9999</th>\n",
       "      <th>Date_Closed31_nuniq_30</th>\n",
       "      <th>Date_Closed31_maxcount_30</th>\n",
       "      <th>Date_Closed31_max_90</th>\n",
       "      <th>Date_Closed31_min_90</th>\n",
       "      <th>Date_Closed31_mean_90</th>\n",
       "      <th>Date_Closed31_mode_90</th>\n",
       "      <th>Date_Closed31_nuniq_90</th>\n",
       "      <th>Date_Closed31_maxcount_90</th>\n",
       "      <th>Date_Closed31_min_360</th>\n",
       "      <th>Date_Closed31_mode_360</th>\n",
       "      <th>Date_Closed31_nuniq_360</th>\n",
       "      <th>Date_Closed31_maxcount_360</th>\n",
       "      <th>Date_Closed31_max_9999</th>\n",
       "      <th>Date_Closed31_min_9999</th>\n",
       "      <th>Date_Closed31_mean_9999</th>\n",
       "      <th>Date_Closed31_mode_9999</th>\n",
       "      <th>Date_Closed31_nuniq_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_30</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_30</th>\n",
       "      <th>Date_of_Last_Payment40_min_90</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_90</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_90</th>\n",
       "      <th>Date_of_Last_Payment40_max_360</th>\n",
       "      <th>Date_of_Last_Payment40_min_360</th>\n",
       "      <th>Date_of_Last_Payment40_mean_360</th>\n",
       "      <th>Date_of_Last_Payment40_mode_360</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_360</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_360</th>\n",
       "      <th>Date_of_Last_Payment40_max_9999</th>\n",
       "      <th>Date_of_Last_Payment40_min_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mean_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_9999</th>\n",
       "      <th>Date_Reported33_nuniq_30</th>\n",
       "      <th>Date_Reported33_max_90</th>\n",
       "      <th>Date_Reported33_mean_90</th>\n",
       "      <th>Date_Reported33_mode_90</th>\n",
       "      <th>Date_Reported33_nuniq_90</th>\n",
       "      <th>Date_Reported33_maxcount_90</th>\n",
       "      <th>Date_Reported33_max_360</th>\n",
       "      <th>Date_Reported33_mean_360</th>\n",
       "      <th>Date_Reported33_mode_360</th>\n",
       "      <th>Date_Reported33_nuniq_360</th>\n",
       "      <th>Date_Reported33_maxcount_360</th>\n",
       "      <th>Date_Reported33_max_9999</th>\n",
       "      <th>Date_Reported33_mean_9999</th>\n",
       "      <th>Date_Reported33_mode_9999</th>\n",
       "      <th>Date_Reported33_nuniq_9999</th>\n",
       "      <th>Date_Reported33_maxcount_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_30</th>\n",
       "      <th>DateOfAddition34_max_90</th>\n",
       "      <th>DateOfAddition34_mean_90</th>\n",
       "      <th>DateOfAddition34_mode_90</th>\n",
       "      <th>DateOfAddition34_nuniq_90</th>\n",
       "      <th>DateOfAddition34_maxcount_90</th>\n",
       "      <th>DateOfAddition34_max_360</th>\n",
       "      <th>DateOfAddition34_mean_360</th>\n",
       "      <th>DateOfAddition34_mode_360</th>\n",
       "      <th>DateOfAddition34_nuniq_360</th>\n",
       "      <th>DateOfAddition34_maxcount_360</th>\n",
       "      <th>DateOfAddition34_max_9999</th>\n",
       "      <th>DateOfAddition34_mean_9999</th>\n",
       "      <th>DateOfAddition34_mode_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_9999</th>\n",
       "      <th>DateOfAddition34_maxcount_9999</th>\n",
       "      <th>Account_Status34_mode_30</th>\n",
       "      <th>Account_Status34_nuniq_30</th>\n",
       "      <th>Account_Status34_mode_90</th>\n",
       "      <th>Account_Status34_nuniq_90</th>\n",
       "      <th>Account_Status34_mode_360</th>\n",
       "      <th>Account_Status34_nuniq_360</th>\n",
       "      <th>Account_Status34_nuniq_9999</th>\n",
       "      <th>Month50_sum_30</th>\n",
       "      <th>Month50_max_30</th>\n",
       "      <th>Month50_std_30</th>\n",
       "      <th>Month50_sum_90</th>\n",
       "      <th>Month50_mean_90</th>\n",
       "      <th>Month50_max_90</th>\n",
       "      <th>Month50_min_90</th>\n",
       "      <th>Month50_std_90</th>\n",
       "      <th>Month50_sum_360</th>\n",
       "      <th>Month50_min_360</th>\n",
       "      <th>Month50_std_360</th>\n",
       "      <th>Month50_sum_9999</th>\n",
       "      <th>Month50_mean_9999</th>\n",
       "      <th>Month50_max_9999</th>\n",
       "      <th>Month50_min_9999</th>\n",
       "      <th>Month50_std_9999</th>\n",
       "      <th>Days_Past_Due58_max_30</th>\n",
       "      <th>Days_Past_Due58_min_30</th>\n",
       "      <th>Days_Past_Due58_mean_90</th>\n",
       "      <th>Days_Past_Due58_max_90</th>\n",
       "      <th>Days_Past_Due58_min_90</th>\n",
       "      <th>Days_Past_Due58_std_90</th>\n",
       "      <th>Days_Past_Due58_sum_360</th>\n",
       "      <th>Days_Past_Due58_mean_360</th>\n",
       "      <th>Days_Past_Due58_max_360</th>\n",
       "      <th>...</th>\n",
       "      <th>948707_lgb</th>\n",
       "      <th>949440_lgb</th>\n",
       "      <th>949441_lgb</th>\n",
       "      <th>949442_lgb</th>\n",
       "      <th>949443_lgb</th>\n",
       "      <th>949444_lgb</th>\n",
       "      <th>950176_lgb</th>\n",
       "      <th>950177_lgb</th>\n",
       "      <th>950178_lgb</th>\n",
       "      <th>950179_lgb</th>\n",
       "      <th>950180_lgb</th>\n",
       "      <th>950181_lgb</th>\n",
       "      <th>950182_lgb</th>\n",
       "      <th>950912_lgb</th>\n",
       "      <th>950913_lgb</th>\n",
       "      <th>950914_lgb</th>\n",
       "      <th>950915_lgb</th>\n",
       "      <th>950916_lgb</th>\n",
       "      <th>951648_lgb</th>\n",
       "      <th>951649_lgb</th>\n",
       "      <th>951650_lgb</th>\n",
       "      <th>951651_lgb</th>\n",
       "      <th>951652_lgb</th>\n",
       "      <th>952384_lgb</th>\n",
       "      <th>952385_lgb</th>\n",
       "      <th>952386_lgb</th>\n",
       "      <th>952387_lgb</th>\n",
       "      <th>953120_lgb</th>\n",
       "      <th>953121_lgb</th>\n",
       "      <th>953122_lgb</th>\n",
       "      <th>953123_lgb</th>\n",
       "      <th>953856_lgb</th>\n",
       "      <th>953857_lgb</th>\n",
       "      <th>953858_lgb</th>\n",
       "      <th>953859_lgb</th>\n",
       "      <th>954592_lgb</th>\n",
       "      <th>954593_lgb</th>\n",
       "      <th>954594_lgb</th>\n",
       "      <th>955328_lgb</th>\n",
       "      <th>955329_lgb</th>\n",
       "      <th>955330_lgb</th>\n",
       "      <th>955331_lgb</th>\n",
       "      <th>955332_lgb</th>\n",
       "      <th>956064_lgb</th>\n",
       "      <th>956065_lgb</th>\n",
       "      <th>956066_lgb</th>\n",
       "      <th>956067_lgb</th>\n",
       "      <th>956068_lgb</th>\n",
       "      <th>956069_lgb</th>\n",
       "      <th>956800_lgb</th>\n",
       "      <th>956801_lgb</th>\n",
       "      <th>957536_lgb</th>\n",
       "      <th>957537_lgb</th>\n",
       "      <th>957538_lgb</th>\n",
       "      <th>957539_lgb</th>\n",
       "      <th>958272_lgb</th>\n",
       "      <th>958273_lgb</th>\n",
       "      <th>958274_lgb</th>\n",
       "      <th>958275_lgb</th>\n",
       "      <th>959008_lgb</th>\n",
       "      <th>959009_lgb</th>\n",
       "      <th>959010_lgb</th>\n",
       "      <th>959744_lgb</th>\n",
       "      <th>959745_lgb</th>\n",
       "      <th>959746_lgb</th>\n",
       "      <th>959747_lgb</th>\n",
       "      <th>959748_lgb</th>\n",
       "      <th>959749_lgb</th>\n",
       "      <th>959750_lgb</th>\n",
       "      <th>960480_lgb</th>\n",
       "      <th>960481_lgb</th>\n",
       "      <th>960482_lgb</th>\n",
       "      <th>960483_lgb</th>\n",
       "      <th>960484_lgb</th>\n",
       "      <th>960485_lgb</th>\n",
       "      <th>961216_lgb</th>\n",
       "      <th>961217_lgb</th>\n",
       "      <th>961218_lgb</th>\n",
       "      <th>961219_lgb</th>\n",
       "      <th>961220_lgb</th>\n",
       "      <th>961952_lgb</th>\n",
       "      <th>961953_lgb</th>\n",
       "      <th>961954_lgb</th>\n",
       "      <th>961955_lgb</th>\n",
       "      <th>961956_lgb</th>\n",
       "      <th>961957_lgb</th>\n",
       "      <th>962688_lgb</th>\n",
       "      <th>962689_lgb</th>\n",
       "      <th>962690_lgb</th>\n",
       "      <th>963424_lgb</th>\n",
       "      <th>963425_lgb</th>\n",
       "      <th>963426_lgb</th>\n",
       "      <th>963427_lgb</th>\n",
       "      <th>964160_lgb</th>\n",
       "      <th>964161_lgb</th>\n",
       "      <th>964162_lgb</th>\n",
       "      <th>964163_lgb</th>\n",
       "      <th>964896_lgb</th>\n",
       "      <th>964897_lgb</th>\n",
       "      <th>964898_lgb</th>\n",
       "      <th>965632_lgb</th>\n",
       "      <th>965633_lgb</th>\n",
       "      <th>965634_lgb</th>\n",
       "      <th>966368_lgb</th>\n",
       "      <th>966369_lgb</th>\n",
       "      <th>966370_lgb</th>\n",
       "      <th>966371_lgb</th>\n",
       "      <th>966372_lgb</th>\n",
       "      <th>967104_lgb</th>\n",
       "      <th>967105_lgb</th>\n",
       "      <th>967106_lgb</th>\n",
       "      <th>967107_lgb</th>\n",
       "      <th>967108_lgb</th>\n",
       "      <th>967109_lgb</th>\n",
       "      <th>967110_lgb</th>\n",
       "      <th>967840_lgb</th>\n",
       "      <th>967841_lgb</th>\n",
       "      <th>967842_lgb</th>\n",
       "      <th>968576_lgb</th>\n",
       "      <th>968577_lgb</th>\n",
       "      <th>968578_lgb</th>\n",
       "      <th>968579_lgb</th>\n",
       "      <th>969312_lgb</th>\n",
       "      <th>969313_lgb</th>\n",
       "      <th>969314_lgb</th>\n",
       "      <th>969315_lgb</th>\n",
       "      <th>970048_lgb</th>\n",
       "      <th>970049_lgb</th>\n",
       "      <th>970050_lgb</th>\n",
       "      <th>970051_lgb</th>\n",
       "      <th>970784_lgb</th>\n",
       "      <th>970785_lgb</th>\n",
       "      <th>970786_lgb</th>\n",
       "      <th>970787_lgb</th>\n",
       "      <th>970788_lgb</th>\n",
       "      <th>971520_lgb</th>\n",
       "      <th>971521_lgb</th>\n",
       "      <th>971522_lgb</th>\n",
       "      <th>971523_lgb</th>\n",
       "      <th>971524_lgb</th>\n",
       "      <th>971525_lgb</th>\n",
       "      <th>971526_lgb</th>\n",
       "      <th>972256_lgb</th>\n",
       "      <th>972257_lgb</th>\n",
       "      <th>972258_lgb</th>\n",
       "      <th>972259_lgb</th>\n",
       "      <th>972260_lgb</th>\n",
       "      <th>972261_lgb</th>\n",
       "      <th>972992_lgb</th>\n",
       "      <th>972993_lgb</th>\n",
       "      <th>972994_lgb</th>\n",
       "      <th>972995_lgb</th>\n",
       "      <th>973728_lgb</th>\n",
       "      <th>973729_lgb</th>\n",
       "      <th>973730_lgb</th>\n",
       "      <th>973731_lgb</th>\n",
       "      <th>973732_lgb</th>\n",
       "      <th>973733_lgb</th>\n",
       "      <th>973734_lgb</th>\n",
       "      <th>974464_lgb</th>\n",
       "      <th>974465_lgb</th>\n",
       "      <th>974466_lgb</th>\n",
       "      <th>974467_lgb</th>\n",
       "      <th>974468_lgb</th>\n",
       "      <th>974469_lgb</th>\n",
       "      <th>974470_lgb</th>\n",
       "      <th>975200_lgb</th>\n",
       "      <th>975201_lgb</th>\n",
       "      <th>975936_lgb</th>\n",
       "      <th>975937_lgb</th>\n",
       "      <th>975938_lgb</th>\n",
       "      <th>975939_lgb</th>\n",
       "      <th>976672_lgb</th>\n",
       "      <th>976673_lgb</th>\n",
       "      <th>976674_lgb</th>\n",
       "      <th>976675_lgb</th>\n",
       "      <th>976676_lgb</th>\n",
       "      <th>976677_lgb</th>\n",
       "      <th>977408_lgb</th>\n",
       "      <th>977409_lgb</th>\n",
       "      <th>977410_lgb</th>\n",
       "      <th>977411_lgb</th>\n",
       "      <th>977412_lgb</th>\n",
       "      <th>978144_lgb</th>\n",
       "      <th>978145_lgb</th>\n",
       "      <th>978146_lgb</th>\n",
       "      <th>978147_lgb</th>\n",
       "      <th>978880_lgb</th>\n",
       "      <th>978881_lgb</th>\n",
       "      <th>978882_lgb</th>\n",
       "      <th>978883_lgb</th>\n",
       "      <th>979616_lgb</th>\n",
       "      <th>979617_lgb</th>\n",
       "      <th>980352_lgb</th>\n",
       "      <th>980353_lgb</th>\n",
       "      <th>980354_lgb</th>\n",
       "      <th>980355_lgb</th>\n",
       "      <th>981088_lgb</th>\n",
       "      <th>981089_lgb</th>\n",
       "      <th>981090_lgb</th>\n",
       "      <th>981091_lgb</th>\n",
       "      <th>981092_lgb</th>\n",
       "      <th>981824_lgb</th>\n",
       "      <th>981825_lgb</th>\n",
       "      <th>981826_lgb</th>\n",
       "      <th>981827_lgb</th>\n",
       "      <th>982560_lgb</th>\n",
       "      <th>982561_lgb</th>\n",
       "      <th>982562_lgb</th>\n",
       "      <th>983296_lgb</th>\n",
       "      <th>983297_lgb</th>\n",
       "      <th>983298_lgb</th>\n",
       "      <th>983299_lgb</th>\n",
       "      <th>983300_lgb</th>\n",
       "      <th>983301_lgb</th>\n",
       "      <th>984032_lgb</th>\n",
       "      <th>984033_lgb</th>\n",
       "      <th>984034_lgb</th>\n",
       "      <th>984768_lgb</th>\n",
       "      <th>984769_lgb</th>\n",
       "      <th>984770_lgb</th>\n",
       "      <th>985504_lgb</th>\n",
       "      <th>985505_lgb</th>\n",
       "      <th>985506_lgb</th>\n",
       "      <th>985507_lgb</th>\n",
       "      <th>985508_lgb</th>\n",
       "      <th>986240_lgb</th>\n",
       "      <th>986241_lgb</th>\n",
       "      <th>986242_lgb</th>\n",
       "      <th>986976_lgb</th>\n",
       "      <th>986977_lgb</th>\n",
       "      <th>986978_lgb</th>\n",
       "      <th>987712_lgb</th>\n",
       "      <th>987713_lgb</th>\n",
       "      <th>987714_lgb</th>\n",
       "      <th>987715_lgb</th>\n",
       "      <th>987716_lgb</th>\n",
       "      <th>988448_lgb</th>\n",
       "      <th>988449_lgb</th>\n",
       "      <th>988450_lgb</th>\n",
       "      <th>988451_lgb</th>\n",
       "      <th>989184_lgb</th>\n",
       "      <th>989185_lgb</th>\n",
       "      <th>989186_lgb</th>\n",
       "      <th>989187_lgb</th>\n",
       "      <th>989920_lgb</th>\n",
       "      <th>989921_lgb</th>\n",
       "      <th>989922_lgb</th>\n",
       "      <th>989923_lgb</th>\n",
       "      <th>989924_lgb</th>\n",
       "      <th>989925_lgb</th>\n",
       "      <th>990656_lgb</th>\n",
       "      <th>990657_lgb</th>\n",
       "      <th>990658_lgb</th>\n",
       "      <th>990659_lgb</th>\n",
       "      <th>991392_lgb</th>\n",
       "      <th>991393_lgb</th>\n",
       "      <th>991394_lgb</th>\n",
       "      <th>991395_lgb</th>\n",
       "      <th>992128_lgb</th>\n",
       "      <th>992129_lgb</th>\n",
       "      <th>992130_lgb</th>\n",
       "      <th>992864_lgb</th>\n",
       "      <th>992865_lgb</th>\n",
       "      <th>992866_lgb</th>\n",
       "      <th>992867_lgb</th>\n",
       "      <th>993600_lgb</th>\n",
       "      <th>993601_lgb</th>\n",
       "      <th>993602_lgb</th>\n",
       "      <th>993603_lgb</th>\n",
       "      <th>994336_lgb</th>\n",
       "      <th>994337_lgb</th>\n",
       "      <th>994338_lgb</th>\n",
       "      <th>994339_lgb</th>\n",
       "      <th>995072_lgb</th>\n",
       "      <th>995073_lgb</th>\n",
       "      <th>995074_lgb</th>\n",
       "      <th>995075_lgb</th>\n",
       "      <th>995076_lgb</th>\n",
       "      <th>995808_lgb</th>\n",
       "      <th>995809_lgb</th>\n",
       "      <th>995810_lgb</th>\n",
       "      <th>995811_lgb</th>\n",
       "      <th>995812_lgb</th>\n",
       "      <th>996544_lgb</th>\n",
       "      <th>996545_lgb</th>\n",
       "      <th>996546_lgb</th>\n",
       "      <th>997280_lgb</th>\n",
       "      <th>997281_lgb</th>\n",
       "      <th>997282_lgb</th>\n",
       "      <th>997283_lgb</th>\n",
       "      <th>997284_lgb</th>\n",
       "      <th>998016_lgb</th>\n",
       "      <th>998017_lgb</th>\n",
       "      <th>998018_lgb</th>\n",
       "      <th>998019_lgb</th>\n",
       "      <th>998752_lgb</th>\n",
       "      <th>998753_lgb</th>\n",
       "      <th>998754_lgb</th>\n",
       "      <th>998755_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.0</td>\n",
       "      <td>6136.0</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.00000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6.136000e+03</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.00000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.0</td>\n",
       "      <td>6136.0</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.00000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.00000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "      <td>6136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.420795</td>\n",
       "      <td>0.421178</td>\n",
       "      <td>22.779172</td>\n",
       "      <td>7.969912</td>\n",
       "      <td>10.862148</td>\n",
       "      <td>45.197849</td>\n",
       "      <td>2.929406</td>\n",
       "      <td>27.316167</td>\n",
       "      <td>5.048240</td>\n",
       "      <td>17.680248</td>\n",
       "      <td>0.410867</td>\n",
       "      <td>2.321834e+05</td>\n",
       "      <td>59.145860</td>\n",
       "      <td>4.066165e+05</td>\n",
       "      <td>24.629726</td>\n",
       "      <td>1.480976e+05</td>\n",
       "      <td>11379.437256</td>\n",
       "      <td>11.039039</td>\n",
       "      <td>12.567700</td>\n",
       "      <td>4.516949</td>\n",
       "      <td>2.317797</td>\n",
       "      <td>3.073990</td>\n",
       "      <td>6.113429</td>\n",
       "      <td>1.310952</td>\n",
       "      <td>0.554759</td>\n",
       "      <td>4.350391</td>\n",
       "      <td>1.763038</td>\n",
       "      <td>8.711713</td>\n",
       "      <td>44.733145</td>\n",
       "      <td>6.755132</td>\n",
       "      <td>149.206160</td>\n",
       "      <td>45.671610</td>\n",
       "      <td>72.427314</td>\n",
       "      <td>15.206812</td>\n",
       "      <td>13.340613</td>\n",
       "      <td>35.103977</td>\n",
       "      <td>25.107241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239.247718</td>\n",
       "      <td>112.860324</td>\n",
       "      <td>224.198338</td>\n",
       "      <td>56.888690</td>\n",
       "      <td>74.066450</td>\n",
       "      <td>3.863638e+03</td>\n",
       "      <td>1.055790e+03</td>\n",
       "      <td>2.768069e+03</td>\n",
       "      <td>688.673144</td>\n",
       "      <td>3.608857e+04</td>\n",
       "      <td>2.288015e+04</td>\n",
       "      <td>233.071219</td>\n",
       "      <td>5.873529e+03</td>\n",
       "      <td>1842.499185</td>\n",
       "      <td>1400.405965</td>\n",
       "      <td>214.083346</td>\n",
       "      <td>3.913422e+04</td>\n",
       "      <td>1.803476e+04</td>\n",
       "      <td>2.751901e+04</td>\n",
       "      <td>1.215874e+04</td>\n",
       "      <td>6.657990e+03</td>\n",
       "      <td>1.886931e+05</td>\n",
       "      <td>1.048791e+05</td>\n",
       "      <td>3.124546e+04</td>\n",
       "      <td>8.613151e+05</td>\n",
       "      <td>5.927062e+04</td>\n",
       "      <td>3.116380e+05</td>\n",
       "      <td>8.097116e+04</td>\n",
       "      <td>0.237940</td>\n",
       "      <td>0.007241</td>\n",
       "      <td>4.366281</td>\n",
       "      <td>0.524265</td>\n",
       "      <td>6.179949</td>\n",
       "      <td>10.443041</td>\n",
       "      <td>4.156943</td>\n",
       "      <td>2.490091</td>\n",
       "      <td>71.124185</td>\n",
       "      <td>12.628921</td>\n",
       "      <td>31.290580</td>\n",
       "      <td>5.609599</td>\n",
       "      <td>8.824554</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.005541</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.561278</td>\n",
       "      <td>0.129771</td>\n",
       "      <td>0.339472</td>\n",
       "      <td>0.053781</td>\n",
       "      <td>0.107031</td>\n",
       "      <td>3.468220</td>\n",
       "      <td>0.293677</td>\n",
       "      <td>1.407106</td>\n",
       "      <td>0.050359</td>\n",
       "      <td>0.433595</td>\n",
       "      <td>1549.319540</td>\n",
       "      <td>1347.766786</td>\n",
       "      <td>202.630012</td>\n",
       "      <td>3.102545e+04</td>\n",
       "      <td>1.616508e+04</td>\n",
       "      <td>2.623001e+04</td>\n",
       "      <td>6.855102e+03</td>\n",
       "      <td>1.318314e+05</td>\n",
       "      <td>9.374314e+04</td>\n",
       "      <td>2.886416e+04</td>\n",
       "      <td>2.401024e+05</td>\n",
       "      <td>6.045691e+04</td>\n",
       "      <td>8.986636</td>\n",
       "      <td>8.072360</td>\n",
       "      <td>0.423596</td>\n",
       "      <td>2799.688722</td>\n",
       "      <td>1281.338850</td>\n",
       "      <td>2527.565352</td>\n",
       "      <td>574.501304</td>\n",
       "      <td>877.045766</td>\n",
       "      <td>470.222625</td>\n",
       "      <td>2.968804e+03</td>\n",
       "      <td>74.166721</td>\n",
       "      <td>56.564754</td>\n",
       "      <td>41.496904</td>\n",
       "      <td>15.392005</td>\n",
       "      <td>1.454459e+04</td>\n",
       "      <td>4.562845e+03</td>\n",
       "      <td>1.109771e+04</td>\n",
       "      <td>1.982555e+03</td>\n",
       "      <td>3512.317134</td>\n",
       "      <td>53.286832</td>\n",
       "      <td>42.240371</td>\n",
       "      <td>38.133475</td>\n",
       "      <td>5.050820</td>\n",
       "      <td>7.362520e+03</td>\n",
       "      <td>1022.178618</td>\n",
       "      <td>1.415998</td>\n",
       "      <td>0.048821</td>\n",
       "      <td>20.839121</td>\n",
       "      <td>8.758644</td>\n",
       "      <td>10.954353</td>\n",
       "      <td>1.486087</td>\n",
       "      <td>67.288524</td>\n",
       "      <td>12.982742</td>\n",
       "      <td>20.060366</td>\n",
       "      <td>9.824081</td>\n",
       "      <td>3.670199</td>\n",
       "      <td>114.862397</td>\n",
       "      <td>15.875705</td>\n",
       "      <td>28.290541</td>\n",
       "      <td>10.823290</td>\n",
       "      <td>5.772870</td>\n",
       "      <td>0.018637</td>\n",
       "      <td>1.988793</td>\n",
       "      <td>3.241362</td>\n",
       "      <td>1.215939</td>\n",
       "      <td>0.886297</td>\n",
       "      <td>18.034550</td>\n",
       "      <td>3.864039</td>\n",
       "      <td>1.479791</td>\n",
       "      <td>3.253520</td>\n",
       "      <td>5.513529</td>\n",
       "      <td>0.727510</td>\n",
       "      <td>8.481742</td>\n",
       "      <td>6.810626</td>\n",
       "      <td>98.873326</td>\n",
       "      <td>1.890156</td>\n",
       "      <td>1.851532</td>\n",
       "      <td>1.871235</td>\n",
       "      <td>0.083279</td>\n",
       "      <td>0.079857</td>\n",
       "      <td>36.946545</td>\n",
       "      <td>31.813867</td>\n",
       "      <td>27.745926</td>\n",
       "      <td>1.422914</td>\n",
       "      <td>0.632497</td>\n",
       "      <td>193.924707</td>\n",
       "      <td>130.409707</td>\n",
       "      <td>94.523794</td>\n",
       "      <td>5.949804</td>\n",
       "      <td>1.155313</td>\n",
       "      <td>1433.123207</td>\n",
       "      <td>625.605366</td>\n",
       "      <td>382.677966</td>\n",
       "      <td>1.588005</td>\n",
       "      <td>0.074478</td>\n",
       "      <td>0.540254</td>\n",
       "      <td>0.907432</td>\n",
       "      <td>1.359192</td>\n",
       "      <td>0.075782</td>\n",
       "      <td>0.658898</td>\n",
       "      <td>1.493481</td>\n",
       "      <td>3.032269</td>\n",
       "      <td>0.075945</td>\n",
       "      <td>0.559811</td>\n",
       "      <td>0.916558</td>\n",
       "      <td>1.378585</td>\n",
       "      <td>0.527216</td>\n",
       "      <td>0.821708</td>\n",
       "      <td>1.130378</td>\n",
       "      <td>0.085398</td>\n",
       "      <td>5.65189</td>\n",
       "      <td>0.778194</td>\n",
       "      <td>16.727021</td>\n",
       "      <td>2.687744</td>\n",
       "      <td>18.573501</td>\n",
       "      <td>8.045306</td>\n",
       "      <td>0.076108</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>12.563233</td>\n",
       "      <td>8.535039</td>\n",
       "      <td>10.737836</td>\n",
       "      <td>9.300359</td>\n",
       "      <td>1.007008</td>\n",
       "      <td>0.258638</td>\n",
       "      <td>35.268905</td>\n",
       "      <td>50.464635</td>\n",
       "      <td>4.085887</td>\n",
       "      <td>0.754563</td>\n",
       "      <td>856.389342</td>\n",
       "      <td>-9.182529e+02</td>\n",
       "      <td>392.478665</td>\n",
       "      <td>244.736473</td>\n",
       "      <td>11.906128</td>\n",
       "      <td>0.076760</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>182.092568</td>\n",
       "      <td>1.187581</td>\n",
       "      <td>0.430411</td>\n",
       "      <td>536.144557</td>\n",
       "      <td>109.897979</td>\n",
       "      <td>241.950743</td>\n",
       "      <td>156.586701</td>\n",
       "      <td>4.967080</td>\n",
       "      <td>1.094524</td>\n",
       "      <td>1631.959909</td>\n",
       "      <td>132.997555</td>\n",
       "      <td>538.439498</td>\n",
       "      <td>389.747881</td>\n",
       "      <td>1.627771</td>\n",
       "      <td>0.074641</td>\n",
       "      <td>23.933670</td>\n",
       "      <td>20.226371</td>\n",
       "      <td>18.675684</td>\n",
       "      <td>0.735658</td>\n",
       "      <td>1.253096</td>\n",
       "      <td>113.781128</td>\n",
       "      <td>64.831367</td>\n",
       "      <td>46.357725</td>\n",
       "      <td>2.802966</td>\n",
       "      <td>2.786832</td>\n",
       "      <td>799.976532</td>\n",
       "      <td>259.726317</td>\n",
       "      <td>133.027379</td>\n",
       "      <td>7.933996</td>\n",
       "      <td>4.751304</td>\n",
       "      <td>0.074641</td>\n",
       "      <td>31.289602</td>\n",
       "      <td>25.670341</td>\n",
       "      <td>23.414765</td>\n",
       "      <td>0.827249</td>\n",
       "      <td>1.100717</td>\n",
       "      <td>180.524609</td>\n",
       "      <td>115.393665</td>\n",
       "      <td>91.770698</td>\n",
       "      <td>3.282106</td>\n",
       "      <td>2.166395</td>\n",
       "      <td>1202.695893</td>\n",
       "      <td>521.993828</td>\n",
       "      <td>288.26206</td>\n",
       "      <td>9.514342</td>\n",
       "      <td>3.419980</td>\n",
       "      <td>0.841265</td>\n",
       "      <td>0.075619</td>\n",
       "      <td>6.320893</td>\n",
       "      <td>0.777868</td>\n",
       "      <td>10.914602</td>\n",
       "      <td>1.671936</td>\n",
       "      <td>2.972295</td>\n",
       "      <td>0.947686</td>\n",
       "      <td>0.782757</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>16.456323</td>\n",
       "      <td>5.380144</td>\n",
       "      <td>5.476206</td>\n",
       "      <td>5.236799</td>\n",
       "      <td>0.106625</td>\n",
       "      <td>58.397816</td>\n",
       "      <td>5.727999</td>\n",
       "      <td>0.984906</td>\n",
       "      <td>159.310137</td>\n",
       "      <td>9.017837</td>\n",
       "      <td>10.835887</td>\n",
       "      <td>5.322197</td>\n",
       "      <td>1.842188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.395681</td>\n",
       "      <td>0.706975</td>\n",
       "      <td>0.229140</td>\n",
       "      <td>0.211415</td>\n",
       "      <td>31.168188</td>\n",
       "      <td>7.134230</td>\n",
       "      <td>18.240548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177966</td>\n",
       "      <td>0.487940</td>\n",
       "      <td>0.097458</td>\n",
       "      <td>0.378748</td>\n",
       "      <td>0.020860</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>0.458931</td>\n",
       "      <td>0.202412</td>\n",
       "      <td>0.150587</td>\n",
       "      <td>0.052640</td>\n",
       "      <td>0.064211</td>\n",
       "      <td>0.020698</td>\n",
       "      <td>0.050522</td>\n",
       "      <td>0.250978</td>\n",
       "      <td>0.033572</td>\n",
       "      <td>0.109844</td>\n",
       "      <td>0.413136</td>\n",
       "      <td>0.192471</td>\n",
       "      <td>0.213005</td>\n",
       "      <td>0.196545</td>\n",
       "      <td>0.239407</td>\n",
       "      <td>0.161995</td>\n",
       "      <td>0.189048</td>\n",
       "      <td>0.092405</td>\n",
       "      <td>0.196545</td>\n",
       "      <td>0.221969</td>\n",
       "      <td>0.489081</td>\n",
       "      <td>0.356584</td>\n",
       "      <td>0.159713</td>\n",
       "      <td>0.275098</td>\n",
       "      <td>0.208605</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.177966</td>\n",
       "      <td>0.156454</td>\n",
       "      <td>0.061604</td>\n",
       "      <td>0.374185</td>\n",
       "      <td>0.262223</td>\n",
       "      <td>0.363592</td>\n",
       "      <td>0.479791</td>\n",
       "      <td>0.033572</td>\n",
       "      <td>0.085398</td>\n",
       "      <td>0.169003</td>\n",
       "      <td>0.232236</td>\n",
       "      <td>0.323501</td>\n",
       "      <td>0.107562</td>\n",
       "      <td>0.239407</td>\n",
       "      <td>0.051499</td>\n",
       "      <td>0.088983</td>\n",
       "      <td>0.189048</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.396023</td>\n",
       "      <td>0.322523</td>\n",
       "      <td>0.277053</td>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.322034</td>\n",
       "      <td>0.097458</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>0.027705</td>\n",
       "      <td>0.804759</td>\n",
       "      <td>0.356584</td>\n",
       "      <td>0.368318</td>\n",
       "      <td>0.275098</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.269068</td>\n",
       "      <td>0.044166</td>\n",
       "      <td>0.396675</td>\n",
       "      <td>0.021512</td>\n",
       "      <td>0.219035</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>0.290091</td>\n",
       "      <td>0.344035</td>\n",
       "      <td>0.133149</td>\n",
       "      <td>0.067471</td>\n",
       "      <td>0.130541</td>\n",
       "      <td>0.034713</td>\n",
       "      <td>0.199478</td>\n",
       "      <td>0.321545</td>\n",
       "      <td>0.119459</td>\n",
       "      <td>0.301988</td>\n",
       "      <td>0.057529</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.074478</td>\n",
       "      <td>0.127934</td>\n",
       "      <td>0.070730</td>\n",
       "      <td>0.458605</td>\n",
       "      <td>0.115711</td>\n",
       "      <td>0.290091</td>\n",
       "      <td>0.511897</td>\n",
       "      <td>0.198012</td>\n",
       "      <td>0.487940</td>\n",
       "      <td>0.097458</td>\n",
       "      <td>0.279498</td>\n",
       "      <td>0.135104</td>\n",
       "      <td>0.257008</td>\n",
       "      <td>0.254726</td>\n",
       "      <td>0.071056</td>\n",
       "      <td>0.417210</td>\n",
       "      <td>0.797588</td>\n",
       "      <td>0.074478</td>\n",
       "      <td>0.127934</td>\n",
       "      <td>0.355769</td>\n",
       "      <td>0.368318</td>\n",
       "      <td>0.275913</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.455183</td>\n",
       "      <td>0.143416</td>\n",
       "      <td>0.274283</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.057529</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.221480</td>\n",
       "      <td>0.244622</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.171121</td>\n",
       "      <td>0.097458</td>\n",
       "      <td>0.487940</td>\n",
       "      <td>0.414602</td>\n",
       "      <td>0.114896</td>\n",
       "      <td>0.074478</td>\n",
       "      <td>0.767275</td>\n",
       "      <td>0.043351</td>\n",
       "      <td>0.425684</td>\n",
       "      <td>0.301988</td>\n",
       "      <td>0.169817</td>\n",
       "      <td>0.102510</td>\n",
       "      <td>0.355769</td>\n",
       "      <td>0.159713</td>\n",
       "      <td>0.275913</td>\n",
       "      <td>0.208605</td>\n",
       "      <td>0.097458</td>\n",
       "      <td>0.401728</td>\n",
       "      <td>0.437093</td>\n",
       "      <td>0.035854</td>\n",
       "      <td>0.027868</td>\n",
       "      <td>0.363918</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>0.104628</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.016134</td>\n",
       "      <td>0.209257</td>\n",
       "      <td>0.075945</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.250815</td>\n",
       "      <td>0.087190</td>\n",
       "      <td>0.380541</td>\n",
       "      <td>0.112288</td>\n",
       "      <td>0.389179</td>\n",
       "      <td>0.036506</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.082790</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.057529</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.420958</td>\n",
       "      <td>0.114896</td>\n",
       "      <td>0.101369</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.070893</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.149609</td>\n",
       "      <td>0.087190</td>\n",
       "      <td>0.385593</td>\n",
       "      <td>0.145372</td>\n",
       "      <td>0.068123</td>\n",
       "      <td>0.588331</td>\n",
       "      <td>0.411669</td>\n",
       "      <td>0.292373</td>\n",
       "      <td>0.074478</td>\n",
       "      <td>0.127934</td>\n",
       "      <td>0.505215</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.269068</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.407920</td>\n",
       "      <td>0.105117</td>\n",
       "      <td>0.124185</td>\n",
       "      <td>0.414928</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.162158</td>\n",
       "      <td>0.276076</td>\n",
       "      <td>0.053618</td>\n",
       "      <td>0.487940</td>\n",
       "      <td>0.097458</td>\n",
       "      <td>0.393742</td>\n",
       "      <td>0.020860</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.637223</td>\n",
       "      <td>0.269068</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.644557</td>\n",
       "      <td>0.355443</td>\n",
       "      <td>0.545469</td>\n",
       "      <td>0.190678</td>\n",
       "      <td>0.246578</td>\n",
       "      <td>0.017275</td>\n",
       "      <td>0.598924</td>\n",
       "      <td>0.033572</td>\n",
       "      <td>0.101369</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.156943</td>\n",
       "      <td>0.323990</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.361310</td>\n",
       "      <td>0.221480</td>\n",
       "      <td>0.443449</td>\n",
       "      <td>0.033572</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.264342</td>\n",
       "      <td>0.269068</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.063722</td>\n",
       "      <td>0.100391</td>\n",
       "      <td>0.910365</td>\n",
       "      <td>0.036506</td>\n",
       "      <td>0.053129</td>\n",
       "      <td>0.090939</td>\n",
       "      <td>0.033572</td>\n",
       "      <td>0.875489</td>\n",
       "      <td>0.090939</td>\n",
       "      <td>0.033572</td>\n",
       "      <td>0.351043</td>\n",
       "      <td>0.403194</td>\n",
       "      <td>0.121252</td>\n",
       "      <td>0.790417</td>\n",
       "      <td>0.036506</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.355769</td>\n",
       "      <td>0.190678</td>\n",
       "      <td>0.453553</td>\n",
       "      <td>0.189374</td>\n",
       "      <td>0.13543</td>\n",
       "      <td>0.432203</td>\n",
       "      <td>0.187744</td>\n",
       "      <td>0.055248</td>\n",
       "      <td>0.235332</td>\n",
       "      <td>0.033572</td>\n",
       "      <td>0.447523</td>\n",
       "      <td>0.283572</td>\n",
       "      <td>0.543677</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.247718</td>\n",
       "      <td>0.371089</td>\n",
       "      <td>0.033572</td>\n",
       "      <td>0.101369</td>\n",
       "      <td>0.275587</td>\n",
       "      <td>0.061441</td>\n",
       "      <td>0.156943</td>\n",
       "      <td>0.414928</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.360984</td>\n",
       "      <td>0.130867</td>\n",
       "      <td>0.543677</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.246252</td>\n",
       "      <td>0.116851</td>\n",
       "      <td>0.797588</td>\n",
       "      <td>0.074478</td>\n",
       "      <td>0.127934</td>\n",
       "      <td>0.737614</td>\n",
       "      <td>0.036506</td>\n",
       "      <td>0.121252</td>\n",
       "      <td>0.104628</td>\n",
       "      <td>0.355769</td>\n",
       "      <td>0.13543</td>\n",
       "      <td>0.055248</td>\n",
       "      <td>0.453553</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.074478</td>\n",
       "      <td>0.097295</td>\n",
       "      <td>0.063722</td>\n",
       "      <td>0.097458</td>\n",
       "      <td>0.206812</td>\n",
       "      <td>0.106095</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.166558</td>\n",
       "      <td>0.350717</td>\n",
       "      <td>0.057040</td>\n",
       "      <td>0.450130</td>\n",
       "      <td>0.072523</td>\n",
       "      <td>0.069589</td>\n",
       "      <td>0.543677</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.363103</td>\n",
       "      <td>0.090939</td>\n",
       "      <td>0.033572</td>\n",
       "      <td>0.472295</td>\n",
       "      <td>0.382171</td>\n",
       "      <td>0.021023</td>\n",
       "      <td>0.577901</td>\n",
       "      <td>0.097458</td>\n",
       "      <td>0.214146</td>\n",
       "      <td>0.110495</td>\n",
       "      <td>0.371089</td>\n",
       "      <td>0.033572</td>\n",
       "      <td>0.258312</td>\n",
       "      <td>0.337027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>218.365611</td>\n",
       "      <td>0.058531</td>\n",
       "      <td>10.342463</td>\n",
       "      <td>7.080987</td>\n",
       "      <td>15.129655</td>\n",
       "      <td>4.650487</td>\n",
       "      <td>1.926498</td>\n",
       "      <td>1.639202</td>\n",
       "      <td>5.020865</td>\n",
       "      <td>22.402551</td>\n",
       "      <td>0.304992</td>\n",
       "      <td>1.192120e+06</td>\n",
       "      <td>43.990324</td>\n",
       "      <td>1.482755e+06</td>\n",
       "      <td>37.434632</td>\n",
       "      <td>5.446422e+05</td>\n",
       "      <td>2365.042937</td>\n",
       "      <td>11.171470</td>\n",
       "      <td>11.354860</td>\n",
       "      <td>4.637332</td>\n",
       "      <td>3.341237</td>\n",
       "      <td>3.786141</td>\n",
       "      <td>5.798618</td>\n",
       "      <td>1.888096</td>\n",
       "      <td>0.871686</td>\n",
       "      <td>4.230650</td>\n",
       "      <td>3.216437</td>\n",
       "      <td>7.856790</td>\n",
       "      <td>49.939239</td>\n",
       "      <td>8.042503</td>\n",
       "      <td>111.090046</td>\n",
       "      <td>33.177066</td>\n",
       "      <td>45.312008</td>\n",
       "      <td>4.525155</td>\n",
       "      <td>2.485758</td>\n",
       "      <td>17.232272</td>\n",
       "      <td>25.193642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1980.411211</td>\n",
       "      <td>1292.641299</td>\n",
       "      <td>1868.988912</td>\n",
       "      <td>1182.143906</td>\n",
       "      <td>648.455157</td>\n",
       "      <td>7.951178e+04</td>\n",
       "      <td>3.339734e+04</td>\n",
       "      <td>4.528668e+04</td>\n",
       "      <td>8479.135303</td>\n",
       "      <td>2.955848e+05</td>\n",
       "      <td>1.780701e+05</td>\n",
       "      <td>4987.828210</td>\n",
       "      <td>5.260209e+04</td>\n",
       "      <td>20573.760948</td>\n",
       "      <td>14136.590112</td>\n",
       "      <td>7327.705454</td>\n",
       "      <td>1.471274e+05</td>\n",
       "      <td>8.671773e+04</td>\n",
       "      <td>1.188054e+05</td>\n",
       "      <td>7.886895e+04</td>\n",
       "      <td>3.900276e+04</td>\n",
       "      <td>4.880868e+05</td>\n",
       "      <td>3.100066e+05</td>\n",
       "      <td>1.109240e+05</td>\n",
       "      <td>2.268388e+06</td>\n",
       "      <td>1.570243e+05</td>\n",
       "      <td>9.633861e+05</td>\n",
       "      <td>2.521924e+05</td>\n",
       "      <td>2.621602</td>\n",
       "      <td>0.257060</td>\n",
       "      <td>15.819469</td>\n",
       "      <td>3.959626</td>\n",
       "      <td>15.990181</td>\n",
       "      <td>25.321545</td>\n",
       "      <td>13.526580</td>\n",
       "      <td>9.008236</td>\n",
       "      <td>128.912589</td>\n",
       "      <td>22.461770</td>\n",
       "      <td>54.330911</td>\n",
       "      <td>15.607764</td>\n",
       "      <td>18.283755</td>\n",
       "      <td>0.087341</td>\n",
       "      <td>0.060102</td>\n",
       "      <td>0.084506</td>\n",
       "      <td>0.055622</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>2.865327</td>\n",
       "      <td>0.610729</td>\n",
       "      <td>1.181622</td>\n",
       "      <td>0.487873</td>\n",
       "      <td>0.423333</td>\n",
       "      <td>9.241554</td>\n",
       "      <td>0.796765</td>\n",
       "      <td>2.387042</td>\n",
       "      <td>0.526624</td>\n",
       "      <td>0.819394</td>\n",
       "      <td>16000.821651</td>\n",
       "      <td>14472.749982</td>\n",
       "      <td>6686.584081</td>\n",
       "      <td>1.254270e+05</td>\n",
       "      <td>8.439949e+04</td>\n",
       "      <td>1.145393e+05</td>\n",
       "      <td>3.680146e+04</td>\n",
       "      <td>4.020219e+05</td>\n",
       "      <td>2.892165e+05</td>\n",
       "      <td>1.042954e+05</td>\n",
       "      <td>8.547554e+05</td>\n",
       "      <td>2.181042e+05</td>\n",
       "      <td>372.832249</td>\n",
       "      <td>367.795452</td>\n",
       "      <td>28.826320</td>\n",
       "      <td>28650.846838</td>\n",
       "      <td>13115.805848</td>\n",
       "      <td>27164.327348</td>\n",
       "      <td>7370.664356</td>\n",
       "      <td>12294.647274</td>\n",
       "      <td>12092.641554</td>\n",
       "      <td>3.899199e+04</td>\n",
       "      <td>1511.736394</td>\n",
       "      <td>1172.156733</td>\n",
       "      <td>1038.578609</td>\n",
       "      <td>531.822083</td>\n",
       "      <td>8.223104e+04</td>\n",
       "      <td>3.331441e+04</td>\n",
       "      <td>6.304831e+04</td>\n",
       "      <td>2.911856e+04</td>\n",
       "      <td>20631.582363</td>\n",
       "      <td>1169.444796</td>\n",
       "      <td>968.081682</td>\n",
       "      <td>946.056981</td>\n",
       "      <td>206.147356</td>\n",
       "      <td>4.358436e+04</td>\n",
       "      <td>12797.110416</td>\n",
       "      <td>8.273249</td>\n",
       "      <td>1.322657</td>\n",
       "      <td>50.676796</td>\n",
       "      <td>19.675049</td>\n",
       "      <td>26.383168</td>\n",
       "      <td>7.396629</td>\n",
       "      <td>148.740940</td>\n",
       "      <td>24.494187</td>\n",
       "      <td>47.022583</td>\n",
       "      <td>20.768641</td>\n",
       "      <td>13.538977</td>\n",
       "      <td>222.533453</td>\n",
       "      <td>25.023740</td>\n",
       "      <td>59.645579</td>\n",
       "      <td>20.503744</td>\n",
       "      <td>17.331187</td>\n",
       "      <td>0.808730</td>\n",
       "      <td>7.639657</td>\n",
       "      <td>11.678759</td>\n",
       "      <td>6.382317</td>\n",
       "      <td>4.464068</td>\n",
       "      <td>40.753255</td>\n",
       "      <td>11.500115</td>\n",
       "      <td>8.586427</td>\n",
       "      <td>9.403188</td>\n",
       "      <td>10.664707</td>\n",
       "      <td>5.196582</td>\n",
       "      <td>15.162340</td>\n",
       "      <td>10.452750</td>\n",
       "      <td>3898.581883</td>\n",
       "      <td>6.782954</td>\n",
       "      <td>6.656011</td>\n",
       "      <td>6.715065</td>\n",
       "      <td>0.312323</td>\n",
       "      <td>0.298016</td>\n",
       "      <td>37.262466</td>\n",
       "      <td>32.025118</td>\n",
       "      <td>29.660961</td>\n",
       "      <td>2.111541</td>\n",
       "      <td>0.740083</td>\n",
       "      <td>134.116951</td>\n",
       "      <td>92.972462</td>\n",
       "      <td>91.813084</td>\n",
       "      <td>8.348975</td>\n",
       "      <td>1.044174</td>\n",
       "      <td>1211.694784</td>\n",
       "      <td>534.225322</td>\n",
       "      <td>563.404556</td>\n",
       "      <td>1.219943</td>\n",
       "      <td>0.264425</td>\n",
       "      <td>0.530113</td>\n",
       "      <td>0.570309</td>\n",
       "      <td>0.717728</td>\n",
       "      <td>0.271361</td>\n",
       "      <td>0.728405</td>\n",
       "      <td>1.175666</td>\n",
       "      <td>1.971831</td>\n",
       "      <td>0.272215</td>\n",
       "      <td>0.564654</td>\n",
       "      <td>0.576825</td>\n",
       "      <td>0.662605</td>\n",
       "      <td>0.505786</td>\n",
       "      <td>0.459430</td>\n",
       "      <td>0.552050</td>\n",
       "      <td>0.699196</td>\n",
       "      <td>12.58330</td>\n",
       "      <td>0.866202</td>\n",
       "      <td>17.627245</td>\n",
       "      <td>2.492163</td>\n",
       "      <td>17.578052</td>\n",
       "      <td>7.787096</td>\n",
       "      <td>0.273663</td>\n",
       "      <td>0.068683</td>\n",
       "      <td>24.912435</td>\n",
       "      <td>38.584600</td>\n",
       "      <td>21.354293</td>\n",
       "      <td>18.950695</td>\n",
       "      <td>1.494172</td>\n",
       "      <td>0.580383</td>\n",
       "      <td>140.354309</td>\n",
       "      <td>106.962473</td>\n",
       "      <td>6.441964</td>\n",
       "      <td>1.109959</td>\n",
       "      <td>753.530852</td>\n",
       "      <td>4.209843e+04</td>\n",
       "      <td>2728.878706</td>\n",
       "      <td>4583.217499</td>\n",
       "      <td>15.715938</td>\n",
       "      <td>0.278208</td>\n",
       "      <td>0.104146</td>\n",
       "      <td>2720.319154</td>\n",
       "      <td>1.691201</td>\n",
       "      <td>0.655276</td>\n",
       "      <td>4263.031638</td>\n",
       "      <td>1800.272880</td>\n",
       "      <td>2153.646923</td>\n",
       "      <td>2125.210980</td>\n",
       "      <td>6.881147</td>\n",
       "      <td>1.119376</td>\n",
       "      <td>10678.949203</td>\n",
       "      <td>1296.860095</td>\n",
       "      <td>2302.800646</td>\n",
       "      <td>9536.814651</td>\n",
       "      <td>1.293191</td>\n",
       "      <td>0.265302</td>\n",
       "      <td>25.767027</td>\n",
       "      <td>21.196906</td>\n",
       "      <td>20.311890</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>1.946051</td>\n",
       "      <td>109.514718</td>\n",
       "      <td>57.254205</td>\n",
       "      <td>53.810619</td>\n",
       "      <td>2.927619</td>\n",
       "      <td>3.243178</td>\n",
       "      <td>711.234021</td>\n",
       "      <td>1256.186163</td>\n",
       "      <td>251.152995</td>\n",
       "      <td>7.540213</td>\n",
       "      <td>5.404223</td>\n",
       "      <td>0.265302</td>\n",
       "      <td>42.275998</td>\n",
       "      <td>28.246993</td>\n",
       "      <td>25.957603</td>\n",
       "      <td>0.927958</td>\n",
       "      <td>1.671261</td>\n",
       "      <td>137.144815</td>\n",
       "      <td>86.593353</td>\n",
       "      <td>90.422163</td>\n",
       "      <td>3.157549</td>\n",
       "      <td>2.588833</td>\n",
       "      <td>860.840922</td>\n",
       "      <td>1298.874381</td>\n",
       "      <td>4587.93111</td>\n",
       "      <td>8.720179</td>\n",
       "      <td>4.417102</td>\n",
       "      <td>3.016915</td>\n",
       "      <td>0.270504</td>\n",
       "      <td>6.942460</td>\n",
       "      <td>0.878266</td>\n",
       "      <td>11.828820</td>\n",
       "      <td>1.343681</td>\n",
       "      <td>1.909240</td>\n",
       "      <td>3.861038</td>\n",
       "      <td>2.862380</td>\n",
       "      <td>0.099492</td>\n",
       "      <td>28.152398</td>\n",
       "      <td>5.270148</td>\n",
       "      <td>5.358151</td>\n",
       "      <td>5.164592</td>\n",
       "      <td>0.345589</td>\n",
       "      <td>85.032516</td>\n",
       "      <td>4.249992</td>\n",
       "      <td>1.185491</td>\n",
       "      <td>188.568047</td>\n",
       "      <td>3.061397</td>\n",
       "      <td>3.225705</td>\n",
       "      <td>4.085716</td>\n",
       "      <td>1.415368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.045771</td>\n",
       "      <td>4.569506</td>\n",
       "      <td>2.715101</td>\n",
       "      <td>1.619562</td>\n",
       "      <td>118.488082</td>\n",
       "      <td>26.735827</td>\n",
       "      <td>49.606670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382515</td>\n",
       "      <td>0.499895</td>\n",
       "      <td>0.296604</td>\n",
       "      <td>0.485115</td>\n",
       "      <td>0.142929</td>\n",
       "      <td>0.121536</td>\n",
       "      <td>0.498351</td>\n",
       "      <td>0.401830</td>\n",
       "      <td>0.357675</td>\n",
       "      <td>0.223332</td>\n",
       "      <td>0.245149</td>\n",
       "      <td>0.142381</td>\n",
       "      <td>0.219036</td>\n",
       "      <td>0.433611</td>\n",
       "      <td>0.180140</td>\n",
       "      <td>0.312720</td>\n",
       "      <td>0.492437</td>\n",
       "      <td>0.394273</td>\n",
       "      <td>0.409465</td>\n",
       "      <td>0.397418</td>\n",
       "      <td>0.426756</td>\n",
       "      <td>0.368476</td>\n",
       "      <td>0.391579</td>\n",
       "      <td>0.289621</td>\n",
       "      <td>0.397418</td>\n",
       "      <td>0.415604</td>\n",
       "      <td>0.499921</td>\n",
       "      <td>0.479030</td>\n",
       "      <td>0.366370</td>\n",
       "      <td>0.446600</td>\n",
       "      <td>0.406344</td>\n",
       "      <td>0.489109</td>\n",
       "      <td>0.382515</td>\n",
       "      <td>0.363315</td>\n",
       "      <td>0.240454</td>\n",
       "      <td>0.483951</td>\n",
       "      <td>0.439879</td>\n",
       "      <td>0.481072</td>\n",
       "      <td>0.499632</td>\n",
       "      <td>0.180140</td>\n",
       "      <td>0.279495</td>\n",
       "      <td>0.374785</td>\n",
       "      <td>0.422293</td>\n",
       "      <td>0.467850</td>\n",
       "      <td>0.309852</td>\n",
       "      <td>0.426756</td>\n",
       "      <td>0.221032</td>\n",
       "      <td>0.284742</td>\n",
       "      <td>0.391579</td>\n",
       "      <td>0.489109</td>\n",
       "      <td>0.489109</td>\n",
       "      <td>0.467480</td>\n",
       "      <td>0.447580</td>\n",
       "      <td>0.268806</td>\n",
       "      <td>0.467294</td>\n",
       "      <td>0.296604</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>0.164141</td>\n",
       "      <td>0.396419</td>\n",
       "      <td>0.479030</td>\n",
       "      <td>0.482388</td>\n",
       "      <td>0.446600</td>\n",
       "      <td>0.177158</td>\n",
       "      <td>0.443511</td>\n",
       "      <td>0.205480</td>\n",
       "      <td>0.489247</td>\n",
       "      <td>0.145097</td>\n",
       "      <td>0.413626</td>\n",
       "      <td>0.129700</td>\n",
       "      <td>0.453841</td>\n",
       "      <td>0.475091</td>\n",
       "      <td>0.339763</td>\n",
       "      <td>0.250856</td>\n",
       "      <td>0.336925</td>\n",
       "      <td>0.183067</td>\n",
       "      <td>0.399641</td>\n",
       "      <td>0.467107</td>\n",
       "      <td>0.324354</td>\n",
       "      <td>0.459158</td>\n",
       "      <td>0.232870</td>\n",
       "      <td>0.359575</td>\n",
       "      <td>0.262569</td>\n",
       "      <td>0.334043</td>\n",
       "      <td>0.256394</td>\n",
       "      <td>0.498324</td>\n",
       "      <td>0.319904</td>\n",
       "      <td>0.453841</td>\n",
       "      <td>0.499899</td>\n",
       "      <td>0.398534</td>\n",
       "      <td>0.499895</td>\n",
       "      <td>0.296604</td>\n",
       "      <td>0.448789</td>\n",
       "      <td>0.341863</td>\n",
       "      <td>0.437019</td>\n",
       "      <td>0.435743</td>\n",
       "      <td>0.256939</td>\n",
       "      <td>0.493138</td>\n",
       "      <td>0.401830</td>\n",
       "      <td>0.262569</td>\n",
       "      <td>0.334043</td>\n",
       "      <td>0.478785</td>\n",
       "      <td>0.482388</td>\n",
       "      <td>0.447009</td>\n",
       "      <td>0.180982</td>\n",
       "      <td>0.290765</td>\n",
       "      <td>0.498028</td>\n",
       "      <td>0.350525</td>\n",
       "      <td>0.446189</td>\n",
       "      <td>0.177158</td>\n",
       "      <td>0.232870</td>\n",
       "      <td>0.239859</td>\n",
       "      <td>0.415277</td>\n",
       "      <td>0.429898</td>\n",
       "      <td>0.408433</td>\n",
       "      <td>0.376646</td>\n",
       "      <td>0.296604</td>\n",
       "      <td>0.499895</td>\n",
       "      <td>0.492693</td>\n",
       "      <td>0.318922</td>\n",
       "      <td>0.262569</td>\n",
       "      <td>0.422603</td>\n",
       "      <td>0.203662</td>\n",
       "      <td>0.494487</td>\n",
       "      <td>0.459158</td>\n",
       "      <td>0.375503</td>\n",
       "      <td>0.303342</td>\n",
       "      <td>0.478785</td>\n",
       "      <td>0.366370</td>\n",
       "      <td>0.447009</td>\n",
       "      <td>0.406344</td>\n",
       "      <td>0.296604</td>\n",
       "      <td>0.490287</td>\n",
       "      <td>0.496067</td>\n",
       "      <td>0.185941</td>\n",
       "      <td>0.164609</td>\n",
       "      <td>0.481165</td>\n",
       "      <td>0.319512</td>\n",
       "      <td>0.355431</td>\n",
       "      <td>0.306099</td>\n",
       "      <td>0.201455</td>\n",
       "      <td>0.126002</td>\n",
       "      <td>0.406811</td>\n",
       "      <td>0.264932</td>\n",
       "      <td>0.290765</td>\n",
       "      <td>0.433517</td>\n",
       "      <td>0.282137</td>\n",
       "      <td>0.485559</td>\n",
       "      <td>0.315746</td>\n",
       "      <td>0.487604</td>\n",
       "      <td>0.187560</td>\n",
       "      <td>0.499969</td>\n",
       "      <td>0.275587</td>\n",
       "      <td>0.177158</td>\n",
       "      <td>0.232870</td>\n",
       "      <td>0.239859</td>\n",
       "      <td>0.493753</td>\n",
       "      <td>0.318922</td>\n",
       "      <td>0.301841</td>\n",
       "      <td>0.408433</td>\n",
       "      <td>0.256667</td>\n",
       "      <td>0.290765</td>\n",
       "      <td>0.356717</td>\n",
       "      <td>0.282137</td>\n",
       "      <td>0.486775</td>\n",
       "      <td>0.352504</td>\n",
       "      <td>0.251977</td>\n",
       "      <td>0.492176</td>\n",
       "      <td>0.492176</td>\n",
       "      <td>0.454890</td>\n",
       "      <td>0.262569</td>\n",
       "      <td>0.334043</td>\n",
       "      <td>0.500014</td>\n",
       "      <td>0.177158</td>\n",
       "      <td>0.443511</td>\n",
       "      <td>0.239859</td>\n",
       "      <td>0.491488</td>\n",
       "      <td>0.306730</td>\n",
       "      <td>0.329820</td>\n",
       "      <td>0.492750</td>\n",
       "      <td>0.290765</td>\n",
       "      <td>0.368626</td>\n",
       "      <td>0.447091</td>\n",
       "      <td>0.225281</td>\n",
       "      <td>0.499895</td>\n",
       "      <td>0.296604</td>\n",
       "      <td>0.488619</td>\n",
       "      <td>0.142929</td>\n",
       "      <td>0.177158</td>\n",
       "      <td>0.480840</td>\n",
       "      <td>0.443511</td>\n",
       "      <td>0.239859</td>\n",
       "      <td>0.478686</td>\n",
       "      <td>0.478686</td>\n",
       "      <td>0.497969</td>\n",
       "      <td>0.392868</td>\n",
       "      <td>0.431054</td>\n",
       "      <td>0.130305</td>\n",
       "      <td>0.490156</td>\n",
       "      <td>0.180140</td>\n",
       "      <td>0.301841</td>\n",
       "      <td>0.311905</td>\n",
       "      <td>0.363776</td>\n",
       "      <td>0.468034</td>\n",
       "      <td>0.290765</td>\n",
       "      <td>0.480419</td>\n",
       "      <td>0.415277</td>\n",
       "      <td>0.496832</td>\n",
       "      <td>0.180140</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>0.441018</td>\n",
       "      <td>0.443511</td>\n",
       "      <td>0.239859</td>\n",
       "      <td>0.427846</td>\n",
       "      <td>0.244277</td>\n",
       "      <td>0.300545</td>\n",
       "      <td>0.285681</td>\n",
       "      <td>0.187560</td>\n",
       "      <td>0.224309</td>\n",
       "      <td>0.287545</td>\n",
       "      <td>0.180140</td>\n",
       "      <td>0.330191</td>\n",
       "      <td>0.287545</td>\n",
       "      <td>0.180140</td>\n",
       "      <td>0.477335</td>\n",
       "      <td>0.490579</td>\n",
       "      <td>0.326446</td>\n",
       "      <td>0.407044</td>\n",
       "      <td>0.187560</td>\n",
       "      <td>0.378345</td>\n",
       "      <td>0.478785</td>\n",
       "      <td>0.392868</td>\n",
       "      <td>0.497879</td>\n",
       "      <td>0.391837</td>\n",
       "      <td>0.34221</td>\n",
       "      <td>0.495423</td>\n",
       "      <td>0.390540</td>\n",
       "      <td>0.228482</td>\n",
       "      <td>0.424241</td>\n",
       "      <td>0.180140</td>\n",
       "      <td>0.497279</td>\n",
       "      <td>0.450768</td>\n",
       "      <td>0.498129</td>\n",
       "      <td>0.290765</td>\n",
       "      <td>0.319512</td>\n",
       "      <td>0.431723</td>\n",
       "      <td>0.483135</td>\n",
       "      <td>0.180140</td>\n",
       "      <td>0.301841</td>\n",
       "      <td>0.446846</td>\n",
       "      <td>0.240156</td>\n",
       "      <td>0.363776</td>\n",
       "      <td>0.492750</td>\n",
       "      <td>0.290765</td>\n",
       "      <td>0.480325</td>\n",
       "      <td>0.337282</td>\n",
       "      <td>0.498129</td>\n",
       "      <td>0.290765</td>\n",
       "      <td>0.430862</td>\n",
       "      <td>0.321269</td>\n",
       "      <td>0.401830</td>\n",
       "      <td>0.262569</td>\n",
       "      <td>0.334043</td>\n",
       "      <td>0.439967</td>\n",
       "      <td>0.187560</td>\n",
       "      <td>0.326446</td>\n",
       "      <td>0.306099</td>\n",
       "      <td>0.478785</td>\n",
       "      <td>0.34221</td>\n",
       "      <td>0.228482</td>\n",
       "      <td>0.497879</td>\n",
       "      <td>0.424343</td>\n",
       "      <td>0.262569</td>\n",
       "      <td>0.296383</td>\n",
       "      <td>0.244277</td>\n",
       "      <td>0.296604</td>\n",
       "      <td>0.405053</td>\n",
       "      <td>0.307984</td>\n",
       "      <td>0.494088</td>\n",
       "      <td>0.372611</td>\n",
       "      <td>0.477233</td>\n",
       "      <td>0.231939</td>\n",
       "      <td>0.497547</td>\n",
       "      <td>0.259373</td>\n",
       "      <td>0.254474</td>\n",
       "      <td>0.498129</td>\n",
       "      <td>0.290765</td>\n",
       "      <td>0.480933</td>\n",
       "      <td>0.287545</td>\n",
       "      <td>0.180140</td>\n",
       "      <td>0.499273</td>\n",
       "      <td>0.485958</td>\n",
       "      <td>0.143474</td>\n",
       "      <td>0.493934</td>\n",
       "      <td>0.296604</td>\n",
       "      <td>0.410262</td>\n",
       "      <td>0.313532</td>\n",
       "      <td>0.483135</td>\n",
       "      <td>0.180140</td>\n",
       "      <td>0.437742</td>\n",
       "      <td>0.472733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.187132</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.399160e+05</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-1.482305e+06</td>\n",
       "      <td>-46.000000</td>\n",
       "      <td>-1.482305e+06</td>\n",
       "      <td>6949.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.335500e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.888000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2651.000000</td>\n",
       "      <td>-160.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2651.000000</td>\n",
       "      <td>-2334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.977556e+06</td>\n",
       "      <td>-135639.916667</td>\n",
       "      <td>-357200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2347.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2629.000000</td>\n",
       "      <td>-147.666667</td>\n",
       "      <td>-2621.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2629.000000</td>\n",
       "      <td>-12.062500</td>\n",
       "      <td>-293.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-90550.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-90061.888889</td>\n",
       "      <td>-357200.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>609.000000</td>\n",
       "      <td>0.385630</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.499375</td>\n",
       "      <td>2.499625</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.555494</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>0.173905</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.936250e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.643750e+03</td>\n",
       "      <td>9523.000000</td>\n",
       "      <td>3.997003</td>\n",
       "      <td>4.998001</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.499583</td>\n",
       "      <td>11.989011</td>\n",
       "      <td>1.999001</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.993007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.734750e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>6.928900e+03</td>\n",
       "      <td>1.879675e+04</td>\n",
       "      <td>3.627108e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.241000e+03</td>\n",
       "      <td>1.332205e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>229.708791</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.750000</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>92.446078</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>176.750000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>105.406818</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>43.666667</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>412.000000</td>\n",
       "      <td>204.964286</td>\n",
       "      <td>55.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>8.222222</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>0.433685</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.995005</td>\n",
       "      <td>5.998334</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.399720</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.347815</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>6.749900e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.555050e+04</td>\n",
       "      <td>11084.500000</td>\n",
       "      <td>7.498375</td>\n",
       "      <td>9.330556</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.497251</td>\n",
       "      <td>27.973027</td>\n",
       "      <td>3.998501</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16.992004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.995000e+02</td>\n",
       "      <td>5.500000e+02</td>\n",
       "      <td>5.540000e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.234450e+04</td>\n",
       "      <td>1.664800e+04</td>\n",
       "      <td>2.934600e+03</td>\n",
       "      <td>2.294945e+05</td>\n",
       "      <td>2.030875e+04</td>\n",
       "      <td>7.397500e+04</td>\n",
       "      <td>1.935719e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.735900e+04</td>\n",
       "      <td>1.100000e+04</td>\n",
       "      <td>2.445148e+03</td>\n",
       "      <td>4.115650e+04</td>\n",
       "      <td>1.011933e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.025000</td>\n",
       "      <td>13.280000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266469</td>\n",
       "      <td>1.976136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>135.712963</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>761.500000</td>\n",
       "      <td>6.500000e+01</td>\n",
       "      <td>401.344720</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>69.242857</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>801.500000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>343.573969</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>51.408333</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>689.500000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1093.000000</td>\n",
       "      <td>471.809184</td>\n",
       "      <td>147.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.871653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>785.000000</td>\n",
       "      <td>0.464872</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>9.995502</td>\n",
       "      <td>12.994503</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>3.666489</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.599940</td>\n",
       "      <td>6.794125e+04</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.183882e+05</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.177898e+05</td>\n",
       "      <td>12879.750000</td>\n",
       "      <td>14.328890</td>\n",
       "      <td>16.328862</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.306700</td>\n",
       "      <td>59.941059</td>\n",
       "      <td>8.347797</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>33.967033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.611000e+03</td>\n",
       "      <td>6.451250e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.646535e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000e+04</td>\n",
       "      <td>9.431125e+03</td>\n",
       "      <td>1.289375e+04</td>\n",
       "      <td>5.450000e+03</td>\n",
       "      <td>1.080156e+03</td>\n",
       "      <td>1.753790e+05</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>1.715273e+04</td>\n",
       "      <td>8.308892e+05</td>\n",
       "      <td>5.530666e+04</td>\n",
       "      <td>2.812500e+05</td>\n",
       "      <td>6.807296e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.462395</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>13.148611</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.728044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.130721</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.539700e+04</td>\n",
       "      <td>5.877900e+03</td>\n",
       "      <td>1.199925e+04</td>\n",
       "      <td>2.330225e+03</td>\n",
       "      <td>9.270875e+04</td>\n",
       "      <td>5.937750e+04</td>\n",
       "      <td>1.549253e+04</td>\n",
       "      <td>1.685515e+05</td>\n",
       "      <td>4.397435e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>19.660000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.999380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.292461</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.761726</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>324.250000</td>\n",
       "      <td>194.839286</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2169.000000</td>\n",
       "      <td>869.400000</td>\n",
       "      <td>477.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1356.250000</td>\n",
       "      <td>1.930000e+02</td>\n",
       "      <td>696.691176</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1466.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>622.426683</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>38.333333</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1243.000000</td>\n",
       "      <td>406.201630</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>174.906250</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>769.890921</td>\n",
       "      <td>460.25000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.876368</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.077698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.215062</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>896.000000</td>\n",
       "      <td>0.538073</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>86.914086</td>\n",
       "      <td>229.771229</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>25.243939</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>4.690287e+07</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>4.785170e+07</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>2.997542e+07</td>\n",
       "      <td>31682.000000</td>\n",
       "      <td>182.409295</td>\n",
       "      <td>146.427286</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>123.292569</td>\n",
       "      <td>470.530470</td>\n",
       "      <td>99.901099</td>\n",
       "      <td>1108.000000</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>301.699301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79346.000000</td>\n",
       "      <td>79346.000000</td>\n",
       "      <td>79346.000000</td>\n",
       "      <td>79346.000000</td>\n",
       "      <td>16343.123331</td>\n",
       "      <td>5.560699e+06</td>\n",
       "      <td>2.525458e+06</td>\n",
       "      <td>2.525458e+06</td>\n",
       "      <td>597647.741895</td>\n",
       "      <td>1.702965e+07</td>\n",
       "      <td>9.116532e+06</td>\n",
       "      <td>312825.000000</td>\n",
       "      <td>3.294129e+06</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>399700.000000</td>\n",
       "      <td>3.890282e+06</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>2.640000e+06</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>1.044503e+06</td>\n",
       "      <td>1.371432e+07</td>\n",
       "      <td>6.832170e+06</td>\n",
       "      <td>3.403592e+06</td>\n",
       "      <td>6.425211e+07</td>\n",
       "      <td>5.000000e+06</td>\n",
       "      <td>4.000000e+07</td>\n",
       "      <td>8.412044e+06</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>176.792781</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>176.792781</td>\n",
       "      <td>1644.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>190.322898</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>376079.000000</td>\n",
       "      <td>2.761657e+06</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>2.639481e+06</td>\n",
       "      <td>1.044370e+06</td>\n",
       "      <td>1.370682e+07</td>\n",
       "      <td>6.832170e+06</td>\n",
       "      <td>3.405465e+06</td>\n",
       "      <td>2.997542e+07</td>\n",
       "      <td>6.910147e+06</td>\n",
       "      <td>23000.000000</td>\n",
       "      <td>23000.000000</td>\n",
       "      <td>2250.485182</td>\n",
       "      <td>806251.000000</td>\n",
       "      <td>403125.500000</td>\n",
       "      <td>806251.000000</td>\n",
       "      <td>218424.000000</td>\n",
       "      <td>403125.500000</td>\n",
       "      <td>619000.000000</td>\n",
       "      <td>1.471134e+06</td>\n",
       "      <td>60504.000000</td>\n",
       "      <td>46618.000000</td>\n",
       "      <td>46618.000000</td>\n",
       "      <td>30252.000000</td>\n",
       "      <td>2.016302e+06</td>\n",
       "      <td>1.934827e+06</td>\n",
       "      <td>1.934827e+06</td>\n",
       "      <td>1.934827e+06</td>\n",
       "      <td>686451.240002</td>\n",
       "      <td>41144.000000</td>\n",
       "      <td>41144.000000</td>\n",
       "      <td>41144.000000</td>\n",
       "      <td>11914.000000</td>\n",
       "      <td>1.264115e+06</td>\n",
       "      <td>493670.000000</td>\n",
       "      <td>184.800000</td>\n",
       "      <td>61.659711</td>\n",
       "      <td>1223.407000</td>\n",
       "      <td>203.901167</td>\n",
       "      <td>625.714000</td>\n",
       "      <td>235.454483</td>\n",
       "      <td>2126.733000</td>\n",
       "      <td>625.714000</td>\n",
       "      <td>625.714000</td>\n",
       "      <td>625.714000</td>\n",
       "      <td>283.421500</td>\n",
       "      <td>3182.898000</td>\n",
       "      <td>625.714000</td>\n",
       "      <td>834.286000</td>\n",
       "      <td>625.714000</td>\n",
       "      <td>302.653683</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>174.291250</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>174.291250</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>183.092817</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>240000.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10229.000000</td>\n",
       "      <td>5685.333333</td>\n",
       "      <td>6110.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2556.000000</td>\n",
       "      <td>2.503000e+03</td>\n",
       "      <td>2503.000000</td>\n",
       "      <td>2503.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>44590.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>44590.000000</td>\n",
       "      <td>44590.000000</td>\n",
       "      <td>44590.000000</td>\n",
       "      <td>44590.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>737482.000000</td>\n",
       "      <td>44590.000000</td>\n",
       "      <td>134258.363636</td>\n",
       "      <td>737482.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>358.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2542.000000</td>\n",
       "      <td>2450.000000</td>\n",
       "      <td>2450.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1444.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1642.000000</td>\n",
       "      <td>735.000000</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>2557.000000</td>\n",
       "      <td>2545.000000</td>\n",
       "      <td>2556.00000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>374.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1759.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>3424.000000</td>\n",
       "      <td>581.000000</td>\n",
       "      <td>581.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 9030 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BureauScore  MissingRate     Len_Name    Tel_nuniq  Email_nuniq  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean    650.420795     0.421178    22.779172     7.969912    10.862148   \n",
       "std     218.365611     0.058531    10.342463     7.080987    15.129655   \n",
       "min       8.000000     0.187132     4.000000     1.000000     1.000000   \n",
       "25%     609.000000     0.385630    15.000000     3.499375     2.499625   \n",
       "50%     718.000000     0.433685    20.000000     5.995005     5.998334   \n",
       "75%     785.000000     0.464872    28.000000     9.995502    12.994503   \n",
       "max     896.000000     0.538073   102.000000    86.914086   229.771229   \n",
       "\n",
       "       Len_of_addrs   City_nuniq  Current_State  CreditAccountActive  \\\n",
       "count   6136.000000  6136.000000    6136.000000          6136.000000   \n",
       "mean      45.197849     2.929406      27.316167             5.048240   \n",
       "std        4.650487     1.926498       1.639202             5.020865   \n",
       "min       18.000000     1.000000       7.000000             0.000000   \n",
       "25%       46.000000     1.555494      27.000000             2.000000   \n",
       "50%       46.000000     2.399720      27.000000             4.000000   \n",
       "75%       46.000000     3.666489      27.000000             7.000000   \n",
       "max       63.000000    25.243939      35.000000            54.000000   \n",
       "\n",
       "       CreditAccountTotal  CreditAccountActivePor  \\\n",
       "count         6136.000000             6136.000000   \n",
       "mean            17.680248                0.410867   \n",
       "std             22.402551                0.304992   \n",
       "min              0.000000                0.000000   \n",
       "25%              3.750000                0.173905   \n",
       "50%             10.000000                0.347815   \n",
       "75%             23.000000                0.599940   \n",
       "max            198.000000                0.999909   \n",
       "\n",
       "       Outstanding_Balance_Secured  Outstanding_Balance_UnSecured_Percentage  \\\n",
       "count                 6.136000e+03                               6136.000000   \n",
       "mean                  2.321834e+05                                 59.145860   \n",
       "std                   1.192120e+06                                 43.990324   \n",
       "min                  -2.399160e+05                                -53.000000   \n",
       "25%                   0.000000e+00                                  5.000000   \n",
       "50%                   0.000000e+00                                 83.000000   \n",
       "75%                   6.794125e+04                                100.000000   \n",
       "max                   4.690287e+07                                181.000000   \n",
       "\n",
       "       Outstanding_Balance_All  Outstanding_Balance_Secured_Percentage  \\\n",
       "count             6.136000e+03                             6136.000000   \n",
       "mean              4.066165e+05                               24.629726   \n",
       "std               1.482755e+06                               37.434632   \n",
       "min              -1.482305e+06                              -46.000000   \n",
       "25%               8.936250e+03                                0.000000   \n",
       "50%               6.749900e+04                                0.000000   \n",
       "75%               3.183882e+05                               51.000000   \n",
       "max               4.785170e+07                              153.000000   \n",
       "\n",
       "       Outstanding_Balance_UnSecured  Diff_dateBirth  State_nuniq  \\\n",
       "count                   6.136000e+03     6136.000000  6136.000000   \n",
       "mean                    1.480976e+05    11379.437256    11.039039   \n",
       "std                     5.446422e+05     2365.042937    11.171470   \n",
       "min                    -1.482305e+06     6949.000000     1.000000   \n",
       "25%                     2.643750e+03     9523.000000     3.997003   \n",
       "50%                     2.555050e+04    11084.500000     7.498375   \n",
       "75%                     1.177898e+05    12879.750000    14.328890   \n",
       "max                     2.997542e+07    31682.000000   182.409295   \n",
       "\n",
       "       Birth_nuniq  TotalCAPSLast90Days  TotalCAPSLast7Days  \\\n",
       "count  6136.000000          6136.000000         6136.000000   \n",
       "mean     12.567700             4.516949            2.317797   \n",
       "std      11.354860             4.637332            3.341237   \n",
       "min       1.000000             0.000000            0.000000   \n",
       "25%       4.998001             2.000000            0.000000   \n",
       "50%       9.330556             3.000000            1.000000   \n",
       "75%      16.328862             6.000000            3.000000   \n",
       "max     146.427286            98.000000           66.000000   \n",
       "\n",
       "       TotalCAPSLast30Days  TotalCAPSLast180Days  CAPSLast30Days  \\\n",
       "count          6136.000000           6136.000000     6136.000000   \n",
       "mean              3.073990              6.113429        1.310952   \n",
       "std               3.786141              5.798618        1.888096   \n",
       "min               0.000000              0.000000        0.000000   \n",
       "25%               1.000000              2.000000        0.000000   \n",
       "50%               2.000000              5.000000        1.000000   \n",
       "75%               4.000000              8.000000        2.000000   \n",
       "max              95.000000            107.000000       94.000000   \n",
       "\n",
       "       CAPSLast7Days  CAPSLast180Days  NonCreditCAPSLast180Days    Pin_nuniq  \\\n",
       "count    6136.000000      6136.000000               6136.000000  6136.000000   \n",
       "mean        0.554759         4.350391                  1.763038     8.711713   \n",
       "std         0.871686         4.230650                  3.216437     7.856790   \n",
       "min         0.000000         0.000000                  0.000000     1.000000   \n",
       "25%         0.000000         2.000000                  0.000000     3.499583   \n",
       "50%         0.000000         3.000000                  0.000000     6.497251   \n",
       "75%         1.000000         6.000000                  2.000000    11.306700   \n",
       "max        23.000000       100.000000                 66.000000   123.292569   \n",
       "\n",
       "         Pan_nuniq  Ident_nuniq  Name_nuniq2   Tel_nuniq2  Email_nuniq2  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000   6136.000000   \n",
       "mean     44.733145     6.755132   149.206160    45.671610     72.427314   \n",
       "std      49.939239     8.042503   111.090046    33.177066     45.312008   \n",
       "min       1.000000     1.000000     7.000000    14.000000      5.000000   \n",
       "25%      11.989011     1.999001    71.000000    28.000000     43.000000   \n",
       "50%      27.973027     3.998501   122.000000    40.000000     64.000000   \n",
       "75%      59.941059     8.347797   197.000000    58.000000     95.000000   \n",
       "max     470.530470    99.901099  1108.000000   274.000000    416.000000   \n",
       "\n",
       "        Pan_nuniq2  Account_nuniq2  Ident_nuniq2  Gender_nuniq  \\\n",
       "count  6136.000000     6136.000000   6136.000000   6136.000000   \n",
       "mean     15.206812       13.340613     35.103977     25.107241   \n",
       "std       4.525155        2.485758     17.232272     25.193642   \n",
       "min       5.000000        5.000000      5.000000      1.000000   \n",
       "25%      14.000000       14.000000     30.000000      7.993007   \n",
       "50%      14.000000       14.000000     30.000000     16.992004   \n",
       "75%      14.000000       14.000000     45.000000     33.967033   \n",
       "max      70.000000       68.000000     90.000000    301.699301   \n",
       "\n",
       "       Amount_Past_Due35_sum_30  Amount_Past_Due35_min_30  \\\n",
       "count                    6136.0                    6136.0   \n",
       "mean                        0.0                       0.0   \n",
       "std                         0.0                       0.0   \n",
       "min                         0.0                       0.0   \n",
       "25%                         0.0                       0.0   \n",
       "50%                         0.0                       0.0   \n",
       "75%                         0.0                       0.0   \n",
       "max                         0.0                       0.0   \n",
       "\n",
       "       Amount_Past_Due35_sum_90  Amount_Past_Due35_mean_90  \\\n",
       "count               6136.000000                6136.000000   \n",
       "mean                 239.247718                 112.860324   \n",
       "std                 1980.411211                1292.641299   \n",
       "min                    0.000000                   0.000000   \n",
       "25%                    0.000000                   0.000000   \n",
       "50%                    0.000000                   0.000000   \n",
       "75%                    0.000000                   0.000000   \n",
       "max                79346.000000               79346.000000   \n",
       "\n",
       "       Amount_Past_Due35_max_90  Amount_Past_Due35_min_90  \\\n",
       "count               6136.000000               6136.000000   \n",
       "mean                 224.198338                 56.888690   \n",
       "std                 1868.988912               1182.143906   \n",
       "min                    0.000000                  0.000000   \n",
       "25%                    0.000000                  0.000000   \n",
       "50%                    0.000000                  0.000000   \n",
       "75%                    0.000000                  0.000000   \n",
       "max                79346.000000              79346.000000   \n",
       "\n",
       "       Amount_Past_Due35_std_90  Amount_Past_Due35_sum_360  \\\n",
       "count               6136.000000               6.136000e+03   \n",
       "mean                  74.066450               3.863638e+03   \n",
       "std                  648.455157               7.951178e+04   \n",
       "min                    0.000000               0.000000e+00   \n",
       "25%                    0.000000               0.000000e+00   \n",
       "50%                    0.000000               0.000000e+00   \n",
       "75%                    0.000000               0.000000e+00   \n",
       "max                16343.123331               5.560699e+06   \n",
       "\n",
       "       Amount_Past_Due35_mean_360  Amount_Past_Due35_max_360  \\\n",
       "count                6.136000e+03               6.136000e+03   \n",
       "mean                 1.055790e+03               2.768069e+03   \n",
       "std                  3.339734e+04               4.528668e+04   \n",
       "min                  0.000000e+00               0.000000e+00   \n",
       "25%                  0.000000e+00               0.000000e+00   \n",
       "50%                  0.000000e+00               0.000000e+00   \n",
       "75%                  0.000000e+00               0.000000e+00   \n",
       "max                  2.525458e+06               2.525458e+06   \n",
       "\n",
       "       Amount_Past_Due35_std_360  Amount_Past_Due35_sum_9999  \\\n",
       "count                6136.000000                6.136000e+03   \n",
       "mean                  688.673144                3.608857e+04   \n",
       "std                  8479.135303                2.955848e+05   \n",
       "min                     0.000000                0.000000e+00   \n",
       "25%                     0.000000                0.000000e+00   \n",
       "50%                     0.000000                0.000000e+00   \n",
       "75%                     0.000000                8.611000e+03   \n",
       "max                597647.741895                1.702965e+07   \n",
       "\n",
       "       Amount_Past_Due35_max_9999  Amount_Past_Due35_min_9999  \\\n",
       "count                6.136000e+03                 6136.000000   \n",
       "mean                 2.288015e+04                  233.071219   \n",
       "std                  1.780701e+05                 4987.828210   \n",
       "min                  0.000000e+00                    0.000000   \n",
       "25%                  0.000000e+00                    0.000000   \n",
       "50%                  0.000000e+00                    0.000000   \n",
       "75%                  6.451250e+03                    0.000000   \n",
       "max                  9.116532e+06               312825.000000   \n",
       "\n",
       "       Amount_Past_Due35_std_9999  \\\n",
       "count                6.136000e+03   \n",
       "mean                 5.873529e+03   \n",
       "std                  5.260209e+04   \n",
       "min                  0.000000e+00   \n",
       "25%                  0.000000e+00   \n",
       "50%                  0.000000e+00   \n",
       "75%                  1.646535e+03   \n",
       "max                  3.294129e+06   \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_max_30  \\\n",
       "count                                      6136.000000   \n",
       "mean                                       1842.499185   \n",
       "std                                       20573.760948   \n",
       "min                                           0.000000   \n",
       "25%                                           0.000000   \n",
       "50%                                           0.000000   \n",
       "75%                                           0.000000   \n",
       "max                                      800000.000000   \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_min_30  \\\n",
       "count                                      6136.000000   \n",
       "mean                                       1400.405965   \n",
       "std                                       14136.590112   \n",
       "min                                           0.000000   \n",
       "25%                                           0.000000   \n",
       "50%                                           0.000000   \n",
       "75%                                           0.000000   \n",
       "max                                      640000.000000   \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_std_30  \\\n",
       "count                                      6136.000000   \n",
       "mean                                        214.083346   \n",
       "std                                        7327.705454   \n",
       "min                                           0.000000   \n",
       "25%                                           0.000000   \n",
       "50%                                           0.000000   \n",
       "75%                                           0.000000   \n",
       "max                                      399700.000000   \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_sum_90  \\\n",
       "count                                     6.136000e+03   \n",
       "mean                                      3.913422e+04   \n",
       "std                                       1.471274e+05   \n",
       "min                                       0.000000e+00   \n",
       "25%                                       0.000000e+00   \n",
       "50%                                       5.995000e+02   \n",
       "75%                                       2.500000e+04   \n",
       "max                                       3.890282e+06   \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_mean_90  \\\n",
       "count                                      6.136000e+03   \n",
       "mean                                       1.803476e+04   \n",
       "std                                        8.671773e+04   \n",
       "min                                        0.000000e+00   \n",
       "25%                                        0.000000e+00   \n",
       "50%                                        5.500000e+02   \n",
       "75%                                        9.431125e+03   \n",
       "max                                        2.500000e+06   \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_max_90  \\\n",
       "count                                     6.136000e+03   \n",
       "mean                                      2.751901e+04   \n",
       "std                                       1.188054e+05   \n",
       "min                                       0.000000e+00   \n",
       "25%                                       0.000000e+00   \n",
       "50%                                       5.540000e+02   \n",
       "75%                                       1.289375e+04   \n",
       "max                                       2.640000e+06   \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_min_90  \\\n",
       "count                                     6.136000e+03   \n",
       "mean                                      1.215874e+04   \n",
       "std                                       7.886895e+04   \n",
       "min                                       0.000000e+00   \n",
       "25%                                       0.000000e+00   \n",
       "50%                                       2.500000e+02   \n",
       "75%                                       5.450000e+03   \n",
       "max                                       2.500000e+06   \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "count                                     6.136000e+03   \n",
       "mean                                      6.657990e+03   \n",
       "std                                       3.900276e+04   \n",
       "min                                       0.000000e+00   \n",
       "25%                                       0.000000e+00   \n",
       "50%                                       0.000000e+00   \n",
       "75%                                       1.080156e+03   \n",
       "max                                       1.044503e+06   \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_sum_360  \\\n",
       "count                                      6.136000e+03   \n",
       "mean                                       1.886931e+05   \n",
       "std                                        4.880868e+05   \n",
       "min                                        0.000000e+00   \n",
       "25%                                        1.734750e+03   \n",
       "50%                                        4.234450e+04   \n",
       "75%                                        1.753790e+05   \n",
       "max                                        1.371432e+07   \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_max_360  \\\n",
       "count                                      6.136000e+03   \n",
       "mean                                       1.048791e+05   \n",
       "std                                        3.100066e+05   \n",
       "min                                        0.000000e+00   \n",
       "25%                                        1.000000e+03   \n",
       "50%                                        1.664800e+04   \n",
       "75%                                        7.000000e+04   \n",
       "max                                        6.832170e+06   \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_std_360  \\\n",
       "count                                      6.136000e+03   \n",
       "mean                                       3.124546e+04   \n",
       "std                                        1.109240e+05   \n",
       "min                                        0.000000e+00   \n",
       "25%                                        0.000000e+00   \n",
       "50%                                        2.934600e+03   \n",
       "75%                                        1.715273e+04   \n",
       "max                                        3.403592e+06   \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "count                                       6.136000e+03   \n",
       "mean                                        8.613151e+05   \n",
       "std                                         2.268388e+06   \n",
       "min                                         0.000000e+00   \n",
       "25%                                         5.000000e+04   \n",
       "50%                                         2.294945e+05   \n",
       "75%                                         8.308892e+05   \n",
       "max                                         6.425211e+07   \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_mean_9999  \\\n",
       "count                                       6.136000e+03    \n",
       "mean                                        5.927062e+04    \n",
       "std                                         1.570243e+05    \n",
       "min                                         0.000000e+00    \n",
       "25%                                         6.928900e+03    \n",
       "50%                                         2.030875e+04    \n",
       "75%                                         5.530666e+04    \n",
       "max                                         5.000000e+06    \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "count                                       6.136000e+03   \n",
       "mean                                        3.116380e+05   \n",
       "std                                         9.633861e+05   \n",
       "min                                         0.000000e+00   \n",
       "25%                                         1.879675e+04   \n",
       "50%                                         7.397500e+04   \n",
       "75%                                         2.812500e+05   \n",
       "max                                         4.000000e+07   \n",
       "\n",
       "       Highest_Credit_or_Original_Loan_Amount58_std_9999  \\\n",
       "count                                       6.136000e+03   \n",
       "mean                                        8.097116e+04   \n",
       "std                                         2.521924e+05   \n",
       "min                                         0.000000e+00   \n",
       "25%                                         3.627108e+03   \n",
       "50%                                         1.935719e+04   \n",
       "75%                                         6.807296e+04   \n",
       "max                                         8.412044e+06   \n",
       "\n",
       "       Terms_Duration34_sum_30  Terms_Duration34_std_30  \\\n",
       "count              6136.000000              6136.000000   \n",
       "mean                  0.237940                 0.007241   \n",
       "std                   2.621602                 0.257060   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                 120.000000                17.500000   \n",
       "\n",
       "       Terms_Duration34_sum_90  Terms_Duration34_std_90  \\\n",
       "count              6136.000000              6136.000000   \n",
       "mean                  4.366281                 0.524265   \n",
       "std                  15.819469                 3.959626   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   3.000000                 0.000000   \n",
       "max                 733.000000               176.792781   \n",
       "\n",
       "       Terms_Duration34_mean_360  Terms_Duration34_max_360  \\\n",
       "count                6136.000000               6136.000000   \n",
       "mean                    6.179949                 10.443041   \n",
       "std                    15.990181                 25.321545   \n",
       "min                     0.000000                  0.000000   \n",
       "25%                     0.000000                  0.000000   \n",
       "50%                     1.333333                  2.000000   \n",
       "75%                     6.000000                 12.000000   \n",
       "max                   264.000000                360.000000   \n",
       "\n",
       "       Terms_Duration34_min_360  Terms_Duration34_std_360  \\\n",
       "count               6136.000000               6136.000000   \n",
       "mean                   4.156943                  2.490091   \n",
       "std                   13.526580                  9.008236   \n",
       "min                    0.000000                  0.000000   \n",
       "25%                    0.000000                  0.000000   \n",
       "50%                    1.000000                  0.000000   \n",
       "75%                    3.000000                  1.462395   \n",
       "max                  264.000000                176.792781   \n",
       "\n",
       "       Terms_Duration34_sum_9999  Terms_Duration34_mean_9999  \\\n",
       "count                6136.000000                 6136.000000   \n",
       "mean                   71.124185                   12.628921   \n",
       "std                   128.912589                   22.461770   \n",
       "min                     0.000000                    0.000000   \n",
       "25%                     3.000000                    1.000000   \n",
       "50%                    25.000000                    6.000000   \n",
       "75%                    79.000000                   13.148611   \n",
       "max                  1644.000000                  360.000000   \n",
       "\n",
       "       Terms_Duration34_max_9999  Terms_Duration34_min_9999  \\\n",
       "count                6136.000000                6136.000000   \n",
       "mean                   31.290580                   5.609599   \n",
       "std                    54.330911                  15.607764   \n",
       "min                     0.000000                   0.000000   \n",
       "25%                     1.000000                   1.000000   \n",
       "50%                    12.000000                   1.000000   \n",
       "75%                    36.000000                   3.000000   \n",
       "max                   546.000000                 360.000000   \n",
       "\n",
       "       Terms_Duration34_std_9999  Payment_Rating34_sum_90  \\\n",
       "count                6136.000000              6136.000000   \n",
       "mean                    8.824554                 0.005704   \n",
       "std                    18.283755                 0.087341   \n",
       "min                     0.000000                 0.000000   \n",
       "25%                     0.000000                 0.000000   \n",
       "50%                     2.500000                 0.000000   \n",
       "75%                     9.728044                 0.000000   \n",
       "max                   190.322898                 3.000000   \n",
       "\n",
       "       Payment_Rating34_mean_90  Payment_Rating34_max_90  \\\n",
       "count               6136.000000              6136.000000   \n",
       "mean                   0.003071                 0.005541   \n",
       "std                    0.060102                 0.084506   \n",
       "min                    0.000000                 0.000000   \n",
       "25%                    0.000000                 0.000000   \n",
       "50%                    0.000000                 0.000000   \n",
       "75%                    0.000000                 0.000000   \n",
       "max                    3.000000                 3.000000   \n",
       "\n",
       "       Payment_Rating34_min_90  Payment_Rating34_std_90  \\\n",
       "count              6136.000000              6136.000000   \n",
       "mean                  0.001793                 0.001664   \n",
       "std                   0.055622                 0.028000   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                   3.000000                 0.600000   \n",
       "\n",
       "       Payment_Rating34_sum_360  Payment_Rating34_mean_360  \\\n",
       "count               6136.000000                6136.000000   \n",
       "mean                   0.561278                   0.129771   \n",
       "std                    2.865327                   0.610729   \n",
       "min                    0.000000                   0.000000   \n",
       "25%                    0.000000                   0.000000   \n",
       "50%                    0.000000                   0.000000   \n",
       "75%                    0.000000                   0.000000   \n",
       "max                   99.000000                   6.000000   \n",
       "\n",
       "       Payment_Rating34_max_360  Payment_Rating34_min_360  \\\n",
       "count               6136.000000               6136.000000   \n",
       "mean                   0.339472                  0.053781   \n",
       "std                    1.181622                  0.487873   \n",
       "min                    0.000000                  0.000000   \n",
       "25%                    0.000000                  0.000000   \n",
       "50%                    0.000000                  0.000000   \n",
       "75%                    0.000000                  0.000000   \n",
       "max                    6.000000                  6.000000   \n",
       "\n",
       "       Payment_Rating34_std_360  Payment_Rating34_sum_9999  \\\n",
       "count               6136.000000                6136.000000   \n",
       "mean                   0.107031                   3.468220   \n",
       "std                    0.423333                   9.241554   \n",
       "min                    0.000000                   0.000000   \n",
       "25%                    0.000000                   0.000000   \n",
       "50%                    0.000000                   0.000000   \n",
       "75%                    0.000000                   2.000000   \n",
       "max                    3.000000                 202.000000   \n",
       "\n",
       "       Payment_Rating34_mean_9999  Payment_Rating34_max_9999  \\\n",
       "count                 6136.000000                6136.000000   \n",
       "mean                     0.293677                   1.407106   \n",
       "std                      0.796765                   2.387042   \n",
       "min                      0.000000                   0.000000   \n",
       "25%                      0.000000                   0.000000   \n",
       "50%                      0.000000                   0.000000   \n",
       "75%                      0.130721                   2.000000   \n",
       "max                      6.000000                   6.000000   \n",
       "\n",
       "       Payment_Rating34_min_9999  Payment_Rating34_std_9999  \\\n",
       "count                6136.000000                6136.000000   \n",
       "mean                    0.050359                   0.433595   \n",
       "std                     0.526624                   0.819394   \n",
       "min                     0.000000                   0.000000   \n",
       "25%                     0.000000                   0.000000   \n",
       "50%                     0.000000                   0.000000   \n",
       "75%                     0.000000                   0.408089   \n",
       "max                     6.000000                   3.000000   \n",
       "\n",
       "       Current_Balance35_mean_30  Current_Balance35_min_30  \\\n",
       "count                6136.000000               6136.000000   \n",
       "mean                 1549.319540               1347.766786   \n",
       "std                 16000.821651              14472.749982   \n",
       "min                     0.000000                  0.000000   \n",
       "25%                     0.000000                  0.000000   \n",
       "50%                     0.000000                  0.000000   \n",
       "75%                     0.000000                  0.000000   \n",
       "max                640000.000000             640000.000000   \n",
       "\n",
       "       Current_Balance35_std_30  Current_Balance35_sum_90  \\\n",
       "count               6136.000000              6.136000e+03   \n",
       "mean                 202.630012              3.102545e+04   \n",
       "std                 6686.584081              1.254270e+05   \n",
       "min                    0.000000              0.000000e+00   \n",
       "25%                    0.000000              0.000000e+00   \n",
       "50%                    0.000000              0.000000e+00   \n",
       "75%                    0.000000              1.539700e+04   \n",
       "max               376079.000000              2.761657e+06   \n",
       "\n",
       "       Current_Balance35_mean_90  Current_Balance35_max_90  \\\n",
       "count               6.136000e+03              6.136000e+03   \n",
       "mean                1.616508e+04              2.623001e+04   \n",
       "std                 8.439949e+04              1.145393e+05   \n",
       "min                 0.000000e+00              0.000000e+00   \n",
       "25%                 0.000000e+00              0.000000e+00   \n",
       "50%                 0.000000e+00              0.000000e+00   \n",
       "75%                 5.877900e+03              1.199925e+04   \n",
       "max                 2.500000e+06              2.639481e+06   \n",
       "\n",
       "       Current_Balance35_std_90  Current_Balance35_sum_360  \\\n",
       "count              6.136000e+03               6.136000e+03   \n",
       "mean               6.855102e+03               1.318314e+05   \n",
       "std                3.680146e+04               4.020219e+05   \n",
       "min                0.000000e+00              -9.335500e+04   \n",
       "25%                0.000000e+00               0.000000e+00   \n",
       "50%                0.000000e+00               1.735900e+04   \n",
       "75%                2.330225e+03               9.270875e+04   \n",
       "max                1.044370e+06               1.370682e+07   \n",
       "\n",
       "       Current_Balance35_max_360  Current_Balance35_std_360  \\\n",
       "count               6.136000e+03               6.136000e+03   \n",
       "mean                9.374314e+04               2.886416e+04   \n",
       "std                 2.892165e+05               1.042954e+05   \n",
       "min                 0.000000e+00               0.000000e+00   \n",
       "25%                 0.000000e+00               0.000000e+00   \n",
       "50%                 1.100000e+04               2.445148e+03   \n",
       "75%                 5.937750e+04               1.549253e+04   \n",
       "max                 6.832170e+06               3.405465e+06   \n",
       "\n",
       "       Current_Balance35_max_9999  Current_Balance35_std_9999  \\\n",
       "count                6.136000e+03                6.136000e+03   \n",
       "mean                 2.401024e+05                6.045691e+04   \n",
       "std                  8.547554e+05                2.181042e+05   \n",
       "min                 -1.888000e+03                0.000000e+00   \n",
       "25%                  6.241000e+03                1.332205e+03   \n",
       "50%                  4.115650e+04                1.011933e+04   \n",
       "75%                  1.685515e+05                4.397435e+04   \n",
       "max                  2.997542e+07                6.910147e+06   \n",
       "\n",
       "       Settlement_Amount37_max_360  Settlement_Amount37_min_360  \\\n",
       "count                  6136.000000                  6136.000000   \n",
       "mean                      8.986636                     8.072360   \n",
       "std                     372.832249                   367.795452   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.000000                     0.000000   \n",
       "max                   23000.000000                 23000.000000   \n",
       "\n",
       "       Settlement_Amount37_std_360  Settlement_Amount37_sum_9999  \\\n",
       "count                  6136.000000                   6136.000000   \n",
       "mean                      0.423596                   2799.688722   \n",
       "std                      28.826320                  28650.846838   \n",
       "min                       0.000000                      0.000000   \n",
       "25%                       0.000000                      0.000000   \n",
       "50%                       0.000000                      0.000000   \n",
       "75%                       0.000000                      0.000000   \n",
       "max                    2250.485182                 806251.000000   \n",
       "\n",
       "       Settlement_Amount37_mean_9999  Settlement_Amount37_max_9999  \\\n",
       "count                    6136.000000                   6136.000000   \n",
       "mean                     1281.338850                   2527.565352   \n",
       "std                     13115.805848                  27164.327348   \n",
       "min                         0.000000                      0.000000   \n",
       "25%                         0.000000                      0.000000   \n",
       "50%                         0.000000                      0.000000   \n",
       "75%                         0.000000                      0.000000   \n",
       "max                    403125.500000                 806251.000000   \n",
       "\n",
       "       Settlement_Amount37_min_9999  Settlement_Amount37_std_9999  \\\n",
       "count                   6136.000000                   6136.000000   \n",
       "mean                     574.501304                    877.045766   \n",
       "std                     7370.664356                  12294.647274   \n",
       "min                        0.000000                      0.000000   \n",
       "25%                        0.000000                      0.000000   \n",
       "50%                        0.000000                      0.000000   \n",
       "75%                        0.000000                      0.000000   \n",
       "max                   218424.000000                 403125.500000   \n",
       "\n",
       "       Value_of_Collateral39_std_90  Value_of_Collateral39_std_360  \\\n",
       "count                   6136.000000                   6.136000e+03   \n",
       "mean                     470.222625                   2.968804e+03   \n",
       "std                    12092.641554                   3.899199e+04   \n",
       "min                        0.000000                   0.000000e+00   \n",
       "25%                        0.000000                   0.000000e+00   \n",
       "50%                        0.000000                   0.000000e+00   \n",
       "75%                        0.000000                   0.000000e+00   \n",
       "max                   619000.000000                   1.471134e+06   \n",
       "\n",
       "       Written_Off_Amt_Total41_sum_360  Written_Off_Amt_Total41_mean_360  \\\n",
       "count                      6136.000000                       6136.000000   \n",
       "mean                         74.166721                         56.564754   \n",
       "std                        1511.736394                       1172.156733   \n",
       "min                           0.000000                          0.000000   \n",
       "25%                           0.000000                          0.000000   \n",
       "50%                           0.000000                          0.000000   \n",
       "75%                           0.000000                          0.000000   \n",
       "max                       60504.000000                      46618.000000   \n",
       "\n",
       "       Written_Off_Amt_Total41_min_360  Written_Off_Amt_Total41_std_360  \\\n",
       "count                      6136.000000                      6136.000000   \n",
       "mean                         41.496904                        15.392005   \n",
       "std                        1038.578609                       531.822083   \n",
       "min                           0.000000                         0.000000   \n",
       "25%                           0.000000                         0.000000   \n",
       "50%                           0.000000                         0.000000   \n",
       "75%                           0.000000                         0.000000   \n",
       "max                       46618.000000                     30252.000000   \n",
       "\n",
       "       Written_Off_Amt_Total41_sum_9999  Written_Off_Amt_Total41_mean_9999  \\\n",
       "count                      6.136000e+03                       6.136000e+03   \n",
       "mean                       1.454459e+04                       4.562845e+03   \n",
       "std                        8.223104e+04                       3.331441e+04   \n",
       "min                        0.000000e+00                       0.000000e+00   \n",
       "25%                        0.000000e+00                       0.000000e+00   \n",
       "50%                        0.000000e+00                       0.000000e+00   \n",
       "75%                        0.000000e+00                       0.000000e+00   \n",
       "max                        2.016302e+06                       1.934827e+06   \n",
       "\n",
       "       Written_Off_Amt_Total41_max_9999  Written_Off_Amt_Total41_min_9999  \\\n",
       "count                      6.136000e+03                      6.136000e+03   \n",
       "mean                       1.109771e+04                      1.982555e+03   \n",
       "std                        6.304831e+04                      2.911856e+04   \n",
       "min                        0.000000e+00                      0.000000e+00   \n",
       "25%                        0.000000e+00                      0.000000e+00   \n",
       "50%                        0.000000e+00                      0.000000e+00   \n",
       "75%                        0.000000e+00                      0.000000e+00   \n",
       "max                        1.934827e+06                      1.934827e+06   \n",
       "\n",
       "       Written_Off_Amt_Total41_std_9999  Written_Off_Amt_Principal45_sum_360  \\\n",
       "count                       6136.000000                          6136.000000   \n",
       "mean                        3512.317134                            53.286832   \n",
       "std                        20631.582363                          1169.444796   \n",
       "min                            0.000000                             0.000000   \n",
       "25%                            0.000000                             0.000000   \n",
       "50%                            0.000000                             0.000000   \n",
       "75%                            0.000000                             0.000000   \n",
       "max                       686451.240002                         41144.000000   \n",
       "\n",
       "       Written_Off_Amt_Principal45_mean_360  \\\n",
       "count                           6136.000000   \n",
       "mean                              42.240371   \n",
       "std                              968.081682   \n",
       "min                                0.000000   \n",
       "25%                                0.000000   \n",
       "50%                                0.000000   \n",
       "75%                                0.000000   \n",
       "max                            41144.000000   \n",
       "\n",
       "       Written_Off_Amt_Principal45_min_360  \\\n",
       "count                          6136.000000   \n",
       "mean                             38.133475   \n",
       "std                             946.056981   \n",
       "min                               0.000000   \n",
       "25%                               0.000000   \n",
       "50%                               0.000000   \n",
       "75%                               0.000000   \n",
       "max                           41144.000000   \n",
       "\n",
       "       Written_Off_Amt_Principal45_std_360  \\\n",
       "count                          6136.000000   \n",
       "mean                              5.050820   \n",
       "std                             206.147356   \n",
       "min                               0.000000   \n",
       "25%                               0.000000   \n",
       "50%                               0.000000   \n",
       "75%                               0.000000   \n",
       "max                           11914.000000   \n",
       "\n",
       "       Written_Off_Amt_Principal45_max_9999  \\\n",
       "count                          6.136000e+03   \n",
       "mean                           7.362520e+03   \n",
       "std                            4.358436e+04   \n",
       "min                            0.000000e+00   \n",
       "25%                            0.000000e+00   \n",
       "50%                            0.000000e+00   \n",
       "75%                            0.000000e+00   \n",
       "max                            1.264115e+06   \n",
       "\n",
       "       Written_Off_Amt_Principal45_min_9999  Rate_of_Interest36_sum_30  \\\n",
       "count                           6136.000000                6136.000000   \n",
       "mean                            1022.178618                   1.415998   \n",
       "std                            12797.110416                   8.273249   \n",
       "min                                0.000000                   0.000000   \n",
       "25%                                0.000000                   0.000000   \n",
       "50%                                0.000000                   0.000000   \n",
       "75%                                0.000000                   0.000000   \n",
       "max                           493670.000000                 184.800000   \n",
       "\n",
       "       Rate_of_Interest36_std_30  Rate_of_Interest36_sum_90  \\\n",
       "count                6136.000000                6136.000000   \n",
       "mean                    0.048821                  20.839121   \n",
       "std                     1.322657                  50.676796   \n",
       "min                     0.000000                   0.000000   \n",
       "25%                     0.000000                   0.000000   \n",
       "50%                     0.000000                   0.000000   \n",
       "75%                     0.000000                  18.000000   \n",
       "max                    61.659711                1223.407000   \n",
       "\n",
       "       Rate_of_Interest36_mean_90  Rate_of_Interest36_max_90  \\\n",
       "count                 6136.000000                6136.000000   \n",
       "mean                     8.758644                  10.954353   \n",
       "std                     19.675049                  26.383168   \n",
       "min                      0.000000                   0.000000   \n",
       "25%                      0.000000                   0.000000   \n",
       "50%                      0.000000                   0.000000   \n",
       "75%                     18.000000                  18.000000   \n",
       "max                    203.901167                 625.714000   \n",
       "\n",
       "       Rate_of_Interest36_std_90  Rate_of_Interest36_sum_360  \\\n",
       "count                6136.000000                 6136.000000   \n",
       "mean                    1.486087                   67.288524   \n",
       "std                     7.396629                  148.740940   \n",
       "min                     0.000000                    0.000000   \n",
       "25%                     0.000000                    0.000000   \n",
       "50%                     0.000000                    0.000000   \n",
       "75%                     0.000000                   64.000000   \n",
       "max                   235.454483                 2126.733000   \n",
       "\n",
       "       Rate_of_Interest36_mean_360  Rate_of_Interest36_max_360  \\\n",
       "count                  6136.000000                 6136.000000   \n",
       "mean                     12.982742                   20.060366   \n",
       "std                      24.494187                   47.022583   \n",
       "min                       0.000000                    0.000000   \n",
       "25%                       0.000000                    0.000000   \n",
       "50%                       0.000000                    0.000000   \n",
       "75%                      18.000000                   18.000000   \n",
       "max                     625.714000                  625.714000   \n",
       "\n",
       "       Rate_of_Interest36_min_360  Rate_of_Interest36_std_360  \\\n",
       "count                 6136.000000                 6136.000000   \n",
       "mean                     9.824081                    3.670199   \n",
       "std                     20.768641                   13.538977   \n",
       "min                      0.000000                    0.000000   \n",
       "25%                      0.000000                    0.000000   \n",
       "50%                      0.000000                    0.000000   \n",
       "75%                     18.000000                    0.000000   \n",
       "max                    625.714000                  283.421500   \n",
       "\n",
       "       Rate_of_Interest36_sum_9999  Rate_of_Interest36_mean_9999  \\\n",
       "count                  6136.000000                   6136.000000   \n",
       "mean                    114.862397                     15.875705   \n",
       "std                     222.533453                     25.023740   \n",
       "min                       0.000000                      0.000000   \n",
       "25%                       0.000000                      0.000000   \n",
       "50%                      28.025000                     13.280000   \n",
       "75%                     130.000000                     19.660000   \n",
       "max                    3182.898000                    625.714000   \n",
       "\n",
       "       Rate_of_Interest36_max_9999  Rate_of_Interest36_min_9999  \\\n",
       "count                  6136.000000                  6136.000000   \n",
       "mean                     28.290541                    10.823290   \n",
       "std                      59.645579                    20.503744   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                      18.000000                     7.270000   \n",
       "75%                      30.000000                    18.000000   \n",
       "max                     834.286000                   625.714000   \n",
       "\n",
       "       Rate_of_Interest36_std_9999  Repayment_Tenure36_std_30  \\\n",
       "count                  6136.000000                6136.000000   \n",
       "mean                      5.772870                   0.018637   \n",
       "std                      17.331187                   0.808730   \n",
       "min                       0.000000                   0.000000   \n",
       "25%                       0.000000                   0.000000   \n",
       "50%                       0.000000                   0.000000   \n",
       "75%                       4.999380                   0.000000   \n",
       "max                     302.653683                  60.000000   \n",
       "\n",
       "       Repayment_Tenure36_mean_90  Repayment_Tenure36_max_90  \\\n",
       "count                 6136.000000                6136.000000   \n",
       "mean                     1.988793                   3.241362   \n",
       "std                      7.639657                  11.678759   \n",
       "min                      0.000000                   0.000000   \n",
       "25%                      0.000000                   0.000000   \n",
       "50%                      0.000000                   0.000000   \n",
       "75%                      1.000000                   2.000000   \n",
       "max                    180.000000                 360.000000   \n",
       "\n",
       "       Repayment_Tenure36_min_90  Repayment_Tenure36_std_90  \\\n",
       "count                6136.000000                6136.000000   \n",
       "mean                    1.215939                   0.886297   \n",
       "std                     6.382317                   4.464068   \n",
       "min                     0.000000                   0.000000   \n",
       "25%                     0.000000                   0.000000   \n",
       "50%                     0.000000                   0.000000   \n",
       "75%                     0.000000                   0.000000   \n",
       "max                   180.000000                 174.291250   \n",
       "\n",
       "       Repayment_Tenure36_sum_360  Repayment_Tenure36_mean_360  \\\n",
       "count                 6136.000000                  6136.000000   \n",
       "mean                    18.034550                     3.864039   \n",
       "std                     40.753255                    11.500115   \n",
       "min                      0.000000                     0.000000   \n",
       "25%                      0.000000                     0.000000   \n",
       "50%                      5.000000                     0.800000   \n",
       "75%                     20.000000                     3.000000   \n",
       "max                    789.000000                   240.000000   \n",
       "\n",
       "       Repayment_Tenure36_min_360  Repayment_Tenure36_std_360  \\\n",
       "count                 6136.000000                 6136.000000   \n",
       "mean                     1.479791                    3.253520   \n",
       "std                      8.586427                    9.403188   \n",
       "min                      0.000000                    0.000000   \n",
       "25%                      0.000000                    0.000000   \n",
       "50%                      0.000000                    0.266469   \n",
       "75%                      0.000000                    3.292461   \n",
       "max                    240.000000                  174.291250   \n",
       "\n",
       "       Repayment_Tenure36_mean_9999  Repayment_Tenure36_min_9999  \\\n",
       "count                   6136.000000                  6136.000000   \n",
       "mean                       5.513529                     0.727510   \n",
       "std                       10.664707                     5.196582   \n",
       "min                       -0.166667                    -1.000000   \n",
       "25%                        0.333333                     0.000000   \n",
       "50%                        1.976136                     0.000000   \n",
       "75%                        6.000000                     0.000000   \n",
       "max                      180.000000                   180.000000   \n",
       "\n",
       "       Repayment_Tenure36_std_9999  Income26_count_360  Income26_std_360  \\\n",
       "count                  6136.000000         6136.000000       6136.000000   \n",
       "mean                      8.481742            6.810626         98.873326   \n",
       "std                      15.162340           10.452750       3898.581883   \n",
       "min                       0.000000            0.000000          0.000000   \n",
       "25%                       0.329980            1.000000          0.000000   \n",
       "50%                       3.605551            3.000000          0.000000   \n",
       "75%                       9.761726            8.000000          0.000000   \n",
       "max                     183.092817          102.000000     240000.000000   \n",
       "\n",
       "       Open_Date29_max_30  Open_Date29_min_30  Open_Date29_mean_30  \\\n",
       "count         6136.000000         6136.000000          6136.000000   \n",
       "mean             1.890156            1.851532             1.871235   \n",
       "std              6.782954            6.656011             6.715065   \n",
       "min              0.000000            0.000000             0.000000   \n",
       "25%              0.000000            0.000000             0.000000   \n",
       "50%              0.000000            0.000000             0.000000   \n",
       "75%              0.000000            0.000000             0.000000   \n",
       "max             30.000000           30.000000            30.000000   \n",
       "\n",
       "       Open_Date29_nuniq_30  Open_Date29_maxcount_30  Open_Date29_max_90  \\\n",
       "count           6136.000000              6136.000000         6136.000000   \n",
       "mean               0.083279                 0.079857           36.946545   \n",
       "std                0.312323                 0.298016           37.262466   \n",
       "min                0.000000                 0.000000            0.000000   \n",
       "25%                0.000000                 0.000000            0.000000   \n",
       "50%                0.000000                 0.000000           35.000000   \n",
       "75%                0.000000                 0.000000           76.000000   \n",
       "max                4.000000                 4.000000           90.000000   \n",
       "\n",
       "       Open_Date29_mean_90  Open_Date29_mode_90  Open_Date29_nuniq_90  \\\n",
       "count          6136.000000          6136.000000           6136.000000   \n",
       "mean             31.813867            27.745926              1.422914   \n",
       "std              32.025118            29.660961              2.111541   \n",
       "min               0.000000             0.000000              0.000000   \n",
       "25%               0.000000             0.000000              0.000000   \n",
       "50%              33.750000            25.000000              1.000000   \n",
       "75%              62.000000            53.000000              2.000000   \n",
       "max              90.000000            90.000000             21.000000   \n",
       "\n",
       "       Open_Date29_maxcount_90  Open_Date29_max_360  Open_Date29_mean_360  \\\n",
       "count              6136.000000          6136.000000           6136.000000   \n",
       "mean                  0.632497           193.924707            130.409707   \n",
       "std                   0.740083           134.116951             92.972462   \n",
       "min                   0.000000             0.000000              0.000000   \n",
       "25%                   0.000000            64.000000             56.500000   \n",
       "50%                   1.000000           218.000000            135.712963   \n",
       "75%                   1.000000           324.250000            194.839286   \n",
       "max                   8.000000           360.000000            360.000000   \n",
       "\n",
       "       Open_Date29_mode_360  Open_Date29_nuniq_360  Open_Date29_maxcount_360  \\\n",
       "count           6136.000000            6136.000000               6136.000000   \n",
       "mean              94.523794               5.949804                  1.155313   \n",
       "std               91.813084               8.348975                  1.044174   \n",
       "min                0.000000               0.000000                  0.000000   \n",
       "25%               30.000000               1.000000                  1.000000   \n",
       "50%               66.000000               3.000000                  1.000000   \n",
       "75%              136.000000               7.250000                  1.000000   \n",
       "max              360.000000              82.000000                 13.000000   \n",
       "\n",
       "       Open_Date29_max_9999  Open_Date29_mean_9999  Open_Date29_mode_9999  \\\n",
       "count           6136.000000            6136.000000            6136.000000   \n",
       "mean            1433.123207             625.605366             382.677966   \n",
       "std             1211.694784             534.225322             563.404556   \n",
       "min                0.000000               0.000000               0.000000   \n",
       "25%              454.000000             229.708791              56.000000   \n",
       "50%             1177.000000             528.000000             140.000000   \n",
       "75%             2169.000000             869.400000             477.250000   \n",
       "max            10229.000000            5685.333333            6110.000000   \n",
       "\n",
       "       Open_Date29_maxcount_9999  Portfolio_Type34_nuniq_30  \\\n",
       "count                6136.000000                6136.000000   \n",
       "mean                    1.588005                   0.074478   \n",
       "std                     1.219943                   0.264425   \n",
       "min                     0.000000                   0.000000   \n",
       "25%                     1.000000                   0.000000   \n",
       "50%                     1.000000                   0.000000   \n",
       "75%                     2.000000                   0.000000   \n",
       "max                    40.000000                   2.000000   \n",
       "\n",
       "       Portfolio_Type34_nuniq_90  Portfolio_Type34_nuniq_360  \\\n",
       "count                6136.000000                 6136.000000   \n",
       "mean                    0.540254                    0.907432   \n",
       "std                     0.530113                    0.570309   \n",
       "min                     0.000000                    0.000000   \n",
       "25%                     0.000000                    1.000000   \n",
       "50%                     1.000000                    1.000000   \n",
       "75%                     1.000000                    1.000000   \n",
       "max                     2.000000                    3.000000   \n",
       "\n",
       "       Portfolio_Type34_nuniq_9999  Account_Type32_nuniq_30  \\\n",
       "count                  6136.000000              6136.000000   \n",
       "mean                      1.359192                 0.075782   \n",
       "std                       0.717728                 0.271361   \n",
       "min                       0.000000                 0.000000   \n",
       "25%                       1.000000                 0.000000   \n",
       "50%                       1.000000                 0.000000   \n",
       "75%                       2.000000                 0.000000   \n",
       "max                       4.000000                 2.000000   \n",
       "\n",
       "       Account_Type32_nuniq_90  Account_Type32_nuniq_360  \\\n",
       "count              6136.000000               6136.000000   \n",
       "mean                  0.658898                  1.493481   \n",
       "std                   0.728405                  1.175666   \n",
       "min                   0.000000                  0.000000   \n",
       "25%                   0.000000                  1.000000   \n",
       "50%                   1.000000                  1.000000   \n",
       "75%                   1.000000                  2.000000   \n",
       "max                   4.000000                  7.000000   \n",
       "\n",
       "       Account_Type32_nuniq_9999  Occupation_Code35_nuniq_30  \\\n",
       "count                6136.000000                 6136.000000   \n",
       "mean                    3.032269                    0.075945   \n",
       "std                     1.971831                    0.272215   \n",
       "min                     0.000000                    0.000000   \n",
       "25%                     2.000000                    0.000000   \n",
       "50%                     3.000000                    0.000000   \n",
       "75%                     4.000000                    0.000000   \n",
       "max                    13.000000                    2.000000   \n",
       "\n",
       "       Occupation_Code35_nuniq_90  Occupation_Code35_nuniq_360  \\\n",
       "count                 6136.000000                  6136.000000   \n",
       "mean                     0.559811                     0.916558   \n",
       "std                      0.564654                     0.576825   \n",
       "min                      0.000000                     0.000000   \n",
       "25%                      0.000000                     1.000000   \n",
       "50%                      1.000000                     1.000000   \n",
       "75%                      1.000000                     1.000000   \n",
       "max                      3.000000                     3.000000   \n",
       "\n",
       "       Occupation_Code35_nuniq_9999  AccountHoldertypeCode41_nuniq_90  \\\n",
       "count                   6136.000000                       6136.000000   \n",
       "mean                       1.378585                          0.527216   \n",
       "std                        0.662605                          0.505786   \n",
       "min                        0.000000                          0.000000   \n",
       "25%                        1.000000                          0.000000   \n",
       "50%                        1.000000                          1.000000   \n",
       "75%                        2.000000                          1.000000   \n",
       "max                        4.000000                          2.000000   \n",
       "\n",
       "       AccountHoldertypeCode41_nuniq_360  AccountHoldertypeCode41_nuniq_9999  \\\n",
       "count                        6136.000000                         6136.000000   \n",
       "mean                            0.821708                            1.130378   \n",
       "std                             0.459430                            0.552050   \n",
       "min                             0.000000                            0.000000   \n",
       "25%                             1.000000                            1.000000   \n",
       "50%                             1.000000                            1.000000   \n",
       "75%                             1.000000                            1.000000   \n",
       "max                             3.000000                            3.000000   \n",
       "\n",
       "       Payment_History_Profile43_mode_30  Payment_History_Profile43_mode_90  \\\n",
       "count                        6136.000000                         6136.00000   \n",
       "mean                            0.085398                            5.65189   \n",
       "std                             0.699196                           12.58330   \n",
       "min                             0.000000                            0.00000   \n",
       "25%                             0.000000                            0.00000   \n",
       "50%                             0.000000                            1.00000   \n",
       "75%                             0.000000                            1.00000   \n",
       "max                            36.000000                           36.00000   \n",
       "\n",
       "       Payment_History_Profile43_nuniq_90  Payment_History_Profile43_mode_360  \\\n",
       "count                         6136.000000                         6136.000000   \n",
       "mean                             0.778194                           16.727021   \n",
       "std                              0.866202                           17.627245   \n",
       "min                              0.000000                            0.000000   \n",
       "25%                              0.000000                            1.000000   \n",
       "50%                              1.000000                            1.000000   \n",
       "75%                              1.000000                           36.000000   \n",
       "max                              5.000000                           36.000000   \n",
       "\n",
       "       Payment_History_Profile43_nuniq_360  \\\n",
       "count                          6136.000000   \n",
       "mean                              2.687744   \n",
       "std                               2.492163   \n",
       "min                               0.000000   \n",
       "25%                               1.000000   \n",
       "50%                               2.000000   \n",
       "75%                               4.000000   \n",
       "max                              17.000000   \n",
       "\n",
       "       Payment_History_Profile43_mode_9999  \\\n",
       "count                          6136.000000   \n",
       "mean                             18.573501   \n",
       "std                              17.578052   \n",
       "min                               0.000000   \n",
       "25%                               1.000000   \n",
       "50%                              36.000000   \n",
       "75%                              36.000000   \n",
       "max                              36.000000   \n",
       "\n",
       "       Payment_History_Profile43_nuniq_9999  Date_Closed31_nuniq_30  \\\n",
       "count                           6136.000000             6136.000000   \n",
       "mean                               8.045306                0.076108   \n",
       "std                                7.787096                0.273663   \n",
       "min                                0.000000                0.000000   \n",
       "25%                                3.000000                0.000000   \n",
       "50%                                6.000000                0.000000   \n",
       "75%                               11.000000                0.000000   \n",
       "max                               78.000000                3.000000   \n",
       "\n",
       "       Date_Closed31_maxcount_30  Date_Closed31_max_90  Date_Closed31_min_90  \\\n",
       "count                6136.000000           6136.000000           6136.000000   \n",
       "mean                    0.003096             12.563233              8.535039   \n",
       "std                     0.068683             24.912435             38.584600   \n",
       "min                     0.000000              0.000000          -2651.000000   \n",
       "25%                     0.000000              0.000000              0.000000   \n",
       "50%                     0.000000              0.000000              0.000000   \n",
       "75%                     0.000000              0.000000              0.000000   \n",
       "max                     3.000000             89.000000             89.000000   \n",
       "\n",
       "       Date_Closed31_mean_90  Date_Closed31_mode_90  Date_Closed31_nuniq_90  \\\n",
       "count            6136.000000            6136.000000             6136.000000   \n",
       "mean               10.737836               9.300359                1.007008   \n",
       "std                21.354293              18.950695                1.494172   \n",
       "min              -160.833333               0.000000                0.000000   \n",
       "25%                 0.000000               0.000000                0.000000   \n",
       "50%                 0.000000               0.000000                1.000000   \n",
       "75%                 0.000000               0.000000                1.000000   \n",
       "max                89.000000              89.000000               20.000000   \n",
       "\n",
       "       Date_Closed31_maxcount_90  Date_Closed31_min_360  \\\n",
       "count                6136.000000            6136.000000   \n",
       "mean                    0.258638              35.268905   \n",
       "std                     0.580383             140.354309   \n",
       "min                     0.000000           -2651.000000   \n",
       "25%                     0.000000               0.000000   \n",
       "50%                     0.000000               0.000000   \n",
       "75%                     0.000000              61.000000   \n",
       "max                    11.000000             354.000000   \n",
       "\n",
       "       Date_Closed31_mode_360  Date_Closed31_nuniq_360  \\\n",
       "count             6136.000000              6136.000000   \n",
       "mean                50.464635                 4.085887   \n",
       "std                106.962473                 6.441964   \n",
       "min              -2334.000000                 0.000000   \n",
       "25%                  0.000000                 1.000000   \n",
       "50%                  3.500000                 1.000000   \n",
       "75%                 79.000000                 5.000000   \n",
       "max                355.000000                71.000000   \n",
       "\n",
       "       Date_Closed31_maxcount_360  Date_Closed31_max_9999  \\\n",
       "count                 6136.000000             6136.000000   \n",
       "mean                     0.754563              856.389342   \n",
       "std                      1.109959              753.530852   \n",
       "min                      0.000000                0.000000   \n",
       "25%                      0.000000              125.750000   \n",
       "50%                      1.000000              761.500000   \n",
       "75%                      1.000000             1356.250000   \n",
       "max                     15.000000             2556.000000   \n",
       "\n",
       "       Date_Closed31_min_9999  Date_Closed31_mean_9999  \\\n",
       "count            6.136000e+03              6136.000000   \n",
       "mean            -9.182529e+02               392.478665   \n",
       "std              4.209843e+04              2728.878706   \n",
       "min             -1.977556e+06           -135639.916667   \n",
       "25%              2.900000e+01                92.446078   \n",
       "50%              6.500000e+01               401.344720   \n",
       "75%              1.930000e+02               696.691176   \n",
       "max              2.503000e+03              2503.000000   \n",
       "\n",
       "       Date_Closed31_mode_9999  Date_Closed31_nuniq_9999  \\\n",
       "count              6136.000000               6136.000000   \n",
       "mean                244.736473                 11.906128   \n",
       "std                4583.217499                 15.715938   \n",
       "min             -357200.000000                  0.000000   \n",
       "25%                  37.000000                  2.000000   \n",
       "50%                 125.000000                  6.000000   \n",
       "75%                 416.000000                 16.000000   \n",
       "max                2503.000000                145.000000   \n",
       "\n",
       "       Date_of_Last_Payment40_nuniq_30  Date_of_Last_Payment40_maxcount_30  \\\n",
       "count                      6136.000000                         6136.000000   \n",
       "mean                          0.076760                            0.008638   \n",
       "std                           0.278208                            0.104146   \n",
       "min                           0.000000                            0.000000   \n",
       "25%                           0.000000                            0.000000   \n",
       "50%                           0.000000                            0.000000   \n",
       "75%                           0.000000                            0.000000   \n",
       "max                           3.000000                            4.000000   \n",
       "\n",
       "       Date_of_Last_Payment40_min_90  Date_of_Last_Payment40_nuniq_90  \\\n",
       "count                    6136.000000                      6136.000000   \n",
       "mean                      182.092568                         1.187581   \n",
       "std                      2720.319154                         1.691201   \n",
       "min                     -2347.000000                         0.000000   \n",
       "25%                         0.000000                         0.000000   \n",
       "50%                         0.000000                         1.000000   \n",
       "75%                        34.000000                         2.000000   \n",
       "max                     44590.000000                        21.000000   \n",
       "\n",
       "       Date_of_Last_Payment40_maxcount_90  Date_of_Last_Payment40_max_360  \\\n",
       "count                         6136.000000                     6136.000000   \n",
       "mean                             0.430411                      536.144557   \n",
       "std                              0.655276                     4263.031638   \n",
       "min                              0.000000                        0.000000   \n",
       "25%                              0.000000                        0.000000   \n",
       "50%                              0.000000                       87.500000   \n",
       "75%                              1.000000                      230.000000   \n",
       "max                             11.000000                    44590.000000   \n",
       "\n",
       "       Date_of_Last_Payment40_min_360  Date_of_Last_Payment40_mean_360  \\\n",
       "count                     6136.000000                      6136.000000   \n",
       "mean                       109.897979                       241.950743   \n",
       "std                       1800.272880                      2153.646923   \n",
       "min                      -2629.000000                      -147.666667   \n",
       "25%                          0.000000                         0.000000   \n",
       "50%                         36.000000                        69.242857   \n",
       "75%                         58.000000                       128.500000   \n",
       "max                      44590.000000                     44590.000000   \n",
       "\n",
       "       Date_of_Last_Payment40_mode_360  Date_of_Last_Payment40_nuniq_360  \\\n",
       "count                      6136.000000                       6136.000000   \n",
       "mean                        156.586701                          4.967080   \n",
       "std                        2125.210980                          6.881147   \n",
       "min                       -2621.000000                          0.000000   \n",
       "25%                           0.000000                          1.000000   \n",
       "50%                          42.000000                          2.000000   \n",
       "75%                          72.000000                          6.000000   \n",
       "max                       44590.000000                         73.000000   \n",
       "\n",
       "       Date_of_Last_Payment40_maxcount_360  Date_of_Last_Payment40_max_9999  \\\n",
       "count                          6136.000000                      6136.000000   \n",
       "mean                              1.094524                      1631.959909   \n",
       "std                               1.119376                     10678.949203   \n",
       "min                               0.000000                         0.000000   \n",
       "25%                               0.000000                       176.750000   \n",
       "50%                               1.000000                       801.500000   \n",
       "75%                               1.000000                      1466.000000   \n",
       "max                              15.000000                    737482.000000   \n",
       "\n",
       "       Date_of_Last_Payment40_min_9999  Date_of_Last_Payment40_mean_9999  \\\n",
       "count                      6136.000000                       6136.000000   \n",
       "mean                        132.997555                        538.439498   \n",
       "std                        1296.860095                       2302.800646   \n",
       "min                       -2629.000000                        -12.062500   \n",
       "25%                          28.000000                        105.406818   \n",
       "50%                          44.000000                        343.573969   \n",
       "75%                          69.000000                        622.426683   \n",
       "max                       44590.000000                     134258.363636   \n",
       "\n",
       "       Date_of_Last_Payment40_mode_9999  Date_of_Last_Payment40_maxcount_9999  \\\n",
       "count                       6136.000000                           6136.000000   \n",
       "mean                         389.747881                              1.627771   \n",
       "std                         9536.814651                              1.293191   \n",
       "min                         -293.000000                              0.000000   \n",
       "25%                           36.000000                              1.000000   \n",
       "50%                           64.000000                              1.000000   \n",
       "75%                          223.000000                              2.000000   \n",
       "max                       737482.000000                             20.000000   \n",
       "\n",
       "       Date_Reported33_nuniq_30  Date_Reported33_max_90  \\\n",
       "count               6136.000000             6136.000000   \n",
       "mean                   0.074641               23.933670   \n",
       "std                    0.265302               25.767027   \n",
       "min                    0.000000                0.000000   \n",
       "25%                    0.000000                0.000000   \n",
       "50%                    0.000000               21.000000   \n",
       "75%                    0.000000               47.000000   \n",
       "max                    2.000000              120.000000   \n",
       "\n",
       "       Date_Reported33_mean_90  Date_Reported33_mode_90  \\\n",
       "count              6136.000000              6136.000000   \n",
       "mean                 20.226371                18.675684   \n",
       "std                  21.196906                20.311890   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                  21.000000                18.000000   \n",
       "75%                  38.333333                32.000000   \n",
       "max                 120.000000               120.000000   \n",
       "\n",
       "       Date_Reported33_nuniq_90  Date_Reported33_maxcount_90  \\\n",
       "count               6136.000000                  6136.000000   \n",
       "mean                   0.735658                     1.253096   \n",
       "std                    0.812217                     1.946051   \n",
       "min                    0.000000                     0.000000   \n",
       "25%                    0.000000                     0.000000   \n",
       "50%                    1.000000                     1.000000   \n",
       "75%                    1.000000                     2.000000   \n",
       "max                    4.000000                    31.000000   \n",
       "\n",
       "       Date_Reported33_max_360  Date_Reported33_mean_360  \\\n",
       "count              6136.000000               6136.000000   \n",
       "mean                113.781128                 64.831367   \n",
       "std                 109.514718                 57.254205   \n",
       "min                   0.000000                  0.000000   \n",
       "25%                  27.000000                 26.000000   \n",
       "50%                  69.000000                 51.408333   \n",
       "75%                 200.000000                 98.000000   \n",
       "max                 358.000000                349.000000   \n",
       "\n",
       "       Date_Reported33_mode_360  Date_Reported33_nuniq_360  \\\n",
       "count               6136.000000                6136.000000   \n",
       "mean                  46.357725                   2.802966   \n",
       "std                   53.810619                   2.927619   \n",
       "min                    0.000000                   0.000000   \n",
       "25%                   20.000000                   1.000000   \n",
       "50%                   32.000000                   2.000000   \n",
       "75%                   54.000000                   4.000000   \n",
       "max                  349.000000                  17.000000   \n",
       "\n",
       "       Date_Reported33_maxcount_360  Date_Reported33_max_9999  \\\n",
       "count                   6136.000000               6136.000000   \n",
       "mean                       2.786832                799.976532   \n",
       "std                        3.243178                711.234021   \n",
       "min                        0.000000                  0.000000   \n",
       "25%                        1.000000                135.000000   \n",
       "50%                        2.000000                689.500000   \n",
       "75%                        4.000000               1243.000000   \n",
       "max                       33.000000               2542.000000   \n",
       "\n",
       "       Date_Reported33_mean_9999  Date_Reported33_mode_9999  \\\n",
       "count                6136.000000                6136.000000   \n",
       "mean                  259.726317                 133.027379   \n",
       "std                  1256.186163                 251.152995   \n",
       "min                -90550.000000                   0.000000   \n",
       "25%                    72.000000                  28.000000   \n",
       "50%                   227.000000                  43.000000   \n",
       "75%                   406.201630                  97.000000   \n",
       "max                  2450.000000                2450.000000   \n",
       "\n",
       "       Date_Reported33_nuniq_9999  Date_Reported33_maxcount_9999  \\\n",
       "count                 6136.000000                    6136.000000   \n",
       "mean                     7.933996                       4.751304   \n",
       "std                      7.540213                       5.404223   \n",
       "min                      0.000000                       0.000000   \n",
       "25%                      2.000000                       2.000000   \n",
       "50%                      5.000000                       3.000000   \n",
       "75%                     11.000000                       6.000000   \n",
       "max                     52.000000                     101.000000   \n",
       "\n",
       "       DateOfAddition34_nuniq_30  DateOfAddition34_max_90  \\\n",
       "count                6136.000000              6136.000000   \n",
       "mean                    0.074641                31.289602   \n",
       "std                     0.265302                42.275998   \n",
       "min                     0.000000                 0.000000   \n",
       "25%                     0.000000                 0.000000   \n",
       "50%                     0.000000                24.000000   \n",
       "75%                     0.000000                59.000000   \n",
       "max                     2.000000              1444.000000   \n",
       "\n",
       "       DateOfAddition34_mean_90  DateOfAddition34_mode_90  \\\n",
       "count               6136.000000               6136.000000   \n",
       "mean                  25.670341                 23.414765   \n",
       "std                   28.246993                 25.957603   \n",
       "min                    0.000000                  0.000000   \n",
       "25%                    0.000000                  0.000000   \n",
       "50%                   24.000000                 20.000000   \n",
       "75%                   49.000000                 45.000000   \n",
       "max                  514.000000                273.000000   \n",
       "\n",
       "       DateOfAddition34_nuniq_90  DateOfAddition34_maxcount_90  \\\n",
       "count                6136.000000                   6136.000000   \n",
       "mean                    0.827249                      1.100717   \n",
       "std                     0.927958                      1.671261   \n",
       "min                     0.000000                      0.000000   \n",
       "25%                     0.000000                      0.000000   \n",
       "50%                     1.000000                      1.000000   \n",
       "75%                     2.000000                      2.000000   \n",
       "max                     4.000000                     31.000000   \n",
       "\n",
       "       DateOfAddition34_max_360  DateOfAddition34_mean_360  \\\n",
       "count               6136.000000                6136.000000   \n",
       "mean                 180.524609                 115.393665   \n",
       "std                  137.144815                  86.593353   \n",
       "min                    0.000000                   0.000000   \n",
       "25%                   51.000000                  43.666667   \n",
       "50%                  194.000000                 116.000000   \n",
       "75%                  303.000000                 174.906250   \n",
       "max                 1642.000000                 735.000000   \n",
       "\n",
       "       DateOfAddition34_mode_360  DateOfAddition34_nuniq_360  \\\n",
       "count                6136.000000                 6136.000000   \n",
       "mean                   91.770698                    3.282106   \n",
       "std                    90.422163                    3.157549   \n",
       "min                     0.000000                    0.000000   \n",
       "25%                    25.000000                    1.000000   \n",
       "50%                    62.000000                    2.000000   \n",
       "75%                   134.000000                    5.000000   \n",
       "max                   359.000000                   16.000000   \n",
       "\n",
       "       DateOfAddition34_maxcount_360  DateOfAddition34_max_9999  \\\n",
       "count                    6136.000000                6136.000000   \n",
       "mean                        2.166395                1202.695893   \n",
       "std                         2.588833                 860.840922   \n",
       "min                         0.000000                   0.000000   \n",
       "25%                         1.000000                 412.000000   \n",
       "50%                         1.000000                1093.000000   \n",
       "75%                         3.000000                1975.000000   \n",
       "max                        38.000000                2557.000000   \n",
       "\n",
       "       DateOfAddition34_mean_9999  DateOfAddition34_mode_9999  \\\n",
       "count                 6136.000000                  6136.00000   \n",
       "mean                   521.993828                   288.26206   \n",
       "std                   1298.874381                  4587.93111   \n",
       "min                 -90061.888889               -357200.00000   \n",
       "25%                    204.964286                    55.00000   \n",
       "50%                    471.809184                   147.00000   \n",
       "75%                    769.890921                   460.25000   \n",
       "max                   2545.000000                  2556.00000   \n",
       "\n",
       "       DateOfAddition34_nuniq_9999  DateOfAddition34_maxcount_9999  \\\n",
       "count                  6136.000000                     6136.000000   \n",
       "mean                      9.514342                        3.419980   \n",
       "std                       8.720179                        4.417102   \n",
       "min                       0.000000                        0.000000   \n",
       "25%                       3.000000                        1.000000   \n",
       "50%                       7.000000                        2.000000   \n",
       "75%                      14.000000                        4.000000   \n",
       "max                      60.000000                       70.000000   \n",
       "\n",
       "       Account_Status34_mode_30  Account_Status34_nuniq_30  \\\n",
       "count               6136.000000                6136.000000   \n",
       "mean                   0.841265                   0.075619   \n",
       "std                    3.016915                   0.270504   \n",
       "min                    0.000000                   0.000000   \n",
       "25%                    0.000000                   0.000000   \n",
       "50%                    0.000000                   0.000000   \n",
       "75%                    0.000000                   0.000000   \n",
       "max                   21.000000                   2.000000   \n",
       "\n",
       "       Account_Status34_mode_90  Account_Status34_nuniq_90  \\\n",
       "count               6136.000000                6136.000000   \n",
       "mean                   6.320893                   0.777868   \n",
       "std                    6.942460                   0.878266   \n",
       "min                    0.000000                   0.000000   \n",
       "25%                    0.000000                   0.000000   \n",
       "50%                   11.000000                   1.000000   \n",
       "75%                   11.000000                   1.000000   \n",
       "max                  130.000000                   5.000000   \n",
       "\n",
       "       Account_Status34_mode_360  Account_Status34_nuniq_360  \\\n",
       "count                6136.000000                 6136.000000   \n",
       "mean                   10.914602                    1.671936   \n",
       "std                    11.828820                    1.343681   \n",
       "min                     0.000000                    0.000000   \n",
       "25%                    11.000000                    1.000000   \n",
       "50%                    11.000000                    2.000000   \n",
       "75%                    13.000000                    2.000000   \n",
       "max                   130.000000                    9.000000   \n",
       "\n",
       "       Account_Status34_nuniq_9999  Month50_sum_30  Month50_max_30  \\\n",
       "count                  6136.000000     6136.000000     6136.000000   \n",
       "mean                      2.972295        0.947686        0.782757   \n",
       "std                       1.909240        3.861038        2.862380   \n",
       "min                       0.000000        0.000000        0.000000   \n",
       "25%                       2.000000        0.000000        0.000000   \n",
       "50%                       3.000000        0.000000        0.000000   \n",
       "75%                       4.000000        0.000000        0.000000   \n",
       "max                      16.000000       60.000000       12.000000   \n",
       "\n",
       "       Month50_std_30  Month50_sum_90  Month50_mean_90  Month50_max_90  \\\n",
       "count     6136.000000     6136.000000      6136.000000     6136.000000   \n",
       "mean         0.001874       16.456323         5.380144        5.476206   \n",
       "std          0.099492       28.152398         5.270148        5.358151   \n",
       "min          0.000000        0.000000         0.000000        0.000000   \n",
       "25%          0.000000        0.000000         0.000000        0.000000   \n",
       "50%          0.000000        8.000000         7.000000        7.000000   \n",
       "75%          0.000000       23.000000        11.000000       11.000000   \n",
       "max          5.500000      374.000000        12.000000       12.000000   \n",
       "\n",
       "       Month50_min_90  Month50_std_90  Month50_sum_360  Month50_min_360  \\\n",
       "count     6136.000000     6136.000000      6136.000000      6136.000000   \n",
       "mean         5.236799        0.106625        58.397816         5.727999   \n",
       "std          5.164592        0.345589        85.032516         4.249992   \n",
       "min          0.000000        0.000000         0.000000         0.000000   \n",
       "25%          0.000000        0.000000         9.000000         1.000000   \n",
       "50%          7.000000        0.000000        30.000000         6.000000   \n",
       "75%         11.000000        0.000000        74.000000        10.000000   \n",
       "max         12.000000        5.500000       920.000000        12.000000   \n",
       "\n",
       "       Month50_std_360  Month50_sum_9999  Month50_mean_9999  Month50_max_9999  \\\n",
       "count      6136.000000       6136.000000        6136.000000       6136.000000   \n",
       "mean          0.984906        159.310137           9.017837         10.835887   \n",
       "std           1.185491        188.568047           3.061397          3.225705   \n",
       "min           0.000000          0.000000           0.000000          0.000000   \n",
       "25%           0.000000         35.000000           8.222222         12.000000   \n",
       "50%           0.471405         96.000000           9.800000         12.000000   \n",
       "75%           1.876368        216.000000          11.000000         12.000000   \n",
       "max           5.500000       1759.000000          12.000000         12.000000   \n",
       "\n",
       "       Month50_min_9999  Month50_std_9999  Days_Past_Due58_max_30  \\\n",
       "count       6136.000000       6136.000000                  6136.0   \n",
       "mean           5.322197          1.842188                     0.0   \n",
       "std            4.085716          1.415368                     0.0   \n",
       "min            0.000000          0.000000                     0.0   \n",
       "25%            1.000000          0.471405                     0.0   \n",
       "50%            4.000000          1.871653                     0.0   \n",
       "75%            9.000000          3.077698                     0.0   \n",
       "max           12.000000          5.500000                     0.0   \n",
       "\n",
       "       Days_Past_Due58_min_30  Days_Past_Due58_mean_90  \\\n",
       "count                  6136.0              6136.000000   \n",
       "mean                      0.0                 0.395681   \n",
       "std                       0.0                 3.045771   \n",
       "min                       0.0                 0.000000   \n",
       "25%                       0.0                 0.000000   \n",
       "50%                       0.0                 0.000000   \n",
       "75%                       0.0                 0.000000   \n",
       "max                       0.0                90.000000   \n",
       "\n",
       "       Days_Past_Due58_max_90  Days_Past_Due58_min_90  Days_Past_Due58_std_90  \\\n",
       "count             6136.000000             6136.000000             6136.000000   \n",
       "mean                 0.706975                0.229140                0.211415   \n",
       "std                  4.569506                2.715101                1.619562   \n",
       "min                  0.000000                0.000000                0.000000   \n",
       "25%                  0.000000                0.000000                0.000000   \n",
       "50%                  0.000000                0.000000                0.000000   \n",
       "75%                  0.000000                0.000000                0.000000   \n",
       "max                 90.000000               90.000000               28.500000   \n",
       "\n",
       "       Days_Past_Due58_sum_360  Days_Past_Due58_mean_360  \\\n",
       "count              6136.000000               6136.000000   \n",
       "mean                 31.168188                  7.134230   \n",
       "std                 118.488082                 26.735827   \n",
       "min                   0.000000                  0.000000   \n",
       "25%                   0.000000                  0.000000   \n",
       "50%                   0.000000                  0.000000   \n",
       "75%                   2.000000                  0.215062   \n",
       "max                3424.000000                581.000000   \n",
       "\n",
       "       Days_Past_Due58_max_360  ...   948707_lgb   949440_lgb   949441_lgb  \\\n",
       "count              6136.000000  ...  6136.000000  6136.000000  6136.000000   \n",
       "mean                 18.240548  ...     0.177966     0.487940     0.097458   \n",
       "std                  49.606670  ...     0.382515     0.499895     0.296604   \n",
       "min                   0.000000  ...     0.000000     0.000000     0.000000   \n",
       "25%                   0.000000  ...     0.000000     0.000000     0.000000   \n",
       "50%                   0.000000  ...     0.000000     0.000000     0.000000   \n",
       "75%                   2.000000  ...     0.000000     1.000000     0.000000   \n",
       "max                 581.000000  ...     1.000000     1.000000     1.000000   \n",
       "\n",
       "        949442_lgb   949443_lgb   949444_lgb   950176_lgb   950177_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.378748     0.020860     0.014993     0.458931     0.202412   \n",
       "std       0.485115     0.142929     0.121536     0.498351     0.401830   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        950178_lgb   950179_lgb   950180_lgb   950181_lgb   950182_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.150587     0.052640     0.064211     0.020698     0.050522   \n",
       "std       0.357675     0.223332     0.245149     0.142381     0.219036   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        950912_lgb   950913_lgb   950914_lgb   950915_lgb   950916_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.250978     0.033572     0.109844     0.413136     0.192471   \n",
       "std       0.433611     0.180140     0.312720     0.492437     0.394273   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        951648_lgb   951649_lgb   951650_lgb   951651_lgb   951652_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.213005     0.196545     0.239407     0.161995     0.189048   \n",
       "std       0.409465     0.397418     0.426756     0.368476     0.391579   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        952384_lgb   952385_lgb   952386_lgb   952387_lgb   953120_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.092405     0.196545     0.221969     0.489081     0.356584   \n",
       "std       0.289621     0.397418     0.415604     0.499921     0.479030   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        953121_lgb   953122_lgb   953123_lgb   953856_lgb   953857_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.159713     0.275098     0.208605     0.603977     0.177966   \n",
       "std       0.366370     0.446600     0.406344     0.489109     0.382515   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        953858_lgb   953859_lgb   954592_lgb   954593_lgb   954594_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.156454     0.061604     0.374185     0.262223     0.363592   \n",
       "std       0.363315     0.240454     0.483951     0.439879     0.481072   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        955328_lgb   955329_lgb   955330_lgb   955331_lgb   955332_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.479791     0.033572     0.085398     0.169003     0.232236   \n",
       "std       0.499632     0.180140     0.279495     0.374785     0.422293   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        956064_lgb   956065_lgb   956066_lgb   956067_lgb   956068_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.323501     0.107562     0.239407     0.051499     0.088983   \n",
       "std       0.467850     0.309852     0.426756     0.221032     0.284742   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        956069_lgb   956800_lgb   956801_lgb   957536_lgb   957537_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.189048     0.603977     0.396023     0.322523     0.277053   \n",
       "std       0.391579     0.489109     0.489109     0.467480     0.447580   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        957538_lgb   957539_lgb   958272_lgb   958273_lgb   958274_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.078390     0.322034     0.097458     0.070078     0.027705   \n",
       "std       0.268806     0.467294     0.296604     0.255300     0.164141   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        958275_lgb   959008_lgb   959009_lgb   959010_lgb   959744_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.804759     0.356584     0.368318     0.275098     0.032432   \n",
       "std       0.396419     0.479030     0.482388     0.446600     0.177158   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     1.000000     1.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        959745_lgb   959746_lgb   959747_lgb   959748_lgb   959749_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.269068     0.044166     0.396675     0.021512     0.219035   \n",
       "std       0.443511     0.205480     0.489247     0.145097     0.413626   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        959750_lgb   960480_lgb   960481_lgb   960482_lgb   960483_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.017112     0.290091     0.344035     0.133149     0.067471   \n",
       "std       0.129700     0.453841     0.475091     0.339763     0.250856   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        960484_lgb   960485_lgb   961216_lgb   961217_lgb   961218_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.130541     0.034713     0.199478     0.321545     0.119459   \n",
       "std       0.336925     0.183067     0.399641     0.467107     0.324354   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        961219_lgb   961220_lgb   961952_lgb   961953_lgb   961954_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.301988     0.057529     0.152542     0.074478     0.127934   \n",
       "std       0.459158     0.232870     0.359575     0.262569     0.334043   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        961955_lgb   961956_lgb   961957_lgb   962688_lgb   962689_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.070730     0.458605     0.115711     0.290091     0.511897   \n",
       "std       0.256394     0.498324     0.319904     0.453841     0.499899   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "75%       0.000000     1.000000     0.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        962690_lgb   963424_lgb   963425_lgb   963426_lgb   963427_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.198012     0.487940     0.097458     0.279498     0.135104   \n",
       "std       0.398534     0.499895     0.296604     0.448789     0.341863   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        964160_lgb   964161_lgb   964162_lgb   964163_lgb   964896_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.257008     0.254726     0.071056     0.417210     0.797588   \n",
       "std       0.437019     0.435743     0.256939     0.493138     0.401830   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "75%       1.000000     1.000000     0.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        964897_lgb   964898_lgb   965632_lgb   965633_lgb   965634_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.074478     0.127934     0.355769     0.368318     0.275913   \n",
       "std       0.262569     0.334043     0.478785     0.482388     0.447009   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        966368_lgb   966369_lgb   966370_lgb   966371_lgb   966372_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.033898     0.093220     0.455183     0.143416     0.274283   \n",
       "std       0.180982     0.290765     0.498028     0.350525     0.446189   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        967104_lgb   967105_lgb   967106_lgb   967107_lgb   967108_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.032432     0.057529     0.061278     0.221480     0.244622   \n",
       "std       0.177158     0.232870     0.239859     0.415277     0.429898   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        967109_lgb   967110_lgb   967840_lgb   967841_lgb   967842_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.211538     0.171121     0.097458     0.487940     0.414602   \n",
       "std       0.408433     0.376646     0.296604     0.499895     0.492693   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        968576_lgb   968577_lgb   968578_lgb   968579_lgb   969312_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.114896     0.074478     0.767275     0.043351     0.425684   \n",
       "std       0.318922     0.262569     0.422603     0.203662     0.494487   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        969313_lgb   969314_lgb   969315_lgb   970048_lgb   970049_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.301988     0.169817     0.102510     0.355769     0.159713   \n",
       "std       0.459158     0.375503     0.303342     0.478785     0.366370   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        970050_lgb   970051_lgb   970784_lgb   970785_lgb   970786_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.275913     0.208605     0.097458     0.401728     0.437093   \n",
       "std       0.447009     0.406344     0.296604     0.490287     0.496067   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        970787_lgb   970788_lgb   971520_lgb   971521_lgb   971522_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.035854     0.027868     0.363918     0.115385     0.148305   \n",
       "std       0.185941     0.164609     0.481165     0.319512     0.355431   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        971523_lgb   971524_lgb   971525_lgb   971526_lgb   972256_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.104628     0.042373     0.016134     0.209257     0.075945   \n",
       "std       0.306099     0.201455     0.126002     0.406811     0.264932   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        972257_lgb   972258_lgb   972259_lgb   972260_lgb   972261_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.093220     0.250815     0.087190     0.380541     0.112288   \n",
       "std       0.290765     0.433517     0.282137     0.485559     0.315746   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        972992_lgb   972993_lgb   972994_lgb   972995_lgb   973728_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.389179     0.036506     0.491525     0.082790     0.032432   \n",
       "std       0.487604     0.187560     0.499969     0.275587     0.177158   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        973729_lgb   973730_lgb   973731_lgb   973732_lgb   973733_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.057529     0.061278     0.420958     0.114896     0.101369   \n",
       "std       0.232870     0.239859     0.493753     0.318922     0.301841   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        973734_lgb   974464_lgb   974465_lgb   974466_lgb   974467_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.211538     0.070893     0.093220     0.149609     0.087190   \n",
       "std       0.408433     0.256667     0.290765     0.356717     0.282137   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        974468_lgb   974469_lgb   974470_lgb   975200_lgb   975201_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.385593     0.145372     0.068123     0.588331     0.411669   \n",
       "std       0.486775     0.352504     0.251977     0.492176     0.492176   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        975936_lgb   975937_lgb   975938_lgb   975939_lgb   976672_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.292373     0.074478     0.127934     0.505215     0.032432   \n",
       "std       0.454890     0.262569     0.334043     0.500014     0.177158   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        976673_lgb   976674_lgb   976675_lgb   976676_lgb   976677_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.269068     0.061278     0.407920     0.105117     0.124185   \n",
       "std       0.443511     0.239859     0.491488     0.306730     0.329820   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        977408_lgb   977409_lgb   977410_lgb   977411_lgb   977412_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.414928     0.093220     0.162158     0.276076     0.053618   \n",
       "std       0.492750     0.290765     0.368626     0.447091     0.225281   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        978144_lgb   978145_lgb   978146_lgb   978147_lgb   978880_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.487940     0.097458     0.393742     0.020860     0.032432   \n",
       "std       0.499895     0.296604     0.488619     0.142929     0.177158   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        978881_lgb   978882_lgb   978883_lgb   979616_lgb   979617_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.637223     0.269068     0.061278     0.644557     0.355443   \n",
       "std       0.480840     0.443511     0.239859     0.478686     0.478686   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       1.000000     1.000000     0.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        980352_lgb   980353_lgb   980354_lgb   980355_lgb   981088_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.545469     0.190678     0.246578     0.017275     0.598924   \n",
       "std       0.497969     0.392868     0.431054     0.130305     0.490156   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "75%       1.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        981089_lgb   981090_lgb   981091_lgb   981092_lgb   981824_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.033572     0.101369     0.109192     0.156943     0.323990   \n",
       "std       0.180140     0.301841     0.311905     0.363776     0.468034   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        981825_lgb   981826_lgb   981827_lgb   982560_lgb   982561_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.093220     0.361310     0.221480     0.443449     0.033572   \n",
       "std       0.290765     0.480419     0.415277     0.496832     0.180140   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        982562_lgb   983296_lgb   983297_lgb   983298_lgb   983299_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.522979     0.264342     0.269068     0.061278     0.241199   \n",
       "std       0.499512     0.441018     0.443511     0.239859     0.427846   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     1.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        983300_lgb   983301_lgb   984032_lgb   984033_lgb   984034_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.063722     0.100391     0.910365     0.036506     0.053129   \n",
       "std       0.244277     0.300545     0.285681     0.187560     0.224309   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        984768_lgb   984769_lgb   984770_lgb   985504_lgb   985505_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.090939     0.033572     0.875489     0.090939     0.033572   \n",
       "std       0.287545     0.180140     0.330191     0.287545     0.180140   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        985506_lgb   985507_lgb   985508_lgb   986240_lgb   986241_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.351043     0.403194     0.121252     0.790417     0.036506   \n",
       "std       0.477335     0.490579     0.326446     0.407044     0.187560   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       1.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        986242_lgb   986976_lgb   986977_lgb   986978_lgb   987712_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.173077     0.355769     0.190678     0.453553     0.189374   \n",
       "std       0.378345     0.478785     0.392868     0.497879     0.391837   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       987713_lgb   987714_lgb   987715_lgb   987716_lgb   988448_lgb  \\\n",
       "count  6136.00000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.13543     0.432203     0.187744     0.055248     0.235332   \n",
       "std       0.34221     0.495423     0.390540     0.228482     0.424241   \n",
       "min       0.00000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.00000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.00000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.00000     1.000000     0.000000     0.000000     0.000000   \n",
       "max       1.00000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        988449_lgb   988450_lgb   988451_lgb   989184_lgb   989185_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.033572     0.447523     0.283572     0.543677     0.093220   \n",
       "std       0.180140     0.497279     0.450768     0.498129     0.290765   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       0.000000     1.000000     1.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        989186_lgb   989187_lgb   989920_lgb   989921_lgb   989922_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.115385     0.247718     0.371089     0.033572     0.101369   \n",
       "std       0.319512     0.431723     0.483135     0.180140     0.301841   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        989923_lgb   989924_lgb   989925_lgb   990656_lgb   990657_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.275587     0.061441     0.156943     0.414928     0.093220   \n",
       "std       0.446846     0.240156     0.363776     0.492750     0.290765   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        990658_lgb   990659_lgb   991392_lgb   991393_lgb   991394_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.360984     0.130867     0.543677     0.093220     0.246252   \n",
       "std       0.480325     0.337282     0.498129     0.290765     0.430862   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        991395_lgb   992128_lgb   992129_lgb   992130_lgb   992864_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.116851     0.797588     0.074478     0.127934     0.737614   \n",
       "std       0.321269     0.401830     0.262569     0.334043     0.439967   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000     0.000000     0.000000     1.000000   \n",
       "75%       0.000000     1.000000     0.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        992865_lgb   992866_lgb   992867_lgb   993600_lgb  993601_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.00000   \n",
       "mean      0.036506     0.121252     0.104628     0.355769     0.13543   \n",
       "std       0.187560     0.326446     0.306099     0.478785     0.34221   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     0.00000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.00000   \n",
       "\n",
       "        993602_lgb   993603_lgb   994336_lgb   994337_lgb   994338_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.055248     0.453553     0.764505     0.074478     0.097295   \n",
       "std       0.228482     0.497879     0.424343     0.262569     0.296383   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        994339_lgb   995072_lgb   995073_lgb   995074_lgb   995075_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.063722     0.097458     0.206812     0.106095     0.423077   \n",
       "std       0.244277     0.296604     0.405053     0.307984     0.494088   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        995076_lgb   995808_lgb   995809_lgb   995810_lgb   995811_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.166558     0.350717     0.057040     0.450130     0.072523   \n",
       "std       0.372611     0.477233     0.231939     0.497547     0.259373   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        995812_lgb   996544_lgb   996545_lgb   996546_lgb   997280_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.069589     0.543677     0.093220     0.363103     0.090939   \n",
       "std       0.254474     0.498129     0.290765     0.480933     0.287545   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        997281_lgb   997282_lgb   997283_lgb   997284_lgb   998016_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.033572     0.472295     0.382171     0.021023     0.577901   \n",
       "std       0.180140     0.499273     0.485958     0.143474     0.493934   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "75%       0.000000     1.000000     1.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        998017_lgb   998018_lgb   998019_lgb   998752_lgb   998753_lgb  \\\n",
       "count  6136.000000  6136.000000  6136.000000  6136.000000  6136.000000   \n",
       "mean      0.097458     0.214146     0.110495     0.371089     0.033572   \n",
       "std       0.296604     0.410262     0.313532     0.483135     0.180140   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        998754_lgb   998755_lgb  \n",
       "count  6136.000000  6136.000000  \n",
       "mean      0.258312     0.337027  \n",
       "std       0.437742     0.472733  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.000000     0.000000  \n",
       "75%       1.000000     1.000000  \n",
       "max       1.000000     1.000000  \n",
       "\n",
       "[8 rows x 9030 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  './data/filter_feas_df32n_old_qcut_oh.pkl' ./data/filter_feas_df_0403_n_old.pkl\n",
    "train_x, test_x, train_y, test_y,oot_x, oot_y,df,final_feas = read_train('./data/filter_feas_df32n_old_lgb_oh.pkl',model='nn')\n",
    "train_x.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437cedd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4c515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 1 1 0.0001\n",
      "验证集最优结果： 0.3444439172744751 0.5625657439231873\n",
      "------------train------------\n",
      " (0.892433769937714, 0.6677266725277641)\n",
      "------------test------------\n",
      " (0.681738840772818, 0.29280479680213195)\n",
      "------------oot------------\n",
      " (0.6551755696891762, 0.250304104542453)\n",
      "隐藏层vs神经元数vs norm 1 1 0.001\n",
      "验证集最优结果： 0.38465946912765503 0.6545520424842834\n",
      "------------train------------\n",
      " (0.940564817578419, 0.7900470985875838)\n",
      "------------test------------\n",
      " (0.679535864978903, 0.2829447035309794)\n",
      "------------oot------------\n",
      " (0.6468378920052363, 0.24128870816390363)\n",
      "隐藏层vs神经元数vs norm 1 1 0.01\n",
      "验证集最优结果： 0.5036781430244446 0.6126749515533447\n",
      "------------train------------\n",
      " (0.8777170687203517, 0.6169702457938504)\n",
      "------------test------------\n",
      " (0.7065989340439707, 0.33965134354874527)\n",
      "------------oot------------\n",
      " (0.683374459852408, 0.2780175859312549)\n",
      "隐藏层vs神经元数vs norm 1 1 0.02\n",
      "验证集最优结果： 0.6428812146186829 0.6574302911758423\n",
      "------------train------------\n",
      " (0.7642066300788, 0.45637658295314026)\n",
      "------------test------------\n",
      " (0.6644470353097935, 0.311503442149678)\n",
      "------------oot------------\n",
      " (0.662632792316871, 0.29696590553644037)\n",
      "隐藏层vs神经元数vs norm 1 1 0.05\n",
      "验证集最优结果： 0.6645736694335938 0.6679037809371948\n",
      "------------train------------\n",
      " (0.735734961987467, 0.37227917503362007)\n",
      "------------test------------\n",
      " (0.6666133688652011, 0.27911392405063296)\n",
      "------------oot------------\n",
      " (0.671384052178547, 0.27190769123831365)\n",
      "隐藏层vs神经元数vs norm 1 1 0.1\n",
      "验证集最优结果： 0.6921020746231079 0.693076491355896\n",
      "------------train------------\n",
      " (0.7804229871428097, 0.41793793598679974)\n",
      "------------test------------\n",
      " (0.7162391738840772, 0.34693537641572286)\n",
      "------------oot------------\n",
      " (0.7215398695536324, 0.3216140131373162)\n",
      "隐藏层vs神经元数vs norm 1 1 0.2\n",
      "验证集最优结果： 0.8147290349006653 0.8041759133338928\n",
      "------------train------------\n",
      " (0.7636986231835505, 0.39315090836857775)\n",
      "------------test------------\n",
      " (0.7129113924050632, 0.32066400177659343)\n",
      "------------oot------------\n",
      " (0.7215236506447016, 0.3352935043269732)\n",
      "隐藏层vs神经元数vs norm 1 1 0.3\n",
      "验证集最优结果： 0.9061788320541382 0.8990845084190369\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49912280701754386, 0.0)\n",
      "------------oot------------\n",
      " (0.5031128720212236, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 1 1 0.4\n",
      "验证集最优结果： 0.9787054061889648 0.9700561761856079\n",
      "------------train------------\n",
      " (0.4900513624344264, 0.0001024676844402217)\n",
      "------------test------------\n",
      " (0.4928003553186764, 0.0)\n",
      "------------oot------------\n",
      " (0.4911410002432836, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 1 1 0.5\n",
      "验证集最优结果： 1.1728729009628296 1.1601835489273071\n",
      "------------train------------\n",
      " (0.7524803067803962, 0.3817633240137823)\n",
      "------------test------------\n",
      " (0.6891738840772819, 0.2804463690872751)\n",
      "------------oot------------\n",
      " (0.6932552508717663, 0.27976922809578425)\n",
      "隐藏层vs神经元数vs norm 1 1 0.6\n",
      "验证集最优结果： 1.2945431470870972 1.2749199867248535\n",
      "------------train------------\n",
      " (0.7127522860648687, 0.3120880057988317)\n",
      "------------test------------\n",
      " (0.6794503664223852, 0.2855762824783478)\n",
      "------------oot------------\n",
      " (0.6651189193572677, 0.265457199457825)\n",
      "隐藏层vs神经元数vs norm 1 1 0.8\n",
      "验证集最优结果： 1.554404854774475 1.5412739515304565\n",
      "------------train------------\n",
      " (0.7167833810139698, 0.32500082908133054)\n",
      "------------test------------\n",
      " (0.6736053741949812, 0.27556073728625363)\n",
      "------------oot------------\n",
      " (0.6570326347617559, 0.2724359642720606)\n",
      "隐藏层vs神经元数vs norm 1 2 0.0001\n",
      "验证集最优结果： 0.3567657172679901 0.5916497707366943\n",
      "------------train------------\n",
      " (0.8965747773832028, 0.6616900129201327)\n",
      "------------test------------\n",
      " (0.6760692871419055, 0.2795691761048191)\n",
      "------------oot------------\n",
      " (0.6376904273682504, 0.23195356758071806)\n",
      "隐藏层vs神经元数vs norm 1 2 0.001\n",
      "验证集最优结果： 0.5870925784111023 0.8294241428375244\n",
      "------------train------------\n",
      " (0.906748045229263, 0.7651505645536261)\n",
      "------------test------------\n",
      " (0.6362014212747057, 0.25826115922718185)\n",
      "------------oot------------\n",
      " (0.599156616735597, 0.19528029750112952)\n",
      "隐藏层vs神经元数vs norm 1 2 0.01\n",
      "验证集最优结果： 0.5317331552505493 0.6164136528968811\n",
      "------------train------------\n",
      " (0.870855862349488, 0.6020761550118136)\n",
      "------------test------------\n",
      " (0.7123806351321341, 0.34252720408616477)\n",
      "------------oot------------\n",
      " (0.6903439567186831, 0.29482500955757135)\n",
      "隐藏层vs神经元数vs norm 1 2 0.02\n",
      "验证集最优结果： 0.6625097990036011 0.6721712946891785\n",
      "------------train------------\n",
      " (0.7112422751616032, 0.36891344323229364)\n",
      "------------test------------\n",
      " (0.6432311792138574, 0.24248278925161)\n",
      "------------oot------------\n",
      " (0.6278548175951992, 0.2203037569944044)\n",
      "隐藏层vs神经元数vs norm 1 2 0.05\n",
      "验证集最优结果： 0.6840491890907288 0.6924328207969666\n",
      "------------train------------\n",
      " (0.7821177647425888, 0.4268899839530462)\n",
      "------------test------------\n",
      " (0.7135753941816567, 0.3359427048634244)\n",
      "------------oot------------\n",
      " (0.6989700992828924, 0.30947763528307787)\n",
      "隐藏层vs神经元数vs norm 1 2 0.1\n",
      "验证集最优结果： 0.7914965748786926 0.7884774208068848\n",
      "------------train------------\n",
      " (0.7723086158808667, 0.40552269686282394)\n",
      "------------test------------\n",
      " (0.7205085498556518, 0.3361758827448368)\n",
      "------------oot------------\n",
      " (0.7153071745502149, 0.32275397073645434)\n",
      "隐藏层vs神经元数vs norm 1 2 0.2\n",
      "验证集最优结果： 1.0009135007858276 0.9973183274269104\n",
      "------------train------------\n",
      " (0.5012368539849033, 0.0026966462475779274)\n",
      "------------test------------\n",
      " (0.5007794803464357, 0.003308905174328247)\n",
      "------------oot------------\n",
      " (0.5011990407673861, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 1 2 0.3\n",
      "验证集最优结果： 1.2295613288879395 1.2062731981277466\n",
      "------------train------------\n",
      " (0.7648767985142862, 0.3952859450748847)\n",
      "------------test------------\n",
      " (0.7165911614479236, 0.3257828114590273)\n",
      "------------oot------------\n",
      " (0.7174561799835494, 0.3252632676467521)\n",
      "隐藏层vs神经元数vs norm 1 2 0.4\n",
      "验证集最优结果： 1.475105881690979 1.4571386575698853\n",
      "------------train------------\n",
      " (0.7384932648139914, 0.3522952693634483)\n",
      "------------test------------\n",
      " (0.6812769264934488, 0.25177659338218966)\n",
      "------------oot------------\n",
      " (0.6818869542047521, 0.28032530497341257)\n",
      "隐藏层vs神经元数vs norm 1 2 0.5\n",
      "验证集最优结果： 1.6730729341506958 1.6536272764205933\n",
      "------------train------------\n",
      " (0.7337694639532357, 0.3358661937180677)\n",
      "------------test------------\n",
      " (0.7034887852542749, 0.3194203864090607)\n",
      "------------oot------------\n",
      " (0.6886745675923029, 0.29798769679908244)\n",
      "隐藏层vs神经元数vs norm 1 2 0.6\n",
      "验证集最优结果： 1.8989262580871582 1.892046570777893\n",
      "------------train------------\n",
      " (0.5926163708707519, 0.14221512934683955)\n",
      "------------test------------\n",
      " (0.5863668665334223, 0.14957805907172994)\n",
      "------------oot------------\n",
      " (0.5893279579235163, 0.15825947937302332)\n",
      "隐藏层vs神经元数vs norm 1 2 0.8\n",
      "验证集最优结果： 2.3227782249450684 2.309939384460449\n",
      "------------train------------\n",
      " (0.6901158615779346, 0.2828101322537002)\n",
      "------------test------------\n",
      " (0.6533944037308461, 0.23905174328225626)\n",
      "------------oot------------\n",
      " (0.6397131570106234, 0.2070552253849095)\n",
      "隐藏层vs神经元数vs norm 1 3 0.0001\n",
      "验证集最优结果： 0.27634209394454956 0.6358270645141602\n",
      "------------train------------\n",
      " (0.9391316912785382, 0.7389694620581927)\n",
      "------------test------------\n",
      " (0.6727648234510326, 0.2669997779258272)\n",
      "------------oot------------\n",
      " (0.6288488050139598, 0.20993292322663606)\n",
      "隐藏层vs神经元数vs norm 1 3 0.001\n",
      "验证集最优结果： 0.5675329566001892 0.8716493248939514\n",
      "------------train------------\n",
      " (0.9030058089837222, 0.756780836241886)\n",
      "------------test------------\n",
      " (0.6265312014212747, 0.25367532755940486)\n",
      "------------oot------------\n",
      " (0.598117448070529, 0.18558370694748555)\n",
      "隐藏层vs神经元数vs norm 1 3 0.01\n",
      "验证集最优结果： 0.5933239459991455 0.6265354752540588\n",
      "------------train------------\n",
      " (0.8116617564747868, 0.4615324536272816)\n",
      "------------test------------\n",
      " (0.72187430601821, 0.329358205640684)\n",
      "------------oot------------\n",
      " (0.716016172569191, 0.34176484899037296)\n",
      "隐藏层vs神经元数vs norm 1 3 0.02\n",
      "验证集最优结果： 0.6698269248008728 0.68992018699646\n",
      "------------train------------\n",
      " (0.7138080280791235, 0.38174342606185013)\n",
      "------------test------------\n",
      " (0.6313535420830557, 0.23487674883411058)\n",
      "------------oot------------\n",
      " (0.6189228327482941, 0.21032912800194625)\n",
      "隐藏层vs神经元数vs norm 1 3 0.05\n",
      "验证集最优结果： 0.803220808506012 0.8043951392173767\n",
      "------------train------------\n",
      " (0.7240414635417407, 0.37138065391167346)\n",
      "------------test------------\n",
      " (0.6464201643348879, 0.25661781034865644)\n",
      "------------oot------------\n",
      " (0.6242125140467336, 0.22729642373058073)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 1 3 0.1\n",
      "验证集最优结果： 0.9271166920661926 0.9253682494163513\n",
      "------------train------------\n",
      " (0.7810999235891574, 0.42387009750673244)\n",
      "------------test------------\n",
      " (0.7165189873417721, 0.32051965356429046)\n",
      "------------oot------------\n",
      " (0.6968419467324691, 0.3126750773294408)\n",
      "隐藏层vs神经元数vs norm 1 3 0.2\n",
      "验证集最优结果： 1.2393089532852173 1.2318589687347412\n",
      "------------train------------\n",
      " (0.7679714038005089, 0.39123258337004985)\n",
      "------------test------------\n",
      " (0.7175816122584944, 0.33455474128358875)\n",
      "------------oot------------\n",
      " (0.7111817792143098, 0.322316060195322)\n",
      "隐藏层vs神经元数vs norm 1 3 0.3\n",
      "验证集最优结果： 1.5477930307388306 1.5340559482574463\n",
      "------------train------------\n",
      " (0.7611260345750603, 0.3796607737596097)\n",
      "------------test------------\n",
      " (0.7162136353542082, 0.32063069065067734)\n",
      "------------oot------------\n",
      " (0.7111389149549925, 0.3356410523754909)\n",
      "隐藏层vs神经元数vs norm 1 3 0.4\n",
      "验证集最优结果： 1.9191287755966187 1.9053211212158203\n",
      "------------train------------\n",
      " (0.7619888205996592, 0.3852106780260961)\n",
      "------------test------------\n",
      " (0.7046191427936931, 0.3138241172551632)\n",
      "------------oot------------\n",
      " (0.7027745919206664, 0.28740833420220346)\n",
      "隐藏层vs神经元数vs norm 1 3 0.5\n",
      "验证集最优结果： 2.26347279548645 2.2545132637023926\n",
      "------------train------------\n",
      " (0.7501879815016728, 0.37152454182258476)\n",
      "------------test------------\n",
      " (0.7145280923828559, 0.331157006440151)\n",
      "------------oot------------\n",
      " (0.7066126808697969, 0.3075730719772008)\n",
      "隐藏层vs神经元数vs norm 1 3 0.6\n",
      "验证集最优结果： 2.583143472671509 2.5675129890441895\n",
      "------------train------------\n",
      " (0.7261754850464184, 0.32062517469928037)\n",
      "------------test------------\n",
      " (0.6772995780590717, 0.29026204752387297)\n",
      "------------oot------------\n",
      " (0.6515483265561464, 0.24503527612692455)\n",
      "隐藏层vs神经元数vs norm 1 3 0.8\n",
      "验证集最优结果： 3.290785789489746 3.2838008403778076\n",
      "------------train------------\n",
      " (0.6144459807829099, 0.19231560046807564)\n",
      "------------test------------\n",
      " (0.6229613590939375, 0.18589829002886962)\n",
      "------------oot------------\n",
      " (0.6310406747066115, 0.22197198762728945)\n",
      "隐藏层vs神经元数vs norm 1 4 0.0001\n",
      "验证集最优结果： 0.34979569911956787 0.6289711594581604\n",
      "------------train------------\n",
      " (0.9377445874525139, 0.7622362590767485)\n",
      "------------test------------\n",
      " (0.6851532311792139, 0.28956251387963583)\n",
      "------------oot------------\n",
      " (0.6465343667095309, 0.235053696173496)\n",
      "隐藏层vs神经元数vs norm 1 4 0.001\n",
      "验证集最优结果： 0.32937943935394287 0.8050699234008789\n",
      "------------train------------\n",
      " (0.976222691922176, 0.8389462477809384)\n",
      "------------test------------\n",
      " (0.6552187430601821, 0.24131689984454807)\n",
      "------------oot------------\n",
      " (0.6271180157323417, 0.19475897542835297)\n",
      "隐藏层vs神经元数vs norm 1 4 0.01\n",
      "验证集最优结果： 0.5783541798591614 0.649412989616394\n",
      "------------train------------\n",
      " (0.856081565359696, 0.5720948144177581)\n",
      "------------test------------\n",
      " (0.7166000444148346, 0.36337996890961577)\n",
      "------------oot------------\n",
      " (0.6901006730847206, 0.28772112744586936)\n",
      "隐藏层vs神经元数vs norm 1 4 0.02\n",
      "验证集最优结果： 0.6613298654556274 0.694327175617218\n",
      "------------train------------\n",
      " (0.8133644526472736, 0.4736382592946785)\n",
      "------------test------------\n",
      " (0.7178347768154564, 0.3441594492560516)\n",
      "------------oot------------\n",
      " (0.7073969809659519, 0.3330344420116081)\n",
      "隐藏层vs神经元数vs norm 1 4 0.05\n",
      "验证集最优结果： 0.7967284917831421 0.8045012354850769\n",
      "------------train------------\n",
      " (0.7683281456530082, 0.399059381850496)\n",
      "------------test------------\n",
      " (0.7171174772373973, 0.33027981345769486)\n",
      "------------oot------------\n",
      " (0.7072324748896535, 0.30463281548674104)\n",
      "隐藏层vs神经元数vs norm 1 4 0.1\n",
      "验证集最优结果： 1.0201656818389893 1.0243209600448608\n",
      "------------train------------\n",
      " (0.7789943277300972, 0.42078036518833)\n",
      "------------test------------\n",
      " (0.7207817010881635, 0.3673884077281812)\n",
      "------------oot------------\n",
      " (0.7046374494607213, 0.30730893546032734)\n",
      "隐藏层vs神经元数vs norm 1 4 0.2\n",
      "验证集最优结果： 1.4207111597061157 1.408877968788147\n",
      "------------train------------\n",
      " (0.7704430136869485, 0.4045956147350425)\n",
      "------------test------------\n",
      " (0.7152165223184543, 0.3315567399511437)\n",
      "------------oot------------\n",
      " (0.7106871024919196, 0.32321273416049767)\n",
      "隐藏层vs神经元数vs norm 1 4 0.3\n",
      "验证集最优结果： 1.8227723836898804 1.809640884399414\n",
      "------------train------------\n",
      " (0.7496408555036449, 0.3638345925217541)\n",
      "------------test------------\n",
      " (0.702221852098601, 0.31282478347768156)\n",
      "------------oot------------\n",
      " (0.6896627625435883, 0.313620408021409)\n",
      "隐藏层vs神经元数vs norm 1 4 0.4\n",
      "验证集最优结果： 2.3216311931610107 2.303967237472534\n",
      "------------train------------\n",
      " (0.7500283241254546, 0.37650999398323837)\n",
      "------------test------------\n",
      " (0.7007550521874306, 0.31345769487008657)\n",
      "------------oot------------\n",
      " (0.692364369374066, 0.284572342126299)\n",
      "隐藏层vs神经元数vs norm 1 4 0.5\n",
      "验证集最优结果： 2.8118350505828857 2.788175344467163\n",
      "------------train------------\n",
      " (0.7516003300082097, 0.36908995295555647)\n",
      "------------test------------\n",
      " (0.7016966466799911, 0.301976460137686)\n",
      "------------oot------------\n",
      " (0.693365307753797, 0.3025614291175755)\n",
      "隐藏层vs神经元数vs norm 1 4 0.6\n",
      "验证集最优结果： 3.1602931022644043 3.1369807720184326\n",
      "------------train------------\n",
      " (0.7345352643821923, 0.35368054582653996)\n",
      "------------test------------\n",
      " (0.7027526093715302, 0.3185542971352432)\n",
      "------------oot------------\n",
      " (0.6643554721440239, 0.2805477357244639)\n",
      "隐藏层vs神经元数vs norm 1 4 0.8\n",
      "验证集最优结果： 3.7815847396850586 3.7693932056427\n",
      "------------train------------\n",
      " (0.5389184312562985, 0.07726875568089908)\n",
      "------------test------------\n",
      " (0.5402576060404175, 0.07984676882078612)\n",
      "------------oot------------\n",
      " (0.5374981174480705, 0.0776491849998262)\n",
      "隐藏层vs神经元数vs norm 1 5 0.0001\n",
      "验证集最优结果： 0.2666398584842682 0.6689398288726807\n",
      "------------train------------\n",
      " (0.9591768474470048, 0.7902391747358276)\n",
      "------------test------------\n",
      " (0.6641128136797689, 0.2608483233399955)\n",
      "------------oot------------\n",
      " (0.6288476465204648, 0.2011052027942863)\n",
      "隐藏层vs神经元数vs norm 1 5 0.001\n",
      "验证集最优结果： 0.3330935835838318 0.9288907647132874\n",
      "------------train------------\n",
      " (0.9907760133573462, 0.8998892076622005)\n",
      "------------test------------\n",
      " (0.6554319342660448, 0.2594159449256051)\n",
      "------------oot------------\n",
      " (0.6372432488791575, 0.22156883189100895)\n",
      "隐藏层vs神经元数vs norm 1 5 0.01\n",
      "验证集最优结果： 0.6145505309104919 0.6855171322822571\n",
      "------------train------------\n",
      " (0.8437812470601452, 0.5398621626907987)\n",
      "------------test------------\n",
      " (0.7209815678436597, 0.3435043304463691)\n",
      "------------oot------------\n",
      " (0.6960866089736906, 0.3090814305077677)\n",
      "隐藏层vs神经元数vs norm 1 5 0.02\n",
      "验证集最优结果： 0.6716851592063904 0.706560492515564\n",
      "------------train------------\n",
      " (0.8088744865617761, 0.4941927082804582)\n",
      "------------test------------\n",
      " (0.7199511436819898, 0.3425161003775261)\n",
      "------------oot------------\n",
      " (0.7065512807145587, 0.3133145657387134)\n",
      "隐藏层vs神经元数vs norm 1 5 0.05\n",
      "验证集最优结果： 0.8478707671165466 0.8526788949966431\n",
      "------------train------------\n",
      " (0.778409300871246, 0.42250553115687645)\n",
      "------------test------------\n",
      " (0.7189762380635132, 0.3377415056628914)\n",
      "------------oot------------\n",
      " (0.6881798908699128, 0.31526083481041256)\n",
      "隐藏层vs神经元数vs norm 1 5 0.1\n",
      "验证集最优结果： 1.1121056079864502 1.1100088357925415\n",
      "------------train------------\n",
      " (0.7696692270051755, 0.40590305907322916)\n",
      "------------test------------\n",
      " (0.7166755496335775, 0.33368865200977127)\n",
      "------------oot------------\n",
      " (0.7129056175349575, 0.3092899593368783)\n",
      "隐藏层vs神经元数vs norm 1 5 0.2\n",
      "验证集最优结果： 1.706872582435608 1.6970657110214233\n",
      "------------train------------\n",
      " (0.7752789604876758, 0.40777400799572805)\n",
      "------------test------------\n",
      " (0.72114812347324, 0.34267155229846774)\n",
      "------------oot------------\n",
      " (0.7095286089968604, 0.3342925659472422)\n",
      "隐藏层vs神经元数vs norm 1 5 0.3\n",
      "验证集最优结果： 2.140383243560791 2.129223108291626\n",
      "------------train------------\n",
      " (0.7538364807967843, 0.3824628656164068)\n",
      "------------test------------\n",
      " (0.7066744392627137, 0.33580946035976017)\n",
      "------------oot------------\n",
      " (0.6782597110717223, 0.27324922670559204)\n",
      "隐藏层vs神经元数vs norm 1 5 0.4\n",
      "验证集最优结果： 2.7490384578704834 2.726785182952881\n",
      "------------train------------\n",
      " (0.7474557355169644, 0.3684426603967814)\n",
      "------------test------------\n",
      " (0.6994914501443483, 0.314257161892072)\n",
      "------------oot------------\n",
      " (0.6692026089273508, 0.2744725958363744)\n",
      "隐藏层vs神经元数vs norm 1 5 0.5\n",
      "验证集最优结果： 3.246541976928711 3.2252728939056396\n",
      "------------train------------\n",
      " (0.721967068212751, 0.3193858165503584)\n",
      "------------test------------\n",
      " (0.669257161892072, 0.26663335554075057)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.6935518252065015, 0.30650957494873665)\n",
      "隐藏层vs神经元数vs norm 1 5 0.6\n",
      "验证集最优结果： 3.885399103164673 3.8670849800109863\n",
      "------------train------------\n",
      " (0.7124661345656527, 0.3124101631158298)\n",
      "------------test------------\n",
      " (0.6724061736620031, 0.2835665112147458)\n",
      "------------oot------------\n",
      " (0.6809080272014272, 0.27062871441976855)\n",
      "隐藏层vs神经元数vs norm 1 5 0.8\n",
      "验证集最优结果： 5.002954959869385 4.979686260223389\n",
      "------------train------------\n",
      " (0.6744370876166382, 0.2530427961630793)\n",
      "------------test------------\n",
      " (0.670777259604708, 0.2864090606262492)\n",
      "------------oot------------\n",
      " (0.6278884139065559, 0.20802835992075908)\n",
      "隐藏层vs神经元数vs norm 1 6 0.0001\n",
      "验证集最优结果： 0.3178759813308716 0.6784706115722656\n",
      "------------train------------\n",
      " (0.9473938758976921, 0.745242595965318)\n",
      "------------test------------\n",
      " (0.6812958027981346, 0.2789473684210526)\n",
      "------------oot------------\n",
      " (0.6466641179809776, 0.23654120182115174)\n",
      "隐藏层vs神经元数vs norm 1 6 0.001\n",
      "验证集最优结果： 0.3596837520599365 0.8138555884361267\n",
      "------------train------------\n",
      " (0.973278404157183, 0.8342948646363988)\n",
      "------------test------------\n",
      " (0.6784354874528092, 0.27926937597157453)\n",
      "------------oot------------\n",
      " (0.6376996953162108, 0.21210857401035693)\n",
      "隐藏层vs神经元数vs norm 1 6 0.01\n",
      "验证集最优结果： 0.6261061429977417 0.6806020140647888\n",
      "------------train------------\n",
      " (0.8413228347948852, 0.5302973390211696)\n",
      "------------test------------\n",
      " (0.7182067510548523, 0.3358982900288696)\n",
      "------------oot------------\n",
      " (0.7075105133284677, 0.3109373370868523)\n",
      "隐藏层vs神经元数vs norm 1 6 0.02\n",
      "验证集最优结果： 0.7197036147117615 0.7460002899169922\n",
      "------------train------------\n",
      " (0.8003204653142828, 0.46276206584056323)\n",
      "------------test------------\n",
      " (0.6951965356429047, 0.307161892071952)\n",
      "------------oot------------\n",
      " (0.68047127515379, 0.28797136204080215)\n",
      "隐藏层vs神经元数vs norm 1 6 0.05\n",
      "验证集最优结果： 0.9096760153770447 0.9176360368728638\n",
      "------------train------------\n",
      " (0.777798555571122, 0.4224691192584426)\n",
      "------------test------------\n",
      " (0.7146724405951588, 0.3401621141461248)\n",
      "------------oot------------\n",
      " (0.7046467174086817, 0.31252215618809304)\n",
      "隐藏层vs神经元数vs norm 1 6 0.1\n",
      "验证集最优结果： 1.2318389415740967 1.2360628843307495\n",
      "------------train------------\n",
      " (0.7731807417604544, 0.3989649004188721)\n",
      "------------test------------\n",
      " (0.7150988230068842, 0.3235509660226516)\n",
      "------------oot------------\n",
      " (0.7063473858594282, 0.2983004900427484)\n",
      "隐藏层vs神经元数vs norm 1 6 0.2\n",
      "验证集最优结果： 1.8633421659469604 1.8647798299789429\n",
      "------------train------------\n",
      " (0.780053724470217, 0.41993206270697425)\n",
      "------------test------------\n",
      " (0.7275371974239396, 0.35420830557406174)\n",
      "------------oot------------\n",
      " (0.7129971385210672, 0.3374969589545755)\n",
      "隐藏层vs神经元数vs norm 1 6 0.3\n",
      "验证集最优结果： 2.613941192626953 2.600550889968872\n",
      "------------train------------\n",
      " (0.7726715843033585, 0.4042585677941496)\n",
      "------------test------------\n",
      " (0.7263402176326894, 0.3420275371974239)\n",
      "------------oot------------\n",
      " (0.7034268237583846, 0.3250755917005526)\n",
      "隐藏层vs神经元数vs norm 1 6 0.4\n",
      "验证集最优结果： 3.279773712158203 3.2660279273986816\n",
      "------------train------------\n",
      " (0.762613440322049, 0.3865871560750681)\n",
      "------------test------------\n",
      " (0.7052609371530091, 0.30524095047745947)\n",
      "------------oot------------\n",
      " (0.7009186853415817, 0.31052027942863103)\n",
      "隐藏层vs神经元数vs norm 1 6 0.5\n",
      "验证集最优结果： 3.8851985931396484 3.8685035705566406\n",
      "------------train------------\n",
      " (0.7364895951985023, 0.355159491559952)\n",
      "------------test------------\n",
      " (0.7029691316899844, 0.3168887408394404)\n",
      "------------oot------------\n",
      " (0.7133006638167727, 0.3373926945400202)\n",
      "隐藏层vs神经元数vs norm 1 6 0.6\n",
      "验证集最优结果： 4.57996940612793 4.581463813781738\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49736842105263157, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 1 6 0.8\n",
      "验证集最优结果： 5.852113723754883 5.8260273933410645\n",
      "------------train------------\n",
      " (0.6921028818867049, 0.28553249694255106)\n",
      "------------test------------\n",
      " (0.6588563180102154, 0.25924938929602487)\n",
      "------------oot------------\n",
      " (0.6395660283367508, 0.21924721092691069)\n",
      "隐藏层vs神经元数vs norm 1 7 0.0001\n",
      "验证集最优结果： 0.26099419593811035 0.8315426707267761\n",
      "------------train------------\n",
      " (0.9663725965947431, 0.8197190057250604)\n",
      "------------test------------\n",
      " (0.6703264490339773, 0.28258938485454144)\n",
      "------------oot------------\n",
      " (0.6269789965129345, 0.22487053835192714)\n",
      "隐藏层vs神经元数vs norm 1 7 0.001\n",
      "验证集最优结果： 0.3505731523036957 0.8456469774246216\n",
      "------------train------------\n",
      " (0.9745065274080752, 0.8264167646336238)\n",
      "------------test------------\n",
      " (0.6635842771485677, 0.26852098600932717)\n",
      "------------oot------------\n",
      " (0.6438686731774002, 0.2398846140478921)\n",
      "隐藏层vs神经元数vs norm 1 7 0.01\n",
      "验证集最优结果： 0.6407865285873413 0.7117990851402283\n",
      "------------train------------\n",
      " (0.8554478088226437, 0.5480821826022866)\n",
      "------------test------------\n",
      " (0.7058005773928493, 0.30328669775705086)\n",
      "------------oot------------\n",
      " (0.6839583405739176, 0.2745003996802558)\n",
      "隐藏层vs神经元数vs norm 1 7 0.02\n",
      "验证集最优结果： 0.7384330630302429 0.7644956111907959\n",
      "------------train------------\n",
      " (0.7940752832920146, 0.46053051729937416)\n",
      "------------test------------\n",
      " (0.7192893626471242, 0.3510104374861204)\n",
      "------------oot------------\n",
      " (0.7039377193897056, 0.31258471483682615)\n",
      "隐藏层vs神经元数vs norm 1 7 0.05\n",
      "验证集最优结果： 0.9766860604286194 0.9873092770576477\n",
      "------------train------------\n",
      " (0.7833140106623244, 0.42748299706471365)\n",
      "------------test------------\n",
      " (0.7141727737064181, 0.3385964912280702)\n",
      "------------oot------------\n",
      " (0.7057078974501558, 0.31940360754874364)\n",
      "隐藏层vs神经元数vs norm 1 7 0.1\n",
      "验证集最优结果： 1.3226901292800903 1.3148438930511475\n",
      "------------train------------\n",
      " (0.7669776567657436, 0.3983431909411529)\n",
      "------------test------------\n",
      " (0.7217965800577392, 0.34882300688429935)\n",
      "------------oot------------\n",
      " (0.7115953613920457, 0.3182636499496055)\n",
      "隐藏层vs神经元数vs norm 1 7 0.2\n",
      "验证集最优结果： 2.079120635986328 2.0685160160064697\n",
      "------------train------------\n",
      " (0.7597048876544038, 0.38837133909832505)\n",
      "------------test------------\n",
      " (0.7124394847879192, 0.3228514323784144)\n",
      "------------oot------------\n",
      " (0.7008619191603239, 0.30449379626733397)\n",
      "隐藏层vs神经元数vs norm 1 7 0.3\n",
      "验证集最优结果： 2.9290237426757812 2.917203187942505\n",
      "------------train------------\n",
      " (0.7523488720094699, 0.37391676294162113)\n",
      "------------test------------\n",
      " (0.7208527648234511, 0.3417832556073729)\n",
      "------------oot------------\n",
      " (0.6987940082716435, 0.2958676537031244)\n",
      "隐藏层vs神经元数vs norm 1 7 0.4\n",
      "验证集最优结果： 3.462228775024414 3.4454169273376465\n",
      "------------train------------\n",
      " (0.7270233814471225, 0.33419517183641184)\n",
      "------------test------------\n",
      " (0.6822562735953809, 0.28125693981789923)\n",
      "------------oot------------\n",
      " (0.6680302135103512, 0.2504083689570083)\n",
      "隐藏层vs神经元数vs norm 1 7 0.5\n",
      "验证集最优结果： 4.386040210723877 4.369001865386963\n",
      "------------train------------\n",
      " (0.7457592659144698, 0.36496268457211617)\n",
      "------------test------------\n",
      " (0.6882744836775483, 0.2775038862980236)\n",
      "------------oot------------\n",
      " (0.6791459585954425, 0.2661661974768012)\n",
      "隐藏层vs神经元数vs norm 1 7 0.6\n",
      "验证集最优结果： 5.146406173706055 5.115059852600098\n",
      "------------train------------\n",
      " (0.6079924117062223, 0.17896827088828116)\n",
      "------------test------------\n",
      " (0.5862658227848101, 0.18905174328225627)\n",
      "------------oot------------\n",
      " (0.5555578725425456, 0.10340249539498841)\n",
      "隐藏层vs神经元数vs norm 1 7 0.8\n",
      "验证集最优结果： 6.658868312835693 6.6265740394592285\n",
      "------------train------------\n",
      " (0.7134672587322569, 0.3207621592391131)\n",
      "------------test------------\n",
      " (0.6690994892294027, 0.2739173884077282)\n",
      "------------oot------------\n",
      " (0.6638480519931881, 0.24149723699301429)\n",
      "隐藏层vs神经元数vs norm 1 8 0.0001\n",
      "验证集最优结果： 0.27045872807502747 0.8436980843544006\n",
      "------------train------------\n",
      " (0.9633165689704299, 0.8064130963717371)\n",
      "------------test------------\n",
      " (0.6716011547856985, 0.2791028203419942)\n",
      "------------oot------------\n",
      " (0.6354359990268654, 0.22664303339936742)\n",
      "隐藏层vs神经元数vs norm 1 8 0.001\n",
      "验证集最优结果： 0.524233877658844 0.6491348743438721\n",
      "------------train------------\n",
      " (0.8800977842209241, 0.6458834589137749)\n",
      "------------test------------\n",
      " (0.6944370419720187, 0.2768043526537864)\n",
      "------------oot------------\n",
      " (0.6612472340967805, 0.24325583011851387)\n",
      "隐藏层vs神经元数vs norm 1 8 0.01\n",
      "验证集最优结果： 0.6551793813705444 0.72489994764328\n",
      "------------train------------\n",
      " (0.8365259394168276, 0.5193324846247713)\n",
      "------------test------------\n",
      " (0.7165134354874527, 0.3319231623362203)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.6882494004796162, 0.30101136482118657)\n",
      "隐藏层vs神经元数vs norm 1 8 0.02\n",
      "验证集最优结果： 0.7625674605369568 0.7799626588821411\n",
      "------------train------------\n",
      " (0.7948993562944869, 0.4448284613807148)\n",
      "------------test------------\n",
      " (0.7195092160781701, 0.3230290917166334)\n",
      "------------oot------------\n",
      " (0.6984673131060368, 0.3245612205887464)\n",
      "隐藏层vs神经元数vs norm 1 8 0.05\n",
      "验证集最优结果： 1.035230040550232 1.0465914011001587\n",
      "------------train------------\n",
      " (0.7682994492869561, 0.3979982931076607)\n",
      "------------test------------\n",
      " (0.7135287586053742, 0.3341105929380413)\n",
      "------------oot------------\n",
      " (0.7090026529501037, 0.3283564452785598)\n",
      "隐藏层vs神经元数vs norm 1 8 0.1\n",
      "验证集最优结果： 1.4393041133880615 1.4370075464248657\n",
      "------------train------------\n",
      " (0.7567844909677511, 0.3821987778325986)\n",
      "------------test------------\n",
      " (0.7054497001998667, 0.31224739062846996)\n",
      "------------oot------------\n",
      " (0.7128673872496205, 0.32737635978173985)\n",
      "隐藏层vs神经元数vs norm 1 8 0.2\n",
      "验证集最优结果： 2.317960739135742 2.308850049972534\n",
      "------------train------------\n",
      " (0.7663041720049353, 0.39606819177023417)\n",
      "------------test------------\n",
      " (0.7136819897845881, 0.3159782367310682)\n",
      "------------oot------------\n",
      " (0.702473383611951, 0.3166093212386613)\n",
      "隐藏层vs神经元数vs norm 1 8 0.3\n",
      "验证集最优结果： 3.2554965019226074 3.2449090480804443\n",
      "------------train------------\n",
      " (0.7638678234550831, 0.4018900347131277)\n",
      "------------test------------\n",
      " (0.7188141239173884, 0.3402398401065955)\n",
      "------------oot------------\n",
      " (0.7097649416698525, 0.3059117923052862)\n",
      "隐藏层vs神经元数vs norm 1 8 0.4\n",
      "验证集最优结果： 4.078390598297119 4.056550979614258\n",
      "------------train------------\n",
      " (0.772025239266104, 0.4046163248482781)\n",
      "------------test------------\n",
      " (0.7159404841216966, 0.3395292027537197)\n",
      "------------oot------------\n",
      " (0.7149804793846083, 0.30884509783477565)\n",
      "隐藏层vs神经元数vs norm 1 8 0.5\n",
      "验证集最优结果： 4.988966941833496 4.963169574737549\n",
      "------------train------------\n",
      " (0.74846166497128, 0.36578337356915785)\n",
      "------------test------------\n",
      " (0.6849478125693982, 0.28264490339773485)\n",
      "------------oot------------\n",
      " (0.6879250223009998, 0.2760713168595558)\n",
      "隐藏层vs神经元数vs norm 1 8 0.6\n",
      "验证集最优结果： 5.850502967834473 5.82155704498291\n",
      "------------train------------\n",
      " (0.7328560532073942, 0.3392722628641275)\n",
      "------------test------------\n",
      " (0.6909193870752832, 0.3086942038640906)\n",
      "------------oot------------\n",
      " (0.6796939260186055, 0.2696833837278003)\n",
      "隐藏层vs神经元数vs norm 1 8 0.8\n",
      "验证集最优结果： 7.547094821929932 7.515786170959473\n",
      "------------train------------\n",
      " (0.6886896386491321, 0.2967093254391255)\n",
      "------------test------------\n",
      " (0.6498600932711525, 0.2973462136353542)\n",
      "------------oot------------\n",
      " (0.6248392590275605, 0.2466757029159281)\n",
      "隐藏层vs神经元数vs norm 1 9 0.0001\n",
      "验证集最优结果： 0.350951224565506 1.026275396347046\n",
      "------------train------------\n",
      " (0.9641846340435007, 0.7883445377753142)\n",
      "------------test------------\n",
      " (0.6753320008882967, 0.29343770819453696)\n",
      "------------oot------------\n",
      " (0.6557073182034083, 0.26793869252424146)\n",
      "隐藏层vs神经元数vs norm 1 9 0.001\n",
      "验证集最优结果： 0.3624262511730194 0.9284905195236206\n",
      "------------train------------\n",
      " (0.9813440457409246, 0.8722360628044336)\n",
      "------------test------------\n",
      " (0.6701399067288474, 0.2699311570064402)\n",
      "------------oot------------\n",
      " (0.6498893638712218, 0.24290828206999615)\n",
      "隐藏层vs神经元数vs norm 1 9 0.01\n",
      "验证集最优结果： 0.683819055557251 0.7317688465118408\n",
      "------------train------------\n",
      " (0.8350490917667824, 0.5166091724143999)\n",
      "------------test------------\n",
      " (0.7063957361758828, 0.32589384854541414)\n",
      "------------oot------------\n",
      " (0.7054970516340551, 0.3160532443610329)\n",
      "隐藏层vs神经元数vs norm 1 9 0.02\n",
      "验证集最优结果： 0.7701037526130676 0.7983835935592651\n",
      "------------train------------\n",
      " (0.8140629113681602, 0.49289609275964974)\n",
      "------------test------------\n",
      " (0.7214901176993116, 0.34042860315345325)\n",
      "------------oot------------\n",
      " (0.707890499194847, 0.3352587495221214)\n",
      "隐藏层vs神经元数vs norm 1 9 0.05\n",
      "验证集最优结果： 1.0820534229278564 1.0996145009994507\n",
      "------------train------------\n",
      " (0.7801738566630052, 0.4207725142957309)\n",
      "------------test------------\n",
      " (0.7239817899178327, 0.347990228736398)\n",
      "------------oot------------\n",
      " (0.713601872125488, 0.31977200848017234)\n",
      "隐藏层vs神经元数vs norm 1 9 0.1\n",
      "验证集最优结果： 1.5676969289779663 1.5679502487182617\n",
      "------------train------------\n",
      " (0.764901163353387, 0.3902739623116547)\n",
      "------------test------------\n",
      " (0.7112524983344437, 0.31435709526982014)\n",
      "------------oot------------\n",
      " (0.6931058052109038, 0.29814061794043023)\n",
      "隐藏层vs神经元数vs norm 1 9 0.2\n",
      "验证集最优结果： 2.596614122390747 2.5976953506469727\n",
      "------------train------------\n",
      " (0.7690152341156478, 0.39855002135307427)\n",
      "------------test------------\n",
      " (0.7162291805463025, 0.3089940039973351)\n",
      "------------oot------------\n",
      " (0.7022034546276023, 0.3171584471553192)\n",
      "隐藏层vs神经元数vs norm 1 9 0.3\n",
      "验证集最优结果： 3.47152042388916 3.452110528945923\n",
      "------------train------------\n",
      " (0.7605353902671943, 0.3822441235053694)\n",
      "------------test------------\n",
      " (0.7056406839884521, 0.329324894514768)\n",
      "------------oot------------\n",
      " (0.6967330483439336, 0.33644736384805196)\n",
      "隐藏层vs神经元数vs norm 1 9 0.4\n",
      "验证集最优结果： 4.5144805908203125 4.494447708129883\n",
      "------------train------------\n",
      " (0.7476646640122527, 0.3641380701287749)\n",
      "------------test------------\n",
      " (0.7035076615589607, 0.31925383077948033)\n",
      "------------oot------------\n",
      " (0.6899141556320162, 0.29963507454905636)\n",
      "隐藏层vs神经元数vs norm 1 9 0.5\n",
      "验证集最优结果： 5.598940372467041 5.584481716156006\n",
      "------------train------------\n",
      " (0.7322029401592783, 0.3348198592389101)\n",
      "------------test------------\n",
      " (0.6887963579835665, 0.29100599600266486)\n",
      "------------oot------------\n",
      " (0.6686222036863263, 0.2769262850589094)\n",
      "隐藏层vs神经元数vs norm 1 9 0.6\n",
      "验证集最优结果： 6.491034030914307 6.470091819763184\n",
      "------------train------------\n",
      " (0.7296742082611695, 0.344057652623721)\n",
      "------------test------------\n",
      " (0.6873673106817677, 0.3066178103486564)\n",
      "------------oot------------\n",
      " (0.7001332267519318, 0.3115698745351545)\n",
      "隐藏层vs神经元数vs norm 1 9 0.8\n",
      "验证集最优结果： 8.503474235534668 8.473843574523926\n",
      "------------train------------\n",
      " (0.7364396472783459, 0.35647180886595886)\n",
      "------------test------------\n",
      " (0.6830446369087275, 0.29457028647568295)\n",
      "------------oot------------\n",
      " (0.6924443054252251, 0.3062732422757446)\n",
      "隐藏层vs神经元数vs norm 1 10 0.0001\n",
      "验证集最优结果： 0.24421098828315735 1.0829778909683228\n",
      "------------train------------\n",
      " (0.9910673085448167, 0.9154050079219567)\n",
      "------------test------------\n",
      " (0.6633888518765267, 0.25829447035309794)\n",
      "------------oot------------\n",
      " (0.6445116370671579, 0.22869356688562192)\n",
      "隐藏层vs神经元数vs norm 1 10 0.001\n",
      "验证集最优结果： 0.3988039493560791 0.7237762808799744\n",
      "------------train------------\n",
      " (0.9536575345896114, 0.7709202938128875)\n",
      "------------test------------\n",
      " (0.6907950255385299, 0.29522540528536534)\n",
      "------------oot------------\n",
      " (0.6583463663851528, 0.2601744691203559)\n",
      "隐藏层vs神经元数vs norm 1 10 0.01\n",
      "验证集最优结果： 0.6799843907356262 0.7422721982002258\n",
      "------------train------------\n",
      " (0.844839087157767, 0.5293997654207435)\n",
      "------------test------------\n",
      " (0.7176038196757717, 0.34706862091938706)\n",
      "------------oot------------\n",
      " (0.6934742061423326, 0.30932471414173013)\n",
      "隐藏层vs神经元数vs norm 1 10 0.02\n",
      "验证集最优结果： 0.7967923879623413 0.8236424922943115\n",
      "------------train------------\n",
      " (0.7954290885046011, 0.46989040560012285)\n",
      "------------test------------\n",
      " (0.7229447035309793, 0.35383077948034647)\n",
      "------------oot------------\n",
      " (0.7125152052271226, 0.3237827129600668)\n",
      "隐藏层vs神经元数vs norm 1 10 0.05\n",
      "验证集最优结果： 1.1506011486053467 1.1682195663452148\n",
      "------------train------------\n",
      " (0.7653014235157245, 0.3914177561472151)\n",
      "------------test------------\n",
      " (0.7088563180102154, 0.3325782811459027)\n",
      "------------oot------------\n",
      " (0.7005827222280147, 0.3209884266499844)\n",
      "隐藏层vs神经元数vs norm 1 10 0.1\n",
      "验证集最优结果： 1.6891462802886963 1.694606900215149\n",
      "------------train------------\n",
      " (0.7645693277808572, 0.39041487229778704)\n",
      "------------test------------\n",
      " (0.698876304685765, 0.295058849655785)\n",
      "------------oot------------\n",
      " (0.6962430055955235, 0.2971813853265214)\n",
      "隐藏层vs神经元数vs norm 1 10 0.2\n",
      "验证集最优结果： 2.8190598487854004 2.8165442943573\n",
      "------------train------------\n",
      " (0.7624590619943027, 0.38442545340596757)\n",
      "------------test------------\n",
      " (0.7149944481456807, 0.3389629136131468)\n",
      "------------oot------------\n",
      " (0.6898689743857088, 0.30495951065234767)\n",
      "隐藏层vs神经元数vs norm 1 10 0.3\n",
      "验证集最优结果： 3.707188129425049 3.691523551940918\n",
      "------------train------------\n",
      " (0.7456774406631568, 0.36252917858682576)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.6900455252054187, 0.2758605374194981)\n",
      "------------oot------------\n",
      " (0.6791598605173832, 0.2892433878983769)\n",
      "隐藏层vs神经元数vs norm 1 10 0.4\n",
      "验证集最优结果： 4.727696895599365 4.7125139236450195\n",
      "------------train------------\n",
      " (0.7458759464217188, 0.37432162535134433)\n",
      "------------test------------\n",
      " (0.6968987341772153, 0.32571618920719525)\n",
      "------------oot------------\n",
      " (0.6837648721602428, 0.27495916310429913)\n",
      "隐藏层vs神经元数vs norm 1 10 0.5\n",
      "验证集最优结果： 6.078531265258789 6.0397419929504395\n",
      "------------train------------\n",
      " (0.7536019015403316, 0.38005291230891364)\n",
      "------------test------------\n",
      " (0.7247834776815456, 0.35405285365312017)\n",
      "------------oot------------\n",
      " (0.6920237722865186, 0.2926771626177319)\n",
      "隐藏层vs神经元数vs norm 1 10 0.6\n",
      "验证集最优结果： 7.287631511688232 7.269596576690674\n",
      "------------train------------\n",
      " (0.7509826813370069, 0.3761404605902112)\n",
      "------------test------------\n",
      " (0.7027514990006662, 0.3236508994003997)\n",
      "------------oot------------\n",
      " (0.7107600875821084, 0.3178674451742953)\n",
      "隐藏层vs神经元数vs norm 1 10 0.8\n",
      "验证集最优结果： 9.308923721313477 9.269021987915039\n",
      "------------train------------\n",
      " (0.7032558193049387, 0.2934774648926356)\n",
      "------------test------------\n",
      " (0.6666677770375306, 0.25306462358427717)\n",
      "------------oot------------\n",
      " (0.6565507014678112, 0.2346783442810968)\n",
      "隐藏层vs神经元数vs norm 1 11 0.0001\n",
      "验证集最优结果： 0.3632428050041199 0.8383849263191223\n",
      "------------train------------\n",
      " (0.9458437306900189, 0.7510496846445339)\n",
      "------------test------------\n",
      " (0.6645725072174106, 0.2667332889184988)\n",
      "------------oot------------\n",
      " (0.6272778878346598, 0.21550759392486007)\n",
      "隐藏层vs神经元数vs norm 1 11 0.001\n",
      "验证集最优结果： 0.40254324674606323 1.1007152795791626\n",
      "------------train------------\n",
      " (0.980597331102597, 0.8522560825805613)\n",
      "------------test------------\n",
      " (0.6852287363979569, 0.30287586053741955)\n",
      "------------oot------------\n",
      " (0.6366686361056082, 0.23647169221144826)\n",
      "隐藏层vs神经元数vs norm 1 11 0.01\n",
      "验证集最优结果： 0.7197383642196655 0.7406638264656067\n",
      "------------train------------\n",
      " (0.7911819586488072, 0.4370744866971363)\n",
      "------------test------------\n",
      " (0.722803686431268, 0.3394403730846103)\n",
      "------------oot------------\n",
      " (0.7114401232637079, 0.3397073645431481)\n",
      "隐藏层vs神经元数vs norm 1 11 0.02\n",
      "验证集最优结果： 0.8326874375343323 0.8573171496391296\n",
      "------------train------------\n",
      " (0.7895708336632739, 0.43726764572711785)\n",
      "------------test------------\n",
      " (0.7227514990006663, 0.35810570730624025)\n",
      "------------oot------------\n",
      " (0.7097023830211193, 0.31974420463629094)\n",
      "隐藏层vs神经元数vs norm 1 11 0.05\n",
      "验证集最优结果： 1.1924238204956055 1.2085192203521729\n",
      "------------train------------\n",
      " (0.7622898617227701, 0.4008162221098732)\n",
      "------------test------------\n",
      " (0.7088385520763936, 0.34514767932489454)\n",
      "------------oot------------\n",
      " (0.6876910066149978, 0.2993014284224794)\n",
      "隐藏层vs神经元数vs norm 1 11 0.1\n",
      "验证集最优结果： 1.7813037633895874 1.7780344486236572\n",
      "------------train------------\n",
      " (0.7769358372266315, 0.4101839613032211)\n",
      "------------test------------\n",
      " (0.719746835443038, 0.3351987563846325)\n",
      "------------oot------------\n",
      " (0.711343968303618, 0.336134570604386)\n",
      "隐藏层vs神经元数vs norm 1 11 0.2\n",
      "验证集最优结果： 2.928081750869751 2.924128770828247\n",
      "------------train------------\n",
      " (0.7650214309063923, 0.3960336749148415)\n",
      "------------test------------\n",
      " (0.7053586497890295, 0.329324894514768)\n",
      "------------oot------------\n",
      " (0.706004471784891, 0.3201751642164529)\n",
      "隐藏层vs神经元数vs norm 1 11 0.3\n",
      "验证集最优结果： 4.278523921966553 4.276735782623291\n",
      "------------train------------\n",
      " (0.7565618234104141, 0.37762725721622237)\n",
      "------------test------------\n",
      " (0.711012658227848, 0.3318676437930268)\n",
      "------------oot------------\n",
      " (0.6849789733430647, 0.29086296180446947)\n",
      "隐藏层vs神经元数vs norm 1 11 0.4\n",
      "验证集最优结果： 5.41867733001709 5.394743919372559\n",
      "------------train------------\n",
      " (0.7531277346993888, 0.3726072882001761)\n",
      "------------test------------\n",
      " (0.7034288252276261, 0.3066511214745725)\n",
      "------------oot------------\n",
      " (0.6960530126623339, 0.26754943870990167)\n",
      "隐藏层vs神经元数vs norm 1 11 0.5\n",
      "验证集最优结果： 6.563398838043213 6.542850971221924\n",
      "------------train------------\n",
      " (0.7187746651695825, 0.3289052945472167)\n",
      "------------test------------\n",
      " (0.6867999111703309, 0.30706195869420394)\n",
      "------------oot------------\n",
      " (0.6614175326405543, 0.26406005630278384)\n",
      "隐藏层vs神经元数vs norm 1 11 0.6\n",
      "验证集最优结果： 7.6403021812438965 7.619894027709961\n",
      "------------train------------\n",
      " (0.7294656181664241, 0.33209559950701806)\n",
      "------------test------------\n",
      " (0.6930990450810571, 0.2909726848767488)\n",
      "------------oot------------\n",
      " (0.6931011712369235, 0.28502415458937197)\n",
      "隐藏层vs神经元数vs norm 1 11 0.8\n",
      "验证集最优结果： 10.170493125915527 10.105996131896973\n",
      "------------train------------\n",
      " (0.7099357106648285, 0.3074927971444409)\n",
      "------------test------------\n",
      " (0.679679102820342, 0.2731401288030202)\n",
      "------------oot------------\n",
      " (0.6969288337445986, 0.2965488478782192)\n",
      "隐藏层vs神经元数vs norm 1 12 0.0001\n",
      "验证集最优结果： 0.32275107502937317 1.3417060375213623\n",
      "------------train------------\n",
      " (0.9744403362618517, 0.8341785902098016)\n",
      "------------test------------\n",
      " (0.6605507439484788, 0.2547079724628026)\n",
      "------------oot------------\n",
      " (0.6313349320543564, 0.2101553539776874)\n",
      "隐藏层vs神经元数vs norm 1 12 0.001\n",
      "验证集最优结果： 0.39154529571533203 0.8434450030326843\n",
      "------------train------------\n",
      " (0.9606203964836123, 0.7857789202180112)\n",
      "------------test------------\n",
      " (0.6789762380635133, 0.28627581612258496)\n",
      "------------oot------------\n",
      " (0.6497016879250224, 0.23907830257533097)\n",
      "隐藏层vs神经元数vs norm 1 12 0.01\n",
      "验证集最优结果： 0.7180419564247131 0.7575048804283142\n",
      "------------train------------\n",
      " (0.8090484921210201, 0.4671138968243816)\n",
      "------------test------------\n",
      " (0.7185587386186987, 0.3332556073728626)\n",
      "------------oot------------\n",
      " (0.6999015280529199, 0.322628853438988)\n",
      "隐藏层vs神经元数vs norm 1 12 0.02\n",
      "验证集最优结果： 0.8546342849731445 0.8723094463348389\n",
      "------------train------------\n",
      " (0.780809643603316, 0.42768305946577384)\n",
      "------------test------------\n",
      " (0.7213835220963802, 0.3523428825227626)\n",
      "------------oot------------\n",
      " (0.7097996964747043, 0.3192298335244848)\n",
      "隐藏层vs神经元数vs norm 1 12 0.05\n",
      "验证集最优结果： 1.248011827468872 1.2591102123260498\n",
      "------------train------------\n",
      " (0.777105917339576, 0.417998035923248)\n",
      "------------test------------\n",
      " (0.7161980901621141, 0.33797468354430377)\n",
      "------------oot------------\n",
      " (0.7104333924165016, 0.31379418204566784)\n",
      "隐藏层vs神经元数vs norm 1 12 0.1\n",
      "验证集最优结果： 1.8865652084350586 1.886603593826294\n",
      "------------train------------\n",
      " (0.7781075152669406, 0.4119623238371373)\n",
      "------------test------------\n",
      " (0.7249344881190318, 0.35104374861203647)\n",
      "------------oot------------\n",
      " (0.721121653401916, 0.32623640218260175)\n",
      "隐藏层vs神经元数vs norm 1 12 0.2\n",
      "验证集最优结果： 3.2351367473602295 3.2317707538604736\n",
      "------------train------------\n",
      " (0.7675320245353929, 0.4014377962273754)\n",
      "------------test------------\n",
      " (0.7141960914945592, 0.34198312236286926)\n",
      "------------oot------------\n",
      " (0.7027908108295972, 0.31579605880512984)\n",
      "隐藏层vs神经元数vs norm 1 12 0.3\n",
      "验证集最优结果： 4.5263352394104 4.5155558586120605\n",
      "------------train------------\n",
      " (0.7711648897254151, 0.3938917348374561)\n",
      "------------test------------\n",
      " (0.7165689540306462, 0.308683100155452)\n",
      "------------oot------------\n",
      " (0.71079484238696, 0.3125360581100337)\n",
      "隐藏层vs神经元数vs norm 1 12 0.4\n",
      "验证集最优结果： 5.587739944458008 5.5780181884765625\n",
      "------------train------------\n",
      " (0.763481843795663, 0.39021778782150596)\n",
      "------------test------------\n",
      " (0.7095514101709971, 0.3136353542083056)\n",
      "------------oot------------\n",
      " (0.6992087489428748, 0.32406075139888085)\n",
      "隐藏层vs神经元数vs norm 1 12 0.5\n",
      "验证集最优结果： 7.257419109344482 7.241022109985352\n",
      "------------train------------\n",
      " (0.7528561344235245, 0.36370654175625816)\n",
      "------------test------------\n",
      " (0.6912302909171664, 0.27336220297579394)\n",
      "------------oot------------\n",
      " (0.6825021142506285, 0.2928717895249018)\n",
      "隐藏层vs神经元数vs norm 1 12 0.6\n",
      "验证集最优结果： 8.58202838897705 8.534340858459473\n",
      "------------train------------\n",
      " (0.7378073945933068, 0.35672100702587206)\n",
      "------------test------------\n",
      " (0.6890239840106596, 0.2834665778369976)\n",
      "------------oot------------\n",
      " (0.6781438617222165, 0.26474125047787855)\n",
      "隐藏层vs神经元数vs norm 1 12 0.8\n",
      "验证集最优结果： 10.970559120178223 10.934980392456055\n",
      "------------train------------\n",
      " (0.6312990046286426, 0.20861080485861963)\n",
      "------------test------------\n",
      " (0.6179902287363979, 0.2116366866533422)\n",
      "------------oot------------\n",
      " (0.5903115189008213, 0.1593229764014875)\n",
      "隐藏层vs神经元数vs norm 1 13 0.0001\n",
      "验证集最优结果： 0.3088154196739197 0.9667481184005737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " (0.9834688627508309, 0.8734488903507792)\n",
      "------------test------------\n",
      " (0.665836109260493, 0.27135243171219187)\n",
      "------------oot------------\n",
      " (0.6385894183204162, 0.21357522677510166)\n",
      "隐藏层vs神经元数vs norm 1 13 0.001\n",
      "验证集最优结果： 0.411699503660202 0.9582934379577637\n",
      "------------train------------\n",
      " (0.9805783806721853, 0.8511043024921847)\n",
      "------------test------------\n",
      " (0.6688763046857651, 0.25650677326226956)\n",
      "------------oot------------\n",
      " (0.6233413269384492, 0.21054460779202722)\n",
      "隐藏层vs神经元数vs norm 1 13 0.01\n",
      "验证集最优结果： 0.7342482209205627 0.7782310247421265\n",
      "------------train------------\n",
      " (0.8178877173462088, 0.4772985349286888)\n",
      "------------test------------\n",
      " (0.7157317343992894, 0.3361425716189207)\n",
      "------------oot------------\n",
      " (0.6957819251844901, 0.3245612205887464)\n",
      "隐藏层vs神经元数vs norm 1 13 0.02\n",
      "验证集最优结果： 0.8962269425392151 0.9189834594726562\n",
      "------------train------------\n",
      " (0.7652564162434968, 0.4119554204660587)\n",
      "------------test------------\n",
      " (0.7083499888962914, 0.31501221407950264)\n",
      "------------oot------------\n",
      " (0.6977768509829817, 0.3219754631077747)\n",
      "隐藏层vs神经元数vs norm 1 13 0.05\n",
      "验证集最优结果： 1.291952133178711 1.297514796257019\n",
      "------------train------------\n",
      " (0.7709808675100962, 0.4158699025880197)\n",
      "------------test------------\n",
      " (0.7213324450366422, 0.3391294692427271)\n",
      "------------oot------------\n",
      " (0.7235185764431933, 0.3440517151496194)\n",
      "隐藏层vs神经元数vs norm 1 13 0.1\n",
      "验证集最优结果： 2.024712562561035 2.0253050327301025\n",
      "------------train------------\n",
      " (0.7693342781476497, 0.4006437731931273)\n",
      "------------test------------\n",
      " (0.7093171219187209, 0.34135021097046414)\n",
      "------------oot------------\n",
      " (0.6892109500805154, 0.3082195113474438)\n",
      "隐藏层vs神经元数vs norm 1 13 0.2\n",
      "验证集最优结果： 3.3746883869171143 3.3727948665618896\n",
      "------------train------------\n",
      " (0.7605022270139739, 0.39520608254672135)\n",
      "------------test------------\n",
      " (0.7130268709749056, 0.33602043082389516)\n",
      "------------oot------------\n",
      " (0.7160949501268551, 0.3246098773155389)\n",
      "隐藏层vs神经元数vs norm 1 13 0.3\n",
      "验证集最优结果： 4.911057472229004 4.897692680358887\n",
      "------------train------------\n",
      " (0.7549679568525771, 0.3715333402367044)\n",
      "------------test------------\n",
      " (0.6993781923162337, 0.29304907839218297)\n",
      "------------oot------------\n",
      " (0.692581007657642, 0.2927327703054947)\n",
      "隐藏层vs神经元数vs norm 1 13 0.4\n",
      "验证集最优结果： 6.310626983642578 6.298081398010254\n",
      "------------train------------\n",
      " (0.7567130884531643, 0.3790547660670886)\n",
      "------------test------------\n",
      " (0.7061536753275595, 0.30586275816122577)\n",
      "------------oot------------\n",
      " (0.7005746127735494, 0.2937198067632851)\n",
      "隐藏层vs神经元数vs norm 1 13 0.5\n",
      "验证集最优结果： 7.791378974914551 7.784733772277832\n",
      "------------train------------\n",
      " (0.7560624118889586, 0.38092585034980464)\n",
      "------------test------------\n",
      " (0.7050621807683766, 0.3273706417943594)\n",
      "------------oot------------\n",
      " (0.6819993280737728, 0.2791436416084524)\n",
      "隐藏层vs神经元数vs norm 1 13 0.6\n",
      "验证集最优结果： 9.07470417022705 9.049090385437012\n",
      "------------train------------\n",
      " (0.7468180535336124, 0.36436669353566975)\n",
      "------------test------------\n",
      " (0.6941239173884077, 0.28053519875638466)\n",
      "------------oot------------\n",
      " (0.6893325918974965, 0.2960066729225316)\n",
      "隐藏层vs神经元数vs norm 1 13 0.8\n",
      "验证集最优结果： 12.008808135986328 11.99156379699707\n",
      "------------train------------\n",
      " (0.71048655906883, 0.30946824415463825)\n",
      "------------test------------\n",
      " (0.672000888296691, 0.2880857206306906)\n",
      "------------oot------------\n",
      " (0.6418922832748295, 0.23546380287074686)\n",
      "隐藏层vs神经元数vs norm 1 14 0.0001\n",
      "验证集最优结果： 0.3148837387561798 1.2695587873458862\n",
      "------------train------------\n",
      " (0.978833452111924, 0.8514294377339616)\n",
      "------------test------------\n",
      " (0.6706884299355984, 0.2846546746613369)\n",
      "------------oot------------\n",
      " (0.6339276404962986, 0.231717234907726)\n",
      "隐藏层vs神经元数vs norm 1 14 0.001\n",
      "验证集最优结果： 0.3688841462135315 0.8365705013275146\n",
      "------------train------------\n",
      " (0.9706195234102111, 0.8113847417902336)\n",
      "------------test------------\n",
      " (0.690810570730624, 0.315312014212747)\n",
      "------------oot------------\n",
      " (0.6601999559772472, 0.2552253849094638)\n",
      "隐藏层vs神经元数vs norm 1 14 0.01\n",
      "验证集最优结果： 0.7358158230781555 0.7893673777580261\n",
      "------------train------------\n",
      " (0.8236141990160666, 0.5044619465205318)\n",
      "------------test------------\n",
      " (0.7157983566511215, 0.3489451476793249)\n",
      "------------oot------------\n",
      " (0.6973597933247604, 0.32128036701073925)\n",
      "隐藏层vs神经元数vs norm 1 14 0.02\n",
      "验证集最优结果： 0.9055697917938232 0.9333515167236328\n",
      "------------train------------\n",
      " (0.7863057421834552, 0.44107072639030176)\n",
      "------------test------------\n",
      " (0.7217010881634465, 0.35267599378192316)\n",
      "------------oot------------\n",
      " (0.7146537842190016, 0.32644493101171235)\n",
      "隐藏层vs神经元数vs norm 1 14 0.05\n",
      "验证集最优结果： 1.3671389818191528 1.3839807510375977\n",
      "------------train------------\n",
      " (0.7742567201271845, 0.41648660373770163)\n",
      "------------test------------\n",
      " (0.7161581168110147, 0.34579169442593827)\n",
      "------------oot------------\n",
      " (0.7038253455206849, 0.30064296388975775)\n",
      "隐藏层vs神经元数vs norm 1 14 0.1\n",
      "验证集最优结果： 2.1473090648651123 2.154595136642456\n",
      "------------train------------\n",
      " (0.7754123579817521, 0.4019344328643779)\n",
      "------------test------------\n",
      " (0.7186608927381745, 0.34961137019764604)\n",
      "------------oot------------\n",
      " (0.7225605023227795, 0.33191533729538114)\n",
      "隐藏层vs神经元数vs norm 1 14 0.2\n",
      "验证集最优结果： 3.6903815269470215 3.6724491119384766\n",
      "------------train------------\n",
      " (0.7717144522073529, 0.41329535125637973)\n",
      "------------test------------\n",
      " (0.7202886964246058, 0.3445369753497668)\n",
      "------------oot------------\n",
      " (0.7107125893488109, 0.3139818579918674)\n",
      "隐藏层vs神经元数vs norm 1 14 0.3\n",
      "验证集最优结果： 5.123686790466309 5.1039862632751465\n",
      "------------train------------\n",
      " (0.7492256380373039, 0.3674150056276011)\n",
      "------------test------------\n",
      " (0.7023939595825005, 0.29611370197646014)\n",
      "------------oot------------\n",
      " (0.6763806346227366, 0.28289020957147326)\n",
      "隐藏层vs神经元数vs norm 1 14 0.4\n",
      "验证集最优结果： 6.46835994720459 6.459923267364502\n",
      "------------train------------\n",
      " (0.7555322735981926, 0.3749147738232291)\n",
      "------------test------------\n",
      " (0.7100199866755497, 0.3290584055074395)\n",
      "------------oot------------\n",
      " (0.7051379186505868, 0.3378097521982414)\n",
      "隐藏层vs神经元数vs norm 1 14 0.5\n",
      "验证集最优结果： 8.031965255737305 8.010226249694824\n",
      "------------train------------\n",
      " (0.7415523380431921, 0.35543332527940047)\n",
      "------------test------------\n",
      " (0.6964445924938929, 0.3079946702198535)\n",
      "------------oot------------\n",
      " (0.689617581297281, 0.2720189066138394)\n",
      "隐藏层vs神经元数vs norm 1 14 0.6\n",
      "验证集最优结果： 9.775582313537598 9.744908332824707\n",
      "------------train------------\n",
      " (0.7399557642810105, 0.3529899379982525)\n",
      "------------test------------\n",
      " (0.6874705751721075, 0.29595825005551857)\n",
      "------------oot------------\n",
      " (0.706297570639141, 0.32362979181871887)\n",
      "隐藏层vs神经元数vs norm 1 14 0.8\n",
      "验证集最优结果： 12.888516426086426 12.83301067352295\n",
      "------------train------------\n",
      " (0.7322692666657191, 0.34246933583479017)\n",
      "------------test------------\n",
      " (0.6788585387519432, 0.27479458139018437)\n",
      "------------oot------------\n",
      " (0.6818394559714547, 0.27920620025718557)\n",
      "隐藏层vs神经元数vs norm 1 15 0.0001\n",
      "验证集最优结果： 0.3333226144313812 0.9434088468551636\n",
      "------------train------------\n",
      " (0.9835089293751299, 0.8834118084192701)\n",
      "------------test------------\n",
      " (0.6627026426826559, 0.2842327337330669)\n",
      "------------oot------------\n",
      " (0.6273334955224227, 0.20503249574253643)\n",
      "隐藏层vs神经元数vs norm 1 15 0.001\n",
      "验证集最优结果： 0.38277578353881836 1.1861164569854736\n",
      "------------train------------\n",
      " (0.9894088751633628, 0.8897450422628438)\n",
      "------------test------------\n",
      " (0.6638352209638019, 0.24806795469686876)\n",
      "------------oot------------\n",
      " (0.6210266569353212, 0.18895492301810723)\n",
      "隐藏层vs神经元数vs norm 1 15 0.01\n",
      "验证集最优结果： 0.7729805707931519 0.8206163644790649\n",
      "------------train------------\n",
      " (0.8140112037651798, 0.4863569760256752)\n",
      "------------test------------\n",
      " (0.721503442149678, 0.33876304685765046)\n",
      "------------oot------------\n",
      " (0.710029078186726, 0.3193201960170994)\n",
      "隐藏层vs神经元数vs norm 1 15 0.02\n",
      "验证集最优结果： 0.9347773194313049 0.9575782418251038\n",
      "------------train------------\n",
      " (0.74860365783915, 0.36205812503087903)\n",
      "------------test------------\n",
      " (0.6771419053964025, 0.28962913613146796)\n",
      "------------oot------------\n",
      " (0.6777349135184606, 0.27894901470128247)\n",
      "隐藏层vs神经元数vs norm 1 15 0.05\n",
      "验证集最优结果： 1.4165139198303223 1.4354944229125977\n",
      "------------train------------\n",
      " (0.766836949819937, 0.40073338165693084)\n",
      "------------test------------\n",
      " (0.7010415278703087, 0.29735731734399296)\n",
      "------------oot------------\n",
      " (0.6875322930061747, 0.26935668856219375)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 1 15 0.1\n",
      "验证集最优结果： 2.1793580055236816 2.179191827774048\n",
      "------------train------------\n",
      " (0.758698958200088, 0.3851811694987408)\n",
      "------------test------------\n",
      " (0.7058549855651788, 0.3477459471463469)\n",
      "------------oot------------\n",
      " (0.6854620651305042, 0.2691968164598756)\n",
      "隐藏层vs神经元数vs norm 1 15 0.2\n",
      "验证集最优结果： 3.9270715713500977 3.915567398071289\n",
      "------------train------------\n",
      " (0.7763917568334915, 0.4143446636603162)\n",
      "------------test------------\n",
      " (0.7234443704197202, 0.33393293359982235)\n",
      "------------oot------------\n",
      " (0.7077387365469943, 0.3126889792513815)\n",
      "隐藏层vs神经元数vs norm 1 15 0.3\n",
      "验证集最优结果： 5.574522495269775 5.555846214294434\n",
      "------------train------------\n",
      " (0.7612057617430065, 0.3856757757324849)\n",
      "------------test------------\n",
      " (0.6938751943149012, 0.27377304019542525)\n",
      "------------oot------------\n",
      " (0.7004854087744298, 0.3130851840266917)\n",
      "隐藏层vs神经元数vs norm 1 15 0.4\n",
      "验证集最优结果： 7.192168712615967 7.172643661499023\n",
      "------------train------------\n",
      " (0.7589999316430904, 0.3812489551883233)\n",
      "------------test------------\n",
      " (0.7083322229624696, 0.3204086164779037)\n",
      "------------oot------------\n",
      " (0.6901748166684044, 0.3228512841900393)\n",
      "隐藏层vs神经元数vs norm 1 15 0.5\n",
      "验证集最优结果： 8.800532341003418 8.781042098999023\n",
      "------------train------------\n",
      " (0.7359279179771228, 0.3358454836048321)\n",
      "------------test------------\n",
      " (0.7086520097712636, 0.3140461914279369)\n",
      "------------oot------------\n",
      " (0.6680000926794796, 0.24735689709102282)\n",
      "隐藏层vs神经元数vs norm 1 15 0.6\n",
      "验证集最优结果： 10.442244529724121 10.413339614868164\n",
      "------------train------------\n",
      " (0.7583683408695134, 0.3772006018115258)\n",
      "------------test------------\n",
      " (0.7076682211858762, 0.3082944703530979)\n",
      "------------oot------------\n",
      " (0.6913970273056916, 0.2794842386959997)\n",
      "隐藏层vs神经元数vs norm 1 15 0.8\n",
      "验证集最优结果： 13.772296905517578 13.717249870300293\n",
      "------------train------------\n",
      " (0.6867386918382528, 0.29982166291380463)\n",
      "------------test------------\n",
      " (0.6499489229402621, 0.2804574727959138)\n",
      "------------oot------------\n",
      " (0.6466780199029183, 0.24577902895075243)\n",
      "隐藏层vs神经元数vs norm 1 16 0.0001\n",
      "验证集最优结果： 0.39285221695899963 0.992676317691803\n",
      "------------train------------\n",
      " (0.9480031322354265, 0.7596420805136108)\n",
      "------------test------------\n",
      " (0.6341550077725959, 0.2303020208749722)\n",
      "------------oot------------\n",
      " (0.61177724487077, 0.2103986376116498)\n",
      "隐藏层vs神经元数vs norm 1 16 0.001\n",
      "验证集最优结果： 0.44529423117637634 0.9769660234451294\n",
      "------------train------------\n",
      " (0.9588393944254603, 0.7819334718068356)\n",
      "------------test------------\n",
      " (0.6868820786142571, 0.2947035309793471)\n",
      "------------oot------------\n",
      " (0.6492985321887418, 0.25173600250234596)\n",
      "隐藏层vs神经元数vs norm 1 16 0.01\n",
      "验证集最优结果： 0.752987802028656 0.802318274974823\n",
      "------------train------------\n",
      " (0.8412246309572878, 0.5301160916903039)\n",
      "------------test------------\n",
      " (0.7166933155673996, 0.33426604485898287)\n",
      "------------oot------------\n",
      " (0.7049386577694365, 0.3101727313801133)\n",
      "隐藏层vs神经元数vs norm 1 16 0.02\n",
      "验证集最优结果： 0.9525865316390991 0.9747720956802368\n",
      "------------train------------\n",
      " (0.7727676223774803, 0.4104558999796283)\n",
      "------------test------------\n",
      " (0.7114634687985788, 0.31401288030202085)\n",
      "------------oot------------\n",
      " (0.6985785284815625, 0.3192993431341883)\n",
      "隐藏层vs神经元数vs norm 1 16 0.05\n",
      "验证集最优结果： 1.460050344467163 1.4815170764923096\n",
      "------------train------------\n",
      " (0.7561858604070688, 0.38594663152715425)\n",
      "------------test------------\n",
      " (0.6977259604707973, 0.3293471019320453)\n",
      "------------oot------------\n",
      " (0.6955166301741216, 0.3204393007333264)\n",
      "隐藏层vs神经元数vs norm 1 16 0.1\n",
      "验证集最优结果： 2.3766727447509766 2.3781003952026367\n",
      "------------train------------\n",
      " (0.7720301799140328, 0.4075660947020687)\n",
      "------------test------------\n",
      " (0.7160370863868533, 0.3325560737286254)\n",
      "------------oot------------\n",
      " (0.7154183899257405, 0.3323393459145727)\n",
      "隐藏层vs神经元数vs norm 1 16 0.2\n",
      "验证集最优结果： 3.9676995277404785 3.9594342708587646\n",
      "------------train------------\n",
      " (0.7590043985302587, 0.3757916373104195)\n",
      "------------test------------\n",
      " (0.7172596047079725, 0.3221630024428159)\n",
      "------------oot------------\n",
      " (0.7131894484412471, 0.31919507871963304)\n",
      "隐藏层vs神经元数vs norm 1 16 0.3\n",
      "验证集最优结果： 5.902055263519287 5.8949384689331055\n",
      "------------train------------\n",
      " (0.7660056350458431, 0.3975805714773011)\n",
      "------------test------------\n",
      " (0.7107550521874305, 0.3392182989118366)\n",
      "------------oot------------\n",
      " (0.7110439184883977, 0.322316060195322)\n",
      "隐藏层vs神经元数vs norm 1 16 0.4\n",
      "验证集最优结果： 7.67750883102417 7.6522440910339355\n",
      "------------train------------\n",
      " (0.7646146734536281, 0.39353221810050354)\n",
      "------------test------------\n",
      " (0.7089029535864979, 0.31027093049078397)\n",
      "------------oot------------\n",
      " (0.6994543495638272, 0.30715601431897965)\n",
      "隐藏层vs神经元数vs norm 1 16 0.5\n",
      "验证集最优结果： 9.399972915649414 9.360169410705566\n",
      "------------train------------\n",
      " (0.7394522242729296, 0.34877698659730816)\n",
      "------------test------------\n",
      " (0.6951010437486121, 0.2943926271374639)\n",
      "------------oot------------\n",
      " (0.6787474368331422, 0.26442845723421265)\n",
      "隐藏层vs神经元数vs norm 1 16 0.6\n",
      "验证集最优结果： 11.119281768798828 11.051806449890137\n",
      "------------train------------\n",
      " (0.7538471065738366, 0.378247883812204)\n",
      "------------test------------\n",
      " (0.7098412169664667, 0.331157006440151)\n",
      "------------oot------------\n",
      " (0.7085172441756739, 0.294268932679943)\n",
      "隐藏层vs神经元数vs norm 1 16 0.8\n",
      "验证集最优结果： 14.075615882873535 14.042486190795898\n",
      "------------train------------\n",
      " (0.6514774229309683, 0.22550375996843397)\n",
      "------------test------------\n",
      " (0.6204219409282701, 0.18645347546080393)\n",
      "------------oot------------\n",
      " (0.6207926412493194, 0.19416119278490251)\n",
      "隐藏层vs神经元数vs norm 1 17 0.0001\n",
      "验证集最优结果： 0.34894198179244995 0.974468469619751\n",
      "------------train------------\n",
      " (0.9880118223613725, 0.9042223589360416)\n",
      "------------test------------\n",
      " (0.6723173439928936, 0.27101932045303134)\n",
      "------------oot------------\n",
      " (0.6352807608985276, 0.2169255899628123)\n",
      "隐藏层vs神经元数vs norm 1 17 0.001\n",
      "验证集最优结果： 0.4014464318752289 0.9417365193367004\n",
      "------------train------------\n",
      " (0.9844529315300645, 0.8744942773084162)\n",
      "------------test------------\n",
      " (0.6682500555185432, 0.2712969131689984)\n",
      "------------oot------------\n",
      " (0.6373011735539105, 0.22287561255343558)\n",
      "隐藏层vs神经元数vs norm 1 17 0.01\n",
      "验证集最优结果： 0.8024287223815918 0.8350921273231506\n",
      "------------train------------\n",
      " (0.7908882269774267, 0.4365769025386132)\n",
      "------------test------------\n",
      " (0.708445480790584, 0.3273595380857206)\n",
      "------------oot------------\n",
      " (0.6913587970203546, 0.3091022833906788)\n",
      "隐藏层vs神经元数vs norm 1 17 0.02\n",
      "验证集最优结果： 0.9744430780410767 0.99025958776474\n",
      "------------train------------\n",
      " (0.7856538473772943, 0.4271184719997238)\n",
      "------------test------------\n",
      " (0.7219431490117698, 0.341427936930935)\n",
      "------------oot------------\n",
      " (0.7104693057148483, 0.33436207555694575)\n",
      "隐藏层vs神经元数vs norm 1 17 0.05\n",
      "验证集最优结果： 1.5146020650863647 1.5260673761367798\n",
      "------------train------------\n",
      " (0.7778256952946758, 0.4134954136574398)\n",
      "------------test------------\n",
      " (0.7200222074172773, 0.3312902509438152)\n",
      "------------oot------------\n",
      " (0.7102121201589453, 0.31054808327251243)\n",
      "隐藏层vs神经元数vs norm 1 17 0.1\n",
      "验证集最优结果： 2.389610528945923 2.3926870822906494\n",
      "------------train------------\n",
      " (0.7592062206141428, 0.3770064952600236)\n",
      "------------test------------\n",
      " (0.7069131689984455, 0.2877970242060848)\n",
      "------------oot------------\n",
      " (0.6799337341720826, 0.2680499078997671)\n",
      "隐藏层vs神经元数vs norm 1 17 0.2\n",
      "验证集最优结果： 4.336073875427246 4.327638149261475\n",
      "------------train------------\n",
      " (0.7702392965600231, 0.39686925353577807)\n",
      "------------test------------\n",
      " (0.7155007772596047, 0.3336775483011326)\n",
      "------------oot------------\n",
      " (0.7116613955212642, 0.30746185660167513)\n",
      "隐藏层vs神经元数vs norm 1 17 0.3\n",
      "验证集最优结果： 5.895973205566406 5.87391996383667\n",
      "------------train------------\n",
      " (0.7552424673731117, 0.3869703608500351)\n",
      "------------test------------\n",
      " (0.722205196535643, 0.34244947812569393)\n",
      "------------oot------------\n",
      " (0.7082310962823943, 0.3069961422166615)\n",
      "隐藏层vs神经元数vs norm 1 17 0.4\n",
      "验证集最优结果： 8.033320426940918 7.997885704040527\n",
      "------------train------------\n",
      " (0.7643358314061423, 0.3900453389047599)\n",
      "------------test------------\n",
      " (0.7100932711525649, 0.3274483677548301)\n",
      "------------oot------------\n",
      " (0.7005340655012222, 0.30572411635908664)\n",
      "隐藏层vs神经元数vs norm 1 17 0.5\n",
      "验证集最优结果： 9.922311782836914 9.901106834411621\n",
      "------------train------------\n",
      " (0.7377165002074395, 0.3524174996396034)\n",
      "------------test------------\n",
      " (0.6942094159449256, 0.3233622029757939)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.6788366408322617, 0.2763006985715776)\n",
      "隐藏层vs神经元数vs norm 1 17 0.6\n",
      "验证集最优结果： 11.699426651000977 11.655515670776367\n",
      "------------train------------\n",
      " (0.7470752379463419, 0.3641479514246324)\n",
      "------------test------------\n",
      " (0.7011503442149678, 0.3047301798800799)\n",
      "------------oot------------\n",
      " (0.6990268654641505, 0.299058144788517)\n",
      "隐藏层vs神经元数vs norm 1 17 0.8\n",
      "验证集最优结果： 15.393647193908691 15.353339195251465\n",
      "------------train------------\n",
      " (0.681830395001418, 0.26004877028626655)\n",
      "------------test------------\n",
      " (0.6545380857206307, 0.2291916500111037)\n",
      "------------oot------------\n",
      " (0.6658429777916797, 0.24078128801306783)\n",
      "隐藏层vs神经元数vs norm 1 18 0.0001\n",
      "验证集最优结果： 0.3414268493652344 1.2002652883529663\n",
      "------------train------------\n",
      " (0.9842639686668169, 0.8868335793505281)\n",
      "------------test------------\n",
      " (0.6802242949145014, 0.30940484121696654)\n",
      "------------oot------------\n",
      " (0.6367242437933711, 0.22917318319257635)\n",
      "隐藏层vs神经元数vs norm 1 18 0.001\n",
      "验证集最优结果： 0.4058118462562561 0.9427073001861572\n",
      "------------train------------\n",
      " (0.9864933514445303, 0.879153511345555)\n",
      "------------test------------\n",
      " (0.6712069731290251, 0.2754941150344215)\n",
      "------------oot------------\n",
      " (0.6482860088740602, 0.21718972647968587)\n",
      "隐藏层vs神经元数vs norm 1 18 0.01\n",
      "验证集最优结果： 0.7845278978347778 0.8292557001113892\n",
      "------------train------------\n",
      " (0.8200307403053322, 0.49330000764785226)\n",
      "------------test------------\n",
      " (0.7199400399733511, 0.3358982900288696)\n",
      "------------oot------------\n",
      " (0.7075012453805072, 0.33251311993883154)\n",
      "隐藏层vs神经元数vs norm 1 18 0.02\n",
      "验证集最优结果： 1.000701665878296 1.0218085050582886\n",
      "------------train------------\n",
      " (0.7629596917577135, 0.40788635697602565)\n",
      "------------test------------\n",
      " (0.7104063957361759, 0.3182544970019987)\n",
      "------------oot------------\n",
      " (0.6960483786883536, 0.31486463003510234)\n",
      "隐藏层vs神经元数vs norm 1 18 0.05\n",
      "验证集最优结果： 1.6006823778152466 1.6115094423294067\n",
      "------------train------------\n",
      " (0.7619388049993943, 0.3913311256081904)\n",
      "------------test------------\n",
      " (0.7112014212747058, 0.32108594270486346)\n",
      "------------oot------------\n",
      " (0.696210567777662, 0.3115351197303027)\n",
      "隐藏层vs神经元数vs norm 1 18 0.1\n",
      "验证集最优结果： 2.5577855110168457 2.5662360191345215\n",
      "------------train------------\n",
      " (0.7767220357635229, 0.4231242627098168)\n",
      "------------test------------\n",
      " (0.7236286919831223, 0.34823451032644903)\n",
      "------------oot------------\n",
      " (0.7178234224214831, 0.3165676154728391)\n",
      "隐藏层vs神经元数vs norm 1 18 0.2\n",
      "验证集最优结果： 4.399324893951416 4.39225959777832\n",
      "------------train------------\n",
      " (0.7773621542307851, 0.41512108986632507)\n",
      "------------test------------\n",
      " (0.7259327115256495, 0.33575394181656676)\n",
      "------------oot------------\n",
      " (0.7162281768787868, 0.3457825044312377)\n",
      "隐藏层vs神经元数vs norm 1 18 0.3\n",
      "验证集最优结果： 6.443484783172607 6.424007415771484\n",
      "------------train------------\n",
      " (0.7621228272147131, 0.3904227231903862)\n",
      "------------test------------\n",
      " (0.7136953142349544, 0.3405063291139241)\n",
      "------------oot------------\n",
      " (0.7239101472445233, 0.3560282209015396)\n",
      "隐藏层vs神经元数vs norm 1 18 0.4\n",
      "验证集最优结果： 8.461179733276367 8.439891815185547\n",
      "------------train------------\n",
      " (0.7537799002259838, 0.3760055064536368)\n",
      "------------test------------\n",
      " (0.7123673106817676, 0.3287141905396402)\n",
      "------------oot------------\n",
      " (0.697331989480879, 0.29798769679908244)\n",
      "隐藏层vs神经元数vs norm 1 18 0.5\n",
      "验证集最优结果： 10.531746864318848 10.497056007385254\n",
      "------------train------------\n",
      " (0.7467741291431225, 0.3650405166970212)\n",
      "------------test------------\n",
      " (0.6863957361758828, 0.2629913391072618)\n",
      "------------oot------------\n",
      " (0.6737890846742896, 0.2520696486289229)\n",
      "隐藏层vs神经元数vs norm 1 18 0.6\n",
      "验证集最优结果： 12.38775634765625 12.369917869567871\n",
      "------------train------------\n",
      " (0.7340767316463389, 0.34308617234468936)\n",
      "------------test------------\n",
      " (0.6838130135465246, 0.3003109038418832)\n",
      "------------oot------------\n",
      " (0.6860169835146376, 0.28503805651131264)\n",
      "隐藏层vs神经元数vs norm 1 18 0.8\n",
      "验证集最优结果： 16.390626907348633 16.348905563354492\n",
      "------------train------------\n",
      " (0.7344138462673405, 0.33945743564129266)\n",
      "------------test------------\n",
      " (0.6806007106373528, 0.2818121252498335)\n",
      "------------oot------------\n",
      " (0.679312781658731, 0.26635387342300076)\n",
      "隐藏层vs神经元数vs norm 1 19 0.0001\n",
      "验证集最优结果： 0.3650685250759125 1.0156091451644897\n",
      "------------train------------\n",
      " (0.991467433346937, 0.9097535834925508)\n",
      "------------test------------\n",
      " (0.673217854763491, 0.28127914723517655)\n",
      "------------oot------------\n",
      " (0.6501928891669273, 0.23832064782956242)\n",
      "隐藏层vs神经元数vs norm 1 19 0.001\n",
      "验证集最优结果： 0.4579170048236847 0.9966237545013428\n",
      "------------train------------\n",
      " (0.9734646598160862, 0.8420843036968906)\n",
      "------------test------------\n",
      " (0.6858027981345769, 0.2964912280701754)\n",
      "------------oot------------\n",
      " (0.6440690925520453, 0.23554721440239113)\n",
      "隐藏层vs神经元数vs norm 1 19 0.01\n",
      "验证集最优结果： 0.8253912925720215 0.8599258065223694\n",
      "------------train------------\n",
      " (0.7957335813132513, 0.4506857687005216)\n",
      "------------test------------\n",
      " (0.7113168998445482, 0.33707528314457025)\n",
      "------------oot------------\n",
      " (0.6944519746521622, 0.32144023911305736)\n",
      "隐藏层vs神经元数vs norm 1 19 0.02\n",
      "验证集最优结果： 1.010511875152588 1.0303007364273071\n",
      "------------train------------\n",
      " (0.7688047489778612, 0.40743411849027333)\n",
      "------------test------------\n",
      " (0.714417055296469, 0.3286808794137242)\n",
      "------------oot------------\n",
      " (0.6980386705128651, 0.31868070760782674)\n",
      "隐藏层vs神经元数vs norm 1 19 0.05\n",
      "验证集最优结果： 1.6440777778625488 1.6645736694335938\n",
      "------------train------------\n",
      " (0.7651182134617089, 0.4008003849644578)\n",
      "------------test------------\n",
      " (0.7152864756828781, 0.32782589384854544)\n",
      "------------oot------------\n",
      " (0.7017724950474403, 0.31522608000556074)\n",
      "隐藏层vs神经元数vs norm 1 19 0.1\n",
      "验证集最优结果： 2.6545896530151367 2.6545684337615967\n",
      "------------train------------\n",
      " (0.7731960374650009, 0.4128087312754519)\n",
      "------------test------------\n",
      " (0.7223872973573173, 0.3509993337774817)\n",
      "------------oot------------\n",
      " (0.7163637206177087, 0.35383866819587806)\n",
      "隐藏层vs神经元数vs norm 1 19 0.2\n",
      "验证集最优结果： 4.676857948303223 4.659770488739014\n",
      "------------train------------\n",
      " (0.7687455288828247, 0.40394331384823)\n",
      "------------test------------\n",
      " (0.7163713080168777, 0.32758161225849436)\n",
      "------------oot------------\n",
      " (0.7024942364948621, 0.3236784485455114)\n",
      "隐藏层vs神经元数vs norm 1 19 0.3\n",
      "验证集最优结果： 6.46707820892334 6.4524641036987305\n",
      "------------train------------\n",
      " (0.7671183637115501, 0.40769915379560207)\n",
      "------------test------------\n",
      " (0.7208594270486343, 0.34884521430157667)\n",
      "------------oot------------\n",
      " (0.7054333344918269, 0.31676224238000905)\n",
      "隐藏层vs神经元数vs norm 1 19 0.4\n",
      "验证集最优结果： 9.068872451782227 9.032724380493164\n",
      "------------train------------\n",
      " (0.7510158445902275, 0.3702988550556026)\n",
      "------------test------------\n",
      " (0.6961947590495225, 0.3002553852986898)\n",
      "------------oot------------\n",
      " (0.6993755720061632, 0.29074479546797344)\n",
      "隐藏层vs神经元数vs norm 1 19 0.5\n",
      "验证集最优结果： 10.465044021606445 10.438700675964355\n",
      "------------train------------\n",
      " (0.7627091399956278, 0.3816528700765259)\n",
      "------------test------------\n",
      " (0.6957628247834777, 0.303775260937153)\n",
      "------------oot------------\n",
      " (0.7010032553667211, 0.3250755917005526)\n",
      "隐藏层vs神经元数vs norm 1 19 0.6\n",
      "验证集最优结果： 12.92722225189209 12.899896621704102\n",
      "------------train------------\n",
      " (0.7385507252262038, 0.34937595555853346)\n",
      "------------test------------\n",
      " (0.6942516100377526, 0.30919387075283145)\n",
      "------------oot------------\n",
      " (0.6883861027120333, 0.2768359225662948)\n",
      "隐藏层vs神经元数vs norm 1 19 0.8\n",
      "验证集最优结果： 17.270946502685547 17.203012466430664\n",
      "------------train------------\n",
      " (0.7076520484400073, 0.30083348053756953)\n",
      "------------test------------\n",
      " (0.6801809904508106, 0.2858982900288697)\n",
      "------------oot------------\n",
      " (0.6390632421598953, 0.23694435755743232)\n",
      "隐藏层vs神经元数vs norm 1 20 0.0001\n",
      "验证集最优结果： 0.4789324998855591 1.0789908170700073\n",
      "------------train------------\n",
      " (0.9529862832723872, 0.7717045709114954)\n",
      "------------test------------\n",
      " (0.6394159449256052, 0.2273928492116367)\n",
      "------------oot------------\n",
      " (0.5936143838552347, 0.16858165641399925)\n",
      "隐藏层vs神经元数vs norm 1 20 0.001\n",
      "验证集最优结果： 0.4120163917541504 0.8979000449180603\n",
      "------------train------------\n",
      " (0.9827607934545213, 0.8697266197372794)\n",
      "------------test------------\n",
      " (0.6766999777925828, 0.28538751943149016)\n",
      "------------oot------------\n",
      " (0.6542568843475944, 0.2370347200500469)\n",
      "隐藏层vs神经元数vs norm 1 20 0.01\n",
      "验证集最优结果： 0.8207136392593384 0.857201099395752\n",
      "------------train------------\n",
      " (0.8078512986797641, 0.46899283199969677)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.7188141239173884, 0.3346990894958916)\n",
      "------------oot------------\n",
      " (0.6972080306769078, 0.3295311576825496)\n",
      "隐藏层vs神经元数vs norm 1 20 0.02\n",
      "验证集最优结果： 1.0373940467834473 1.0614787340164185\n",
      "------------train------------\n",
      " (0.7753715468762584, 0.41829257975593204)\n",
      "------------test------------\n",
      " (0.7157606040417499, 0.3408172329558073)\n",
      "------------oot------------\n",
      " (0.7047556157972173, 0.3275848886108504)\n",
      "隐藏层vs神经元数vs norm 1 20 0.05\n",
      "验证集最优结果： 1.6938363313674927 1.7078373432159424\n",
      "------------train------------\n",
      " (0.7642987427066222, 0.3858915399187433)\n",
      "------------test------------\n",
      " (0.7133422163002443, 0.3233177881412392)\n",
      "------------oot------------\n",
      " (0.6945886768845793, 0.30201230320091754)\n",
      "隐藏层vs神经元数vs norm 1 20 0.1\n",
      "验证集最优结果： 2.703090190887451 2.702345132827759\n",
      "------------train------------\n",
      " (0.769139697835387, 0.3980210336241548)\n",
      "------------test------------\n",
      " (0.713175660670664, 0.3268487674883411)\n",
      "------------oot------------\n",
      " (0.6937568785551269, 0.3130504292218399)\n",
      "隐藏层vs神经元数vs norm 1 20 0.2\n",
      "验证集最优结果： 4.870249271392822 4.864352703094482\n",
      "------------train------------\n",
      " (0.7573396708987038, 0.38396536402761616)\n",
      "------------test------------\n",
      " (0.710777259604708, 0.33927381745502994)\n",
      "------------oot------------\n",
      " (0.7046675702915929, 0.31427379835262226)\n",
      "隐藏层vs神经元数vs norm 1 20 0.3\n",
      "验证集最优结果： 7.056982517242432 7.045079231262207\n",
      "------------train------------\n",
      " (0.7625343222750804, 0.3847229751634305)\n",
      "------------test------------\n",
      " (0.7162380635132135, 0.32779258272262934)\n",
      "------------oot------------\n",
      " (0.7037187641191395, 0.31522608000556074)\n",
      "隐藏层vs神经元数vs norm 1 20 0.4\n",
      "验证集最优结果： 9.392984390258789 9.37578296661377\n",
      "------------train------------\n",
      " (0.7342991284832414, 0.3419362872993539)\n",
      "------------test------------\n",
      " (0.6886520097712636, 0.2860648456584499)\n",
      "------------oot------------\n",
      " (0.6802801237271053, 0.2712195461022487)\n",
      "隐藏层vs神经元数vs norm 1 20 0.5\n",
      "验证集最优结果： 11.579028129577637 11.54533576965332\n",
      "------------train------------\n",
      " (0.75100156408731, 0.36251834976944775)\n",
      "------------test------------\n",
      " (0.6988829669109482, 0.3063069065067733)\n",
      "------------oot------------\n",
      " (0.6700378827372884, 0.2667083724324888)\n",
      "隐藏层vs神经元数vs norm 1 20 0.6\n",
      "验证集最优结果： 13.039921760559082 12.995162010192871\n",
      "------------train------------\n",
      " (0.7537189881282321, 0.3888511910683914)\n",
      "------------test------------\n",
      " (0.7003175660670664, 0.3023872973573174)\n",
      "------------oot------------\n",
      " (0.6948632398429083, 0.29298995586139787)\n",
      "隐藏层vs神经元数vs norm 1 20 0.8\n",
      "验证集最优结果： 17.84783363342285 17.80333137512207\n",
      "------------train------------\n",
      " (0.6538103562748598, 0.23101535729344536)\n",
      "------------test------------\n",
      " (0.631367976904286, 0.20679546968687543)\n",
      "------------oot------------\n",
      " (0.5956927211853705, 0.14700587356201994)\n",
      "隐藏层vs神经元数vs norm 1 22 0.0001\n",
      "验证集最优结果： 0.5606074333190918 1.3340038061141968\n",
      "------------train------------\n",
      " (0.9100996995679977, 0.6655856799718992)\n",
      "------------test------------\n",
      " (0.6459538085720631, 0.24142793693093492)\n",
      "------------oot------------\n",
      " (0.6022706472503156, 0.17005526013971434)\n",
      "隐藏层vs神经元数vs norm 1 22 0.001\n",
      "验证集最优结果： 0.4732216000556946 0.945668637752533\n",
      "------------train------------\n",
      " (0.9682838828619753, 0.8161996400771824)\n",
      "------------test------------\n",
      " (0.6908216744392628, 0.28683100155451924)\n",
      "------------oot------------\n",
      " (0.6667987349251034, 0.25950022590623156)\n",
      "隐藏层vs神经元数vs norm 1 22 0.01\n",
      "验证集最优结果： 0.8520600199699402 0.8877136707305908\n",
      "------------train------------\n",
      " (0.7897446361821922, 0.45137055603946835)\n",
      "------------test------------\n",
      " (0.7120208749722406, 0.3369753497668221)\n",
      "------------oot------------\n",
      " (0.6997057426522549, 0.3192506864073958)\n",
      "隐藏层vs神经元数vs norm 1 22 0.02\n",
      "验证集最优结果： 1.0926198959350586 1.114184021949768\n",
      "------------train------------\n",
      " (0.762892079329209, 0.4051828073573692)\n",
      "------------test------------\n",
      " (0.7076149233844105, 0.31489007328447705)\n",
      "------------oot------------\n",
      " (0.7009696590553645, 0.3170055260139715)\n",
      "隐藏层vs神经元数vs norm 1 22 0.05\n",
      "验证集最优结果： 1.7935501337051392 1.8085252046585083\n",
      "------------train------------\n",
      " (0.7616839217103576, 0.38593986351629295)\n",
      "------------test------------\n",
      " (0.7129757939151676, 0.3245502998001333)\n",
      "------------oot------------\n",
      " (0.6953405391628726, 0.3107913669064748)\n",
      "隐藏层vs神经元数vs norm 1 22 0.1\n",
      "验证集最优结果： 2.9934539794921875 2.9943525791168213\n",
      "------------train------------\n",
      " (0.7736622180531276, 0.4046842756773256)\n",
      "------------test------------\n",
      " (0.7167466133688652, 0.33831889851210306)\n",
      "------------oot------------\n",
      " (0.6921871198693219, 0.32314322455079414)\n",
      "隐藏层vs神经元数vs norm 1 22 0.2\n",
      "验证集最优结果： 5.152738094329834 5.14758825302124\n",
      "------------train------------\n",
      " (0.7663214304326316, 0.40801346022000096)\n",
      "------------test------------\n",
      " (0.7160848323339997, 0.3512991339107262)\n",
      "------------oot------------\n",
      " (0.6996686708604132, 0.3167761443019497)\n",
      "隐藏层vs神经元数vs norm 1 22 0.3\n",
      "验证集最优结果： 7.880367755889893 7.870666027069092\n",
      "------------train------------\n",
      " (0.7552677120536242, 0.377709014787427)\n",
      "------------test------------\n",
      " (0.7070841661114813, 0.31162558294470355)\n",
      "------------oot------------\n",
      " (0.6898040987499855, 0.3204184478504153)\n",
      "隐藏层vs神经元数vs norm 1 22 0.4\n",
      "验证集最优结果： 10.372517585754395 10.359421730041504\n",
      "------------train------------\n",
      " (0.7525094769072085, 0.3728221048649139)\n",
      "------------test------------\n",
      " (0.715127692649345, 0.33181212524983345)\n",
      "------------oot------------\n",
      " (0.6891831462366339, 0.28911827060091055)\n",
      "隐藏层vs神经元数vs norm 1 22 0.5\n",
      "验证集最优结果： 11.92674732208252 11.881994247436523\n",
      "------------train------------\n",
      " (0.7529395163173358, 0.3650268453150814)\n",
      "------------test------------\n",
      " (0.7083144570286476, 0.3387519431490118)\n",
      "------------oot------------\n",
      " (0.6908386334410732, 0.29790428526743823)\n",
      "隐藏层vs神经元数vs norm 1 22 0.6\n",
      "验证集最优结果： 14.997323989868164 14.964599609375\n",
      "------------train------------\n",
      " (0.7475529241529326, 0.35613679232832435)\n",
      "------------test------------\n",
      " (0.7051154785698424, 0.31632245169886736)\n",
      "------------oot------------\n",
      " (0.6894264298705962, 0.2930386125881903)\n",
      "隐藏层vs神经元数vs norm 1 22 0.8\n",
      "验证集最优结果： 19.727460861206055 19.663850784301758\n",
      "------------train------------\n",
      " (0.6891850570441795, 0.2723072622786945)\n",
      "------------test------------\n",
      " (0.6343981789917832, 0.2221630024428159)\n",
      "------------oot------------\n",
      " (0.6355796522202528, 0.21749556876238135)\n",
      "隐藏层vs神经元数vs norm 1 24 0.0001\n",
      "验证集最优结果： 0.30035388469696045 1.0511913299560547\n",
      "------------train------------\n",
      " (0.9980611002484536, 0.9699438052058186)\n",
      "------------test------------\n",
      " (0.6572318454363757, 0.24915611814345995)\n",
      "------------oot------------\n",
      " (0.6312584714836826, 0.21785701873283986)\n",
      "隐藏层vs神经元数vs norm 1 24 0.001\n",
      "验证集最优结果： 0.4498264491558075 0.8548215627670288\n",
      "------------train------------\n",
      " (0.9753778411263594, 0.8384516415471944)\n",
      "------------test------------\n",
      " (0.6726271374639129, 0.2737286253608705)\n",
      "------------oot------------\n",
      " (0.6403294755499948, 0.2303478955965662)\n",
      "隐藏层vs神经元数vs norm 1 24 0.01\n",
      "验证集最优结果： 0.8649427890777588 0.9032437205314636\n",
      "------------train------------\n",
      " (0.8057671574151342, 0.47012484949635847)\n",
      "------------test------------\n",
      " (0.7144326004885632, 0.3333000222074173)\n",
      "------------oot------------\n",
      " (0.6991137524762798, 0.3316512007785076)\n",
      "隐藏层vs神经元数vs norm 1 24 0.02\n",
      "验证集最优结果： 1.1348984241485596 1.1547443866729736\n",
      "------------train------------\n",
      " (0.7608692562429824, 0.39997969596741606)\n",
      "------------test------------\n",
      " (0.7092205196535643, 0.3133133466577837)\n",
      "------------oot------------\n",
      " (0.6971512644956499, 0.3115698745351545)\n",
      "隐藏层vs神经元数vs norm 1 24 0.05\n",
      "验证集最优结果： 1.913894772529602 1.926392912864685\n",
      "------------train------------\n",
      " (0.762827715545918, 0.3958307699492196)\n",
      "------------test------------\n",
      " (0.712440595158783, 0.3243726404619142)\n",
      "------------oot------------\n",
      " (0.697901968280448, 0.32095367184513257)\n",
      "隐藏层vs神经元数vs norm 1 24 0.1\n",
      "验证集最优结果： 3.1433074474334717 3.1479406356811523\n",
      "------------train------------\n",
      " (0.7757739728020715, 0.4203281267025777)\n",
      "------------test------------\n",
      " (0.7062003109038419, 0.3101154785698424)\n",
      "------------oot------------\n",
      " (0.7050394467035067, 0.30655128071455884)\n",
      "隐藏层vs神经元数vs norm 1 24 0.2\n",
      "验证集最优结果： 5.6773271560668945 5.662659168243408\n",
      "------------train------------\n",
      " (0.7611135137549669, 0.39434992917276634)\n",
      "------------test------------\n",
      " (0.7108838552076393, 0.33781923162336225)\n",
      "------------oot------------\n",
      " (0.6832748294118328, 0.2995933687832343)\n",
      "隐藏层vs神经元数vs norm 1 24 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集最优结果： 8.590391159057617 8.567315101623535\n",
      "------------train------------\n",
      " (0.7559569662797395, 0.37362709207675737)\n",
      "------------test------------\n",
      " (0.7054452587164113, 0.3039307128580946)\n",
      "------------oot------------\n",
      " (0.6995933687832342, 0.2892294859764363)\n",
      "隐藏层vs神经元数vs norm 1 24 0.4\n",
      "验证集最优结果： 10.825628280639648 10.796889305114746\n",
      "------------train------------\n",
      " (0.7682283851729125, 0.40155704857875163)\n",
      "------------test------------\n",
      " (0.7216544525871641, 0.33773040195425275)\n",
      "------------oot------------\n",
      " (0.7125430090710041, 0.3266673617627637)\n",
      "隐藏层vs神经元数vs norm 1 24 0.5\n",
      "验证集最优结果： 13.501300811767578 13.458745002746582\n",
      "------------train------------\n",
      " (0.756354248517298, 0.3833446020714174)\n",
      "------------test------------\n",
      " (0.706815456362425, 0.3179991117033089)\n",
      "------------oot------------\n",
      " (0.6985009094173936, 0.3134466339971501)\n",
      "隐藏层vs神经元数vs norm 1 24 0.6\n",
      "验证集最优结果： 16.396831512451172 16.364173889160156\n",
      "------------train------------\n",
      " (0.7483885027738693, 0.37292362502783344)\n",
      "------------test------------\n",
      " (0.7002931379080614, 0.3235953808572063)\n",
      "------------oot------------\n",
      " (0.701215259676317, 0.3055086365690056)\n",
      "隐藏层vs神经元数vs norm 1 24 0.8\n",
      "验证集最优结果： 20.997512817382812 20.96726417541504\n",
      "------------train------------\n",
      " (0.6973948572592669, 0.2824978562325597)\n",
      "------------test------------\n",
      " (0.6761092604930047, 0.27123029091716633)\n",
      "------------oot------------\n",
      " (0.6640994450816159, 0.23960657560907797)\n",
      "隐藏层vs神经元数vs norm 1 26 0.0001\n",
      "验证集最优结果： 0.41328734159469604 1.662199854850769\n",
      "------------train------------\n",
      " (0.9981628911318077, 0.9616381022768264)\n",
      "------------test------------\n",
      " (0.6599800133244504, 0.2528425494115034)\n",
      "------------oot------------\n",
      " (0.6257648953301127, 0.2055538178153129)\n",
      "隐藏层vs神经元数vs norm 1 26 0.001\n",
      "验证集最优结果： 0.4650697410106659 0.9557055234909058\n",
      "------------train------------\n",
      " (0.9718492709837099, 0.8300464488585412)\n",
      "------------test------------\n",
      " (0.6910237619364867, 0.31320230957139683)\n",
      "------------oot------------\n",
      " (0.6350189413686441, 0.23502589232961463)\n",
      "隐藏层vs神经元数vs norm 1 26 0.01\n",
      "验证集最优结果： 0.9018785357475281 0.9286257028579712\n",
      "------------train------------\n",
      " (0.7717040294706266, 0.41202540169836466)\n",
      "------------test------------\n",
      " (0.7057805907172996, 0.3056962025316456)\n",
      "------------oot------------\n",
      " (0.685260487262364, 0.30006603412921834)\n",
      "隐藏层vs神经元数vs norm 1 26 0.02\n",
      "验证集最优结果： 1.1781507730484009 1.1947705745697021\n",
      "------------train------------\n",
      " (0.7730519465137637, 0.4026102864289876)\n",
      "------------test------------\n",
      " (0.7128425494115035, 0.3461914279369309)\n",
      "------------oot------------\n",
      " (0.7049039029645847, 0.3342230563375386)\n",
      "隐藏层vs神经元数vs norm 1 26 0.05\n",
      "验证集最优结果： 2.02516770362854 2.042269468307495\n",
      "------------train------------\n",
      " (0.7688442064811825, 0.3976190137789933)\n",
      "------------test------------\n",
      " (0.7113946258050188, 0.32689318232289577)\n",
      "------------oot------------\n",
      " (0.7022590623153651, 0.28311959128349495)\n",
      "隐藏层vs神经元数vs norm 1 26 0.1\n",
      "验证集最优结果： 3.308549165725708 3.3056793212890625\n",
      "------------train------------\n",
      " (0.7644110240068114, 0.3939301771391483)\n",
      "------------test------------\n",
      " (0.7154241616699978, 0.3319675771707751)\n",
      "------------oot------------\n",
      " (0.7076796533787464, 0.3109998957355855)\n",
      "隐藏层vs神经元数vs norm 1 26 0.2\n",
      "验证集最优结果： 6.27316427230835 6.2640557289123535\n",
      "------------train------------\n",
      " (0.7588666695092312, 0.3912523459617648)\n",
      "------------test------------\n",
      " (0.7157495003331114, 0.32244059515878304)\n",
      "------------oot------------\n",
      " (0.6957425364056582, 0.32480450422270873)\n",
      "隐藏层vs神经元数vs norm 1 26 0.3\n",
      "验证集最优结果： 9.234406471252441 9.21137809753418\n",
      "------------train------------\n",
      " (0.7538048741860621, 0.37219944786567394)\n",
      "------------test------------\n",
      " (0.7028270042194094, 0.2973684210526315)\n",
      "------------oot------------\n",
      " (0.6756079194615322, 0.2485455114169534)\n",
      "隐藏层vs神经元数vs norm 1 26 0.4\n",
      "验证集最优结果： 11.964739799499512 11.9369478225708\n",
      "------------train------------\n",
      " (0.7556869226463734, 0.38575848082521)\n",
      "------------test------------\n",
      " (0.6999289362647124, 0.30445258716411283)\n",
      "------------oot------------\n",
      " (0.6893013125731299, 0.32488791575435305)\n",
      "隐藏层vs神经元数vs norm 1 26 0.5\n",
      "验证集最优结果： 14.794708251953125 14.755859375\n",
      "------------train------------\n",
      " (0.7464348487586453, 0.35867087095501365)\n",
      "------------test------------\n",
      " (0.6955585165445258, 0.29873417721518986)\n",
      "------------oot------------\n",
      " (0.6845167344385361, 0.29919716400792407)\n",
      "隐藏层vs神经元数vs norm 1 26 0.6\n",
      "验证集最优结果： 17.476226806640625 17.42066192626953\n",
      "------------train------------\n",
      " (0.6915311203291419, 0.27764451564391873)\n",
      "------------test------------\n",
      " (0.6747035309793471, 0.27249611370197646)\n",
      "------------oot------------\n",
      " (0.6396042586220879, 0.23923817467764918)\n",
      "隐藏层vs神经元数vs norm 1 26 0.8\n",
      "验证集最优结果： 23.055906295776367 22.950653076171875\n",
      "------------train------------\n",
      " (0.6930062082963631, 0.2872802680673742)\n",
      "------------test------------\n",
      " (0.6607272929158339, 0.2711747723739729)\n",
      "------------oot------------\n",
      " (0.6682491687809172, 0.272442915233031)\n",
      "隐藏层vs神经元数vs norm 1 28 0.0001\n",
      "验证集最优结果： 0.46959248185157776 1.4661121368408203\n",
      "------------train------------\n",
      " (0.9945958786874661, 0.9381841020778471)\n",
      "------------test------------\n",
      " (0.6575571840994893, 0.2554075061070398)\n",
      "------------oot------------\n",
      " (0.6328502415458936, 0.21618183713898442)\n",
      "隐藏层vs神经元数vs norm 1 28 0.001\n",
      "验证集最优结果： 0.4982270300388336 0.9387866258621216\n",
      "------------train------------\n",
      " (0.9716538108300358, 0.8227023449127231)\n",
      "------------test------------\n",
      " (0.6854696868754163, 0.285498556517877)\n",
      "------------oot------------\n",
      " (0.64003985217623, 0.2260869565217391)\n",
      "隐藏层vs神经元数vs norm 1 28 0.01\n",
      "验证集最优结果： 0.9202648997306824 0.9483973979949951\n",
      "------------train------------\n",
      " (0.7772695001620937, 0.421544879695223)\n",
      "------------test------------\n",
      " (0.7065312014212747, 0.31195869420386413)\n",
      "------------oot------------\n",
      " (0.6887313337735609, 0.30322177040975906)\n",
      "隐藏层vs神经元数vs norm 1 28 0.02\n",
      "验证集最优结果： 1.223129391670227 1.2414097785949707\n",
      "------------train------------\n",
      " (0.7689284682164058, 0.4012141811485178)\n",
      "------------test------------\n",
      " (0.7094026204752387, 0.3421274705751721)\n",
      "------------oot------------\n",
      " (0.7108168537633661, 0.3341396448058944)\n",
      "隐藏层vs神经元数vs norm 1 28 0.05\n",
      "验证集最优结果： 2.1031856536865234 2.119886636734009\n",
      "------------train------------\n",
      " (0.7643347485244044, 0.405722759263884)\n",
      "------------test------------\n",
      " (0.7166067066400177, 0.35033311125916056)\n",
      "------------oot------------\n",
      " (0.6978996512934579, 0.3028881242831821)\n",
      "隐藏层vs神经元数vs norm 1 28 0.1\n",
      "验证集最优结果： 3.519679546356201 3.509082555770874\n",
      "------------train------------\n",
      " (0.7655937339048242, 0.39822393858977667)\n",
      "------------test------------\n",
      " (0.7143793026870975, 0.32928047968021323)\n",
      "------------oot------------\n",
      " (0.7050799939758339, 0.31197998123240533)\n",
      "隐藏层vs神经元数vs norm 1 28 0.2\n",
      "验证集最优结果： 6.838829040527344 6.828797340393066\n",
      "------------train------------\n",
      " (0.7622632634400852, 0.3935253147294251)\n",
      "------------test------------\n",
      " (0.7168087941372419, 0.340262047523873)\n",
      "------------oot------------\n",
      " (0.6953996223311206, 0.3079831786744518)\n",
      "隐藏层vs神经元数vs norm 1 28 0.3\n",
      "验证集最优结果： 9.897473335266113 9.881547927856445\n",
      "------------train------------\n",
      " (0.7626740816993662, 0.38806989189456254)\n",
      "------------test------------\n",
      " (0.7068243393293361, 0.30356429047301803)\n",
      "------------oot------------\n",
      " (0.6952142633719112, 0.3087199805373093)\n",
      "隐藏层vs神经元数vs norm 1 28 0.4\n",
      "验证集最优结果： 12.924644470214844 12.899895668029785\n",
      "------------train------------\n",
      " (0.7495837334919756, 0.36913529862832717)\n",
      "------------test------------\n",
      " (0.6941272485009993, 0.28294470353097934)\n",
      "------------oot------------\n",
      " (0.6894449657665173, 0.2848573315260835)\n",
      "隐藏层vs神经元数vs norm 1 28 0.5\n",
      "验证集最优结果： 15.825020790100098 15.801490783691406\n",
      "------------train------------\n",
      " (0.7625971294158733, 0.38091109608612705)\n",
      "------------test------------\n",
      " (0.7056606706640018, 0.3275705085498557)\n",
      "------------oot------------\n",
      " (0.7189494780986805, 0.3469363639523164)\n",
      "隐藏层vs神经元数vs norm 1 28 0.6\n",
      "验证集最优结果： 17.913576126098633 17.876745223999023\n",
      "------------train------------\n",
      " (0.7119291605839169, 0.3027171533204876)\n",
      "------------test------------\n",
      " (0.6635876082611591, 0.24901176993115698)\n",
      "------------oot------------\n",
      " (0.6657410303641146, 0.25033885934730477)\n",
      "隐藏层vs神经元数vs norm 1 28 0.8\n",
      "验证集最优结果： 25.144643783569336 25.061866760253906\n",
      "------------train------------\n",
      " (0.6979090230444002, 0.2919702288738233)\n",
      "------------test------------\n",
      " (0.6532789251610037, 0.2632467244059516)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.6417451546009569, 0.22300768081187225)\n",
      "隐藏层vs神经元数vs norm 1 30 0.0001\n",
      "验证集最优结果： 0.4828854501247406 1.5520087480545044\n",
      "------------train------------\n",
      " (0.98952271310605, 0.9117398593201262)\n",
      "------------test------------\n",
      " (0.6381390184321564, 0.2203642016433489)\n",
      "------------oot------------\n",
      " (0.6148472526326765, 0.187536926980155)\n",
      "隐藏层vs神经元数vs norm 1 30 0.001\n",
      "验证集最优结果： 0.40136945247650146 0.9840251207351685\n",
      "------------train------------\n",
      " (0.988271984698881, 0.8921490397207789)\n",
      "------------test------------\n",
      " (0.632964690206529, 0.22532755940484123)\n",
      "------------oot------------\n",
      " (0.5946628204682631, 0.15927431967469496)\n",
      "隐藏层vs神经元数vs norm 1 30 0.01\n",
      "验证集最优结果： 0.9396105408668518 0.9713160991668701\n",
      "------------train------------\n",
      " (0.7751660023864007, 0.4170127489020594)\n",
      "------------test------------\n",
      " (0.7044614701310237, 0.3095936042638242)\n",
      "------------oot------------\n",
      " (0.6875543043825809, 0.29573558544468775)\n",
      "隐藏层vs神经元数vs norm 1 30 0.02\n",
      "验证集最优结果： 1.2637174129486084 1.2826824188232422\n",
      "------------train------------\n",
      " (0.7642716029830685, 0.4116933630855091)\n",
      "------------test------------\n",
      " (0.7103664223850766, 0.3171774372640462)\n",
      "------------oot------------\n",
      " (0.6959974049745711, 0.3236645466235707)\n",
      "隐藏层vs神经元数vs norm 1 30 0.05\n",
      "验证集最优结果： 2.2442901134490967 2.2599685192108154\n",
      "------------train------------\n",
      " (0.7636543603925176, 0.39778063387836127)\n",
      "------------test------------\n",
      " (0.7147679324894515, 0.3451698867421719)\n",
      "------------oot------------\n",
      " (0.7018431631506389, 0.30165085323045904)\n",
      "隐藏层vs神经元数vs norm 1 30 0.1\n",
      "验证集最优结果： 3.9293501377105713 3.9332473278045654\n",
      "------------train------------\n",
      " (0.7669270320445012, 0.39796188120922693)\n",
      "------------test------------\n",
      " (0.7194314901176994, 0.333555407506107)\n",
      "------------oot------------\n",
      " (0.7169174805083469, 0.32528412052966327)\n",
      "隐藏层vs神经元数vs norm 1 30 0.2\n",
      "验证集最优结果： 6.972872257232666 6.968216419219971\n",
      "------------train------------\n",
      " (0.7587321891334171, 0.3889271281502553)\n",
      "------------test------------\n",
      " (0.6979791250277593, 0.31321341328003555)\n",
      "------------oot------------\n",
      " (0.6909000335963114, 0.28995238591735306)\n",
      "隐藏层vs神经元数vs norm 1 30 0.3\n",
      "验证集最优结果： 10.135168075561523 10.128798484802246\n",
      "------------train------------\n",
      " (0.7704983760157937, 0.39943879653938064)\n",
      "------------test------------\n",
      " (0.7101043748612036, 0.3221185876082612)\n",
      "------------oot------------\n",
      " (0.6944705105480833, 0.3076842873527265)\n",
      "隐藏层vs神经元数vs norm 1 30 0.4\n",
      "验证集最优结果： 13.815489768981934 13.793548583984375\n",
      "------------train------------\n",
      " (0.7573447469068499, 0.3805908338121701)\n",
      "------------test------------\n",
      " (0.7099400399733511, 0.32506107039751275)\n",
      "------------oot------------\n",
      " (0.6842873527265144, 0.2921766934278664)\n",
      "隐藏层vs神经元数vs norm 1 30 0.5\n",
      "验证集最优结果： 16.263256072998047 16.218782424926758\n",
      "------------train------------\n",
      " (0.7432341210621176, 0.3637074892777788)\n",
      "------------test------------\n",
      " (0.7079957805907173, 0.3197868087941373)\n",
      "------------oot------------\n",
      " (0.6917480508346945, 0.29150245021374205)\n",
      "隐藏层vs神经元数vs norm 1 30 0.6\n",
      "验证集最优结果： 20.222448348999023 20.18486785888672\n",
      "------------train------------\n",
      " (0.7296670341696564, 0.33803574727976726)\n",
      "------------test------------\n",
      " (0.6956562291805464, 0.2898401065956029)\n",
      "------------oot------------\n",
      " (0.6923782712960067, 0.2809995481875369)\n",
      "隐藏层vs神经元数vs norm 1 30 0.8\n",
      "验证集最优结果： 26.151994705200195 26.087480545043945\n",
      "------------train------------\n",
      " (0.7065481181884201, 0.31222201241388553)\n",
      "------------test------------\n",
      " (0.6914357095269821, 0.29542527204086166)\n",
      "------------oot------------\n",
      " (0.6760898527554768, 0.24916414694331493)\n",
      "隐藏层vs神经元数vs norm 1 32 0.0001\n",
      "验证集最优结果： 0.5025835633277893 1.3136570453643799\n",
      "------------train------------\n",
      " (0.9925962021983853, 0.9253718514367472)\n",
      "------------test------------\n",
      " (0.6660248723073506, 0.27217410615145454)\n",
      "------------oot------------\n",
      " (0.6380124885598767, 0.2056302783859869)\n",
      "隐藏层vs神经元数vs norm 1 32 0.001\n",
      "验证集最优结果： 0.45572978258132935 0.8331591486930847\n",
      "------------train------------\n",
      " (0.9609974423686956, 0.7846439247965705)\n",
      "------------test------------\n",
      " (0.6749278258938485, 0.29937819231623364)\n",
      "------------oot------------\n",
      " (0.6395231640774337, 0.21976158203871687)\n",
      "隐藏层vs神经元数vs norm 1 32 0.01\n",
      "验证集最优结果： 0.963651716709137 0.9971180558204651\n",
      "------------train------------\n",
      " (0.7912053082862787, 0.450295660554476)\n",
      "------------test------------\n",
      " (0.7159782367310681, 0.3402509438152343)\n",
      "------------oot------------\n",
      " (0.702314670003128, 0.3340492823132798)\n",
      "隐藏层vs神经元数vs norm 1 32 0.02\n",
      "验证集最优结果： 1.3124172687530518 1.33479905128479\n",
      "------------train------------\n",
      " (0.7638876537269068, 0.411187928034387)\n",
      "------------test------------\n",
      " (0.7122540528536532, 0.3296802131912059)\n",
      "------------oot------------\n",
      " (0.7039099155458242, 0.32212838424912243)\n",
      "隐藏层vs神经元数vs norm 1 32 0.05\n",
      "验证集最优结果： 2.3380002975463867 2.352327585220337\n",
      "------------train------------\n",
      " (0.763877975471375, 0.39765055270960703)\n",
      "------------test------------\n",
      " (0.718150122140795, 0.3451698867421719)\n",
      "------------oot------------\n",
      " (0.697053951042065, 0.3012198936502972)\n",
      "隐藏层vs神经元数vs norm 1 32 0.1\n",
      "验证集最优结果： 4.030405044555664 4.03244686126709\n",
      "------------train------------\n",
      " (0.7712107768390546, 0.4109071909438601)\n",
      "------------test------------\n",
      " (0.7228914057295137, 0.3527870308683101)\n",
      "------------oot------------\n",
      " (0.7238591735307406, 0.3394640809091857)\n",
      "隐藏层vs神经元数vs norm 1 32 0.2\n",
      "验证集最优结果： 7.655163764953613 7.634016990661621\n",
      "------------train------------\n",
      " (0.7588714071168342, 0.3795357009188928)\n",
      "------------test------------\n",
      " (0.7211481234732401, 0.3338885187652676)\n",
      "------------oot------------\n",
      " (0.7055202215039562, 0.3129322628853439)\n",
      "隐藏层vs神经元数vs norm 1 32 0.3\n",
      "验证集最优结果： 10.936174392700195 10.915013313293457\n",
      "------------train------------\n",
      " (0.7623384560407542, 0.392627741128999)\n",
      "------------test------------\n",
      " (0.721900954918943, 0.32779258272262934)\n",
      "------------oot------------\n",
      " (0.6930281861467348, 0.3016439022694888)\n",
      "隐藏层vs神经元数vs norm 1 32 0.4\n",
      "验证集最优结果： 13.990636825561523 13.961005210876465\n",
      "------------train------------\n",
      " (0.7647511842327005, 0.39565047013987453)\n",
      "------------test------------\n",
      " (0.7343548745280923, 0.3522651565622918)\n",
      "------------oot------------\n",
      " (0.7128430588862242, 0.3099155458242102)\n",
      "隐藏层vs神经元数vs norm 1 32 0.5\n",
      "验证集最优结果： 17.94339942932129 17.862207412719727\n",
      "------------train------------\n",
      " (0.7311274355533086, 0.3300512541462526)\n",
      "------------test------------\n",
      " (0.6895336442371752, 0.2893848545414168)\n",
      "------------oot------------\n",
      " (0.6485988021177261, 0.2451951482292427)\n",
      "隐藏层vs神经元数vs norm 1 32 0.6\n",
      "验证集最优结果： 21.65233039855957 21.61788558959961\n",
      "------------train------------\n",
      " (0.7401250999127603, 0.35326864468552094)\n",
      "------------test------------\n",
      " (0.7000233177881413, 0.30494115034421493)\n",
      "------------oot------------\n",
      " (0.6698594747390494, 0.27192159316025444)\n",
      "隐藏层vs神经元数vs norm 1 32 0.8\n",
      "验证集最优结果： 28.05331039428711 27.97942352294922\n",
      "------------train------------\n",
      " (0.694020124003495, 0.273757647006272)\n",
      "------------test------------\n",
      " (0.679434821230291, 0.2683988452143016)\n",
      "------------oot------------\n",
      " (0.6845306363604768, 0.2614742988218121)\n",
      "隐藏层vs神经元数vs norm 1 34 0.0001\n",
      "验证集最优结果： 0.24790504574775696 1.5720492601394653\n",
      "------------train------------\n",
      " (0.9999964806343522, 0.9982787594777532)\n",
      "------------test------------\n",
      " (0.6850943815234288, 0.3036309127248501)\n",
      "------------oot------------\n",
      " (0.6541167066346922, 0.25001216418169814)\n",
      "隐藏层vs神经元数vs norm 1 34 0.001\n",
      "验证集最优结果： 0.5144572257995605 1.050032138824463\n",
      "------------train------------\n",
      " (0.9664303954074984, 0.8058958849817162)\n",
      "------------test------------\n",
      " (0.7034465911614479, 0.3372418387741506)\n",
      "------------oot------------\n",
      " (0.6753206130747575, 0.27778820421923334)\n",
      "隐藏层vs神经元数vs norm 1 34 0.01\n",
      "验证集最优结果： 0.9802599549293518 1.0075479745864868\n",
      "------------train------------\n",
      " (0.7750076986123546, 0.4210847903168715)\n",
      "------------test------------\n",
      " (0.7116588940706196, 0.31727737064179434)\n",
      "------------oot------------\n",
      " (0.6901029900717108, 0.30297848677579675)\n",
      "隐藏层vs神经元数vs norm 1 34 0.02\n",
      "验证集最优结果： 1.378697156906128 1.4085968732833862\n",
      "------------train------------\n",
      " (0.7620560269475121, 0.39149856619689904)\n",
      "------------test------------\n",
      " (0.6901154785698423, 0.31834332667110815)\n",
      "------------oot------------\n",
      " (0.6863425201867491, 0.3024780175859312)\n",
      "隐藏层vs神经元数vs norm 1 34 0.05\n",
      "验证集最优结果： 2.4490113258361816 2.4677319526672363\n",
      "------------train------------\n",
      " (0.766694077110655, 0.4091721436794562)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.719888962913613, 0.3504330446369087)\n",
      "------------oot------------\n",
      " (0.6997323880026414, 0.2961109373370869)\n",
      "隐藏层vs神经元数vs norm 1 34 0.1\n",
      "验证集最优结果： 4.3373260498046875 4.340127944946289\n",
      "------------train------------\n",
      " (0.759323374882152, 0.38423730270402334)\n",
      "------------test------------\n",
      " (0.7157117477237398, 0.31987563846324674)\n",
      "------------oot------------\n",
      " (0.7100429801086667, 0.31364126090432)\n",
      "隐藏层vs神经元数vs norm 1 34 0.2\n",
      "验证集最优结果： 8.124716758728027 8.117386817932129\n",
      "------------train------------\n",
      " (0.7608813709824241, 0.3817889070948381)\n",
      "------------test------------\n",
      " (0.7049156118143459, 0.3089940039973351)\n",
      "------------oot------------\n",
      " (0.6915916542128616, 0.3234907725993119)\n",
      "隐藏层vs神经元数vs norm 1 34 0.3\n",
      "验证集最优结果： 11.78317928314209 11.758410453796387\n",
      "------------train------------\n",
      " (0.7486548240012616, 0.36909387840185603)\n",
      "------------test------------\n",
      " (0.6937941372418388, 0.30200977126360207)\n",
      "------------oot------------\n",
      " (0.673679027792259, 0.2522920793799742)\n",
      "隐藏层vs神经元数vs norm 1 34 0.4\n",
      "验证集最优结果： 14.779671669006348 14.736550331115723\n",
      "------------train------------\n",
      " (0.7356119195500085, 0.34162401127821335)\n",
      "------------test------------\n",
      " (0.7146135909393737, 0.32126360204308235)\n",
      "------------oot------------\n",
      " (0.682490529315678, 0.2674521252563167)\n",
      "隐藏层vs神经元数vs norm 1 34 0.5\n",
      "验证集最优结果： 18.68919563293457 18.667381286621094\n",
      "------------train------------\n",
      " (0.7581123070186303, 0.3765669806346905)\n",
      "------------test------------\n",
      " (0.7105196535642906, 0.32583833000222073)\n",
      "------------oot------------\n",
      " (0.7047139100313952, 0.3027143502589233)\n",
      "隐藏层vs神经元数vs norm 1 34 0.6\n",
      "验证集最优结果： 22.814531326293945 22.77139663696289\n",
      "------------train------------\n",
      " (0.7496834262919625, 0.3748655027041587)\n",
      "------------test------------\n",
      " (0.7062780368643127, 0.32606040417499443)\n",
      "------------oot------------\n",
      " (0.6982796371598372, 0.30517499044242863)\n",
      "隐藏层vs神经元数vs norm 1 34 0.8\n",
      "验证集最优结果： 29.76917266845703 29.68423843383789\n",
      "------------train------------\n",
      " (0.7304219381011263, 0.3404653278187581)\n",
      "------------test------------\n",
      " (0.7078159005107707, 0.3154230512991339)\n",
      "------------oot------------\n",
      " (0.6993245982923806, 0.30044138602161746)\n",
      "隐藏层vs神经元数vs norm 1 36 0.0001\n",
      "验证集最优结果： 0.8021767139434814 1.6467831134796143\n",
      "------------train------------\n",
      " (0.9297400610068498, 0.71930473578024)\n",
      "------------test------------\n",
      " (0.6759116144792361, 0.2807017543859649)\n",
      "------------oot------------\n",
      " (0.6225581853357893, 0.22507906718103776)\n",
      "隐藏层vs神经元数vs norm 1 36 0.001\n",
      "验证集最优结果： 0.4972757399082184 0.9067801237106323\n",
      "------------train------------\n",
      " (0.9739158154201005, 0.8410596268524893)\n",
      "------------test------------\n",
      " (0.6883888518765268, 0.30168776371308015)\n",
      "------------oot------------\n",
      " (0.6354452669748258, 0.2220832030028152)\n",
      "隐藏层vs神经元数vs norm 1 36 0.01\n",
      "验证集最优结果： 1.0096718072891235 1.0379726886749268\n",
      "------------train------------\n",
      " (0.7766259976894011, 0.42913330883313405)\n",
      "------------test------------\n",
      " (0.7087808127914723, 0.3192094159449256)\n",
      "------------oot------------\n",
      " (0.6973343064678692, 0.32806450491780487)\n",
      "隐藏层vs神经元数vs norm 1 36 0.02\n",
      "验证集最优结果： 1.4055129289627075 1.431349754333496\n",
      "------------train------------\n",
      " (0.7496051204062972, 0.38473190893776743)\n",
      "------------test------------\n",
      " (0.7031978680879414, 0.30489673550966023)\n",
      "------------oot------------\n",
      " (0.6899292160474519, 0.3059813019149898)\n",
      "隐藏层vs神经元数vs norm 1 36 0.05\n",
      "验证集最优结果： 2.5791404247283936 2.5914549827575684\n",
      "------------train------------\n",
      " (0.7631333589164144, 0.3939016161333136)\n",
      "------------test------------\n",
      " (0.712651565622918, 0.32215189873417727)\n",
      "------------oot------------\n",
      " (0.7067296887127978, 0.33494595627845547)\n",
      "隐藏层vs神经元数vs norm 1 36 0.1\n",
      "验证集最优结果： 4.602356910705566 4.609437465667725\n",
      "------------train------------\n",
      " (0.763439679087997, 0.3906168297418884)\n",
      "------------test------------\n",
      " (0.7147057517210749, 0.3285587386186986)\n",
      "------------oot------------\n",
      " (0.7161806786454894, 0.3139332012650749)\n",
      "隐藏层vs神经元数vs norm 1 36 0.2\n",
      "验证集最优结果： 8.565850257873535 8.565558433532715\n",
      "------------train------------\n",
      " (0.7622908769243992, 0.39818062332026427)\n",
      "------------test------------\n",
      " (0.7140750610703975, 0.3336220297579391)\n",
      "------------oot------------\n",
      " (0.7007773491351845, 0.33322211795780765)\n",
      "隐藏层vs神经元数vs norm 1 36 0.3\n",
      "验证集最优结果： 12.50996208190918 12.497060775756836\n",
      "------------train------------\n",
      " (0.7583555493289855, 0.390648368672502)\n",
      "------------test------------\n",
      " (0.7149045081057073, 0.346435709526982)\n",
      "------------oot------------\n",
      " (0.7096421413593763, 0.30789281618183717)\n",
      "隐藏层vs神经元数vs norm 1 36 0.4\n",
      "验证集最优结果： 15.844171524047852 15.828845024108887\n",
      "------------train------------\n",
      " (0.7638681618556261, 0.3893842396038277)\n",
      "------------test------------\n",
      " (0.7160659560293138, 0.3287808127914724)\n",
      "------------oot------------\n",
      " (0.7203257683708106, 0.3535814826399749)\n",
      "隐藏层vs神经元数vs norm 1 36 0.5\n",
      "验证集最优结果： 20.214948654174805 20.172809600830078\n",
      "------------train------------\n",
      " (0.7429447209176882, 0.35953392770004716)\n",
      "------------test------------\n",
      " (0.7027614923384411, 0.32426160337552745)\n",
      "------------oot------------\n",
      " (0.7058839884614048, 0.30867132381051676)\n",
      "隐藏层vs神经元数vs norm 1 36 0.6\n",
      "验证集最优结果： 23.480512619018555 23.459823608398438\n",
      "------------train------------\n",
      " (0.7658493616750557, 0.3921764501647672)\n",
      "------------test------------\n",
      " (0.7062680435265378, 0.32328447701532315)\n",
      "------------oot------------\n",
      " (0.6977478886456052, 0.32138463142529455)\n",
      "隐藏层vs神经元数vs norm 1 36 0.8\n",
      "验证集最优结果： 31.703542709350586 31.675491333007812\n",
      "------------train------------\n",
      " (0.7135285769106601, 0.31979270936334)\n",
      "------------test------------\n",
      " (0.6604952254052854, 0.27279591383522095)\n",
      "------------oot------------\n",
      " (0.670422502577648, 0.27538317172349075)\n",
      "隐藏层vs神经元数vs norm 1 38 0.0001\n",
      "验证集最优结果： 0.4003935754299164 1.270282506942749\n",
      "------------train------------\n",
      " (0.9994241776359203, 0.9838339292566897)\n",
      "------------test------------\n",
      " (0.693539862314013, 0.31015989340439704)\n",
      "------------oot------------\n",
      " (0.6339380669377541, 0.20462934000625588)\n",
      "隐藏层vs神经元数vs norm 1 38 0.001\n",
      "验证集最优结果： 0.48363548517227173 0.9025070071220398\n",
      "------------train------------\n",
      " (0.9516315982183887, 0.7597406227517515)\n",
      "------------test------------\n",
      " (0.6604241616699978, 0.25013324450366425)\n",
      "------------oot------------\n",
      " (0.6385616144765347, 0.22443262781079487)\n",
      "隐藏层vs神经元数vs norm 1 38 0.01\n",
      "验证集最优结果： 1.0463676452636719 1.078167200088501\n",
      "------------train------------\n",
      " (0.7636487429435027, 0.39936191193599624)\n",
      "------------test------------\n",
      " (0.6857028647568288, 0.2977903619809016)\n",
      "------------oot------------\n",
      " (0.6710666249609007, 0.26223195356758067)\n",
      "隐藏层vs神经元数vs norm 1 38 0.02\n",
      "验证集最优结果： 1.4508535861968994 1.4771720170974731\n",
      "------------train------------\n",
      " (0.7608275652960768, 0.39507600137796695)\n",
      "------------test------------\n",
      " (0.6986453475460803, 0.31889851210304243)\n",
      "------------oot------------\n",
      " (0.6994844703946987, 0.31521217808362)\n",
      "隐藏层vs神经元数vs norm 1 38 0.05\n",
      "验证集最优结果： 2.6435446739196777 2.646958589553833\n",
      "------------train------------\n",
      " (0.7887718699810969, 0.42428890201882996)\n",
      "------------test------------\n",
      " (0.7230546302465023, 0.3430601821008217)\n",
      "------------oot------------\n",
      " (0.7148217657757852, 0.30864351996663536)\n",
      "隐藏层vs神经元数vs norm 1 38 0.1\n",
      "验证集最优结果： 4.643612384796143 4.653883934020996\n",
      "------------train------------\n",
      " (0.7748006651601075, 0.4235085503665217)\n",
      "------------test------------\n",
      " (0.7119098378858539, 0.34250499666888745)\n",
      "------------oot------------\n",
      " (0.6973980236100974, 0.30998505543391375)\n",
      "隐藏层vs神经元数vs norm 1 38 0.2\n",
      "验证集最优结果： 8.978939056396484 8.949652671813965\n",
      "------------train------------\n",
      " (0.7742465681108925, 0.41174561212935834)\n",
      "------------test------------\n",
      " (0.715953808572063, 0.33243393293359985)\n",
      "------------oot------------\n",
      " (0.7029865962302622, 0.3062176345879818)\n",
      "隐藏层vs神经元数vs norm 1 38 0.3\n",
      "验证集最优结果： 13.095949172973633 13.051168441772461\n",
      "------------train------------\n",
      " (0.7646994089496115, 0.3924967124387241)\n",
      "------------test------------\n",
      " (0.7099333777481679, 0.3351321341328004)\n",
      "------------oot------------\n",
      " (0.7068640739582247, 0.32235081500017376)\n",
      "隐藏层vs神经元数vs norm 1 38 0.4\n",
      "验证集最优结果： 17.170936584472656 17.11035919189453\n",
      "------------train------------\n",
      " (0.7488757995558831, 0.3701540196231707)\n",
      "------------test------------\n",
      " (0.7167110815012213, 0.3383966244725738)\n",
      "------------oot------------\n",
      " (0.7041531991797867, 0.3114795120425399)\n",
      "隐藏层vs神经元数vs norm 1 38 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集最优结果： 20.62864112854004 20.595569610595703\n",
      "------------train------------\n",
      " (0.7434071790998411, 0.3721176902944694)\n",
      "------------test------------\n",
      " (0.6952487230735066, 0.30699533644237176)\n",
      "------------oot------------\n",
      " (0.6793544874245531, 0.30238765509331667)\n",
      "隐藏层vs神经元数vs norm 1 38 0.6\n",
      "验证集最优结果： 25.401641845703125 25.352752685546875\n",
      "------------train------------\n",
      " (0.7054521065095405, 0.3037349267938106)\n",
      "------------test------------\n",
      " (0.6653741949811236, 0.2508882966910948)\n",
      "------------oot------------\n",
      " (0.6447862000254868, 0.23253744830222778)\n",
      "隐藏层vs神经元数vs norm 1 38 0.8\n",
      "验证集最优结果： 33.29423904418945 33.21355438232422\n",
      "------------train------------\n",
      " (0.7053402989701119, 0.310345243002046)\n",
      "------------test------------\n",
      " (0.664721296913169, 0.26998667554963357)\n",
      "------------oot------------\n",
      " (0.663630255216117, 0.2518819726827234)\n",
      "隐藏层vs神经元数vs norm 1 40 0.0001\n",
      "验证集最优结果： 0.24897126853466034 1.638844609260559\n",
      "------------train------------\n",
      " (0.9999768534028542, 0.9956668487261588)\n",
      "------------test------------\n",
      " (0.6704186098156785, 0.2788141239173884)\n",
      "------------oot------------\n",
      " (0.6383739385303351, 0.2169394918847531)\n",
      "隐藏层vs神经元数vs norm 1 40 0.001\n",
      "验证集最优结果： 0.5108081698417664 0.9220791459083557\n",
      "------------train------------\n",
      " (0.9526699464447299, 0.781361980969707)\n",
      "------------test------------\n",
      " (0.6869775705085499, 0.3044858982900289)\n",
      "------------oot------------\n",
      " (0.6334966809161366, 0.2455913530045529)\n",
      "隐藏层vs神经元数vs norm 1 40 0.01\n",
      "验证集最优结果： 1.0712958574295044 1.099135398864746\n",
      "------------train------------\n",
      " (0.7582583606930172, 0.40044574119532544)\n",
      "------------test------------\n",
      " (0.7002775927159671, 0.3047190761714412)\n",
      "------------oot------------\n",
      " (0.6880223357545847, 0.3051541375595176)\n",
      "隐藏层vs神经元数vs norm 1 40 0.02\n",
      "验证集最优结果： 1.5165109634399414 1.5464487075805664\n",
      "------------train------------\n",
      " (0.7557363968057695, 0.3907153719800289)\n",
      "------------test------------\n",
      " (0.6862958027981346, 0.29739062846990894)\n",
      "------------oot------------\n",
      " (0.679846847159953, 0.2811316164459736)\n",
      "隐藏层vs神经元数vs norm 1 40 0.05\n",
      "验证集最优结果： 2.8100783824920654 2.8263137340545654\n",
      "------------train------------\n",
      " (0.7612512427759944, 0.38452602604736663)\n",
      "------------test------------\n",
      " (0.7139085054408172, 0.3251276926493449)\n",
      "------------oot------------\n",
      " (0.6945909938715694, 0.3054599798422132)\n",
      "隐藏层vs神经元数vs norm 1 40 0.1\n",
      "验证集最优结果： 4.893742561340332 4.897235870361328\n",
      "------------train------------\n",
      " (0.7704813206284233, 0.4128421652491068)\n",
      "------------test------------\n",
      " (0.7191450144348213, 0.34166111481234734)\n",
      "------------oot------------\n",
      " (0.7042227087894901, 0.2890209571473257)\n",
      "隐藏层vs神经元数vs norm 1 40 0.2\n",
      "验证集最优结果： 9.166533470153809 9.160083770751953\n",
      "------------train------------\n",
      " (0.7621174804861327, 0.3885999625052198)\n",
      "------------test------------\n",
      " (0.7161381301354651, 0.33428825227626036)\n",
      "------------oot------------\n",
      " (0.7045123321632549, 0.32259409863413624)\n",
      "隐藏层vs神经元数vs norm 1 40 0.3\n",
      "验证集最优结果： 13.579014778137207 13.542123794555664\n",
      "------------train------------\n",
      " (0.7612415645204628, 0.38678613559439035)\n",
      "------------test------------\n",
      " (0.7135376415722852, 0.33461025982678216)\n",
      "------------oot------------\n",
      " (0.7102109616654503, 0.33484169186390017)\n",
      "隐藏层vs神经元数vs norm 1 40 0.4\n",
      "验证集最优结果： 18.164005279541016 18.13788604736328\n",
      "------------train------------\n",
      " (0.7403255007143635, 0.34452071992685135)\n",
      "------------test------------\n",
      " (0.6952775927159671, 0.28881856540084394)\n",
      "------------oot------------\n",
      " (0.69362017632271, 0.3064470163000034)\n",
      "隐藏层vs神经元数vs norm 1 40 0.5\n",
      "验证集最优结果： 21.72096824645996 21.695730209350586\n",
      "------------train------------\n",
      " (0.7580376558588301, 0.38840490843219705)\n",
      "------------test------------\n",
      " (0.7220219853431046, 0.3397623806351321)\n",
      "------------oot------------\n",
      " (0.7122557026842294, 0.3211761025961839)\n",
      "隐藏层vs神经元数vs norm 1 40 0.6\n",
      "验证集最优结果： 25.59823989868164 25.553966522216797\n",
      "------------train------------\n",
      " (0.7408090750904037, 0.3413815811291614)\n",
      "------------test------------\n",
      " (0.6710859427048634, 0.26226959804574734)\n",
      "------------oot------------\n",
      " (0.6613236946674544, 0.2327042713655163)\n",
      "隐藏层vs神经元数vs norm 1 40 0.8\n",
      "验证集最优结果： 35.00260543823242 34.91251754760742\n",
      "------------train------------\n",
      " (0.7187159865154151, 0.3242805773654706)\n",
      "------------test------------\n",
      " (0.6777259604707973, 0.27868087941372416)\n",
      "------------oot------------\n",
      " (0.6624022521113544, 0.25513502241684916)\n",
      "隐藏层vs神经元数vs norm 1 42 0.0001\n",
      "验证集最优结果： 0.22607126832008362 1.4060962200164795\n",
      "------------train------------\n",
      " (0.9999964806343521, 0.9984413270986418)\n",
      "------------test------------\n",
      " (0.6728536531201421, 0.2849433710859427)\n",
      "------------oot------------\n",
      " (0.628852280494445, 0.212914885482918)\n",
      "隐藏层vs神经元数vs norm 1 42 0.001\n",
      "验证集最优结果： 0.48813876509666443 0.8944460153579712\n",
      "------------train------------\n",
      " (0.9692957004857402, 0.8199455987286969)\n",
      "------------test------------\n",
      " (0.6962358427714856, 0.31862091938707526)\n",
      "------------oot------------\n",
      " (0.6545696775912604, 0.25532269836304866)\n",
      "隐藏层vs神经元数vs norm 1 42 0.01\n",
      "验证集最优结果： 1.0936633348464966 1.1230214834213257\n",
      "------------train------------\n",
      " (0.7618378939574522, 0.400277217724879)\n",
      "------------test------------\n",
      " (0.6970242060848324, 0.29125027759271604)\n",
      "------------oot------------\n",
      " (0.6883559818811618, 0.3115907274180655)\n",
      "隐藏层vs神经元数vs norm 1 42 0.02\n",
      "验证集最优结果： 1.5442931652069092 1.5721884965896606\n",
      "------------train------------\n",
      " (0.7611686730434865, 0.3929409646716601)\n",
      "------------test------------\n",
      " (0.695836109260493, 0.32465023317788144)\n",
      "------------oot------------\n",
      " (0.6954343771359723, 0.3179021999791471)\n",
      "隐藏层vs神经元数vs norm 1 42 0.05\n",
      "验证集最优结果： 2.885969877243042 2.902066946029663\n",
      "------------train------------\n",
      " (0.7727614634875966, 0.4109898960365852)\n",
      "------------test------------\n",
      " (0.708285587386187, 0.30701754385964913)\n",
      "------------oot------------\n",
      " (0.6986179172603947, 0.2857053487644667)\n",
      "隐藏层vs神经元数vs norm 1 42 0.1\n",
      "验证集最优结果： 5.262038230895996 5.271655559539795\n",
      "------------train------------\n",
      " (0.7759745766440005, 0.40975838878026233)\n",
      "------------test------------\n",
      " (0.7114234954474794, 0.33829669109482563)\n",
      "------------oot------------\n",
      " (0.7148704225025777, 0.3294755499947868)\n",
      "隐藏层vs神经元数vs norm 1 42 0.2\n",
      "验证集最优结果： 9.467229843139648 9.463563919067383\n",
      "------------train------------\n",
      " (0.7762430636348685, 0.42387997880259)\n",
      "------------test------------\n",
      " (0.7259138352209638, 0.34481456806573396)\n",
      "------------oot------------\n",
      " (0.7133400525956046, 0.3386230146317728)\n",
      "隐藏层vs神经元数vs norm 1 42 0.3\n",
      "验证集最优结果： 13.97750473022461 13.963573455810547\n",
      "------------train------------\n",
      " (0.7586999734017175, 0.37330087395324246)\n",
      "------------test------------\n",
      " (0.7112547190761713, 0.32129691316899844)\n",
      "------------oot------------\n",
      " (0.7106859439984243, 0.3104090640531053)\n",
      "隐藏层vs神经元数vs norm 1 42 0.4\n",
      "验证集最优结果： 18.837100982666016 18.80058479309082\n",
      "------------train------------\n",
      " (0.7572455278676231, 0.37519754131701427)\n",
      "------------test------------\n",
      " (0.7181012658227848, 0.331157006440151)\n",
      "------------oot------------\n",
      " (0.711776086377275, 0.313189448441247)\n",
      "隐藏层vs神经元数vs norm 1 42 0.5\n",
      "验证集最优结果： 22.754018783569336 22.72662353515625\n",
      "------------train------------\n",
      " (0.7699217414904107, 0.3958869444393684)\n",
      "------------test------------\n",
      " (0.7117199644681322, 0.31850988230068844)\n",
      "------------oot------------\n",
      " (0.7021420544723641, 0.3344107322837382)\n",
      "隐藏层vs神经元数vs norm 1 42 0.6\n",
      "验证集最优结果： 28.018142700195312 27.898704528808594\n",
      "------------train------------\n",
      " (0.7563648742943503, 0.3842599078603002)\n",
      "------------test------------\n",
      " (0.7081656673328891, 0.33618698645347544)\n",
      "------------oot------------\n",
      " (0.7026529501036852, 0.2994613005247975)\n",
      "隐藏层vs神经元数vs norm 1 42 0.8\n",
      "验证集最优结果： 36.70883560180664 36.70957946777344\n",
      "------------train------------\n",
      " (0.6614978690917803, 0.26392589298827307)\n",
      "------------test------------\n",
      " (0.6478392182989118, 0.26010437486120364)\n",
      "------------oot------------\n",
      " (0.6104484528319374, 0.22295207312410942)\n",
      "隐藏层vs神经元数vs norm 1 44 0.0001\n",
      "验证集最优结果： 0.6682801842689514 1.866370677947998\n",
      "------------train------------\n",
      " (0.9892124674881679, 0.8960013915030332)\n",
      "------------test------------\n",
      " (0.6604952254052854, 0.27154119475904953)\n",
      "------------oot------------\n",
      " (0.6067424321412435, 0.19196468911827058)\n",
      "隐藏层vs神经元数vs norm 1 44 0.001\n",
      "验证集最优结果： 0.5679897665977478 1.0599685907363892\n",
      "------------train------------\n",
      " (0.9612968591691996, 0.8045361915996803)\n",
      "------------test------------\n",
      " (0.6946080390850543, 0.31022651565622916)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.6682167309630556, 0.2597435095401939)\n",
      "隐藏层vs神经元数vs norm 1 44 0.01\n",
      "验证集最优结果： 1.1222336292266846 1.1549625396728516\n",
      "------------train------------\n",
      " (0.7662923956660366, 0.4114451124471164)\n",
      "------------test------------\n",
      " (0.6890051077059738, 0.31714412613813014)\n",
      "------------oot------------\n",
      " (0.6766806844379568, 0.29975324088555244)\n",
      "隐藏层vs神经元数vs norm 1 44 0.02\n",
      "验证集最优结果： 1.5756944417953491 1.6001496315002441\n",
      "------------train------------\n",
      " (0.7640948225393712, 0.4017274670922392)\n",
      "------------test------------\n",
      " (0.7022940262047523, 0.3164334887852543)\n",
      "------------oot------------\n",
      " (0.6999756716366038, 0.31374552531887534)\n",
      "隐藏层vs神经元数vs norm 1 44 0.05\n",
      "验证集最优结果： 2.9826786518096924 2.997689723968506\n",
      "------------train------------\n",
      " (0.7767124928682085, 0.4120785982637345)\n",
      "------------test------------\n",
      " (0.7124139462580502, 0.3345769487008661)\n",
      "------------oot------------\n",
      " (0.7085705348764466, 0.30473707990129634)\n",
      "隐藏层vs神经元数vs norm 1 44 0.1\n",
      "验证集最优结果： 5.512345314025879 5.5224928855896\n",
      "------------train------------\n",
      " (0.7668267301235365, 0.41088052498106653)\n",
      "------------test------------\n",
      " (0.7192960248723074, 0.33618698645347544)\n",
      "------------oot------------\n",
      " (0.7042145993350247, 0.33014979320891114)\n",
      "隐藏层vs神经元数vs norm 1 44 0.2\n",
      "验证集最优结果： 10.357698440551758 10.33153247833252\n",
      "------------train------------\n",
      " (0.7637654234507516, 0.38627772261848925)\n",
      "------------test------------\n",
      " (0.7147568287808128, 0.3247168554297135)\n",
      "------------oot------------\n",
      " (0.7038543078580614, 0.2948667153233935)\n",
      "隐藏层vs神经元数vs norm 1 44 0.3\n",
      "验证集最优结果： 15.054033279418945 15.026129722595215\n",
      "------------train------------\n",
      " (0.765750481036372, 0.39595096982211636)\n",
      "------------test------------\n",
      " (0.7172784810126582, 0.3374861203642016)\n",
      "------------oot------------\n",
      " (0.7095494618797717, 0.3247697494178571)\n",
      "隐藏层vs神经元数vs norm 1 44 0.4\n",
      "验证集最优结果： 18.704608917236328 18.687517166137695\n",
      "------------train------------\n",
      " (0.7358701868444758, 0.3447167215213947)\n",
      "------------test------------\n",
      " (0.6913790806129247, 0.3265600710637353)\n",
      "------------oot------------\n",
      " (0.6802337839873029, 0.28648385639314633)\n",
      "隐藏层vs神经元数vs norm 1 44 0.5\n",
      "验证集最优结果： 24.648962020874023 24.656204223632812\n",
      "------------train------------\n",
      " (0.7394919524966854, 0.3478034759150181)\n",
      "------------test------------\n",
      " (0.7079602487230736, 0.341672218520986)\n",
      "------------oot------------\n",
      " (0.6838506006788772, 0.2802766482466201)\n",
      "隐藏层vs神经元数vs norm 1 44 0.6\n",
      "验证集最优结果： 29.031984329223633 28.99751091003418\n",
      "------------train------------\n",
      " (0.7310461517428644, 0.34595215422401715)\n",
      "------------test------------\n",
      " (0.6979491450144348, 0.32085276482345104)\n",
      "------------oot------------\n",
      " (0.6808547365006545, 0.2997810447294339)\n",
      "隐藏层vs神经元数vs norm 1 44 0.8\n",
      "验证集最优结果： 38.52525329589844 38.43001174926758\n",
      "------------train------------\n",
      " (0.6754122903016435, 0.280404239752724)\n",
      "------------test------------\n",
      " (0.625659560293138, 0.2359982234066178)\n",
      "------------oot------------\n",
      " (0.6393042088068677, 0.21164285962534318)\n",
      "隐藏层vs神经元数vs norm 1 46 0.0001\n",
      "验证集最优结果： 0.2555497884750366 1.4350457191467285\n",
      "------------train------------\n",
      " (0.999848531916924, 0.9905031271594185)\n",
      "------------test------------\n",
      " (0.6750111037086387, 0.2856873195647346)\n",
      "------------oot------------\n",
      " (0.6365597377170727, 0.2272616689257289)\n",
      "隐藏层vs神经元数vs norm 1 46 0.001\n",
      "验证集最优结果： 0.5442859530448914 1.0121790170669556\n",
      "------------train------------\n",
      " (0.9717583765978427, 0.8220304167944129)\n",
      "------------test------------\n",
      " (0.6806107039751277, 0.2891072618254497)\n",
      "------------oot------------\n",
      " (0.6417312526790162, 0.2247384700934904)\n",
      "隐藏层vs神经元数vs norm 1 46 0.01\n",
      "验证集最优结果： 1.1429733037948608 1.1742298603057861\n",
      "------------train------------\n",
      " (0.7625709372138401, 0.40404483401114955)\n",
      "------------test------------\n",
      " (0.6990584055074395, 0.29234954474794583)\n",
      "------------oot------------\n",
      " (0.6949617117899883, 0.3125569109929448)\n",
      "隐藏层vs神经元数vs norm 1 46 0.02\n",
      "验证集最优结果： 1.6171354055404663 1.6390058994293213\n",
      "------------train------------\n",
      " (0.7594542682122096, 0.399004290242085)\n",
      "------------test------------\n",
      " (0.7095292027537198, 0.3172440595158783)\n",
      "------------oot------------\n",
      " (0.6973783292206814, 0.3106384457651271)\n",
      "隐藏层vs神经元数vs norm 1 46 0.05\n",
      "验证集最优结果： 3.0717356204986572 3.0874030590057373\n",
      "------------train------------\n",
      " (0.7665822018911177, 0.4020999784100454)\n",
      "------------test------------\n",
      " (0.7202287363979569, 0.3512103042416167)\n",
      "------------oot------------\n",
      " (0.7059372791621775, 0.3079414729086296)\n",
      "隐藏层vs神经元数vs norm 1 46 0.1\n",
      "验证集最优结果： 5.60640287399292 5.600953578948975\n",
      "------------train------------\n",
      " (0.7618018204595615, 0.38674579824965705)\n",
      "------------test------------\n",
      " (0.7174961137019764, 0.32180768376637797)\n",
      "------------oot------------\n",
      " (0.7098020134616945, 0.31919507871963304)\n",
      "隐藏层vs神经元数vs norm 1 46 0.2\n",
      "验证集最优结果： 10.181229591369629 10.16437816619873\n",
      "------------train------------\n",
      " (0.7594579906181833, 0.4036172310849324)\n",
      "------------test------------\n",
      " (0.7181345769487009, 0.33090162114146127)\n",
      "------------oot------------\n",
      " (0.7161065350618057, 0.32921836443888364)\n",
      "隐藏层vs神经元数vs norm 1 46 0.3\n",
      "验证集最优结果： 15.817322731018066 15.78668212890625\n",
      "------------train------------\n",
      " (0.7605939335611446, 0.38572599437307575)\n",
      "------------test------------\n",
      " (0.7086286919831224, 0.3168554297135243)\n",
      "------------oot------------\n",
      " (0.6926146039689987, 0.29919716400792407)\n",
      "隐藏层vs神经元数vs norm 1 46 0.4\n",
      "验证集最优结果： 19.72540283203125 19.711977005004883\n",
      "------------train------------\n",
      " (0.7172357548599394, 0.30014964072014344)\n",
      "------------test------------\n",
      " (0.6855174328225628, 0.2544414834554741)\n",
      "------------oot------------\n",
      " (0.66202110775148, 0.23743092482535713)\n",
      "隐藏层vs神经元数vs norm 1 46 0.5\n",
      "验证集最优结果： 25.252714157104492 25.199743270874023\n",
      "------------train------------\n",
      " (0.7545936858519471, 0.3837012762438081)\n",
      "------------test------------\n",
      " (0.7048967355096603, 0.3149900066622252)\n",
      "------------oot------------\n",
      " (0.7032356723316998, 0.3009766100163348)\n",
      "隐藏层vs神经元数vs norm 1 46 0.6\n",
      "验证集最优结果： 29.079870223999023 29.062376022338867\n",
      "------------train------------\n",
      " (0.7236124393332426, 0.32619781948226073)\n",
      "------------test------------\n",
      " (0.6760604041749944, 0.25690650677326227)\n",
      "------------oot------------\n",
      " (0.6817780558162166, 0.29700761130226255)\n",
      "隐藏层vs神经元数vs norm 1 46 0.8\n",
      "验证集最优结果： 39.966861724853516 39.881568908691406\n",
      "------------train------------\n",
      " (0.6693712314869523, 0.2415794100866373)\n",
      "------------test------------\n",
      " (0.641875416389074, 0.24173884077281815)\n",
      "------------oot------------\n",
      " (0.6368250327274413, 0.19797031939665657)\n",
      "隐藏层vs神经元数vs norm 1 48 0.0001\n",
      "验证集最优结果： 0.2715578079223633 1.5592665672302246\n",
      "------------train------------\n",
      " (0.9999943148708765, 0.9991093297706524)\n",
      "------------test------------\n",
      " (0.6891872085276483, 0.31691094825671773)\n",
      "------------oot------------\n",
      " (0.651601617256919, 0.24411774927883778)\n",
      "隐藏层vs神经元数vs norm 1 48 0.001\n",
      "验证集最优结果： 0.5135946273803711 1.0077857971191406\n",
      "------------train------------\n",
      " (0.9584297944081339, 0.7895288043158252)\n",
      "------------test------------\n",
      " (0.6810148789695758, 0.3078725294248279)\n",
      "------------oot------------\n",
      " (0.6390898875102816, 0.2338581308865951)\n",
      "隐藏层vs神经元数vs norm 1 48 0.01\n",
      "验证集最优结果： 1.1731793880462646 1.2040679454803467\n",
      "------------train------------\n",
      " (0.7578185753472496, 0.39623766276220124)\n",
      "------------test------------\n",
      " (0.6820874972240728, 0.29478125693981794)\n",
      "------------oot------------\n",
      " (0.6656935321308171, 0.26897438570882426)\n",
      "隐藏层vs神经元数vs norm 1 48 0.02\n",
      "验证集最优结果： 1.6479347944259644 1.671378254890442\n",
      "------------train------------\n",
      " (0.764616771536995, 0.40196299387021256)\n",
      "------------test------------\n",
      " (0.7134388185654009, 0.3247945813901843)\n",
      "------------oot------------\n",
      " (0.6999385998447618, 0.3171584471553192)\n",
      "隐藏层vs神经元数vs norm 1 48 0.05\n",
      "验证集最优结果： 3.1853044033050537 3.1960606575012207\n",
      "------------train------------\n",
      " (0.7686384589509988, 0.40082204259921395)\n",
      "------------test------------\n",
      " (0.7219031756606706, 0.3580946035976016)\n",
      "------------oot------------\n",
      " (0.706104102225466, 0.3140722204844819)\n",
      "隐藏层vs神经元数vs norm 1 48 0.1\n",
      "验证集最优结果： 5.8675408363342285 5.868011951446533\n",
      "------------train------------\n",
      " (0.7843396350282463, 0.4265519894906328)\n",
      "------------test------------\n",
      " (0.7252653786364646, 0.35982678214523656)\n",
      "------------oot------------\n",
      " (0.7049734125742884, 0.3306155075939249)\n",
      "隐藏层vs神经元数vs norm 1 48 0.2\n",
      "验证集最优结果： 10.96169376373291 10.955405235290527\n",
      "------------train------------\n",
      " (0.76332144193825, 0.3959233563378022)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.7149755718409948, 0.3301132578281145)\n",
      "------------oot------------\n",
      " (0.7040651536741621, 0.30117818788447503)\n",
      "隐藏层vs神经元数vs norm 1 48 0.3\n",
      "验证集最优结果： 16.2515926361084 16.233543395996094\n",
      "------------train------------\n",
      " (0.766518108828261, 0.3908355718529258)\n",
      "------------test------------\n",
      " (0.7109005107705973, 0.34653564290473016)\n",
      "------------oot------------\n",
      " (0.7074525886537146, 0.3332777256455705)\n",
      "隐藏层vs神经元数vs norm 1 48 0.4\n",
      "验证集最优结果： 20.870248794555664 20.857942581176758\n",
      "------------train------------\n",
      " (0.763998310704489, 0.39879339902364674)\n",
      "------------test------------\n",
      " (0.7029424827892516, 0.3195092160781701)\n",
      "------------oot------------\n",
      " (0.6857331526083481, 0.3019775483960658)\n",
      "隐藏层vs神经元数vs norm 1 48 0.5\n",
      "验证集最优结果： 26.514083862304688 26.44116973876953\n",
      "------------train------------\n",
      " (0.7407947269073777, 0.35061544906767267)\n",
      "------------test------------\n",
      " (0.6984388185654008, 0.30445258716411283)\n",
      "------------oot------------\n",
      " (0.6957587553145889, 0.3024780175859312)\n",
      "隐藏层vs神经元数vs norm 1 48 0.6\n",
      "验证集最优结果： 31.48890495300293 31.429962158203125\n",
      "------------train------------\n",
      " (0.7167889307828761, 0.3072366956134491)\n",
      "------------test------------\n",
      " (0.6840073284477015, 0.28264490339773485)\n",
      "------------oot------------\n",
      " (0.6766690995030062, 0.24966461613318042)\n",
      "隐藏层vs神经元数vs norm 1 48 0.8\n",
      "验证集最优结果： 39.62882614135742 39.582908630371094\n",
      "------------train------------\n",
      " (0.7156002650353054, 0.31699657335610093)\n",
      "------------test------------\n",
      " (0.689720186542305, 0.3001332445036642)\n",
      "------------oot------------\n",
      " (0.6491131732295323, 0.23698606332325442)\n",
      "隐藏层vs神经元数vs norm 1 50 0.0001\n",
      "验证集最优结果： 0.31558963656425476 1.2334520816802979\n",
      "------------train------------\n",
      " (0.9998367555780254, 0.9913336974523177)\n",
      "------------test------------\n",
      " (0.679062846990895, 0.2982567177437264)\n",
      "------------oot------------\n",
      " (0.6349390053174852, 0.21007889340701347)\n",
      "隐藏层vs神经元数vs norm 1 50 0.001\n",
      "验证集最优结果： 0.5387662649154663 1.0374789237976074\n",
      "------------train------------\n",
      " (0.9689218355657618, 0.8181780650121587)\n",
      "------------test------------\n",
      " (0.6906551188096824, 0.3100155451920942)\n",
      "------------oot------------\n",
      " (0.6483508845097834, 0.24606401835053704)\n",
      "隐藏层vs神经元数vs norm 1 50 0.01\n",
      "验证集最优结果： 1.1842951774597168 1.2107352018356323\n",
      "------------train------------\n",
      " (0.7622194067297039, 0.4113327634668188)\n",
      "------------test------------\n",
      " (0.7073306684432601, 0.3174439262713747)\n",
      "------------oot------------\n",
      " (0.6944658765741031, 0.3158864212977444)\n",
      "隐藏层vs神经元数vs norm 1 50 0.02\n",
      "验证集最优结果： 1.7230185270309448 1.7512322664260864\n",
      "------------train------------\n",
      " (0.7559902648931771, 0.3936100502254086)\n",
      "------------test------------\n",
      " (0.6893049078392183, 0.3032978014656896)\n",
      "------------oot------------\n",
      " (0.6823109628239438, 0.29764709971153513)\n",
      "隐藏层vs神经元数vs norm 1 50 0.05\n",
      "验证集最优结果： 3.251680612564087 3.2616398334503174\n",
      "------------train------------\n",
      " (0.7759531220495702, 0.4086814628920117)\n",
      "------------test------------\n",
      " (0.7229957805907172, 0.3493115700644015)\n",
      "------------oot------------\n",
      " (0.7012778183250501, 0.31601848955618117)\n",
      "隐藏层vs神经元数vs norm 1 50 0.1\n",
      "验证集最优结果： 5.831299304962158 5.826332092285156\n",
      "------------train------------\n",
      " (0.7586168622283405, 0.37750597446158773)\n",
      "------------test------------\n",
      " (0.7069331556739952, 0.2980679546968688)\n",
      "------------oot------------\n",
      " (0.6814745305205112, 0.2802488444027387)\n",
      "隐藏层vs神经元数vs norm 1 50 0.2\n",
      "验证集最优结果： 11.464159965515137 11.458135604858398\n",
      "------------train------------\n",
      " (0.7770209111231582, 0.41399990118704144)\n",
      "------------test------------\n",
      " (0.7252964690206528, 0.3558516544525872)\n",
      "------------oot------------\n",
      " (0.7033051819414033, 0.33080318354012445)\n",
      "隐藏层vs神经元数vs norm 1 50 0.3\n",
      "验证集最优结果： 17.126955032348633 17.114288330078125\n",
      "------------train------------\n",
      " (0.7596563610165281, 0.3836451017536593)\n",
      "------------test------------\n",
      " (0.7006284699089497, 0.2897179658005774)\n",
      "------------oot------------\n",
      " (0.6929424576281004, 0.29533242970840723)\n",
      "隐藏层vs神经元数vs norm 1 50 0.4\n",
      "验证集最优结果： 22.442167282104492 22.395366668701172\n",
      "------------train------------\n",
      " (0.7411341426520721, 0.35969947324571466)\n",
      "------------test------------\n",
      " (0.692458361092605, 0.29732400621807686)\n",
      "------------oot------------\n",
      " (0.6919380437678843, 0.28819379279185353)\n",
      "隐藏层vs神经元数vs norm 1 50 0.5\n",
      "验证集最优结果： 26.622657775878906 26.58171272277832\n",
      "------------train------------\n",
      " (0.7656540368815983, 0.39506124711428936)\n",
      "------------test------------\n",
      " (0.7132544970019987, 0.3173995114368199)\n",
      "------------oot------------\n",
      " (0.7066995678819263, 0.31353699648976474)\n",
      "隐藏层vs神经元数vs norm 1 50 0.6\n",
      "验证集最优结果： 32.853878021240234 32.79850769042969\n",
      "------------train------------\n",
      " (0.7192395598356456, 0.31551383753660645)\n",
      "------------test------------\n",
      " (0.6961125916055962, 0.3021319120586276)\n",
      "------------oot------------\n",
      " (0.6836826191220936, 0.27197720084801724)\n",
      "隐藏层vs神经元数vs norm 1 50 0.8\n",
      "验证集最优结果： 43.26268005371094 43.1699104309082\n",
      "------------train------------\n",
      " (0.6989174566627344, 0.2893256963098774)\n",
      "------------test------------\n",
      " (0.6605451920941594, 0.23166777703753055)\n",
      "------------oot------------\n",
      " (0.6607931046467175, 0.23476870677371148)\n",
      "隐藏层vs神经元数vs norm 1 52 0.0001\n",
      "验证集最优结果： 0.30425482988357544 1.2417819499969482\n",
      "------------train------------\n",
      " (0.9996295190854523, 0.9860074082646888)\n",
      "------------test------------\n",
      " (0.6578136797690428, 0.2397512769264935)\n",
      "------------oot------------\n",
      " (0.6141961792884534, 0.17980745838112117)\n",
      "隐藏层vs神经元数vs norm 1 52 0.001\n",
      "验证集最优结果： 0.5744662880897522 0.9872518181800842\n",
      "------------train------------\n",
      " (0.9633012732658834, 0.8058180528568112)\n",
      "------------test------------\n",
      " (0.6902287363979569, 0.2918165667332889)\n",
      "------------oot------------\n",
      " (0.6738840811408844, 0.2717756229798769)\n",
      "隐藏层vs神经元数vs norm 1 52 0.01\n",
      "验证集最优结果： 1.2093448638916016 1.2407642602920532\n",
      "------------train------------\n",
      " (0.7670022246451702, 0.4107633030329487)\n",
      "------------test------------\n",
      " (0.6885098823006885, 0.31198090162114145)\n",
      "------------oot------------\n",
      " (0.6768938472410477, 0.28303617975185075)\n",
      "隐藏层vs神经元数vs norm 1 52 0.02\n",
      "验证集最优结果： 1.7538702487945557 1.7780333757400513\n",
      "------------train------------\n",
      " (0.744443835323467, 0.3731433146603913)\n",
      "------------test------------\n",
      " (0.6992715967133023, 0.3003109038418832)\n",
      "------------oot------------\n",
      " (0.6863286182648085, 0.29994091683175195)\n",
      "隐藏层vs神经元数vs norm 1 52 0.05\n",
      "验证集最优结果： 3.452240228652954 3.468681812286377\n",
      "------------train------------\n",
      " (0.7599975364440464, 0.3877585633949425)\n",
      "------------test------------\n",
      " (0.7130535198756385, 0.3208083499888963)\n",
      "------------oot------------\n",
      " (0.6959348463258379, 0.3087755882250721)\n",
      "隐藏层vs神经元数vs norm 1 52 0.1\n",
      "验证集最优结果： 6.313571929931641 6.318382263183594\n",
      "------------train------------\n",
      " (0.7831866366979146, 0.4139831165201054)\n",
      "------------test------------\n",
      " (0.7240195425272041, 0.3346435709526982)\n",
      "------------oot------------\n",
      " (0.7137038195530532, 0.30863656900566505)\n",
      "隐藏层vs神经元数vs norm 1 52 0.2\n",
      "验证集最优结果： 11.467093467712402 11.444209098815918\n",
      "------------train------------\n",
      " (0.766802500644653, 0.3998081945721907)\n",
      "------------test------------\n",
      " (0.7162369531423496, 0.32926937597157446)\n",
      "------------oot------------\n",
      " (0.7081187224133736, 0.30879644110798316)\n",
      "隐藏层vs神经元数vs norm 1 52 0.3\n",
      "验证集最优结果： 17.5482177734375 17.51510238647461\n",
      "------------train------------\n",
      " (0.7649600450478803, 0.38191790538185455)\n",
      "------------test------------\n",
      " (0.7161969797912503, 0.3206195869420387)\n",
      "------------oot------------\n",
      " (0.7101704143931231, 0.3289959336878324)\n",
      "隐藏层vs神经元数vs norm 1 52 0.4\n",
      "验证集最优结果： 23.259605407714844 23.23216438293457\n",
      "------------train------------\n",
      " (0.7592139361465247, 0.3817534427179249)\n",
      "------------test------------\n",
      " (0.710337552742616, 0.3292249611370198)\n",
      "------------oot------------\n",
      " (0.7116938333391258, 0.3103673582872832)\n",
      "隐藏层vs神经元数vs norm 1 52 0.5\n",
      "验证集最优结果： 28.80223274230957 28.767305374145508\n",
      "------------train------------\n",
      " (0.7304267433888377, 0.33472226452229015)\n",
      "------------test------------\n",
      " (0.6846813235620697, 0.28170108816344663)\n",
      "------------oot------------\n",
      " (0.657487922705314, 0.24552184339484937)\n",
      "隐藏层vs神经元数vs norm 1 52 0.6\n",
      "验证集最优结果： 33.38782501220703 33.37462615966797\n",
      "------------train------------\n",
      " (0.7206758671006316, 0.3220312966358248)\n",
      "------------test------------\n",
      " (0.6753164556962026, 0.2649233844103931)\n",
      "------------oot------------\n",
      " (0.6626269998493959, 0.2676606540854273)\n",
      "隐藏层vs神经元数vs norm 1 52 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集最优结果： 45.4702262878418 45.3115348815918\n",
      "------------train------------\n",
      " (0.738467275652284, 0.35938814474609465)\n",
      "------------test------------\n",
      " (0.6737896957583833, 0.28371085942704866)\n",
      "------------oot------------\n",
      " (0.6855976088694261, 0.26697250894936225)\n",
      "隐藏层vs神经元数vs norm 1 54 0.0001\n",
      "验证集最优结果： 0.3365843892097473 1.6701284646987915\n",
      "------------train------------\n",
      " (0.9990986363134916, 0.9722374840867144)\n",
      "------------test------------\n",
      " (0.6813668665334223, 0.28481012658227844)\n",
      "------------oot------------\n",
      " (0.6547133307846477, 0.23818162861015535)\n",
      "隐藏层vs神经元数vs norm 1 54 0.001\n",
      "验证集最优结果： 0.5470921397209167 0.9542900919914246\n",
      "------------train------------\n",
      " (0.9595457040389459, 0.7981813001213504)\n",
      "------------test------------\n",
      " (0.6875816122584943, 0.31120364201643347)\n",
      "------------oot------------\n",
      " (0.660510432233923, 0.2578737010391686)\n",
      "隐藏层vs神经元数vs norm 1 54 0.01\n",
      "验证集最优结果： 1.2340396642684937 1.2628365755081177\n",
      "------------train------------\n",
      " (0.7533197431675238, 0.3920286368075563)\n",
      "------------test------------\n",
      " (0.6941328003553187, 0.2903952920275372)\n",
      "------------oot------------\n",
      " (0.6854203593646822, 0.29629861328328644)\n",
      "隐藏层vs神经元数vs norm 1 54 0.02\n",
      "验证集最优结果： 1.8171980381011963 1.8450593948364258\n",
      "------------train------------\n",
      " (0.7617434125258284, 0.4010200745970157)\n",
      "------------test------------\n",
      " (0.6957383966244726, 0.3259826782145237)\n",
      "------------oot------------\n",
      " (0.6914700123958804, 0.3135717512946165)\n",
      "隐藏层vs神经元数vs norm 1 54 0.05\n",
      "验证集最优结果： 3.5332043170928955 3.5539708137512207\n",
      "------------train------------\n",
      " (0.7476438185388, 0.36566330905647837)\n",
      "------------test------------\n",
      " (0.7048678658671996, 0.33526537863646466)\n",
      "------------oot------------\n",
      " (0.6822634645906464, 0.2825774163278073)\n",
      "隐藏层vs神经元数vs norm 1 54 0.1\n",
      "验证集最优结果： 6.301323413848877 6.305938720703125\n",
      "------------train------------\n",
      " (0.7831509016005669, 0.4202700571693877)\n",
      "------------test------------\n",
      " (0.7295958250055519, 0.36091494559182774)\n",
      "------------oot------------\n",
      " (0.7105735701294038, 0.33322211795780765)\n",
      "隐藏层vs神经元数vs norm 1 54 0.2\n",
      "验证集最优结果： 12.421111106872559 12.41239070892334\n",
      "------------train------------\n",
      " (0.7647255334715362, 0.3844629481861393)\n",
      "------------test------------\n",
      " (0.7225360870530757, 0.3300244281590051)\n",
      "------------oot------------\n",
      " (0.7125244731750832, 0.33301358912869705)\n",
      "隐藏层vs神经元数vs norm 1 54 0.3\n",
      "验证集最优结果： 17.486248016357422 17.464662551879883\n",
      "------------train------------\n",
      " (0.75089469719581, 0.37400041555586694)\n",
      "------------test------------\n",
      " (0.7086631134799022, 0.3386631134799023)\n",
      "------------oot------------\n",
      " (0.6876481423556806, 0.29342091544155985)\n",
      "隐藏层vs神经元数vs norm 1 54 0.4\n",
      "验证集最优结果： 23.235578536987305 23.195276260375977\n",
      "------------train------------\n",
      " (0.7312229321865615, 0.33561198723011715)\n",
      "------------test------------\n",
      " (0.6859760159893404, 0.26977570508549853)\n",
      "------------oot------------\n",
      " (0.6611696150326116, 0.23061203211343967)\n",
      "隐藏层vs神经元数vs norm 1 54 0.5\n",
      "验证集最优结果： 29.140798568725586 29.10431671142578\n",
      "------------train------------\n",
      " (0.7569729123901298, 0.3722793103938373)\n",
      "------------test------------\n",
      " (0.6923095713968466, 0.28627581612258496)\n",
      "------------oot------------\n",
      " (0.6965210440343377, 0.32112744586939146)\n",
      "隐藏层vs神经元数vs norm 1 54 0.6\n",
      "验证集最优结果： 35.23339080810547 35.1851692199707\n",
      "------------train------------\n",
      " (0.7371217274129482, 0.34076284957622105)\n",
      "------------test------------\n",
      " (0.7167610481900955, 0.32710415278703087)\n",
      "------------oot------------\n",
      " (0.6863865429395614, 0.27198415180898755)\n",
      "隐藏层vs神经元数vs norm 1 54 0.8\n",
      "验证集最优结果： 46.47221755981445 46.30662536621094\n",
      "------------train------------\n",
      " (0.7005002236827589, 0.2916982901974161)\n",
      "------------test------------\n",
      " (0.6846324672440595, 0.2804907839218299)\n",
      "------------oot------------\n",
      " (0.6587553145889086, 0.2516456400097314)\n",
      "隐藏层vs神经元数vs norm 1 56 0.0001\n",
      "验证集最优结果： 0.32408401370048523 1.6149896383285522\n",
      "------------train------------\n",
      " (0.9965108196805634, 0.9540319409504588)\n",
      "------------test------------\n",
      " (0.6823217854763491, 0.28106817677104146)\n",
      "------------oot------------\n",
      " (0.6453862996559274, 0.2348104125395336)\n",
      "隐藏层vs神经元数vs norm 1 56 0.001\n",
      "验证集最优结果： 0.544086217880249 1.1314736604690552\n",
      "------------train------------\n",
      " (0.9694419572004529, 0.8186303034979111)\n",
      "------------test------------\n",
      " (0.6859138352209638, 0.314079502553853)\n",
      "------------oot------------\n",
      " (0.6461729167390724, 0.237604698849616)\n",
      "隐藏层vs神经元数vs norm 1 56 0.01\n",
      "验证集最优结果： 1.24519944190979 1.2747970819473267\n",
      "------------train------------\n",
      " (0.7514619918662047, 0.3899635813335553)\n",
      "------------test------------\n",
      " (0.6959737952476128, 0.29371530091050413)\n",
      "------------oot------------\n",
      " (0.6881914758048633, 0.2957981440934209)\n",
      "隐藏层vs神经元数vs norm 1 56 0.02\n",
      "验证集最优结果： 1.8397012948989868 1.8600726127624512\n",
      "------------train------------\n",
      " (0.7488671365019806, 0.3824697689874853)\n",
      "------------test------------\n",
      " (0.7016233622029758, 0.3059737952476127)\n",
      "------------oot------------\n",
      " (0.6902466432650981, 0.31372467243596425)\n",
      "隐藏层vs神经元数vs norm 1 56 0.05\n",
      "验证集最优结果： 3.6890780925750732 3.7027525901794434\n",
      "------------train------------\n",
      " (0.7724815385583731, 0.40805677548951325)\n",
      "------------test------------\n",
      " (0.7147845880524094, 0.33096824339329334)\n",
      "------------oot------------\n",
      " (0.7041717350757075, 0.3320335036318771)\n",
      "隐藏层vs神经元数vs norm 1 56 0.1\n",
      "验证集最优结果： 6.666594505310059 6.6665730476379395\n",
      "------------train------------\n",
      " (0.7745153258221948, 0.410643103160052)\n",
      "------------test------------\n",
      " (0.7255185431934266, 0.35169886742171885)\n",
      "------------oot------------\n",
      " (0.7095471448927814, 0.32174608139575295)\n",
      "隐藏层vs神经元数vs norm 1 56 0.2\n",
      "验证集最优结果： 12.495562553405762 12.477713584899902\n",
      "------------train------------\n",
      " (0.7637011273475691, 0.3938907873159354)\n",
      "------------test------------\n",
      " (0.7149344881190318, 0.32992449478125696)\n",
      "------------oot------------\n",
      " (0.704769517719158, 0.3159003232196851)\n",
      "隐藏层vs神经元数vs norm 1 56 0.3\n",
      "验证集最优结果： 18.533737182617188 18.518531799316406\n",
      "------------train------------\n",
      " (0.74652391578158, 0.3511937079156624)\n",
      "------------test------------\n",
      " (0.6947257383966244, 0.29760159893404403)\n",
      "------------oot------------\n",
      " (0.667732480682121, 0.2504292218399194)\n",
      "隐藏层vs神经元数vs norm 1 56 0.4\n",
      "验证集最优结果： 24.861221313476562 24.818492889404297\n",
      "------------train------------\n",
      " (0.7461500508616015, 0.3550964136987247)\n",
      "------------test------------\n",
      " (0.7015733955141017, 0.3063624250499667)\n",
      "------------oot------------\n",
      " (0.7002456006209525, 0.2792131512181559)\n",
      "隐藏层vs神经元数vs norm 1 56 0.5\n",
      "验证集最优结果： 30.653371810913086 30.579519271850586\n",
      "------------train------------\n",
      " (0.7336893983847466, 0.344382787865498)\n",
      "------------test------------\n",
      " (0.7071319120586276, 0.3118254497001999)\n",
      "------------oot------------\n",
      " (0.703354997161691, 0.3181593855350502)\n",
      "隐藏层vs神经元数vs norm 1 56 0.6\n",
      "验证集最优结果： 35.02101516723633 35.014488220214844\n",
      "------------train------------\n",
      " (0.6712915192086301, 0.30640328275598816)\n",
      "------------test------------\n",
      " (0.6678814123917389, 0.3101376859871197)\n",
      "------------oot------------\n",
      " (0.6353491120147361, 0.25749139818579914)\n",
      "隐藏层vs神经元数vs norm 1 56 0.8\n",
      "验证集最优结果： 46.33685302734375 46.29267501831055\n",
      "------------train------------\n",
      " (0.6545103039581358, 0.24847993860060547)\n",
      "------------test------------\n",
      " (0.6304152787030868, 0.2218965134354875)\n",
      "------------oot------------\n",
      " (0.6196758535200825, 0.20052827303374693)\n",
      "隐藏层vs神经元数vs norm 1 58 0.0001\n",
      "验证集最优结果： 0.3379516899585724 1.5225955247879028\n",
      "------------train------------\n",
      " (0.9995579135305397, 0.986290175758474)\n",
      "------------test------------\n",
      " (0.6710959360426383, 0.265489673550966)\n",
      "------------oot------------\n",
      " (0.6440181188382628, 0.22702533625273694)\n",
      "隐藏层vs神经元数vs norm 1 58 0.001\n",
      "验证集最优结果： 0.5568203330039978 1.0633924007415771\n",
      "------------train------------\n",
      " (0.9717641294070749, 0.8264906713122293)\n",
      "------------test------------\n",
      " (0.6800266489007328, 0.280735065511881)\n",
      "------------oot------------\n",
      " (0.6545302888124284, 0.23094567824001666)\n",
      "隐藏层vs神经元数vs norm 1 58 0.01\n",
      "验证集最优结果： 1.2626032829284668 1.2907161712646484\n",
      "------------train------------\n",
      " (0.7583388323421582, 0.40271667955972734)\n",
      "------------test------------\n",
      " (0.7006084832334, 0.2952143015767266)\n",
      "------------oot------------\n",
      " (0.6917920735875067, 0.30090710040663127)\n",
      "隐藏层vs神经元数vs norm 1 58 0.02\n",
      "验证集最优结果： 1.8735134601593018 1.8956390619277954\n",
      "------------train------------\n",
      " (0.7594851980218458, 0.3967106113611891)\n",
      "------------test------------\n",
      " (0.7108905174328225, 0.31243615367532757)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.7017041439312318, 0.31186181489590936)\n",
      "隐藏层vs神经元数vs norm 1 58 0.05\n",
      "验证集最优结果： 3.7688217163085938 3.7778069972991943\n",
      "------------train------------\n",
      " (0.777698862771135, 0.4293757389821859)\n",
      "------------test------------\n",
      " (0.7083055740617366, 0.32962469464801236)\n",
      "------------oot------------\n",
      " (0.6929598350305263, 0.3007472283043131)\n",
      "隐藏层vs神经元数vs norm 1 58 0.1\n",
      "验证集最优结果： 6.790970325469971 6.7895588874816895\n",
      "------------train------------\n",
      " (0.7549402080080458, 0.39247302440070964)\n",
      "------------test------------\n",
      " (0.7164756828780813, 0.34606928714190544)\n",
      "------------oot------------\n",
      " (0.6975103974791181, 0.30559899906162025)\n",
      "隐藏层vs神经元数vs norm 1 58 0.2\n",
      "验证集最优结果： 12.872383117675781 12.856298446655273\n",
      "------------train------------\n",
      " (0.7661594042526119, 0.39420414621881383)\n",
      "------------test------------\n",
      " (0.7142760381967577, 0.34198312236286926)\n",
      "------------oot------------\n",
      " (0.7010577045609889, 0.3097209189170403)\n",
      "隐藏层vs神经元数vs norm 1 58 0.3\n",
      "验证集最优结果： 19.248289108276367 19.220123291015625\n",
      "------------train------------\n",
      " (0.7536215964519379, 0.36892833285618853)\n",
      "------------test------------\n",
      " (0.7054252720408618, 0.3138907395069953)\n",
      "------------oot------------\n",
      " (0.6946037373000151, 0.2992180168908352)\n",
      "隐藏层vs神经元数vs norm 1 58 0.4\n",
      "验证集最优结果： 25.854999542236328 25.762413024902344\n",
      "------------train------------\n",
      " (0.7392958832220334, 0.3431265096894227)\n",
      "------------test------------\n",
      " (0.7070819453697536, 0.3106595602931379)\n",
      "------------oot------------\n",
      " (0.7000486567267925, 0.3170055260139715)\n",
      "隐藏层vs神经元数vs norm 1 58 0.5\n",
      "验证集最优结果： 30.965885162353516 30.940044403076172\n",
      "------------train------------\n",
      " (0.7416973088358412, 0.3547220073378773)\n",
      "------------test------------\n",
      " (0.7077281812125249, 0.325582944703531)\n",
      "------------oot------------\n",
      " (0.6649022810736918, 0.26287839293782367)\n",
      "隐藏层vs神经元数vs norm 1 58 0.6\n",
      "验证集最优结果： 37.56180953979492 37.54087829589844\n",
      "------------train------------\n",
      " (0.7370320512690358, 0.3612680274429304)\n",
      "------------test------------\n",
      " (0.6924672440595159, 0.292871419053964)\n",
      "------------oot------------\n",
      " (0.6984754225605023, 0.2913286761894832)\n",
      "隐藏层vs神经元数vs norm 1 58 0.8\n",
      "验证集最优结果： 50.071311950683594 49.87819290161133\n",
      "------------train------------\n",
      " (0.7108906093172498, 0.3004797842899578)\n",
      "------------test------------\n",
      " (0.690016655562958, 0.2775483011325783)\n",
      "------------oot------------\n",
      " (0.6648663677753449, 0.26638167726688217)\n",
      "隐藏层vs神经元数vs norm 1 60 0.0001\n",
      "验证集最优结果： 0.3033139109611511 1.4815970659255981\n",
      "------------train------------\n",
      " (0.9997998022387227, 0.9890646541309569)\n",
      "------------test------------\n",
      " (0.657880302020875, 0.2445258716411281)\n",
      "------------oot------------\n",
      " (0.6249805952339578, 0.19500921002328572)\n",
      "隐藏层vs神经元数vs norm 1 60 0.001\n",
      "验证集最优结果： 0.5695056319236755 1.0294901132583618\n",
      "------------train------------\n",
      " (0.9535075554689252, 0.7757450733956938)\n",
      "------------test------------\n",
      " (0.6833288918498779, 0.31002664890073284)\n",
      "------------oot------------\n",
      " (0.6430901655487204, 0.23041045424529943)\n",
      "隐藏层vs神经元数vs norm 1 60 0.01\n",
      "验证集最优结果： 1.2969598770141602 1.326377034187317\n",
      "------------train------------\n",
      " (0.7557742299864842, 0.3884187151743541)\n",
      "------------test------------\n",
      " (0.6791960914945593, 0.295836109260493)\n",
      "------------oot------------\n",
      " (0.6618797715450828, 0.25361971292531194)\n",
      "隐藏层vs神经元数vs norm 1 60 0.02\n",
      "验证集最优结果： 1.955461859703064 1.983244776725769\n",
      "------------train------------\n",
      " (0.7622891849216841, 0.3939301771391483)\n",
      "------------test------------\n",
      " (0.6948967355096602, 0.3204197201865423)\n",
      "------------oot------------\n",
      " (0.6927235023575342, 0.3076912383136969)\n",
      "隐藏层vs神经元数vs norm 1 60 0.05\n",
      "验证集最优结果： 3.9132301807403564 3.9271388053894043\n",
      "------------train------------\n",
      " (0.7640045372744815, 0.3842391977470645)\n",
      "------------test------------\n",
      " (0.6929380413057962, 0.29362647124139457)\n",
      "------------oot------------\n",
      " (0.6983282938866299, 0.2996281235880861)\n",
      "隐藏层vs神经元数vs norm 1 60 0.1\n",
      "验证集最优结果： 7.215816974639893 7.214158058166504\n",
      "------------train------------\n",
      " (0.7533707062893096, 0.37505081084154124)\n",
      "------------test------------\n",
      " (0.7114212747057518, 0.3219853431045969)\n",
      "------------oot------------\n",
      " (0.7039516213116463, 0.3066416432071734)\n",
      "隐藏层vs神经元数vs norm 1 60 0.2\n",
      "验证集最优结果： 13.504947662353516 13.488746643066406\n",
      "------------train------------\n",
      " (0.7643752212293551, 0.3943992002918366)\n",
      "------------test------------\n",
      " (0.715203197868088, 0.34055074394847884)\n",
      "------------oot------------\n",
      " (0.7057217993720966, 0.3068779758801654)\n",
      "隐藏层vs神经元数vs norm 1 60 0.3\n",
      "验证集最优结果： 19.79216957092285 19.78931427001953\n",
      "------------train------------\n",
      " (0.7649046150389263, 0.40499655169846616)\n",
      "------------test------------\n",
      " (0.7195125471907616, 0.34910059960026646)\n",
      "------------oot------------\n",
      " (0.7058955733963553, 0.29305251451013103)\n",
      "隐藏层vs神经元数vs norm 1 60 0.4\n",
      "验证集最优结果： 26.05452537536621 26.041725158691406\n",
      "------------train------------\n",
      " (0.7494407931025848, 0.3737502698744331)\n",
      "------------test------------\n",
      " (0.7148689762380636, 0.32381745502998)\n",
      "------------oot------------\n",
      " (0.7001865174527045, 0.30123379557223784)\n",
      "隐藏层vs神经元数vs norm 1 60 0.5\n",
      "验证集最优结果： 32.8941535949707 32.80268859863281\n",
      "------------train------------\n",
      " (0.7492424903843486, 0.3709659102060927)\n",
      "------------test------------\n",
      " (0.7048834110592939, 0.32248500999333773)\n",
      "------------oot------------\n",
      " (0.6790486451418575, 0.2826399749765405)\n",
      "隐藏层vs神经元数vs norm 1 60 0.6\n",
      "验证集最优结果： 37.486061096191406 37.451622009277344\n",
      "------------train------------\n",
      " (0.6791946608515917, 0.30525840603869003)\n",
      "------------test------------\n",
      " (0.6492071952031979, 0.28730846102598273)\n",
      "------------oot------------\n",
      " (0.6422664766737334, 0.267222743544295)\n",
      "隐藏层vs神经元数vs norm 1 60 0.8\n",
      "验证集最优结果： 51.903873443603516 51.7320442199707\n",
      "------------train------------\n",
      " (0.7060898561730012, 0.32064114720491305)\n",
      "------------test------------\n",
      " (0.6787674883411059, 0.2846657783699756)\n",
      "------------oot------------\n",
      " (0.6662646694238812, 0.26089041810030233)\n",
      "隐藏层vs神经元数vs norm 1 62 0.0001\n",
      "验证集最优结果： 0.2778644859790802 1.681117057800293\n",
      "------------train------------\n",
      " (0.9999327259720386, 0.9944333110665776)\n",
      "------------test------------\n",
      " (0.6512280701754387, 0.24501443482123025)\n",
      "------------oot------------\n",
      " (0.614602810505219, 0.17808362006047335)\n",
      "隐藏层vs神经元数vs norm 1 62 0.001\n",
      "验证集最优结果： 0.6025032997131348 1.02969229221344\n",
      "------------train------------\n",
      " (0.9528433428829967, 0.7761441153160763)\n",
      "------------test------------\n",
      " (0.6818032422829226, 0.29676882078614253)\n",
      "------------oot------------\n",
      " (0.6573384770444515, 0.2567267924790602)\n",
      "隐藏层vs神经元数vs norm 1 62 0.01\n",
      "验证集最优结果： 1.3188254833221436 1.3475003242492676\n",
      "------------train------------\n",
      " (0.7475208437814501, 0.3827672907449482)\n",
      "------------test------------\n",
      " (0.694679102820342, 0.2899178325560738)\n",
      "------------oot------------\n",
      " (0.6869403028301996, 0.2982657352378966)\n",
      "隐藏层vs神经元数vs norm 1 62 0.02\n",
      "验证集最优结果： 1.9843573570251465 2.0135045051574707\n",
      "------------train------------\n",
      " (0.7540208414126464, 0.3886335318390919)\n",
      "------------test------------\n",
      " (0.687154119475905, 0.3004108372196314)\n",
      "------------oot------------\n",
      " (0.678860969195658, 0.2860320439300733)\n",
      "隐藏层vs神经元数vs norm 1 62 0.05\n",
      "验证集最优结果： 3.9902873039245605 4.012225151062012\n",
      "------------train------------\n",
      " (0.7694967780884295, 0.4053798918336504)\n",
      "------------test------------\n",
      " (0.7055485232067511, 0.31989784588052406)\n",
      "------------oot------------\n",
      " (0.6947114771950555, 0.28101345010947765)\n",
      "隐藏层vs神经元数vs norm 1 62 0.1\n",
      "验证集最优结果： 7.295064449310303 7.302676677703857\n",
      "------------train------------\n",
      " (0.767993941276677, 0.4035571311484841)\n",
      "------------test------------\n",
      " (0.7069864534754609, 0.3077392849211637)\n",
      "------------oot------------\n",
      " (0.7022115640820676, 0.3118687658568797)\n",
      "隐藏层vs神经元数vs norm 1 62 0.2\n",
      "验证集最优结果： 13.787803649902344 13.786710739135742\n",
      "------------train------------\n",
      " (0.7644424275772077, 0.4025167525188844)\n",
      "------------test------------\n",
      " (0.707450588496558, 0.3141017099711304)\n",
      "------------oot------------\n",
      " (0.7010785574439, 0.29797379487714176)\n",
      "隐藏层vs神经元数vs norm 1 62 0.3\n",
      "验证集最优结果： 21.044164657592773 21.01113510131836\n",
      "------------train------------\n",
      " (0.7606974164472139, 0.3843644059479987)\n",
      "------------test------------\n",
      " (0.7130357539418166, 0.31732178547634915)\n",
      "------------oot------------\n",
      " (0.7069046212305518, 0.3073228373822681)\n",
      "隐藏层vs神经元数vs norm 1 62 0.4\n",
      "验证集最优结果： 27.518346786499023 27.475955963134766\n",
      "------------train------------\n",
      " (0.7547741210215094, 0.37982239385897765)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.7085698423273373, 0.3162558294470353)\n",
      "------------oot------------\n",
      " (0.6891819877431389, 0.2772668821464568)\n",
      "隐藏层vs神经元数vs norm 1 62 0.5\n",
      "验证集最优结果： 34.16799545288086 34.14529800415039\n",
      "------------train------------\n",
      " (0.7394952688220074, 0.3562816277607562)\n",
      "------------test------------\n",
      " (0.682660448589829, 0.27291805463024654)\n",
      "------------oot------------\n",
      " (0.6972613213776805, 0.28304313071282106)\n",
      "隐藏层vs神经元数vs norm 1 62 0.6\n",
      "验证集最优结果： 38.685211181640625 38.658599853515625\n",
      "------------train------------\n",
      " (0.723355254920513, 0.3260253705655147)\n",
      "------------test------------\n",
      " (0.6845391960914946, 0.3018210082167444)\n",
      "------------oot------------\n",
      " (0.6575620662889977, 0.2376742084593195)\n",
      "隐藏层vs神经元数vs norm 1 62 0.8\n",
      "验证集最优结果： 51.2889404296875 51.16221618652344\n",
      "------------train------------\n",
      " (0.6831483297564396, 0.2742246397557019)\n",
      "------------test------------\n",
      " (0.6614923384410394, 0.23908505440817235)\n",
      "------------oot------------\n",
      " (0.6308564742408971, 0.20291245264657837)\n",
      "隐藏层vs神经元数vs norm 1 64 0.0001\n",
      "验证集最优结果： 0.30488908290863037 1.535401463508606\n",
      "------------train------------\n",
      " (0.9993566328875245, 0.9769135027907893)\n",
      "------------test------------\n",
      " (0.6837197423939596, 0.2832778147901399)\n",
      "------------oot------------\n",
      " (0.6743799163567696, 0.2738192055051611)\n",
      "隐藏层vs神经元数vs norm 1 64 0.001\n",
      "验证集最优结果： 0.6136124730110168 1.0531742572784424\n",
      "------------train------------\n",
      " (0.9572745626342182, 0.7812654691348249)\n",
      "------------test------------\n",
      " (0.6984610259826782, 0.326215856095936)\n",
      "------------oot------------\n",
      " (0.67320983792676, 0.28670628714419766)\n",
      "隐藏层vs神经元数vs norm 1 64 0.01\n",
      "验证集最优结果： 1.3419575691223145 1.3687334060668945\n",
      "------------train------------\n",
      " (0.754138063360764, 0.4004713242763812)\n",
      "------------test------------\n",
      " (0.699129469242727, 0.30578503220075504)\n",
      "------------oot------------\n",
      " (0.6944195368343007, 0.3191255691099294)\n",
      "隐藏层vs神经元数vs norm 1 64 0.02\n",
      "验证集最优结果： 2.012204885482788 2.0324594974517822\n",
      "------------train------------\n",
      " (0.7574236619134926, 0.38937733623274917)\n",
      "------------test------------\n",
      " (0.7101487896957585, 0.31355762824783473)\n",
      "------------oot------------\n",
      " (0.6985414566897207, 0.31938275466583255)\n",
      "隐藏层vs神经元数vs norm 1 64 0.05\n",
      "验证集最优结果： 4.13534688949585 4.148245811462402\n",
      "------------train------------\n",
      " (0.7643462541428687, 0.39694410773590405)\n",
      "------------test------------\n",
      " (0.7153320008882968, 0.3271263602043083)\n",
      "------------oot------------\n",
      " (0.6986827928961179, 0.3189378931637299)\n",
      "隐藏层vs神经元数vs norm 1 64 0.1\n",
      "验证集最优结果： 7.435513019561768 7.437297821044922\n",
      "------------train------------\n",
      " (0.7620240819362466, 0.3853181540385736)\n",
      "------------test------------\n",
      " (0.6989829002886964, 0.3143904063957362)\n",
      "------------oot------------\n",
      " (0.6905733384307048, 0.2995308101345011)\n",
      "隐藏层vs神经元数vs norm 1 64 0.2\n",
      "验证集最优结果： 14.517851829528809 14.502328872680664\n",
      "------------train------------\n",
      " (0.7673556501723474, 0.3933104980646873)\n",
      "------------test------------\n",
      " (0.7166044858982901, 0.3445147679324895)\n",
      "------------oot------------\n",
      " (0.7157497190653275, 0.31527473673235323)\n",
      "隐藏层vs神经元数vs norm 1 64 0.3\n",
      "验证集最优结果： 21.5036678314209 21.438528060913086\n",
      "------------train------------\n",
      " (0.7555535928324059, 0.37529703107667545)\n",
      "------------test------------\n",
      " (0.7142738174550299, 0.3279258272262936)\n",
      "------------oot------------\n",
      " (0.6967851805512112, 0.30364577902895074)\n",
      "隐藏层vs神经元数vs norm 1 64 0.4\n",
      "验证集最优结果： 28.000871658325195 27.93134880065918\n",
      "------------train------------\n",
      " (0.7486600353696247, 0.3774606287888171)\n",
      "------------test------------\n",
      " (0.7018942926937597, 0.32073062402842556)\n",
      "------------oot------------\n",
      " (0.7052560849870828, 0.332012650748966)\n",
      "隐藏层vs神经元数vs norm 1 64 0.5\n",
      "验证集最优结果： 33.822086334228516 33.81565475463867\n",
      "------------train------------\n",
      " (0.7292798362682813, 0.32535344244720443)\n",
      "------------test------------\n",
      " (0.6813635354208306, 0.28122362869198314)\n",
      "------------oot------------\n",
      " (0.6888599265515124, 0.29240607513988803)\n",
      "隐藏层vs神经元数vs norm 1 64 0.6\n",
      "验证集最优结果： 40.00007247924805 39.98039627075195\n",
      "------------train------------\n",
      " (0.6992850273326119, 0.2806987835854079)\n",
      "------------test------------\n",
      " (0.6638640906062625, 0.25332000888296685)\n",
      "------------oot------------\n",
      " (0.6489092783744019, 0.22107531366211378)\n",
      "隐藏层vs神经元数vs norm 1 64 0.8\n",
      "验证集最优结果： 55.265838623046875 55.195491790771484\n",
      "------------train------------\n",
      " (0.6988980324715626, 0.3011242342841711)\n",
      "------------test------------\n",
      " (0.6673451032644903, 0.29753497668221185)\n",
      "------------oot------------\n",
      " (0.6508787173160022, 0.2393771938970563)\n",
      "隐藏层vs神经元数vs norm 1 66 0.0001\n",
      "验证集最优结果： 0.3587224781513214 1.7005484104156494\n",
      "------------train------------\n",
      " (0.9999519471228848, 0.9940658080768088)\n",
      "------------test------------\n",
      " (0.682609371530091, 0.2845214301576727)\n",
      "------------oot------------\n",
      " (0.6510281629768648, 0.2355680672853022)\n",
      "隐藏层vs神经元数vs norm 1 66 0.001\n",
      "验证集最优结果： 0.6305739879608154 0.968305766582489\n",
      "------------train------------\n",
      " (0.9433566220587071, 0.7399271355950672)\n",
      "------------test------------\n",
      " (0.6885187652675995, 0.30969353764157226)\n",
      "------------oot------------\n",
      " (0.6545094359295173, 0.2421992840510201)\n",
      "隐藏层vs神经元数vs norm 1 66 0.01\n",
      "验证集最优结果： 1.3703222274780273 1.3987290859222412\n",
      "------------train------------\n",
      " (0.7550244020631605, 0.3938504499712021)\n",
      "------------test------------\n",
      " (0.6813391072618254, 0.3108927381745503)\n",
      "------------oot------------\n",
      " (0.6691018199932808, 0.2676954088902791)\n",
      "隐藏层vs神经元数vs norm 1 66 0.02\n",
      "验证集最优结果： 2.0712101459503174 2.0982909202575684\n",
      "------------train------------\n",
      " (0.7600765868109065, 0.39475479158248955)\n",
      "------------test------------\n",
      " (0.6952409504774595, 0.3126915389740173)\n",
      "------------oot------------\n",
      " (0.6896233737647564, 0.29440100093837973)\n",
      "隐藏层vs神经元数vs norm 1 66 0.05\n",
      "验证集最优结果： 4.121891498565674 4.132848262786865\n",
      "------------train------------\n",
      " (0.7541766410226735, 0.3719579652381427)\n",
      "------------test------------\n",
      " (0.7108172329558072, 0.32707084166111483)\n",
      "------------oot------------\n",
      " (0.6927385627729701, 0.28369652104403437)\n",
      "隐藏层vs神经元数vs norm 1 66 0.1\n",
      "验证集最优结果： 7.838354587554932 7.842375755310059\n",
      "------------train------------\n",
      " (0.754290072884709, 0.3772892627538088)\n",
      "------------test------------\n",
      " (0.7144903397734844, 0.32589384854541414)\n",
      "------------oot------------\n",
      " (0.7038149190792293, 0.30231814548361313)\n",
      "隐藏层vs神经元数vs norm 1 66 0.2\n",
      "验证集最优结果： 14.6694974899292 14.650248527526855\n",
      "------------train------------\n",
      " (0.7654181717030819, 0.39484453540651043)\n",
      "------------test------------\n",
      " (0.7143037974683543, 0.32488341105929375)\n",
      "------------oot------------\n",
      " (0.7062639743277841, 0.30925520453202654)\n",
      "隐藏层vs神经元数vs norm 1 66 0.3\n",
      "验证集最优结果： 21.90789794921875 21.876323699951172\n",
      "------------train------------\n",
      " (0.7617704845692737, 0.38222828635995393)\n",
      "------------test------------\n",
      " (0.7134643570952699, 0.3166777703753053)\n",
      "------------oot------------\n",
      " (0.7069567534378294, 0.3149341396448059)\n",
      "隐藏层vs神经元数vs norm 1 66 0.4\n",
      "验证集最优结果： 29.092655181884766 28.997089385986328\n",
      "------------train------------\n",
      " (0.7497140853811642, 0.3690712732455793)\n",
      "------------test------------\n",
      " (0.712636020430824, 0.32248500999333773)\n",
      "------------oot------------\n",
      " (0.6941866796417938, 0.32395648698432555)\n",
      "隐藏层vs神经元数vs norm 1 66 0.5\n",
      "验证集最优结果： 36.558345794677734 36.52104187011719\n",
      "------------train------------\n",
      " (0.7548619698024891, 0.3733866923309638)\n",
      "------------test------------\n",
      " (0.7028103486564512, 0.3086497890295359)\n",
      "------------oot------------\n",
      " (0.7004715068524889, 0.2887290167865707)\n",
      "隐藏层vs神经元数vs norm 1 66 0.6\n",
      "验证集最优结果： 41.41200637817383 41.35148239135742\n",
      "------------train------------\n",
      " (0.7034566938673024, 0.31264487773249977)\n",
      "------------test------------\n",
      " (0.6860337552742617, 0.3062513879635798)\n",
      "------------oot------------\n",
      " (0.6524021362620048, 0.27674556007368023)\n",
      "隐藏层vs神经元数vs norm 1 66 0.8\n",
      "验证集最优结果： 56.63888168334961 56.46198272705078\n",
      "------------train------------\n",
      " (0.6703246411769841, 0.2626234569781238)\n",
      "------------test------------\n",
      " (0.6636364645791695, 0.26404619142793695)\n",
      "------------oot------------\n",
      " (0.6298045621473835, 0.20398985159698327)\n",
      "隐藏层vs神经元数vs norm 1 68 0.0001\n",
      "验证集最优结果： 0.3248339593410492 1.4162116050720215\n",
      "------------train------------\n",
      " (0.998700812635064, 0.9681270003702103)\n",
      "------------test------------\n",
      " (0.669620253164557, 0.25249833444370423)\n",
      "------------oot------------\n",
      " (0.6302807029738527, 0.21609147464636988)\n",
      "隐藏层vs神经元数vs norm 1 68 0.001\n",
      "验证集最优结果： 0.5785284638404846 0.9102485179901123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " (0.9538475803345969, 0.7765579115001364)\n",
      "------------test------------\n",
      " (0.6870530757272929, 0.290084388185654)\n",
      "------------oot------------\n",
      " (0.6570094648918546, 0.2447016300003475)\n",
      "隐藏层vs神经元数vs norm 1 68 0.01\n",
      "验证集最优结果： 1.398922085762024 1.4277418851852417\n",
      "------------train------------\n",
      " (0.7599209225610966, 0.3962790829886724)\n",
      "------------test------------\n",
      " (0.6861803242282922, 0.3117255163224517)\n",
      "------------oot------------\n",
      " (0.679706669447051, 0.3044103847356897)\n",
      "隐藏层vs神经元数vs norm 1 68 0.02\n",
      "验证集最优结果： 2.1393260955810547 2.170315742492676\n",
      "------------train------------\n",
      " (0.7566037850777543, 0.38871136396399686)\n",
      "------------test------------\n",
      " (0.6855585165445259, 0.30664001776593375)\n",
      "------------oot------------\n",
      " (0.680529199828543, 0.2858999756716366)\n",
      "隐藏层vs神经元数vs norm 1 68 0.05\n",
      "验证集最优结果： 4.226197242736816 4.238789081573486\n",
      "------------train------------\n",
      " (0.7842615321829068, 0.42408396664994974)\n",
      "------------test------------\n",
      " (0.7212702642682656, 0.3558405507439485)\n",
      "------------oot------------\n",
      " (0.7020053522399472, 0.32036979112362285)\n",
      "隐藏层vs神经元数vs norm 1 68 0.1\n",
      "验证集最优结果： 7.9157586097717285 7.922343730926514\n",
      "------------train------------\n",
      " (0.7683935246379283, 0.40955832637920214)\n",
      "------------test------------\n",
      " (0.7080302020874971, 0.33376637797024206)\n",
      "------------oot------------\n",
      " (0.6974941785701874, 0.30839328537170263)\n",
      "隐藏层vs神经元数vs norm 1 68 0.2\n",
      "验证集最优结果： 14.945229530334473 14.922246932983398\n",
      "------------train------------\n",
      " (0.7618736967349085, 0.3895399038536377)\n",
      "------------test------------\n",
      " (0.7187053075727293, 0.349400399733511)\n",
      "------------oot------------\n",
      " (0.7086933351869229, 0.31941750947068437)\n",
      "隐藏层vs神经元数vs norm 1 68 0.3\n",
      "验证集最优结果： 22.176191329956055 22.152891159057617\n",
      "------------train------------\n",
      " (0.7643810417186957, 0.39826035048821046)\n",
      "------------test------------\n",
      " (0.7132689318232289, 0.3259937819231623)\n",
      "------------oot------------\n",
      " (0.7049826805222489, 0.3128836061585514)\n",
      "隐藏层vs神经元数vs norm 1 68 0.4\n",
      "验证集最优结果： 29.645727157592773 29.586811065673828\n",
      "------------train------------\n",
      " (0.7713645460458235, 0.398142181018572)\n",
      "------------test------------\n",
      " (0.723142349544748, 0.33879635798356655)\n",
      "------------oot------------\n",
      " (0.7151681553308078, 0.32618079449483894)\n",
      "隐藏层vs神经元数vs norm 1 68 0.5\n",
      "验证集最优结果： 35.71554946899414 35.6634635925293\n",
      "------------train------------\n",
      " (0.7152857555705805, 0.3344829476582344)\n",
      "------------test------------\n",
      " (0.6713124583610925, 0.3011103708638685)\n",
      "------------oot------------\n",
      " (0.6459585954424866, 0.25070030931776316)\n",
      "隐藏层vs神经元数vs norm 1 68 0.6\n",
      "验证集最优结果： 44.39854431152344 44.29048156738281\n",
      "------------train------------\n",
      " (0.6838208669957273, 0.27083846856157434)\n",
      "------------test------------\n",
      " (0.6694015101043749, 0.267432822562736)\n",
      "------------oot------------\n",
      " (0.6418528944959974, 0.23957182080422618)\n",
      "隐藏层vs神经元数vs norm 1 68 0.8\n",
      "验证集最优结果： 57.747703552246094 57.61155319213867\n",
      "------------train------------\n",
      " (0.6720849331219008, 0.26700384896777685)\n",
      "------------test------------\n",
      " (0.6497512769264935, 0.2359982234066178)\n",
      "------------oot------------\n",
      " (0.6472989724162699, 0.24040593612066868)\n",
      "隐藏层vs神经元数vs norm 1 70 0.0001\n",
      "验证集最优结果： 0.33770594000816345 1.4128773212432861\n",
      "------------train------------\n",
      " (0.9956332793922866, 0.9521658649957802)\n",
      "------------test------------\n",
      " (0.6870319786808793, 0.278758605374195)\n",
      "------------oot------------\n",
      " (0.6617222164297547, 0.2544121224759323)\n",
      "隐藏层vs神经元数vs norm 1 70 0.001\n",
      "验证集最优结果： 0.6067590713500977 0.961814820766449\n",
      "------------train------------\n",
      " (0.941743669710241, 0.7475165122544989)\n",
      "------------test------------\n",
      " (0.686098156784366, 0.3195536309127248)\n",
      "------------oot------------\n",
      " (0.6480496762010681, 0.24174747158794704)\n",
      "隐藏层vs神经元数vs norm 1 70 0.01\n",
      "验证集最优结果： 1.4191563129425049 1.448248028755188\n",
      "------------train------------\n",
      " (0.7614923870029827, 0.4023058613004462)\n",
      "------------test------------\n",
      " (0.6898867421718855, 0.3210970464135021)\n",
      "------------oot------------\n",
      " (0.6866020227296423, 0.31257081291488553)\n",
      "隐藏层vs神经元数vs norm 1 70 0.02\n",
      "验证集最优结果： 2.1690611839294434 2.1972603797912598\n",
      "------------train------------\n",
      " (0.7616641591186426, 0.39626717128955646)\n",
      "------------test------------\n",
      " (0.6990162114146125, 0.3301132578281145)\n",
      "------------oot------------\n",
      " (0.6999965245195149, 0.32376881103812605)\n",
      "隐藏层vs神经元数vs norm 1 70 0.05\n",
      "验证集最优结果： 4.334508419036865 4.3409833908081055\n",
      "------------train------------\n",
      " (0.7773620188705679, 0.4097386261885473)\n",
      "------------test------------\n",
      " (0.7148323339995558, 0.34711303575394187)\n",
      "------------oot------------\n",
      " (0.7175951992029566, 0.32697320404545926)\n",
      "隐藏层vs神经元数vs norm 1 70 0.1\n",
      "验证集最优结果： 8.36086368560791 8.36325454711914\n",
      "------------train------------\n",
      " (0.7608428610006234, 0.3870847402335911)\n",
      "------------test------------\n",
      " (0.7120475238729735, 0.3283921829891183)\n",
      "------------oot------------\n",
      " (0.6920770629872913, 0.31046467174086817)\n",
      "隐藏层vs神经元数vs norm 1 70 0.2\n",
      "验证集最优结果： 15.322114944458008 15.285554885864258\n",
      "------------train------------\n",
      " (0.7630844938779957, 0.3877930802503352)\n",
      "------------test------------\n",
      " (0.7132356206973129, 0.3368976238063513)\n",
      "------------oot------------\n",
      " (0.7046050116428596, 0.31341187919229835)\n",
      "隐藏层vs神经元数vs norm 1 70 0.3\n",
      "验证集最优结果： 22.980926513671875 22.941490173339844\n",
      "------------train------------\n",
      " (0.7582708138330021, 0.37865883743170226)\n",
      "------------test------------\n",
      " (0.7171796580057739, 0.3362091938707529)\n",
      "------------oot------------\n",
      " (0.7079646427785308, 0.3159003232196851)\n",
      "隐藏层vs神经元数vs norm 1 70 0.4\n",
      "验证集最优结果： 31.014141082763672 30.951675415039062\n",
      "------------train------------\n",
      " (0.7401656402978196, 0.3651086028862859)\n",
      "------------test------------\n",
      " (0.6967133022429491, 0.29786808794137243)\n",
      "------------oot------------\n",
      " (0.6826307070285801, 0.2921836443888367)\n",
      "隐藏层vs神经元数vs norm 1 70 0.5\n",
      "验证集最优结果： 38.1684684753418 38.04667663574219\n",
      "------------train------------\n",
      " (0.6906895858586474, 0.2938451032426217)\n",
      "------------test------------\n",
      " (0.6753242282922496, 0.2977459471463469)\n",
      "------------oot------------\n",
      " (0.652228362237746, 0.2422062350119904)\n",
      "隐藏层vs神经元数vs norm 1 70 0.6\n",
      "验证集最优结果： 45.465606689453125 45.300193786621094\n",
      "------------train------------\n",
      " (0.7061719521447488, 0.3020966620847233)\n",
      "------------test------------\n",
      " (0.6760737286253609, 0.26738840772818123)\n",
      "------------oot------------\n",
      " (0.6535687392115294, 0.24110103221770413)\n",
      "隐藏层vs神经元数vs norm 1 70 0.8\n",
      "验证集最优结果： 57.53318405151367 57.48421096801758\n",
      "------------train------------\n",
      " (0.5572891815376786, 0.11306165184133887)\n",
      "------------test------------\n",
      " (0.5839928936264713, 0.15390850544081724)\n",
      "------------oot------------\n",
      " (0.560040083874929, 0.11404441664060055)\n",
      "隐藏层vs神经元数vs norm 1 72 0.0001\n",
      "验证集最优结果： 0.3167017102241516 1.6055529117584229\n",
      "------------train------------\n",
      " (0.9998213245132616, 0.9902203596656333)\n",
      "------------test------------\n",
      " (0.6801088163446591, 0.28900732844770155)\n",
      "------------oot------------\n",
      " (0.6513977224017888, 0.2416640600563028)\n",
      "隐藏层vs神经元数vs norm 1 72 0.001\n",
      "验证集最优结果： 0.5719653964042664 0.9863525629043579\n",
      "------------train------------\n",
      " (0.9732817881626137, 0.8332731657167763)\n",
      "------------test------------\n",
      " (0.6813391072618254, 0.28160115478569847)\n",
      "------------oot------------\n",
      " (0.6411357870225559, 0.23240538004379102)\n",
      "隐藏层vs神经元数vs norm 1 72 0.01\n",
      "验证集最优结果： 1.4416720867156982 1.4677183628082275\n",
      "------------train------------\n",
      " (0.7636184899349526, 0.4003057787307137)\n",
      "------------test------------\n",
      " (0.6883766377970242, 0.317288474350433)\n",
      "------------oot------------\n",
      " (0.6820167054761987, 0.29821707851110424)\n",
      "隐藏层vs神经元数vs norm 1 72 0.02\n",
      "验证集最优结果： 2.216801643371582 2.24448299407959\n",
      "------------train------------\n",
      " (0.76512938067963, 0.39828796397252453)\n",
      "------------test------------\n",
      " (0.7008560959360426, 0.33397734843437704)\n",
      "------------oot------------\n",
      " (0.7013125731299019, 0.32169742466896045)\n",
      "隐藏层vs神经元数vs norm 1 72 0.05\n",
      "验证集最优结果： 4.455649375915527 4.4640045166015625\n",
      "------------train------------\n",
      " (0.7649425158997496, 0.39946735754521534)\n",
      "------------test------------\n",
      " (0.6988985121030424, 0.33816344659116143)\n",
      "------------oot------------\n",
      " (0.6877466143027606, 0.2736940882076947)\n",
      "隐藏层vs神经元数vs norm 1 72 0.1\n",
      "验证集最优结果： 8.514252662658691 8.52393913269043\n",
      "------------train------------\n",
      " (0.7839472257585078, 0.429545209974153)\n",
      "------------test------------\n",
      " (0.7219875638463247, 0.34769042860315347)\n",
      "------------oot------------\n",
      " (0.7035739524322571, 0.3221075313662114)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 1 72 0.2\n",
      "验证集最优结果： 15.698210716247559 15.697656631469727\n",
      "------------train------------\n",
      " (0.7613064697446226, 0.38967783591499106)\n",
      "------------test------------\n",
      " (0.7163757495003331, 0.3331001554519209)\n",
      "------------oot------------\n",
      " (0.7153071745502149, 0.3159489799464776)\n",
      "隐藏层vs神经元数vs norm 1 72 0.3\n",
      "验证集最优结果： 24.221439361572266 24.17070960998535\n",
      "------------train------------\n",
      " (0.7687741575687681, 0.3962258864233026)\n",
      "------------test------------\n",
      " (0.7148656451254719, 0.3418054630246502)\n",
      "------------oot------------\n",
      " (0.7146398822970609, 0.30616897786118935)\n",
      "隐藏层vs神经元数vs norm 1 72 0.4\n",
      "验证集最优结果： 31.6763973236084 31.56182861328125\n",
      "------------train------------\n",
      " (0.752562741152687, 0.3792833894739835)\n",
      "------------test------------\n",
      " (0.7033100155451921, 0.3269487008660893)\n",
      "------------oot------------\n",
      " (0.6717258077595895, 0.2808535780071595)\n",
      "隐藏层vs神经元数vs norm 1 72 0.5\n",
      "验证集最优结果： 39.627593994140625 39.55103302001953\n",
      "------------train------------\n",
      " (0.7475914341347336, 0.365214048495505)\n",
      "------------test------------\n",
      " (0.7065756162558294, 0.3487785920497446)\n",
      "------------oot------------\n",
      " (0.7044717848909278, 0.311187571681785)\n",
      "隐藏层vs神经元数vs norm 1 72 0.6\n",
      "验证集最优结果： 46.9746208190918 46.83388137817383\n",
      "------------train------------\n",
      " (0.7044738582196477, 0.2904842444091154)\n",
      "------------test------------\n",
      " (0.6756340217632689, 0.27694870086608925)\n",
      "------------oot------------\n",
      " (0.6633811791146793, 0.26453967260973826)\n",
      "隐藏层vs神经元数vs norm 1 72 0.8\n",
      "验证集最优结果： 59.47977066040039 59.42231369018555\n",
      "------------train------------\n",
      " (0.6723059086765223, 0.25100521881317517)\n",
      "------------test------------\n",
      " (0.6367566067066399, 0.20233177881412392)\n",
      "------------oot------------\n",
      " (0.6484505149503585, 0.21872588885413408)\n",
      "隐藏层vs神经元数vs norm 1 74 0.0001\n",
      "验证集最优结果： 0.34747108817100525 1.3124604225158691\n",
      "------------train------------\n",
      " (0.9977582994425189, 0.9540743086984507)\n",
      "------------test------------\n",
      " (0.6704785698423272, 0.251021541194759)\n",
      "------------oot------------\n",
      " (0.6347304764883746, 0.22098495116949923)\n",
      "隐藏层vs神经元数vs norm 1 74 0.001\n",
      "验证集最优结果： 0.5417913198471069 1.0050541162490845\n",
      "------------train------------\n",
      " (0.9762509145274676, 0.8421197680738038)\n",
      "------------test------------\n",
      " (0.682938041305796, 0.2779813457694871)\n",
      "------------oot------------\n",
      " (0.6509702383021119, 0.24374934834740905)\n",
      "隐藏层vs神经元数vs norm 1 74 0.01\n",
      "验证集最优结果： 1.4515106678009033 1.4812268018722534\n",
      "------------train------------\n",
      " (0.7587886343440002, 0.39405633286160296)\n",
      "------------test------------\n",
      " (0.6857961359093937, 0.30385298689762374)\n",
      "------------oot------------\n",
      " (0.675091231362736, 0.2808605289681299)\n",
      "隐藏层vs神经元数vs norm 1 74 0.02\n",
      "验证集最优结果： 2.2547366619110107 2.285932779312134\n",
      "------------train------------\n",
      " (0.7624744930590666, 0.3966268233867262)\n",
      "------------test------------\n",
      " (0.6978836331334666, 0.3342993559848989)\n",
      "------------oot------------\n",
      " (0.6982958560687682, 0.31524693288847183)\n",
      "隐藏层vs神经元数vs norm 1 74 0.05\n",
      "验证集最优结果： 4.601342678070068 4.613629341125488\n",
      "------------train------------\n",
      " (0.7755317456933455, 0.4056005289877289)\n",
      "------------test------------\n",
      " (0.7013046857650456, 0.3075172107483899)\n",
      "------------oot------------\n",
      " (0.6950103685167808, 0.29465123553331246)\n",
      "隐藏层vs神经元数vs norm 1 74 0.1\n",
      "验证集最优结果： 8.521745681762695 8.527099609375\n",
      "------------train------------\n",
      " (0.7568244899119414, 0.3979195134612352)\n",
      "------------test------------\n",
      " (0.7138951809904508, 0.34752387297357323)\n",
      "------------oot------------\n",
      " (0.6914051367601571, 0.3069752893337504)\n",
      "隐藏层vs神经元数vs norm 1 74 0.2\n",
      "验证集最优结果： 16.279521942138672 16.278486251831055\n",
      "------------train------------\n",
      " (0.765209852328771, 0.3889448603387118)\n",
      "------------test------------\n",
      " (0.7138907395069953, 0.337119697979125)\n",
      "------------oot------------\n",
      " (0.7065188428966971, 0.30539047023250965)\n",
      "隐藏层vs神经元数vs norm 1 74 0.3\n",
      "验证集最优结果： 24.091737747192383 24.038787841796875\n",
      "------------train------------\n",
      " (0.7704788164644047, 0.4014319757380347)\n",
      "------------test------------\n",
      " (0.7208683100155451, 0.335531867643793)\n",
      "------------oot------------\n",
      " (0.7086551049015859, 0.3297049317068085)\n",
      "隐藏层vs神经元数vs norm 1 74 0.4\n",
      "验证集最优结果： 31.982955932617188 31.97044563293457\n",
      "------------train------------\n",
      " (0.7411470695528172, 0.34661731433146603)\n",
      "------------test------------\n",
      " (0.6917033089051743, 0.3109704641350211)\n",
      "------------oot------------\n",
      " (0.676466363141371, 0.2494977930698919)\n",
      "隐藏层vs神经元数vs norm 1 74 0.5\n",
      "验证集最优结果： 40.398948669433594 40.29726028442383\n",
      "------------train------------\n",
      " (0.7235860440908837, 0.3255476843589239)\n",
      "------------test------------\n",
      " (0.7017910282034199, 0.30157672662669327)\n",
      "------------oot------------\n",
      " (0.6946859903381642, 0.29362249330970003)\n",
      "隐藏层vs神经元数vs norm 1 74 0.6\n",
      "验证集最优结果： 48.22600555419922 48.114444732666016\n",
      "------------train------------\n",
      " (0.7215702597359528, 0.3256391878657687)\n",
      "------------test------------\n",
      " (0.6806218076837663, 0.27310681767710415)\n",
      "------------oot------------\n",
      " (0.6897484910622227, 0.2826330240155701)\n",
      "隐藏层vs神经元数vs norm 1 74 0.8\n",
      "验证集最优结果： 60.58393096923828 60.544952392578125\n",
      "------------train------------\n",
      " (0.7121975122145675, 0.29807781723528115)\n",
      "------------test------------\n",
      " (0.6836497890295359, 0.28432156340217635)\n",
      "------------oot------------\n",
      " (0.6552972115061574, 0.2304591109720919)\n",
      "隐藏层vs神经元数vs norm 1 76 0.0001\n",
      "验证集最优结果： 0.31877458095550537 1.3995397090911865\n",
      "------------train------------\n",
      " (0.9974771562713404, 0.9635041782315052)\n",
      "------------test------------\n",
      " (0.6873584277148568, 0.2889073950699534)\n",
      "------------oot------------\n",
      " (0.6510582838077363, 0.2338094741598026)\n",
      "隐藏层vs神经元数vs norm 1 76 0.001\n",
      "验证集最优结果： 0.6117709875106812 1.0065333843231201\n",
      "------------train------------\n",
      " (0.9329491810368458, 0.7309189131386717)\n",
      "------------test------------\n",
      " (0.6876660004441484, 0.3028869642460582)\n",
      "------------oot------------\n",
      " (0.648146989654653, 0.24392312237166786)\n",
      "隐藏层vs神经元数vs norm 1 76 0.01\n",
      "验证集最优结果： 1.4884862899780273 1.520260214805603\n",
      "------------train------------\n",
      " (0.7550173633318649, 0.3966002927841498)\n",
      "------------test------------\n",
      " (0.6829025094381524, 0.2970575172107484)\n",
      "------------oot------------\n",
      " (0.6763424043373997, 0.2840371181315816)\n",
      "隐藏层vs神经元数vs norm 1 76 0.02\n",
      "验证集最优结果： 2.299150228500366 2.3267245292663574\n",
      "------------train------------\n",
      " (0.7629587442361927, 0.3924207753568603)\n",
      "------------test------------\n",
      " (0.6989118365534089, 0.329569176104819)\n",
      "------------oot------------\n",
      " (0.6993906324215988, 0.32369930142842246)\n",
      "隐藏层vs神经元数vs norm 1 76 0.05\n",
      "验证集最优结果： 4.685292720794678 4.693967342376709\n",
      "------------train------------\n",
      " (0.784642097433638, 0.4248298014468654)\n",
      "------------test------------\n",
      " (0.7193959582500555, 0.36449033977348433)\n",
      "------------oot------------\n",
      " (0.6999362828577718, 0.311757550481354)\n",
      "隐藏层vs神经元数vs norm 1 76 0.1\n",
      "验证集最优结果： 8.83027458190918 8.833765983581543\n",
      "------------train------------\n",
      " (0.7551628755653828, 0.3949430776446511)\n",
      "------------test------------\n",
      " (0.7124761270264268, 0.34391516766600044)\n",
      "------------oot------------\n",
      " (0.6913866008642362, 0.3053348625447468)\n",
      "隐藏层vs神经元数vs norm 1 76 0.2\n",
      "验证集最优结果： 16.96142578125 16.954679489135742\n",
      "------------train------------\n",
      " (0.7654653447387852, 0.39466125767238636)\n",
      "------------test------------\n",
      " (0.716164779036198, 0.3292915833888519)\n",
      "------------oot------------\n",
      " (0.7063346424309829, 0.3062245855489521)\n",
      "隐藏层vs神经元数vs norm 1 76 0.3\n",
      "验证集最优结果： 24.723186492919922 24.718536376953125\n",
      "------------train------------\n",
      " (0.761177674497932, 0.3845180397945503)\n",
      "------------test------------\n",
      " (0.710634021763269, 0.32103042416167)\n",
      "------------oot------------\n",
      " (0.7146584181929819, 0.33449414381538245)\n",
      "隐藏层vs神经元数vs norm 1 76 0.4\n",
      "验证集最优结果： 32.25242614746094 32.19064712524414\n",
      "------------train------------\n",
      " (0.7354379816708729, 0.3369991587362499)\n",
      "------------test------------\n",
      " (0.6925993781923163, 0.2824117255163225)\n",
      "------------oot------------\n",
      " (0.6792293701270867, 0.2646022312584715)\n",
      "隐藏层vs神经元数vs norm 1 76 0.5\n",
      "验证集最优结果： 40.68405532836914 40.59757614135742\n",
      "------------train------------\n",
      " (0.745071026889984, 0.357541831383131)\n",
      "------------test------------\n",
      " (0.6965356429047302, 0.316833222296247)\n",
      "------------oot------------\n",
      " (0.6750425746359434, 0.2744239391095819)\n",
      "隐藏层vs神经元数vs norm 1 76 0.6\n",
      "验证集最优结果： 47.7652702331543 47.690879821777344\n",
      "------------train------------\n",
      " (0.7466385658855705, 0.35957737832977676)\n",
      "------------test------------\n",
      " (0.7139584721296913, 0.3444037308461026)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.700019694389416, 0.3135856532165572)\n",
      "隐藏层vs神经元数vs norm 1 76 0.8\n",
      "验证集最优结果： 62.52644729614258 62.46369171142578\n",
      "------------train------------\n",
      " (0.6506806250122671, 0.21137337153198663)\n",
      "------------test------------\n",
      " (0.623310015545192, 0.1776371308016878)\n",
      "------------oot------------\n",
      " (0.6263568855060879, 0.19224967851805508)\n",
      "隐藏层vs神经元数vs norm 1 78 0.0001\n",
      "验证集最优结果： 0.32889437675476074 1.4743146896362305\n",
      "------------train------------\n",
      " (0.997504837435763, 0.9663633920999716)\n",
      "------------test------------\n",
      " (0.6767355096602264, 0.2666444592493893)\n",
      "------------oot------------\n",
      " (0.6386635619040999, 0.21821846870329825)\n",
      "隐藏层vs神经元数vs norm 1 78 0.001\n",
      "验证集最优结果： 0.5688557028770447 0.9392668604850769\n",
      "------------train------------\n",
      " (0.9605607703079241, 0.7816083365650586)\n",
      "------------test------------\n",
      " (0.6519475904952253, 0.2281479013990673)\n",
      "------------oot------------\n",
      " (0.6243144614742988, 0.21557015257359324)\n",
      "隐藏层vs神经元数vs norm 1 78 0.01\n",
      "验证集最优结果： 1.5060349702835083 1.532899022102356\n",
      "------------train------------\n",
      " (0.7543563993911497, 0.39110060715825434)\n",
      "------------test------------\n",
      " (0.6802953586497891, 0.2955141017099711)\n",
      "------------oot------------\n",
      " (0.666124491710979, 0.2757724255378306)\n",
      "隐藏层vs神经元数vs norm 1 78 0.02\n",
      "验证集最优结果： 2.34458327293396 2.373528480529785\n",
      "------------train------------\n",
      " (0.7575689711066849, 0.3912168815848516)\n",
      "------------test------------\n",
      " (0.6899444814568066, 0.3110926049300466)\n",
      "------------oot------------\n",
      " (0.6841738203639987, 0.2956799777569249)\n",
      "隐藏层vs神经元数vs norm 1 78 0.05\n",
      "验证集最优结果： 4.896852493286133 4.909575462341309\n",
      "------------train------------\n",
      " (0.7841415353503358, 0.4282230113722886)\n",
      "------------test------------\n",
      " (0.7183821896513435, 0.3694536975349767)\n",
      "------------oot------------\n",
      " (0.6965766517221006, 0.3200917526848087)\n",
      "隐藏层vs神经元数vs norm 1 78 0.1\n",
      "验证集最优结果： 8.970107078552246 8.96373462677002\n",
      "------------train------------\n",
      " (0.7734982968300668, 0.407921821352939)\n",
      "------------test------------\n",
      " (0.7270575172107484, 0.3618476571174773)\n",
      "------------oot------------\n",
      " (0.708497549786258, 0.32240642268793657)\n",
      "隐藏层vs神经元数vs norm 1 78 0.2\n",
      "验证集最优结果： 17.10573959350586 17.088336944580078\n",
      "------------train------------\n",
      " (0.7722076371588161, 0.40640741124261354)\n",
      "------------test------------\n",
      " (0.717406173662003, 0.35169886742171885)\n",
      "------------oot------------\n",
      " (0.7145402518564858, 0.3269106453967261)\n",
      "隐藏层vs神经元数vs norm 1 78 0.3\n",
      "验证集最优结果： 25.086719512939453 25.068805694580078\n",
      "------------train------------\n",
      " (0.7572053935632155, 0.37922328953753504)\n",
      "------------test------------\n",
      " (0.7058594270486342, 0.33544303797468356)\n",
      "------------oot------------\n",
      " (0.7085102932147036, 0.31617836165849933)\n",
      "隐藏层vs神经元数vs norm 1 78 0.4\n",
      "验证集最优结果： 34.312286376953125 34.21794509887695\n",
      "------------train------------\n",
      " (0.737421888694647, 0.35744031122021147)\n",
      "------------test------------\n",
      " (0.6993382189651344, 0.3091272485009993)\n",
      "------------oot------------\n",
      " (0.6784612889398626, 0.2760643658985855)\n",
      "隐藏层vs神经元数vs norm 1 78 0.5\n",
      "验证集最优结果： 41.156436920166016 41.144615173339844\n",
      "------------train------------\n",
      " (0.7478120712888121, 0.3631085203165534)\n",
      "------------test------------\n",
      " (0.6969786808794137, 0.31084832333999557)\n",
      "------------oot------------\n",
      " (0.6865892793011967, 0.2925103395544434)\n",
      "隐藏层vs神经元数vs norm 1 78 0.6\n",
      "验证集最优结果： 48.369606018066406 48.317955017089844\n",
      "------------train------------\n",
      " (0.7086026155654775, 0.32687570345012884)\n",
      "------------test------------\n",
      " (0.6697623806351322, 0.2923828558738618)\n",
      "------------oot------------\n",
      " (0.6695327795734427, 0.2500955757133424)\n",
      "隐藏层vs神经元数vs norm 1 78 0.8\n",
      "验证集最优结果： 63.576053619384766 63.584503173828125\n",
      "------------train------------\n",
      " (0.7104845963456803, 0.30477733582666855)\n",
      "------------test------------\n",
      " (0.6712413946258051, 0.24971130357539423)\n",
      "------------oot------------\n",
      " (0.6768556169557107, 0.26638862822785253)\n",
      "隐藏层vs神经元数vs norm 1 80 0.0001\n",
      "验证集最优结果： 0.33953070640563965 1.473177194595337\n",
      "------------train------------\n",
      " (0.99955155160033, 0.9829008912793503)\n",
      "------------test------------\n",
      " (0.6702931379080612, 0.2567954696868754)\n",
      "------------oot------------\n",
      " (0.6439358658001135, 0.24060751398880892)\n",
      "隐藏层vs神经元数vs norm 1 80 0.001\n",
      "验证集最优结果： 0.6399142146110535 1.0001932382583618\n",
      "------------train------------\n",
      " (0.9467583596778157, 0.7615721818510375)\n",
      "------------test------------\n",
      " (0.692998001332445, 0.31245836109260494)\n",
      "------------oot------------\n",
      " (0.6573593299273625, 0.26027178257394085)\n",
      "隐藏层vs神经元数vs norm 1 80 0.01\n",
      "验证集最优结果： 1.5300469398498535 1.5569672584533691\n",
      "------------train------------\n",
      " (0.7613675172025915, 0.39672144017856714)\n",
      "------------test------------\n",
      " (0.6865356429047301, 0.32889184987785924)\n",
      "------------oot------------\n",
      " (0.6809786953046257, 0.2961109373370869)\n",
      "隐藏层vs神经元数vs norm 1 80 0.02\n",
      "验证集最优结果： 2.360805034637451 2.3841006755828857\n",
      "------------train------------\n",
      " (0.7526784741384153, 0.3839151453870253)\n",
      "------------test------------\n",
      " (0.7052254052853653, 0.30524095047745947)\n",
      "------------oot------------\n",
      " (0.6942735666539233, 0.306634692246203)\n",
      "隐藏层vs神经元数vs norm 1 80 0.05\n"
     ]
    }
   ],
   "source": [
    "def model_metrics2(nnmodel, x, y):\n",
    "    yprob = nnmodel.predict(x)\n",
    "    fpr,tpr,_ = roc_curve(y, yprob,pos_label=1)\n",
    "    return auc(fpr, tpr),max(tpr-fpr)\n",
    "\n",
    "np.random.seed(42) # 固定随机种子，使每次运行结果固定\n",
    "random.set_seed(42)\n",
    "\n",
    "bestval = 0\n",
    "# 创建模型结构：输入层的特征维数为13；1层k个神经元的relu隐藏层；线性的输出层；\n",
    "for layer_nums in range(1,6):\n",
    "    for k in list(range(1,20,1)) + list(range(20,100,2)) + list(range(100,1000,30)):  # 网格搜索超参数：神经元数,5,10,100\n",
    "        for norm in [0.0001,0.001,0.01,0.02,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.8]:\n",
    "            print(\"隐藏层vs神经元数vs norm\",layer_nums,k,norm)\n",
    "            model = Sequential()\n",
    "            model.add(BatchNormalization())  # 输入层 批标准化  input_dim=train_x.shape\n",
    "            for _ in range(layer_nums):\n",
    "                model.add(Dense(k,  \n",
    "                                kernel_initializer='random_uniform',   # 均匀初始化\n",
    "                                activation='relu',                     # relu激活函数\n",
    "                                kernel_regularizer=regularizers.l1_l2(l1=norm, l2=norm),  # L1及L2 正则项\n",
    "                                use_bias=True))   # 隐藏层1\n",
    "                model.add(Dropout(norm)) # dropout正则\n",
    "            model.add(Dense(1,use_bias=True,activation='sigmoid'))  # 输出层\n",
    "\n",
    "\n",
    "\n",
    "            # 编译模型：优化目标为回归预测损失mse，优化算法为adam\n",
    "            model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy) \n",
    "\n",
    "            # 训练模型\n",
    "            history = model.fit(train_x, \n",
    "                                train_y, \n",
    "                                epochs=1000,              # 训练迭代次数\n",
    "                                batch_size=1000,           # 每epoch采样的batch大小\n",
    "                                validation_data=(test_x,test_y),   # 从训练集再拆分验证集，作为早停的衡量指标\n",
    "                                callbacks=[EarlyStopping(monitor='val_loss', patience=10)],    #早停法\n",
    "                                verbose=False,shuffle=True,use_multiprocessing=True,workers=16)  # 不输出过程  \n",
    "            print(\"验证集最优结果：\",min(history.history['loss']),min(history.history['val_loss']))\n",
    "            print('------------train------------\\n',model_metrics2(model, train_x,train_y))\n",
    "\n",
    "            print('------------test------------\\n',model_metrics2(model, test_x,test_y))\n",
    "\n",
    "            print('------------oot------------\\n',model_metrics2(model, oot_x,oot_y))\n",
    "            if model_metrics2(model, test_x,test_y)[0] > bestval: # 仅以test调参\n",
    "                bestval = model_metrics2(model, oot_x,oot_y)[0]\n",
    "                best_paras = ['bestval, layer_nums, k, norm',bestval, layer_nums, k, norm]\n",
    "\n",
    "# 模型评估：拟合效果\n",
    "plt.plot(history.history['loss'],c='blue')    # 蓝色线训练集损失\n",
    "plt.plot(history.history['val_loss'],c='red') # 红色线验证集损失\n",
    "plt.show()\n",
    "model.summary()   #模型概述信息\n",
    "print(best_paras)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950655c6",
   "metadata": {},
   "source": [
    "####  autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb24599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./data/automodel\"\n",
      "Presets specified: ['best_quality']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (7671 samples, 108.19 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./data/automodel/\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    7671\n",
      "Train Data Columns: 1761\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1.0, 0.0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    115523.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 108.07 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 57): ['Amount_Past_Due35_sum_30', 'Amount_Past_Due35_min_30', 'Days_Past_Due58_max_30', 'Days_Past_Due58_min_30', 'Duecount53_std_30', 'feature_7', 'feature_10', 'feature_13', 'feature_14', 'feature_17', 'feature_264', 'feature_265', 'feature_266', 'feature_267', 'feature_268', 'feature_269', 'feature_270', 'feature_271', 'feature_306', 'feature_307', 'feature_308', 'feature_309', 'feature_327', 'feature_328', 'feature_338', 'feature_339', 'feature_341', 'feature_342', 'feature_361', 'feature_362', 'feature_363', 'feature_364', 'feature_365', 'feature_366', 'feature_367', 'feature_368', 'feature_507', 'feature_508', 'feature_509', 'feature_510', 'feature_511', 'feature_512', 'feature_513', 'feature_514', 'feature_531', 'feature_532', 'feature_533', 'feature_534', 'feature_547', 'feature_548', 'feature_549', 'feature_550', 'feature_551', 'feature_552', 'feature_553', 'feature_554', 'feature_589']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1051 | ['BureauScore', 'MissingRate', 'Tel_nuniq', 'Email_nuniq', 'City_nuniq', ...]\n",
      "\t\t('int', [])   :  653 | ['Len_Name', 'Len_of_addrs', 'Current_State', 'CreditAccountActive', 'CreditAccountTotal', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 1049 | ['BureauScore', 'MissingRate', 'Tel_nuniq', 'Email_nuniq', 'City_nuniq', ...]\n",
      "\t\t('int', [])       :  651 | ['Len_Name', 'Len_of_addrs', 'Current_State', 'CreditAccountActive', 'CreditAccountTotal', ...]\n",
      "\t\t('int', ['bool']) :    4 | ['Number_of_Major_Credit_Card_Held62_sum_7', 'feature_6', 'feature_593', 'feature_1300_sms']\n",
      "\t2.4s = Fit runtime\n",
      "\t1704 features in original data used to generate 1704 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 104.36 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.74s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t0.5138\t = Validation score   (roc_auc)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t5.39s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t0.515\t = Validation score   (roc_auc)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t5.41s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.7237\t = Validation score   (roc_auc)\n",
      "\t39.11s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.7236\t = Validation score   (roc_auc)\n",
      "\t40.06s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.6408\t = Validation score   (roc_auc)\n",
      "\t3.25s\t = Training   runtime\n",
      "\t4.28s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.6445\t = Validation score   (roc_auc)\n",
      "\t4.24s\t = Training   runtime\n",
      "\t4.35s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\t0.7292\t = Validation score   (roc_auc)\n",
      "\t106.96s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.6362\t = Validation score   (roc_auc)\n",
      "\t1.99s\t = Training   runtime\n",
      "\t4.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.6445\t = Validation score   (roc_auc)\n",
      "\t2.1s\t = Training   runtime\n",
      "\t4.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tfuture feature annotations is not defined (dispatch.py, line 4)\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 962, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 934, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 189, in _fit\n",
      "    n_repeats=n_repeats, n_repeat_start=n_repeat_start, save_folds=save_bag_folds, groups=groups, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 388, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 59, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(*job)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 64, in _fit_fold_model\n",
      "    fold_model = self._fit(model_base, time_start_fold, time_limit_fold, fold_ctx, kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 111, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 163, in _fit\n",
      "    try_import_fastai()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/utils/try_import.py\", line 107, in try_import_fastai\n",
      "    import autogluon.tabular.models.fastainn.imports_helper\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "    from fastai.tabular.all import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "    from ..basics import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "    from .data.all import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "    from ..torch_basics import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "    from .imports import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/imports.py\", line 30, in <module>\n",
      "    from fastcore.all import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastcore/all.py\", line 3, in <module>\n",
      "    from .dispatch import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastcore/dispatch.py\", line 4\n",
      "    from __future__ import annotations\n",
      "                                     ^\n",
      "SyntaxError: future feature annotations is not defined\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\t0.7227\t = Validation score   (roc_auc)\n",
      "\t154.98s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ...\n",
      "\tWarning: Exception caused NeuralNetMXNet_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tlibquadmath.so.0: cannot open shared object file: No such file or directory\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 962, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 934, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 189, in _fit\n",
      "    n_repeats=n_repeats, n_repeat_start=n_repeat_start, save_folds=save_bag_folds, groups=groups, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 388, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 59, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(*job)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 64, in _fit_fold_model\n",
      "    fold_model = self._fit(model_base, time_start_fold, time_limit_fold, fold_ctx, kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 111, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/models/tabular_nn/tabular_nn_model.py\", line 168, in _fit\n",
      "    try_import_mxnet()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/utils/try_import.py\", line 31, in try_import_mxnet\n",
      "    import mxnet as mx\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/__init__.py\", line 23, in <module>\n",
      "    from .context import Context, current_context, cpu, gpu, cpu_pinned\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/context.py\", line 23, in <module>\n",
      "    from .base import classproperty, with_metaclass, _MXClassPropertyMetaClass\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/base.py\", line 356, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/base.py\", line 347, in _load_lib\n",
      "    lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)\n",
      "  File \"/usr/lib64/python3.6/ctypes/__init__.py\", line 343, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: libquadmath.so.0: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.7163\t = Validation score   (roc_auc)\n",
      "\t121.76s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7335\t = Validation score   (roc_auc)\n",
      "\t2.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 11 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.7221\t = Validation score   (roc_auc)\n",
      "\t31.46s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.714\t = Validation score   (roc_auc)\n",
      "\t37.63s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ...\n",
      "\t0.7073\t = Validation score   (roc_auc)\n",
      "\t3.13s\t = Training   runtime\n",
      "\t4.38s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ...\n",
      "\t0.7088\t = Validation score   (roc_auc)\n",
      "\t4.19s\t = Training   runtime\n",
      "\t4.41s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\t0.7278\t = Validation score   (roc_auc)\n",
      "\t72.99s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ...\n",
      "\t0.6907\t = Validation score   (roc_auc)\n",
      "\t1.99s\t = Training   runtime\n",
      "\t4.4s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ...\n",
      "\t0.695\t = Validation score   (roc_auc)\n",
      "\t2.22s\t = Training   runtime\n",
      "\t4.27s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tfuture feature annotations is not defined (dispatch.py, line 4)\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 962, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 934, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 189, in _fit\n",
      "    n_repeats=n_repeats, n_repeat_start=n_repeat_start, save_folds=save_bag_folds, groups=groups, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 388, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 59, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(*job)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 64, in _fit_fold_model\n",
      "    fold_model = self._fit(model_base, time_start_fold, time_limit_fold, fold_ctx, kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 111, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 163, in _fit\n",
      "    try_import_fastai()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/utils/try_import.py\", line 107, in try_import_fastai\n",
      "    import autogluon.tabular.models.fastainn.imports_helper\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "    from fastai.tabular.all import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "    from ..basics import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "    from .data.all import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "    from ..torch_basics import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "    from .imports import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/imports.py\", line 30, in <module>\n",
      "    from fastcore.all import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastcore/all.py\", line 3, in <module>\n",
      "    from .dispatch import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastcore/dispatch.py\", line 4\n",
      "    from __future__ import annotations\n",
      "                                     ^\n",
      "SyntaxError: future feature annotations is not defined\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\t0.7129\t = Validation score   (roc_auc)\n",
      "\t156.48s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L2 ...\n",
      "\tWarning: Exception caused NeuralNetMXNet_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tlibquadmath.so.0: cannot open shared object file: No such file or directory\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 962, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 934, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 189, in _fit\n",
      "    n_repeats=n_repeats, n_repeat_start=n_repeat_start, save_folds=save_bag_folds, groups=groups, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 388, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 59, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(*job)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 64, in _fit_fold_model\n",
      "    fold_model = self._fit(model_base, time_start_fold, time_limit_fold, fold_ctx, kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 111, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/models/tabular_nn/tabular_nn_model.py\", line 168, in _fit\n",
      "    try_import_mxnet()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/utils/try_import.py\", line 31, in try_import_mxnet\n",
      "    import mxnet as mx\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/__init__.py\", line 23, in <module>\n",
      "    from .context import Context, current_context, cpu, gpu, cpu_pinned\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/context.py\", line 23, in <module>\n",
      "    from .base import classproperty, with_metaclass, _MXClassPropertyMetaClass\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/base.py\", line 356, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/base.py\", line 347, in _load_lib\n",
      "    lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)\n",
      "  File \"/usr/lib64/python3.6/ctypes/__init__.py\", line 343, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: libquadmath.so.0: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.7077\t = Validation score   (roc_auc)\n",
      "\t117.45s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7283\t = Validation score   (roc_auc)\n",
      "\t2.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 976.95s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./data/automodel/\")\n",
      "Evaluation: roc_auc on test data: 0.7300130909764941\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"roc_auc\": 0.7300130909764941,\n",
      "    \"accuracy\": 0.7210743801652892,\n",
      "    \"balanced_accuracy\": 0.5380148055468669,\n",
      "    \"mcc\": 0.15257391971809992,\n",
      "    \"f1\": 0.8318804483188045,\n",
      "    \"precision\": 0.7292576419213974,\n",
      "    \"recall\": 0.9681159420289855\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  \n",
      "              0         1\n",
      "0     0.314340  0.685660\n",
      "1789  0.086377  0.913623\n",
      "3921  0.225109  0.774891\n",
      "3922  0.075995  0.924005\n",
      "3923  0.105877  0.894123\n",
      "...        ...       ...\n",
      "8714  0.366803  0.633197\n",
      "8718  0.340966  0.659034\n",
      "8721  0.456564  0.543436\n",
      "8723  0.286990  0.713010\n",
      "8724  0.581488  0.418512\n",
      "\n",
      "[1452 rows x 2 columns]\n",
      "0.7300130909764941 0.3458033573141487\n",
      "{'roc_auc': 0.7300130909764941, 'accuracy': 0.7210743801652892, 'balanced_accuracy': 0.5380148055468669, 'mcc': 0.15257391971809992, 'f1': 0.8318804483188045, 'precision': 0.7292576419213974, 'recall': 0.9681159420289855}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n",
      "Computing feature importance via permutation shuffling for 1761 features using 1000 rows with 3 shuffle sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L2   0.733550      10.295661  347.655579                0.002392           2.456590            2       True         12\n",
      "1           CatBoost_BAG_L1   0.729190       0.800230  106.959460                0.800230         106.959460            1       True          7\n",
      "2       WeightedEnsemble_L3   0.728325      40.298569  743.484664                0.002392           2.033625            3       True         22\n",
      "3           CatBoost_BAG_L2   0.727775      30.894764  548.392217                0.932192          72.991360            2       True         17\n",
      "4         LightGBMXT_BAG_L1   0.723712       0.242499   39.105738                0.242499          39.105738            1       True          3\n",
      "5           LightGBM_BAG_L1   0.723562       0.254709   40.058334                0.254709          40.058334            1       True          4\n",
      "6            XGBoost_BAG_L1   0.722663       0.384475  154.984993                0.384475         154.984993            1       True         10\n",
      "7         LightGBMXT_BAG_L2   0.722149      30.197714  506.859643                0.235142          31.458786            2       True         13\n",
      "8      LightGBMLarge_BAG_L1   0.716333       0.236607  121.761869                0.236607         121.761869            1       True         11\n",
      "9           LightGBM_BAG_L2   0.714032      30.200924  513.031050                0.238351          37.630194            2       True         14\n",
      "10           XGBoost_BAG_L2   0.712854      30.347161  631.881180                0.384589         156.480323            2       True         20\n",
      "11  RandomForestEntr_BAG_L2   0.708833      34.371543  479.589384                4.408971           4.188527            2       True         16\n",
      "12     LightGBMLarge_BAG_L2   0.707741      30.201514  592.852427                0.238942         117.451570            2       True         21\n",
      "13  RandomForestGini_BAG_L2   0.707261      34.341073  478.528560                4.378501           3.127703            2       True         15\n",
      "14    ExtraTreesEntr_BAG_L2   0.694975      34.233581  477.616334                4.271009           2.215477            2       True         19\n",
      "15    ExtraTreesGini_BAG_L2   0.690716      34.365754  477.392866                4.403182           1.992009            2       True         18\n",
      "16    ExtraTreesEntr_BAG_L1   0.644539       4.352430    2.100752                4.352430           2.100752            1       True          9\n",
      "17  RandomForestEntr_BAG_L1   0.644479       4.345647    4.235652                4.345647           4.235652            1       True          6\n",
      "18  RandomForestGini_BAG_L1   0.640840       4.284757    3.249153                4.284757           3.249153            1       True          5\n",
      "19    ExtraTreesGini_BAG_L1   0.636168       4.258927    1.989712                4.258927           1.989712            1       True          8\n",
      "20    KNeighborsDist_BAG_L1   0.515038       5.409837    0.487729                5.409837           0.487729            1       True          2\n",
      "21    KNeighborsUnif_BAG_L1   0.513839       5.392455    0.467465                5.392455           0.467465            1       True          1\n",
      "Number of models trained: 22\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_LGB', 'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XT'}\n",
      "Bagging used: True  (with 10 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 1049 | ['BureauScore', 'MissingRate', 'Tel_nuniq', 'Email_nuniq', 'City_nuniq', ...]\n",
      "('int', [])       :  651 | ['Len_Name', 'Len_of_addrs', 'Current_State', 'CreditAccountActive', 'CreditAccountTotal', ...]\n",
      "('int', ['bool']) :    4 | ['Number_of_Major_Credit_Card_Held62_sum_7', 'feature_6', 'feature_593', 'feature_1300_sms']\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t10234.36s\t= Expected runtime (3411.45s per shuffle set)\n",
      "\t5970.57s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature_2</th>\n",
       "      <td>0.188764</td>\n",
       "      <td>0.028887</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>3</td>\n",
       "      <td>0.354291</td>\n",
       "      <td>0.023238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_Rating34_mean_9999</th>\n",
       "      <td>0.004409</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>-0.000388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_4</th>\n",
       "      <td>0.004160</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.017681</td>\n",
       "      <td>3</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>-0.003818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_1236_sms</th>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004452</td>\n",
       "      <td>0.001393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.078636</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015356</td>\n",
       "      <td>-0.009755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_256</th>\n",
       "      <td>-0.000378</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.991376</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>-0.000877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_32</th>\n",
       "      <td>-0.000397</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.968303</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>-0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_545</th>\n",
       "      <td>-0.000506</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.984164</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>-0.001423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_253</th>\n",
       "      <td>-0.000541</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.962814</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>-0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_254</th>\n",
       "      <td>-0.000902</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.966808</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>-0.003330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1761 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   importance    stddev  \\\n",
       "feature_2                                            0.188764  0.028887   \n",
       "Payment_Rating34_mean_9999                           0.004409  0.000837   \n",
       "feature_4                                            0.004160  0.001392   \n",
       "feature_1236_sms                                     0.002922  0.000267   \n",
       "Highest_Credit_or_Original_Loan_Amount58_sum_9999    0.002801  0.002191   \n",
       "...                                                       ...       ...   \n",
       "feature_256                                         -0.000378  0.000087   \n",
       "feature_32                                          -0.000397  0.000182   \n",
       "feature_545                                         -0.000506  0.000160   \n",
       "feature_253                                         -0.000541  0.000271   \n",
       "feature_254                                         -0.000902  0.000424   \n",
       "\n",
       "                                                    p_value  n  p99_high  \\\n",
       "feature_2                                          0.003858  3  0.354291   \n",
       "Payment_Rating34_mean_9999                         0.005901  3  0.009205   \n",
       "feature_4                                          0.017681  3  0.012138   \n",
       "feature_1236_sms                                   0.001385  3  0.004452   \n",
       "Highest_Credit_or_Original_Loan_Amount58_sum_9999  0.078636  3  0.015356   \n",
       "...                                                     ... ..       ...   \n",
       "feature_256                                        0.991376  3  0.000121   \n",
       "feature_32                                         0.968303  3  0.000645   \n",
       "feature_545                                        0.984164  3  0.000410   \n",
       "feature_253                                        0.962814  3  0.001011   \n",
       "feature_254                                        0.966808  3  0.001526   \n",
       "\n",
       "                                                    p99_low  \n",
       "feature_2                                          0.023238  \n",
       "Payment_Rating34_mean_9999                        -0.000388  \n",
       "feature_4                                         -0.003818  \n",
       "feature_1236_sms                                   0.001393  \n",
       "Highest_Credit_or_Original_Loan_Amount58_sum_9999 -0.009755  \n",
       "...                                                     ...  \n",
       "feature_256                                       -0.000877  \n",
       "feature_32                                        -0.001438  \n",
       "feature_545                                       -0.001423  \n",
       "feature_253                                       -0.002092  \n",
       "feature_254                                       -0.003330  \n",
       "\n",
       "[1761 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "# train = pd.concat([train_x,train_y],axis=1)\n",
    "# val = pd.concat([test_x,test_y],axis=1)\n",
    "# vpath='./data/automodel'\n",
    "# model = TabularPredictor(label='label',eval_metric='roc_auc',path=vpath)\n",
    "# predictor = model.fit( pd.concat([train,val]) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train = pd.concat([train_x,train_y],axis=1)\n",
    "val = pd.concat([test_x,test_y],axis=1)\n",
    "vpath='./data/automodel'\n",
    "model = TabularPredictor(label='label',eval_metric='roc_auc',path=vpath)\n",
    "predictor2 = model.fit( pd.concat([train,val]),auto_stack=True, presets='best_quality')\n",
    "\n",
    "\n",
    "y_pred = predictor2.predict_proba(oot_x)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "fpr,tpr,_ = roc_curve(oot_y, y_pred[1],pos_label=1)\n",
    "print(auc(fpr, tpr),max(tpr-fpr))   # val-》oot0.6085821264860178\n",
    "\n",
    "perf = predictor2.evaluate_predictions(y_true=oot_y, y_pred=y_pred, auxiliary_metrics=True)\n",
    "print(perf)\n",
    "\n",
    "predictor2.leaderboard(val, silent=True)\n",
    "\n",
    "predictor2.fit_summary(show_plot=True)\n",
    "\n",
    "predictor2.feature_importance(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bacd4e",
   "metadata": {},
   "source": [
    "#### pytorch  Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18a7c14c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment Tracking is turned off\n",
      "Global seed set to 42\n",
      "Preparing the DataLoaders...\n",
      "Preprocessing data: Stage: fit...\n",
      "Preprocessing data: Stage: inference...\n",
      "Preparing the Model: TabTransformerModel...\n",
      "/usr/local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning:\n",
      "\n",
      "Checkpoint directory saved_models exists and is not empty.\n",
      "\n",
      "Preparing the Trainer...\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name         | Type                   | Params\n",
      "--------------------------------------------------------\n",
      "0 | backbone     | TabTransformerBackbone | 507 K \n",
      "1 | dropout      | Dropout                | 0     \n",
      "2 | output_layer | Linear                 | 66    \n",
      "3 | loss         | CrossEntropyLoss       | 0     \n",
      "--------------------------------------------------------\n",
      "507 K     Trainable params\n",
      "0         Non-trainable params\n",
      "507 K     Total params\n",
      "2.029     Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "Global seed set to 42\n",
      "/usr/local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24868428bca142b18a198b8bd1d57745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restored states from the checkpoint file at /home/projects/Euler/lr_find_temp_model.ckpt\n",
      "Learning rate set to 0.006918309709189364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type                   | Params\n",
      "--------------------------------------------------------\n",
      "0 | backbone     | TabTransformerBackbone | 507 K \n",
      "1 | dropout      | Dropout                | 0     \n",
      "2 | output_layer | Linear                 | 66    \n",
      "3 | loss         | CrossEntropyLoss       | 0     \n",
      "--------------------------------------------------------\n",
      "507 K     Trainable params\n",
      "0         Non-trainable params\n",
      "507 K     Total params\n",
      "2.029     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75313b674b754aa4a0e9c2f24c9d2e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 3it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training the model completed...\n",
      "Loading the best model...\n",
      "Preprocessing data: Stage: inference...\n",
      "/usr/local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning:\n",
      "\n",
      "The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf03bbd79154697a4ae0cc147951f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data: Stage: inference...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': 0.1179153099656105}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b26611c26549489780fae94595892f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Predictions...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Directory is not empty. Overwriting the contents.\n",
      "Experiment Tracking is turned off\n",
      "Preparing the Trainer...\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Preprocessing data: Stage: inference...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655c0fa18a9e4c90a946d7712de2071a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Predictions...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'1_probability'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1_probability'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3ea10299e8b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m### oot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0myprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabular_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moot_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1_probability'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moot_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1_probability'"
     ]
    }
   ],
   "source": [
    "#### Pytorch FC transformer网络实现\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig,TabTransformerConfig\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=['label'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=list(train_x.columns),\n",
    "    categorical_cols=[],\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=100\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "# model_config = CategoryEmbeddingModelConfig(\n",
    "#     task=\"classification\",\n",
    "#     layers=\"1024-512-512\",  # Number of nodes in each layer\n",
    "#     activation=\"LeakyReLU\", # Activation between each layers\n",
    "#     learning_rate = 1e-3\n",
    "# )\n",
    "model_config = TabTransformerConfig(\n",
    "    task=\"classification\"\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "tabular_model.fit(train=pd.concat([train_x,train_y],axis=1), validation=pd.concat([test_x,test_y],axis=1))\n",
    "result = tabular_model.evaluate(test_x)\n",
    "pred_df = tabular_model.predict(test_x)\n",
    "tabular_model.save_model(\"examples/basic\")\n",
    "loaded_model = TabularModel.load_from_checkpoint(\"examples/basic\")\n",
    "\n",
    "\n",
    "### oot\n",
    "yprob = tabular_model.predict(oot_x)['1.0_probability']\n",
    "fpr,tpr,_ = roc_curve(oot_y, yprob,pos_label=1)\n",
    "auc(fpr, tpr),max(tpr-fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7bbd44",
   "metadata": {},
   "source": [
    "#### tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a5efd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 12\n",
      "\n",
      "Early stopping occured at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.53921\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.4809428380570665, 0.003109494910117361)\n",
      "------------test------------\n",
      " (0.5392049744614701, 0.09709082833666449)\n",
      "------------oot------------\n",
      " (0.4730754526813332, 0.0016404267890035816)\n",
      "8 8 14\n",
      "\n",
      "Early stopping occured at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.54293\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5108400522761158, 0.02644789748358589)\n",
      "------------test------------\n",
      " (0.5429202753719743, 0.09945591827670441)\n",
      "------------oot------------\n",
      " (0.5265665728286936, 0.05789455392207976)\n",
      "8 8 16\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.52775\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5155775245188113, 0.033688450863225916)\n",
      "------------test------------\n",
      " (0.527627137463913, 0.07195203197868089)\n",
      "------------oot------------\n",
      " (0.4750576350513792, 0.01135091926458831)\n",
      "8 8 18\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.52722\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.49610859679507613, 0.020119130527180618)\n",
      "------------test------------\n",
      " (0.5271474572507218, 0.07187430601821015)\n",
      "------------oot------------\n",
      " (0.5018211517742328, 0.03403190491085395)\n",
      "10 10 12\n",
      "\n",
      "Early stopping occured at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.53065\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5017384312698344, 0.01319180069020176)\n",
      "------------test------------\n",
      " (0.5306517876970909, 0.08079058405507439)\n",
      "------------oot------------\n",
      " (0.5040303988693104, 0.03865429395613945)\n",
      "10 10 14\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.50916\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5029842867091833, 0.026774657047969663)\n",
      "------------test------------\n",
      " (0.5091538974017322, 0.03984010659560289)\n",
      "------------oot------------\n",
      " (0.5224226415968675, 0.0649289264240781)\n",
      "10 10 16\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.52701\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5234412763385603, 0.04798465556577525)\n",
      "------------test------------\n",
      " (0.5269864534754609, 0.06496779924494789)\n",
      "------------oot------------\n",
      " (0.49992006394884086, 0.032405380043791066)\n",
      "10 10 18\n",
      "------------train------------\n",
      " (0.49929646527096744, 0.021474898462917058)\n",
      "------------test------------\n",
      " (0.5264512547190761, 0.0675438596491228)\n",
      "------------oot------------\n",
      " (0.4951169499183262, 0.02958328988982728)\n",
      "12 12 12\n",
      "\n",
      "Early stopping occured at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.53997\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5155176953027975, 0.034967334195577904)\n",
      "------------test------------\n",
      " (0.5399689096158117, 0.08592049744614705)\n",
      "------------oot------------\n",
      " (0.5085728518634368, 0.05655996941577174)\n",
      "12 12 14\n",
      "\n",
      "Early stopping occured at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.52643\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5020793359769185, 0.02212652254864339)\n",
      "------------test------------\n",
      " (0.5260826115922719, 0.08422163002442817)\n",
      "------------oot------------\n",
      " (0.5267994300212004, 0.05490564070482744)\n",
      "12 12 16\n",
      "\n",
      "Early stopping occured at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.53699\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.4797923438907535, 0.0005300706106573516)\n",
      "------------test------------\n",
      " (0.5363957361758828, 0.07408394403730845)\n",
      "------------oot------------\n",
      " (0.48923875392439675, 0.023139749070308968)\n",
      "12 12 18\n",
      "\n",
      "Early stopping occured at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.53241\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.4906947972270106, 0.012803452226980094)\n",
      "------------test------------\n",
      " (0.5323595380857206, 0.0844214967799245)\n",
      "------------oot------------\n",
      " (0.4844205794784463, 0.015326868939630922)\n",
      "14 14 12\n",
      "\n",
      "Early stopping occured at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.51885\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.4906038351610347, 0.012877223545368341)\n",
      "------------test------------\n",
      " (0.5188385520763935, 0.09166111481234734)\n",
      "------------oot------------\n",
      " (0.5080607977386207, 0.04560525492649359)\n",
      "14 14 14\n",
      "\n",
      "Early stopping occured at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.52743\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5014663572332101, 0.01541698730118124)\n",
      "------------test------------\n",
      " (0.527423939595825, 0.07662669331556743)\n",
      "------------oot------------\n",
      " (0.5307962325791541, 0.07302679595454073)\n",
      "14 14 16\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.51672\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.501943163598389, 0.022626678551293744)\n",
      "------------test------------\n",
      " (0.5164978902953586, 0.054541416833222334)\n",
      "------------oot------------\n",
      " (0.5031290909301543, 0.0406005630278386)\n",
      "14 14 18\n",
      "\n",
      "Early stopping occured at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.53311\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5070229618304491, 0.02625230196969419)\n",
      "------------test------------\n",
      " (0.5331379080612926, 0.08408838552076392)\n",
      "------------oot------------\n",
      " (0.5021814432511962, 0.029666701421471514)\n",
      "16 16 12\n",
      "\n",
      "Early stopping occured at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.54344\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5296030087869085, 0.05217134708457771)\n",
      "------------test------------\n",
      " (0.5434443704197202, 0.0884521430157672)\n",
      "------------oot------------\n",
      " (0.5375386647203976, 0.07204671045772082)\n",
      "16 16 14\n",
      "\n",
      "Early stopping occured at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.53678\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5101031512535371, 0.026372637202808136)\n",
      "------------test------------\n",
      " (0.53672218520986, 0.08807461692205198)\n",
      "------------oot------------\n",
      " (0.5033503631877108, 0.040649219754631094)\n",
      "16 16 16\n",
      "\n",
      "Early stopping occured at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.54427\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5146918626175011, 0.04058979153849751)\n",
      "------------test------------\n",
      " (0.5442682656007106, 0.08060182100821672)\n",
      "------------oot------------\n",
      " (0.4824615669783014, 0.0105932645188197)\n",
      "16 16 18\n",
      "\n",
      "Early stopping occured at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.56935\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5465721716990211, 0.08464480463798246)\n",
      "------------test------------\n",
      " (0.5693537641572284, 0.11140350877192984)\n",
      "------------oot------------\n",
      " (0.5074224678228432, 0.05409237827129601)\n",
      "18 18 12\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.50879\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5152532014383377, 0.035226142930914084)\n",
      "------------test------------\n",
      " (0.5087819231623363, 0.03355540750610703)\n",
      "------------oot------------\n",
      " (0.5203500967342068, 0.05824905293156779)\n",
      "18 18 14\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.53523\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5115346532308115, 0.035485222386684834)\n",
      "------------test------------\n",
      " (0.5351865423051299, 0.07974683544303796)\n",
      "------------oot------------\n",
      " (0.525300339438594, 0.09364334619261117)\n",
      "18 18 16\n",
      "\n",
      "Early stopping occured at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.52136\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5114762452970785, 0.024796367473210457)\n",
      "------------test------------\n",
      " (0.5213713080168777, 0.05292027537197419)\n",
      "------------oot------------\n",
      " (0.4969241997706183, 0.02874917457338476)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18 18\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.51868\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.4973288691533692, 0.016561187217393303)\n",
      "------------test------------\n",
      " (0.5186164779036199, 0.04870086608927382)\n",
      "------------oot------------\n",
      " (0.4861861235649162, 0.03508150001737742)\n",
      "20 20 12\n",
      "\n",
      "Early stopping occured at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.53022\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.517346547197739, 0.031172916586296506)\n",
      "------------test------------\n",
      " (0.5302409504774594, 0.07199644681323564)\n",
      "------------oot------------\n",
      " (0.5523303096653112, 0.10615507593924861)\n",
      "20 20 14\n",
      "\n",
      "Early stopping occured at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.53068\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.4937649699940239, 0.011843342206195595)\n",
      "------------test------------\n",
      " (0.530599600266489, 0.05853875194314895)\n",
      "------------oot------------\n",
      " (0.5186401603354998, 0.0491919507871964)\n",
      "20 20 16\n",
      "\n",
      "Early stopping occured at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.53041\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.514882517483464, 0.03481045170381292)\n",
      "------------test------------\n",
      " (0.5304108372196313, 0.05981567843659785)\n",
      "------------oot------------\n",
      " (0.5008074699660562, 0.03456017794460084)\n",
      "20 20 18\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.53212\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5064847696067583, 0.02149966938266945)\n",
      "------------test------------\n",
      " (0.5321174772373973, 0.08786364645791694)\n",
      "------------oot------------\n",
      " (0.4768382395532849, 0.012372710527230386)\n",
      "30 30 12\n",
      "\n",
      "Early stopping occured at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.5524\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5432974696437792, 0.0665210190729314)\n",
      "------------test------------\n",
      " (0.5524006218076838, 0.12426160337552739)\n",
      "------------oot------------\n",
      " (0.5201079715937396, 0.04700934904250509)\n",
      "30 30 14\n",
      "\n",
      "Early stopping occured at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.53387\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5228760797515328, 0.041076005438773544)\n",
      "------------test------------\n",
      " (0.5338729735731734, 0.06542305129913384)\n",
      "------------oot------------\n",
      " (0.4774429731577058, 0.0073749695895457545)\n",
      "30 30 16\n",
      "\n",
      "Early stopping occured at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.554\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5169070325724059, 0.0377128454815745)\n",
      "------------test------------\n",
      " (0.5540051077059738, 0.11456806573395512)\n",
      "------------oot------------\n",
      " (0.5245056129009835, 0.0824592499913113)\n",
      "30 30 18\n",
      "\n",
      "Early stopping occured at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.53383\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5338805270114697, 0.05086539170878063)\n",
      "------------test------------\n",
      " (0.5338574283810793, 0.05964912280701751)\n",
      "------------oot------------\n",
      " (0.5756762705777407, 0.12178778716157507)\n",
      "40 40 12\n",
      "\n",
      "Early stopping occured at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.51213\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5030200894866396, 0.022249158905450206)\n",
      "------------test------------\n",
      " (0.5119975571840994, 0.042182989118365544)\n",
      "------------oot------------\n",
      " (0.4684449541815822, 0.007513988808952848)\n",
      "40 40 14\n",
      "\n",
      "Early stopping occured at epoch 58 with best_epoch = 48 and best_val_0_auc = 0.55936\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5800043179909294, 0.1251100647766319)\n",
      "------------test------------\n",
      " (0.5593626471241394, 0.11241394625805018)\n",
      "------------oot------------\n",
      " (0.5560235869275594, 0.1066416432071734)\n",
      "40 40 16\n",
      "\n",
      "Early stopping occured at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.53644\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.4891743635870187, 0.008839834346166087)\n",
      "------------test------------\n",
      " (0.5337541638907395, 0.09479236064845659)\n",
      "------------oot------------\n",
      " (0.5094347710237607, 0.059618392242727525)\n",
      "40 40 18\n",
      "\n",
      "Early stopping occured at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.52495\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5098113823053063, 0.032389804939158995)\n",
      "------------test------------\n",
      " (0.5249111703308905, 0.06223628691983124)\n",
      "------------oot------------\n",
      " (0.4857447375432987, 0.038105168039481496)\n",
      "50 50 12\n",
      "\n",
      "Early stopping occured at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.53304\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5244693371883923, 0.05136175762534856)\n",
      "------------test------------\n",
      " (0.5330379746835443, 0.07613813013546522)\n",
      "------------oot------------\n",
      " (0.5391211668346483, 0.06833489729955167)\n",
      "50 50 14\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.5289\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5013785084522304, 0.023088933693120706)\n",
      "------------test------------\n",
      " (0.528902953586498, 0.08011325782811457)\n",
      "------------oot------------\n",
      " (0.4894565507014678, 0.02190942897855619)\n",
      "50 50 16\n",
      "\n",
      "Early stopping occured at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.51057\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5056638775693907, 0.01948388502773868)\n",
      "------------test------------\n",
      " (0.5105729513657561, 0.03895180990450811)\n",
      "------------oot------------\n",
      " (0.5412446854110915, 0.08383554026344142)\n",
      "50 50 18\n",
      "\n",
      "Early stopping occured at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.54007\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5075469412313314, 0.037377964304157074)\n",
      "------------test------------\n",
      " (0.5400688429935598, 0.08925161003775259)\n",
      "------------oot------------\n",
      " (0.4884718312306676, 0.022590623153651013)\n",
      "60 60 12\n",
      "\n",
      "Early stopping occured at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.53764\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5241927962645995, 0.059491221551512374)\n",
      "------------test------------\n",
      " (0.5376393515434155, 0.0968798578725294)\n",
      "------------oot------------\n",
      " (0.5083515796058805, 0.045132589580509475)\n",
      "60 60 14\n",
      "\n",
      "Early stopping occured at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.53134\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.501951014490988, 0.01459819334718071)\n",
      "------------test------------\n",
      " (0.5313368865200977, 0.06865423051299124)\n",
      "------------oot------------\n",
      " (0.4990396088925961, 0.03889062662913145)\n",
      "60 60 16\n",
      "\n",
      "Early stopping occured at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.52716\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5116576279881614, 0.027205237898965784)\n",
      "------------test------------\n",
      " (0.527694870086609, 0.06897623806351316)\n",
      "------------oot------------\n",
      " (0.4847148368261912, 0.022847808709554163)\n",
      "60 60 18\n",
      "\n",
      "Early stopping occured at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.53978\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5101344194637163, 0.03228327644820206)\n",
      "------------test------------\n",
      " (0.5397690428603154, 0.08945147679324894)\n",
      "------------oot------------\n",
      " (0.5043721544503528, 0.03646474125047783)\n",
      "70 70 12\n",
      "\n",
      "Early stopping occured at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.54047\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5101677857572626, 0.027201583173100674)\n",
      "------------test------------\n",
      " (0.540414168332223, 0.06724405951587831)\n",
      "------------oot------------\n",
      " (0.4977536811130805, 0.02040802140895981)\n",
      "70 70 14\n",
      "\n",
      "Early stopping occured at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.52767\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5020821108613716, 0.022258092679787178)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.5273073506551188, 0.07503886298023538)\n",
      "------------oot------------\n",
      " (0.5027039238174678, 0.03798700170298541)\n",
      "70 70 16\n",
      "\n",
      "Early stopping occured at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.53901\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5105784686563265, 0.030716888014461874)\n",
      "------------test------------\n",
      " (0.5404363757495003, 0.09397068620919391)\n",
      "------------oot------------\n",
      " (0.5311391466536914, 0.08139575296284707)\n",
      "70 70 18\n",
      "\n",
      "Early stopping occured at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.50745\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.49929274286499375, 0.010915041836459194)\n",
      "------------test------------\n",
      " (0.5032511658894071, 0.044481456806573394)\n",
      "------------oot------------\n",
      " (0.5100835273809937, 0.04283182149932219)\n",
      "80 80 12\n",
      "\n",
      "Early stopping occured at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.55117\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5026753270133648, 0.02888194490974516)\n",
      "------------test------------\n",
      " (0.5511703308905175, 0.09806795469686874)\n",
      "------------oot------------\n",
      " (0.525554049514012, 0.06596461960866096)\n",
      "80 80 14\n",
      "\n",
      "Early stopping occured at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.54523\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5138686017763321, 0.03795514027040914)\n",
      "------------test------------\n",
      " (0.5435332000888297, 0.09184987785920501)\n",
      "------------oot------------\n",
      " (0.5021872357186714, 0.027942863100823723)\n",
      "80 80 16\n",
      "\n",
      "Early stopping occured at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.52298\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5084962224347378, 0.019996494170373857)\n",
      "------------test------------\n",
      " (0.5230013324450367, 0.054197201865422984)\n",
      "------------oot------------\n",
      " (0.5131535351429002, 0.06424078128801305)\n",
      "80 80 18\n",
      "\n",
      "Early stopping occured at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.55335\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5117660515221595, 0.03460172624885027)\n",
      "------------test------------\n",
      " (0.5532467244059516, 0.09871196979791252)\n",
      "------------oot------------\n",
      " (0.48510409064053106, 0.00125812393563407)\n",
      "90 90 12\n",
      "\n",
      "Early stopping occured at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.57123\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5486189535436966, 0.07598012641290686)\n",
      "------------test------------\n",
      " (0.5712291805463025, 0.12482789251610032)\n",
      "------------oot------------\n",
      " (0.572778878346598, 0.12298335244847597)\n",
      "90 90 14\n",
      "\n",
      "Early stopping occured at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.53839\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5142395564516402, 0.03947455870877181)\n",
      "------------test------------\n",
      " (0.5381812125249834, 0.0939151676660005)\n",
      "------------oot------------\n",
      " (0.5450016798155679, 0.09081430507767696)\n",
      "90 90 16\n",
      "\n",
      "Early stopping occured at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.52034\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.501657012099173, 0.015716133381250774)\n",
      "------------test------------\n",
      " (0.5202043082389518, 0.06771041527870308)\n",
      "------------oot------------\n",
      " (0.49430716296527993, 0.024516039342439178)\n",
      "90 90 18\n",
      "\n",
      "Early stopping occured at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.52386\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5061151685336225, 0.02490871645350823)\n",
      "------------test------------\n",
      " (0.523842993559849, 0.051532311792138574)\n",
      "------------oot------------\n",
      " (0.4868128685457431, 0.01894136864421514)\n",
      "['nd,na,ns', 30, 30, 18, 0.5756762705777407]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "n_steps: 决策的步数，通常为{3 ~ 10}\n",
    "n_d: 预测阶段的特征数，通常为{8 ~ 64}\n",
    "n_a: Attentive阶段的特征数，通常为{8 ~ 64}\n",
    "gamma: Attentive中注意力更新的比例，通常为{1.0 ~ 2.0}\n",
    "momentum: BN层的动量，通常为{0.0 ~ 1.0}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def model_metrics2(nnmodel, x, y):\n",
    "    yprob = nnmodel.predict_proba(x)[:,1]\n",
    "    fpr,tpr,_ = roc_curve(y, yprob,pos_label=1)\n",
    "    return auc(fpr, tpr),max(tpr-fpr)\n",
    "\n",
    "\n",
    "bestval=0\n",
    "\n",
    "for nd in list(range(1,20,3)) + list(range(20,100,10)):\n",
    "    for ns in range(1,20,3):\n",
    "        print(nd,nd,ns)\n",
    "        clf = TabNetClassifier(n_d=nd,\n",
    "                               n_a=nd,\n",
    "                               n_steps=ns,\n",
    "                               verbose=False)  \n",
    "\n",
    "        clf.fit(\n",
    "            train_x.values,\n",
    "            train_y.values,\n",
    "            num_workers=16,\n",
    "            max_epochs=200,\n",
    "            patience=3,\n",
    "            batch_size=2024,\n",
    "            eval_set=[(test_x.values,test_y.values)]\n",
    "        )\n",
    "\n",
    "        print('------------train------------\\n',model_metrics2(clf, train_x.values,train_y.values))\n",
    "\n",
    "        print('------------test------------\\n',model_metrics2(clf, test_x.values,test_y.values))\n",
    "\n",
    "        print('------------oot------------\\n',model_metrics2(clf, oot_x.values,oot_y.values))\n",
    "        if model_metrics2(clf, test_x.values,test_y.values)[0] > bestval:\n",
    "            bestval =model_metrics2(clf, oot_x.values,oot_y.values)[0]\n",
    "            bestparas = ['nd,na,ns',nd,nd,ns,bestval ]\n",
    "print(bestparas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fe598f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nd,na,ns', 30, 30, 18, 0.5756762705777407]\n"
     ]
    }
   ],
   "source": [
    "print(bestparas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d39a0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43aac941",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### qcut-onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6199944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/filter_feas_df32n_old.pkl')\n",
    "df.head()\n",
    "\n",
    "# qcut-onehot\n",
    "df2 = df[final_feas].apply(lambda x: pd.qcut(x.replace([np.inf, -np.inf], np.nan).fillna(-9999),q=50,duplicates='drop'))\n",
    "df2 = df2.applymap(lambda x: str(x).replace(']','qcut').replace('(','').replace(',','_'))\n",
    "df2 = pd.get_dummies(df2,prefix_sep='_')\n",
    "df2.head()\n",
    "\n",
    "# 等频onehot 存储\n",
    "pd.concat([df,df2],axis=1).to_pickle('./data/filter_feas_df32n_old_qcut_oh.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7134dc0",
   "metadata": {},
   "source": [
    "#### lgb_onehot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b875c6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26ade2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9123, 1802)\n",
      "1.0    5631\n",
      "0.0    2040\n",
      "Name: label, dtype: int64\n",
      "1.0    1035\n",
      "0.0     417\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BureauScore</th>\n",
       "      <th>MissingRate</th>\n",
       "      <th>Len_Name</th>\n",
       "      <th>Tel_nuniq</th>\n",
       "      <th>Email_nuniq</th>\n",
       "      <th>Len_of_addrs</th>\n",
       "      <th>City_nuniq</th>\n",
       "      <th>Current_State</th>\n",
       "      <th>CreditAccountActive</th>\n",
       "      <th>CreditAccountTotal</th>\n",
       "      <th>CreditAccountActivePor</th>\n",
       "      <th>Outstanding_Balance_Secured</th>\n",
       "      <th>Outstanding_Balance_UnSecured_Percentage</th>\n",
       "      <th>Outstanding_Balance_All</th>\n",
       "      <th>Outstanding_Balance_Secured_Percentage</th>\n",
       "      <th>Outstanding_Balance_UnSecured</th>\n",
       "      <th>Diff_dateBirth</th>\n",
       "      <th>State_nuniq</th>\n",
       "      <th>Birth_nuniq</th>\n",
       "      <th>TotalCAPSLast90Days</th>\n",
       "      <th>TotalCAPSLast7Days</th>\n",
       "      <th>TotalCAPSLast30Days</th>\n",
       "      <th>TotalCAPSLast180Days</th>\n",
       "      <th>CAPSLast30Days</th>\n",
       "      <th>CAPSLast7Days</th>\n",
       "      <th>CAPSLast180Days</th>\n",
       "      <th>NonCreditCAPSLast180Days</th>\n",
       "      <th>Pin_nuniq</th>\n",
       "      <th>Pan_nuniq</th>\n",
       "      <th>Ident_nuniq</th>\n",
       "      <th>Name_nuniq2</th>\n",
       "      <th>Tel_nuniq2</th>\n",
       "      <th>Email_nuniq2</th>\n",
       "      <th>Pan_nuniq2</th>\n",
       "      <th>Account_nuniq2</th>\n",
       "      <th>Ident_nuniq2</th>\n",
       "      <th>Gender_nuniq</th>\n",
       "      <th>Amount_Past_Due35_sum_30</th>\n",
       "      <th>Amount_Past_Due35_min_30</th>\n",
       "      <th>Amount_Past_Due35_sum_90</th>\n",
       "      <th>Amount_Past_Due35_mean_90</th>\n",
       "      <th>Amount_Past_Due35_max_90</th>\n",
       "      <th>Amount_Past_Due35_min_90</th>\n",
       "      <th>Amount_Past_Due35_std_90</th>\n",
       "      <th>Amount_Past_Due35_sum_360</th>\n",
       "      <th>Amount_Past_Due35_mean_360</th>\n",
       "      <th>Amount_Past_Due35_max_360</th>\n",
       "      <th>Amount_Past_Due35_std_360</th>\n",
       "      <th>Amount_Past_Due35_sum_9999</th>\n",
       "      <th>Amount_Past_Due35_max_9999</th>\n",
       "      <th>Amount_Past_Due35_min_9999</th>\n",
       "      <th>Amount_Past_Due35_std_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_9999</th>\n",
       "      <th>Terms_Duration34_sum_30</th>\n",
       "      <th>Terms_Duration34_std_30</th>\n",
       "      <th>Terms_Duration34_sum_90</th>\n",
       "      <th>Terms_Duration34_std_90</th>\n",
       "      <th>Terms_Duration34_mean_360</th>\n",
       "      <th>Terms_Duration34_max_360</th>\n",
       "      <th>Terms_Duration34_min_360</th>\n",
       "      <th>Terms_Duration34_std_360</th>\n",
       "      <th>Terms_Duration34_sum_9999</th>\n",
       "      <th>Terms_Duration34_mean_9999</th>\n",
       "      <th>Terms_Duration34_max_9999</th>\n",
       "      <th>Terms_Duration34_min_9999</th>\n",
       "      <th>Terms_Duration34_std_9999</th>\n",
       "      <th>Payment_Rating34_sum_90</th>\n",
       "      <th>Payment_Rating34_mean_90</th>\n",
       "      <th>Payment_Rating34_max_90</th>\n",
       "      <th>Payment_Rating34_min_90</th>\n",
       "      <th>Payment_Rating34_std_90</th>\n",
       "      <th>Payment_Rating34_sum_360</th>\n",
       "      <th>Payment_Rating34_mean_360</th>\n",
       "      <th>Payment_Rating34_max_360</th>\n",
       "      <th>Payment_Rating34_min_360</th>\n",
       "      <th>Payment_Rating34_std_360</th>\n",
       "      <th>Payment_Rating34_sum_9999</th>\n",
       "      <th>Payment_Rating34_mean_9999</th>\n",
       "      <th>Payment_Rating34_max_9999</th>\n",
       "      <th>Payment_Rating34_min_9999</th>\n",
       "      <th>Payment_Rating34_std_9999</th>\n",
       "      <th>Current_Balance35_mean_30</th>\n",
       "      <th>Current_Balance35_min_30</th>\n",
       "      <th>Current_Balance35_std_30</th>\n",
       "      <th>Current_Balance35_sum_90</th>\n",
       "      <th>Current_Balance35_mean_90</th>\n",
       "      <th>Current_Balance35_max_90</th>\n",
       "      <th>Current_Balance35_std_90</th>\n",
       "      <th>Current_Balance35_sum_360</th>\n",
       "      <th>Current_Balance35_max_360</th>\n",
       "      <th>Current_Balance35_std_360</th>\n",
       "      <th>Current_Balance35_max_9999</th>\n",
       "      <th>Current_Balance35_std_9999</th>\n",
       "      <th>Settlement_Amount37_max_360</th>\n",
       "      <th>Settlement_Amount37_min_360</th>\n",
       "      <th>Settlement_Amount37_std_360</th>\n",
       "      <th>Settlement_Amount37_sum_9999</th>\n",
       "      <th>Settlement_Amount37_mean_9999</th>\n",
       "      <th>Settlement_Amount37_max_9999</th>\n",
       "      <th>Settlement_Amount37_min_9999</th>\n",
       "      <th>Settlement_Amount37_std_9999</th>\n",
       "      <th>Value_of_Collateral39_std_90</th>\n",
       "      <th>Value_of_Collateral39_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_360</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_360</th>\n",
       "      <th>Written_Off_Amt_Total41_min_360</th>\n",
       "      <th>Written_Off_Amt_Total41_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_max_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_min_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_std_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_mean_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_std_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_max_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_9999</th>\n",
       "      <th>Rate_of_Interest36_sum_30</th>\n",
       "      <th>Rate_of_Interest36_std_30</th>\n",
       "      <th>Rate_of_Interest36_sum_90</th>\n",
       "      <th>Rate_of_Interest36_mean_90</th>\n",
       "      <th>Rate_of_Interest36_max_90</th>\n",
       "      <th>Rate_of_Interest36_std_90</th>\n",
       "      <th>Rate_of_Interest36_sum_360</th>\n",
       "      <th>Rate_of_Interest36_mean_360</th>\n",
       "      <th>Rate_of_Interest36_max_360</th>\n",
       "      <th>Rate_of_Interest36_min_360</th>\n",
       "      <th>Rate_of_Interest36_std_360</th>\n",
       "      <th>Rate_of_Interest36_sum_9999</th>\n",
       "      <th>Rate_of_Interest36_mean_9999</th>\n",
       "      <th>Rate_of_Interest36_max_9999</th>\n",
       "      <th>Rate_of_Interest36_min_9999</th>\n",
       "      <th>Rate_of_Interest36_std_9999</th>\n",
       "      <th>Repayment_Tenure36_std_30</th>\n",
       "      <th>Repayment_Tenure36_mean_90</th>\n",
       "      <th>Repayment_Tenure36_max_90</th>\n",
       "      <th>Repayment_Tenure36_min_90</th>\n",
       "      <th>Repayment_Tenure36_std_90</th>\n",
       "      <th>Repayment_Tenure36_sum_360</th>\n",
       "      <th>Repayment_Tenure36_mean_360</th>\n",
       "      <th>Repayment_Tenure36_min_360</th>\n",
       "      <th>Repayment_Tenure36_std_360</th>\n",
       "      <th>Repayment_Tenure36_mean_9999</th>\n",
       "      <th>Repayment_Tenure36_min_9999</th>\n",
       "      <th>Repayment_Tenure36_std_9999</th>\n",
       "      <th>Income26_count_360</th>\n",
       "      <th>Income26_std_360</th>\n",
       "      <th>Open_Date29_max_30</th>\n",
       "      <th>Open_Date29_min_30</th>\n",
       "      <th>Open_Date29_mean_30</th>\n",
       "      <th>Open_Date29_nuniq_30</th>\n",
       "      <th>Open_Date29_maxcount_30</th>\n",
       "      <th>Open_Date29_max_90</th>\n",
       "      <th>Open_Date29_mean_90</th>\n",
       "      <th>Open_Date29_mode_90</th>\n",
       "      <th>Open_Date29_nuniq_90</th>\n",
       "      <th>Open_Date29_maxcount_90</th>\n",
       "      <th>Open_Date29_max_360</th>\n",
       "      <th>Open_Date29_mean_360</th>\n",
       "      <th>Open_Date29_mode_360</th>\n",
       "      <th>Open_Date29_nuniq_360</th>\n",
       "      <th>Open_Date29_maxcount_360</th>\n",
       "      <th>Open_Date29_max_9999</th>\n",
       "      <th>Open_Date29_mean_9999</th>\n",
       "      <th>Open_Date29_mode_9999</th>\n",
       "      <th>Open_Date29_maxcount_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_30</th>\n",
       "      <th>Portfolio_Type34_nuniq_90</th>\n",
       "      <th>Portfolio_Type34_nuniq_360</th>\n",
       "      <th>Portfolio_Type34_nuniq_9999</th>\n",
       "      <th>Account_Type32_nuniq_30</th>\n",
       "      <th>Account_Type32_nuniq_90</th>\n",
       "      <th>Account_Type32_nuniq_360</th>\n",
       "      <th>Account_Type32_nuniq_9999</th>\n",
       "      <th>Occupation_Code35_nuniq_30</th>\n",
       "      <th>Occupation_Code35_nuniq_90</th>\n",
       "      <th>Occupation_Code35_nuniq_360</th>\n",
       "      <th>Occupation_Code35_nuniq_9999</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_360</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_9999</th>\n",
       "      <th>Payment_History_Profile43_mode_30</th>\n",
       "      <th>Payment_History_Profile43_mode_90</th>\n",
       "      <th>Payment_History_Profile43_nuniq_90</th>\n",
       "      <th>Payment_History_Profile43_mode_360</th>\n",
       "      <th>Payment_History_Profile43_nuniq_360</th>\n",
       "      <th>Payment_History_Profile43_mode_9999</th>\n",
       "      <th>Payment_History_Profile43_nuniq_9999</th>\n",
       "      <th>Date_Closed31_nuniq_30</th>\n",
       "      <th>Date_Closed31_maxcount_30</th>\n",
       "      <th>Date_Closed31_max_90</th>\n",
       "      <th>Date_Closed31_min_90</th>\n",
       "      <th>Date_Closed31_mean_90</th>\n",
       "      <th>Date_Closed31_mode_90</th>\n",
       "      <th>Date_Closed31_nuniq_90</th>\n",
       "      <th>Date_Closed31_maxcount_90</th>\n",
       "      <th>Date_Closed31_min_360</th>\n",
       "      <th>Date_Closed31_mode_360</th>\n",
       "      <th>Date_Closed31_nuniq_360</th>\n",
       "      <th>Date_Closed31_maxcount_360</th>\n",
       "      <th>Date_Closed31_max_9999</th>\n",
       "      <th>Date_Closed31_min_9999</th>\n",
       "      <th>Date_Closed31_mean_9999</th>\n",
       "      <th>Date_Closed31_mode_9999</th>\n",
       "      <th>Date_Closed31_nuniq_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_30</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_30</th>\n",
       "      <th>Date_of_Last_Payment40_min_90</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_90</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_90</th>\n",
       "      <th>Date_of_Last_Payment40_max_360</th>\n",
       "      <th>Date_of_Last_Payment40_min_360</th>\n",
       "      <th>Date_of_Last_Payment40_mean_360</th>\n",
       "      <th>Date_of_Last_Payment40_mode_360</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_360</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_360</th>\n",
       "      <th>Date_of_Last_Payment40_max_9999</th>\n",
       "      <th>Date_of_Last_Payment40_min_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mean_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_9999</th>\n",
       "      <th>Date_Reported33_nuniq_30</th>\n",
       "      <th>Date_Reported33_max_90</th>\n",
       "      <th>Date_Reported33_mean_90</th>\n",
       "      <th>Date_Reported33_mode_90</th>\n",
       "      <th>Date_Reported33_nuniq_90</th>\n",
       "      <th>Date_Reported33_maxcount_90</th>\n",
       "      <th>Date_Reported33_max_360</th>\n",
       "      <th>Date_Reported33_mean_360</th>\n",
       "      <th>Date_Reported33_mode_360</th>\n",
       "      <th>Date_Reported33_nuniq_360</th>\n",
       "      <th>Date_Reported33_maxcount_360</th>\n",
       "      <th>Date_Reported33_max_9999</th>\n",
       "      <th>Date_Reported33_mean_9999</th>\n",
       "      <th>Date_Reported33_mode_9999</th>\n",
       "      <th>Date_Reported33_nuniq_9999</th>\n",
       "      <th>Date_Reported33_maxcount_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_30</th>\n",
       "      <th>DateOfAddition34_max_90</th>\n",
       "      <th>DateOfAddition34_mean_90</th>\n",
       "      <th>DateOfAddition34_mode_90</th>\n",
       "      <th>DateOfAddition34_nuniq_90</th>\n",
       "      <th>DateOfAddition34_maxcount_90</th>\n",
       "      <th>DateOfAddition34_max_360</th>\n",
       "      <th>DateOfAddition34_mean_360</th>\n",
       "      <th>DateOfAddition34_mode_360</th>\n",
       "      <th>DateOfAddition34_nuniq_360</th>\n",
       "      <th>DateOfAddition34_maxcount_360</th>\n",
       "      <th>DateOfAddition34_max_9999</th>\n",
       "      <th>DateOfAddition34_mean_9999</th>\n",
       "      <th>DateOfAddition34_mode_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_9999</th>\n",
       "      <th>DateOfAddition34_maxcount_9999</th>\n",
       "      <th>Account_Status34_mode_30</th>\n",
       "      <th>Account_Status34_nuniq_30</th>\n",
       "      <th>Account_Status34_mode_90</th>\n",
       "      <th>Account_Status34_nuniq_90</th>\n",
       "      <th>Account_Status34_mode_360</th>\n",
       "      <th>Account_Status34_nuniq_360</th>\n",
       "      <th>Account_Status34_nuniq_9999</th>\n",
       "      <th>Month50_sum_30</th>\n",
       "      <th>Month50_max_30</th>\n",
       "      <th>Month50_std_30</th>\n",
       "      <th>Month50_sum_90</th>\n",
       "      <th>Month50_mean_90</th>\n",
       "      <th>Month50_max_90</th>\n",
       "      <th>Month50_min_90</th>\n",
       "      <th>Month50_std_90</th>\n",
       "      <th>Month50_sum_360</th>\n",
       "      <th>Month50_min_360</th>\n",
       "      <th>Month50_std_360</th>\n",
       "      <th>Month50_sum_9999</th>\n",
       "      <th>Month50_mean_9999</th>\n",
       "      <th>Month50_max_9999</th>\n",
       "      <th>Month50_min_9999</th>\n",
       "      <th>Month50_std_9999</th>\n",
       "      <th>Days_Past_Due58_max_30</th>\n",
       "      <th>Days_Past_Due58_min_30</th>\n",
       "      <th>Days_Past_Due58_mean_90</th>\n",
       "      <th>Days_Past_Due58_max_90</th>\n",
       "      <th>Days_Past_Due58_min_90</th>\n",
       "      <th>Days_Past_Due58_std_90</th>\n",
       "      <th>Days_Past_Due58_sum_360</th>\n",
       "      <th>Days_Past_Due58_mean_360</th>\n",
       "      <th>Days_Past_Due58_max_360</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_1031_sms</th>\n",
       "      <th>feature_1032_sms</th>\n",
       "      <th>feature_1033_sms</th>\n",
       "      <th>feature_1034_sms</th>\n",
       "      <th>feature_1035_sms</th>\n",
       "      <th>feature_1036_sms</th>\n",
       "      <th>feature_1037_sms</th>\n",
       "      <th>feature_1038_sms</th>\n",
       "      <th>feature_1039_sms</th>\n",
       "      <th>feature_1040_sms</th>\n",
       "      <th>feature_1041_sms</th>\n",
       "      <th>feature_1042_sms</th>\n",
       "      <th>feature_1043_sms</th>\n",
       "      <th>feature_1044_sms</th>\n",
       "      <th>feature_1045_sms</th>\n",
       "      <th>feature_1046_sms</th>\n",
       "      <th>feature_1047_sms</th>\n",
       "      <th>feature_1048_sms</th>\n",
       "      <th>feature_1049_sms</th>\n",
       "      <th>feature_1050_sms</th>\n",
       "      <th>feature_1051_sms</th>\n",
       "      <th>feature_1052_sms</th>\n",
       "      <th>feature_1053_sms</th>\n",
       "      <th>feature_1054_sms</th>\n",
       "      <th>feature_1055_sms</th>\n",
       "      <th>feature_1056_sms</th>\n",
       "      <th>feature_1057_sms</th>\n",
       "      <th>feature_1058_sms</th>\n",
       "      <th>feature_1059_sms</th>\n",
       "      <th>feature_1060_sms</th>\n",
       "      <th>feature_1061_sms</th>\n",
       "      <th>feature_1062_sms</th>\n",
       "      <th>feature_1063_sms</th>\n",
       "      <th>feature_1064_sms</th>\n",
       "      <th>feature_1065_sms</th>\n",
       "      <th>feature_1066_sms</th>\n",
       "      <th>feature_1067_sms</th>\n",
       "      <th>feature_1068_sms</th>\n",
       "      <th>feature_1069_sms</th>\n",
       "      <th>feature_1070_sms</th>\n",
       "      <th>feature_1071_sms</th>\n",
       "      <th>feature_1072_sms</th>\n",
       "      <th>feature_1073_sms</th>\n",
       "      <th>feature_1074_sms</th>\n",
       "      <th>feature_1075_sms</th>\n",
       "      <th>feature_1076_sms</th>\n",
       "      <th>feature_1077_sms</th>\n",
       "      <th>feature_1078_sms</th>\n",
       "      <th>feature_1079_sms</th>\n",
       "      <th>feature_1080_sms</th>\n",
       "      <th>feature_1081_sms</th>\n",
       "      <th>feature_1082_sms</th>\n",
       "      <th>feature_1083_sms</th>\n",
       "      <th>feature_1084_sms</th>\n",
       "      <th>feature_1085_sms</th>\n",
       "      <th>feature_1086_sms</th>\n",
       "      <th>feature_1087_sms</th>\n",
       "      <th>feature_1088_sms</th>\n",
       "      <th>feature_1089_sms</th>\n",
       "      <th>feature_1090_sms</th>\n",
       "      <th>feature_1091_sms</th>\n",
       "      <th>feature_1092_sms</th>\n",
       "      <th>feature_1093_sms</th>\n",
       "      <th>feature_1094_sms</th>\n",
       "      <th>feature_1095_sms</th>\n",
       "      <th>feature_1096_sms</th>\n",
       "      <th>feature_1097_sms</th>\n",
       "      <th>feature_1098_sms</th>\n",
       "      <th>feature_1099_sms</th>\n",
       "      <th>feature_1100_sms</th>\n",
       "      <th>feature_1101_sms</th>\n",
       "      <th>feature_1102_sms</th>\n",
       "      <th>feature_1103_sms</th>\n",
       "      <th>feature_1104_sms</th>\n",
       "      <th>feature_1105_sms</th>\n",
       "      <th>feature_1106_sms</th>\n",
       "      <th>feature_1107_sms</th>\n",
       "      <th>feature_1108_sms</th>\n",
       "      <th>feature_1109_sms</th>\n",
       "      <th>feature_1110_sms</th>\n",
       "      <th>feature_1111_sms</th>\n",
       "      <th>feature_1112_sms</th>\n",
       "      <th>feature_1113_sms</th>\n",
       "      <th>feature_1114_sms</th>\n",
       "      <th>feature_1115_sms</th>\n",
       "      <th>feature_1116_sms</th>\n",
       "      <th>feature_1117_sms</th>\n",
       "      <th>feature_1118_sms</th>\n",
       "      <th>feature_1119_sms</th>\n",
       "      <th>feature_1120_sms</th>\n",
       "      <th>feature_1121_sms</th>\n",
       "      <th>feature_1122_sms</th>\n",
       "      <th>feature_1123_sms</th>\n",
       "      <th>feature_1124_sms</th>\n",
       "      <th>feature_1125_sms</th>\n",
       "      <th>feature_1126_sms</th>\n",
       "      <th>feature_1127_sms</th>\n",
       "      <th>feature_1128_sms</th>\n",
       "      <th>feature_1129_sms</th>\n",
       "      <th>feature_1130_sms</th>\n",
       "      <th>feature_1131_sms</th>\n",
       "      <th>feature_1132_sms</th>\n",
       "      <th>feature_1133_sms</th>\n",
       "      <th>feature_1134_sms</th>\n",
       "      <th>feature_1135_sms</th>\n",
       "      <th>feature_1136_sms</th>\n",
       "      <th>feature_1137_sms</th>\n",
       "      <th>feature_1138_sms</th>\n",
       "      <th>feature_1139_sms</th>\n",
       "      <th>feature_1140_sms</th>\n",
       "      <th>feature_1141_sms</th>\n",
       "      <th>feature_1142_sms</th>\n",
       "      <th>feature_1143_sms</th>\n",
       "      <th>feature_1144_sms</th>\n",
       "      <th>feature_1145_sms</th>\n",
       "      <th>feature_1146_sms</th>\n",
       "      <th>feature_1147_sms</th>\n",
       "      <th>feature_1148_sms</th>\n",
       "      <th>feature_1149_sms</th>\n",
       "      <th>feature_1150_sms</th>\n",
       "      <th>feature_1151_sms</th>\n",
       "      <th>feature_1152_sms</th>\n",
       "      <th>feature_1153_sms</th>\n",
       "      <th>feature_1154_sms</th>\n",
       "      <th>feature_1155_sms</th>\n",
       "      <th>feature_1156_sms</th>\n",
       "      <th>feature_1157_sms</th>\n",
       "      <th>feature_1158_sms</th>\n",
       "      <th>feature_1159_sms</th>\n",
       "      <th>feature_1160_sms</th>\n",
       "      <th>feature_1161_sms</th>\n",
       "      <th>feature_1162_sms</th>\n",
       "      <th>feature_1163_sms</th>\n",
       "      <th>feature_1164_sms</th>\n",
       "      <th>feature_1165_sms</th>\n",
       "      <th>feature_1166_sms</th>\n",
       "      <th>feature_1167_sms</th>\n",
       "      <th>feature_1168_sms</th>\n",
       "      <th>feature_1169_sms</th>\n",
       "      <th>feature_1170_sms</th>\n",
       "      <th>feature_1171_sms</th>\n",
       "      <th>feature_1172_sms</th>\n",
       "      <th>feature_1173_sms</th>\n",
       "      <th>feature_1174_sms</th>\n",
       "      <th>feature_1175_sms</th>\n",
       "      <th>feature_1176_sms</th>\n",
       "      <th>feature_1177_sms</th>\n",
       "      <th>feature_1178_sms</th>\n",
       "      <th>feature_1179_sms</th>\n",
       "      <th>feature_1180_sms</th>\n",
       "      <th>feature_1181_sms</th>\n",
       "      <th>feature_1182_sms</th>\n",
       "      <th>feature_1183_sms</th>\n",
       "      <th>feature_1184_sms</th>\n",
       "      <th>feature_1185_sms</th>\n",
       "      <th>feature_1186_sms</th>\n",
       "      <th>feature_1187_sms</th>\n",
       "      <th>feature_1188_sms</th>\n",
       "      <th>feature_1189_sms</th>\n",
       "      <th>feature_1190_sms</th>\n",
       "      <th>feature_1191_sms</th>\n",
       "      <th>feature_1192_sms</th>\n",
       "      <th>feature_1193_sms</th>\n",
       "      <th>feature_1194_sms</th>\n",
       "      <th>feature_1195_sms</th>\n",
       "      <th>feature_1196_sms</th>\n",
       "      <th>feature_1197_sms</th>\n",
       "      <th>feature_1198_sms</th>\n",
       "      <th>feature_1199_sms</th>\n",
       "      <th>feature_1200_sms</th>\n",
       "      <th>feature_1201_sms</th>\n",
       "      <th>feature_1202_sms</th>\n",
       "      <th>feature_1203_sms</th>\n",
       "      <th>feature_1204_sms</th>\n",
       "      <th>feature_1205_sms</th>\n",
       "      <th>feature_1206_sms</th>\n",
       "      <th>feature_1207_sms</th>\n",
       "      <th>feature_1208_sms</th>\n",
       "      <th>feature_1209_sms</th>\n",
       "      <th>feature_1210_sms</th>\n",
       "      <th>feature_1211_sms</th>\n",
       "      <th>feature_1212_sms</th>\n",
       "      <th>feature_1213_sms</th>\n",
       "      <th>feature_1214_sms</th>\n",
       "      <th>feature_1215_sms</th>\n",
       "      <th>feature_1216_sms</th>\n",
       "      <th>feature_1217_sms</th>\n",
       "      <th>feature_1218_sms</th>\n",
       "      <th>feature_1219_sms</th>\n",
       "      <th>feature_1220_sms</th>\n",
       "      <th>feature_1221_sms</th>\n",
       "      <th>feature_1222_sms</th>\n",
       "      <th>feature_1223_sms</th>\n",
       "      <th>feature_1224_sms</th>\n",
       "      <th>feature_1225_sms</th>\n",
       "      <th>feature_1226_sms</th>\n",
       "      <th>feature_1227_sms</th>\n",
       "      <th>feature_1228_sms</th>\n",
       "      <th>feature_1229_sms</th>\n",
       "      <th>feature_1230_sms</th>\n",
       "      <th>feature_1231_sms</th>\n",
       "      <th>feature_1232_sms</th>\n",
       "      <th>feature_1233_sms</th>\n",
       "      <th>feature_1234_sms</th>\n",
       "      <th>feature_1235_sms</th>\n",
       "      <th>feature_1236_sms</th>\n",
       "      <th>feature_1237_sms</th>\n",
       "      <th>feature_1238_sms</th>\n",
       "      <th>feature_1239_sms</th>\n",
       "      <th>feature_1240_sms</th>\n",
       "      <th>feature_1241_sms</th>\n",
       "      <th>feature_1242_sms</th>\n",
       "      <th>feature_1243_sms</th>\n",
       "      <th>feature_1244_sms</th>\n",
       "      <th>feature_1245_sms</th>\n",
       "      <th>feature_1246_sms</th>\n",
       "      <th>feature_1247_sms</th>\n",
       "      <th>feature_1248_sms</th>\n",
       "      <th>feature_1249_sms</th>\n",
       "      <th>feature_1250_sms</th>\n",
       "      <th>feature_1251_sms</th>\n",
       "      <th>feature_1252_sms</th>\n",
       "      <th>feature_1253_sms</th>\n",
       "      <th>feature_1254_sms</th>\n",
       "      <th>feature_1255_sms</th>\n",
       "      <th>feature_1256_sms</th>\n",
       "      <th>feature_1257_sms</th>\n",
       "      <th>feature_1258_sms</th>\n",
       "      <th>feature_1259_sms</th>\n",
       "      <th>feature_1260_sms</th>\n",
       "      <th>feature_1261_sms</th>\n",
       "      <th>feature_1262_sms</th>\n",
       "      <th>feature_1263_sms</th>\n",
       "      <th>feature_1264_sms</th>\n",
       "      <th>feature_1265_sms</th>\n",
       "      <th>feature_1266_sms</th>\n",
       "      <th>feature_1267_sms</th>\n",
       "      <th>feature_1268_sms</th>\n",
       "      <th>feature_1269_sms</th>\n",
       "      <th>feature_1270_sms</th>\n",
       "      <th>feature_1271_sms</th>\n",
       "      <th>feature_1272_sms</th>\n",
       "      <th>feature_1273_sms</th>\n",
       "      <th>feature_1274_sms</th>\n",
       "      <th>feature_1275_sms</th>\n",
       "      <th>feature_1276_sms</th>\n",
       "      <th>feature_1277_sms</th>\n",
       "      <th>feature_1278_sms</th>\n",
       "      <th>feature_1279_sms</th>\n",
       "      <th>feature_1280_sms</th>\n",
       "      <th>feature_1281_sms</th>\n",
       "      <th>feature_1282_sms</th>\n",
       "      <th>feature_1283_sms</th>\n",
       "      <th>feature_1284_sms</th>\n",
       "      <th>feature_1285_sms</th>\n",
       "      <th>feature_1286_sms</th>\n",
       "      <th>feature_1287_sms</th>\n",
       "      <th>feature_1288_sms</th>\n",
       "      <th>feature_1289_sms</th>\n",
       "      <th>feature_1290_sms</th>\n",
       "      <th>feature_1291_sms</th>\n",
       "      <th>feature_1292_sms</th>\n",
       "      <th>feature_1293_sms</th>\n",
       "      <th>feature_1294_sms</th>\n",
       "      <th>feature_1295_sms</th>\n",
       "      <th>feature_1296_sms</th>\n",
       "      <th>feature_1297_sms</th>\n",
       "      <th>feature_1298_sms</th>\n",
       "      <th>feature_1299_sms</th>\n",
       "      <th>feature_1300_sms</th>\n",
       "      <th>feature_1301_sms</th>\n",
       "      <th>feature_1302_sms</th>\n",
       "      <th>feature_1303_sms</th>\n",
       "      <th>feature_1304_sms</th>\n",
       "      <th>feature_1305_sms</th>\n",
       "      <th>feature_1306_sms</th>\n",
       "      <th>feature_1307_sms</th>\n",
       "      <th>feature_1308_sms</th>\n",
       "      <th>feature_1309_sms</th>\n",
       "      <th>feature_1310_sms</th>\n",
       "      <th>feature_1311_sms</th>\n",
       "      <th>feature_1312_sms</th>\n",
       "      <th>feature_1313_sms</th>\n",
       "      <th>feature_1314_sms</th>\n",
       "      <th>feature_1315_sms</th>\n",
       "      <th>feature_1316_sms</th>\n",
       "      <th>feature_1317_sms</th>\n",
       "      <th>feature_1318_sms</th>\n",
       "      <th>feature_1319_sms</th>\n",
       "      <th>feature_1320_sms</th>\n",
       "      <th>feature_1321_sms</th>\n",
       "      <th>feature_1322_sms</th>\n",
       "      <th>feature_1323_sms</th>\n",
       "      <th>feature_1324_sms</th>\n",
       "      <th>feature_1325_sms</th>\n",
       "      <th>feature_1326_sms</th>\n",
       "      <th>feature_1327_sms</th>\n",
       "      <th>feature_1328_sms</th>\n",
       "      <th>feature_1329_sms</th>\n",
       "      <th>feature_1330_sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>732.0</td>\n",
       "      <td>0.400396</td>\n",
       "      <td>17</td>\n",
       "      <td>6.665722</td>\n",
       "      <td>5.998750</td>\n",
       "      <td>46</td>\n",
       "      <td>6.998800</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>0.363620</td>\n",
       "      <td>59011</td>\n",
       "      <td>22</td>\n",
       "      <td>364464</td>\n",
       "      <td>16</td>\n",
       "      <td>81364</td>\n",
       "      <td>12949</td>\n",
       "      <td>28.486257</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11.397920</td>\n",
       "      <td>65.935065</td>\n",
       "      <td>5.498875</td>\n",
       "      <td>214</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87016.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>13492.000000</td>\n",
       "      <td>604227.0</td>\n",
       "      <td>33568.166667</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>42007.514571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>260.0</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.334615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85432.0</td>\n",
       "      <td>59011.0</td>\n",
       "      <td>16295.000000</td>\n",
       "      <td>224089.0</td>\n",
       "      <td>47740.988110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.40</td>\n",
       "      <td>9.840000</td>\n",
       "      <td>24.35</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.559937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.433437</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217.0</td>\n",
       "      <td>164.500000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1173.500000</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>792.642857</td>\n",
       "      <td>217.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>713.952381</td>\n",
       "      <td>564.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>281.136364</td>\n",
       "      <td>258.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197.0</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>771.045455</td>\n",
       "      <td>197.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>239.0</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.095351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>783</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>905</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>101</td>\n",
       "      <td>9</td>\n",
       "      <td>1227</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>271</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>416</td>\n",
       "      <td>26</td>\n",
       "      <td>91</td>\n",
       "      <td>166</td>\n",
       "      <td>16</td>\n",
       "      <td>2999</td>\n",
       "      <td>173</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>723</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>171</td>\n",
       "      <td>12</td>\n",
       "      <td>1088</td>\n",
       "      <td>49</td>\n",
       "      <td>201</td>\n",
       "      <td>390</td>\n",
       "      <td>42</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>0.045682</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.175182</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.306569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.124088</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.051095</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.036496</td>\n",
       "      <td>42.142857</td>\n",
       "      <td>42.142857</td>\n",
       "      <td>0.098366</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>0.210169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.098305</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>0.105085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.857143</td>\n",
       "      <td>0.376271</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>0.091525</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>38.214286</td>\n",
       "      <td>38.214286</td>\n",
       "      <td>0.178393</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>9.714286</td>\n",
       "      <td>0.254206</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>0.080374</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>4.785714</td>\n",
       "      <td>0.125234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.071429</td>\n",
       "      <td>0.368224</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>0.069159</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.065421</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>37.285714</td>\n",
       "      <td>37.285714</td>\n",
       "      <td>0.261087</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>9.142857</td>\n",
       "      <td>0.245211</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>0.088123</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.809524</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>2.476190</td>\n",
       "      <td>0.066411</td>\n",
       "      <td>3.095238</td>\n",
       "      <td>0.083014</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>30.166667</td>\n",
       "      <td>30.166667</td>\n",
       "      <td>0.301767</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.243094</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>0.081768</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>0.098343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.364641</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>0.111602</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>20.450000</td>\n",
       "      <td>21.910714</td>\n",
       "      <td>0.409136</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>4.516667</td>\n",
       "      <td>0.220864</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>0.079870</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>1.983333</td>\n",
       "      <td>0.096985</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>6.933333</td>\n",
       "      <td>0.339038</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.021190</td>\n",
       "      <td>1.516667</td>\n",
       "      <td>0.074165</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>0.135289</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>2.999</td>\n",
       "      <td>17.335260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.241080</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.057019</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.362788</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.067022</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.130043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.014005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6547</th>\n",
       "      <td>518.0</td>\n",
       "      <td>0.370718</td>\n",
       "      <td>42</td>\n",
       "      <td>34.988670</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>46</td>\n",
       "      <td>11.797840</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>0.107691</td>\n",
       "      <td>201224</td>\n",
       "      <td>22</td>\n",
       "      <td>290622</td>\n",
       "      <td>69</td>\n",
       "      <td>64832</td>\n",
       "      <td>10624</td>\n",
       "      <td>45.977511</td>\n",
       "      <td>30.990003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.244439</td>\n",
       "      <td>138.862138</td>\n",
       "      <td>12.997600</td>\n",
       "      <td>272</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>75</td>\n",
       "      <td>92.908092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98741.0</td>\n",
       "      <td>66750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8805.042136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>543500.0</td>\n",
       "      <td>212000.0</td>\n",
       "      <td>81793.398267</td>\n",
       "      <td>2748243.0</td>\n",
       "      <td>42280.661538</td>\n",
       "      <td>237771.0</td>\n",
       "      <td>50555.892598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.118252</td>\n",
       "      <td>224.0</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.647876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.101317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21779.0</td>\n",
       "      <td>21779.0</td>\n",
       "      <td>8711.600000</td>\n",
       "      <td>164164.0</td>\n",
       "      <td>21030.920771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.00</td>\n",
       "      <td>18.40</td>\n",
       "      <td>32.00</td>\n",
       "      <td>14.50</td>\n",
       "      <td>6.843975</td>\n",
       "      <td>583.80</td>\n",
       "      <td>12.973333</td>\n",
       "      <td>32.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>6.082344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.118252</td>\n",
       "      <td>3.446154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.589107</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>353.0</td>\n",
       "      <td>300.800000</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>709.092308</td>\n",
       "      <td>430.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>504.517241</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>101.40</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>431.246154</td>\n",
       "      <td>303.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>303.0</td>\n",
       "      <td>272.600000</td>\n",
       "      <td>303.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>658.938462</td>\n",
       "      <td>485.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.939072</td>\n",
       "      <td>681.0</td>\n",
       "      <td>10.476923</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.637643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>389.0</td>\n",
       "      <td>77.800000</td>\n",
       "      <td>206.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>568</td>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>184</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>32</td>\n",
       "      <td>83</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>3000</td>\n",
       "      <td>283</td>\n",
       "      <td>291</td>\n",
       "      <td>88</td>\n",
       "      <td>719</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>6</td>\n",
       "      <td>461</td>\n",
       "      <td>141</td>\n",
       "      <td>424</td>\n",
       "      <td>378</td>\n",
       "      <td>35</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.571429</td>\n",
       "      <td>12.571429</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>13.071429</td>\n",
       "      <td>13.071429</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>0.092896</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.109290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.087432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.136612</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.087432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>11.952381</td>\n",
       "      <td>11.952381</td>\n",
       "      <td>0.083667</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.067729</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.390438</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.011952</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.131474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.063745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.619048</td>\n",
       "      <td>0.135458</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.043825</td>\n",
       "      <td>1.380952</td>\n",
       "      <td>0.115538</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.066007</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>0.366337</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>0.125413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.118812</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.052805</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.033003</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>9.466667</td>\n",
       "      <td>9.466667</td>\n",
       "      <td>0.189333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.063380</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.110915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.059859</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.147887</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>1.383333</td>\n",
       "      <td>0.146127</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.040493</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>3.000</td>\n",
       "      <td>10.600707</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.239667</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.070667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.141333</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.011667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>762.0</td>\n",
       "      <td>0.420800</td>\n",
       "      <td>12</td>\n",
       "      <td>2.998002</td>\n",
       "      <td>8.992008</td>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.399920</td>\n",
       "      <td>68568</td>\n",
       "      <td>1</td>\n",
       "      <td>68932</td>\n",
       "      <td>99</td>\n",
       "      <td>364</td>\n",
       "      <td>8226</td>\n",
       "      <td>3.498751</td>\n",
       "      <td>6.994006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.498751</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>4.996004</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>6.994006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>784.400000</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>1568.800000</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1568.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25350.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>6039.172129</td>\n",
       "      <td>25350.0</td>\n",
       "      <td>5070.000000</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>6039.172129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68932.0</td>\n",
       "      <td>68568.0</td>\n",
       "      <td>27391.162791</td>\n",
       "      <td>68568.0</td>\n",
       "      <td>27391.162791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>194.400000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>194.400000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>156.666667</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>154.25</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>154.250000</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>115.2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>115.200000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>182.200000</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>182.200000</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.033150</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.033150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>327</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>464</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>114</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>972</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>21</td>\n",
       "      <td>260</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>2975</td>\n",
       "      <td>167</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1199</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>395</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>102</td>\n",
       "      <td>89</td>\n",
       "      <td>669</td>\n",
       "      <td>162</td>\n",
       "      <td>185</td>\n",
       "      <td>84</td>\n",
       "      <td>36</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>0.045378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>0.281481</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.081481</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>18.357143</td>\n",
       "      <td>18.357143</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>0.268482</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.038911</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.140078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.093385</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.027237</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>0.287938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.027237</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.023346</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>15.571429</td>\n",
       "      <td>15.571429</td>\n",
       "      <td>0.109916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>0.293578</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.051988</td>\n",
       "      <td>2.190476</td>\n",
       "      <td>0.140673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.085627</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>3.952381</td>\n",
       "      <td>0.253823</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.033639</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.061162</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.024465</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>15.466667</td>\n",
       "      <td>15.466667</td>\n",
       "      <td>0.155966</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.233333</td>\n",
       "      <td>0.338362</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.047414</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.023707</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.245690</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.036638</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>0.326723</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.233333</td>\n",
       "      <td>0.384774</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.022634</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>0.115226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.021605</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.267490</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.033951</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>2.975</td>\n",
       "      <td>17.814371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>1.199</td>\n",
       "      <td>0.403025</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.132773</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.029916</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.224874</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.062185</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.028235</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.012101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>746.0</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>27</td>\n",
       "      <td>5.998334</td>\n",
       "      <td>4.498251</td>\n",
       "      <td>46</td>\n",
       "      <td>2.749563</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.599880</td>\n",
       "      <td>47246</td>\n",
       "      <td>0</td>\n",
       "      <td>47246</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>11472</td>\n",
       "      <td>4.998667</td>\n",
       "      <td>3.749313</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.998667</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>2.499250</td>\n",
       "      <td>164</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>13.987013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43490.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>6255.000000</td>\n",
       "      <td>228499.0</td>\n",
       "      <td>45699.800000</td>\n",
       "      <td>85485.0</td>\n",
       "      <td>23840.693366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.545268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>14549.000000</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>12079.789773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.44</td>\n",
       "      <td>15.813333</td>\n",
       "      <td>25.00</td>\n",
       "      <td>9.95</td>\n",
       "      <td>6.578198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.631514</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.0</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>524.200000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>76.00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>197.400000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>161.400000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.0</td>\n",
       "      <td>209.500000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>508.600000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>381</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>441</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>629</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>207</td>\n",
       "      <td>32</td>\n",
       "      <td>71</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1129</td>\n",
       "      <td>265</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>129</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>295</td>\n",
       "      <td>42</td>\n",
       "      <td>168</td>\n",
       "      <td>181</td>\n",
       "      <td>27</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>0.064659</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.714286</td>\n",
       "      <td>21.714286</td>\n",
       "      <td>0.134632</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046053</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.059211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.138158</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>19.571429</td>\n",
       "      <td>19.571429</td>\n",
       "      <td>0.242693</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.018248</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.094891</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.182482</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.054745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>0.394161</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>0.120438</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>18.142857</td>\n",
       "      <td>18.142857</td>\n",
       "      <td>0.337467</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.020997</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.110236</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.196850</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.049869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.404199</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.018373</td>\n",
       "      <td>2.047619</td>\n",
       "      <td>0.112861</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.018373</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>0.390611</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>0.120181</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.024943</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.197279</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.049887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.566667</td>\n",
       "      <td>0.378685</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>0.120181</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>10.483333</td>\n",
       "      <td>10.483333</td>\n",
       "      <td>0.557130</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.138315</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.182830</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.062003</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>0.329094</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.050874</td>\n",
       "      <td>1.183333</td>\n",
       "      <td>0.112878</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.031797</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>1.129</td>\n",
       "      <td>4.260377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.024801</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.023915</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.122232</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.114260</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.052259</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.261293</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.037201</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.148804</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.160319</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.023915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>700.0</td>\n",
       "      <td>0.385723</td>\n",
       "      <td>52</td>\n",
       "      <td>7.748313</td>\n",
       "      <td>12.497126</td>\n",
       "      <td>46</td>\n",
       "      <td>3.666222</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.437473</td>\n",
       "      <td>40878</td>\n",
       "      <td>88</td>\n",
       "      <td>339424</td>\n",
       "      <td>12</td>\n",
       "      <td>298546</td>\n",
       "      <td>11260</td>\n",
       "      <td>20.990005</td>\n",
       "      <td>7.798640</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.999286</td>\n",
       "      <td>52.948052</td>\n",
       "      <td>3.999250</td>\n",
       "      <td>258</td>\n",
       "      <td>62</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>37.963037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>803.666667</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>1797.053298</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1202.818128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>331598.0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>28811.055984</td>\n",
       "      <td>548219.0</td>\n",
       "      <td>34263.687500</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>27368.428373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278210.0</td>\n",
       "      <td>75464.0</td>\n",
       "      <td>29261.683648</td>\n",
       "      <td>75464.0</td>\n",
       "      <td>28188.354776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>62.00</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>42.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.944272</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.942103</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332.0</td>\n",
       "      <td>268.333333</td>\n",
       "      <td>244.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>244.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>523.777778</td>\n",
       "      <td>51.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>69.20</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>285.461538</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>269.625000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.0</td>\n",
       "      <td>246.666667</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>560.937500</td>\n",
       "      <td>242.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>165.0</td>\n",
       "      <td>10.312500</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.310810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>482</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>677</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>40</td>\n",
       "      <td>19</td>\n",
       "      <td>1121</td>\n",
       "      <td>60</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>266</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>16</td>\n",
       "      <td>130</td>\n",
       "      <td>67</td>\n",
       "      <td>27</td>\n",
       "      <td>3000</td>\n",
       "      <td>159</td>\n",
       "      <td>156</td>\n",
       "      <td>57</td>\n",
       "      <td>725</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>1047</td>\n",
       "      <td>52</td>\n",
       "      <td>256</td>\n",
       "      <td>174</td>\n",
       "      <td>79</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>23.142857</td>\n",
       "      <td>23.142857</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>9.285714</td>\n",
       "      <td>0.401235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>0.290123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>22.952381</td>\n",
       "      <td>22.952381</td>\n",
       "      <td>0.160667</td>\n",
       "      <td>1.380952</td>\n",
       "      <td>0.060166</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>0.292531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.029046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>2.095238</td>\n",
       "      <td>0.091286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>0.286307</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>2.809524</td>\n",
       "      <td>0.122407</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.056017</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.018672</td>\n",
       "      <td>22.566667</td>\n",
       "      <td>22.566667</td>\n",
       "      <td>0.225667</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0.060561</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.023634</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>0.262925</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.011817</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.097489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.257016</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.137371</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.059084</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.028065</td>\n",
       "      <td>18.683333</td>\n",
       "      <td>18.683333</td>\n",
       "      <td>0.373667</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.066905</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.022302</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.046387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>0.110616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.266667</td>\n",
       "      <td>0.281891</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.014273</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.115968</td>\n",
       "      <td>1.116667</td>\n",
       "      <td>0.059768</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.024086</td>\n",
       "      <td>3.000</td>\n",
       "      <td>18.867925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.047667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>1.047</td>\n",
       "      <td>0.349000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.026333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1761 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BureauScore  MissingRate  Len_Name  Tel_nuniq  Email_nuniq  \\\n",
       "502         732.0     0.400396        17   6.665722     5.998750   \n",
       "6547        518.0     0.370718        42  34.988670    25.987506   \n",
       "6938        762.0     0.420800        12   2.998002     8.992008   \n",
       "3115        746.0     0.396552        27   5.998334     4.498251   \n",
       "3649        700.0     0.385723        52   7.748313    12.497126   \n",
       "\n",
       "      Len_of_addrs  City_nuniq  Current_State  CreditAccountActive  \\\n",
       "502             46    6.998800             27                    8   \n",
       "6547            46   11.797840             27                    7   \n",
       "6938            46    1.000000             27                    2   \n",
       "3115            46    2.749563             27                    3   \n",
       "3649            46    3.666222             27                    7   \n",
       "\n",
       "      CreditAccountTotal  CreditAccountActivePor  Outstanding_Balance_Secured  \\\n",
       "502                   22                0.363620                        59011   \n",
       "6547                  65                0.107691                       201224   \n",
       "6938                   5                0.399920                        68568   \n",
       "3115                   5                0.599880                        47246   \n",
       "3649                  16                0.437473                        40878   \n",
       "\n",
       "      Outstanding_Balance_UnSecured_Percentage  Outstanding_Balance_All  \\\n",
       "502                                         22                   364464   \n",
       "6547                                        22                   290622   \n",
       "6938                                         1                    68932   \n",
       "3115                                         0                    47246   \n",
       "3649                                        88                   339424   \n",
       "\n",
       "      Outstanding_Balance_Secured_Percentage  Outstanding_Balance_UnSecured  \\\n",
       "502                                       16                          81364   \n",
       "6547                                      69                          64832   \n",
       "6938                                      99                            364   \n",
       "3115                                     100                              0   \n",
       "3649                                      12                         298546   \n",
       "\n",
       "      Diff_dateBirth  State_nuniq  Birth_nuniq  TotalCAPSLast90Days  \\\n",
       "502            12949    28.486257    25.987506                    4   \n",
       "6547           10624    45.977511    30.990003                    1   \n",
       "6938            8226     3.498751     6.994006                    0   \n",
       "3115           11472     4.998667     3.749313                    5   \n",
       "3649           11260    20.990005     7.798640                    3   \n",
       "\n",
       "      TotalCAPSLast7Days  TotalCAPSLast30Days  TotalCAPSLast180Days  \\\n",
       "502                    3                    3                     5   \n",
       "6547                   1                    1                     2   \n",
       "6938                   0                    0                     0   \n",
       "3115                   2                    4                     6   \n",
       "3649                   2                    2                     3   \n",
       "\n",
       "      CAPSLast30Days  CAPSLast7Days  CAPSLast180Days  \\\n",
       "502                0              0                2   \n",
       "6547               0              0                1   \n",
       "6938               0              0                0   \n",
       "3115               2              0                4   \n",
       "3649               1              1                2   \n",
       "\n",
       "      NonCreditCAPSLast180Days  Pin_nuniq   Pan_nuniq  Ident_nuniq  \\\n",
       "502                          3  11.397920   65.935065     5.498875   \n",
       "6547                         1  23.244439  138.862138    12.997600   \n",
       "6938                         0   3.498751   10.990010     4.996004   \n",
       "3115                         2   4.998667   10.990010     2.499250   \n",
       "3649                         1   5.999286   52.948052     3.999250   \n",
       "\n",
       "      Name_nuniq2  Tel_nuniq2  Email_nuniq2  Pan_nuniq2  Account_nuniq2  \\\n",
       "502           214          86            93          14              14   \n",
       "6547          272          44            47          14              14   \n",
       "6938           57          14            25          14              14   \n",
       "3115          164          44            44          14              14   \n",
       "3649          258          62            87          14              14   \n",
       "\n",
       "      Ident_nuniq2  Gender_nuniq  Amount_Past_Due35_sum_30  \\\n",
       "502             60     25.987506                       NaN   \n",
       "6547            75     92.908092                       NaN   \n",
       "6938            15      6.994006                       NaN   \n",
       "3115            30     13.987013                       NaN   \n",
       "3649            60     37.963037                       NaN   \n",
       "\n",
       "      Amount_Past_Due35_min_30  Amount_Past_Due35_sum_90  \\\n",
       "502                        NaN                       NaN   \n",
       "6547                       NaN                       NaN   \n",
       "6938                       NaN                       0.0   \n",
       "3115                       NaN                       NaN   \n",
       "3649                       NaN                       NaN   \n",
       "\n",
       "      Amount_Past_Due35_mean_90  Amount_Past_Due35_max_90  \\\n",
       "502                         NaN                       NaN   \n",
       "6547                        NaN                       NaN   \n",
       "6938                        0.0                       0.0   \n",
       "3115                        NaN                       NaN   \n",
       "3649                        NaN                       NaN   \n",
       "\n",
       "      Amount_Past_Due35_min_90  Amount_Past_Due35_std_90  \\\n",
       "502                        NaN                       NaN   \n",
       "6547                       NaN                       NaN   \n",
       "6938                       0.0                       0.0   \n",
       "3115                       NaN                       NaN   \n",
       "3649                       NaN                       NaN   \n",
       "\n",
       "      Amount_Past_Due35_sum_360  Amount_Past_Due35_mean_360  \\\n",
       "502                         0.0                    0.000000   \n",
       "6547                        0.0                    0.000000   \n",
       "6938                     3922.0                  784.400000   \n",
       "3115                        0.0                    0.000000   \n",
       "3649                     4822.0                  803.666667   \n",
       "\n",
       "      Amount_Past_Due35_max_360  Amount_Past_Due35_std_360  \\\n",
       "502                         0.0                   0.000000   \n",
       "6547                        0.0                   0.000000   \n",
       "6938                     3922.0                1568.800000   \n",
       "3115                        0.0                   0.000000   \n",
       "3649                     4822.0                1797.053298   \n",
       "\n",
       "      Amount_Past_Due35_sum_9999  Amount_Past_Due35_max_9999  \\\n",
       "502                          0.0                         0.0   \n",
       "6547                     98741.0                     66750.0   \n",
       "6938                      3922.0                      3922.0   \n",
       "3115                         0.0                         0.0   \n",
       "3649                      4822.0                      4822.0   \n",
       "\n",
       "      Amount_Past_Due35_min_9999  Amount_Past_Due35_std_9999  \\\n",
       "502                          0.0                    0.000000   \n",
       "6547                         0.0                 8805.042136   \n",
       "6938                         0.0                 1568.800000   \n",
       "3115                         0.0                    0.000000   \n",
       "3649                         0.0                 1202.818128   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_30  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                              NaN   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_min_30  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                              NaN   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_30  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                              NaN   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_90  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                            350.0   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_mean_90  \\\n",
       "502                                                NaN   \n",
       "6547                                               NaN   \n",
       "6938                                             350.0   \n",
       "3115                                               NaN   \n",
       "3649                                               NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_90  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                            350.0   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_min_90  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                            350.0   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                              0.0   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_360  \\\n",
       "502                                            87016.0   \n",
       "6547                                          543500.0   \n",
       "6938                                           25350.0   \n",
       "3115                                           43490.0   \n",
       "3649                                          331598.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_360  \\\n",
       "502                                            57000.0   \n",
       "6547                                          212000.0   \n",
       "6938                                           17000.0   \n",
       "3115                                           28000.0   \n",
       "3649                                           88000.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_360  \\\n",
       "502                                       13492.000000   \n",
       "6547                                      81793.398267   \n",
       "6938                                       6039.172129   \n",
       "3115                                       6255.000000   \n",
       "3649                                      28811.055984   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "502                                            604227.0   \n",
       "6547                                          2748243.0   \n",
       "6938                                            25350.0   \n",
       "3115                                           228499.0   \n",
       "3649                                           548219.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_mean_9999  \\\n",
       "502                                        33568.166667    \n",
       "6547                                       42280.661538    \n",
       "6938                                        5070.000000    \n",
       "3115                                       45699.800000    \n",
       "3649                                       34263.687500    \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "502                                            195000.0   \n",
       "6547                                           237771.0   \n",
       "6938                                            17000.0   \n",
       "3115                                            85485.0   \n",
       "3649                                            88000.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_9999  \\\n",
       "502                                        42007.514571   \n",
       "6547                                       50555.892598   \n",
       "6938                                        6039.172129   \n",
       "3115                                       23840.693366   \n",
       "3649                                       27368.428373   \n",
       "\n",
       "      Terms_Duration34_sum_30  Terms_Duration34_std_30  \\\n",
       "502                       NaN                      NaN   \n",
       "6547                      NaN                      NaN   \n",
       "6938                      NaN                      NaN   \n",
       "3115                      NaN                      NaN   \n",
       "3649                      NaN                      NaN   \n",
       "\n",
       "      Terms_Duration34_sum_90  Terms_Duration34_std_90  \\\n",
       "502                       NaN                      NaN   \n",
       "6547                      NaN                      NaN   \n",
       "6938                      0.0                      NaN   \n",
       "3115                      NaN                      NaN   \n",
       "3649                      NaN                      NaN   \n",
       "\n",
       "      Terms_Duration34_mean_360  Terms_Duration34_max_360  \\\n",
       "502                         4.5                       8.0   \n",
       "6547                        4.8                      13.0   \n",
       "6938                       30.0                      30.0   \n",
       "3115                       11.0                      12.0   \n",
       "3649                       24.0                      24.0   \n",
       "\n",
       "      Terms_Duration34_min_360  Terms_Duration34_std_360  \\\n",
       "502                        1.0                  3.500000   \n",
       "6547                       2.0                  4.118252   \n",
       "6938                      30.0                  0.000000   \n",
       "3115                      10.0                  1.000000   \n",
       "3649                      24.0                  0.000000   \n",
       "\n",
       "      Terms_Duration34_sum_9999  Terms_Duration34_mean_9999  \\\n",
       "502                       260.0                   17.333333   \n",
       "6547                      224.0                    5.600000   \n",
       "6938                       30.0                   30.000000   \n",
       "3115                       58.0                   14.500000   \n",
       "3649                       31.0                   15.500000   \n",
       "\n",
       "      Terms_Duration34_max_9999  Terms_Duration34_min_9999  \\\n",
       "502                        47.0                        1.0   \n",
       "6547                       40.0                        0.0   \n",
       "6938                       30.0                       30.0   \n",
       "3115                       24.0                       10.0   \n",
       "3649                       24.0                        7.0   \n",
       "\n",
       "      Terms_Duration34_std_9999  Payment_Rating34_sum_90  \\\n",
       "502                   17.334615                      NaN   \n",
       "6547                   7.647876                      NaN   \n",
       "6938                   0.000000                      0.0   \n",
       "3115                   5.545268                      NaN   \n",
       "3649                   8.500000                      NaN   \n",
       "\n",
       "      Payment_Rating34_mean_90  Payment_Rating34_max_90  \\\n",
       "502                        NaN                      NaN   \n",
       "6547                       NaN                      NaN   \n",
       "6938                       0.0                      0.0   \n",
       "3115                       NaN                      NaN   \n",
       "3649                       NaN                      NaN   \n",
       "\n",
       "      Payment_Rating34_min_90  Payment_Rating34_std_90  \\\n",
       "502                       NaN                      NaN   \n",
       "6547                      NaN                      NaN   \n",
       "6938                      0.0                      0.0   \n",
       "3115                      NaN                      NaN   \n",
       "3649                      NaN                      NaN   \n",
       "\n",
       "      Payment_Rating34_sum_360  Payment_Rating34_mean_360  \\\n",
       "502                        0.0                        0.0   \n",
       "6547                       0.0                        0.0   \n",
       "6938                       0.0                        0.0   \n",
       "3115                       0.0                        0.0   \n",
       "3649                       0.0                        0.0   \n",
       "\n",
       "      Payment_Rating34_max_360  Payment_Rating34_min_360  \\\n",
       "502                        0.0                       0.0   \n",
       "6547                       0.0                       0.0   \n",
       "6938                       0.0                       0.0   \n",
       "3115                       0.0                       0.0   \n",
       "3649                       0.0                       0.0   \n",
       "\n",
       "      Payment_Rating34_std_360  Payment_Rating34_sum_9999  \\\n",
       "502                        0.0                        0.0   \n",
       "6547                       0.0                       17.0   \n",
       "6938                       0.0                        0.0   \n",
       "3115                       0.0                        0.0   \n",
       "3649                       0.0                        0.0   \n",
       "\n",
       "      Payment_Rating34_mean_9999  Payment_Rating34_max_9999  \\\n",
       "502                     0.000000                        0.0   \n",
       "6547                    0.269841                        6.0   \n",
       "6938                    0.000000                        0.0   \n",
       "3115                    0.000000                        0.0   \n",
       "3649                    0.000000                        0.0   \n",
       "\n",
       "      Payment_Rating34_min_9999  Payment_Rating34_std_9999  \\\n",
       "502                         0.0                   0.000000   \n",
       "6547                        0.0                   1.101317   \n",
       "6938                        0.0                   0.000000   \n",
       "3115                        0.0                   0.000000   \n",
       "3649                        0.0                   0.000000   \n",
       "\n",
       "      Current_Balance35_mean_30  Current_Balance35_min_30  \\\n",
       "502                         NaN                       NaN   \n",
       "6547                        NaN                       NaN   \n",
       "6938                        NaN                       NaN   \n",
       "3115                        NaN                       NaN   \n",
       "3649                        NaN                       NaN   \n",
       "\n",
       "      Current_Balance35_std_30  Current_Balance35_sum_90  \\\n",
       "502                        NaN                       NaN   \n",
       "6547                       NaN                       NaN   \n",
       "6938                       NaN                     364.0   \n",
       "3115                       NaN                       NaN   \n",
       "3649                       NaN                       NaN   \n",
       "\n",
       "      Current_Balance35_mean_90  Current_Balance35_max_90  \\\n",
       "502                         NaN                       NaN   \n",
       "6547                        NaN                       NaN   \n",
       "6938                      364.0                     364.0   \n",
       "3115                        NaN                       NaN   \n",
       "3649                        NaN                       NaN   \n",
       "\n",
       "      Current_Balance35_std_90  Current_Balance35_sum_360  \\\n",
       "502                        NaN                    85432.0   \n",
       "6547                       NaN                    21779.0   \n",
       "6938                       0.0                    68932.0   \n",
       "3115                       NaN                    29098.0   \n",
       "3649                       NaN                   278210.0   \n",
       "\n",
       "      Current_Balance35_max_360  Current_Balance35_std_360  \\\n",
       "502                     59011.0               16295.000000   \n",
       "6547                    21779.0                8711.600000   \n",
       "6938                    68568.0               27391.162791   \n",
       "3115                    29098.0               14549.000000   \n",
       "3649                    75464.0               29261.683648   \n",
       "\n",
       "      Current_Balance35_max_9999  Current_Balance35_std_9999  \\\n",
       "502                     224089.0                47740.988110   \n",
       "6547                    164164.0                21030.920771   \n",
       "6938                     68568.0                27391.162791   \n",
       "3115                     29098.0                12079.789773   \n",
       "3649                     75464.0                28188.354776   \n",
       "\n",
       "      Settlement_Amount37_max_360  Settlement_Amount37_min_360  \\\n",
       "502                           NaN                          NaN   \n",
       "6547                          NaN                          NaN   \n",
       "6938                          0.0                          0.0   \n",
       "3115                          NaN                          NaN   \n",
       "3649                          NaN                          NaN   \n",
       "\n",
       "      Settlement_Amount37_std_360  Settlement_Amount37_sum_9999  \\\n",
       "502                           NaN                           0.0   \n",
       "6547                          NaN                           0.0   \n",
       "6938                          0.0                           0.0   \n",
       "3115                          NaN                           0.0   \n",
       "3649                          NaN                           0.0   \n",
       "\n",
       "      Settlement_Amount37_mean_9999  Settlement_Amount37_max_9999  \\\n",
       "502                             0.0                           0.0   \n",
       "6547                            0.0                           0.0   \n",
       "6938                            0.0                           0.0   \n",
       "3115                            NaN                           NaN   \n",
       "3649                            0.0                           0.0   \n",
       "\n",
       "      Settlement_Amount37_min_9999  Settlement_Amount37_std_9999  \\\n",
       "502                            0.0                           0.0   \n",
       "6547                           0.0                           0.0   \n",
       "6938                           0.0                           0.0   \n",
       "3115                           NaN                           NaN   \n",
       "3649                           0.0                           0.0   \n",
       "\n",
       "      Value_of_Collateral39_std_90  Value_of_Collateral39_std_360  \\\n",
       "502                            NaN                            0.0   \n",
       "6547                           NaN                            NaN   \n",
       "6938                           NaN                            NaN   \n",
       "3115                           NaN                            0.0   \n",
       "3649                           NaN                            0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_sum_360  Written_Off_Amt_Total41_mean_360  \\\n",
       "502                               0.0                               NaN   \n",
       "6547                              0.0                               NaN   \n",
       "6938                              0.0                               0.0   \n",
       "3115                              0.0                               NaN   \n",
       "3649                              0.0                               0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_min_360  Written_Off_Amt_Total41_std_360  \\\n",
       "502                               NaN                              NaN   \n",
       "6547                              NaN                              NaN   \n",
       "6938                              0.0                              0.0   \n",
       "3115                              NaN                              NaN   \n",
       "3649                              0.0                              0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_sum_9999  Written_Off_Amt_Total41_mean_9999  \\\n",
       "502                                0.0                                0.0   \n",
       "6547                               0.0                                0.0   \n",
       "6938                               0.0                                0.0   \n",
       "3115                               0.0                                NaN   \n",
       "3649                               0.0                                0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_max_9999  Written_Off_Amt_Total41_min_9999  \\\n",
       "502                                0.0                               0.0   \n",
       "6547                               0.0                               0.0   \n",
       "6938                               0.0                               0.0   \n",
       "3115                               NaN                               NaN   \n",
       "3649                               0.0                               0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_std_9999  Written_Off_Amt_Principal45_sum_360  \\\n",
       "502                                0.0                                  0.0   \n",
       "6547                               0.0                                  0.0   \n",
       "6938                               0.0                                  0.0   \n",
       "3115                               NaN                                  0.0   \n",
       "3649                               0.0                                  0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_mean_360  \\\n",
       "502                                    NaN   \n",
       "6547                                   NaN   \n",
       "6938                                   0.0   \n",
       "3115                                   NaN   \n",
       "3649                                   NaN   \n",
       "\n",
       "      Written_Off_Amt_Principal45_min_360  \\\n",
       "502                                   NaN   \n",
       "6547                                  NaN   \n",
       "6938                                  0.0   \n",
       "3115                                  NaN   \n",
       "3649                                  NaN   \n",
       "\n",
       "      Written_Off_Amt_Principal45_std_360  \\\n",
       "502                                   NaN   \n",
       "6547                                  NaN   \n",
       "6938                                  0.0   \n",
       "3115                                  NaN   \n",
       "3649                                  NaN   \n",
       "\n",
       "      Written_Off_Amt_Principal45_max_9999  \\\n",
       "502                                    0.0   \n",
       "6547                                   0.0   \n",
       "6938                                   0.0   \n",
       "3115                                   0.0   \n",
       "3649                                   0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_min_9999  Rate_of_Interest36_sum_30  \\\n",
       "502                                    0.0                        NaN   \n",
       "6547                                   0.0                        NaN   \n",
       "6938                                   0.0                        NaN   \n",
       "3115                                   0.0                        NaN   \n",
       "3649                                   0.0                        NaN   \n",
       "\n",
       "      Rate_of_Interest36_std_30  Rate_of_Interest36_sum_90  \\\n",
       "502                         NaN                        NaN   \n",
       "6547                        NaN                        NaN   \n",
       "6938                        NaN                        0.0   \n",
       "3115                        NaN                        NaN   \n",
       "3649                        NaN                        NaN   \n",
       "\n",
       "      Rate_of_Interest36_mean_90  Rate_of_Interest36_max_90  \\\n",
       "502                          NaN                        NaN   \n",
       "6547                         NaN                        NaN   \n",
       "6938                         NaN                        NaN   \n",
       "3115                         NaN                        NaN   \n",
       "3649                         NaN                        NaN   \n",
       "\n",
       "      Rate_of_Interest36_std_90  Rate_of_Interest36_sum_360  \\\n",
       "502                         NaN                        7.40   \n",
       "6547                        NaN                       92.00   \n",
       "6938                        NaN                        0.00   \n",
       "3115                        NaN                        9.95   \n",
       "3649                        NaN                       62.00   \n",
       "\n",
       "      Rate_of_Interest36_mean_360  Rate_of_Interest36_max_360  \\\n",
       "502                          7.40                        7.40   \n",
       "6547                        18.40                       32.00   \n",
       "6938                          NaN                         NaN   \n",
       "3115                         9.95                        9.95   \n",
       "3649                        31.00                       42.00   \n",
       "\n",
       "      Rate_of_Interest36_min_360  Rate_of_Interest36_std_360  \\\n",
       "502                         7.40                    0.000000   \n",
       "6547                       14.50                    6.843975   \n",
       "6938                         NaN                         NaN   \n",
       "3115                        9.95                    0.000000   \n",
       "3649                       20.00                   11.000000   \n",
       "\n",
       "      Rate_of_Interest36_sum_9999  Rate_of_Interest36_mean_9999  \\\n",
       "502                         98.40                      9.840000   \n",
       "6547                       583.80                     12.973333   \n",
       "6938                         0.00                           NaN   \n",
       "3115                        47.44                     15.813333   \n",
       "3649                        62.00                     31.000000   \n",
       "\n",
       "      Rate_of_Interest36_max_9999  Rate_of_Interest36_min_9999  \\\n",
       "502                         24.35                         1.00   \n",
       "6547                        32.00                         1.40   \n",
       "6938                          NaN                          NaN   \n",
       "3115                        25.00                         9.95   \n",
       "3649                        42.00                        20.00   \n",
       "\n",
       "      Rate_of_Interest36_std_9999  Repayment_Tenure36_std_30  \\\n",
       "502                      5.559937                        NaN   \n",
       "6547                     6.082344                        NaN   \n",
       "6938                          NaN                        NaN   \n",
       "3115                     6.578198                        NaN   \n",
       "3649                    11.000000                        NaN   \n",
       "\n",
       "      Repayment_Tenure36_mean_90  Repayment_Tenure36_max_90  \\\n",
       "502                          NaN                        NaN   \n",
       "6547                         NaN                        NaN   \n",
       "6938                         0.0                        0.0   \n",
       "3115                         NaN                        NaN   \n",
       "3649                         NaN                        NaN   \n",
       "\n",
       "      Repayment_Tenure36_min_90  Repayment_Tenure36_std_90  \\\n",
       "502                         NaN                        NaN   \n",
       "6547                        NaN                        NaN   \n",
       "6938                        0.0                        0.0   \n",
       "3115                        NaN                        NaN   \n",
       "3649                        NaN                        NaN   \n",
       "\n",
       "      Repayment_Tenure36_sum_360  Repayment_Tenure36_mean_360  \\\n",
       "502                          9.0                          4.5   \n",
       "6547                        24.0                          4.8   \n",
       "6938                        30.0                          6.0   \n",
       "3115                        22.0                         11.0   \n",
       "3649                        24.0                          4.0   \n",
       "\n",
       "      Repayment_Tenure36_min_360  Repayment_Tenure36_std_360  \\\n",
       "502                          1.0                    3.500000   \n",
       "6547                         2.0                    4.118252   \n",
       "6938                         0.0                   12.000000   \n",
       "3115                        10.0                    1.000000   \n",
       "3649                         0.0                    8.944272   \n",
       "\n",
       "      Repayment_Tenure36_mean_9999  Repayment_Tenure36_min_9999  \\\n",
       "502                      11.818182                          0.0   \n",
       "6547                      3.446154                          0.0   \n",
       "6938                      6.000000                          0.0   \n",
       "3115                     11.600000                          0.0   \n",
       "3649                      1.937500                          0.0   \n",
       "\n",
       "      Repayment_Tenure36_std_9999  Income26_count_360  Income26_std_360  \\\n",
       "502                     16.433437                 2.0               NaN   \n",
       "6547                     6.589107                 5.0               NaN   \n",
       "6938                    12.000000                 5.0               NaN   \n",
       "3115                     7.631514                 2.0               NaN   \n",
       "3649                     5.942103                 6.0               NaN   \n",
       "\n",
       "      Open_Date29_max_30  Open_Date29_min_30  Open_Date29_mean_30  \\\n",
       "502                  NaN                 NaN                  NaN   \n",
       "6547                 NaN                 NaN                  NaN   \n",
       "6938                 NaN                 NaN                  NaN   \n",
       "3115                 NaN                 NaN                  NaN   \n",
       "3649                 NaN                 NaN                  NaN   \n",
       "\n",
       "      Open_Date29_nuniq_30  Open_Date29_maxcount_30  Open_Date29_max_90  \\\n",
       "502                    NaN                      NaN                 NaN   \n",
       "6547                   NaN                      NaN                 NaN   \n",
       "6938                   NaN                      NaN                89.0   \n",
       "3115                   NaN                      NaN                 NaN   \n",
       "3649                   NaN                      NaN                 NaN   \n",
       "\n",
       "      Open_Date29_mean_90  Open_Date29_mode_90  Open_Date29_nuniq_90  \\\n",
       "502                   NaN                  NaN                   NaN   \n",
       "6547                  NaN                  NaN                   NaN   \n",
       "6938                 89.0                 89.0                   1.0   \n",
       "3115                  NaN                  NaN                   NaN   \n",
       "3649                  NaN                  NaN                   NaN   \n",
       "\n",
       "      Open_Date29_maxcount_90  Open_Date29_max_360  Open_Date29_mean_360  \\\n",
       "502                       NaN                217.0            164.500000   \n",
       "6547                      NaN                353.0            300.800000   \n",
       "6938                      1.0                307.0            194.400000   \n",
       "3115                      NaN                304.0            219.000000   \n",
       "3649                      NaN                332.0            268.333333   \n",
       "\n",
       "      Open_Date29_mode_360  Open_Date29_nuniq_360  Open_Date29_maxcount_360  \\\n",
       "502                  112.0                    2.0                       1.0   \n",
       "6547                 212.0                    5.0                       1.0   \n",
       "6938                  89.0                    5.0                       1.0   \n",
       "3115                 134.0                    2.0                       1.0   \n",
       "3649                 244.0                    6.0                       1.0   \n",
       "\n",
       "      Open_Date29_max_9999  Open_Date29_mean_9999  Open_Date29_mode_9999  \\\n",
       "502                 2400.0            1173.500000                 1627.0   \n",
       "6547                1940.0             709.092308                  430.0   \n",
       "6938                 307.0             194.400000                   89.0   \n",
       "3115                1019.0             524.200000                  134.0   \n",
       "3649                1156.0             584.000000                  244.0   \n",
       "\n",
       "      Open_Date29_maxcount_9999  Portfolio_Type34_nuniq_30  \\\n",
       "502                         4.0                        NaN   \n",
       "6547                        3.0                        NaN   \n",
       "6938                        1.0                        NaN   \n",
       "3115                        1.0                        NaN   \n",
       "3649                        1.0                        NaN   \n",
       "\n",
       "      Portfolio_Type34_nuniq_90  Portfolio_Type34_nuniq_360  \\\n",
       "502                         NaN                         1.0   \n",
       "6547                        NaN                         1.0   \n",
       "6938                        1.0                         1.0   \n",
       "3115                        NaN                         1.0   \n",
       "3649                        NaN                         2.0   \n",
       "\n",
       "      Portfolio_Type34_nuniq_9999  Account_Type32_nuniq_30  \\\n",
       "502                           2.0                      NaN   \n",
       "6547                          3.0                      NaN   \n",
       "6938                          1.0                      NaN   \n",
       "3115                          1.0                      NaN   \n",
       "3649                          2.0                      NaN   \n",
       "\n",
       "      Account_Type32_nuniq_90  Account_Type32_nuniq_360  \\\n",
       "502                       NaN                       2.0   \n",
       "6547                      NaN                       2.0   \n",
       "6938                      1.0                       2.0   \n",
       "3115                      NaN                       2.0   \n",
       "3649                      NaN                       4.0   \n",
       "\n",
       "      Account_Type32_nuniq_9999  Occupation_Code35_nuniq_30  \\\n",
       "502                         5.0                         NaN   \n",
       "6547                        8.0                         NaN   \n",
       "6938                        2.0                         NaN   \n",
       "3115                        5.0                         NaN   \n",
       "3649                        4.0                         NaN   \n",
       "\n",
       "      Occupation_Code35_nuniq_90  Occupation_Code35_nuniq_360  \\\n",
       "502                          NaN                          1.0   \n",
       "6547                         NaN                          1.0   \n",
       "6938                         1.0                          1.0   \n",
       "3115                         NaN                          1.0   \n",
       "3649                         NaN                          1.0   \n",
       "\n",
       "      Occupation_Code35_nuniq_9999  AccountHoldertypeCode41_nuniq_90  \\\n",
       "502                            1.0                               NaN   \n",
       "6547                           1.0                               NaN   \n",
       "6938                           1.0                               1.0   \n",
       "3115                           1.0                               NaN   \n",
       "3649                           2.0                               NaN   \n",
       "\n",
       "      AccountHoldertypeCode41_nuniq_360  AccountHoldertypeCode41_nuniq_9999  \\\n",
       "502                                 1.0                                 2.0   \n",
       "6547                                1.0                                 2.0   \n",
       "6938                                1.0                                 1.0   \n",
       "3115                                1.0                                 1.0   \n",
       "3649                                1.0                                 1.0   \n",
       "\n",
       "      Payment_History_Profile43_mode_30  Payment_History_Profile43_mode_90  \\\n",
       "502                                   0                                  0   \n",
       "6547                                  0                                  0   \n",
       "6938                                  0                                  1   \n",
       "3115                                  0                                  0   \n",
       "3649                                  0                                  0   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_90  Payment_History_Profile43_mode_360  \\\n",
       "502                                  NaN                                  36   \n",
       "6547                                 NaN                                  36   \n",
       "6938                                 1.0                                   1   \n",
       "3115                                 NaN                                  36   \n",
       "3649                                 NaN                                  36   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_360  \\\n",
       "502                                   2.0   \n",
       "6547                                  4.0   \n",
       "6938                                  4.0   \n",
       "3115                                  2.0   \n",
       "3649                                  4.0   \n",
       "\n",
       "      Payment_History_Profile43_mode_9999  \\\n",
       "502                                    36   \n",
       "6547                                   36   \n",
       "6938                                    1   \n",
       "3115                                   36   \n",
       "3649                                   36   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_9999  Date_Closed31_nuniq_30  \\\n",
       "502                                   19.0                     NaN   \n",
       "6547                                  30.0                     NaN   \n",
       "6938                                   4.0                     NaN   \n",
       "3115                                   5.0                     NaN   \n",
       "3649                                  12.0                     NaN   \n",
       "\n",
       "      Date_Closed31_maxcount_30  Date_Closed31_max_90  Date_Closed31_min_90  \\\n",
       "502                         NaN                   NaN                   NaN   \n",
       "6547                        NaN                   NaN                   NaN   \n",
       "6938                        NaN                   NaN                   NaN   \n",
       "3115                        NaN                   NaN                   NaN   \n",
       "3649                        NaN                   NaN                   NaN   \n",
       "\n",
       "      Date_Closed31_mean_90  Date_Closed31_mode_90  Date_Closed31_nuniq_90  \\\n",
       "502                     NaN                    NaN                     NaN   \n",
       "6547                    NaN                    NaN                     NaN   \n",
       "6938                    NaN                    0.0                     1.0   \n",
       "3115                    NaN                    NaN                     NaN   \n",
       "3649                    NaN                    NaN                     NaN   \n",
       "\n",
       "      Date_Closed31_maxcount_90  Date_Closed31_min_360  \\\n",
       "502                         NaN                    NaN   \n",
       "6547                        NaN                   30.0   \n",
       "6938                        0.0                   91.0   \n",
       "3115                        NaN                    NaN   \n",
       "3649                        NaN                   74.0   \n",
       "\n",
       "      Date_Closed31_mode_360  Date_Closed31_nuniq_360  \\\n",
       "502                      0.0                      1.0   \n",
       "6547                    30.0                      3.0   \n",
       "6938                    91.0                      4.0   \n",
       "3115                     0.0                      1.0   \n",
       "3649                    74.0                      2.0   \n",
       "\n",
       "      Date_Closed31_maxcount_360  Date_Closed31_max_9999  \\\n",
       "502                          0.0                  1790.0   \n",
       "6547                         3.0                  1327.0   \n",
       "6938                         1.0                   222.0   \n",
       "3115                         0.0                   660.0   \n",
       "3649                         1.0                   939.0   \n",
       "\n",
       "      Date_Closed31_min_9999  Date_Closed31_mean_9999  \\\n",
       "502                    217.0               792.642857   \n",
       "6547                    30.0               504.517241   \n",
       "6938                    91.0               156.666667   \n",
       "3115                   124.0               392.000000   \n",
       "3649                    51.0               523.777778   \n",
       "\n",
       "      Date_Closed31_mode_9999  Date_Closed31_nuniq_9999  \\\n",
       "502                     217.0                      15.0   \n",
       "6547                     30.0                      38.0   \n",
       "6938                     91.0                       4.0   \n",
       "3115                    124.0                       3.0   \n",
       "3649                     51.0                      10.0   \n",
       "\n",
       "      Date_of_Last_Payment40_nuniq_30  Date_of_Last_Payment40_maxcount_30  \\\n",
       "502                               NaN                                 NaN   \n",
       "6547                              NaN                                 NaN   \n",
       "6938                              NaN                                 NaN   \n",
       "3115                              NaN                                 NaN   \n",
       "3649                              NaN                                 NaN   \n",
       "\n",
       "      Date_of_Last_Payment40_min_90  Date_of_Last_Payment40_nuniq_90  \\\n",
       "502                             NaN                              NaN   \n",
       "6547                            NaN                              NaN   \n",
       "6938                            NaN                              1.0   \n",
       "3115                            NaN                              NaN   \n",
       "3649                            NaN                              NaN   \n",
       "\n",
       "      Date_of_Last_Payment40_maxcount_90  Date_of_Last_Payment40_max_360  \\\n",
       "502                                  NaN                            73.0   \n",
       "6547                                 NaN                           212.0   \n",
       "6938                                 0.0                           222.0   \n",
       "3115                                 NaN                           119.0   \n",
       "3649                                 NaN                           100.0   \n",
       "\n",
       "      Date_of_Last_Payment40_min_360  Date_of_Last_Payment40_mean_360  \\\n",
       "502                             73.0                            73.00   \n",
       "6547                            31.0                           101.40   \n",
       "6938                            91.0                           154.25   \n",
       "3115                            33.0                            76.00   \n",
       "3649                            50.0                            69.20   \n",
       "\n",
       "      Date_of_Last_Payment40_mode_360  Date_of_Last_Payment40_nuniq_360  \\\n",
       "502                              73.0                               2.0   \n",
       "6547                             31.0                               3.0   \n",
       "6938                             91.0                               5.0   \n",
       "3115                             33.0                               2.0   \n",
       "3649                             50.0                               6.0   \n",
       "\n",
       "      Date_of_Last_Payment40_maxcount_360  Date_of_Last_Payment40_max_9999  \\\n",
       "502                                   1.0                           1957.0   \n",
       "6547                                  3.0                           1327.0   \n",
       "6938                                  1.0                            222.0   \n",
       "3115                                  1.0                            660.0   \n",
       "3649                                  1.0                            941.0   \n",
       "\n",
       "      Date_of_Last_Payment40_min_9999  Date_of_Last_Payment40_mean_9999  \\\n",
       "502                              73.0                        713.952381   \n",
       "6547                             31.0                        490.000000   \n",
       "6938                             91.0                        154.250000   \n",
       "3115                             33.0                        197.400000   \n",
       "3649                             35.0                        285.461538   \n",
       "\n",
       "      Date_of_Last_Payment40_mode_9999  Date_of_Last_Payment40_maxcount_9999  \\\n",
       "502                              564.0                                   2.0   \n",
       "6547                              31.0                                   8.0   \n",
       "6938                              91.0                                   1.0   \n",
       "3115                              33.0                                   1.0   \n",
       "3649                              53.0                                   2.0   \n",
       "\n",
       "      Date_Reported33_nuniq_30  Date_Reported33_max_90  \\\n",
       "502                        NaN                     NaN   \n",
       "6547                       NaN                     NaN   \n",
       "6938                       NaN                    60.0   \n",
       "3115                       NaN                     NaN   \n",
       "3649                       NaN                     NaN   \n",
       "\n",
       "      Date_Reported33_mean_90  Date_Reported33_mode_90  \\\n",
       "502                       NaN                      NaN   \n",
       "6547                      NaN                      NaN   \n",
       "6938                     60.0                     60.0   \n",
       "3115                      NaN                      NaN   \n",
       "3649                      NaN                      NaN   \n",
       "\n",
       "      Date_Reported33_nuniq_90  Date_Reported33_maxcount_90  \\\n",
       "502                        NaN                          NaN   \n",
       "6547                       NaN                          NaN   \n",
       "6938                       1.0                          1.0   \n",
       "3115                       NaN                          NaN   \n",
       "3649                       NaN                          NaN   \n",
       "\n",
       "      Date_Reported33_max_360  Date_Reported33_mean_360  \\\n",
       "502                      44.0                      44.0   \n",
       "6547                    181.0                      64.8   \n",
       "6938                    213.0                     115.2   \n",
       "3115                     58.0                      42.5   \n",
       "3649                     58.0                      48.0   \n",
       "\n",
       "      Date_Reported33_mode_360  Date_Reported33_nuniq_360  \\\n",
       "502                       44.0                        1.0   \n",
       "6547                      28.0                        3.0   \n",
       "6938                      60.0                        4.0   \n",
       "3115                      27.0                        2.0   \n",
       "3649                      58.0                        2.0   \n",
       "\n",
       "      Date_Reported33_maxcount_360  Date_Reported33_max_9999  \\\n",
       "502                            2.0                     989.0   \n",
       "6547                           3.0                    1854.0   \n",
       "6938                           2.0                     213.0   \n",
       "3115                           1.0                     576.0   \n",
       "3649                           4.0                     912.0   \n",
       "\n",
       "      Date_Reported33_mean_9999  Date_Reported33_mode_9999  \\\n",
       "502                  281.136364                      258.0   \n",
       "6547                 431.246154                      303.0   \n",
       "6938                 115.200000                       60.0   \n",
       "3115                 161.400000                       27.0   \n",
       "3649                 269.625000                       28.0   \n",
       "\n",
       "      Date_Reported33_nuniq_9999  Date_Reported33_maxcount_9999  \\\n",
       "502                         11.0                            5.0   \n",
       "6547                        26.0                           12.0   \n",
       "6938                         4.0                            2.0   \n",
       "3115                         4.0                            2.0   \n",
       "3649                         8.0                            5.0   \n",
       "\n",
       "      DateOfAddition34_nuniq_30  DateOfAddition34_max_90  \\\n",
       "502                         NaN                      NaN   \n",
       "6547                        NaN                      NaN   \n",
       "6938                        NaN                     60.0   \n",
       "3115                        NaN                      NaN   \n",
       "3649                        NaN                      NaN   \n",
       "\n",
       "      DateOfAddition34_mean_90  DateOfAddition34_mode_90  \\\n",
       "502                        NaN                       NaN   \n",
       "6547                       NaN                       NaN   \n",
       "6938                      60.0                      60.0   \n",
       "3115                       NaN                       NaN   \n",
       "3649                       NaN                       NaN   \n",
       "\n",
       "      DateOfAddition34_nuniq_90  DateOfAddition34_maxcount_90  \\\n",
       "502                         NaN                           NaN   \n",
       "6547                        NaN                           NaN   \n",
       "6938                        1.0                           1.0   \n",
       "3115                        NaN                           NaN   \n",
       "3649                        NaN                           NaN   \n",
       "\n",
       "      DateOfAddition34_max_360  DateOfAddition34_mean_360  \\\n",
       "502                      197.0                 151.000000   \n",
       "6547                     303.0                 272.600000   \n",
       "6938                     303.0                 182.200000   \n",
       "3115                     300.0                 209.500000   \n",
       "3649                     301.0                 246.666667   \n",
       "\n",
       "      DateOfAddition34_mode_360  DateOfAddition34_nuniq_360  \\\n",
       "502                       105.0                         2.0   \n",
       "6547                      303.0                         3.0   \n",
       "6938                      213.0                         4.0   \n",
       "3115                      119.0                         2.0   \n",
       "3649                      242.0                         3.0   \n",
       "\n",
       "      DateOfAddition34_maxcount_360  DateOfAddition34_max_9999  \\\n",
       "502                             1.0                     2115.0   \n",
       "6547                            3.0                     1885.0   \n",
       "6938                            2.0                      303.0   \n",
       "3115                            1.0                     1003.0   \n",
       "3649                            4.0                     1154.0   \n",
       "\n",
       "      DateOfAddition34_mean_9999  DateOfAddition34_mode_9999  \\\n",
       "502                   771.045455                       197.0   \n",
       "6547                  658.938462                       485.0   \n",
       "6938                  182.200000                       213.0   \n",
       "3115                  508.600000                       119.0   \n",
       "3649                  560.937500                       242.0   \n",
       "\n",
       "      DateOfAddition34_nuniq_9999  DateOfAddition34_maxcount_9999  \\\n",
       "502                          15.0                             5.0   \n",
       "6547                         27.0                             5.0   \n",
       "6938                          4.0                             2.0   \n",
       "3115                          5.0                             1.0   \n",
       "3649                         12.0                             4.0   \n",
       "\n",
       "      Account_Status34_mode_30  Account_Status34_nuniq_30  \\\n",
       "502                        NaN                        NaN   \n",
       "6547                       NaN                        NaN   \n",
       "6938                       NaN                        NaN   \n",
       "3115                       NaN                        NaN   \n",
       "3649                       NaN                        NaN   \n",
       "\n",
       "      Account_Status34_mode_90  Account_Status34_nuniq_90  \\\n",
       "502                        NaN                        NaN   \n",
       "6547                       NaN                        NaN   \n",
       "6938                      11.0                        1.0   \n",
       "3115                       NaN                        NaN   \n",
       "3649                       NaN                        NaN   \n",
       "\n",
       "      Account_Status34_mode_360  Account_Status34_nuniq_360  \\\n",
       "502                        11.0                         2.0   \n",
       "6547                       13.0                         2.0   \n",
       "6938                       13.0                         2.0   \n",
       "3115                       11.0                         1.0   \n",
       "3649                       11.0                         2.0   \n",
       "\n",
       "      Account_Status34_nuniq_9999  Month50_sum_30  Month50_max_30  \\\n",
       "502                           4.0             NaN             NaN   \n",
       "6547                          8.0             NaN             NaN   \n",
       "6938                          2.0             NaN             NaN   \n",
       "3115                          2.0             NaN             NaN   \n",
       "3649                          2.0             NaN             NaN   \n",
       "\n",
       "      Month50_std_30  Month50_sum_90  Month50_mean_90  Month50_max_90  \\\n",
       "502              NaN             NaN              NaN             NaN   \n",
       "6547             NaN             NaN              NaN             NaN   \n",
       "6938             NaN             8.0              8.0             8.0   \n",
       "3115             NaN             NaN              NaN             NaN   \n",
       "3649             NaN             NaN              NaN             NaN   \n",
       "\n",
       "      Month50_min_90  Month50_std_90  Month50_sum_360  Month50_min_360  \\\n",
       "502              NaN             NaN             20.0             10.0   \n",
       "6547             NaN             NaN             54.0              7.0   \n",
       "6938             8.0             0.0             35.0              3.0   \n",
       "3115             NaN             NaN             19.0              9.0   \n",
       "3649             NaN             NaN             54.0              8.0   \n",
       "\n",
       "      Month50_std_360  Month50_sum_9999  Month50_mean_9999  Month50_max_9999  \\\n",
       "502          0.000000             239.0          10.863636              12.0   \n",
       "6547         1.939072             681.0          10.476923              12.0   \n",
       "6938         3.033150              35.0           7.000000              12.0   \n",
       "3115         0.500000              55.0          11.000000              12.0   \n",
       "3649         1.414214             165.0          10.312500              12.0   \n",
       "\n",
       "      Month50_min_9999  Month50_std_9999  Days_Past_Due58_max_30  \\\n",
       "502                3.0          2.095351                     NaN   \n",
       "6547               1.0          2.637643                     NaN   \n",
       "6938               3.0          3.033150                     NaN   \n",
       "3115               9.0          1.264911                     NaN   \n",
       "3649               4.0          2.310810                     NaN   \n",
       "\n",
       "      Days_Past_Due58_min_30  Days_Past_Due58_mean_90  Days_Past_Due58_max_90  \\\n",
       "502                      NaN                      NaN                     NaN   \n",
       "6547                     NaN                      NaN                     NaN   \n",
       "6938                     NaN                      0.0                     0.0   \n",
       "3115                     NaN                      NaN                     NaN   \n",
       "3649                     NaN                      NaN                     NaN   \n",
       "\n",
       "      Days_Past_Due58_min_90  Days_Past_Due58_std_90  Days_Past_Due58_sum_360  \\\n",
       "502                      NaN                     NaN                      0.0   \n",
       "6547                     NaN                     NaN                    389.0   \n",
       "6938                     0.0                     0.0                     26.0   \n",
       "3115                     NaN                     NaN                      0.0   \n",
       "3649                     NaN                     NaN                     23.0   \n",
       "\n",
       "      Days_Past_Due58_mean_360  Days_Past_Due58_max_360  ...  \\\n",
       "502                   0.000000                      0.0  ...   \n",
       "6547                 77.800000                    206.0  ...   \n",
       "6938                  5.200000                     26.0  ...   \n",
       "3115                  0.000000                      0.0  ...   \n",
       "3649                  3.833333                     22.0  ...   \n",
       "\n",
       "      feature_1031_sms  feature_1032_sms  feature_1033_sms  feature_1034_sms  \\\n",
       "502                  7               783                21                 3   \n",
       "6547                 1               251                21                17   \n",
       "6938                 5               327                21                 0   \n",
       "3115                 6               381                21                 6   \n",
       "3649                 6               482                21                29   \n",
       "\n",
       "      feature_1035_sms  feature_1036_sms  feature_1037_sms  feature_1038_sms  \\\n",
       "502                  4               192                 1                 4   \n",
       "6547                 1                98                 3                 4   \n",
       "6938                 0                96                 2                17   \n",
       "3115                 8                42                 2                 9   \n",
       "3649                10               141                 0                 5   \n",
       "\n",
       "      feature_1039_sms  feature_1040_sms  feature_1041_sms  feature_1042_sms  \\\n",
       "502                 69                 1                 1                87   \n",
       "6547                33                 0                 1                16   \n",
       "6938                46                 0                 1                28   \n",
       "3115                75                 2                 1                19   \n",
       "3649                14                 0                 1                44   \n",
       "\n",
       "      feature_1043_sms  feature_1044_sms  feature_1045_sms  feature_1046_sms  \\\n",
       "502                  0               290                 5                52   \n",
       "6547                 0                34                11                29   \n",
       "6938                 9                83                11                20   \n",
       "3115                 0               154                 7                43   \n",
       "3649                 0               138                 5                59   \n",
       "\n",
       "      feature_1047_sms  feature_1048_sms  feature_1049_sms  feature_1050_sms  \\\n",
       "502                 65                 9               905                30   \n",
       "6547                 2                 2               303                30   \n",
       "6938                 8                 6               464                30   \n",
       "3115                 7                 6               441                30   \n",
       "3649                27                 9               677                30   \n",
       "\n",
       "      feature_1051_sms  feature_1052_sms  feature_1053_sms  feature_1054_sms  \\\n",
       "502                  5                 5               220                 1   \n",
       "6547                20                 3               111                 4   \n",
       "6938                 1                 0               157                 2   \n",
       "3115                 9                 9                53                 2   \n",
       "3649                41                16               178                 3   \n",
       "\n",
       "      feature_1055_sms  feature_1056_sms  feature_1057_sms  feature_1058_sms  \\\n",
       "502                  4                74                 1                 1   \n",
       "6547                 4                38                 0                 1   \n",
       "6938                22                58                 0                 1   \n",
       "3115                11                87                 2                 2   \n",
       "3649                 8                29                 0                 3   \n",
       "\n",
       "      feature_1059_sms  feature_1060_sms  feature_1061_sms  feature_1062_sms  \\\n",
       "502                 89                 0               330                 5   \n",
       "6547                17                 1                36                16   \n",
       "6938                36                11               114                17   \n",
       "3115                22                 0               167                 9   \n",
       "3649                66                 0               174                 7   \n",
       "\n",
       "      feature_1063_sms  feature_1064_sms  feature_1065_sms  feature_1066_sms  \\\n",
       "502                 60               101                 9              1227   \n",
       "6547                39                10                 3               568   \n",
       "6938                24                14                 7               972   \n",
       "3115                53                 9                 6               629   \n",
       "3649                93                40                19              1121   \n",
       "\n",
       "      feature_1067_sms  feature_1068_sms  feature_1069_sms  feature_1070_sms  \\\n",
       "502                 56                 6                 5               271   \n",
       "6547                60                36                 4               184   \n",
       "6938                60                 2                 0               374   \n",
       "3115                60                12                12                87   \n",
       "3649                60                75                25               266   \n",
       "\n",
       "      feature_1071_sms  feature_1072_sms  feature_1073_sms  feature_1074_sms  \\\n",
       "502                  4                 5                98                 1   \n",
       "6547                 7                 7                63                 0   \n",
       "6938                 2                22               112                 0   \n",
       "3115                 2                17               115                 2   \n",
       "3649                 3                13                52                 0   \n",
       "\n",
       "      feature_1075_sms  feature_1076_sms  feature_1077_sms  feature_1078_sms  \\\n",
       "502                  1               119                 2               416   \n",
       "6547                 1                34                 1                84   \n",
       "6938                 2                48                21               260   \n",
       "3115                 2                39                 1               207   \n",
       "3649                 7               124                 0               316   \n",
       "\n",
       "      feature_1079_sms  feature_1080_sms  feature_1081_sms  feature_1082_sms  \\\n",
       "502                 26                91               166                16   \n",
       "6547                32                83                23                 9   \n",
       "6938                36                48                33                12   \n",
       "3115                32                71                20                10   \n",
       "3649                16               130                67                27   \n",
       "\n",
       "      feature_1083_sms  feature_1084_sms  feature_1085_sms  feature_1086_sms  \\\n",
       "502               2999               173                28                 9   \n",
       "6547              3000               283               291                88   \n",
       "6938              2975               167                11                10   \n",
       "3115              1129               265                28                27   \n",
       "3649              3000               159               156                57   \n",
       "\n",
       "      feature_1087_sms  feature_1088_sms  feature_1089_sms  feature_1090_sms  \\\n",
       "502                723                 7                 6               265   \n",
       "6547               719                13                39               212   \n",
       "6938              1199                 2                25               395   \n",
       "3115               138                 3                21               129   \n",
       "3649               725                14                31               143   \n",
       "\n",
       "      feature_1091_sms  feature_1092_sms  feature_1093_sms  feature_1094_sms  \\\n",
       "502                  1                 2               171                12   \n",
       "6547                 0                 3               186                 6   \n",
       "6938                 0                 6               102                89   \n",
       "3115                 2                 3                59                 6   \n",
       "3649                 0                13               252                 1   \n",
       "\n",
       "      feature_1095_sms  feature_1096_sms  feature_1097_sms  feature_1098_sms  \\\n",
       "502               1088                49               201               390   \n",
       "6547               461               141               424               378   \n",
       "6938               669               162               185                84   \n",
       "3115               295                42               168               181   \n",
       "3649              1047                52               256               174   \n",
       "\n",
       "      feature_1099_sms  feature_1100_sms  feature_1101_sms  feature_1102_sms  \\\n",
       "502                 42         45.666667         45.666667          0.045682   \n",
       "6547                35         13.333333         13.333333          0.013333   \n",
       "6938                36         24.000000         24.000000          0.024202   \n",
       "3115                27         24.333333         24.333333          0.064659   \n",
       "3649                79         19.000000         19.000000          0.019000   \n",
       "\n",
       "      feature_1103_sms  feature_1104_sms  feature_1105_sms  feature_1106_sms  \\\n",
       "502           0.333333          0.007299          0.000000          0.000000   \n",
       "6547          0.666667          0.050000          0.333333          0.025000   \n",
       "6938          0.000000          0.000000          0.000000          0.000000   \n",
       "3115          0.333333          0.013699          0.666667          0.027397   \n",
       "3649          2.666667          0.140351          0.666667          0.035088   \n",
       "\n",
       "      feature_1107_sms  feature_1108_sms  feature_1109_sms  feature_1110_sms  \\\n",
       "502           7.000000          0.153285          0.000000          0.000000   \n",
       "6547          4.333333          0.325000          0.000000          0.000000   \n",
       "6938          6.000000          0.250000          0.333333          0.013889   \n",
       "3115          3.333333          0.136986          0.000000          0.000000   \n",
       "3649          6.000000          0.315789          0.000000          0.000000   \n",
       "\n",
       "      feature_1111_sms  feature_1112_sms  feature_1113_sms  feature_1114_sms  \\\n",
       "502           0.000000          0.000000          8.000000          0.175182   \n",
       "6547          1.000000          0.075000          2.333333          0.175000   \n",
       "6938          0.000000          0.000000          3.000000          0.125000   \n",
       "3115          0.333333          0.013699          4.000000          0.164384   \n",
       "3649          0.000000          0.000000          0.333333          0.017544   \n",
       "\n",
       "      feature_1115_sms  feature_1116_sms  feature_1117_sms  feature_1118_sms  \\\n",
       "502           0.333333          0.007299          0.333333          0.007299   \n",
       "6547          0.000000          0.000000          0.000000          0.000000   \n",
       "6938          0.000000          0.000000          0.333333          0.013889   \n",
       "3115          0.000000          0.000000          0.000000          0.000000   \n",
       "3649          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "      feature_1119_sms  feature_1120_sms  feature_1121_sms  feature_1122_sms  \\\n",
       "502           5.000000          0.109489          0.000000          0.000000   \n",
       "6547          2.000000          0.150000          0.000000          0.000000   \n",
       "6938          2.333333          0.097222          0.666667          0.027778   \n",
       "3115          0.666667          0.027397          0.000000          0.000000   \n",
       "3649          1.333333          0.070175          0.000000          0.000000   \n",
       "\n",
       "      feature_1123_sms  feature_1124_sms  feature_1125_sms  feature_1126_sms  \\\n",
       "502          14.000000          0.306569          1.000000          0.021898   \n",
       "6547          1.333333          0.100000          0.000000          0.000000   \n",
       "6938          8.000000          0.333333          0.666667          0.027778   \n",
       "3115         10.666667          0.438356          0.666667          0.027397   \n",
       "3649          4.333333          0.228070          0.000000          0.000000   \n",
       "\n",
       "      feature_1127_sms  feature_1128_sms  feature_1129_sms  feature_1130_sms  \\\n",
       "502           5.666667          0.124088          2.333333          0.051095   \n",
       "6547          1.333333          0.100000          0.000000          0.000000   \n",
       "6938          2.000000          0.083333          0.000000          0.000000   \n",
       "3115          3.333333          0.136986          0.333333          0.013699   \n",
       "3649          0.666667          0.035088          2.333333          0.122807   \n",
       "\n",
       "      feature_1131_sms  feature_1132_sms  feature_1133_sms  feature_1134_sms  \\\n",
       "502           1.666667          0.036496         42.142857         42.142857   \n",
       "6547          0.000000          0.000000         12.571429         12.571429   \n",
       "6938          0.666667          0.027778         19.285714         19.285714   \n",
       "3115          0.000000          0.000000         21.714286         21.714286   \n",
       "3649          0.666667          0.035088         23.142857         23.142857   \n",
       "\n",
       "      feature_1135_sms  feature_1136_sms  feature_1137_sms  feature_1138_sms  \\\n",
       "502           0.098366          0.142857          0.003390          0.142857   \n",
       "6547          0.029333          1.428571          0.113636          0.142857   \n",
       "6938          0.045378          0.000000          0.000000          0.000000   \n",
       "3115          0.134632          0.285714          0.013158          1.000000   \n",
       "3649          0.054000          2.000000          0.086420          0.428571   \n",
       "\n",
       "      feature_1139_sms  feature_1140_sms  feature_1141_sms  feature_1142_sms  \\\n",
       "502           0.003390          8.857143          0.210169          0.000000   \n",
       "6547          0.011364          4.571429          0.363636          0.000000   \n",
       "6938          0.000000          5.000000          0.259259          0.285714   \n",
       "3115          0.046053          2.000000          0.092105          0.285714   \n",
       "3649          0.018519          9.285714          0.401235          0.000000   \n",
       "\n",
       "      feature_1143_sms  feature_1144_sms  feature_1145_sms  feature_1146_sms  \\\n",
       "502           0.000000          0.142857          0.003390          4.142857   \n",
       "6547          0.000000          0.428571          0.034091          1.571429   \n",
       "6938          0.014815          0.571429          0.029630          2.571429   \n",
       "3115          0.013158          0.142857          0.006579          3.571429   \n",
       "3649          0.000000          0.000000          0.000000          0.571429   \n",
       "\n",
       "      feature_1147_sms  feature_1148_sms  feature_1149_sms  feature_1150_sms  \\\n",
       "502           0.098305          0.142857           0.00339          0.142857   \n",
       "6547          0.125000          0.000000           0.00000          0.000000   \n",
       "6938          0.133333          0.000000           0.00000          0.142857   \n",
       "3115          0.164474          0.000000           0.00000          0.142857   \n",
       "3649          0.024691          0.000000           0.00000          0.000000   \n",
       "\n",
       "      feature_1151_sms  feature_1152_sms  feature_1153_sms  feature_1154_sms  \\\n",
       "502           0.003390          4.428571          0.105085          0.000000   \n",
       "6547          0.000000          1.428571          0.113636          0.000000   \n",
       "6938          0.007407          1.714286          0.088889          0.428571   \n",
       "3115          0.006579          1.285714          0.059211          0.000000   \n",
       "3649          0.000000          1.285714          0.055556          0.000000   \n",
       "\n",
       "      feature_1155_sms  feature_1156_sms  feature_1157_sms  feature_1158_sms  \\\n",
       "502           0.000000         15.857143          0.376271          0.714286   \n",
       "6547          0.000000          1.714286          0.136364          0.428571   \n",
       "6938          0.022222          5.428571          0.281481          0.571429   \n",
       "3115          0.000000          8.142857          0.375000          0.285714   \n",
       "3649          0.000000          6.714286          0.290123          0.000000   \n",
       "\n",
       "      feature_1159_sms  feature_1160_sms  feature_1161_sms  feature_1162_sms  \\\n",
       "502           0.016949          3.857143          0.091525          2.857143   \n",
       "6547          0.034091          0.714286          0.056818          0.000000   \n",
       "6938          0.029630          1.571429          0.081481          0.571429   \n",
       "3115          0.013158          3.000000          0.138158          0.714286   \n",
       "3649          0.000000          1.571429          0.067901          1.000000   \n",
       "\n",
       "      feature_1163_sms  feature_1164_sms  feature_1165_sms  feature_1166_sms  \\\n",
       "502           0.067797          0.714286          0.016949         38.214286   \n",
       "6547          0.000000          0.142857          0.011364         13.071429   \n",
       "6938          0.029630          0.428571          0.022222         18.357143   \n",
       "3115          0.032895          0.857143          0.039474         19.571429   \n",
       "3649          0.043210          0.285714          0.012346         24.000000   \n",
       "\n",
       "      feature_1167_sms  feature_1168_sms  feature_1169_sms  feature_1170_sms  \\\n",
       "502          38.214286          0.178393          0.214286          0.005607   \n",
       "6547         13.071429          0.061000          1.214286          0.092896   \n",
       "6938         18.357143          0.086387          0.000000          0.000000   \n",
       "3115         19.571429          0.242693          0.357143          0.018248   \n",
       "3649         24.000000          0.112000          1.428571          0.059524   \n",
       "\n",
       "      feature_1171_sms  feature_1172_sms  feature_1173_sms  feature_1174_sms  \\\n",
       "502           0.071429          0.001869          9.714286          0.254206   \n",
       "6547          0.071429          0.005464          5.142857          0.393443   \n",
       "6938          0.000000          0.000000          4.928571          0.268482   \n",
       "3115          0.500000          0.025547          1.857143          0.094891   \n",
       "3649          0.214286          0.008929          8.285714          0.345238   \n",
       "\n",
       "      feature_1175_sms  feature_1176_sms  feature_1177_sms  feature_1178_sms  \\\n",
       "502           0.071429          0.001869          0.071429          0.001869   \n",
       "6547          0.142857          0.010929          0.285714          0.021858   \n",
       "6938          0.142857          0.007782          0.714286          0.038911   \n",
       "3115          0.142857          0.007299          0.642857          0.032847   \n",
       "3649          0.000000          0.000000          0.071429          0.002976   \n",
       "\n",
       "      feature_1179_sms  feature_1180_sms  feature_1181_sms  feature_1182_sms  \\\n",
       "502           3.071429          0.080374          0.071429          0.001869   \n",
       "6547          1.428571          0.109290          0.000000          0.000000   \n",
       "6938          2.571429          0.140078          0.000000          0.000000   \n",
       "3115          3.571429          0.182482          0.071429          0.003650   \n",
       "3649          0.642857          0.026786          0.000000          0.000000   \n",
       "\n",
       "      feature_1183_sms  feature_1184_sms  feature_1185_sms  feature_1186_sms  \\\n",
       "502           0.071429          0.001869          4.785714          0.125234   \n",
       "6547          0.000000          0.000000          1.142857          0.087432   \n",
       "6938          0.071429          0.003891          1.714286          0.093385   \n",
       "3115          0.071429          0.003650          1.071429          0.054745   \n",
       "3649          0.000000          0.000000          1.857143          0.077381   \n",
       "\n",
       "      feature_1187_sms  feature_1188_sms  feature_1189_sms  feature_1190_sms  \\\n",
       "502                0.0          0.000000         14.071429          0.368224   \n",
       "6547               0.0          0.000000          1.785714          0.136612   \n",
       "6938               0.5          0.027237          5.285714          0.287938   \n",
       "3115               0.0          0.000000          7.714286          0.394161   \n",
       "3649               0.0          0.000000          6.857143          0.285714   \n",
       "\n",
       "      feature_1191_sms  feature_1192_sms  feature_1193_sms  feature_1194_sms  \\\n",
       "502           0.357143          0.009346          2.642857          0.069159   \n",
       "6547          0.642857          0.049180          1.142857          0.087432   \n",
       "6938          0.500000          0.027237          1.142857          0.062257   \n",
       "3115          0.285714          0.014599          2.357143          0.120438   \n",
       "3649          0.071429          0.002976          3.000000          0.125000   \n",
       "\n",
       "      feature_1195_sms  feature_1196_sms  feature_1197_sms  feature_1198_sms  \\\n",
       "502           2.500000          0.065421          0.500000          0.013084   \n",
       "6547          0.000000          0.000000          0.071429          0.005464   \n",
       "6938          0.428571          0.023346          0.357143          0.019455   \n",
       "3115          0.500000          0.025547          0.428571          0.021898   \n",
       "3649          1.142857          0.047619          0.428571          0.017857   \n",
       "\n",
       "      feature_1199_sms  feature_1200_sms  feature_1201_sms  feature_1202_sms  \\\n",
       "502          37.285714         37.285714          0.261087          0.142857   \n",
       "6547         11.952381         11.952381          0.083667          0.809524   \n",
       "6938         15.571429         15.571429          0.109916          0.000000   \n",
       "3115         18.142857         18.142857          0.337467          0.285714   \n",
       "3649         22.952381         22.952381          0.160667          1.380952   \n",
       "\n",
       "      feature_1203_sms  feature_1204_sms  feature_1205_sms  feature_1206_sms  \\\n",
       "502           0.003831          0.190476          0.005109          9.142857   \n",
       "6547          0.067729          0.047619          0.003984          4.666667   \n",
       "6938          0.000000          0.000000          0.000000          4.571429   \n",
       "3115          0.015748          0.380952          0.020997          2.000000   \n",
       "3649          0.060166          0.476190          0.020747          6.714286   \n",
       "\n",
       "      feature_1207_sms  feature_1208_sms  feature_1209_sms  feature_1210_sms  \\\n",
       "502           0.245211          0.047619          0.001277          0.190476   \n",
       "6547          0.390438          0.142857          0.011952          0.190476   \n",
       "6938          0.293578          0.095238          0.006116          0.809524   \n",
       "3115          0.110236          0.095238          0.005249          0.428571   \n",
       "3649          0.292531          0.000000          0.000000          0.238095   \n",
       "\n",
       "      feature_1211_sms  feature_1212_sms  feature_1213_sms  feature_1214_sms  \\\n",
       "502           0.005109          3.285714          0.088123          0.047619   \n",
       "6547          0.015936          1.571429          0.131474          0.000000   \n",
       "6938          0.051988          2.190476          0.140673          0.000000   \n",
       "3115          0.023622          3.571429          0.196850          0.095238   \n",
       "3649          0.010373          0.666667          0.029046          0.000000   \n",
       "\n",
       "      feature_1215_sms  feature_1216_sms  feature_1217_sms  feature_1218_sms  \\\n",
       "502           0.001277          0.047619          0.001277          4.142857   \n",
       "6547          0.000000          0.047619          0.003984          0.761905   \n",
       "6938          0.000000          0.047619          0.003058          1.333333   \n",
       "3115          0.005249          0.047619          0.002625          0.904762   \n",
       "3649          0.000000          0.047619          0.002075          2.095238   \n",
       "\n",
       "      feature_1219_sms  feature_1220_sms  feature_1221_sms  feature_1222_sms  \\\n",
       "502           0.111111          0.000000          0.000000         13.809524   \n",
       "6547          0.063745          0.000000          0.000000          1.619048   \n",
       "6938          0.085627          0.428571          0.027523          3.952381   \n",
       "3115          0.049869          0.000000          0.000000          7.333333   \n",
       "3649          0.091286          0.000000          0.000000          6.571429   \n",
       "\n",
       "      feature_1223_sms  feature_1224_sms  feature_1225_sms  feature_1226_sms  \\\n",
       "502           0.370370          0.238095          0.006386          2.476190   \n",
       "6547          0.135458          0.523810          0.043825          1.380952   \n",
       "6938          0.253823          0.523810          0.033639          0.952381   \n",
       "3115          0.404199          0.333333          0.018373          2.047619   \n",
       "3649          0.286307          0.238095          0.010373          2.809524   \n",
       "\n",
       "      feature_1227_sms  feature_1228_sms  feature_1229_sms  feature_1230_sms  \\\n",
       "502           0.066411          3.095238          0.083014          0.428571   \n",
       "6547          0.115538          0.095238          0.007968          0.095238   \n",
       "6938          0.061162          0.380952          0.024465          0.285714   \n",
       "3115          0.112861          0.333333          0.018373          0.285714   \n",
       "3649          0.122407          1.285714          0.056017          0.428571   \n",
       "\n",
       "      feature_1231_sms  feature_1232_sms  feature_1233_sms  feature_1234_sms  \\\n",
       "502           0.011494         30.166667         30.166667          0.301767   \n",
       "6547          0.007968         10.100000         10.100000          0.101000   \n",
       "6938          0.018349         15.466667         15.466667          0.155966   \n",
       "3115          0.015748         14.700000         14.700000          0.390611   \n",
       "3649          0.018672         22.566667         22.566667          0.225667   \n",
       "\n",
       "      feature_1235_sms  feature_1236_sms  feature_1237_sms  feature_1238_sms  \\\n",
       "502           0.166667          0.005525          0.166667          0.005525   \n",
       "6547          0.666667          0.066007          0.100000          0.009901   \n",
       "6938          0.033333          0.002155          0.000000          0.000000   \n",
       "3115          0.300000          0.020408          0.300000          0.020408   \n",
       "3649          1.366667          0.060561          0.533333          0.023634   \n",
       "\n",
       "      feature_1239_sms  feature_1240_sms  feature_1241_sms  feature_1242_sms  \\\n",
       "502           7.333333          0.243094          0.033333          0.001105   \n",
       "6547          3.700000          0.366337          0.133333          0.013201   \n",
       "6938          5.233333          0.338362          0.066667          0.004310   \n",
       "3115          1.766667          0.120181          0.066667          0.004535   \n",
       "3649          5.933333          0.262925          0.100000          0.004431   \n",
       "\n",
       "      feature_1243_sms  feature_1244_sms  feature_1245_sms  feature_1246_sms  \\\n",
       "502           0.133333          0.004420          2.466667          0.081768   \n",
       "6547          0.133333          0.013201          1.266667          0.125413   \n",
       "6938          0.733333          0.047414          1.933333          0.125000   \n",
       "3115          0.366667          0.024943          2.900000          0.197279   \n",
       "3649          0.266667          0.011817          0.966667          0.042836   \n",
       "\n",
       "      feature_1247_sms  feature_1248_sms  feature_1249_sms  feature_1250_sms  \\\n",
       "502           0.033333          0.001105          0.033333          0.001105   \n",
       "6547          0.000000          0.000000          0.033333          0.003300   \n",
       "6938          0.000000          0.000000          0.033333          0.002155   \n",
       "3115          0.066667          0.004535          0.066667          0.004535   \n",
       "3649          0.000000          0.000000          0.100000          0.004431   \n",
       "\n",
       "      feature_1251_sms  feature_1252_sms  feature_1253_sms  feature_1254_sms  \\\n",
       "502           2.966667          0.098343          0.000000          0.000000   \n",
       "6547          0.566667          0.056106          0.033333          0.003300   \n",
       "6938          1.200000          0.077586          0.366667          0.023707   \n",
       "3115          0.733333          0.049887          0.000000          0.000000   \n",
       "3649          2.200000          0.097489          0.000000          0.000000   \n",
       "\n",
       "      feature_1255_sms  feature_1256_sms  feature_1257_sms  feature_1258_sms  \\\n",
       "502          11.000000          0.364641          0.166667          0.005525   \n",
       "6547          1.200000          0.118812          0.533333          0.052805   \n",
       "6938          3.800000          0.245690          0.566667          0.036638   \n",
       "3115          5.566667          0.378685          0.300000          0.020408   \n",
       "3649          5.800000          0.257016          0.233333          0.010340   \n",
       "\n",
       "      feature_1259_sms  feature_1260_sms  feature_1261_sms  feature_1262_sms  \\\n",
       "502           2.000000          0.066298          3.366667          0.111602   \n",
       "6547          1.300000          0.128713          0.333333          0.033003   \n",
       "6938          0.800000          0.051724          0.466667          0.030172   \n",
       "3115          1.766667          0.120181          0.300000          0.020408   \n",
       "3649          3.100000          0.137371          1.333333          0.059084   \n",
       "\n",
       "      feature_1263_sms  feature_1264_sms  feature_1265_sms  feature_1266_sms  \\\n",
       "502           0.300000          0.009945         20.450000         21.910714   \n",
       "6547          0.100000          0.009901          9.466667          9.466667   \n",
       "6938          0.233333          0.015086         16.200000         16.200000   \n",
       "3115          0.200000          0.013605         10.483333         10.483333   \n",
       "3649          0.633333          0.028065         18.683333         18.683333   \n",
       "\n",
       "      feature_1267_sms  feature_1268_sms  feature_1269_sms  feature_1270_sms  \\\n",
       "502           0.409136          0.100000          0.004890          0.083333   \n",
       "6547          0.189333          0.600000          0.063380          0.066667   \n",
       "6938          0.326723          0.033333          0.002058          0.000000   \n",
       "3115          0.557130          0.200000          0.019078          0.200000   \n",
       "3649          0.373667          1.250000          0.066905          0.416667   \n",
       "\n",
       "      feature_1271_sms  feature_1272_sms  feature_1273_sms  feature_1274_sms  \\\n",
       "502           0.004075          4.516667          0.220864          0.066667   \n",
       "6547          0.007042          3.066667          0.323944          0.116667   \n",
       "6938          0.000000          6.233333          0.384774          0.033333   \n",
       "3115          0.019078          1.450000          0.138315          0.033333   \n",
       "3649          0.022302          4.433333          0.237288          0.050000   \n",
       "\n",
       "      feature_1275_sms  feature_1276_sms  feature_1277_sms  feature_1278_sms  \\\n",
       "502           0.003260          0.083333          0.004075          1.633333   \n",
       "6547          0.012324          0.116667          0.012324          1.050000   \n",
       "6938          0.002058          0.366667          0.022634          1.866667   \n",
       "3115          0.003180          0.283333          0.027027          1.916667   \n",
       "3649          0.002676          0.216667          0.011597          0.866667   \n",
       "\n",
       "      feature_1279_sms  feature_1280_sms  feature_1281_sms  feature_1282_sms  \\\n",
       "502           0.079870          0.016667          0.000815          0.016667   \n",
       "6547          0.110915          0.000000          0.000000          0.016667   \n",
       "6938          0.115226          0.000000          0.000000          0.033333   \n",
       "3115          0.182830          0.033333          0.003180          0.033333   \n",
       "3649          0.046387          0.000000          0.000000          0.116667   \n",
       "\n",
       "      feature_1283_sms  feature_1284_sms  feature_1285_sms  feature_1286_sms  \\\n",
       "502           0.000815          1.983333          0.096985          0.033333   \n",
       "6547          0.001761          0.566667          0.059859          0.016667   \n",
       "6938          0.002058          0.800000          0.049383          0.350000   \n",
       "3115          0.003180          0.650000          0.062003          0.016667   \n",
       "3649          0.006244          2.066667          0.110616          0.000000   \n",
       "\n",
       "      feature_1287_sms  feature_1288_sms  feature_1289_sms  feature_1290_sms  \\\n",
       "502           0.001630          6.933333          0.339038          0.433333   \n",
       "6547          0.001761          1.400000          0.147887          0.533333   \n",
       "6938          0.021605          4.333333          0.267490          0.600000   \n",
       "3115          0.001590          3.450000          0.329094          0.533333   \n",
       "3649          0.000000          5.266667          0.281891          0.266667   \n",
       "\n",
       "      feature_1291_sms  feature_1292_sms  feature_1293_sms  feature_1294_sms  \\\n",
       "502           0.021190          1.516667          0.074165          2.766667   \n",
       "6547          0.056338          1.383333          0.146127          0.383333   \n",
       "6938          0.037037          0.800000          0.049383          0.550000   \n",
       "3115          0.050874          1.183333          0.112878          0.333333   \n",
       "3649          0.014273          2.166667          0.115968          1.116667   \n",
       "\n",
       "      feature_1295_sms  feature_1296_sms  feature_1297_sms  feature_1298_sms  \\\n",
       "502           0.135289          0.266667          0.013040             2.999   \n",
       "6547          0.040493          0.150000          0.015845             3.000   \n",
       "6938          0.033951          0.200000          0.012346             2.975   \n",
       "3115          0.031797          0.166667          0.015898             1.129   \n",
       "3649          0.059768          0.450000          0.024086             3.000   \n",
       "\n",
       "      feature_1299_sms  feature_1300_sms  feature_1301_sms  feature_1302_sms  \\\n",
       "502          17.335260               1.0             0.028          0.009336   \n",
       "6547         10.600707               1.0             0.291          0.097000   \n",
       "6938         17.814371               1.0             0.011          0.003697   \n",
       "3115          4.260377               1.0             0.028          0.024801   \n",
       "3649         18.867925               1.0             0.156          0.052000   \n",
       "\n",
       "      feature_1303_sms  feature_1304_sms  feature_1305_sms  feature_1306_sms  \\\n",
       "502              0.009          0.003001             0.723          0.241080   \n",
       "6547             0.088          0.029333             0.719          0.239667   \n",
       "6938             0.010          0.003361             1.199          0.403025   \n",
       "3115             0.027          0.023915             0.138          0.122232   \n",
       "3649             0.057          0.019000             0.725          0.241667   \n",
       "\n",
       "      feature_1307_sms  feature_1308_sms  feature_1309_sms  feature_1310_sms  \\\n",
       "502              0.007          0.002334             0.006          0.002001   \n",
       "6547             0.013          0.004333             0.039          0.013000   \n",
       "6938             0.002          0.000672             0.025          0.008403   \n",
       "3115             0.003          0.002657             0.021          0.018601   \n",
       "3649             0.014          0.004667             0.031          0.010333   \n",
       "\n",
       "      feature_1311_sms  feature_1312_sms  feature_1313_sms  feature_1314_sms  \\\n",
       "502              0.265          0.088363             0.001          0.000333   \n",
       "6547             0.212          0.070667             0.000          0.000000   \n",
       "6938             0.395          0.132773             0.000          0.000000   \n",
       "3115             0.129          0.114260             0.002          0.001771   \n",
       "3649             0.143          0.047667             0.000          0.000000   \n",
       "\n",
       "      feature_1315_sms  feature_1316_sms  feature_1317_sms  feature_1318_sms  \\\n",
       "502              0.002          0.000667             0.171          0.057019   \n",
       "6547             0.003          0.001000             0.186          0.062000   \n",
       "6938             0.006          0.002017             0.102          0.034286   \n",
       "3115             0.003          0.002657             0.059          0.052259   \n",
       "3649             0.013          0.004333             0.252          0.084000   \n",
       "\n",
       "      feature_1319_sms  feature_1320_sms  feature_1321_sms  feature_1322_sms  \\\n",
       "502              0.012          0.004001             1.088          0.362788   \n",
       "6547             0.006          0.002000             0.461          0.153667   \n",
       "6938             0.089          0.029916             0.669          0.224874   \n",
       "3115             0.006          0.005314             0.295          0.261293   \n",
       "3649             0.001          0.000333             1.047          0.349000   \n",
       "\n",
       "      feature_1323_sms  feature_1324_sms  feature_1325_sms  feature_1326_sms  \\\n",
       "502              0.049          0.016339             0.201          0.067022   \n",
       "6547             0.141          0.047000             0.424          0.141333   \n",
       "6938             0.162          0.054454             0.185          0.062185   \n",
       "3115             0.042          0.037201             0.168          0.148804   \n",
       "3649             0.052          0.017333             0.256          0.085333   \n",
       "\n",
       "      feature_1327_sms  feature_1328_sms  feature_1329_sms  feature_1330_sms  \n",
       "502              0.390          0.130043             0.042          0.014005  \n",
       "6547             0.378          0.126000             0.035          0.011667  \n",
       "6938             0.084          0.028235             0.036          0.012101  \n",
       "3115             0.181          0.160319             0.027          0.023915  \n",
       "3649             0.174          0.058000             0.079          0.026333  \n",
       "\n",
       "[5 rows x 1761 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6136, 1761)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y,oot_x, oot_y,df,final_feas =  read_train(file='./data/filter_feas_df_0403_n_old.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf33aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad97904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5292621851563598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5292621851563598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " 0.7969966275001877\n",
      "------------test------------\n",
      " 0.7310259826782145\n",
      "------------oot------------\n",
      " 0.7241094081256734\n"
     ]
    }
   ],
   "source": [
    "paras = {'boosting_type': 'dart', 'class_weight': None, 'feature_fraction': 0.5292621851563598, 'learning_rate': 0.23938665909933876, 'max_depth': 14, 'min_child_samples': 91, 'min_child_weight': 0.13614638467767243, 'min_split_gain': 3.983261344288425, 'n_estimators': 2110, 'num_leaves': 736, 'reg_alpha': 6.683254293882608, 'reg_lambda': 9.003622043307438, 'subsample': 0.8646544005048526, 'subsample_for_bin': 340000, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "\n",
    "clf = LGBMClassifier(**paras)\n",
    "clf.fit(train_x, train_y,\n",
    "        eval_set=[(test_x,test_y)],\n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=50,verbose=-1)\n",
    "\n",
    "\n",
    "print('------------train------------\\n',model_metrics(clf, train_x,train_y))\n",
    "\n",
    "\n",
    "print('------------test------------\\n',model_metrics(clf, test_x,test_y))\n",
    "\n",
    "print('------------oot------------\\n',model_metrics(clf, oot_x,oot_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86f1cfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9123, 999488)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred = clf.predict(df[final_feas],pred_leaf=True) \n",
    "train_matrix = np.zeros([len(y_pred), len(y_pred[0])*clf.get_params()['num_leaves']],dtype=np.int64)\n",
    "print(train_matrix.shape) \n",
    "\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0]))*clf.get_params()['num_leaves'] + np.array(y_pred[i])\n",
    "    train_matrix[i][temp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9af8ddc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992219\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'add_suffix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8b6aa7d28e81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdroplist2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdroplist2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdroplist2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_lgb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#  存储lgb-onehot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'add_suffix'"
     ]
    }
   ],
   "source": [
    "# drop zero-features\n",
    "df2 = pd.DataFrame(train_matrix)\n",
    "droplist2 = []\n",
    "for k in df2.columns:\n",
    "    if not df2[k].any():\n",
    "        droplist2.append(k)\n",
    "print(len(droplist2))\n",
    "df2 = df2.drop(droplist2,axis=1).add_suffix('_lgb')\n",
    "\n",
    "#  存储lgb-onehot\n",
    "pd.concat([df,df2],axis=1).to_pickle('./data/filter_feas_df32n_old_lgb_oh.pkl')\n",
    "df2.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef9450a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_lgb</th>\n",
       "      <th>1_lgb</th>\n",
       "      <th>2_lgb</th>\n",
       "      <th>3_lgb</th>\n",
       "      <th>4_lgb</th>\n",
       "      <th>5_lgb</th>\n",
       "      <th>6_lgb</th>\n",
       "      <th>7_lgb</th>\n",
       "      <th>8_lgb</th>\n",
       "      <th>9_lgb</th>\n",
       "      <th>10_lgb</th>\n",
       "      <th>11_lgb</th>\n",
       "      <th>12_lgb</th>\n",
       "      <th>13_lgb</th>\n",
       "      <th>14_lgb</th>\n",
       "      <th>15_lgb</th>\n",
       "      <th>16_lgb</th>\n",
       "      <th>736_lgb</th>\n",
       "      <th>737_lgb</th>\n",
       "      <th>738_lgb</th>\n",
       "      <th>739_lgb</th>\n",
       "      <th>740_lgb</th>\n",
       "      <th>741_lgb</th>\n",
       "      <th>742_lgb</th>\n",
       "      <th>743_lgb</th>\n",
       "      <th>744_lgb</th>\n",
       "      <th>745_lgb</th>\n",
       "      <th>746_lgb</th>\n",
       "      <th>747_lgb</th>\n",
       "      <th>748_lgb</th>\n",
       "      <th>749_lgb</th>\n",
       "      <th>750_lgb</th>\n",
       "      <th>751_lgb</th>\n",
       "      <th>752_lgb</th>\n",
       "      <th>1472_lgb</th>\n",
       "      <th>1473_lgb</th>\n",
       "      <th>1474_lgb</th>\n",
       "      <th>1475_lgb</th>\n",
       "      <th>1476_lgb</th>\n",
       "      <th>1477_lgb</th>\n",
       "      <th>1478_lgb</th>\n",
       "      <th>1479_lgb</th>\n",
       "      <th>1480_lgb</th>\n",
       "      <th>1481_lgb</th>\n",
       "      <th>1482_lgb</th>\n",
       "      <th>1483_lgb</th>\n",
       "      <th>1484_lgb</th>\n",
       "      <th>1485_lgb</th>\n",
       "      <th>1486_lgb</th>\n",
       "      <th>1487_lgb</th>\n",
       "      <th>2208_lgb</th>\n",
       "      <th>2209_lgb</th>\n",
       "      <th>2210_lgb</th>\n",
       "      <th>2211_lgb</th>\n",
       "      <th>2212_lgb</th>\n",
       "      <th>2213_lgb</th>\n",
       "      <th>2214_lgb</th>\n",
       "      <th>2215_lgb</th>\n",
       "      <th>2216_lgb</th>\n",
       "      <th>2217_lgb</th>\n",
       "      <th>2218_lgb</th>\n",
       "      <th>2219_lgb</th>\n",
       "      <th>2220_lgb</th>\n",
       "      <th>2221_lgb</th>\n",
       "      <th>2222_lgb</th>\n",
       "      <th>2944_lgb</th>\n",
       "      <th>2945_lgb</th>\n",
       "      <th>2946_lgb</th>\n",
       "      <th>2947_lgb</th>\n",
       "      <th>2948_lgb</th>\n",
       "      <th>2949_lgb</th>\n",
       "      <th>2950_lgb</th>\n",
       "      <th>2951_lgb</th>\n",
       "      <th>2952_lgb</th>\n",
       "      <th>2953_lgb</th>\n",
       "      <th>2954_lgb</th>\n",
       "      <th>2955_lgb</th>\n",
       "      <th>2956_lgb</th>\n",
       "      <th>3680_lgb</th>\n",
       "      <th>3681_lgb</th>\n",
       "      <th>3682_lgb</th>\n",
       "      <th>3683_lgb</th>\n",
       "      <th>3684_lgb</th>\n",
       "      <th>3685_lgb</th>\n",
       "      <th>3686_lgb</th>\n",
       "      <th>3687_lgb</th>\n",
       "      <th>3688_lgb</th>\n",
       "      <th>3689_lgb</th>\n",
       "      <th>3690_lgb</th>\n",
       "      <th>3691_lgb</th>\n",
       "      <th>3692_lgb</th>\n",
       "      <th>3693_lgb</th>\n",
       "      <th>3694_lgb</th>\n",
       "      <th>3695_lgb</th>\n",
       "      <th>3696_lgb</th>\n",
       "      <th>3697_lgb</th>\n",
       "      <th>4416_lgb</th>\n",
       "      <th>4417_lgb</th>\n",
       "      <th>4418_lgb</th>\n",
       "      <th>4419_lgb</th>\n",
       "      <th>4420_lgb</th>\n",
       "      <th>4421_lgb</th>\n",
       "      <th>4422_lgb</th>\n",
       "      <th>4423_lgb</th>\n",
       "      <th>4424_lgb</th>\n",
       "      <th>4425_lgb</th>\n",
       "      <th>4426_lgb</th>\n",
       "      <th>4427_lgb</th>\n",
       "      <th>5152_lgb</th>\n",
       "      <th>5153_lgb</th>\n",
       "      <th>5154_lgb</th>\n",
       "      <th>5155_lgb</th>\n",
       "      <th>5156_lgb</th>\n",
       "      <th>5157_lgb</th>\n",
       "      <th>5158_lgb</th>\n",
       "      <th>5159_lgb</th>\n",
       "      <th>5160_lgb</th>\n",
       "      <th>5161_lgb</th>\n",
       "      <th>5162_lgb</th>\n",
       "      <th>5163_lgb</th>\n",
       "      <th>5164_lgb</th>\n",
       "      <th>5888_lgb</th>\n",
       "      <th>5889_lgb</th>\n",
       "      <th>5890_lgb</th>\n",
       "      <th>5891_lgb</th>\n",
       "      <th>5892_lgb</th>\n",
       "      <th>5893_lgb</th>\n",
       "      <th>5894_lgb</th>\n",
       "      <th>5895_lgb</th>\n",
       "      <th>5896_lgb</th>\n",
       "      <th>5897_lgb</th>\n",
       "      <th>5898_lgb</th>\n",
       "      <th>5899_lgb</th>\n",
       "      <th>6624_lgb</th>\n",
       "      <th>6625_lgb</th>\n",
       "      <th>6626_lgb</th>\n",
       "      <th>6627_lgb</th>\n",
       "      <th>6628_lgb</th>\n",
       "      <th>6629_lgb</th>\n",
       "      <th>6630_lgb</th>\n",
       "      <th>6631_lgb</th>\n",
       "      <th>6632_lgb</th>\n",
       "      <th>6633_lgb</th>\n",
       "      <th>6634_lgb</th>\n",
       "      <th>7360_lgb</th>\n",
       "      <th>7361_lgb</th>\n",
       "      <th>7362_lgb</th>\n",
       "      <th>7363_lgb</th>\n",
       "      <th>7364_lgb</th>\n",
       "      <th>7365_lgb</th>\n",
       "      <th>7366_lgb</th>\n",
       "      <th>7367_lgb</th>\n",
       "      <th>7368_lgb</th>\n",
       "      <th>7369_lgb</th>\n",
       "      <th>7370_lgb</th>\n",
       "      <th>8096_lgb</th>\n",
       "      <th>8097_lgb</th>\n",
       "      <th>8098_lgb</th>\n",
       "      <th>8099_lgb</th>\n",
       "      <th>8100_lgb</th>\n",
       "      <th>8101_lgb</th>\n",
       "      <th>8102_lgb</th>\n",
       "      <th>8103_lgb</th>\n",
       "      <th>8104_lgb</th>\n",
       "      <th>8105_lgb</th>\n",
       "      <th>8832_lgb</th>\n",
       "      <th>8833_lgb</th>\n",
       "      <th>8834_lgb</th>\n",
       "      <th>8835_lgb</th>\n",
       "      <th>8836_lgb</th>\n",
       "      <th>8837_lgb</th>\n",
       "      <th>8838_lgb</th>\n",
       "      <th>9568_lgb</th>\n",
       "      <th>9569_lgb</th>\n",
       "      <th>9570_lgb</th>\n",
       "      <th>9571_lgb</th>\n",
       "      <th>9572_lgb</th>\n",
       "      <th>10304_lgb</th>\n",
       "      <th>10305_lgb</th>\n",
       "      <th>10306_lgb</th>\n",
       "      <th>10307_lgb</th>\n",
       "      <th>10308_lgb</th>\n",
       "      <th>10309_lgb</th>\n",
       "      <th>10310_lgb</th>\n",
       "      <th>10311_lgb</th>\n",
       "      <th>11040_lgb</th>\n",
       "      <th>11041_lgb</th>\n",
       "      <th>11042_lgb</th>\n",
       "      <th>11043_lgb</th>\n",
       "      <th>11044_lgb</th>\n",
       "      <th>11776_lgb</th>\n",
       "      <th>11777_lgb</th>\n",
       "      <th>12512_lgb</th>\n",
       "      <th>12513_lgb</th>\n",
       "      <th>12514_lgb</th>\n",
       "      <th>12515_lgb</th>\n",
       "      <th>12516_lgb</th>\n",
       "      <th>12517_lgb</th>\n",
       "      <th>12518_lgb</th>\n",
       "      <th>13248_lgb</th>\n",
       "      <th>13249_lgb</th>\n",
       "      <th>13250_lgb</th>\n",
       "      <th>13251_lgb</th>\n",
       "      <th>13252_lgb</th>\n",
       "      <th>13253_lgb</th>\n",
       "      <th>13254_lgb</th>\n",
       "      <th>13255_lgb</th>\n",
       "      <th>13256_lgb</th>\n",
       "      <th>13257_lgb</th>\n",
       "      <th>13984_lgb</th>\n",
       "      <th>13985_lgb</th>\n",
       "      <th>13986_lgb</th>\n",
       "      <th>13987_lgb</th>\n",
       "      <th>13988_lgb</th>\n",
       "      <th>13989_lgb</th>\n",
       "      <th>13990_lgb</th>\n",
       "      <th>14720_lgb</th>\n",
       "      <th>14721_lgb</th>\n",
       "      <th>14722_lgb</th>\n",
       "      <th>14723_lgb</th>\n",
       "      <th>14724_lgb</th>\n",
       "      <th>14725_lgb</th>\n",
       "      <th>14726_lgb</th>\n",
       "      <th>14727_lgb</th>\n",
       "      <th>14728_lgb</th>\n",
       "      <th>14729_lgb</th>\n",
       "      <th>14730_lgb</th>\n",
       "      <th>14731_lgb</th>\n",
       "      <th>15456_lgb</th>\n",
       "      <th>15457_lgb</th>\n",
       "      <th>15458_lgb</th>\n",
       "      <th>15459_lgb</th>\n",
       "      <th>15460_lgb</th>\n",
       "      <th>15461_lgb</th>\n",
       "      <th>15462_lgb</th>\n",
       "      <th>15463_lgb</th>\n",
       "      <th>16192_lgb</th>\n",
       "      <th>16193_lgb</th>\n",
       "      <th>16194_lgb</th>\n",
       "      <th>16195_lgb</th>\n",
       "      <th>16196_lgb</th>\n",
       "      <th>16197_lgb</th>\n",
       "      <th>16198_lgb</th>\n",
       "      <th>16199_lgb</th>\n",
       "      <th>16200_lgb</th>\n",
       "      <th>16201_lgb</th>\n",
       "      <th>16928_lgb</th>\n",
       "      <th>16929_lgb</th>\n",
       "      <th>16930_lgb</th>\n",
       "      <th>16931_lgb</th>\n",
       "      <th>16932_lgb</th>\n",
       "      <th>16933_lgb</th>\n",
       "      <th>16934_lgb</th>\n",
       "      <th>16935_lgb</th>\n",
       "      <th>16936_lgb</th>\n",
       "      <th>17664_lgb</th>\n",
       "      <th>17665_lgb</th>\n",
       "      <th>17666_lgb</th>\n",
       "      <th>17667_lgb</th>\n",
       "      <th>17668_lgb</th>\n",
       "      <th>17669_lgb</th>\n",
       "      <th>17670_lgb</th>\n",
       "      <th>17671_lgb</th>\n",
       "      <th>17672_lgb</th>\n",
       "      <th>18400_lgb</th>\n",
       "      <th>18401_lgb</th>\n",
       "      <th>18402_lgb</th>\n",
       "      <th>18403_lgb</th>\n",
       "      <th>18404_lgb</th>\n",
       "      <th>18405_lgb</th>\n",
       "      <th>18406_lgb</th>\n",
       "      <th>18407_lgb</th>\n",
       "      <th>18408_lgb</th>\n",
       "      <th>19136_lgb</th>\n",
       "      <th>19137_lgb</th>\n",
       "      <th>19138_lgb</th>\n",
       "      <th>19872_lgb</th>\n",
       "      <th>19873_lgb</th>\n",
       "      <th>19874_lgb</th>\n",
       "      <th>19875_lgb</th>\n",
       "      <th>19876_lgb</th>\n",
       "      <th>19877_lgb</th>\n",
       "      <th>19878_lgb</th>\n",
       "      <th>19879_lgb</th>\n",
       "      <th>20608_lgb</th>\n",
       "      <th>20609_lgb</th>\n",
       "      <th>20610_lgb</th>\n",
       "      <th>20611_lgb</th>\n",
       "      <th>20612_lgb</th>\n",
       "      <th>20613_lgb</th>\n",
       "      <th>20614_lgb</th>\n",
       "      <th>20615_lgb</th>\n",
       "      <th>21344_lgb</th>\n",
       "      <th>21345_lgb</th>\n",
       "      <th>21346_lgb</th>\n",
       "      <th>21347_lgb</th>\n",
       "      <th>21348_lgb</th>\n",
       "      <th>21349_lgb</th>\n",
       "      <th>21350_lgb</th>\n",
       "      <th>21351_lgb</th>\n",
       "      <th>...</th>\n",
       "      <th>948707_lgb</th>\n",
       "      <th>949440_lgb</th>\n",
       "      <th>949441_lgb</th>\n",
       "      <th>949442_lgb</th>\n",
       "      <th>949443_lgb</th>\n",
       "      <th>949444_lgb</th>\n",
       "      <th>950176_lgb</th>\n",
       "      <th>950177_lgb</th>\n",
       "      <th>950178_lgb</th>\n",
       "      <th>950179_lgb</th>\n",
       "      <th>950180_lgb</th>\n",
       "      <th>950181_lgb</th>\n",
       "      <th>950182_lgb</th>\n",
       "      <th>950912_lgb</th>\n",
       "      <th>950913_lgb</th>\n",
       "      <th>950914_lgb</th>\n",
       "      <th>950915_lgb</th>\n",
       "      <th>950916_lgb</th>\n",
       "      <th>951648_lgb</th>\n",
       "      <th>951649_lgb</th>\n",
       "      <th>951650_lgb</th>\n",
       "      <th>951651_lgb</th>\n",
       "      <th>951652_lgb</th>\n",
       "      <th>952384_lgb</th>\n",
       "      <th>952385_lgb</th>\n",
       "      <th>952386_lgb</th>\n",
       "      <th>952387_lgb</th>\n",
       "      <th>953120_lgb</th>\n",
       "      <th>953121_lgb</th>\n",
       "      <th>953122_lgb</th>\n",
       "      <th>953123_lgb</th>\n",
       "      <th>953856_lgb</th>\n",
       "      <th>953857_lgb</th>\n",
       "      <th>953858_lgb</th>\n",
       "      <th>953859_lgb</th>\n",
       "      <th>954592_lgb</th>\n",
       "      <th>954593_lgb</th>\n",
       "      <th>954594_lgb</th>\n",
       "      <th>955328_lgb</th>\n",
       "      <th>955329_lgb</th>\n",
       "      <th>955330_lgb</th>\n",
       "      <th>955331_lgb</th>\n",
       "      <th>955332_lgb</th>\n",
       "      <th>956064_lgb</th>\n",
       "      <th>956065_lgb</th>\n",
       "      <th>956066_lgb</th>\n",
       "      <th>956067_lgb</th>\n",
       "      <th>956068_lgb</th>\n",
       "      <th>956069_lgb</th>\n",
       "      <th>956800_lgb</th>\n",
       "      <th>956801_lgb</th>\n",
       "      <th>957536_lgb</th>\n",
       "      <th>957537_lgb</th>\n",
       "      <th>957538_lgb</th>\n",
       "      <th>957539_lgb</th>\n",
       "      <th>958272_lgb</th>\n",
       "      <th>958273_lgb</th>\n",
       "      <th>958274_lgb</th>\n",
       "      <th>958275_lgb</th>\n",
       "      <th>959008_lgb</th>\n",
       "      <th>959009_lgb</th>\n",
       "      <th>959010_lgb</th>\n",
       "      <th>959744_lgb</th>\n",
       "      <th>959745_lgb</th>\n",
       "      <th>959746_lgb</th>\n",
       "      <th>959747_lgb</th>\n",
       "      <th>959748_lgb</th>\n",
       "      <th>959749_lgb</th>\n",
       "      <th>959750_lgb</th>\n",
       "      <th>960480_lgb</th>\n",
       "      <th>960481_lgb</th>\n",
       "      <th>960482_lgb</th>\n",
       "      <th>960483_lgb</th>\n",
       "      <th>960484_lgb</th>\n",
       "      <th>960485_lgb</th>\n",
       "      <th>961216_lgb</th>\n",
       "      <th>961217_lgb</th>\n",
       "      <th>961218_lgb</th>\n",
       "      <th>961219_lgb</th>\n",
       "      <th>961220_lgb</th>\n",
       "      <th>961952_lgb</th>\n",
       "      <th>961953_lgb</th>\n",
       "      <th>961954_lgb</th>\n",
       "      <th>961955_lgb</th>\n",
       "      <th>961956_lgb</th>\n",
       "      <th>961957_lgb</th>\n",
       "      <th>962688_lgb</th>\n",
       "      <th>962689_lgb</th>\n",
       "      <th>962690_lgb</th>\n",
       "      <th>963424_lgb</th>\n",
       "      <th>963425_lgb</th>\n",
       "      <th>963426_lgb</th>\n",
       "      <th>963427_lgb</th>\n",
       "      <th>964160_lgb</th>\n",
       "      <th>964161_lgb</th>\n",
       "      <th>964162_lgb</th>\n",
       "      <th>964163_lgb</th>\n",
       "      <th>964896_lgb</th>\n",
       "      <th>964897_lgb</th>\n",
       "      <th>964898_lgb</th>\n",
       "      <th>965632_lgb</th>\n",
       "      <th>965633_lgb</th>\n",
       "      <th>965634_lgb</th>\n",
       "      <th>966368_lgb</th>\n",
       "      <th>966369_lgb</th>\n",
       "      <th>966370_lgb</th>\n",
       "      <th>966371_lgb</th>\n",
       "      <th>966372_lgb</th>\n",
       "      <th>967104_lgb</th>\n",
       "      <th>967105_lgb</th>\n",
       "      <th>967106_lgb</th>\n",
       "      <th>967107_lgb</th>\n",
       "      <th>967108_lgb</th>\n",
       "      <th>967109_lgb</th>\n",
       "      <th>967110_lgb</th>\n",
       "      <th>967840_lgb</th>\n",
       "      <th>967841_lgb</th>\n",
       "      <th>967842_lgb</th>\n",
       "      <th>968576_lgb</th>\n",
       "      <th>968577_lgb</th>\n",
       "      <th>968578_lgb</th>\n",
       "      <th>968579_lgb</th>\n",
       "      <th>969312_lgb</th>\n",
       "      <th>969313_lgb</th>\n",
       "      <th>969314_lgb</th>\n",
       "      <th>969315_lgb</th>\n",
       "      <th>970048_lgb</th>\n",
       "      <th>970049_lgb</th>\n",
       "      <th>970050_lgb</th>\n",
       "      <th>970051_lgb</th>\n",
       "      <th>970784_lgb</th>\n",
       "      <th>970785_lgb</th>\n",
       "      <th>970786_lgb</th>\n",
       "      <th>970787_lgb</th>\n",
       "      <th>970788_lgb</th>\n",
       "      <th>971520_lgb</th>\n",
       "      <th>971521_lgb</th>\n",
       "      <th>971522_lgb</th>\n",
       "      <th>971523_lgb</th>\n",
       "      <th>971524_lgb</th>\n",
       "      <th>971525_lgb</th>\n",
       "      <th>971526_lgb</th>\n",
       "      <th>972256_lgb</th>\n",
       "      <th>972257_lgb</th>\n",
       "      <th>972258_lgb</th>\n",
       "      <th>972259_lgb</th>\n",
       "      <th>972260_lgb</th>\n",
       "      <th>972261_lgb</th>\n",
       "      <th>972992_lgb</th>\n",
       "      <th>972993_lgb</th>\n",
       "      <th>972994_lgb</th>\n",
       "      <th>972995_lgb</th>\n",
       "      <th>973728_lgb</th>\n",
       "      <th>973729_lgb</th>\n",
       "      <th>973730_lgb</th>\n",
       "      <th>973731_lgb</th>\n",
       "      <th>973732_lgb</th>\n",
       "      <th>973733_lgb</th>\n",
       "      <th>973734_lgb</th>\n",
       "      <th>974464_lgb</th>\n",
       "      <th>974465_lgb</th>\n",
       "      <th>974466_lgb</th>\n",
       "      <th>974467_lgb</th>\n",
       "      <th>974468_lgb</th>\n",
       "      <th>974469_lgb</th>\n",
       "      <th>974470_lgb</th>\n",
       "      <th>975200_lgb</th>\n",
       "      <th>975201_lgb</th>\n",
       "      <th>975936_lgb</th>\n",
       "      <th>975937_lgb</th>\n",
       "      <th>975938_lgb</th>\n",
       "      <th>975939_lgb</th>\n",
       "      <th>976672_lgb</th>\n",
       "      <th>976673_lgb</th>\n",
       "      <th>976674_lgb</th>\n",
       "      <th>976675_lgb</th>\n",
       "      <th>976676_lgb</th>\n",
       "      <th>976677_lgb</th>\n",
       "      <th>977408_lgb</th>\n",
       "      <th>977409_lgb</th>\n",
       "      <th>977410_lgb</th>\n",
       "      <th>977411_lgb</th>\n",
       "      <th>977412_lgb</th>\n",
       "      <th>978144_lgb</th>\n",
       "      <th>978145_lgb</th>\n",
       "      <th>978146_lgb</th>\n",
       "      <th>978147_lgb</th>\n",
       "      <th>978880_lgb</th>\n",
       "      <th>978881_lgb</th>\n",
       "      <th>978882_lgb</th>\n",
       "      <th>978883_lgb</th>\n",
       "      <th>979616_lgb</th>\n",
       "      <th>979617_lgb</th>\n",
       "      <th>980352_lgb</th>\n",
       "      <th>980353_lgb</th>\n",
       "      <th>980354_lgb</th>\n",
       "      <th>980355_lgb</th>\n",
       "      <th>981088_lgb</th>\n",
       "      <th>981089_lgb</th>\n",
       "      <th>981090_lgb</th>\n",
       "      <th>981091_lgb</th>\n",
       "      <th>981092_lgb</th>\n",
       "      <th>981824_lgb</th>\n",
       "      <th>981825_lgb</th>\n",
       "      <th>981826_lgb</th>\n",
       "      <th>981827_lgb</th>\n",
       "      <th>982560_lgb</th>\n",
       "      <th>982561_lgb</th>\n",
       "      <th>982562_lgb</th>\n",
       "      <th>983296_lgb</th>\n",
       "      <th>983297_lgb</th>\n",
       "      <th>983298_lgb</th>\n",
       "      <th>983299_lgb</th>\n",
       "      <th>983300_lgb</th>\n",
       "      <th>983301_lgb</th>\n",
       "      <th>984032_lgb</th>\n",
       "      <th>984033_lgb</th>\n",
       "      <th>984034_lgb</th>\n",
       "      <th>984768_lgb</th>\n",
       "      <th>984769_lgb</th>\n",
       "      <th>984770_lgb</th>\n",
       "      <th>985504_lgb</th>\n",
       "      <th>985505_lgb</th>\n",
       "      <th>985506_lgb</th>\n",
       "      <th>985507_lgb</th>\n",
       "      <th>985508_lgb</th>\n",
       "      <th>986240_lgb</th>\n",
       "      <th>986241_lgb</th>\n",
       "      <th>986242_lgb</th>\n",
       "      <th>986976_lgb</th>\n",
       "      <th>986977_lgb</th>\n",
       "      <th>986978_lgb</th>\n",
       "      <th>987712_lgb</th>\n",
       "      <th>987713_lgb</th>\n",
       "      <th>987714_lgb</th>\n",
       "      <th>987715_lgb</th>\n",
       "      <th>987716_lgb</th>\n",
       "      <th>988448_lgb</th>\n",
       "      <th>988449_lgb</th>\n",
       "      <th>988450_lgb</th>\n",
       "      <th>988451_lgb</th>\n",
       "      <th>989184_lgb</th>\n",
       "      <th>989185_lgb</th>\n",
       "      <th>989186_lgb</th>\n",
       "      <th>989187_lgb</th>\n",
       "      <th>989920_lgb</th>\n",
       "      <th>989921_lgb</th>\n",
       "      <th>989922_lgb</th>\n",
       "      <th>989923_lgb</th>\n",
       "      <th>989924_lgb</th>\n",
       "      <th>989925_lgb</th>\n",
       "      <th>990656_lgb</th>\n",
       "      <th>990657_lgb</th>\n",
       "      <th>990658_lgb</th>\n",
       "      <th>990659_lgb</th>\n",
       "      <th>991392_lgb</th>\n",
       "      <th>991393_lgb</th>\n",
       "      <th>991394_lgb</th>\n",
       "      <th>991395_lgb</th>\n",
       "      <th>992128_lgb</th>\n",
       "      <th>992129_lgb</th>\n",
       "      <th>992130_lgb</th>\n",
       "      <th>992864_lgb</th>\n",
       "      <th>992865_lgb</th>\n",
       "      <th>992866_lgb</th>\n",
       "      <th>992867_lgb</th>\n",
       "      <th>993600_lgb</th>\n",
       "      <th>993601_lgb</th>\n",
       "      <th>993602_lgb</th>\n",
       "      <th>993603_lgb</th>\n",
       "      <th>994336_lgb</th>\n",
       "      <th>994337_lgb</th>\n",
       "      <th>994338_lgb</th>\n",
       "      <th>994339_lgb</th>\n",
       "      <th>995072_lgb</th>\n",
       "      <th>995073_lgb</th>\n",
       "      <th>995074_lgb</th>\n",
       "      <th>995075_lgb</th>\n",
       "      <th>995076_lgb</th>\n",
       "      <th>995808_lgb</th>\n",
       "      <th>995809_lgb</th>\n",
       "      <th>995810_lgb</th>\n",
       "      <th>995811_lgb</th>\n",
       "      <th>995812_lgb</th>\n",
       "      <th>996544_lgb</th>\n",
       "      <th>996545_lgb</th>\n",
       "      <th>996546_lgb</th>\n",
       "      <th>997280_lgb</th>\n",
       "      <th>997281_lgb</th>\n",
       "      <th>997282_lgb</th>\n",
       "      <th>997283_lgb</th>\n",
       "      <th>997284_lgb</th>\n",
       "      <th>998016_lgb</th>\n",
       "      <th>998017_lgb</th>\n",
       "      <th>998018_lgb</th>\n",
       "      <th>998019_lgb</th>\n",
       "      <th>998752_lgb</th>\n",
       "      <th>998753_lgb</th>\n",
       "      <th>998754_lgb</th>\n",
       "      <th>998755_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_lgb  1_lgb  2_lgb  3_lgb  4_lgb  5_lgb  6_lgb  7_lgb  8_lgb  9_lgb  \\\n",
       "0      0      0      0      0      0      1      0      0      0      0   \n",
       "1      0      0      0      0      0      0      0      0      0      1   \n",
       "2      0      0      0      0      0      0      0      0      0      0   \n",
       "3      0      0      0      0      0      0      0      0      0      1   \n",
       "4      0      0      0      0      1      0      0      0      0      0   \n",
       "\n",
       "   10_lgb  11_lgb  12_lgb  13_lgb  14_lgb  15_lgb  16_lgb  736_lgb  737_lgb  \\\n",
       "0       0       0       0       0       0       0       0        0        0   \n",
       "1       0       0       0       0       0       0       0        0        0   \n",
       "2       0       0       1       0       0       0       0        1        0   \n",
       "3       0       0       0       0       0       0       0        0        0   \n",
       "4       0       0       0       0       0       0       0        0        0   \n",
       "\n",
       "   738_lgb  739_lgb  740_lgb  741_lgb  742_lgb  743_lgb  744_lgb  745_lgb  \\\n",
       "0        0        0        0        0        0        1        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        1        0        0        0   \n",
       "\n",
       "   746_lgb  747_lgb  748_lgb  749_lgb  750_lgb  751_lgb  752_lgb  1472_lgb  \\\n",
       "0        0        0        0        0        0        0        0         0   \n",
       "1        0        0        0        0        0        0        1         0   \n",
       "2        0        0        0        0        0        0        0         0   \n",
       "3        1        0        0        0        0        0        0         1   \n",
       "4        0        0        0        0        0        0        0         0   \n",
       "\n",
       "   1473_lgb  1474_lgb  1475_lgb  1476_lgb  1477_lgb  1478_lgb  1479_lgb  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         1         0   \n",
       "\n",
       "   1480_lgb  1481_lgb  1482_lgb  1483_lgb  1484_lgb  1485_lgb  1486_lgb  \\\n",
       "0         0         0         0         0         1         0         0   \n",
       "1         0         0         0         0         1         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   1487_lgb  2208_lgb  2209_lgb  2210_lgb  2211_lgb  2212_lgb  2213_lgb  \\\n",
       "0         0         0         0         0         0         1         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         1   \n",
       "4         0         0         1         0         0         0         0   \n",
       "\n",
       "   2214_lgb  2215_lgb  2216_lgb  2217_lgb  2218_lgb  2219_lgb  2220_lgb  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         1         0         0         0         0         0   \n",
       "2         0         0         1         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   2221_lgb  2222_lgb  2944_lgb  2945_lgb  2946_lgb  2947_lgb  2948_lgb  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         1         0   \n",
       "4         0         0         0         0         0         1         0   \n",
       "\n",
       "   2949_lgb  2950_lgb  2951_lgb  2952_lgb  2953_lgb  2954_lgb  2955_lgb  \\\n",
       "0         1         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         1         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   2956_lgb  3680_lgb  3681_lgb  3682_lgb  3683_lgb  3684_lgb  3685_lgb  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         1         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         1         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   3686_lgb  3687_lgb  3688_lgb  3689_lgb  3690_lgb  3691_lgb  3692_lgb  \\\n",
       "0         0         1         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         1         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   3693_lgb  3694_lgb  3695_lgb  3696_lgb  3697_lgb  4416_lgb  4417_lgb  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         1         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         1         0         0         0         1         0   \n",
       "\n",
       "   4418_lgb  4419_lgb  4420_lgb  4421_lgb  4422_lgb  4423_lgb  4424_lgb  \\\n",
       "0         0         0         0         0         1         0         0   \n",
       "1         1         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         1         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   4425_lgb  4426_lgb  4427_lgb  5152_lgb  5153_lgb  5154_lgb  5155_lgb  \\\n",
       "0         0         0         0         0         0         0         1   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   5156_lgb  5157_lgb  5158_lgb  5159_lgb  5160_lgb  5161_lgb  5162_lgb  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         1         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         1         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   5163_lgb  5164_lgb  5888_lgb  5889_lgb  5890_lgb  5891_lgb  5892_lgb  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         1         0         0         0         1         0   \n",
       "3         0         0         0         0         0         1         0   \n",
       "4         0         1         0         0         0         0         1   \n",
       "\n",
       "   5893_lgb  5894_lgb  5895_lgb  5896_lgb  5897_lgb  5898_lgb  5899_lgb  \\\n",
       "0         0         0         0         0         0         1         0   \n",
       "1         0         0         0         0         0         1         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   6624_lgb  6625_lgb  6626_lgb  6627_lgb  6628_lgb  6629_lgb  6630_lgb  \\\n",
       "0         0         0         0         0         0         1         0   \n",
       "1         0         0         0         0         1         0         0   \n",
       "2         0         0         0         1         0         0         0   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   6631_lgb  6632_lgb  6633_lgb  6634_lgb  7360_lgb  7361_lgb  7362_lgb  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   7363_lgb  7364_lgb  7365_lgb  7366_lgb  7367_lgb  7368_lgb  7369_lgb  \\\n",
       "0         1         0         0         0         0         0         0   \n",
       "1         0         0         0         1         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         1         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         1         0   \n",
       "\n",
       "   7370_lgb  8096_lgb  8097_lgb  8098_lgb  8099_lgb  8100_lgb  8101_lgb  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         1         1         0         0         0         0         0   \n",
       "3         0         1         0         0         0         0         0   \n",
       "4         0         1         0         0         0         0         0   \n",
       "\n",
       "   8102_lgb  8103_lgb  8104_lgb  8105_lgb  8832_lgb  8833_lgb  8834_lgb  \\\n",
       "0         0         1         0         0         1         0         0   \n",
       "1         0         0         0         0         1         0         0   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         1         0         0   \n",
       "\n",
       "   8835_lgb  8836_lgb  8837_lgb  8838_lgb  9568_lgb  9569_lgb  9570_lgb  \\\n",
       "0         0         0         0         0         0         1         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         0         0         1         0   \n",
       "\n",
       "   9571_lgb  9572_lgb  10304_lgb  10305_lgb  10306_lgb  10307_lgb  10308_lgb  \\\n",
       "0         0         0          0          1          0          0          0   \n",
       "1         0         1          0          0          0          1          0   \n",
       "2         0         1          1          0          0          0          0   \n",
       "3         1         0          0          1          0          0          0   \n",
       "4         0         0          1          0          0          0          0   \n",
       "\n",
       "   10309_lgb  10310_lgb  10311_lgb  11040_lgb  11041_lgb  11042_lgb  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          0          0          0          0          0          0   \n",
       "4          0          0          0          0          0          0   \n",
       "\n",
       "   11043_lgb  11044_lgb  11776_lgb  11777_lgb  12512_lgb  12513_lgb  \\\n",
       "0          1          0          1          0          0          0   \n",
       "1          0          1          1          0          0          0   \n",
       "2          0          1          1          0          1          0   \n",
       "3          0          1          1          0          1          0   \n",
       "4          0          1          1          0          0          0   \n",
       "\n",
       "   12514_lgb  12515_lgb  12516_lgb  12517_lgb  12518_lgb  13248_lgb  \\\n",
       "0          0          1          0          0          0          0   \n",
       "1          0          1          0          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          0          0          0          0          0          0   \n",
       "4          0          1          0          0          0          0   \n",
       "\n",
       "   13249_lgb  13250_lgb  13251_lgb  13252_lgb  13253_lgb  13254_lgb  \\\n",
       "0          0          0          0          0          0          1   \n",
       "1          0          0          0          1          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          0          0          0          0          0          0   \n",
       "4          0          0          1          0          0          0   \n",
       "\n",
       "   13255_lgb  13256_lgb  13257_lgb  13984_lgb  13985_lgb  13986_lgb  \\\n",
       "0          0          0          0          1          0          0   \n",
       "1          0          0          0          0          1          0   \n",
       "2          1          0          0          1          0          0   \n",
       "3          1          0          0          1          0          0   \n",
       "4          0          0          0          1          0          0   \n",
       "\n",
       "   13987_lgb  13988_lgb  13989_lgb  13990_lgb  14720_lgb  14721_lgb  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          0          0          0          0          1          0   \n",
       "4          0          0          0          0          0          0   \n",
       "\n",
       "   14722_lgb  14723_lgb  14724_lgb  14725_lgb  14726_lgb  14727_lgb  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          1          0          0          0          0          0   \n",
       "2          0          0          0          0          0          1   \n",
       "3          0          0          0          0          0          0   \n",
       "4          0          0          0          0          0          0   \n",
       "\n",
       "   14728_lgb  14729_lgb  14730_lgb  14731_lgb  15456_lgb  15457_lgb  \\\n",
       "0          0          1          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          0          0          0          0          0          0   \n",
       "4          0          1          0          0          0          0   \n",
       "\n",
       "   15458_lgb  15459_lgb  15460_lgb  15461_lgb  15462_lgb  15463_lgb  \\\n",
       "0          0          0          0          0          1          0   \n",
       "1          0          0          1          0          0          0   \n",
       "2          0          0          0          1          0          0   \n",
       "3          0          0          0          1          0          0   \n",
       "4          0          0          0          1          0          0   \n",
       "\n",
       "   16192_lgb  16193_lgb  16194_lgb  16195_lgb  16196_lgb  16197_lgb  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          1          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          0          0          0          1          0          0   \n",
       "4          0          0          0          0          0          0   \n",
       "\n",
       "   16198_lgb  16199_lgb  16200_lgb  16201_lgb  16928_lgb  16929_lgb  \\\n",
       "0          1          0          0          0          0          0   \n",
       "1          0          0          0          0          0          1   \n",
       "2          0          0          1          0          0          0   \n",
       "3          0          0          0          0          0          0   \n",
       "4          1          0          0          0          0          0   \n",
       "\n",
       "   16930_lgb  16931_lgb  16932_lgb  16933_lgb  16934_lgb  16935_lgb  \\\n",
       "0          1          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          1          0          0          0          0   \n",
       "3          0          0          0          0          1          0   \n",
       "4          0          0          1          0          0          0   \n",
       "\n",
       "   16936_lgb  17664_lgb  17665_lgb  17666_lgb  17667_lgb  17668_lgb  \\\n",
       "0          0          0          0          1          0          0   \n",
       "1          0          0          0          1          0          0   \n",
       "2          0          0          0          0          1          0   \n",
       "3          0          0          0          0          1          0   \n",
       "4          0          0          0          0          1          0   \n",
       "\n",
       "   17669_lgb  17670_lgb  17671_lgb  17672_lgb  18400_lgb  18401_lgb  \\\n",
       "0          0          0          0          0          0          1   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          0          0          0          0          0          0   \n",
       "4          0          0          0          0          0          0   \n",
       "\n",
       "   18402_lgb  18403_lgb  18404_lgb  18405_lgb  18406_lgb  18407_lgb  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          1          0          0          0          0          0   \n",
       "2          0          1          0          0          0          0   \n",
       "3          0          0          0          0          0          1   \n",
       "4          0          1          0          0          0          0   \n",
       "\n",
       "   18408_lgb  19136_lgb  19137_lgb  19138_lgb  19872_lgb  19873_lgb  \\\n",
       "0          0          1          0          0          0          0   \n",
       "1          0          1          0          0          0          0   \n",
       "2          0          1          0          0          0          0   \n",
       "3          0          1          0          0          0          0   \n",
       "4          0          1          0          0          0          0   \n",
       "\n",
       "   19874_lgb  19875_lgb  19876_lgb  19877_lgb  19878_lgb  19879_lgb  \\\n",
       "0          0          0          1          0          0          0   \n",
       "1          0          0          0          0          0          1   \n",
       "2          1          0          0          0          0          0   \n",
       "3          1          0          0          0          0          0   \n",
       "4          0          0          0          0          1          0   \n",
       "\n",
       "   20608_lgb  20609_lgb  20610_lgb  20611_lgb  20612_lgb  20613_lgb  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          1          0   \n",
       "3          0          0          0          1          0          0   \n",
       "4          0          0          0          0          0          1   \n",
       "\n",
       "   20614_lgb  20615_lgb  21344_lgb  21345_lgb  21346_lgb  21347_lgb  \\\n",
       "0          0          1          0          0          0          0   \n",
       "1          1          0          0          0          0          0   \n",
       "2          0          0          1          0          0          0   \n",
       "3          0          0          1          0          0          0   \n",
       "4          0          0          1          0          0          0   \n",
       "\n",
       "   21348_lgb  21349_lgb  21350_lgb  21351_lgb  ...  948707_lgb  949440_lgb  \\\n",
       "0          0          0          1          0  ...           0           1   \n",
       "1          1          0          0          0  ...           0           0   \n",
       "2          0          0          0          0  ...           0           1   \n",
       "3          0          0          0          0  ...           0           1   \n",
       "4          0          0          0          0  ...           0           1   \n",
       "\n",
       "   949441_lgb  949442_lgb  949443_lgb  949444_lgb  950176_lgb  950177_lgb  \\\n",
       "0           0           0           0           0           1           0   \n",
       "1           1           0           0           0           0           0   \n",
       "2           0           0           0           0           1           0   \n",
       "3           0           0           0           0           1           0   \n",
       "4           0           0           0           0           1           0   \n",
       "\n",
       "   950178_lgb  950179_lgb  950180_lgb  950181_lgb  950182_lgb  950912_lgb  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           1           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           1   \n",
       "4           0           0           0           0           0           1   \n",
       "\n",
       "   950913_lgb  950914_lgb  950915_lgb  950916_lgb  951648_lgb  951649_lgb  \\\n",
       "0           0           0           1           0           0           0   \n",
       "1           0           0           1           0           1           0   \n",
       "2           0           0           1           0           0           0   \n",
       "3           0           0           0           0           1           0   \n",
       "4           0           0           0           0           1           0   \n",
       "\n",
       "   951650_lgb  951651_lgb  951652_lgb  952384_lgb  952385_lgb  952386_lgb  \\\n",
       "0           1           0           0           1           0           0   \n",
       "1           0           0           0           0           0           1   \n",
       "2           0           0           1           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   952387_lgb  953120_lgb  953121_lgb  953122_lgb  953123_lgb  953856_lgb  \\\n",
       "0           0           1           0           0           0           1   \n",
       "1           0           1           0           0           0           1   \n",
       "2           1           0           1           0           0           1   \n",
       "3           1           1           0           0           0           1   \n",
       "4           1           1           0           0           0           1   \n",
       "\n",
       "   953857_lgb  953858_lgb  953859_lgb  954592_lgb  954593_lgb  954594_lgb  \\\n",
       "0           0           0           0           0           0           1   \n",
       "1           0           0           0           0           0           1   \n",
       "2           0           0           0           1           0           0   \n",
       "3           0           0           0           0           0           1   \n",
       "4           0           0           0           0           1           0   \n",
       "\n",
       "   955328_lgb  955329_lgb  955330_lgb  955331_lgb  955332_lgb  956064_lgb  \\\n",
       "0           1           0           0           0           0           0   \n",
       "1           0           0           1           0           0           1   \n",
       "2           1           0           0           0           0           0   \n",
       "3           1           0           0           0           0           1   \n",
       "4           0           0           0           0           1           1   \n",
       "\n",
       "   956065_lgb  956066_lgb  956067_lgb  956068_lgb  956069_lgb  956800_lgb  \\\n",
       "0           0           1           0           0           0           1   \n",
       "1           0           0           0           0           0           1   \n",
       "2           0           0           0           0           1           1   \n",
       "3           0           0           0           0           0           1   \n",
       "4           0           0           0           0           0           1   \n",
       "\n",
       "   956801_lgb  957536_lgb  957537_lgb  957538_lgb  957539_lgb  958272_lgb  \\\n",
       "0           0           0           0           0           1           0   \n",
       "1           0           0           0           0           1           1   \n",
       "2           0           1           0           0           0           0   \n",
       "3           0           1           0           0           0           0   \n",
       "4           0           1           0           0           0           0   \n",
       "\n",
       "   958273_lgb  958274_lgb  958275_lgb  959008_lgb  959009_lgb  959010_lgb  \\\n",
       "0           0           0           1           1           0           0   \n",
       "1           0           0           0           1           0           0   \n",
       "2           0           0           1           0           1           0   \n",
       "3           0           0           1           1           0           0   \n",
       "4           0           0           1           1           0           0   \n",
       "\n",
       "   959744_lgb  959745_lgb  959746_lgb  959747_lgb  959748_lgb  959749_lgb  \\\n",
       "0           0           0           0           0           0           1   \n",
       "1           0           0           0           0           0           1   \n",
       "2           0           0           0           1           0           0   \n",
       "3           0           0           0           1           0           0   \n",
       "4           0           0           0           0           0           1   \n",
       "\n",
       "   959750_lgb  960480_lgb  960481_lgb  960482_lgb  960483_lgb  960484_lgb  \\\n",
       "0           0           0           1           0           0           0   \n",
       "1           0           1           0           0           0           0   \n",
       "2           0           1           0           0           0           0   \n",
       "3           0           0           1           0           0           0   \n",
       "4           0           1           0           0           0           0   \n",
       "\n",
       "   960485_lgb  961216_lgb  961217_lgb  961218_lgb  961219_lgb  961220_lgb  \\\n",
       "0           0           0           1           0           0           0   \n",
       "1           0           0           0           1           0           0   \n",
       "2           0           0           0           0           1           0   \n",
       "3           0           0           0           0           1           0   \n",
       "4           0           1           0           0           0           0   \n",
       "\n",
       "   961952_lgb  961953_lgb  961954_lgb  961955_lgb  961956_lgb  961957_lgb  \\\n",
       "0           0           0           0           0           1           0   \n",
       "1           0           0           0           0           1           0   \n",
       "2           0           0           0           0           1           0   \n",
       "3           0           0           0           1           0           0   \n",
       "4           1           0           0           0           0           0   \n",
       "\n",
       "   962688_lgb  962689_lgb  962690_lgb  963424_lgb  963425_lgb  963426_lgb  \\\n",
       "0           0           1           0           1           0           0   \n",
       "1           1           0           0           0           1           0   \n",
       "2           1           0           0           1           0           0   \n",
       "3           0           1           0           1           0           0   \n",
       "4           1           0           0           1           0           0   \n",
       "\n",
       "   963427_lgb  964160_lgb  964161_lgb  964162_lgb  964163_lgb  964896_lgb  \\\n",
       "0           0           0           0           0           1           1   \n",
       "1           0           0           0           0           1           1   \n",
       "2           0           1           0           0           0           1   \n",
       "3           0           1           0           0           0           1   \n",
       "4           0           0           0           0           1           1   \n",
       "\n",
       "   964897_lgb  964898_lgb  965632_lgb  965633_lgb  965634_lgb  966368_lgb  \\\n",
       "0           0           0           1           0           0           0   \n",
       "1           0           0           1           0           0           0   \n",
       "2           0           0           0           1           0           0   \n",
       "3           0           0           1           0           0           0   \n",
       "4           0           0           1           0           0           0   \n",
       "\n",
       "   966369_lgb  966370_lgb  966371_lgb  966372_lgb  967104_lgb  967105_lgb  \\\n",
       "0           0           0           0           1           0           0   \n",
       "1           0           0           0           1           0           0   \n",
       "2           0           1           0           0           0           0   \n",
       "3           1           0           0           0           0           0   \n",
       "4           0           0           1           0           0           0   \n",
       "\n",
       "   967106_lgb  967107_lgb  967108_lgb  967109_lgb  967110_lgb  967840_lgb  \\\n",
       "0           0           0           0           0           1           0   \n",
       "1           0           0           0           0           1           1   \n",
       "2           0           1           0           0           0           0   \n",
       "3           0           1           0           0           0           0   \n",
       "4           0           0           0           0           1           0   \n",
       "\n",
       "   967841_lgb  967842_lgb  968576_lgb  968577_lgb  968578_lgb  968579_lgb  \\\n",
       "0           1           0           0           0           1           0   \n",
       "1           0           0           0           0           1           0   \n",
       "2           1           0           0           0           1           0   \n",
       "3           1           0           1           0           0           0   \n",
       "4           1           0           0           0           1           0   \n",
       "\n",
       "   969312_lgb  969313_lgb  969314_lgb  969315_lgb  970048_lgb  970049_lgb  \\\n",
       "0           0           0           0           1           1           0   \n",
       "1           0           0           0           1           1           0   \n",
       "2           1           0           0           0           0           1   \n",
       "3           1           0           0           0           1           0   \n",
       "4           0           1           0           0           1           0   \n",
       "\n",
       "   970050_lgb  970051_lgb  970784_lgb  970785_lgb  970786_lgb  970787_lgb  \\\n",
       "0           0           0           0           0           1           0   \n",
       "1           0           0           1           0           0           0   \n",
       "2           0           0           0           0           1           0   \n",
       "3           0           0           0           1           0           0   \n",
       "4           0           0           0           1           0           0   \n",
       "\n",
       "   970788_lgb  971520_lgb  971521_lgb  971522_lgb  971523_lgb  971524_lgb  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           1           0           0           0           0   \n",
       "2           0           0           0           1           0           0   \n",
       "3           0           1           0           0           0           0   \n",
       "4           0           1           0           0           0           0   \n",
       "\n",
       "   971525_lgb  971526_lgb  972256_lgb  972257_lgb  972258_lgb  972259_lgb  \\\n",
       "0           0           1           0           0           0           0   \n",
       "1           0           0           0           0           1           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           1           0           0   \n",
       "4           0           0           0           0           1           0   \n",
       "\n",
       "   972260_lgb  972261_lgb  972992_lgb  972993_lgb  972994_lgb  972995_lgb  \\\n",
       "0           0           1           0           0           1           0   \n",
       "1           0           0           0           0           0           1   \n",
       "2           1           0           1           0           0           0   \n",
       "3           0           0           1           0           0           0   \n",
       "4           0           0           1           0           0           0   \n",
       "\n",
       "   973728_lgb  973729_lgb  973730_lgb  973731_lgb  973732_lgb  973733_lgb  \\\n",
       "0           0           0           0           0           0           1   \n",
       "1           0           0           0           0           1           0   \n",
       "2           0           0           0           1           0           0   \n",
       "3           0           0           0           0           1           0   \n",
       "4           0           0           0           1           0           0   \n",
       "\n",
       "   973734_lgb  974464_lgb  974465_lgb  974466_lgb  974467_lgb  974468_lgb  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           1           0           0   \n",
       "2           0           0           0           0           0           1   \n",
       "3           0           0           1           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   974469_lgb  974470_lgb  975200_lgb  975201_lgb  975936_lgb  975937_lgb  \\\n",
       "0           1           0           0           1           0           0   \n",
       "1           0           0           1           0           0           0   \n",
       "2           0           0           1           0           0           0   \n",
       "3           0           0           0           1           1           0   \n",
       "4           0           1           1           0           1           0   \n",
       "\n",
       "   975938_lgb  975939_lgb  976672_lgb  976673_lgb  976674_lgb  976675_lgb  \\\n",
       "0           0           1           0           0           0           0   \n",
       "1           0           1           0           0           0           0   \n",
       "2           0           1           0           0           0           1   \n",
       "3           0           0           0           0           0           1   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   976676_lgb  976677_lgb  977408_lgb  977409_lgb  977410_lgb  977411_lgb  \\\n",
       "0           0           1           0           0           0           1   \n",
       "1           0           1           1           0           0           0   \n",
       "2           0           0           1           0           0           0   \n",
       "3           0           0           0           1           0           0   \n",
       "4           1           0           1           0           0           0   \n",
       "\n",
       "   977412_lgb  978144_lgb  978145_lgb  978146_lgb  978147_lgb  978880_lgb  \\\n",
       "0           0           1           0           0           0           0   \n",
       "1           0           0           1           0           0           0   \n",
       "2           0           1           0           0           0           0   \n",
       "3           0           1           0           0           0           0   \n",
       "4           0           1           0           0           0           0   \n",
       "\n",
       "   978881_lgb  978882_lgb  978883_lgb  979616_lgb  979617_lgb  980352_lgb  \\\n",
       "0           1           0           0           1           0           0   \n",
       "1           1           0           0           1           0           0   \n",
       "2           1           0           0           1           0           1   \n",
       "3           1           0           0           1           0           0   \n",
       "4           1           0           0           1           0           1   \n",
       "\n",
       "   980353_lgb  980354_lgb  980355_lgb  981088_lgb  981089_lgb  981090_lgb  \\\n",
       "0           0           1           0           1           0           0   \n",
       "1           1           0           0           0           0           1   \n",
       "2           0           0           0           1           0           0   \n",
       "3           1           0           0           1           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   981091_lgb  981092_lgb  981824_lgb  981825_lgb  981826_lgb  981827_lgb  \\\n",
       "0           0           0           0           0           1           0   \n",
       "1           0           0           0           0           1           0   \n",
       "2           0           0           1           0           0           0   \n",
       "3           0           0           0           1           0           0   \n",
       "4           0           1           0           0           1           0   \n",
       "\n",
       "   982560_lgb  982561_lgb  982562_lgb  983296_lgb  983297_lgb  983298_lgb  \\\n",
       "0           0           0           1           1           0           0   \n",
       "1           0           0           1           0           0           0   \n",
       "2           0           0           1           0           0           0   \n",
       "3           1           0           0           1           0           0   \n",
       "4           1           0           0           0           0           0   \n",
       "\n",
       "   983299_lgb  983300_lgb  983301_lgb  984032_lgb  984033_lgb  984034_lgb  \\\n",
       "0           0           0           0           1           0           0   \n",
       "1           1           0           0           1           0           0   \n",
       "2           1           0           0           1           0           0   \n",
       "3           0           0           0           1           0           0   \n",
       "4           0           0           1           1           0           0   \n",
       "\n",
       "   984768_lgb  984769_lgb  984770_lgb  985504_lgb  985505_lgb  985506_lgb  \\\n",
       "0           0           0           1           0           0           1   \n",
       "1           1           0           0           1           0           0   \n",
       "2           0           0           1           0           0           1   \n",
       "3           0           0           1           0           0           1   \n",
       "4           0           0           1           0           0           0   \n",
       "\n",
       "   985507_lgb  985508_lgb  986240_lgb  986241_lgb  986242_lgb  986976_lgb  \\\n",
       "0           0           0           1           0           0           0   \n",
       "1           0           0           0           0           1           0   \n",
       "2           0           0           1           0           0           0   \n",
       "3           0           0           1           0           0           0   \n",
       "4           0           1           1           0           0           1   \n",
       "\n",
       "   986977_lgb  986978_lgb  987712_lgb  987713_lgb  987714_lgb  987715_lgb  \\\n",
       "0           0           1           0           0           1           0   \n",
       "1           1           0           0           0           0           0   \n",
       "2           0           1           1           0           0           0   \n",
       "3           1           0           0           1           0           0   \n",
       "4           0           0           0           0           0           1   \n",
       "\n",
       "   987716_lgb  988448_lgb  988449_lgb  988450_lgb  988451_lgb  989184_lgb  \\\n",
       "0           0           0           0           0           1           0   \n",
       "1           1           0           0           0           1           0   \n",
       "2           0           0           0           0           1           1   \n",
       "3           0           1           0           0           0           0   \n",
       "4           0           1           0           0           0           0   \n",
       "\n",
       "   989185_lgb  989186_lgb  989187_lgb  989920_lgb  989921_lgb  989922_lgb  \\\n",
       "0           0           0           1           1           0           0   \n",
       "1           0           1           0           0           0           1   \n",
       "2           0           0           0           1           0           0   \n",
       "3           1           0           0           1           0           0   \n",
       "4           0           1           0           0           0           0   \n",
       "\n",
       "   989923_lgb  989924_lgb  989925_lgb  990656_lgb  990657_lgb  990658_lgb  \\\n",
       "0           0           0           0           0           0           1   \n",
       "1           0           0           0           1           0           0   \n",
       "2           0           0           0           1           0           0   \n",
       "3           0           0           0           0           1           0   \n",
       "4           0           0           1           1           0           0   \n",
       "\n",
       "   990659_lgb  991392_lgb  991393_lgb  991394_lgb  991395_lgb  992128_lgb  \\\n",
       "0           0           0           0           0           1           1   \n",
       "1           0           0           0           1           0           1   \n",
       "2           0           1           0           0           0           1   \n",
       "3           0           0           1           0           0           1   \n",
       "4           0           0           0           0           1           1   \n",
       "\n",
       "   992129_lgb  992130_lgb  992864_lgb  992865_lgb  992866_lgb  992867_lgb  \\\n",
       "0           0           0           1           0           0           0   \n",
       "1           0           0           0           0           0           1   \n",
       "2           0           0           1           0           0           0   \n",
       "3           0           0           1           0           0           0   \n",
       "4           0           0           1           0           0           0   \n",
       "\n",
       "   993600_lgb  993601_lgb  993602_lgb  993603_lgb  994336_lgb  994337_lgb  \\\n",
       "0           0           0           0           1           1           0   \n",
       "1           0           0           1           0           0           0   \n",
       "2           0           0           0           1           1           0   \n",
       "3           0           1           0           0           0           0   \n",
       "4           1           0           0           0           1           0   \n",
       "\n",
       "   994338_lgb  994339_lgb  995072_lgb  995073_lgb  995074_lgb  995075_lgb  \\\n",
       "0           0           0           0           0           0           1   \n",
       "1           0           1           1           0           0           0   \n",
       "2           0           0           0           1           0           0   \n",
       "3           1           0           0           0           0           1   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   995076_lgb  995808_lgb  995809_lgb  995810_lgb  995811_lgb  995812_lgb  \\\n",
       "0           0           0           0           1           0           0   \n",
       "1           0           0           1           0           0           0   \n",
       "2           0           1           0           0           0           0   \n",
       "3           0           1           0           0           0           0   \n",
       "4           1           1           0           0           0           0   \n",
       "\n",
       "   996544_lgb  996545_lgb  996546_lgb  997280_lgb  997281_lgb  997282_lgb  \\\n",
       "0           0           0           1           0           0           1   \n",
       "1           0           0           1           1           0           0   \n",
       "2           1           0           0           0           0           1   \n",
       "3           0           1           0           0           0           1   \n",
       "4           0           0           1           0           0           1   \n",
       "\n",
       "   997283_lgb  997284_lgb  998016_lgb  998017_lgb  998018_lgb  998019_lgb  \\\n",
       "0           0           0           0           0           1           0   \n",
       "1           0           0           0           1           0           0   \n",
       "2           0           0           1           0           0           0   \n",
       "3           0           0           1           0           0           0   \n",
       "4           0           0           1           0           0           0   \n",
       "\n",
       "   998752_lgb  998753_lgb  998754_lgb  998755_lgb  \n",
       "0           1           0           0           0  \n",
       "1           0           0           1           0  \n",
       "2           1           0           0           0  \n",
       "3           1           0           0           0  \n",
       "4           0           0           1           0  \n",
       "\n",
       "[5 rows x 7269 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.add_suffix('_lgb')\n",
    "\n",
    "#  存储lgb-onehot\n",
    "pd.concat([df,df2],axis=1).to_pickle('./data/filter_feas_df32n_old_lgb_oh.pkl')\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb0052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab31d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae55c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d0e987e",
   "metadata": {},
   "source": [
    "### 训练集异常检测编码\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15477c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models import iforest\n",
    "\n",
    "\n",
    "it = iforest.IForest()\n",
    "\n",
    "it.fit(train_x)\n",
    "ift = it.predict_proba(df[final_feas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b10d9d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>report_timestamp</th>\n",
       "      <th>BureauScore</th>\n",
       "      <th>BureauScoreConfidLevel</th>\n",
       "      <th>MissingRate</th>\n",
       "      <th>Current_Enquiry_Reason</th>\n",
       "      <th>Current_Gender_Code</th>\n",
       "      <th>First_Name1</th>\n",
       "      <th>Len_Name</th>\n",
       "      <th>Tel_nuniq</th>\n",
       "      <th>Email_nuniq</th>\n",
       "      <th>IncomeTaxPAN_5</th>\n",
       "      <th>Len_of_addrs</th>\n",
       "      <th>City_nuniq</th>\n",
       "      <th>PinCode3</th>\n",
       "      <th>Current_State</th>\n",
       "      <th>Current_City</th>\n",
       "      <th>CreditAccountActive</th>\n",
       "      <th>CreditAccountTotal</th>\n",
       "      <th>CreditAccountActivePor</th>\n",
       "      <th>Outstanding_Balance_Secured</th>\n",
       "      <th>Outstanding_Balance_UnSecured_Percentage</th>\n",
       "      <th>Outstanding_Balance_All</th>\n",
       "      <th>Outstanding_Balance_Secured_Percentage</th>\n",
       "      <th>Outstanding_Balance_UnSecured</th>\n",
       "      <th>Diff_dateBirth</th>\n",
       "      <th>State_nuniq</th>\n",
       "      <th>Birth_nuniq</th>\n",
       "      <th>TotalCAPSLast90Days</th>\n",
       "      <th>TotalCAPSLast7Days</th>\n",
       "      <th>TotalCAPSLast30Days</th>\n",
       "      <th>TotalCAPSLast180Days</th>\n",
       "      <th>CAPSLast30Days</th>\n",
       "      <th>CAPSLast7Days</th>\n",
       "      <th>CAPSLast180Days</th>\n",
       "      <th>NonCreditCAPSLast180Days</th>\n",
       "      <th>Pin_nuniq</th>\n",
       "      <th>Pan_nuniq</th>\n",
       "      <th>Ident_nuniq</th>\n",
       "      <th>Name_nuniq2</th>\n",
       "      <th>Tel_nuniq2</th>\n",
       "      <th>Email_nuniq2</th>\n",
       "      <th>Pan_nuniq2</th>\n",
       "      <th>Account_nuniq2</th>\n",
       "      <th>Ident_nuniq2</th>\n",
       "      <th>Gender_nuniq</th>\n",
       "      <th>Amount_Past_Due35_sum_30</th>\n",
       "      <th>Amount_Past_Due35_min_30</th>\n",
       "      <th>Amount_Past_Due35_sum_90</th>\n",
       "      <th>Amount_Past_Due35_mean_90</th>\n",
       "      <th>Amount_Past_Due35_max_90</th>\n",
       "      <th>Amount_Past_Due35_min_90</th>\n",
       "      <th>Amount_Past_Due35_std_90</th>\n",
       "      <th>Amount_Past_Due35_sum_360</th>\n",
       "      <th>Amount_Past_Due35_mean_360</th>\n",
       "      <th>Amount_Past_Due35_max_360</th>\n",
       "      <th>Amount_Past_Due35_std_360</th>\n",
       "      <th>Amount_Past_Due35_sum_9999</th>\n",
       "      <th>Amount_Past_Due35_max_9999</th>\n",
       "      <th>Amount_Past_Due35_min_9999</th>\n",
       "      <th>Amount_Past_Due35_std_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_9999</th>\n",
       "      <th>Terms_Duration34_sum_30</th>\n",
       "      <th>Terms_Duration34_std_30</th>\n",
       "      <th>Terms_Duration34_sum_90</th>\n",
       "      <th>Terms_Duration34_std_90</th>\n",
       "      <th>Terms_Duration34_mean_360</th>\n",
       "      <th>Terms_Duration34_max_360</th>\n",
       "      <th>Terms_Duration34_min_360</th>\n",
       "      <th>Terms_Duration34_std_360</th>\n",
       "      <th>Terms_Duration34_sum_9999</th>\n",
       "      <th>Terms_Duration34_mean_9999</th>\n",
       "      <th>Terms_Duration34_max_9999</th>\n",
       "      <th>Terms_Duration34_min_9999</th>\n",
       "      <th>Terms_Duration34_std_9999</th>\n",
       "      <th>Payment_Rating34_sum_90</th>\n",
       "      <th>Payment_Rating34_mean_90</th>\n",
       "      <th>Payment_Rating34_max_90</th>\n",
       "      <th>Payment_Rating34_min_90</th>\n",
       "      <th>Payment_Rating34_std_90</th>\n",
       "      <th>Payment_Rating34_sum_360</th>\n",
       "      <th>Payment_Rating34_mean_360</th>\n",
       "      <th>Payment_Rating34_max_360</th>\n",
       "      <th>Payment_Rating34_min_360</th>\n",
       "      <th>Payment_Rating34_std_360</th>\n",
       "      <th>Payment_Rating34_sum_9999</th>\n",
       "      <th>Payment_Rating34_mean_9999</th>\n",
       "      <th>Payment_Rating34_max_9999</th>\n",
       "      <th>Payment_Rating34_min_9999</th>\n",
       "      <th>Payment_Rating34_std_9999</th>\n",
       "      <th>Current_Balance35_mean_30</th>\n",
       "      <th>Current_Balance35_min_30</th>\n",
       "      <th>Current_Balance35_std_30</th>\n",
       "      <th>Current_Balance35_sum_90</th>\n",
       "      <th>Current_Balance35_mean_90</th>\n",
       "      <th>Current_Balance35_max_90</th>\n",
       "      <th>Current_Balance35_std_90</th>\n",
       "      <th>Current_Balance35_sum_360</th>\n",
       "      <th>Current_Balance35_max_360</th>\n",
       "      <th>Current_Balance35_std_360</th>\n",
       "      <th>Current_Balance35_max_9999</th>\n",
       "      <th>Current_Balance35_std_9999</th>\n",
       "      <th>Settlement_Amount37_max_360</th>\n",
       "      <th>Settlement_Amount37_min_360</th>\n",
       "      <th>Settlement_Amount37_std_360</th>\n",
       "      <th>Settlement_Amount37_sum_9999</th>\n",
       "      <th>Settlement_Amount37_mean_9999</th>\n",
       "      <th>Settlement_Amount37_max_9999</th>\n",
       "      <th>Settlement_Amount37_min_9999</th>\n",
       "      <th>Settlement_Amount37_std_9999</th>\n",
       "      <th>Value_of_Collateral39_std_90</th>\n",
       "      <th>Value_of_Collateral39_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_360</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_360</th>\n",
       "      <th>Written_Off_Amt_Total41_min_360</th>\n",
       "      <th>Written_Off_Amt_Total41_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_max_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_min_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_std_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_mean_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_std_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_max_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_9999</th>\n",
       "      <th>Rate_of_Interest36_sum_30</th>\n",
       "      <th>Rate_of_Interest36_std_30</th>\n",
       "      <th>Rate_of_Interest36_sum_90</th>\n",
       "      <th>Rate_of_Interest36_mean_90</th>\n",
       "      <th>Rate_of_Interest36_max_90</th>\n",
       "      <th>Rate_of_Interest36_std_90</th>\n",
       "      <th>Rate_of_Interest36_sum_360</th>\n",
       "      <th>Rate_of_Interest36_mean_360</th>\n",
       "      <th>Rate_of_Interest36_max_360</th>\n",
       "      <th>Rate_of_Interest36_min_360</th>\n",
       "      <th>Rate_of_Interest36_std_360</th>\n",
       "      <th>Rate_of_Interest36_sum_9999</th>\n",
       "      <th>Rate_of_Interest36_mean_9999</th>\n",
       "      <th>Rate_of_Interest36_max_9999</th>\n",
       "      <th>Rate_of_Interest36_min_9999</th>\n",
       "      <th>Rate_of_Interest36_std_9999</th>\n",
       "      <th>Repayment_Tenure36_std_30</th>\n",
       "      <th>Repayment_Tenure36_mean_90</th>\n",
       "      <th>Repayment_Tenure36_max_90</th>\n",
       "      <th>Repayment_Tenure36_min_90</th>\n",
       "      <th>Repayment_Tenure36_std_90</th>\n",
       "      <th>Repayment_Tenure36_sum_360</th>\n",
       "      <th>Repayment_Tenure36_mean_360</th>\n",
       "      <th>Repayment_Tenure36_min_360</th>\n",
       "      <th>Repayment_Tenure36_std_360</th>\n",
       "      <th>Repayment_Tenure36_mean_9999</th>\n",
       "      <th>Repayment_Tenure36_min_9999</th>\n",
       "      <th>Repayment_Tenure36_std_9999</th>\n",
       "      <th>Income26_count_360</th>\n",
       "      <th>Income26_std_360</th>\n",
       "      <th>Open_Date29_max_30</th>\n",
       "      <th>Open_Date29_min_30</th>\n",
       "      <th>Open_Date29_mean_30</th>\n",
       "      <th>Open_Date29_nuniq_30</th>\n",
       "      <th>Open_Date29_maxcount_30</th>\n",
       "      <th>Open_Date29_max_90</th>\n",
       "      <th>Open_Date29_mean_90</th>\n",
       "      <th>Open_Date29_mode_90</th>\n",
       "      <th>Open_Date29_nuniq_90</th>\n",
       "      <th>Open_Date29_maxcount_90</th>\n",
       "      <th>Open_Date29_max_360</th>\n",
       "      <th>Open_Date29_mean_360</th>\n",
       "      <th>Open_Date29_mode_360</th>\n",
       "      <th>Open_Date29_nuniq_360</th>\n",
       "      <th>Open_Date29_maxcount_360</th>\n",
       "      <th>Open_Date29_max_9999</th>\n",
       "      <th>Open_Date29_mean_9999</th>\n",
       "      <th>Open_Date29_mode_9999</th>\n",
       "      <th>Open_Date29_maxcount_9999</th>\n",
       "      <th>Portfolio_Type34_mode_30</th>\n",
       "      <th>Portfolio_Type34_nuniq_30</th>\n",
       "      <th>Portfolio_Type34_nuniq_90</th>\n",
       "      <th>Portfolio_Type34_mode_360</th>\n",
       "      <th>Portfolio_Type34_nuniq_360</th>\n",
       "      <th>Portfolio_Type34_mode_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_9999</th>\n",
       "      <th>Account_Type32_nuniq_30</th>\n",
       "      <th>Account_Type32_mode_90</th>\n",
       "      <th>Account_Type32_nuniq_90</th>\n",
       "      <th>Account_Type32_mode_360</th>\n",
       "      <th>Account_Type32_nuniq_360</th>\n",
       "      <th>Account_Type32_mode_9999</th>\n",
       "      <th>Account_Type32_nuniq_9999</th>\n",
       "      <th>Occupation_Code35_nuniq_30</th>\n",
       "      <th>Occupation_Code35_nuniq_90</th>\n",
       "      <th>Occupation_Code35_nuniq_360</th>\n",
       "      <th>Occupation_Code35_nuniq_9999</th>\n",
       "      <th>CurrencyCode32_mode_360</th>\n",
       "      <th>CurrencyCode32_mode_9999</th>\n",
       "      <th>AccountHoldertypeCode41_mode_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_360</th>\n",
       "      <th>AccountHoldertypeCode41_mode_9999</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_9999</th>\n",
       "      <th>Payment_History_Profile43_mode_30</th>\n",
       "      <th>Payment_History_Profile43_mode_90</th>\n",
       "      <th>Payment_History_Profile43_nuniq_90</th>\n",
       "      <th>Payment_History_Profile43_mode_360</th>\n",
       "      <th>Payment_History_Profile43_nuniq_360</th>\n",
       "      <th>Payment_History_Profile43_mode_9999</th>\n",
       "      <th>Payment_History_Profile43_nuniq_9999</th>\n",
       "      <th>Date_Closed31_nuniq_30</th>\n",
       "      <th>Date_Closed31_maxcount_30</th>\n",
       "      <th>Date_Closed31_max_90</th>\n",
       "      <th>Date_Closed31_min_90</th>\n",
       "      <th>Date_Closed31_mean_90</th>\n",
       "      <th>Date_Closed31_mode_90</th>\n",
       "      <th>Date_Closed31_nuniq_90</th>\n",
       "      <th>Date_Closed31_maxcount_90</th>\n",
       "      <th>Date_Closed31_min_360</th>\n",
       "      <th>Date_Closed31_mode_360</th>\n",
       "      <th>Date_Closed31_nuniq_360</th>\n",
       "      <th>Date_Closed31_maxcount_360</th>\n",
       "      <th>Date_Closed31_max_9999</th>\n",
       "      <th>Date_Closed31_min_9999</th>\n",
       "      <th>Date_Closed31_mean_9999</th>\n",
       "      <th>Date_Closed31_mode_9999</th>\n",
       "      <th>Date_Closed31_nuniq_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_30</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_30</th>\n",
       "      <th>Date_of_Last_Payment40_min_90</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_90</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_90</th>\n",
       "      <th>Date_of_Last_Payment40_max_360</th>\n",
       "      <th>Date_of_Last_Payment40_min_360</th>\n",
       "      <th>Date_of_Last_Payment40_mean_360</th>\n",
       "      <th>Date_of_Last_Payment40_mode_360</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_360</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_360</th>\n",
       "      <th>Date_of_Last_Payment40_max_9999</th>\n",
       "      <th>Date_of_Last_Payment40_min_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mean_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_9999</th>\n",
       "      <th>Date_Reported33_nuniq_30</th>\n",
       "      <th>Date_Reported33_max_90</th>\n",
       "      <th>Date_Reported33_mean_90</th>\n",
       "      <th>Date_Reported33_mode_90</th>\n",
       "      <th>Date_Reported33_nuniq_90</th>\n",
       "      <th>Date_Reported33_maxcount_90</th>\n",
       "      <th>Date_Reported33_max_360</th>\n",
       "      <th>Date_Reported33_mean_360</th>\n",
       "      <th>Date_Reported33_mode_360</th>\n",
       "      <th>Date_Reported33_nuniq_360</th>\n",
       "      <th>Date_Reported33_maxcount_360</th>\n",
       "      <th>Date_Reported33_max_9999</th>\n",
       "      <th>Date_Reported33_mean_9999</th>\n",
       "      <th>Date_Reported33_mode_9999</th>\n",
       "      <th>Date_Reported33_nuniq_9999</th>\n",
       "      <th>Date_Reported33_maxcount_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_30</th>\n",
       "      <th>DateOfAddition34_max_90</th>\n",
       "      <th>DateOfAddition34_mean_90</th>\n",
       "      <th>DateOfAddition34_mode_90</th>\n",
       "      <th>DateOfAddition34_nuniq_90</th>\n",
       "      <th>DateOfAddition34_maxcount_90</th>\n",
       "      <th>DateOfAddition34_max_360</th>\n",
       "      <th>DateOfAddition34_mean_360</th>\n",
       "      <th>DateOfAddition34_mode_360</th>\n",
       "      <th>DateOfAddition34_nuniq_360</th>\n",
       "      <th>DateOfAddition34_maxcount_360</th>\n",
       "      <th>DateOfAddition34_max_9999</th>\n",
       "      <th>DateOfAddition34_mean_9999</th>\n",
       "      <th>DateOfAddition34_mode_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_9999</th>\n",
       "      <th>DateOfAddition34_maxcount_9999</th>\n",
       "      <th>Account_Status34_mode_30</th>\n",
       "      <th>Account_Status34_nuniq_30</th>\n",
       "      <th>Account_Status34_mode_90</th>\n",
       "      <th>Account_Status34_nuniq_90</th>\n",
       "      <th>Account_Status34_mode_360</th>\n",
       "      <th>Account_Status34_nuniq_360</th>\n",
       "      <th>Account_Status34_mode_9999</th>\n",
       "      <th>Account_Status34_nuniq_9999</th>\n",
       "      <th>Month50_sum_30</th>\n",
       "      <th>Month50_max_30</th>\n",
       "      <th>Month50_std_30</th>\n",
       "      <th>Month50_sum_90</th>\n",
       "      <th>Month50_mean_90</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_1036_sms</th>\n",
       "      <th>feature_1037_sms</th>\n",
       "      <th>feature_1038_sms</th>\n",
       "      <th>feature_1039_sms</th>\n",
       "      <th>feature_1040_sms</th>\n",
       "      <th>feature_1041_sms</th>\n",
       "      <th>feature_1042_sms</th>\n",
       "      <th>feature_1043_sms</th>\n",
       "      <th>feature_1044_sms</th>\n",
       "      <th>feature_1045_sms</th>\n",
       "      <th>feature_1046_sms</th>\n",
       "      <th>feature_1047_sms</th>\n",
       "      <th>feature_1048_sms</th>\n",
       "      <th>feature_1049_sms</th>\n",
       "      <th>feature_1050_sms</th>\n",
       "      <th>feature_1051_sms</th>\n",
       "      <th>feature_1052_sms</th>\n",
       "      <th>feature_1053_sms</th>\n",
       "      <th>feature_1054_sms</th>\n",
       "      <th>feature_1055_sms</th>\n",
       "      <th>feature_1056_sms</th>\n",
       "      <th>feature_1057_sms</th>\n",
       "      <th>feature_1058_sms</th>\n",
       "      <th>feature_1059_sms</th>\n",
       "      <th>feature_1060_sms</th>\n",
       "      <th>feature_1061_sms</th>\n",
       "      <th>feature_1062_sms</th>\n",
       "      <th>feature_1063_sms</th>\n",
       "      <th>feature_1064_sms</th>\n",
       "      <th>feature_1065_sms</th>\n",
       "      <th>feature_1066_sms</th>\n",
       "      <th>feature_1067_sms</th>\n",
       "      <th>feature_1068_sms</th>\n",
       "      <th>feature_1069_sms</th>\n",
       "      <th>feature_1070_sms</th>\n",
       "      <th>feature_1071_sms</th>\n",
       "      <th>feature_1072_sms</th>\n",
       "      <th>feature_1073_sms</th>\n",
       "      <th>feature_1074_sms</th>\n",
       "      <th>feature_1075_sms</th>\n",
       "      <th>feature_1076_sms</th>\n",
       "      <th>feature_1077_sms</th>\n",
       "      <th>feature_1078_sms</th>\n",
       "      <th>feature_1079_sms</th>\n",
       "      <th>feature_1080_sms</th>\n",
       "      <th>feature_1081_sms</th>\n",
       "      <th>feature_1082_sms</th>\n",
       "      <th>feature_1083_sms</th>\n",
       "      <th>feature_1084_sms</th>\n",
       "      <th>feature_1085_sms</th>\n",
       "      <th>feature_1086_sms</th>\n",
       "      <th>feature_1087_sms</th>\n",
       "      <th>feature_1088_sms</th>\n",
       "      <th>feature_1089_sms</th>\n",
       "      <th>feature_1090_sms</th>\n",
       "      <th>feature_1091_sms</th>\n",
       "      <th>feature_1092_sms</th>\n",
       "      <th>feature_1093_sms</th>\n",
       "      <th>feature_1094_sms</th>\n",
       "      <th>feature_1095_sms</th>\n",
       "      <th>feature_1096_sms</th>\n",
       "      <th>feature_1097_sms</th>\n",
       "      <th>feature_1098_sms</th>\n",
       "      <th>feature_1099_sms</th>\n",
       "      <th>feature_1100_sms</th>\n",
       "      <th>feature_1101_sms</th>\n",
       "      <th>feature_1102_sms</th>\n",
       "      <th>feature_1103_sms</th>\n",
       "      <th>feature_1104_sms</th>\n",
       "      <th>feature_1105_sms</th>\n",
       "      <th>feature_1106_sms</th>\n",
       "      <th>feature_1107_sms</th>\n",
       "      <th>feature_1108_sms</th>\n",
       "      <th>feature_1109_sms</th>\n",
       "      <th>feature_1110_sms</th>\n",
       "      <th>feature_1111_sms</th>\n",
       "      <th>feature_1112_sms</th>\n",
       "      <th>feature_1113_sms</th>\n",
       "      <th>feature_1114_sms</th>\n",
       "      <th>feature_1115_sms</th>\n",
       "      <th>feature_1116_sms</th>\n",
       "      <th>feature_1117_sms</th>\n",
       "      <th>feature_1118_sms</th>\n",
       "      <th>feature_1119_sms</th>\n",
       "      <th>feature_1120_sms</th>\n",
       "      <th>feature_1121_sms</th>\n",
       "      <th>feature_1122_sms</th>\n",
       "      <th>feature_1123_sms</th>\n",
       "      <th>feature_1124_sms</th>\n",
       "      <th>feature_1125_sms</th>\n",
       "      <th>feature_1126_sms</th>\n",
       "      <th>feature_1127_sms</th>\n",
       "      <th>feature_1128_sms</th>\n",
       "      <th>feature_1129_sms</th>\n",
       "      <th>feature_1130_sms</th>\n",
       "      <th>feature_1131_sms</th>\n",
       "      <th>feature_1132_sms</th>\n",
       "      <th>feature_1133_sms</th>\n",
       "      <th>feature_1134_sms</th>\n",
       "      <th>feature_1135_sms</th>\n",
       "      <th>feature_1136_sms</th>\n",
       "      <th>feature_1137_sms</th>\n",
       "      <th>feature_1138_sms</th>\n",
       "      <th>feature_1139_sms</th>\n",
       "      <th>feature_1140_sms</th>\n",
       "      <th>feature_1141_sms</th>\n",
       "      <th>feature_1142_sms</th>\n",
       "      <th>feature_1143_sms</th>\n",
       "      <th>feature_1144_sms</th>\n",
       "      <th>feature_1145_sms</th>\n",
       "      <th>feature_1146_sms</th>\n",
       "      <th>feature_1147_sms</th>\n",
       "      <th>feature_1148_sms</th>\n",
       "      <th>feature_1149_sms</th>\n",
       "      <th>feature_1150_sms</th>\n",
       "      <th>feature_1151_sms</th>\n",
       "      <th>feature_1152_sms</th>\n",
       "      <th>feature_1153_sms</th>\n",
       "      <th>feature_1154_sms</th>\n",
       "      <th>feature_1155_sms</th>\n",
       "      <th>feature_1156_sms</th>\n",
       "      <th>feature_1157_sms</th>\n",
       "      <th>feature_1158_sms</th>\n",
       "      <th>feature_1159_sms</th>\n",
       "      <th>feature_1160_sms</th>\n",
       "      <th>feature_1161_sms</th>\n",
       "      <th>feature_1162_sms</th>\n",
       "      <th>feature_1163_sms</th>\n",
       "      <th>feature_1164_sms</th>\n",
       "      <th>feature_1165_sms</th>\n",
       "      <th>feature_1166_sms</th>\n",
       "      <th>feature_1167_sms</th>\n",
       "      <th>feature_1168_sms</th>\n",
       "      <th>feature_1169_sms</th>\n",
       "      <th>feature_1170_sms</th>\n",
       "      <th>feature_1171_sms</th>\n",
       "      <th>feature_1172_sms</th>\n",
       "      <th>feature_1173_sms</th>\n",
       "      <th>feature_1174_sms</th>\n",
       "      <th>feature_1175_sms</th>\n",
       "      <th>feature_1176_sms</th>\n",
       "      <th>feature_1177_sms</th>\n",
       "      <th>feature_1178_sms</th>\n",
       "      <th>feature_1179_sms</th>\n",
       "      <th>feature_1180_sms</th>\n",
       "      <th>feature_1181_sms</th>\n",
       "      <th>feature_1182_sms</th>\n",
       "      <th>feature_1183_sms</th>\n",
       "      <th>feature_1184_sms</th>\n",
       "      <th>feature_1185_sms</th>\n",
       "      <th>feature_1186_sms</th>\n",
       "      <th>feature_1187_sms</th>\n",
       "      <th>feature_1188_sms</th>\n",
       "      <th>feature_1189_sms</th>\n",
       "      <th>feature_1190_sms</th>\n",
       "      <th>feature_1191_sms</th>\n",
       "      <th>feature_1192_sms</th>\n",
       "      <th>feature_1193_sms</th>\n",
       "      <th>feature_1194_sms</th>\n",
       "      <th>feature_1195_sms</th>\n",
       "      <th>feature_1196_sms</th>\n",
       "      <th>feature_1197_sms</th>\n",
       "      <th>feature_1198_sms</th>\n",
       "      <th>feature_1199_sms</th>\n",
       "      <th>feature_1200_sms</th>\n",
       "      <th>feature_1201_sms</th>\n",
       "      <th>feature_1202_sms</th>\n",
       "      <th>feature_1203_sms</th>\n",
       "      <th>feature_1204_sms</th>\n",
       "      <th>feature_1205_sms</th>\n",
       "      <th>feature_1206_sms</th>\n",
       "      <th>feature_1207_sms</th>\n",
       "      <th>feature_1208_sms</th>\n",
       "      <th>feature_1209_sms</th>\n",
       "      <th>feature_1210_sms</th>\n",
       "      <th>feature_1211_sms</th>\n",
       "      <th>feature_1212_sms</th>\n",
       "      <th>feature_1213_sms</th>\n",
       "      <th>feature_1214_sms</th>\n",
       "      <th>feature_1215_sms</th>\n",
       "      <th>feature_1216_sms</th>\n",
       "      <th>feature_1217_sms</th>\n",
       "      <th>feature_1218_sms</th>\n",
       "      <th>feature_1219_sms</th>\n",
       "      <th>feature_1220_sms</th>\n",
       "      <th>feature_1221_sms</th>\n",
       "      <th>feature_1222_sms</th>\n",
       "      <th>feature_1223_sms</th>\n",
       "      <th>feature_1224_sms</th>\n",
       "      <th>feature_1225_sms</th>\n",
       "      <th>feature_1226_sms</th>\n",
       "      <th>feature_1227_sms</th>\n",
       "      <th>feature_1228_sms</th>\n",
       "      <th>feature_1229_sms</th>\n",
       "      <th>feature_1230_sms</th>\n",
       "      <th>feature_1231_sms</th>\n",
       "      <th>feature_1232_sms</th>\n",
       "      <th>feature_1233_sms</th>\n",
       "      <th>feature_1234_sms</th>\n",
       "      <th>feature_1235_sms</th>\n",
       "      <th>feature_1236_sms</th>\n",
       "      <th>feature_1237_sms</th>\n",
       "      <th>feature_1238_sms</th>\n",
       "      <th>feature_1239_sms</th>\n",
       "      <th>feature_1240_sms</th>\n",
       "      <th>feature_1241_sms</th>\n",
       "      <th>feature_1242_sms</th>\n",
       "      <th>feature_1243_sms</th>\n",
       "      <th>feature_1244_sms</th>\n",
       "      <th>feature_1245_sms</th>\n",
       "      <th>feature_1246_sms</th>\n",
       "      <th>feature_1247_sms</th>\n",
       "      <th>feature_1248_sms</th>\n",
       "      <th>feature_1249_sms</th>\n",
       "      <th>feature_1250_sms</th>\n",
       "      <th>feature_1251_sms</th>\n",
       "      <th>feature_1252_sms</th>\n",
       "      <th>feature_1253_sms</th>\n",
       "      <th>feature_1254_sms</th>\n",
       "      <th>feature_1255_sms</th>\n",
       "      <th>feature_1256_sms</th>\n",
       "      <th>feature_1257_sms</th>\n",
       "      <th>feature_1258_sms</th>\n",
       "      <th>feature_1259_sms</th>\n",
       "      <th>feature_1260_sms</th>\n",
       "      <th>feature_1261_sms</th>\n",
       "      <th>feature_1262_sms</th>\n",
       "      <th>feature_1263_sms</th>\n",
       "      <th>feature_1264_sms</th>\n",
       "      <th>feature_1265_sms</th>\n",
       "      <th>feature_1266_sms</th>\n",
       "      <th>feature_1267_sms</th>\n",
       "      <th>feature_1268_sms</th>\n",
       "      <th>feature_1269_sms</th>\n",
       "      <th>feature_1270_sms</th>\n",
       "      <th>feature_1271_sms</th>\n",
       "      <th>feature_1272_sms</th>\n",
       "      <th>feature_1273_sms</th>\n",
       "      <th>feature_1274_sms</th>\n",
       "      <th>feature_1275_sms</th>\n",
       "      <th>feature_1276_sms</th>\n",
       "      <th>feature_1277_sms</th>\n",
       "      <th>feature_1278_sms</th>\n",
       "      <th>feature_1279_sms</th>\n",
       "      <th>feature_1280_sms</th>\n",
       "      <th>feature_1281_sms</th>\n",
       "      <th>feature_1282_sms</th>\n",
       "      <th>feature_1283_sms</th>\n",
       "      <th>feature_1284_sms</th>\n",
       "      <th>feature_1285_sms</th>\n",
       "      <th>feature_1286_sms</th>\n",
       "      <th>feature_1287_sms</th>\n",
       "      <th>feature_1288_sms</th>\n",
       "      <th>feature_1289_sms</th>\n",
       "      <th>feature_1290_sms</th>\n",
       "      <th>feature_1291_sms</th>\n",
       "      <th>feature_1292_sms</th>\n",
       "      <th>feature_1293_sms</th>\n",
       "      <th>feature_1294_sms</th>\n",
       "      <th>feature_1295_sms</th>\n",
       "      <th>feature_1296_sms</th>\n",
       "      <th>feature_1297_sms</th>\n",
       "      <th>feature_1298_sms</th>\n",
       "      <th>feature_1299_sms</th>\n",
       "      <th>feature_1300_sms</th>\n",
       "      <th>feature_1301_sms</th>\n",
       "      <th>feature_1302_sms</th>\n",
       "      <th>feature_1303_sms</th>\n",
       "      <th>feature_1304_sms</th>\n",
       "      <th>feature_1305_sms</th>\n",
       "      <th>feature_1306_sms</th>\n",
       "      <th>feature_1307_sms</th>\n",
       "      <th>feature_1308_sms</th>\n",
       "      <th>feature_1309_sms</th>\n",
       "      <th>feature_1310_sms</th>\n",
       "      <th>feature_1311_sms</th>\n",
       "      <th>feature_1312_sms</th>\n",
       "      <th>feature_1313_sms</th>\n",
       "      <th>feature_1314_sms</th>\n",
       "      <th>feature_1315_sms</th>\n",
       "      <th>feature_1316_sms</th>\n",
       "      <th>feature_1317_sms</th>\n",
       "      <th>feature_1318_sms</th>\n",
       "      <th>feature_1319_sms</th>\n",
       "      <th>feature_1320_sms</th>\n",
       "      <th>feature_1321_sms</th>\n",
       "      <th>feature_1322_sms</th>\n",
       "      <th>feature_1323_sms</th>\n",
       "      <th>feature_1324_sms</th>\n",
       "      <th>feature_1325_sms</th>\n",
       "      <th>feature_1326_sms</th>\n",
       "      <th>feature_1327_sms</th>\n",
       "      <th>feature_1328_sms</th>\n",
       "      <th>feature_1329_sms</th>\n",
       "      <th>feature_1330_sms</th>\n",
       "      <th>order_id</th>\n",
       "      <th>pan</th>\n",
       "      <th>label</th>\n",
       "      <th>label_pred</th>\n",
       "      <th>ift_socre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BPZPK3933F</td>\n",
       "      <td>20220210120018</td>\n",
       "      <td>558.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325254</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>11.329890</td>\n",
       "      <td>11.994503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>4.285245</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>0.636335</td>\n",
       "      <td>5064366</td>\n",
       "      <td>2</td>\n",
       "      <td>5181373</td>\n",
       "      <td>98</td>\n",
       "      <td>117007</td>\n",
       "      <td>13092</td>\n",
       "      <td>51.949051</td>\n",
       "      <td>22.489255</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13.246938</td>\n",
       "      <td>66.934066</td>\n",
       "      <td>5.498875</td>\n",
       "      <td>146</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>44.956044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6920.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>6920.0</td>\n",
       "      <td>2996.447897</td>\n",
       "      <td>3937140.0</td>\n",
       "      <td>2057589.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>547470.733164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114378.0</td>\n",
       "      <td>75400.0</td>\n",
       "      <td>28277.352966</td>\n",
       "      <td>6254569.0</td>\n",
       "      <td>284298.590909</td>\n",
       "      <td>1890000.0</td>\n",
       "      <td>509837.280159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.109609</td>\n",
       "      <td>501.0</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.033943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.227273</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.294892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97130.0</td>\n",
       "      <td>75400.0</td>\n",
       "      <td>30111.798663</td>\n",
       "      <td>2057589.0</td>\n",
       "      <td>539918.618880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19637.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.930</td>\n",
       "      <td>18.1860</td>\n",
       "      <td>47.880</td>\n",
       "      <td>7.55</td>\n",
       "      <td>15.316455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.769696</td>\n",
       "      <td>22.772727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.589290</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>113.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2884.0</td>\n",
       "      <td>1061.772727</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1742.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>720.625000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1742.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>401.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>33.25</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>140.25</td>\n",
       "      <td>163.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2478.0</td>\n",
       "      <td>974.136364</td>\n",
       "      <td>163.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>13</td>\n",
       "      <td>71</td>\n",
       "      <td>46</td>\n",
       "      <td>34</td>\n",
       "      <td>737</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>209</td>\n",
       "      <td>15</td>\n",
       "      <td>101</td>\n",
       "      <td>61</td>\n",
       "      <td>48</td>\n",
       "      <td>1876</td>\n",
       "      <td>51</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>445</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>541</td>\n",
       "      <td>30</td>\n",
       "      <td>322</td>\n",
       "      <td>154</td>\n",
       "      <td>113</td>\n",
       "      <td>3000</td>\n",
       "      <td>86</td>\n",
       "      <td>143</td>\n",
       "      <td>25</td>\n",
       "      <td>681</td>\n",
       "      <td>10</td>\n",
       "      <td>58</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>870</td>\n",
       "      <td>38</td>\n",
       "      <td>527</td>\n",
       "      <td>212</td>\n",
       "      <td>162</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>0.037333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0.258929</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.098214</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>30.142857</td>\n",
       "      <td>30.142857</td>\n",
       "      <td>0.070333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>9.428571</td>\n",
       "      <td>0.312796</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.047393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>0.284360</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>0.113744</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>34.428571</td>\n",
       "      <td>34.428571</td>\n",
       "      <td>0.160667</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>0.035270</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>9.071429</td>\n",
       "      <td>0.263485</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>0.039419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>0.035270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.785714</td>\n",
       "      <td>0.284232</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>0.143154</td>\n",
       "      <td>3.214286</td>\n",
       "      <td>0.093361</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>0.068465</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.036190</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>6.523810</td>\n",
       "      <td>0.260952</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.036190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.238095</td>\n",
       "      <td>0.049524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>0.291429</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.024762</td>\n",
       "      <td>3.380952</td>\n",
       "      <td>0.135238</td>\n",
       "      <td>2.190476</td>\n",
       "      <td>0.087619</td>\n",
       "      <td>1.619048</td>\n",
       "      <td>0.064762</td>\n",
       "      <td>24.566667</td>\n",
       "      <td>35.095238</td>\n",
       "      <td>0.245667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.028494</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>6.466667</td>\n",
       "      <td>0.263229</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.006784</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>0.051560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.054274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.966667</td>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>0.137042</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>0.082768</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.065129</td>\n",
       "      <td>31.266667</td>\n",
       "      <td>36.784314</td>\n",
       "      <td>0.625333</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.031450</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>7.416667</td>\n",
       "      <td>0.237207</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.020256</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>0.050107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.183333</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.016667</td>\n",
       "      <td>0.288380</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>5.366667</td>\n",
       "      <td>0.171642</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>0.060235</td>\n",
       "      <td>3.000</td>\n",
       "      <td>34.883721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.047667</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.019333</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.175667</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.070667</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>A5CFUD6W</td>\n",
       "      <td>BPZPK3933F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.508873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FRGPM5396K</td>\n",
       "      <td>20211225195910</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353659</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.499750</td>\n",
       "      <td>5.497751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.749813</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>64753</td>\n",
       "      <td>0</td>\n",
       "      <td>38960</td>\n",
       "      <td>9491</td>\n",
       "      <td>1.999667</td>\n",
       "      <td>1.999667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.999667</td>\n",
       "      <td>8.992008</td>\n",
       "      <td>1.333222</td>\n",
       "      <td>129</td>\n",
       "      <td>28</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>4.996004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>820.000000</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>710.140831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27793.0</td>\n",
       "      <td>25793.0</td>\n",
       "      <td>11896.500000</td>\n",
       "      <td>89990.0</td>\n",
       "      <td>22497.500000</td>\n",
       "      <td>52822.0</td>\n",
       "      <td>19511.426992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25793.0</td>\n",
       "      <td>25793.0</td>\n",
       "      <td>12896.500000</td>\n",
       "      <td>38960.0</td>\n",
       "      <td>16844.306878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.924812</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>282.5</td>\n",
       "      <td>257.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>466.500000</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>624.000000</td>\n",
       "      <td>624.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>184.750000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>269.50</td>\n",
       "      <td>239.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>451.500000</td>\n",
       "      <td>239.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>788</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>113</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>790</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>114</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>795</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>115</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.181132</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>0.236111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>55.714286</td>\n",
       "      <td>55.714286</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.074359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017949</td>\n",
       "      <td>9.142857</td>\n",
       "      <td>0.164103</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.028205</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.161538</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>0.105128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>0.223077</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>0.058974</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.071795</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>53.214286</td>\n",
       "      <td>53.214286</td>\n",
       "      <td>0.937107</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>0.041611</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>0.144966</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>7.857143</td>\n",
       "      <td>0.147651</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>0.123490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.244295</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>3.785714</td>\n",
       "      <td>0.071141</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>0.088591</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.065772</td>\n",
       "      <td>37.523810</td>\n",
       "      <td>49.250000</td>\n",
       "      <td>0.991195</td>\n",
       "      <td>1.476190</td>\n",
       "      <td>0.039340</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>5.380952</td>\n",
       "      <td>0.143401</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.022843</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.151015</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>0.125635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.190476</td>\n",
       "      <td>0.244924</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>2.619048</td>\n",
       "      <td>0.069797</td>\n",
       "      <td>3.523810</td>\n",
       "      <td>0.093909</td>\n",
       "      <td>2.380952</td>\n",
       "      <td>0.063452</td>\n",
       "      <td>26.266667</td>\n",
       "      <td>49.250000</td>\n",
       "      <td>0.991195</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.039340</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>0.143401</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.022843</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>3.966667</td>\n",
       "      <td>0.151015</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.125635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.433333</td>\n",
       "      <td>0.244924</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.069797</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>0.093909</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.063452</td>\n",
       "      <td>13.166667</td>\n",
       "      <td>43.888889</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.039241</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.018987</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.144304</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.018987</td>\n",
       "      <td>1.983333</td>\n",
       "      <td>0.150633</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>0.125316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>0.245570</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.069620</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>0.093671</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.795</td>\n",
       "      <td>34.565217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.038994</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.144654</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.022642</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.149686</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.124528</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.246541</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.069182</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.093082</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.062893</td>\n",
       "      <td>OZFCFMGC</td>\n",
       "      <td>FRGPM5396K</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.609313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOTPT1160A</td>\n",
       "      <td>20211225200656</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462342</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>5.997501</td>\n",
       "      <td>3.999000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.332556</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.571347</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>52450</td>\n",
       "      <td>0</td>\n",
       "      <td>52450</td>\n",
       "      <td>10038</td>\n",
       "      <td>9.995502</td>\n",
       "      <td>8.996002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.999000</td>\n",
       "      <td>19.981019</td>\n",
       "      <td>2.332889</td>\n",
       "      <td>215</td>\n",
       "      <td>32</td>\n",
       "      <td>78</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>6.997001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5033.0</td>\n",
       "      <td>5033.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1761.183125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49825.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>5087.500000</td>\n",
       "      <td>81440.0</td>\n",
       "      <td>11634.285714</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>10802.348431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27519.0</td>\n",
       "      <td>27519.0</td>\n",
       "      <td>27519.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47345.0</td>\n",
       "      <td>27519.0</td>\n",
       "      <td>3846.500000</td>\n",
       "      <td>27519.0</td>\n",
       "      <td>10579.132457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.199125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>607.428571</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>877.000000</td>\n",
       "      <td>836.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>465.666667</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>503.714286</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>101.50</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>582.000000</td>\n",
       "      <td>878.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>BIHEWFB9</td>\n",
       "      <td>BOTPT1160A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.199260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUGPR1229F</td>\n",
       "      <td>20211225201101</td>\n",
       "      <td>741.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462164</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>3.999000</td>\n",
       "      <td>29.971029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.999334</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.133324</td>\n",
       "      <td>146833</td>\n",
       "      <td>2</td>\n",
       "      <td>150306</td>\n",
       "      <td>98</td>\n",
       "      <td>3473</td>\n",
       "      <td>9795</td>\n",
       "      <td>7.997667</td>\n",
       "      <td>7.997667</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11.994503</td>\n",
       "      <td>37.963037</td>\n",
       "      <td>7.496752</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>22.978022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>2344.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>216888.0</td>\n",
       "      <td>14459.200000</td>\n",
       "      <td>174000.0</td>\n",
       "      <td>42649.025768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1736.5</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1736.5</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1736.500000</td>\n",
       "      <td>146833.0</td>\n",
       "      <td>36574.914332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.612</td>\n",
       "      <td>88.306</td>\n",
       "      <td>88.306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.612</td>\n",
       "      <td>88.306</td>\n",
       "      <td>88.306</td>\n",
       "      <td>88.306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.612</td>\n",
       "      <td>46.1224</td>\n",
       "      <td>88.306</td>\n",
       "      <td>18.00</td>\n",
       "      <td>34.442765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.718022</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>614.400000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>662.923077</td>\n",
       "      <td>687.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>618.428571</td>\n",
       "      <td>687.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>564.933333</td>\n",
       "      <td>756.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>601.400000</td>\n",
       "      <td>756.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>893</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>31</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>1565</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>495</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>421</td>\n",
       "      <td>48</td>\n",
       "      <td>95</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>3000</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>264</td>\n",
       "      <td>1</td>\n",
       "      <td>880</td>\n",
       "      <td>65</td>\n",
       "      <td>195</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>33.285714</td>\n",
       "      <td>33.285714</td>\n",
       "      <td>0.077667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.012876</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>0.188841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.077253</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>0.115880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.360515</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.085837</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.034335</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.034335</td>\n",
       "      <td>31.285714</td>\n",
       "      <td>31.285714</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>7.357143</td>\n",
       "      <td>0.235160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>0.141553</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>0.105023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.071429</td>\n",
       "      <td>0.321918</td>\n",
       "      <td>1.642857</td>\n",
       "      <td>0.052511</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>0.070776</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.020548</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>30.142857</td>\n",
       "      <td>30.142857</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.265403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>2.761905</td>\n",
       "      <td>0.091627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.238095</td>\n",
       "      <td>0.306477</td>\n",
       "      <td>1.238095</td>\n",
       "      <td>0.041074</td>\n",
       "      <td>1.952381</td>\n",
       "      <td>0.064771</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.026856</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>29.766667</td>\n",
       "      <td>29.766667</td>\n",
       "      <td>0.297667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.010078</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.268757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.022396</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.010078</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.083987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.933333</td>\n",
       "      <td>0.300112</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.061590</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.029115</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>26.083333</td>\n",
       "      <td>26.083333</td>\n",
       "      <td>0.521667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.011502</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>0.316294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.017891</td>\n",
       "      <td>3.716667</td>\n",
       "      <td>0.142492</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.092013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.016667</td>\n",
       "      <td>0.269010</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.030671</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>0.060703</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.024920</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.023642</td>\n",
       "      <td>3.000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>1.012</td>\n",
       "      <td>0.337333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.014667</td>\n",
       "      <td>MN6E2VSW</td>\n",
       "      <td>BUGPR1229F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDMPS5726L</td>\n",
       "      <td>20211225201949</td>\n",
       "      <td>828.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480803</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>8.992008</td>\n",
       "      <td>3.998501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>1.833194</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13509</td>\n",
       "      <td>4.665445</td>\n",
       "      <td>3.999000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.665445</td>\n",
       "      <td>16.984016</td>\n",
       "      <td>2.999000</td>\n",
       "      <td>125</td>\n",
       "      <td>14</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14400.0</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>748.331477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>852.666667</td>\n",
       "      <td>749.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>817.666667</td>\n",
       "      <td>686.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>834.333333</td>\n",
       "      <td>714.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>776.166667</td>\n",
       "      <td>786.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>837.333333</td>\n",
       "      <td>909.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>89</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>109</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>114</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>0.359649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>0.429825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>2.619048</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>0.482456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>3.869565</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>1.816667</td>\n",
       "      <td>3.205882</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.073394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.055046</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.091743</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.339450</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.114</td>\n",
       "      <td>3.081081</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.324561</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.359649</td>\n",
       "      <td>8KCEGVBW</td>\n",
       "      <td>IDMPS5726L</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1803 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID report_timestamp  BureauScore  BureauScoreConfidLevel  \\\n",
       "0  BPZPK3933F   20220210120018        558.0                     0.0   \n",
       "1  FRGPM5396K   20211225195910        719.0                     0.0   \n",
       "2  BOTPT1160A   20211225200656        781.0                     0.0   \n",
       "3  BUGPR1229F   20211225201101        741.0                     0.0   \n",
       "4  IDMPS5726L   20211225201949        828.0                     0.0   \n",
       "\n",
       "   MissingRate  Current_Enquiry_Reason  Current_Gender_Code  First_Name1  \\\n",
       "0     0.325254                       2                    2          0.0   \n",
       "1     0.353659                       2                    1          0.0   \n",
       "2     0.462342                       2                    1          0.0   \n",
       "3     0.462164                       2                    1          0.0   \n",
       "4     0.480803                       2                    1          0.0   \n",
       "\n",
       "   Len_Name  Tel_nuniq  Email_nuniq  IncomeTaxPAN_5  Len_of_addrs  City_nuniq  \\\n",
       "0        13  11.329890    11.994503             0.0            46    4.285245   \n",
       "1        42   1.499750     5.497751             0.0            46    1.000000   \n",
       "2        26   5.997501     3.999000             0.0            46    3.332556   \n",
       "3        14   3.999000    29.971029             0.0            46    2.999334   \n",
       "4        26   8.992008     3.998501             0.0            46    1.833194   \n",
       "\n",
       "   PinCode3  Current_State  Current_City  CreditAccountActive  \\\n",
       "0       422             27           0.0                   14   \n",
       "1       422             27           0.0                    3   \n",
       "2       422             27           0.0                    4   \n",
       "3       422             27           0.0                    2   \n",
       "4       422             27           0.0                    0   \n",
       "\n",
       "   CreditAccountTotal  CreditAccountActivePor  Outstanding_Balance_Secured  \\\n",
       "0                  22                0.636335                      5064366   \n",
       "1                   4                0.749813                            0   \n",
       "2                   7                0.571347                            0   \n",
       "3                  15                0.133324                       146833   \n",
       "4                   6                0.000000                            0   \n",
       "\n",
       "   Outstanding_Balance_UnSecured_Percentage  Outstanding_Balance_All  \\\n",
       "0                                         2                  5181373   \n",
       "1                                        60                    64753   \n",
       "2                                       100                    52450   \n",
       "3                                         2                   150306   \n",
       "4                                         0                        0   \n",
       "\n",
       "   Outstanding_Balance_Secured_Percentage  Outstanding_Balance_UnSecured  \\\n",
       "0                                      98                         117007   \n",
       "1                                       0                          38960   \n",
       "2                                       0                          52450   \n",
       "3                                      98                           3473   \n",
       "4                                       0                              0   \n",
       "\n",
       "   Diff_dateBirth  State_nuniq  Birth_nuniq  TotalCAPSLast90Days  \\\n",
       "0           13092    51.949051    22.489255                    4   \n",
       "1            9491     1.999667     1.999667                    1   \n",
       "2           10038     9.995502     8.996002                    1   \n",
       "3            9795     7.997667     7.997667                    5   \n",
       "4           13509     4.665445     3.999000                    5   \n",
       "\n",
       "   TotalCAPSLast7Days  TotalCAPSLast30Days  TotalCAPSLast180Days  \\\n",
       "0                   3                    3                     4   \n",
       "1                   0                    0                     1   \n",
       "2                   0                    0                     2   \n",
       "3                   2                    3                     5   \n",
       "4                   3                    5                     5   \n",
       "\n",
       "   CAPSLast30Days  CAPSLast7Days  CAPSLast180Days  NonCreditCAPSLast180Days  \\\n",
       "0               2              2                3                         1   \n",
       "1               0              0                1                         0   \n",
       "2               0              0                2                         0   \n",
       "3               1              0                3                         2   \n",
       "4               3              1                3                         2   \n",
       "\n",
       "   Pin_nuniq  Pan_nuniq  Ident_nuniq  Name_nuniq2  Tel_nuniq2  Email_nuniq2  \\\n",
       "0  13.246938  66.934066     5.498875          146          44            54   \n",
       "1   1.999667   8.992008     1.333222          129          28            39   \n",
       "2   4.999000  19.981019     2.332889          215          32            78   \n",
       "3  11.994503  37.963037     7.496752           27          42            27   \n",
       "4   4.665445  16.984016     2.999000          125          14            58   \n",
       "\n",
       "   Pan_nuniq2  Account_nuniq2  Ident_nuniq2  Gender_nuniq  \\\n",
       "0          14              14            60     44.956044   \n",
       "1          14              14            45      4.996004   \n",
       "2          14              14            45      6.997001   \n",
       "3          14              14            30     22.978022   \n",
       "4          14              14            30     10.990010   \n",
       "\n",
       "   Amount_Past_Due35_sum_30  Amount_Past_Due35_min_30  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Amount_Past_Due35_sum_90  Amount_Past_Due35_mean_90  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                       0.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   Amount_Past_Due35_max_90  Amount_Past_Due35_min_90  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Amount_Past_Due35_std_90  Amount_Past_Due35_sum_360  \\\n",
       "0                       0.0                     6920.0   \n",
       "1                       0.0                     1640.0   \n",
       "2                       0.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   Amount_Past_Due35_mean_360  Amount_Past_Due35_max_360  \\\n",
       "0                      1730.0                     6920.0   \n",
       "1                       820.0                     1640.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         0.0                        0.0   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   Amount_Past_Due35_std_360  Amount_Past_Due35_sum_9999  \\\n",
       "0                2996.447897                   3937140.0   \n",
       "1                 820.000000                      1640.0   \n",
       "2                   0.000000                      5033.0   \n",
       "3                   0.000000                         0.0   \n",
       "4                   0.000000                         0.0   \n",
       "\n",
       "   Amount_Past_Due35_max_9999  Amount_Past_Due35_min_9999  \\\n",
       "0                   2057589.0                         0.0   \n",
       "1                      1640.0                         0.0   \n",
       "2                      5033.0                         0.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "   Amount_Past_Due35_std_9999  \\\n",
       "0               547470.733164   \n",
       "1                  710.140831   \n",
       "2                 1761.183125   \n",
       "3                    0.000000   \n",
       "4                    0.000000   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_max_30  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_min_30  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_std_30  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_sum_90  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                          30000.0   \n",
       "3                                           4688.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_mean_90  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                           30000.0   \n",
       "3                                            2344.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_max_90  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                          30000.0   \n",
       "3                                           3473.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_min_90  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                          30000.0   \n",
       "3                                           1215.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                           1129.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_sum_360  \\\n",
       "0                                          114378.0   \n",
       "1                                           27793.0   \n",
       "2                                           49825.0   \n",
       "3                                            4688.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_max_360  \\\n",
       "0                                           75400.0   \n",
       "1                                           25793.0   \n",
       "2                                           30000.0   \n",
       "3                                            3473.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_std_360  \\\n",
       "0                                      28277.352966   \n",
       "1                                      11896.500000   \n",
       "2                                       5087.500000   \n",
       "3                                       1129.000000   \n",
       "4                                          0.000000   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                          6254569.0   \n",
       "1                                            89990.0   \n",
       "2                                            81440.0   \n",
       "3                                           216888.0   \n",
       "4                                            14400.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_mean_9999  \\\n",
       "0                                      284298.590909    \n",
       "1                                       22497.500000    \n",
       "2                                       11634.285714    \n",
       "3                                       14459.200000    \n",
       "4                                        2400.000000    \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                          1890000.0   \n",
       "1                                            52822.0   \n",
       "2                                            30000.0   \n",
       "3                                           174000.0   \n",
       "4                                             4000.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_std_9999  Terms_Duration34_sum_30  \\\n",
       "0                                      509837.280159                      0.0   \n",
       "1                                       19511.426992                      0.0   \n",
       "2                                       10802.348431                      0.0   \n",
       "3                                       42649.025768                      0.0   \n",
       "4                                         748.331477                      0.0   \n",
       "\n",
       "   Terms_Duration34_std_30  Terms_Duration34_sum_90  Terms_Duration34_std_90  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                     12.0                      0.0   \n",
       "3                      0.0                      4.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   Terms_Duration34_mean_360  Terms_Duration34_max_360  \\\n",
       "0                   7.333333                      12.0   \n",
       "1                   0.000000                       0.0   \n",
       "2                  12.000000                      12.0   \n",
       "3                   2.000000                       2.0   \n",
       "4                   0.000000                       0.0   \n",
       "\n",
       "   Terms_Duration34_min_360  Terms_Duration34_std_360  \\\n",
       "0                       2.0                  4.109609   \n",
       "1                       0.0                  0.000000   \n",
       "2                      12.0                  0.000000   \n",
       "3                       2.0                  0.000000   \n",
       "4                       0.0                  0.000000   \n",
       "\n",
       "   Terms_Duration34_sum_9999  Terms_Duration34_mean_9999  \\\n",
       "0                      501.0                   55.666667   \n",
       "1                       42.0                   21.000000   \n",
       "2                       12.0                   12.000000   \n",
       "3                        7.0                    1.400000   \n",
       "4                        0.0                    0.000000   \n",
       "\n",
       "   Terms_Duration34_max_9999  Terms_Duration34_min_9999  \\\n",
       "0                      240.0                        2.0   \n",
       "1                       36.0                        6.0   \n",
       "2                       12.0                       12.0   \n",
       "3                        2.0                        1.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Terms_Duration34_std_9999  Payment_Rating34_sum_90  \\\n",
       "0                  72.033943                      0.0   \n",
       "1                  15.000000                      0.0   \n",
       "2                   0.000000                      0.0   \n",
       "3                   0.489898                      0.0   \n",
       "4                   0.000000                      0.0   \n",
       "\n",
       "   Payment_Rating34_mean_90  Payment_Rating34_max_90  Payment_Rating34_min_90  \\\n",
       "0                       0.0                      0.0                      0.0   \n",
       "1                       0.0                      0.0                      0.0   \n",
       "2                       0.0                      0.0                      0.0   \n",
       "3                       0.0                      0.0                      0.0   \n",
       "4                       0.0                      0.0                      0.0   \n",
       "\n",
       "   Payment_Rating34_std_90  Payment_Rating34_sum_360  \\\n",
       "0                      0.0                       1.0   \n",
       "1                      0.0                       0.0   \n",
       "2                      0.0                       0.0   \n",
       "3                      0.0                       0.0   \n",
       "4                      0.0                       0.0   \n",
       "\n",
       "   Payment_Rating34_mean_360  Payment_Rating34_max_360  \\\n",
       "0                       0.25                       1.0   \n",
       "1                       0.00                       0.0   \n",
       "2                       0.00                       0.0   \n",
       "3                       0.00                       0.0   \n",
       "4                       0.00                       0.0   \n",
       "\n",
       "   Payment_Rating34_min_360  Payment_Rating34_std_360  \\\n",
       "0                       0.0                  0.433013   \n",
       "1                       0.0                  0.000000   \n",
       "2                       0.0                  0.000000   \n",
       "3                       0.0                  0.000000   \n",
       "4                       0.0                  0.000000   \n",
       "\n",
       "   Payment_Rating34_sum_9999  Payment_Rating34_mean_9999  \\\n",
       "0                       27.0                    1.227273   \n",
       "1                        0.0                    0.000000   \n",
       "2                        0.0                    0.000000   \n",
       "3                        0.0                    0.000000   \n",
       "4                        0.0                    0.000000   \n",
       "\n",
       "   Payment_Rating34_max_9999  Payment_Rating34_min_9999  \\\n",
       "0                        6.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Payment_Rating34_std_9999  Current_Balance35_mean_30  \\\n",
       "0                   2.294892                        0.0   \n",
       "1                   0.000000                        0.0   \n",
       "2                   0.000000                        0.0   \n",
       "3                   0.000000                        0.0   \n",
       "4                   0.000000                        0.0   \n",
       "\n",
       "   Current_Balance35_min_30  Current_Balance35_std_30  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Current_Balance35_sum_90  Current_Balance35_mean_90  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                   27519.0                    27519.0   \n",
       "3                    3473.0                     1736.5   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   Current_Balance35_max_90  Current_Balance35_std_90  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                   27519.0                       0.0   \n",
       "3                    3473.0                    1736.5   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Current_Balance35_sum_360  Current_Balance35_max_360  \\\n",
       "0                    97130.0                    75400.0   \n",
       "1                    25793.0                    25793.0   \n",
       "2                    47345.0                    27519.0   \n",
       "3                     3473.0                     3473.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Current_Balance35_std_360  Current_Balance35_max_9999  \\\n",
       "0               30111.798663                   2057589.0   \n",
       "1               12896.500000                     38960.0   \n",
       "2                3846.500000                     27519.0   \n",
       "3                1736.500000                    146833.0   \n",
       "4                   0.000000                         0.0   \n",
       "\n",
       "   Current_Balance35_std_9999  Settlement_Amount37_max_360  \\\n",
       "0               539918.618880                          0.0   \n",
       "1                16844.306878                          0.0   \n",
       "2                10579.132457                          0.0   \n",
       "3                36574.914332                          0.0   \n",
       "4                    0.000000                          0.0   \n",
       "\n",
       "   Settlement_Amount37_min_360  Settlement_Amount37_std_360  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   Settlement_Amount37_sum_9999  Settlement_Amount37_mean_9999  \\\n",
       "0                           0.0                            0.0   \n",
       "1                           0.0                            0.0   \n",
       "2                           0.0                            0.0   \n",
       "3                           0.0                            0.0   \n",
       "4                           0.0                            0.0   \n",
       "\n",
       "   Settlement_Amount37_max_9999  Settlement_Amount37_min_9999  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   Settlement_Amount37_std_9999  Value_of_Collateral39_std_90  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   Value_of_Collateral39_std_360  Written_Off_Amt_Total41_sum_360  \\\n",
       "0                            0.0                              0.0   \n",
       "1                            0.0                              0.0   \n",
       "2                            0.0                              0.0   \n",
       "3                            0.0                              0.0   \n",
       "4                            0.0                              0.0   \n",
       "\n",
       "   Written_Off_Amt_Total41_mean_360  Written_Off_Amt_Total41_min_360  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "\n",
       "   Written_Off_Amt_Total41_std_360  Written_Off_Amt_Total41_sum_9999  \\\n",
       "0                              0.0                               0.0   \n",
       "1                              0.0                               0.0   \n",
       "2                              0.0                               0.0   \n",
       "3                              0.0                               0.0   \n",
       "4                              0.0                               0.0   \n",
       "\n",
       "   Written_Off_Amt_Total41_mean_9999  Written_Off_Amt_Total41_max_9999  \\\n",
       "0                                0.0                               0.0   \n",
       "1                                0.0                               0.0   \n",
       "2                                0.0                               0.0   \n",
       "3                                0.0                               0.0   \n",
       "4                                0.0                               0.0   \n",
       "\n",
       "   Written_Off_Amt_Total41_min_9999  Written_Off_Amt_Total41_std_9999  \\\n",
       "0                               0.0                               0.0   \n",
       "1                               0.0                               0.0   \n",
       "2                               0.0                               0.0   \n",
       "3                               0.0                               0.0   \n",
       "4                               0.0                               0.0   \n",
       "\n",
       "   Written_Off_Amt_Principal45_sum_360  Written_Off_Amt_Principal45_mean_360  \\\n",
       "0                                  0.0                                   0.0   \n",
       "1                                  0.0                                   0.0   \n",
       "2                                  0.0                                   0.0   \n",
       "3                                  0.0                                   0.0   \n",
       "4                                  0.0                                   0.0   \n",
       "\n",
       "   Written_Off_Amt_Principal45_min_360  Written_Off_Amt_Principal45_std_360  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  0.0   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  0.0   \n",
       "4                                  0.0                                  0.0   \n",
       "\n",
       "   Written_Off_Amt_Principal45_max_9999  Written_Off_Amt_Principal45_min_9999  \\\n",
       "0                               19637.0                                   0.0   \n",
       "1                                   0.0                                   0.0   \n",
       "2                                   0.0                                   0.0   \n",
       "3                                   0.0                                   0.0   \n",
       "4                                   0.0                                   0.0   \n",
       "\n",
       "   Rate_of_Interest36_sum_30  Rate_of_Interest36_std_30  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Rate_of_Interest36_sum_90  Rate_of_Interest36_mean_90  \\\n",
       "0                      0.000                       0.000   \n",
       "1                      0.000                       0.000   \n",
       "2                     28.000                      28.000   \n",
       "3                    176.612                      88.306   \n",
       "4                      0.000                       0.000   \n",
       "\n",
       "   Rate_of_Interest36_max_90  Rate_of_Interest36_std_90  \\\n",
       "0                      0.000                        0.0   \n",
       "1                      0.000                        0.0   \n",
       "2                     28.000                        0.0   \n",
       "3                     88.306                        0.0   \n",
       "4                      0.000                        0.0   \n",
       "\n",
       "   Rate_of_Interest36_sum_360  Rate_of_Interest36_mean_360  \\\n",
       "0                      18.000                       18.000   \n",
       "1                       0.000                        0.000   \n",
       "2                      28.000                       28.000   \n",
       "3                     176.612                       88.306   \n",
       "4                       0.000                        0.000   \n",
       "\n",
       "   Rate_of_Interest36_max_360  Rate_of_Interest36_min_360  \\\n",
       "0                      18.000                      18.000   \n",
       "1                       0.000                       0.000   \n",
       "2                      28.000                      28.000   \n",
       "3                      88.306                      88.306   \n",
       "4                       0.000                       0.000   \n",
       "\n",
       "   Rate_of_Interest36_std_360  Rate_of_Interest36_sum_9999  \\\n",
       "0                         0.0                       90.930   \n",
       "1                         0.0                        0.000   \n",
       "2                         0.0                       28.000   \n",
       "3                         0.0                      230.612   \n",
       "4                         0.0                        0.000   \n",
       "\n",
       "   Rate_of_Interest36_mean_9999  Rate_of_Interest36_max_9999  \\\n",
       "0                       18.1860                       47.880   \n",
       "1                        0.0000                        0.000   \n",
       "2                       28.0000                       28.000   \n",
       "3                       46.1224                       88.306   \n",
       "4                        0.0000                        0.000   \n",
       "\n",
       "   Rate_of_Interest36_min_9999  Rate_of_Interest36_std_9999  \\\n",
       "0                         7.55                    15.316455   \n",
       "1                         0.00                     0.000000   \n",
       "2                        28.00                     0.000000   \n",
       "3                        18.00                    34.442765   \n",
       "4                         0.00                     0.000000   \n",
       "\n",
       "   Repayment_Tenure36_std_30  Repayment_Tenure36_mean_90  \\\n",
       "0                        0.0                         0.0   \n",
       "1                        0.0                         0.0   \n",
       "2                        0.0                        12.0   \n",
       "3                        0.0                         2.0   \n",
       "4                        0.0                         0.0   \n",
       "\n",
       "   Repayment_Tenure36_max_90  Repayment_Tenure36_min_90  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                       12.0                       12.0   \n",
       "3                        2.0                        2.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Repayment_Tenure36_std_90  Repayment_Tenure36_sum_360  \\\n",
       "0                        0.0                        22.0   \n",
       "1                        0.0                         0.0   \n",
       "2                        0.0                        12.0   \n",
       "3                        0.0                         4.0   \n",
       "4                        0.0                         0.0   \n",
       "\n",
       "   Repayment_Tenure36_mean_360  Repayment_Tenure36_min_360  \\\n",
       "0                          5.5                         0.0   \n",
       "1                          0.0                         0.0   \n",
       "2                          6.0                         0.0   \n",
       "3                          2.0                         2.0   \n",
       "4                          0.0                         0.0   \n",
       "\n",
       "   Repayment_Tenure36_std_360  Repayment_Tenure36_mean_9999  \\\n",
       "0                    4.769696                     22.772727   \n",
       "1                    0.000000                     10.500000   \n",
       "2                    6.000000                      1.714286   \n",
       "3                    0.000000                      0.466667   \n",
       "4                    0.000000                      0.000000   \n",
       "\n",
       "   Repayment_Tenure36_min_9999  Repayment_Tenure36_std_9999  \\\n",
       "0                          0.0                    53.589290   \n",
       "1                          0.0                    14.924812   \n",
       "2                          0.0                     4.199125   \n",
       "3                          0.0                     0.718022   \n",
       "4                          0.0                     0.000000   \n",
       "\n",
       "   Income26_count_360  Income26_std_360  Open_Date29_max_30  \\\n",
       "0                 4.0               0.0                 0.0   \n",
       "1                 2.0               0.0                 0.0   \n",
       "2                 2.0               0.0                 0.0   \n",
       "3                 2.0               0.0                 0.0   \n",
       "4                 0.0               0.0                 0.0   \n",
       "\n",
       "   Open_Date29_min_30  Open_Date29_mean_30  Open_Date29_nuniq_30  \\\n",
       "0                 0.0                  0.0                   0.0   \n",
       "1                 0.0                  0.0                   0.0   \n",
       "2                 0.0                  0.0                   0.0   \n",
       "3                 0.0                  0.0                   0.0   \n",
       "4                 0.0                  0.0                   0.0   \n",
       "\n",
       "   Open_Date29_maxcount_30  Open_Date29_max_90  Open_Date29_mean_90  \\\n",
       "0                      0.0                 0.0                  0.0   \n",
       "1                      0.0                 0.0                  0.0   \n",
       "2                      0.0                42.0                 42.0   \n",
       "3                      0.0                68.0                 53.0   \n",
       "4                      0.0                 0.0                  0.0   \n",
       "\n",
       "   Open_Date29_mode_90  Open_Date29_nuniq_90  Open_Date29_maxcount_90  \\\n",
       "0                  0.0                   0.0                      0.0   \n",
       "1                  0.0                   0.0                      0.0   \n",
       "2                 42.0                   1.0                      1.0   \n",
       "3                 38.0                   2.0                      1.0   \n",
       "4                  0.0                   0.0                      0.0   \n",
       "\n",
       "   Open_Date29_max_360  Open_Date29_mean_360  Open_Date29_mode_360  \\\n",
       "0                180.0                 153.5                 113.0   \n",
       "1                308.0                 282.5                 257.0   \n",
       "2                224.0                 133.0                  42.0   \n",
       "3                 68.0                  53.0                  38.0   \n",
       "4                  0.0                   0.0                   0.0   \n",
       "\n",
       "   Open_Date29_nuniq_360  Open_Date29_maxcount_360  Open_Date29_max_9999  \\\n",
       "0                    4.0                       1.0                2884.0   \n",
       "1                    2.0                       1.0                 813.0   \n",
       "2                    2.0                       1.0                 906.0   \n",
       "3                    2.0                       1.0                 772.0   \n",
       "4                    0.0                       0.0                 932.0   \n",
       "\n",
       "   Open_Date29_mean_9999  Open_Date29_mode_9999  Open_Date29_maxcount_9999  \\\n",
       "0            1061.772727                 1182.0                        2.0   \n",
       "1             466.500000                  257.0                        1.0   \n",
       "2             607.428571                   42.0                        1.0   \n",
       "3             614.400000                   38.0                        1.0   \n",
       "4             852.666667                  749.0                        1.0   \n",
       "\n",
       "   Portfolio_Type34_mode_30  Portfolio_Type34_nuniq_30  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                       0.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   Portfolio_Type34_nuniq_90  Portfolio_Type34_mode_360  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        1.0                        0.0   \n",
       "3                        1.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Portfolio_Type34_nuniq_360  Portfolio_Type34_mode_9999  \\\n",
       "0                         1.0                         0.0   \n",
       "1                         2.0                         0.0   \n",
       "2                         2.0                         0.0   \n",
       "3                         1.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "   Portfolio_Type34_nuniq_9999  Account_Type32_nuniq_30  \\\n",
       "0                          3.0                      0.0   \n",
       "1                          2.0                      0.0   \n",
       "2                          2.0                      0.0   \n",
       "3                          1.0                      0.0   \n",
       "4                          1.0                      0.0   \n",
       "\n",
       "   Account_Type32_mode_90  Account_Type32_nuniq_90  Account_Type32_mode_360  \\\n",
       "0                     0.0                      0.0                      5.0   \n",
       "1                     0.0                      0.0                      6.0   \n",
       "2                     5.0                      1.0                      5.0   \n",
       "3                     5.0                      1.0                      5.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   Account_Type32_nuniq_360  Account_Type32_mode_9999  \\\n",
       "0                       3.0                       7.0   \n",
       "1                       2.0                       6.0   \n",
       "2                       2.0                       5.0   \n",
       "3                       1.0                       5.0   \n",
       "4                       0.0                       5.0   \n",
       "\n",
       "   Account_Type32_nuniq_9999  Occupation_Code35_nuniq_30  \\\n",
       "0                        9.0                         0.0   \n",
       "1                        3.0                         0.0   \n",
       "2                        3.0                         0.0   \n",
       "3                        2.0                         0.0   \n",
       "4                        1.0                         0.0   \n",
       "\n",
       "   Occupation_Code35_nuniq_90  Occupation_Code35_nuniq_360  \\\n",
       "0                         0.0                          1.0   \n",
       "1                         0.0                          1.0   \n",
       "2                         1.0                          2.0   \n",
       "3                         1.0                          1.0   \n",
       "4                         0.0                          0.0   \n",
       "\n",
       "   Occupation_Code35_nuniq_9999  CurrencyCode32_mode_360  \\\n",
       "0                           1.0                      0.0   \n",
       "1                           1.0                      0.0   \n",
       "2                           3.0                      0.0   \n",
       "3                           2.0                      0.0   \n",
       "4                           1.0                      0.0   \n",
       "\n",
       "   CurrencyCode32_mode_9999  AccountHoldertypeCode41_mode_90  \\\n",
       "0                       0.0                              0.0   \n",
       "1                       0.0                              0.0   \n",
       "2                       0.0                              1.0   \n",
       "3                       0.0                              1.0   \n",
       "4                       0.0                              0.0   \n",
       "\n",
       "   AccountHoldertypeCode41_nuniq_90  AccountHoldertypeCode41_nuniq_360  \\\n",
       "0                               0.0                                1.0   \n",
       "1                               0.0                                1.0   \n",
       "2                               1.0                                1.0   \n",
       "3                               1.0                                1.0   \n",
       "4                               0.0                                0.0   \n",
       "\n",
       "   AccountHoldertypeCode41_mode_9999  AccountHoldertypeCode41_nuniq_9999  \\\n",
       "0                                1.0                                 2.0   \n",
       "1                                1.0                                 1.0   \n",
       "2                                1.0                                 1.0   \n",
       "3                                1.0                                 2.0   \n",
       "4                                1.0                                 1.0   \n",
       "\n",
       "   Payment_History_Profile43_mode_30  Payment_History_Profile43_mode_90  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  0   \n",
       "2                                  0                                  1   \n",
       "3                                  0                                 36   \n",
       "4                                  0                                  0   \n",
       "\n",
       "   Payment_History_Profile43_nuniq_90  Payment_History_Profile43_mode_360  \\\n",
       "0                                 0.0                                  36   \n",
       "1                                 0.0                                  36   \n",
       "2                                 1.0                                  36   \n",
       "3                                 2.0                                  36   \n",
       "4                                 0.0                                   0   \n",
       "\n",
       "   Payment_History_Profile43_nuniq_360  Payment_History_Profile43_mode_9999  \\\n",
       "0                                  2.0                                   36   \n",
       "1                                  2.0                                   36   \n",
       "2                                  2.0                                    1   \n",
       "3                                  2.0                                    1   \n",
       "4                                  0.0                                   36   \n",
       "\n",
       "   Payment_History_Profile43_nuniq_9999  Date_Closed31_nuniq_30  \\\n",
       "0                                  17.0                     0.0   \n",
       "1                                   4.0                     0.0   \n",
       "2                                   4.0                     0.0   \n",
       "3                                   5.0                     0.0   \n",
       "4                                   4.0                     0.0   \n",
       "\n",
       "   Date_Closed31_maxcount_30  Date_Closed31_max_90  Date_Closed31_min_90  \\\n",
       "0                        0.0                   0.0                   0.0   \n",
       "1                        0.0                   0.0                   0.0   \n",
       "2                        0.0                   0.0                   0.0   \n",
       "3                        0.0                  38.0                  38.0   \n",
       "4                        0.0                   0.0                   0.0   \n",
       "\n",
       "   Date_Closed31_mean_90  Date_Closed31_mode_90  Date_Closed31_nuniq_90  \\\n",
       "0                    0.0                    0.0                     0.0   \n",
       "1                    0.0                    0.0                     0.0   \n",
       "2                    0.0                    0.0                     1.0   \n",
       "3                   38.0                   38.0                     2.0   \n",
       "4                    0.0                    0.0                     0.0   \n",
       "\n",
       "   Date_Closed31_maxcount_90  Date_Closed31_min_360  Date_Closed31_mode_360  \\\n",
       "0                        0.0                    0.0                     0.0   \n",
       "1                        0.0                    0.0                     0.0   \n",
       "2                        0.0                    0.0                     0.0   \n",
       "3                        1.0                   38.0                    38.0   \n",
       "4                        0.0                    0.0                     0.0   \n",
       "\n",
       "   Date_Closed31_nuniq_360  Date_Closed31_maxcount_360  \\\n",
       "0                      1.0                         0.0   \n",
       "1                      1.0                         0.0   \n",
       "2                      1.0                         0.0   \n",
       "3                      2.0                         1.0   \n",
       "4                      0.0                         0.0   \n",
       "\n",
       "   Date_Closed31_max_9999  Date_Closed31_min_9999  Date_Closed31_mean_9999  \\\n",
       "0                  1742.0                    87.0               720.625000   \n",
       "1                   624.0                   624.0               624.000000   \n",
       "2                   903.0                   836.0               877.000000   \n",
       "3                   764.0                    38.0               662.923077   \n",
       "4                   915.0                   686.0               817.666667   \n",
       "\n",
       "   Date_Closed31_mode_9999  Date_Closed31_nuniq_9999  \\\n",
       "0                     87.0                       9.0   \n",
       "1                    624.0                       2.0   \n",
       "2                    836.0                       4.0   \n",
       "3                    687.0                      13.0   \n",
       "4                    686.0                       6.0   \n",
       "\n",
       "   Date_of_Last_Payment40_nuniq_30  Date_of_Last_Payment40_maxcount_30  \\\n",
       "0                              0.0                                 0.0   \n",
       "1                              0.0                                 0.0   \n",
       "2                              0.0                                 0.0   \n",
       "3                              0.0                                 0.0   \n",
       "4                              0.0                                 0.0   \n",
       "\n",
       "   Date_of_Last_Payment40_min_90  Date_of_Last_Payment40_nuniq_90  \\\n",
       "0                            0.0                              0.0   \n",
       "1                            0.0                              0.0   \n",
       "2                           24.0                              1.0   \n",
       "3                           38.0                              2.0   \n",
       "4                            0.0                              0.0   \n",
       "\n",
       "   Date_of_Last_Payment40_maxcount_90  Date_of_Last_Payment40_max_360  \\\n",
       "0                                 0.0                           150.0   \n",
       "1                                 0.0                            42.0   \n",
       "2                                 1.0                            65.0   \n",
       "3                                 1.0                            38.0   \n",
       "4                                 0.0                             0.0   \n",
       "\n",
       "   Date_of_Last_Payment40_min_360  Date_of_Last_Payment40_mean_360  \\\n",
       "0                            70.0                             97.0   \n",
       "1                            42.0                             42.0   \n",
       "2                            24.0                             44.5   \n",
       "3                            38.0                             38.0   \n",
       "4                             0.0                              0.0   \n",
       "\n",
       "   Date_of_Last_Payment40_mode_360  Date_of_Last_Payment40_nuniq_360  \\\n",
       "0                             70.0                               4.0   \n",
       "1                             42.0                               2.0   \n",
       "2                             24.0                               2.0   \n",
       "3                             38.0                               2.0   \n",
       "4                              0.0                               0.0   \n",
       "\n",
       "   Date_of_Last_Payment40_maxcount_360  Date_of_Last_Payment40_max_9999  \\\n",
       "0                                  1.0                           1742.0   \n",
       "1                                  1.0                            632.0   \n",
       "2                                  1.0                            903.0   \n",
       "3                                  1.0                            764.0   \n",
       "4                                  0.0                            932.0   \n",
       "\n",
       "   Date_of_Last_Payment40_min_9999  Date_of_Last_Payment40_mean_9999  \\\n",
       "0                             54.0                        436.000000   \n",
       "1                             42.0                        248.000000   \n",
       "2                             24.0                        465.666667   \n",
       "3                             38.0                        618.428571   \n",
       "4                            714.0                        834.333333   \n",
       "\n",
       "   Date_of_Last_Payment40_mode_9999  Date_of_Last_Payment40_maxcount_9999  \\\n",
       "0                             401.0                                   2.0   \n",
       "1                              42.0                                   1.0   \n",
       "2                              24.0                                   1.0   \n",
       "3                             687.0                                   2.0   \n",
       "4                             714.0                                   1.0   \n",
       "\n",
       "   Date_Reported33_nuniq_30  Date_Reported33_max_90  Date_Reported33_mean_90  \\\n",
       "0                       0.0                     0.0                      0.0   \n",
       "1                       0.0                     0.0                      0.0   \n",
       "2                       0.0                    25.0                     25.0   \n",
       "3                       0.0                    25.0                     25.0   \n",
       "4                       0.0                     0.0                      0.0   \n",
       "\n",
       "   Date_Reported33_mode_90  Date_Reported33_nuniq_90  \\\n",
       "0                      0.0                       0.0   \n",
       "1                      0.0                       0.0   \n",
       "2                     25.0                       1.0   \n",
       "3                     25.0                       1.0   \n",
       "4                      0.0                       0.0   \n",
       "\n",
       "   Date_Reported33_maxcount_90  Date_Reported33_max_360  \\\n",
       "0                          0.0                     41.0   \n",
       "1                          0.0                     55.0   \n",
       "2                          1.0                     25.0   \n",
       "3                          2.0                     25.0   \n",
       "4                          0.0                      0.0   \n",
       "\n",
       "   Date_Reported33_mean_360  Date_Reported33_mode_360  \\\n",
       "0                     33.25                      41.0   \n",
       "1                     40.00                      25.0   \n",
       "2                     25.00                      25.0   \n",
       "3                     25.00                      25.0   \n",
       "4                      0.00                       0.0   \n",
       "\n",
       "   Date_Reported33_nuniq_360  Date_Reported33_maxcount_360  \\\n",
       "0                        2.0                           3.0   \n",
       "1                        2.0                           1.0   \n",
       "2                        1.0                           2.0   \n",
       "3                        1.0                           2.0   \n",
       "4                        0.0                           0.0   \n",
       "\n",
       "   Date_Reported33_max_9999  Date_Reported33_mean_9999  \\\n",
       "0                    1716.0                 304.000000   \n",
       "1                     604.0                 184.750000   \n",
       "2                     878.0                 503.714286   \n",
       "3                     756.0                 564.933333   \n",
       "4                     878.0                 776.166667   \n",
       "\n",
       "   Date_Reported33_mode_9999  Date_Reported33_nuniq_9999  \\\n",
       "0                       41.0                        12.0   \n",
       "1                       55.0                         3.0   \n",
       "2                       25.0                         3.0   \n",
       "3                      756.0                         7.0   \n",
       "4                      786.0                         5.0   \n",
       "\n",
       "   Date_Reported33_maxcount_9999  DateOfAddition34_nuniq_30  \\\n",
       "0                           10.0                        0.0   \n",
       "1                            2.0                        0.0   \n",
       "2                            3.0                        0.0   \n",
       "3                            4.0                        0.0   \n",
       "4                            2.0                        0.0   \n",
       "\n",
       "   DateOfAddition34_max_90  DateOfAddition34_mean_90  \\\n",
       "0                      0.0                       0.0   \n",
       "1                      0.0                       0.0   \n",
       "2                     25.0                      25.0   \n",
       "3                     55.0                      40.0   \n",
       "4                      0.0                       0.0   \n",
       "\n",
       "   DateOfAddition34_mode_90  DateOfAddition34_nuniq_90  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                      25.0                        1.0   \n",
       "3                      25.0                        2.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   DateOfAddition34_maxcount_90  DateOfAddition34_max_360  \\\n",
       "0                           0.0                     163.0   \n",
       "1                           0.0                     300.0   \n",
       "2                           1.0                     178.0   \n",
       "3                           1.0                      55.0   \n",
       "4                           0.0                       0.0   \n",
       "\n",
       "   DateOfAddition34_mean_360  DateOfAddition34_mode_360  \\\n",
       "0                     140.25                      163.0   \n",
       "1                     269.50                      239.0   \n",
       "2                     101.50                       25.0   \n",
       "3                      40.00                       25.0   \n",
       "4                       0.00                        0.0   \n",
       "\n",
       "   DateOfAddition34_nuniq_360  DateOfAddition34_maxcount_360  \\\n",
       "0                         3.0                            2.0   \n",
       "1                         2.0                            1.0   \n",
       "2                         2.0                            1.0   \n",
       "3                         2.0                            1.0   \n",
       "4                         0.0                            0.0   \n",
       "\n",
       "   DateOfAddition34_max_9999  DateOfAddition34_mean_9999  \\\n",
       "0                     2478.0                  974.136364   \n",
       "1                      786.0                  451.500000   \n",
       "2                      878.0                  582.000000   \n",
       "3                      756.0                  601.400000   \n",
       "4                      909.0                  837.333333   \n",
       "\n",
       "   DateOfAddition34_mode_9999  DateOfAddition34_nuniq_9999  \\\n",
       "0                       163.0                         18.0   \n",
       "1                       239.0                          4.0   \n",
       "2                       878.0                          4.0   \n",
       "3                       756.0                          7.0   \n",
       "4                       909.0                          5.0   \n",
       "\n",
       "   DateOfAddition34_maxcount_9999  Account_Status34_mode_30  \\\n",
       "0                             2.0                       0.0   \n",
       "1                             1.0                       0.0   \n",
       "2                             4.0                       0.0   \n",
       "3                             6.0                       0.0   \n",
       "4                             2.0                       0.0   \n",
       "\n",
       "   Account_Status34_nuniq_30  Account_Status34_mode_90  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                      11.0   \n",
       "3                        0.0                      11.0   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   Account_Status34_nuniq_90  Account_Status34_mode_360  \\\n",
       "0                        0.0                       11.0   \n",
       "1                        0.0                       11.0   \n",
       "2                        1.0                       11.0   \n",
       "3                        2.0                       11.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Account_Status34_nuniq_360  Account_Status34_mode_9999  \\\n",
       "0                         2.0                        13.0   \n",
       "1                         1.0                        11.0   \n",
       "2                         1.0                        11.0   \n",
       "3                         2.0                        13.0   \n",
       "4                         0.0                        13.0   \n",
       "\n",
       "   Account_Status34_nuniq_9999  Month50_sum_30  Month50_max_30  \\\n",
       "0                          7.0             0.0             0.0   \n",
       "1                          2.0             0.0             0.0   \n",
       "2                          2.0             0.0             0.0   \n",
       "3                          3.0             0.0             0.0   \n",
       "4                          1.0             0.0             0.0   \n",
       "\n",
       "   Month50_std_30  Month50_sum_90  Month50_mean_90  ...  feature_1036_sms  \\\n",
       "0             0.0             0.0              0.0  ...               137   \n",
       "1             0.0             0.0              0.0  ...               113   \n",
       "2             0.0            11.0             11.0  ...                 0   \n",
       "3             0.0            22.0             11.0  ...               168   \n",
       "4             0.0             0.0              0.0  ...                 1   \n",
       "\n",
       "   feature_1037_sms  feature_1038_sms  feature_1039_sms  feature_1040_sms  \\\n",
       "0                 1                 3                19                 0   \n",
       "1                18                15               119                 2   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 4                93                 1   \n",
       "4                 1                 1                 0                 0   \n",
       "\n",
       "   feature_1041_sms  feature_1042_sms  feature_1043_sms  feature_1044_sms  \\\n",
       "0                 0                26                 0               153   \n",
       "1                 1                99                 0               193   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 5                58                 0               194   \n",
       "4                 1                 7                 0                 6   \n",
       "\n",
       "   feature_1045_sms  feature_1046_sms  feature_1047_sms  feature_1048_sms  \\\n",
       "0                13                71                46                34   \n",
       "1                 3                55                74                50   \n",
       "2                 0                 0                 0                 1   \n",
       "3                26                41                17                18   \n",
       "4                 0                 3                20                13   \n",
       "\n",
       "   feature_1049_sms  feature_1050_sms  feature_1051_sms  feature_1052_sms  \\\n",
       "0               737                21                21                 4   \n",
       "1               788                16                31                15   \n",
       "2                 1                 1                 0                 0   \n",
       "3               893                30                 3                 9   \n",
       "4                89                23                 0                 2   \n",
       "\n",
       "   feature_1053_sms  feature_1054_sms  feature_1055_sms  feature_1056_sms  \\\n",
       "0               194                 1                 5                38   \n",
       "1               113                18                15               119   \n",
       "2                 0                 0                 0                 0   \n",
       "3               240                 0                20               133   \n",
       "4                 1                 1                 1                 0   \n",
       "\n",
       "   feature_1057_sms  feature_1058_sms  feature_1059_sms  feature_1060_sms  \\\n",
       "0                 0                 0                40                 0   \n",
       "1                 2                 1                99                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 1                 9                75                 0   \n",
       "4                 0                 2                 8                 0   \n",
       "\n",
       "   feature_1061_sms  feature_1062_sms  feature_1063_sms  feature_1064_sms  \\\n",
       "0               209                15               101                61   \n",
       "1               193                 3                55                74   \n",
       "2                 0                 0                 0                 0   \n",
       "3               268                31                55                26   \n",
       "4                 6                 0                 6                31   \n",
       "\n",
       "   feature_1065_sms  feature_1066_sms  feature_1067_sms  feature_1068_sms  \\\n",
       "0                48              1876                51                59   \n",
       "1                50               790                18                31   \n",
       "2                 1                 1                 1                 0   \n",
       "3                23              1565                60                 3   \n",
       "4                31               109                34                 0   \n",
       "\n",
       "   feature_1069_sms  feature_1070_sms  feature_1071_sms  feature_1072_sms  \\\n",
       "0                 7               445                 2                38   \n",
       "1                15               114                18                15   \n",
       "2                 0                 0                 0                 0   \n",
       "3                18               495                 0                28   \n",
       "4                 2                 1                 1                 1   \n",
       "\n",
       "   feature_1073_sms  feature_1074_sms  feature_1075_sms  feature_1076_sms  \\\n",
       "0                94                 0                 0                71   \n",
       "1               119                 2                 1                99   \n",
       "2                 0                 0                 0                 0   \n",
       "3               223                 1                13               144   \n",
       "4                 0                 0                 2                 8   \n",
       "\n",
       "   feature_1077_sms  feature_1078_sms  feature_1079_sms  feature_1080_sms  \\\n",
       "0                 0               541                30               322   \n",
       "1                 0               194                 3                55   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0               421                48                95   \n",
       "4                 0                 6                 0                10   \n",
       "\n",
       "   feature_1081_sms  feature_1082_sms  feature_1083_sms  feature_1084_sms  \\\n",
       "0               154               113              3000                86   \n",
       "1                74                50               795                23   \n",
       "2                 0                 1                 1                 1   \n",
       "3                39                37              3000               150   \n",
       "4                37                41               114                37   \n",
       "\n",
       "   feature_1085_sms  feature_1086_sms  feature_1087_sms  feature_1088_sms  \\\n",
       "0               143                25               681                10   \n",
       "1                31                15               115                18   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 6                22              1012                 0   \n",
       "4                 0                 2                 4                 1   \n",
       "\n",
       "   feature_1089_sms  feature_1090_sms  feature_1091_sms  feature_1092_sms  \\\n",
       "0                58               181                 0                 1   \n",
       "1                16               119                 2                 1   \n",
       "2                 0                 0                 0                 0   \n",
       "3                99               314                 1                16   \n",
       "4                 1                 0                 0                 2   \n",
       "\n",
       "   feature_1093_sms  feature_1094_sms  feature_1095_sms  feature_1096_sms  \\\n",
       "0                90                 2               870                38   \n",
       "1                99                 1               196                 3   \n",
       "2                 0                 0                 0                 0   \n",
       "3               264                 1               880                65   \n",
       "4                 9                 0                 6                 1   \n",
       "\n",
       "   feature_1097_sms  feature_1098_sms  feature_1099_sms  feature_1100_sms  \\\n",
       "0               527               212               162         37.333333   \n",
       "1                55                74                50         48.000000   \n",
       "2                 0                 0                 1          0.333333   \n",
       "3               195                77                44         32.000000   \n",
       "4                10                37                41          9.000000   \n",
       "\n",
       "   feature_1101_sms  feature_1102_sms  feature_1103_sms  feature_1104_sms  \\\n",
       "0         37.333333          0.037333          0.000000          0.000000   \n",
       "1         48.000000          0.181132          5.000000          0.104167   \n",
       "2          1.000000          1.000000          0.000000          0.000000   \n",
       "3         32.000000          0.032000          0.666667          0.020833   \n",
       "4          9.000000          0.236842          0.000000          0.000000   \n",
       "\n",
       "   feature_1105_sms  feature_1106_sms  feature_1107_sms  feature_1108_sms  \\\n",
       "0          0.666667          0.017857          9.666667          0.258929   \n",
       "1          1.666667          0.034722          7.333333          0.152778   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          1.000000          0.031250          5.000000          0.156250   \n",
       "4          0.666667          0.074074          0.000000          0.000000   \n",
       "\n",
       "   feature_1109_sms  feature_1110_sms  feature_1111_sms  feature_1112_sms  \\\n",
       "0          0.333333          0.008929          0.333333          0.008929   \n",
       "1          1.000000          0.020833          3.333333          0.069444   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.000000          0.000000          0.666667          0.020833   \n",
       "4          0.000000          0.000000          0.333333          0.037037   \n",
       "\n",
       "   feature_1113_sms  feature_1114_sms  feature_1115_sms  feature_1116_sms  \\\n",
       "0          1.333333          0.035714          0.000000          0.000000   \n",
       "1          8.000000          0.166667          0.000000          0.000000   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          3.666667          0.114583          0.333333          0.010417   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1117_sms  feature_1118_sms  feature_1119_sms  feature_1120_sms  \\\n",
       "0          0.000000          0.000000          1.333333          0.035714   \n",
       "1          0.333333          0.006944          1.666667          0.034722   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.333333          0.010417          3.000000          0.093750   \n",
       "4          0.333333          0.037037          2.333333          0.259259   \n",
       "\n",
       "   feature_1121_sms  feature_1122_sms  feature_1123_sms  feature_1124_sms  \\\n",
       "0               0.0               0.0         10.000000          0.267857   \n",
       "1               0.0               0.0         11.333333          0.236111   \n",
       "2               0.0               0.0          0.000000          0.000000   \n",
       "3               0.0               0.0         13.333333          0.416667   \n",
       "4               0.0               0.0          1.666667          0.185185   \n",
       "\n",
       "   feature_1125_sms  feature_1126_sms  feature_1127_sms  feature_1128_sms  \\\n",
       "0               1.0          0.026786          4.666667          0.125000   \n",
       "1               0.0          0.000000          3.333333          0.069444   \n",
       "2               0.0          0.000000          0.000000          0.000000   \n",
       "3               0.0          0.000000          2.333333          0.072917   \n",
       "4               0.0          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1129_sms  feature_1130_sms  feature_1131_sms  feature_1132_sms  \\\n",
       "0          3.666667          0.098214          4.333333          0.116071   \n",
       "1          3.333333          0.069444          1.666667          0.034722   \n",
       "2          0.000000          0.000000          0.333333          1.000000   \n",
       "3          1.000000          0.031250          0.666667          0.020833   \n",
       "4          2.333333          0.259259          1.333333          0.148148   \n",
       "\n",
       "   feature_1133_sms  feature_1134_sms  feature_1135_sms  feature_1136_sms  \\\n",
       "0         30.142857         30.142857          0.070333          0.714286   \n",
       "1         55.714286         55.714286          0.490566          4.142857   \n",
       "2          0.142857          1.000000          1.000000          0.000000   \n",
       "3         33.285714         33.285714          0.077667          0.285714   \n",
       "4          5.857143          5.857143          0.359649          0.000000   \n",
       "\n",
       "   feature_1137_sms  feature_1138_sms  feature_1139_sms  feature_1140_sms  \\\n",
       "0          0.023697          0.285714          0.009479          9.428571   \n",
       "1          0.074359          1.000000          0.017949          9.142857   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.008584          0.428571          0.012876          6.285714   \n",
       "4          0.000000          0.285714          0.048780          0.000000   \n",
       "\n",
       "   feature_1141_sms  feature_1142_sms  feature_1143_sms  feature_1144_sms  \\\n",
       "0          0.312796          0.142857          0.004739          0.142857   \n",
       "1          0.164103          1.571429          0.028205          1.714286   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.188841          0.000000          0.000000          0.285714   \n",
       "4          0.000000          0.142857          0.024390          0.142857   \n",
       "\n",
       "   feature_1145_sms  feature_1146_sms  feature_1147_sms  feature_1148_sms  \\\n",
       "0          0.004739          0.857143          0.028436          0.000000   \n",
       "1          0.030769          9.000000          0.161538          0.285714   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.008584          2.571429          0.077253          0.142857   \n",
       "4          0.024390          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1149_sms  feature_1150_sms  feature_1151_sms  feature_1152_sms  \\\n",
       "0          0.000000          0.000000          0.000000          1.428571   \n",
       "1          0.005128          0.142857          0.002564          5.857143   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.004292          0.285714          0.008584          3.857143   \n",
       "4          0.000000          0.142857          0.024390          1.000000   \n",
       "\n",
       "   feature_1153_sms  feature_1154_sms  feature_1155_sms  feature_1156_sms  \\\n",
       "0          0.047393               0.0               0.0          8.571429   \n",
       "1          0.105128               0.0               0.0         12.428571   \n",
       "2          0.000000               0.0               0.0          0.000000   \n",
       "3          0.115880               0.0               0.0         12.000000   \n",
       "4          0.170732               0.0               0.0          0.714286   \n",
       "\n",
       "   feature_1157_sms  feature_1158_sms  feature_1159_sms  feature_1160_sms  \\\n",
       "0          0.284360          0.857143          0.028436          3.428571   \n",
       "1          0.223077          0.285714          0.005128          3.285714   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.360515          2.000000          0.060086          2.857143   \n",
       "4          0.121951          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1161_sms  feature_1162_sms  feature_1163_sms  feature_1164_sms  \\\n",
       "0          0.113744          2.142857          0.071090          2.142857   \n",
       "1          0.058974          4.000000          0.071795          2.857143   \n",
       "2          0.000000          0.000000          0.000000          0.142857   \n",
       "3          0.085837          1.142857          0.034335          1.142857   \n",
       "4          0.000000          2.428571          0.414634          1.000000   \n",
       "\n",
       "   feature_1165_sms  feature_1166_sms  feature_1167_sms  feature_1168_sms  \\\n",
       "0          0.071090         34.428571         34.428571          0.160667   \n",
       "1          0.051282         53.214286         53.214286          0.937107   \n",
       "2          1.000000          0.071429          1.000000          1.000000   \n",
       "3          0.034335         31.285714         31.285714          0.146000   \n",
       "4          0.170732          3.500000          3.769231          0.429825   \n",
       "\n",
       "   feature_1169_sms  feature_1170_sms  feature_1171_sms  feature_1172_sms  \\\n",
       "0          1.214286          0.035270          0.214286          0.006224   \n",
       "1          2.214286          0.041611          1.071429          0.020134   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.142857          0.004566          0.214286          0.006849   \n",
       "4          0.000000          0.000000          0.142857          0.040816   \n",
       "\n",
       "   feature_1173_sms  feature_1174_sms  feature_1175_sms  feature_1176_sms  \\\n",
       "0          9.071429          0.263485          0.071429          0.002075   \n",
       "1          7.714286          0.144966          1.285714          0.024161   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          7.357143          0.235160          0.000000          0.000000   \n",
       "4          0.071429          0.020408          0.071429          0.020408   \n",
       "\n",
       "   feature_1177_sms  feature_1178_sms  feature_1179_sms  feature_1180_sms  \\\n",
       "0          0.142857          0.004149          1.357143          0.039419   \n",
       "1          1.071429          0.020134          7.857143          0.147651   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.142857          0.004566          4.428571          0.141553   \n",
       "4          0.071429          0.020408          0.000000          0.000000   \n",
       "\n",
       "   feature_1181_sms  feature_1182_sms  feature_1183_sms  feature_1184_sms  \\\n",
       "0          0.000000          0.000000          0.000000          0.000000   \n",
       "1          0.142857          0.002685          0.071429          0.001342   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.071429          0.002283          0.214286          0.006849   \n",
       "4          0.000000          0.000000          0.071429          0.020408   \n",
       "\n",
       "   feature_1185_sms  feature_1186_sms  feature_1187_sms  feature_1188_sms  \\\n",
       "0          1.214286          0.035270               0.0               0.0   \n",
       "1          6.571429          0.123490               0.0               0.0   \n",
       "2          0.000000          0.000000               0.0               0.0   \n",
       "3          3.285714          0.105023               0.0               0.0   \n",
       "4          0.500000          0.142857               0.0               0.0   \n",
       "\n",
       "   feature_1189_sms  feature_1190_sms  feature_1191_sms  feature_1192_sms  \\\n",
       "0          9.785714          0.284232          0.857143          0.024896   \n",
       "1         13.000000          0.244295          0.214286          0.004027   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3         10.071429          0.321918          1.642857          0.052511   \n",
       "4          0.428571          0.122449          0.000000          0.000000   \n",
       "\n",
       "   feature_1193_sms  feature_1194_sms  feature_1195_sms  feature_1196_sms  \\\n",
       "0          4.928571          0.143154          3.214286          0.093361   \n",
       "1          3.785714          0.071141          4.714286          0.088591   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          2.214286          0.070776          0.642857          0.020548   \n",
       "4          0.000000          0.000000          1.357143          0.387755   \n",
       "\n",
       "   feature_1197_sms  feature_1198_sms  feature_1199_sms  feature_1200_sms  \\\n",
       "0          2.357143          0.068465         25.000000         35.000000   \n",
       "1          3.500000          0.065772         37.523810         49.250000   \n",
       "2          0.071429          1.000000          0.047619          1.000000   \n",
       "3          0.857143          0.027397         30.142857         30.142857   \n",
       "4          0.785714          0.224490          2.619048          3.437500   \n",
       "\n",
       "   feature_1201_sms  feature_1202_sms  feature_1203_sms  feature_1204_sms  \\\n",
       "0          0.175000          0.904762          0.036190          0.142857   \n",
       "1          0.991195          1.476190          0.039340          0.714286   \n",
       "2          1.000000          0.000000          0.000000          0.000000   \n",
       "3          0.211000          0.142857          0.004739          0.238095   \n",
       "4          0.482456          0.000000          0.000000          0.095238   \n",
       "\n",
       "   feature_1205_sms  feature_1206_sms  feature_1207_sms  feature_1208_sms  \\\n",
       "0          0.005714          6.523810          0.260952          0.047619   \n",
       "1          0.019036          5.380952          0.143401          0.857143   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.007899          8.000000          0.265403          0.000000   \n",
       "4          0.036364          0.047619          0.018182          0.047619   \n",
       "\n",
       "   feature_1209_sms  feature_1210_sms  feature_1211_sms  feature_1212_sms  \\\n",
       "0          0.001905          0.142857          0.005714          0.904762   \n",
       "1          0.022843          0.714286          0.019036          5.666667   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.000000          0.190476          0.006319          4.428571   \n",
       "4          0.018182          0.047619          0.018182          0.000000   \n",
       "\n",
       "   feature_1213_sms  feature_1214_sms  feature_1215_sms  feature_1216_sms  \\\n",
       "0          0.036190          0.000000          0.000000          0.000000   \n",
       "1          0.151015          0.095238          0.002538          0.047619   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.146919          0.047619          0.001580          0.238095   \n",
       "4          0.000000          0.000000          0.000000          0.047619   \n",
       "\n",
       "   feature_1217_sms  feature_1218_sms  feature_1219_sms  feature_1220_sms  \\\n",
       "0          0.000000          1.238095          0.049524               0.0   \n",
       "1          0.001269          4.714286          0.125635               0.0   \n",
       "2          0.000000          0.000000          0.000000               0.0   \n",
       "3          0.007899          2.761905          0.091627               0.0   \n",
       "4          0.018182          0.333333          0.127273               0.0   \n",
       "\n",
       "   feature_1221_sms  feature_1222_sms  feature_1223_sms  feature_1224_sms  \\\n",
       "0               0.0          7.285714          0.291429          0.619048   \n",
       "1               0.0          9.190476          0.244924          0.142857   \n",
       "2               0.0          0.000000          0.000000          0.000000   \n",
       "3               0.0          9.238095          0.306477          1.238095   \n",
       "4               0.0          0.285714          0.109091          0.000000   \n",
       "\n",
       "   feature_1225_sms  feature_1226_sms  feature_1227_sms  feature_1228_sms  \\\n",
       "0          0.024762          3.380952          0.135238          2.190476   \n",
       "1          0.003807          2.619048          0.069797          3.523810   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.041074          1.952381          0.064771          0.809524   \n",
       "4          0.000000          0.142857          0.054545          0.952381   \n",
       "\n",
       "   feature_1229_sms  feature_1230_sms  feature_1231_sms  feature_1232_sms  \\\n",
       "0          0.087619          1.619048          0.064762         24.566667   \n",
       "1          0.093909          2.380952          0.063452         26.266667   \n",
       "2          0.000000          0.047619          1.000000          0.033333   \n",
       "3          0.026856          0.857143          0.028436         29.766667   \n",
       "4          0.363636          0.619048          0.236364          2.966667   \n",
       "\n",
       "   feature_1233_sms  feature_1234_sms  feature_1235_sms  feature_1236_sms  \\\n",
       "0         35.095238          0.245667          0.700000          0.028494   \n",
       "1         49.250000          0.991195          1.033333          0.039340   \n",
       "2          1.000000          1.000000          0.000000          0.000000   \n",
       "3         29.766667          0.297667          0.100000          0.003359   \n",
       "4          3.869565          0.780702          0.000000          0.000000   \n",
       "\n",
       "   feature_1237_sms  feature_1238_sms  feature_1239_sms  feature_1240_sms  \\\n",
       "0          0.133333          0.005427          6.466667          0.263229   \n",
       "1          0.500000          0.019036          3.766667          0.143401   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.300000          0.010078          8.000000          0.268757   \n",
       "4          0.066667          0.022472          0.033333          0.011236   \n",
       "\n",
       "   feature_1241_sms  feature_1242_sms  feature_1243_sms  feature_1244_sms  \\\n",
       "0          0.033333          0.001357          0.166667          0.006784   \n",
       "1          0.600000          0.022843          0.500000          0.019036   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.000000          0.000000          0.666667          0.022396   \n",
       "4          0.033333          0.011236          0.033333          0.011236   \n",
       "\n",
       "   feature_1245_sms  feature_1246_sms  feature_1247_sms  feature_1248_sms  \\\n",
       "0          1.266667          0.051560          0.000000          0.000000   \n",
       "1          3.966667          0.151015          0.066667          0.002538   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          4.433333          0.148936          0.033333          0.001120   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1249_sms  feature_1250_sms  feature_1251_sms  feature_1252_sms  \\\n",
       "0          0.000000          0.000000          1.333333          0.054274   \n",
       "1          0.033333          0.001269          3.300000          0.125635   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.300000          0.010078          2.500000          0.083987   \n",
       "4          0.066667          0.022472          0.266667          0.089888   \n",
       "\n",
       "   feature_1253_sms  feature_1254_sms  feature_1255_sms  feature_1256_sms  \\\n",
       "0               0.0               0.0          6.966667          0.283582   \n",
       "1               0.0               0.0          6.433333          0.244924   \n",
       "2               0.0               0.0          0.000000          0.000000   \n",
       "3               0.0               0.0          8.933333          0.300112   \n",
       "4               0.0               0.0          0.200000          0.067416   \n",
       "\n",
       "   feature_1257_sms  feature_1258_sms  feature_1259_sms  feature_1260_sms  \\\n",
       "0          0.500000          0.020353          3.366667          0.137042   \n",
       "1          0.100000          0.003807          1.833333          0.069797   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          1.033333          0.034714          1.833333          0.061590   \n",
       "4          0.000000          0.000000          0.200000          0.067416   \n",
       "\n",
       "   feature_1261_sms  feature_1262_sms  feature_1263_sms  feature_1264_sms  \\\n",
       "0          2.033333          0.082768          1.600000          0.065129   \n",
       "1          2.466667          0.093909          1.666667          0.063452   \n",
       "2          0.000000          0.000000          0.033333          1.000000   \n",
       "3          0.866667          0.029115          0.766667          0.025756   \n",
       "4          1.033333          0.348315          1.033333          0.348315   \n",
       "\n",
       "   feature_1265_sms  feature_1266_sms  feature_1267_sms  feature_1268_sms  \\\n",
       "0         31.266667         36.784314          0.625333          0.983333   \n",
       "1         13.166667         43.888889          0.993711          0.516667   \n",
       "2          0.016667          1.000000          1.000000          0.000000   \n",
       "3         26.083333         26.083333          0.521667          0.050000   \n",
       "4          1.816667          3.205882          0.956140          0.000000   \n",
       "\n",
       "   feature_1269_sms  feature_1270_sms  feature_1271_sms  feature_1272_sms  \\\n",
       "0          0.031450          0.116667          0.003731          7.416667   \n",
       "1          0.039241          0.250000          0.018987          1.900000   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.001917          0.300000          0.011502          8.250000   \n",
       "4          0.000000          0.033333          0.018349          0.016667   \n",
       "\n",
       "   feature_1273_sms  feature_1274_sms  feature_1275_sms  feature_1276_sms  \\\n",
       "0          0.237207          0.033333          0.001066          0.633333   \n",
       "1          0.144304          0.300000          0.022785          0.250000   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.316294          0.000000          0.000000          0.466667   \n",
       "4          0.009174          0.016667          0.009174          0.016667   \n",
       "\n",
       "   feature_1277_sms  feature_1278_sms  feature_1279_sms  feature_1280_sms  \\\n",
       "0          0.020256          1.566667          0.050107          0.000000   \n",
       "1          0.018987          1.983333          0.150633          0.033333   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.017891          3.716667          0.142492          0.016667   \n",
       "4          0.009174          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1281_sms  feature_1282_sms  feature_1283_sms  feature_1284_sms  \\\n",
       "0          0.000000          0.000000          0.000000          1.183333   \n",
       "1          0.002532          0.016667          0.001266          1.650000   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.000639          0.216667          0.008307          2.400000   \n",
       "4          0.000000          0.033333          0.018349          0.133333   \n",
       "\n",
       "   feature_1285_sms  feature_1286_sms  feature_1287_sms  feature_1288_sms  \\\n",
       "0          0.037846               0.0               0.0          9.016667   \n",
       "1          0.125316               0.0               0.0          3.233333   \n",
       "2          0.000000               0.0               0.0          0.000000   \n",
       "3          0.092013               0.0               0.0          7.016667   \n",
       "4          0.073394               0.0               0.0          0.100000   \n",
       "\n",
       "   feature_1289_sms  feature_1290_sms  feature_1291_sms  feature_1292_sms  \\\n",
       "0          0.288380              0.50          0.015991          5.366667   \n",
       "1          0.245570              0.05          0.003797          0.916667   \n",
       "2          0.000000              0.00          0.000000          0.000000   \n",
       "3          0.269010              0.80          0.030671          1.583333   \n",
       "4          0.055046              0.00          0.000000          0.166667   \n",
       "\n",
       "   feature_1293_sms  feature_1294_sms  feature_1295_sms  feature_1296_sms  \\\n",
       "0          0.171642          2.566667          0.082090          1.883333   \n",
       "1          0.069620          1.233333          0.093671          0.833333   \n",
       "2          0.000000          0.000000          0.000000          0.016667   \n",
       "3          0.060703          0.650000          0.024920          0.616667   \n",
       "4          0.091743          0.616667          0.339450          0.683333   \n",
       "\n",
       "   feature_1297_sms  feature_1298_sms  feature_1299_sms  feature_1300_sms  \\\n",
       "0          0.060235             3.000         34.883721               1.0   \n",
       "1          0.063291             0.795         34.565217               1.0   \n",
       "2          1.000000             0.001          1.000000               1.0   \n",
       "3          0.023642             3.000         20.000000               1.0   \n",
       "4          0.376147             0.114          3.081081               1.0   \n",
       "\n",
       "   feature_1301_sms  feature_1302_sms  feature_1303_sms  feature_1304_sms  \\\n",
       "0             0.143          0.047667             0.025          0.008333   \n",
       "1             0.031          0.038994             0.015          0.018868   \n",
       "2             0.000          0.000000             0.000          0.000000   \n",
       "3             0.006          0.002000             0.022          0.007333   \n",
       "4             0.000          0.000000             0.002          0.017544   \n",
       "\n",
       "   feature_1305_sms  feature_1306_sms  feature_1307_sms  feature_1308_sms  \\\n",
       "0             0.681          0.227000             0.010          0.003333   \n",
       "1             0.115          0.144654             0.018          0.022642   \n",
       "2             0.000          0.000000             0.000          0.000000   \n",
       "3             1.012          0.337333             0.000          0.000000   \n",
       "4             0.004          0.035088             0.001          0.008772   \n",
       "\n",
       "   feature_1309_sms  feature_1310_sms  feature_1311_sms  feature_1312_sms  \\\n",
       "0             0.058          0.019333             0.181          0.060333   \n",
       "1             0.016          0.020126             0.119          0.149686   \n",
       "2             0.000          0.000000             0.000          0.000000   \n",
       "3             0.099          0.033000             0.314          0.104667   \n",
       "4             0.001          0.008772             0.000          0.000000   \n",
       "\n",
       "   feature_1313_sms  feature_1314_sms  feature_1315_sms  feature_1316_sms  \\\n",
       "0             0.000          0.000000             0.001          0.000333   \n",
       "1             0.002          0.002516             0.001          0.001258   \n",
       "2             0.000          0.000000             0.000          0.000000   \n",
       "3             0.001          0.000333             0.016          0.005333   \n",
       "4             0.000          0.000000             0.002          0.017544   \n",
       "\n",
       "   feature_1317_sms  feature_1318_sms  feature_1319_sms  feature_1320_sms  \\\n",
       "0             0.090          0.030000             0.002          0.000667   \n",
       "1             0.099          0.124528             0.001          0.001258   \n",
       "2             0.000          0.000000             0.000          0.000000   \n",
       "3             0.264          0.088000             0.001          0.000333   \n",
       "4             0.009          0.078947             0.000          0.000000   \n",
       "\n",
       "   feature_1321_sms  feature_1322_sms  feature_1323_sms  feature_1324_sms  \\\n",
       "0             0.870          0.290000             0.038          0.012667   \n",
       "1             0.196          0.246541             0.003          0.003774   \n",
       "2             0.000          0.000000             0.000          0.000000   \n",
       "3             0.880          0.293333             0.065          0.021667   \n",
       "4             0.006          0.052632             0.001          0.008772   \n",
       "\n",
       "   feature_1325_sms  feature_1326_sms  feature_1327_sms  feature_1328_sms  \\\n",
       "0             0.527          0.175667             0.212          0.070667   \n",
       "1             0.055          0.069182             0.074          0.093082   \n",
       "2             0.000          0.000000             0.000          0.000000   \n",
       "3             0.195          0.065000             0.077          0.025667   \n",
       "4             0.010          0.087719             0.037          0.324561   \n",
       "\n",
       "   feature_1329_sms  feature_1330_sms  order_id         pan  label  \\\n",
       "0             0.162          0.054000  A5CFUD6W  BPZPK3933F    1.0   \n",
       "1             0.050          0.062893  OZFCFMGC  FRGPM5396K    1.0   \n",
       "2             0.001          1.000000  BIHEWFB9  BOTPT1160A    1.0   \n",
       "3             0.044          0.014667  MN6E2VSW  BUGPR1229F    1.0   \n",
       "4             0.041          0.359649  8KCEGVBW  IDMPS5726L    1.0   \n",
       "\n",
       "   label_pred  ift_socre  \n",
       "0         NaN   0.508873  \n",
       "1         NaN   0.609313  \n",
       "2         NaN   0.199260  \n",
       "3         NaN   0.254405  \n",
       "4         NaN   0.111287  \n",
       "\n",
       "[5 rows x 1803 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ift_socre'] = ift[:,1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "004a50fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./data/filter_feas_df_0403_n_old_itf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1457c614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
