{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c477715f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from hyperopt import hp, tpe, Trials, STATUS_OK, Trials, anneal\n",
    "from functools import partial\n",
    "from hyperopt.fmin import fmin\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_curve,auc, fbeta_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%reload_ext autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "from feas_select import  calc_feas,get_drop\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow import random\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense,Dropout,BatchNormalization,GaussianNoise\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import  mean_squared_error\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import  mean_squared_error\n",
    "import keras_tuner as kt  # pip install tf.keras_tuner \n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  # 全屏展示\n",
    "pd.set_option('display.max_columns', 600)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2306773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train(file='./data/filter_feas_df32n_old.pkl',model='tree'):\n",
    "    df = pd.read_pickle(file)\n",
    "    df3 = pd.read_csv('./data/EXPERIAN_FEATURE_0327.csv',nrows=2) # 取旧模型特征列表\n",
    "    print(df.shape)\n",
    "    df.head()\n",
    "\n",
    "    ##############################配置\n",
    "    oot_dt ='20220200000000'\n",
    "    nofeas = ['ID', 'report_timestamp','label','pan','label_y','order_id','label_pred']\n",
    "    catefeas= list(pd.read_pickle('./data/catefeas.pkl').values)\n",
    "    cbfeas = [col for col in df.columns if '_cb'in str(col)]\n",
    "    vcount = [col for col in df.columns if 'vcount'in str(col)]\n",
    "    old_feas = [col for col in df.columns if 'feature_'in str(col)]\n",
    "    old_cols = list(df3.columns)\n",
    "    sms_feas = [col for col in df3.columns if '_sms'in str(col)]\n",
    "    nosms_feas = [col for col in df3.columns if '_sms' not in str(col) and col not in nofeas]\n",
    "    drop_list=[]\n",
    "    # try:\n",
    "    #     upper1\n",
    "    # except:\n",
    "    #     print('first run')\n",
    "    #     upper1,upper2,var_features,miss_features,sigle_rate = calc_feas(df,catefeas) ## 过滤法特征选择\n",
    "    # drop_list = get_drop(upper1,upper2,var_features,miss_features,sigle_rate)\n",
    "\n",
    "    drop_feas = nofeas+cbfeas+vcount+drop_list+catefeas                # 去除旧模型部分特征、类别特征等等\n",
    "    final_feas = [col for col in df.columns if col not in drop_feas]\n",
    "    \n",
    "\n",
    "\n",
    "    ###########################\n",
    "    # 强制类型转换\n",
    "    def to_category_or_num(df, category_list, drop_list):\n",
    "        if model == 'nn':  # 全数值型\n",
    "            for ft in set(df.columns)-set(drop_list):\n",
    "                df[ft] = pd.to_numeric(df[ft], errors='coerce').replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        else:\n",
    "            for ft in set(df.columns)-set(drop_list):\n",
    "                if ft in category_list:\n",
    "                    df[ft] = df[ft].astype('category')\n",
    "                else:\n",
    "                    df[ft] = pd.to_numeric(df[ft], errors='coerce')\n",
    "\n",
    "    to_category_or_num(df, catefeas, nofeas)\n",
    "    df = df.reset_index(drop=True)\n",
    "    ### 剔除特征 \n",
    "\n",
    "    x = df[df['label'].notnull()&(df.report_timestamp<=oot_dt)][final_feas]\n",
    "    y = df[df['label'].notnull()&(df.report_timestamp<=oot_dt)]['label']\n",
    "    oot_x = df[df['label'].notnull()&(df.report_timestamp>oot_dt)][final_feas]\n",
    "    oot_y = df[df['label'].notnull()&(df.report_timestamp>oot_dt)]['label']\n",
    "\n",
    "    # ### 直接用旧模型的特征\n",
    "    # x = df.loc[df['label'].notnull()&(df.report_timestamp<=oot_dt),old_fea]\n",
    "    # y = df.loc[df['label'].notnull()&(df.report_timestamp<=oot_dt)]['label']\n",
    "    # oot_x = df.loc[df['label'].notnull()&(df.report_timestamp>oot_dt),old_fea]\n",
    "    # oot_y = df.loc[df['label'].notnull()&(df.report_timestamp>oot_dt)]['label']\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y,test_size=0.2,random_state=42)\n",
    "    print(y.value_counts())\n",
    "    print(oot_y.value_counts())\n",
    "    display(train_x.head())\n",
    "    print(train_x.shape)\n",
    "    return train_x, test_x, train_y, test_y,oot_x,oot_y,df,final_feas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "130bf64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9123, 1802)\n",
      "1.0    5631\n",
      "0.0    2040\n",
      "Name: label, dtype: int64\n",
      "1.0    1035\n",
      "0.0     417\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BureauScore</th>\n",
       "      <th>MissingRate</th>\n",
       "      <th>Len_Name</th>\n",
       "      <th>Tel_nuniq</th>\n",
       "      <th>Email_nuniq</th>\n",
       "      <th>Len_of_addrs</th>\n",
       "      <th>City_nuniq</th>\n",
       "      <th>Current_State</th>\n",
       "      <th>CreditAccountActive</th>\n",
       "      <th>CreditAccountTotal</th>\n",
       "      <th>CreditAccountActivePor</th>\n",
       "      <th>Outstanding_Balance_Secured</th>\n",
       "      <th>Outstanding_Balance_UnSecured_Percentage</th>\n",
       "      <th>Outstanding_Balance_All</th>\n",
       "      <th>Outstanding_Balance_Secured_Percentage</th>\n",
       "      <th>Outstanding_Balance_UnSecured</th>\n",
       "      <th>Diff_dateBirth</th>\n",
       "      <th>State_nuniq</th>\n",
       "      <th>Birth_nuniq</th>\n",
       "      <th>TotalCAPSLast90Days</th>\n",
       "      <th>TotalCAPSLast7Days</th>\n",
       "      <th>TotalCAPSLast30Days</th>\n",
       "      <th>TotalCAPSLast180Days</th>\n",
       "      <th>CAPSLast30Days</th>\n",
       "      <th>CAPSLast7Days</th>\n",
       "      <th>CAPSLast180Days</th>\n",
       "      <th>NonCreditCAPSLast180Days</th>\n",
       "      <th>Pin_nuniq</th>\n",
       "      <th>Pan_nuniq</th>\n",
       "      <th>Ident_nuniq</th>\n",
       "      <th>Name_nuniq2</th>\n",
       "      <th>Tel_nuniq2</th>\n",
       "      <th>Email_nuniq2</th>\n",
       "      <th>Pan_nuniq2</th>\n",
       "      <th>Account_nuniq2</th>\n",
       "      <th>Ident_nuniq2</th>\n",
       "      <th>Gender_nuniq</th>\n",
       "      <th>Amount_Past_Due35_sum_30</th>\n",
       "      <th>Amount_Past_Due35_min_30</th>\n",
       "      <th>Amount_Past_Due35_sum_90</th>\n",
       "      <th>Amount_Past_Due35_mean_90</th>\n",
       "      <th>Amount_Past_Due35_max_90</th>\n",
       "      <th>Amount_Past_Due35_min_90</th>\n",
       "      <th>Amount_Past_Due35_std_90</th>\n",
       "      <th>Amount_Past_Due35_sum_360</th>\n",
       "      <th>Amount_Past_Due35_mean_360</th>\n",
       "      <th>Amount_Past_Due35_max_360</th>\n",
       "      <th>Amount_Past_Due35_std_360</th>\n",
       "      <th>Amount_Past_Due35_sum_9999</th>\n",
       "      <th>Amount_Past_Due35_max_9999</th>\n",
       "      <th>Amount_Past_Due35_min_9999</th>\n",
       "      <th>Amount_Past_Due35_std_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_9999</th>\n",
       "      <th>Terms_Duration34_sum_30</th>\n",
       "      <th>Terms_Duration34_std_30</th>\n",
       "      <th>Terms_Duration34_sum_90</th>\n",
       "      <th>Terms_Duration34_std_90</th>\n",
       "      <th>Terms_Duration34_mean_360</th>\n",
       "      <th>Terms_Duration34_max_360</th>\n",
       "      <th>Terms_Duration34_min_360</th>\n",
       "      <th>Terms_Duration34_std_360</th>\n",
       "      <th>Terms_Duration34_sum_9999</th>\n",
       "      <th>Terms_Duration34_mean_9999</th>\n",
       "      <th>Terms_Duration34_max_9999</th>\n",
       "      <th>Terms_Duration34_min_9999</th>\n",
       "      <th>Terms_Duration34_std_9999</th>\n",
       "      <th>Payment_Rating34_sum_90</th>\n",
       "      <th>Payment_Rating34_mean_90</th>\n",
       "      <th>Payment_Rating34_max_90</th>\n",
       "      <th>Payment_Rating34_min_90</th>\n",
       "      <th>Payment_Rating34_std_90</th>\n",
       "      <th>Payment_Rating34_sum_360</th>\n",
       "      <th>Payment_Rating34_mean_360</th>\n",
       "      <th>Payment_Rating34_max_360</th>\n",
       "      <th>Payment_Rating34_min_360</th>\n",
       "      <th>Payment_Rating34_std_360</th>\n",
       "      <th>Payment_Rating34_sum_9999</th>\n",
       "      <th>Payment_Rating34_mean_9999</th>\n",
       "      <th>Payment_Rating34_max_9999</th>\n",
       "      <th>Payment_Rating34_min_9999</th>\n",
       "      <th>Payment_Rating34_std_9999</th>\n",
       "      <th>Current_Balance35_mean_30</th>\n",
       "      <th>Current_Balance35_min_30</th>\n",
       "      <th>Current_Balance35_std_30</th>\n",
       "      <th>Current_Balance35_sum_90</th>\n",
       "      <th>Current_Balance35_mean_90</th>\n",
       "      <th>Current_Balance35_max_90</th>\n",
       "      <th>Current_Balance35_std_90</th>\n",
       "      <th>Current_Balance35_sum_360</th>\n",
       "      <th>Current_Balance35_max_360</th>\n",
       "      <th>Current_Balance35_std_360</th>\n",
       "      <th>Current_Balance35_max_9999</th>\n",
       "      <th>Current_Balance35_std_9999</th>\n",
       "      <th>Settlement_Amount37_max_360</th>\n",
       "      <th>Settlement_Amount37_min_360</th>\n",
       "      <th>Settlement_Amount37_std_360</th>\n",
       "      <th>Settlement_Amount37_sum_9999</th>\n",
       "      <th>Settlement_Amount37_mean_9999</th>\n",
       "      <th>Settlement_Amount37_max_9999</th>\n",
       "      <th>Settlement_Amount37_min_9999</th>\n",
       "      <th>Settlement_Amount37_std_9999</th>\n",
       "      <th>Value_of_Collateral39_std_90</th>\n",
       "      <th>Value_of_Collateral39_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_360</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_360</th>\n",
       "      <th>Written_Off_Amt_Total41_min_360</th>\n",
       "      <th>Written_Off_Amt_Total41_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_max_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_min_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_std_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_mean_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_std_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_max_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_9999</th>\n",
       "      <th>Rate_of_Interest36_sum_30</th>\n",
       "      <th>Rate_of_Interest36_std_30</th>\n",
       "      <th>Rate_of_Interest36_sum_90</th>\n",
       "      <th>Rate_of_Interest36_mean_90</th>\n",
       "      <th>Rate_of_Interest36_max_90</th>\n",
       "      <th>Rate_of_Interest36_std_90</th>\n",
       "      <th>Rate_of_Interest36_sum_360</th>\n",
       "      <th>Rate_of_Interest36_mean_360</th>\n",
       "      <th>Rate_of_Interest36_max_360</th>\n",
       "      <th>Rate_of_Interest36_min_360</th>\n",
       "      <th>Rate_of_Interest36_std_360</th>\n",
       "      <th>Rate_of_Interest36_sum_9999</th>\n",
       "      <th>Rate_of_Interest36_mean_9999</th>\n",
       "      <th>Rate_of_Interest36_max_9999</th>\n",
       "      <th>Rate_of_Interest36_min_9999</th>\n",
       "      <th>Rate_of_Interest36_std_9999</th>\n",
       "      <th>Repayment_Tenure36_std_30</th>\n",
       "      <th>Repayment_Tenure36_mean_90</th>\n",
       "      <th>Repayment_Tenure36_max_90</th>\n",
       "      <th>Repayment_Tenure36_min_90</th>\n",
       "      <th>Repayment_Tenure36_std_90</th>\n",
       "      <th>Repayment_Tenure36_sum_360</th>\n",
       "      <th>Repayment_Tenure36_mean_360</th>\n",
       "      <th>Repayment_Tenure36_min_360</th>\n",
       "      <th>Repayment_Tenure36_std_360</th>\n",
       "      <th>Repayment_Tenure36_mean_9999</th>\n",
       "      <th>Repayment_Tenure36_min_9999</th>\n",
       "      <th>Repayment_Tenure36_std_9999</th>\n",
       "      <th>Income26_count_360</th>\n",
       "      <th>Income26_std_360</th>\n",
       "      <th>Open_Date29_max_30</th>\n",
       "      <th>Open_Date29_min_30</th>\n",
       "      <th>Open_Date29_mean_30</th>\n",
       "      <th>Open_Date29_nuniq_30</th>\n",
       "      <th>Open_Date29_maxcount_30</th>\n",
       "      <th>Open_Date29_max_90</th>\n",
       "      <th>Open_Date29_mean_90</th>\n",
       "      <th>Open_Date29_mode_90</th>\n",
       "      <th>Open_Date29_nuniq_90</th>\n",
       "      <th>Open_Date29_maxcount_90</th>\n",
       "      <th>Open_Date29_max_360</th>\n",
       "      <th>Open_Date29_mean_360</th>\n",
       "      <th>Open_Date29_mode_360</th>\n",
       "      <th>Open_Date29_nuniq_360</th>\n",
       "      <th>Open_Date29_maxcount_360</th>\n",
       "      <th>Open_Date29_max_9999</th>\n",
       "      <th>Open_Date29_mean_9999</th>\n",
       "      <th>Open_Date29_mode_9999</th>\n",
       "      <th>Open_Date29_maxcount_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_30</th>\n",
       "      <th>Portfolio_Type34_nuniq_90</th>\n",
       "      <th>Portfolio_Type34_nuniq_360</th>\n",
       "      <th>Portfolio_Type34_nuniq_9999</th>\n",
       "      <th>Account_Type32_nuniq_30</th>\n",
       "      <th>Account_Type32_nuniq_90</th>\n",
       "      <th>Account_Type32_nuniq_360</th>\n",
       "      <th>Account_Type32_nuniq_9999</th>\n",
       "      <th>Occupation_Code35_nuniq_30</th>\n",
       "      <th>Occupation_Code35_nuniq_90</th>\n",
       "      <th>Occupation_Code35_nuniq_360</th>\n",
       "      <th>Occupation_Code35_nuniq_9999</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_360</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_9999</th>\n",
       "      <th>Payment_History_Profile43_mode_30</th>\n",
       "      <th>Payment_History_Profile43_mode_90</th>\n",
       "      <th>Payment_History_Profile43_nuniq_90</th>\n",
       "      <th>Payment_History_Profile43_mode_360</th>\n",
       "      <th>Payment_History_Profile43_nuniq_360</th>\n",
       "      <th>Payment_History_Profile43_mode_9999</th>\n",
       "      <th>Payment_History_Profile43_nuniq_9999</th>\n",
       "      <th>Date_Closed31_nuniq_30</th>\n",
       "      <th>Date_Closed31_maxcount_30</th>\n",
       "      <th>Date_Closed31_max_90</th>\n",
       "      <th>Date_Closed31_min_90</th>\n",
       "      <th>Date_Closed31_mean_90</th>\n",
       "      <th>Date_Closed31_mode_90</th>\n",
       "      <th>Date_Closed31_nuniq_90</th>\n",
       "      <th>Date_Closed31_maxcount_90</th>\n",
       "      <th>Date_Closed31_min_360</th>\n",
       "      <th>Date_Closed31_mode_360</th>\n",
       "      <th>Date_Closed31_nuniq_360</th>\n",
       "      <th>Date_Closed31_maxcount_360</th>\n",
       "      <th>Date_Closed31_max_9999</th>\n",
       "      <th>Date_Closed31_min_9999</th>\n",
       "      <th>Date_Closed31_mean_9999</th>\n",
       "      <th>Date_Closed31_mode_9999</th>\n",
       "      <th>Date_Closed31_nuniq_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_30</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_30</th>\n",
       "      <th>Date_of_Last_Payment40_min_90</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_90</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_90</th>\n",
       "      <th>Date_of_Last_Payment40_max_360</th>\n",
       "      <th>Date_of_Last_Payment40_min_360</th>\n",
       "      <th>Date_of_Last_Payment40_mean_360</th>\n",
       "      <th>Date_of_Last_Payment40_mode_360</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_360</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_360</th>\n",
       "      <th>Date_of_Last_Payment40_max_9999</th>\n",
       "      <th>Date_of_Last_Payment40_min_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mean_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_9999</th>\n",
       "      <th>Date_Reported33_nuniq_30</th>\n",
       "      <th>Date_Reported33_max_90</th>\n",
       "      <th>Date_Reported33_mean_90</th>\n",
       "      <th>Date_Reported33_mode_90</th>\n",
       "      <th>Date_Reported33_nuniq_90</th>\n",
       "      <th>Date_Reported33_maxcount_90</th>\n",
       "      <th>Date_Reported33_max_360</th>\n",
       "      <th>Date_Reported33_mean_360</th>\n",
       "      <th>Date_Reported33_mode_360</th>\n",
       "      <th>Date_Reported33_nuniq_360</th>\n",
       "      <th>Date_Reported33_maxcount_360</th>\n",
       "      <th>Date_Reported33_max_9999</th>\n",
       "      <th>Date_Reported33_mean_9999</th>\n",
       "      <th>Date_Reported33_mode_9999</th>\n",
       "      <th>Date_Reported33_nuniq_9999</th>\n",
       "      <th>Date_Reported33_maxcount_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_30</th>\n",
       "      <th>DateOfAddition34_max_90</th>\n",
       "      <th>DateOfAddition34_mean_90</th>\n",
       "      <th>DateOfAddition34_mode_90</th>\n",
       "      <th>DateOfAddition34_nuniq_90</th>\n",
       "      <th>DateOfAddition34_maxcount_90</th>\n",
       "      <th>DateOfAddition34_max_360</th>\n",
       "      <th>DateOfAddition34_mean_360</th>\n",
       "      <th>DateOfAddition34_mode_360</th>\n",
       "      <th>DateOfAddition34_nuniq_360</th>\n",
       "      <th>DateOfAddition34_maxcount_360</th>\n",
       "      <th>DateOfAddition34_max_9999</th>\n",
       "      <th>DateOfAddition34_mean_9999</th>\n",
       "      <th>DateOfAddition34_mode_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_9999</th>\n",
       "      <th>DateOfAddition34_maxcount_9999</th>\n",
       "      <th>Account_Status34_mode_30</th>\n",
       "      <th>Account_Status34_nuniq_30</th>\n",
       "      <th>Account_Status34_mode_90</th>\n",
       "      <th>Account_Status34_nuniq_90</th>\n",
       "      <th>Account_Status34_mode_360</th>\n",
       "      <th>Account_Status34_nuniq_360</th>\n",
       "      <th>Account_Status34_nuniq_9999</th>\n",
       "      <th>Month50_sum_30</th>\n",
       "      <th>Month50_max_30</th>\n",
       "      <th>Month50_std_30</th>\n",
       "      <th>Month50_sum_90</th>\n",
       "      <th>Month50_mean_90</th>\n",
       "      <th>Month50_max_90</th>\n",
       "      <th>Month50_min_90</th>\n",
       "      <th>Month50_std_90</th>\n",
       "      <th>Month50_sum_360</th>\n",
       "      <th>Month50_min_360</th>\n",
       "      <th>Month50_std_360</th>\n",
       "      <th>Month50_sum_9999</th>\n",
       "      <th>Month50_mean_9999</th>\n",
       "      <th>Month50_max_9999</th>\n",
       "      <th>Month50_min_9999</th>\n",
       "      <th>Month50_std_9999</th>\n",
       "      <th>Days_Past_Due58_max_30</th>\n",
       "      <th>Days_Past_Due58_min_30</th>\n",
       "      <th>Days_Past_Due58_mean_90</th>\n",
       "      <th>Days_Past_Due58_max_90</th>\n",
       "      <th>Days_Past_Due58_min_90</th>\n",
       "      <th>Days_Past_Due58_std_90</th>\n",
       "      <th>Days_Past_Due58_sum_360</th>\n",
       "      <th>Days_Past_Due58_mean_360</th>\n",
       "      <th>Days_Past_Due58_max_360</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_1031_sms</th>\n",
       "      <th>feature_1032_sms</th>\n",
       "      <th>feature_1033_sms</th>\n",
       "      <th>feature_1034_sms</th>\n",
       "      <th>feature_1035_sms</th>\n",
       "      <th>feature_1036_sms</th>\n",
       "      <th>feature_1037_sms</th>\n",
       "      <th>feature_1038_sms</th>\n",
       "      <th>feature_1039_sms</th>\n",
       "      <th>feature_1040_sms</th>\n",
       "      <th>feature_1041_sms</th>\n",
       "      <th>feature_1042_sms</th>\n",
       "      <th>feature_1043_sms</th>\n",
       "      <th>feature_1044_sms</th>\n",
       "      <th>feature_1045_sms</th>\n",
       "      <th>feature_1046_sms</th>\n",
       "      <th>feature_1047_sms</th>\n",
       "      <th>feature_1048_sms</th>\n",
       "      <th>feature_1049_sms</th>\n",
       "      <th>feature_1050_sms</th>\n",
       "      <th>feature_1051_sms</th>\n",
       "      <th>feature_1052_sms</th>\n",
       "      <th>feature_1053_sms</th>\n",
       "      <th>feature_1054_sms</th>\n",
       "      <th>feature_1055_sms</th>\n",
       "      <th>feature_1056_sms</th>\n",
       "      <th>feature_1057_sms</th>\n",
       "      <th>feature_1058_sms</th>\n",
       "      <th>feature_1059_sms</th>\n",
       "      <th>feature_1060_sms</th>\n",
       "      <th>feature_1061_sms</th>\n",
       "      <th>feature_1062_sms</th>\n",
       "      <th>feature_1063_sms</th>\n",
       "      <th>feature_1064_sms</th>\n",
       "      <th>feature_1065_sms</th>\n",
       "      <th>feature_1066_sms</th>\n",
       "      <th>feature_1067_sms</th>\n",
       "      <th>feature_1068_sms</th>\n",
       "      <th>feature_1069_sms</th>\n",
       "      <th>feature_1070_sms</th>\n",
       "      <th>feature_1071_sms</th>\n",
       "      <th>feature_1072_sms</th>\n",
       "      <th>feature_1073_sms</th>\n",
       "      <th>feature_1074_sms</th>\n",
       "      <th>feature_1075_sms</th>\n",
       "      <th>feature_1076_sms</th>\n",
       "      <th>feature_1077_sms</th>\n",
       "      <th>feature_1078_sms</th>\n",
       "      <th>feature_1079_sms</th>\n",
       "      <th>feature_1080_sms</th>\n",
       "      <th>feature_1081_sms</th>\n",
       "      <th>feature_1082_sms</th>\n",
       "      <th>feature_1083_sms</th>\n",
       "      <th>feature_1084_sms</th>\n",
       "      <th>feature_1085_sms</th>\n",
       "      <th>feature_1086_sms</th>\n",
       "      <th>feature_1087_sms</th>\n",
       "      <th>feature_1088_sms</th>\n",
       "      <th>feature_1089_sms</th>\n",
       "      <th>feature_1090_sms</th>\n",
       "      <th>feature_1091_sms</th>\n",
       "      <th>feature_1092_sms</th>\n",
       "      <th>feature_1093_sms</th>\n",
       "      <th>feature_1094_sms</th>\n",
       "      <th>feature_1095_sms</th>\n",
       "      <th>feature_1096_sms</th>\n",
       "      <th>feature_1097_sms</th>\n",
       "      <th>feature_1098_sms</th>\n",
       "      <th>feature_1099_sms</th>\n",
       "      <th>feature_1100_sms</th>\n",
       "      <th>feature_1101_sms</th>\n",
       "      <th>feature_1102_sms</th>\n",
       "      <th>feature_1103_sms</th>\n",
       "      <th>feature_1104_sms</th>\n",
       "      <th>feature_1105_sms</th>\n",
       "      <th>feature_1106_sms</th>\n",
       "      <th>feature_1107_sms</th>\n",
       "      <th>feature_1108_sms</th>\n",
       "      <th>feature_1109_sms</th>\n",
       "      <th>feature_1110_sms</th>\n",
       "      <th>feature_1111_sms</th>\n",
       "      <th>feature_1112_sms</th>\n",
       "      <th>feature_1113_sms</th>\n",
       "      <th>feature_1114_sms</th>\n",
       "      <th>feature_1115_sms</th>\n",
       "      <th>feature_1116_sms</th>\n",
       "      <th>feature_1117_sms</th>\n",
       "      <th>feature_1118_sms</th>\n",
       "      <th>feature_1119_sms</th>\n",
       "      <th>feature_1120_sms</th>\n",
       "      <th>feature_1121_sms</th>\n",
       "      <th>feature_1122_sms</th>\n",
       "      <th>feature_1123_sms</th>\n",
       "      <th>feature_1124_sms</th>\n",
       "      <th>feature_1125_sms</th>\n",
       "      <th>feature_1126_sms</th>\n",
       "      <th>feature_1127_sms</th>\n",
       "      <th>feature_1128_sms</th>\n",
       "      <th>feature_1129_sms</th>\n",
       "      <th>feature_1130_sms</th>\n",
       "      <th>feature_1131_sms</th>\n",
       "      <th>feature_1132_sms</th>\n",
       "      <th>feature_1133_sms</th>\n",
       "      <th>feature_1134_sms</th>\n",
       "      <th>feature_1135_sms</th>\n",
       "      <th>feature_1136_sms</th>\n",
       "      <th>feature_1137_sms</th>\n",
       "      <th>feature_1138_sms</th>\n",
       "      <th>feature_1139_sms</th>\n",
       "      <th>feature_1140_sms</th>\n",
       "      <th>feature_1141_sms</th>\n",
       "      <th>feature_1142_sms</th>\n",
       "      <th>feature_1143_sms</th>\n",
       "      <th>feature_1144_sms</th>\n",
       "      <th>feature_1145_sms</th>\n",
       "      <th>feature_1146_sms</th>\n",
       "      <th>feature_1147_sms</th>\n",
       "      <th>feature_1148_sms</th>\n",
       "      <th>feature_1149_sms</th>\n",
       "      <th>feature_1150_sms</th>\n",
       "      <th>feature_1151_sms</th>\n",
       "      <th>feature_1152_sms</th>\n",
       "      <th>feature_1153_sms</th>\n",
       "      <th>feature_1154_sms</th>\n",
       "      <th>feature_1155_sms</th>\n",
       "      <th>feature_1156_sms</th>\n",
       "      <th>feature_1157_sms</th>\n",
       "      <th>feature_1158_sms</th>\n",
       "      <th>feature_1159_sms</th>\n",
       "      <th>feature_1160_sms</th>\n",
       "      <th>feature_1161_sms</th>\n",
       "      <th>feature_1162_sms</th>\n",
       "      <th>feature_1163_sms</th>\n",
       "      <th>feature_1164_sms</th>\n",
       "      <th>feature_1165_sms</th>\n",
       "      <th>feature_1166_sms</th>\n",
       "      <th>feature_1167_sms</th>\n",
       "      <th>feature_1168_sms</th>\n",
       "      <th>feature_1169_sms</th>\n",
       "      <th>feature_1170_sms</th>\n",
       "      <th>feature_1171_sms</th>\n",
       "      <th>feature_1172_sms</th>\n",
       "      <th>feature_1173_sms</th>\n",
       "      <th>feature_1174_sms</th>\n",
       "      <th>feature_1175_sms</th>\n",
       "      <th>feature_1176_sms</th>\n",
       "      <th>feature_1177_sms</th>\n",
       "      <th>feature_1178_sms</th>\n",
       "      <th>feature_1179_sms</th>\n",
       "      <th>feature_1180_sms</th>\n",
       "      <th>feature_1181_sms</th>\n",
       "      <th>feature_1182_sms</th>\n",
       "      <th>feature_1183_sms</th>\n",
       "      <th>feature_1184_sms</th>\n",
       "      <th>feature_1185_sms</th>\n",
       "      <th>feature_1186_sms</th>\n",
       "      <th>feature_1187_sms</th>\n",
       "      <th>feature_1188_sms</th>\n",
       "      <th>feature_1189_sms</th>\n",
       "      <th>feature_1190_sms</th>\n",
       "      <th>feature_1191_sms</th>\n",
       "      <th>feature_1192_sms</th>\n",
       "      <th>feature_1193_sms</th>\n",
       "      <th>feature_1194_sms</th>\n",
       "      <th>feature_1195_sms</th>\n",
       "      <th>feature_1196_sms</th>\n",
       "      <th>feature_1197_sms</th>\n",
       "      <th>feature_1198_sms</th>\n",
       "      <th>feature_1199_sms</th>\n",
       "      <th>feature_1200_sms</th>\n",
       "      <th>feature_1201_sms</th>\n",
       "      <th>feature_1202_sms</th>\n",
       "      <th>feature_1203_sms</th>\n",
       "      <th>feature_1204_sms</th>\n",
       "      <th>feature_1205_sms</th>\n",
       "      <th>feature_1206_sms</th>\n",
       "      <th>feature_1207_sms</th>\n",
       "      <th>feature_1208_sms</th>\n",
       "      <th>feature_1209_sms</th>\n",
       "      <th>feature_1210_sms</th>\n",
       "      <th>feature_1211_sms</th>\n",
       "      <th>feature_1212_sms</th>\n",
       "      <th>feature_1213_sms</th>\n",
       "      <th>feature_1214_sms</th>\n",
       "      <th>feature_1215_sms</th>\n",
       "      <th>feature_1216_sms</th>\n",
       "      <th>feature_1217_sms</th>\n",
       "      <th>feature_1218_sms</th>\n",
       "      <th>feature_1219_sms</th>\n",
       "      <th>feature_1220_sms</th>\n",
       "      <th>feature_1221_sms</th>\n",
       "      <th>feature_1222_sms</th>\n",
       "      <th>feature_1223_sms</th>\n",
       "      <th>feature_1224_sms</th>\n",
       "      <th>feature_1225_sms</th>\n",
       "      <th>feature_1226_sms</th>\n",
       "      <th>feature_1227_sms</th>\n",
       "      <th>feature_1228_sms</th>\n",
       "      <th>feature_1229_sms</th>\n",
       "      <th>feature_1230_sms</th>\n",
       "      <th>feature_1231_sms</th>\n",
       "      <th>feature_1232_sms</th>\n",
       "      <th>feature_1233_sms</th>\n",
       "      <th>feature_1234_sms</th>\n",
       "      <th>feature_1235_sms</th>\n",
       "      <th>feature_1236_sms</th>\n",
       "      <th>feature_1237_sms</th>\n",
       "      <th>feature_1238_sms</th>\n",
       "      <th>feature_1239_sms</th>\n",
       "      <th>feature_1240_sms</th>\n",
       "      <th>feature_1241_sms</th>\n",
       "      <th>feature_1242_sms</th>\n",
       "      <th>feature_1243_sms</th>\n",
       "      <th>feature_1244_sms</th>\n",
       "      <th>feature_1245_sms</th>\n",
       "      <th>feature_1246_sms</th>\n",
       "      <th>feature_1247_sms</th>\n",
       "      <th>feature_1248_sms</th>\n",
       "      <th>feature_1249_sms</th>\n",
       "      <th>feature_1250_sms</th>\n",
       "      <th>feature_1251_sms</th>\n",
       "      <th>feature_1252_sms</th>\n",
       "      <th>feature_1253_sms</th>\n",
       "      <th>feature_1254_sms</th>\n",
       "      <th>feature_1255_sms</th>\n",
       "      <th>feature_1256_sms</th>\n",
       "      <th>feature_1257_sms</th>\n",
       "      <th>feature_1258_sms</th>\n",
       "      <th>feature_1259_sms</th>\n",
       "      <th>feature_1260_sms</th>\n",
       "      <th>feature_1261_sms</th>\n",
       "      <th>feature_1262_sms</th>\n",
       "      <th>feature_1263_sms</th>\n",
       "      <th>feature_1264_sms</th>\n",
       "      <th>feature_1265_sms</th>\n",
       "      <th>feature_1266_sms</th>\n",
       "      <th>feature_1267_sms</th>\n",
       "      <th>feature_1268_sms</th>\n",
       "      <th>feature_1269_sms</th>\n",
       "      <th>feature_1270_sms</th>\n",
       "      <th>feature_1271_sms</th>\n",
       "      <th>feature_1272_sms</th>\n",
       "      <th>feature_1273_sms</th>\n",
       "      <th>feature_1274_sms</th>\n",
       "      <th>feature_1275_sms</th>\n",
       "      <th>feature_1276_sms</th>\n",
       "      <th>feature_1277_sms</th>\n",
       "      <th>feature_1278_sms</th>\n",
       "      <th>feature_1279_sms</th>\n",
       "      <th>feature_1280_sms</th>\n",
       "      <th>feature_1281_sms</th>\n",
       "      <th>feature_1282_sms</th>\n",
       "      <th>feature_1283_sms</th>\n",
       "      <th>feature_1284_sms</th>\n",
       "      <th>feature_1285_sms</th>\n",
       "      <th>feature_1286_sms</th>\n",
       "      <th>feature_1287_sms</th>\n",
       "      <th>feature_1288_sms</th>\n",
       "      <th>feature_1289_sms</th>\n",
       "      <th>feature_1290_sms</th>\n",
       "      <th>feature_1291_sms</th>\n",
       "      <th>feature_1292_sms</th>\n",
       "      <th>feature_1293_sms</th>\n",
       "      <th>feature_1294_sms</th>\n",
       "      <th>feature_1295_sms</th>\n",
       "      <th>feature_1296_sms</th>\n",
       "      <th>feature_1297_sms</th>\n",
       "      <th>feature_1298_sms</th>\n",
       "      <th>feature_1299_sms</th>\n",
       "      <th>feature_1300_sms</th>\n",
       "      <th>feature_1301_sms</th>\n",
       "      <th>feature_1302_sms</th>\n",
       "      <th>feature_1303_sms</th>\n",
       "      <th>feature_1304_sms</th>\n",
       "      <th>feature_1305_sms</th>\n",
       "      <th>feature_1306_sms</th>\n",
       "      <th>feature_1307_sms</th>\n",
       "      <th>feature_1308_sms</th>\n",
       "      <th>feature_1309_sms</th>\n",
       "      <th>feature_1310_sms</th>\n",
       "      <th>feature_1311_sms</th>\n",
       "      <th>feature_1312_sms</th>\n",
       "      <th>feature_1313_sms</th>\n",
       "      <th>feature_1314_sms</th>\n",
       "      <th>feature_1315_sms</th>\n",
       "      <th>feature_1316_sms</th>\n",
       "      <th>feature_1317_sms</th>\n",
       "      <th>feature_1318_sms</th>\n",
       "      <th>feature_1319_sms</th>\n",
       "      <th>feature_1320_sms</th>\n",
       "      <th>feature_1321_sms</th>\n",
       "      <th>feature_1322_sms</th>\n",
       "      <th>feature_1323_sms</th>\n",
       "      <th>feature_1324_sms</th>\n",
       "      <th>feature_1325_sms</th>\n",
       "      <th>feature_1326_sms</th>\n",
       "      <th>feature_1327_sms</th>\n",
       "      <th>feature_1328_sms</th>\n",
       "      <th>feature_1329_sms</th>\n",
       "      <th>feature_1330_sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>732.0</td>\n",
       "      <td>0.400396</td>\n",
       "      <td>17</td>\n",
       "      <td>6.665722</td>\n",
       "      <td>5.998750</td>\n",
       "      <td>46</td>\n",
       "      <td>6.998800</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>0.363620</td>\n",
       "      <td>59011</td>\n",
       "      <td>22</td>\n",
       "      <td>364464</td>\n",
       "      <td>16</td>\n",
       "      <td>81364</td>\n",
       "      <td>12949</td>\n",
       "      <td>28.486257</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11.397920</td>\n",
       "      <td>65.935065</td>\n",
       "      <td>5.498875</td>\n",
       "      <td>214</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87016.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>13492.000000</td>\n",
       "      <td>604227.0</td>\n",
       "      <td>33568.166667</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>42007.514571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>260.0</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.334615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85432.0</td>\n",
       "      <td>59011.0</td>\n",
       "      <td>16295.000000</td>\n",
       "      <td>224089.0</td>\n",
       "      <td>47740.988110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.40</td>\n",
       "      <td>9.840000</td>\n",
       "      <td>24.35</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.559937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.433437</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217.0</td>\n",
       "      <td>164.500000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1173.500000</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>792.642857</td>\n",
       "      <td>217.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>713.952381</td>\n",
       "      <td>564.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>281.136364</td>\n",
       "      <td>258.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197.0</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>771.045455</td>\n",
       "      <td>197.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>239.0</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.095351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>783</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>905</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>101</td>\n",
       "      <td>9</td>\n",
       "      <td>1227</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>271</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>416</td>\n",
       "      <td>26</td>\n",
       "      <td>91</td>\n",
       "      <td>166</td>\n",
       "      <td>16</td>\n",
       "      <td>2999</td>\n",
       "      <td>173</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>723</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>171</td>\n",
       "      <td>12</td>\n",
       "      <td>1088</td>\n",
       "      <td>49</td>\n",
       "      <td>201</td>\n",
       "      <td>390</td>\n",
       "      <td>42</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>0.045682</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.175182</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.306569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.124088</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.051095</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.036496</td>\n",
       "      <td>42.142857</td>\n",
       "      <td>42.142857</td>\n",
       "      <td>0.098366</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>0.210169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.098305</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>0.105085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.857143</td>\n",
       "      <td>0.376271</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>0.091525</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>38.214286</td>\n",
       "      <td>38.214286</td>\n",
       "      <td>0.178393</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>9.714286</td>\n",
       "      <td>0.254206</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>0.080374</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>4.785714</td>\n",
       "      <td>0.125234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.071429</td>\n",
       "      <td>0.368224</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>0.069159</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.065421</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>37.285714</td>\n",
       "      <td>37.285714</td>\n",
       "      <td>0.261087</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>9.142857</td>\n",
       "      <td>0.245211</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>0.088123</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.809524</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>2.476190</td>\n",
       "      <td>0.066411</td>\n",
       "      <td>3.095238</td>\n",
       "      <td>0.083014</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>30.166667</td>\n",
       "      <td>30.166667</td>\n",
       "      <td>0.301767</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.243094</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>0.081768</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>0.098343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.364641</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>0.111602</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>20.450000</td>\n",
       "      <td>21.910714</td>\n",
       "      <td>0.409136</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>4.516667</td>\n",
       "      <td>0.220864</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>0.079870</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>1.983333</td>\n",
       "      <td>0.096985</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>6.933333</td>\n",
       "      <td>0.339038</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.021190</td>\n",
       "      <td>1.516667</td>\n",
       "      <td>0.074165</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>0.135289</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>2.999</td>\n",
       "      <td>17.335260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.241080</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.057019</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.362788</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.067022</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.130043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.014005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6547</th>\n",
       "      <td>518.0</td>\n",
       "      <td>0.370718</td>\n",
       "      <td>42</td>\n",
       "      <td>34.988670</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>46</td>\n",
       "      <td>11.797840</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>0.107691</td>\n",
       "      <td>201224</td>\n",
       "      <td>22</td>\n",
       "      <td>290622</td>\n",
       "      <td>69</td>\n",
       "      <td>64832</td>\n",
       "      <td>10624</td>\n",
       "      <td>45.977511</td>\n",
       "      <td>30.990003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.244439</td>\n",
       "      <td>138.862138</td>\n",
       "      <td>12.997600</td>\n",
       "      <td>272</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>75</td>\n",
       "      <td>92.908092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98741.0</td>\n",
       "      <td>66750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8805.042136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>543500.0</td>\n",
       "      <td>212000.0</td>\n",
       "      <td>81793.398267</td>\n",
       "      <td>2748243.0</td>\n",
       "      <td>42280.661538</td>\n",
       "      <td>237771.0</td>\n",
       "      <td>50555.892598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.118252</td>\n",
       "      <td>224.0</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.647876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.101317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21779.0</td>\n",
       "      <td>21779.0</td>\n",
       "      <td>8711.600000</td>\n",
       "      <td>164164.0</td>\n",
       "      <td>21030.920771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.00</td>\n",
       "      <td>18.40</td>\n",
       "      <td>32.00</td>\n",
       "      <td>14.50</td>\n",
       "      <td>6.843975</td>\n",
       "      <td>583.80</td>\n",
       "      <td>12.973333</td>\n",
       "      <td>32.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>6.082344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.118252</td>\n",
       "      <td>3.446154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.589107</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>353.0</td>\n",
       "      <td>300.800000</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>709.092308</td>\n",
       "      <td>430.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>504.517241</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>101.40</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>431.246154</td>\n",
       "      <td>303.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>303.0</td>\n",
       "      <td>272.600000</td>\n",
       "      <td>303.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>658.938462</td>\n",
       "      <td>485.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.939072</td>\n",
       "      <td>681.0</td>\n",
       "      <td>10.476923</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.637643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>389.0</td>\n",
       "      <td>77.800000</td>\n",
       "      <td>206.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>568</td>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>184</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>32</td>\n",
       "      <td>83</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>3000</td>\n",
       "      <td>283</td>\n",
       "      <td>291</td>\n",
       "      <td>88</td>\n",
       "      <td>719</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>6</td>\n",
       "      <td>461</td>\n",
       "      <td>141</td>\n",
       "      <td>424</td>\n",
       "      <td>378</td>\n",
       "      <td>35</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.571429</td>\n",
       "      <td>12.571429</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>13.071429</td>\n",
       "      <td>13.071429</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>0.092896</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.109290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.087432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.136612</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.087432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>11.952381</td>\n",
       "      <td>11.952381</td>\n",
       "      <td>0.083667</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.067729</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.390438</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.011952</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.131474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.063745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.619048</td>\n",
       "      <td>0.135458</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.043825</td>\n",
       "      <td>1.380952</td>\n",
       "      <td>0.115538</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.066007</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>0.366337</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>0.125413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.118812</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.052805</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.033003</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>9.466667</td>\n",
       "      <td>9.466667</td>\n",
       "      <td>0.189333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.063380</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.110915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.059859</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.147887</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>1.383333</td>\n",
       "      <td>0.146127</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.040493</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>3.000</td>\n",
       "      <td>10.600707</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.239667</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.070667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.141333</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.011667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>762.0</td>\n",
       "      <td>0.420800</td>\n",
       "      <td>12</td>\n",
       "      <td>2.998002</td>\n",
       "      <td>8.992008</td>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.399920</td>\n",
       "      <td>68568</td>\n",
       "      <td>1</td>\n",
       "      <td>68932</td>\n",
       "      <td>99</td>\n",
       "      <td>364</td>\n",
       "      <td>8226</td>\n",
       "      <td>3.498751</td>\n",
       "      <td>6.994006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.498751</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>4.996004</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>6.994006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>784.400000</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>1568.800000</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1568.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25350.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>6039.172129</td>\n",
       "      <td>25350.0</td>\n",
       "      <td>5070.000000</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>6039.172129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68932.0</td>\n",
       "      <td>68568.0</td>\n",
       "      <td>27391.162791</td>\n",
       "      <td>68568.0</td>\n",
       "      <td>27391.162791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>194.400000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>194.400000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>156.666667</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>154.25</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>154.250000</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>115.2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>115.200000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>182.200000</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>182.200000</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.033150</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.033150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>327</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>464</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>114</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>972</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>21</td>\n",
       "      <td>260</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>2975</td>\n",
       "      <td>167</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1199</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>395</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>102</td>\n",
       "      <td>89</td>\n",
       "      <td>669</td>\n",
       "      <td>162</td>\n",
       "      <td>185</td>\n",
       "      <td>84</td>\n",
       "      <td>36</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>0.045378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>0.281481</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.081481</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>18.357143</td>\n",
       "      <td>18.357143</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>0.268482</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.038911</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.140078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.093385</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.027237</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>0.287938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.027237</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.023346</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>15.571429</td>\n",
       "      <td>15.571429</td>\n",
       "      <td>0.109916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>0.293578</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.051988</td>\n",
       "      <td>2.190476</td>\n",
       "      <td>0.140673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.085627</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>3.952381</td>\n",
       "      <td>0.253823</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.033639</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.061162</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.024465</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>15.466667</td>\n",
       "      <td>15.466667</td>\n",
       "      <td>0.155966</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.233333</td>\n",
       "      <td>0.338362</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.047414</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.023707</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.245690</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.036638</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>0.326723</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.233333</td>\n",
       "      <td>0.384774</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.022634</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>0.115226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.021605</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.267490</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.033951</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>2.975</td>\n",
       "      <td>17.814371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>1.199</td>\n",
       "      <td>0.403025</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.132773</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.029916</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.224874</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.062185</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.028235</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.012101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>746.0</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>27</td>\n",
       "      <td>5.998334</td>\n",
       "      <td>4.498251</td>\n",
       "      <td>46</td>\n",
       "      <td>2.749563</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.599880</td>\n",
       "      <td>47246</td>\n",
       "      <td>0</td>\n",
       "      <td>47246</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>11472</td>\n",
       "      <td>4.998667</td>\n",
       "      <td>3.749313</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.998667</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>2.499250</td>\n",
       "      <td>164</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>13.987013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43490.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>6255.000000</td>\n",
       "      <td>228499.0</td>\n",
       "      <td>45699.800000</td>\n",
       "      <td>85485.0</td>\n",
       "      <td>23840.693366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.545268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>14549.000000</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>12079.789773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.44</td>\n",
       "      <td>15.813333</td>\n",
       "      <td>25.00</td>\n",
       "      <td>9.95</td>\n",
       "      <td>6.578198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.631514</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.0</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>524.200000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>76.00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>197.400000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>161.400000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.0</td>\n",
       "      <td>209.500000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>508.600000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>381</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>441</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>629</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>207</td>\n",
       "      <td>32</td>\n",
       "      <td>71</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1129</td>\n",
       "      <td>265</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>129</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>295</td>\n",
       "      <td>42</td>\n",
       "      <td>168</td>\n",
       "      <td>181</td>\n",
       "      <td>27</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>0.064659</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.714286</td>\n",
       "      <td>21.714286</td>\n",
       "      <td>0.134632</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046053</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.059211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.138158</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>19.571429</td>\n",
       "      <td>19.571429</td>\n",
       "      <td>0.242693</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.018248</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.094891</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.182482</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.054745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>0.394161</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>0.120438</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>18.142857</td>\n",
       "      <td>18.142857</td>\n",
       "      <td>0.337467</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.020997</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.110236</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.196850</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.049869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.404199</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.018373</td>\n",
       "      <td>2.047619</td>\n",
       "      <td>0.112861</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.018373</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>0.390611</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>0.120181</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.024943</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.197279</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.049887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.566667</td>\n",
       "      <td>0.378685</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>0.120181</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>10.483333</td>\n",
       "      <td>10.483333</td>\n",
       "      <td>0.557130</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.138315</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.182830</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.062003</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>0.329094</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.050874</td>\n",
       "      <td>1.183333</td>\n",
       "      <td>0.112878</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.031797</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>1.129</td>\n",
       "      <td>4.260377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.024801</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.023915</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.122232</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.114260</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.052259</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.261293</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.037201</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.148804</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.160319</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.023915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>700.0</td>\n",
       "      <td>0.385723</td>\n",
       "      <td>52</td>\n",
       "      <td>7.748313</td>\n",
       "      <td>12.497126</td>\n",
       "      <td>46</td>\n",
       "      <td>3.666222</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.437473</td>\n",
       "      <td>40878</td>\n",
       "      <td>88</td>\n",
       "      <td>339424</td>\n",
       "      <td>12</td>\n",
       "      <td>298546</td>\n",
       "      <td>11260</td>\n",
       "      <td>20.990005</td>\n",
       "      <td>7.798640</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.999286</td>\n",
       "      <td>52.948052</td>\n",
       "      <td>3.999250</td>\n",
       "      <td>258</td>\n",
       "      <td>62</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>37.963037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>803.666667</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>1797.053298</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1202.818128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>331598.0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>28811.055984</td>\n",
       "      <td>548219.0</td>\n",
       "      <td>34263.687500</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>27368.428373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278210.0</td>\n",
       "      <td>75464.0</td>\n",
       "      <td>29261.683648</td>\n",
       "      <td>75464.0</td>\n",
       "      <td>28188.354776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>62.00</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>42.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.944272</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.942103</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332.0</td>\n",
       "      <td>268.333333</td>\n",
       "      <td>244.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>244.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>523.777778</td>\n",
       "      <td>51.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>69.20</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>285.461538</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>269.625000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.0</td>\n",
       "      <td>246.666667</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>560.937500</td>\n",
       "      <td>242.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>165.0</td>\n",
       "      <td>10.312500</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.310810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>482</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>677</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>40</td>\n",
       "      <td>19</td>\n",
       "      <td>1121</td>\n",
       "      <td>60</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>266</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>16</td>\n",
       "      <td>130</td>\n",
       "      <td>67</td>\n",
       "      <td>27</td>\n",
       "      <td>3000</td>\n",
       "      <td>159</td>\n",
       "      <td>156</td>\n",
       "      <td>57</td>\n",
       "      <td>725</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>1047</td>\n",
       "      <td>52</td>\n",
       "      <td>256</td>\n",
       "      <td>174</td>\n",
       "      <td>79</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>23.142857</td>\n",
       "      <td>23.142857</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>9.285714</td>\n",
       "      <td>0.401235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>0.290123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>22.952381</td>\n",
       "      <td>22.952381</td>\n",
       "      <td>0.160667</td>\n",
       "      <td>1.380952</td>\n",
       "      <td>0.060166</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>0.292531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.029046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>2.095238</td>\n",
       "      <td>0.091286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>0.286307</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>2.809524</td>\n",
       "      <td>0.122407</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.056017</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.018672</td>\n",
       "      <td>22.566667</td>\n",
       "      <td>22.566667</td>\n",
       "      <td>0.225667</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0.060561</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.023634</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>0.262925</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.011817</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.097489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.257016</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.137371</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.059084</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.028065</td>\n",
       "      <td>18.683333</td>\n",
       "      <td>18.683333</td>\n",
       "      <td>0.373667</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.066905</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.022302</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.046387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>0.110616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.266667</td>\n",
       "      <td>0.281891</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.014273</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.115968</td>\n",
       "      <td>1.116667</td>\n",
       "      <td>0.059768</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.024086</td>\n",
       "      <td>3.000</td>\n",
       "      <td>18.867925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.047667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>1.047</td>\n",
       "      <td>0.349000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.026333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1761 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BureauScore  MissingRate  Len_Name  Tel_nuniq  Email_nuniq  \\\n",
       "502         732.0     0.400396        17   6.665722     5.998750   \n",
       "6547        518.0     0.370718        42  34.988670    25.987506   \n",
       "6938        762.0     0.420800        12   2.998002     8.992008   \n",
       "3115        746.0     0.396552        27   5.998334     4.498251   \n",
       "3649        700.0     0.385723        52   7.748313    12.497126   \n",
       "\n",
       "      Len_of_addrs  City_nuniq  Current_State  CreditAccountActive  \\\n",
       "502             46    6.998800             27                    8   \n",
       "6547            46   11.797840             27                    7   \n",
       "6938            46    1.000000             27                    2   \n",
       "3115            46    2.749563             27                    3   \n",
       "3649            46    3.666222             27                    7   \n",
       "\n",
       "      CreditAccountTotal  CreditAccountActivePor  Outstanding_Balance_Secured  \\\n",
       "502                   22                0.363620                        59011   \n",
       "6547                  65                0.107691                       201224   \n",
       "6938                   5                0.399920                        68568   \n",
       "3115                   5                0.599880                        47246   \n",
       "3649                  16                0.437473                        40878   \n",
       "\n",
       "      Outstanding_Balance_UnSecured_Percentage  Outstanding_Balance_All  \\\n",
       "502                                         22                   364464   \n",
       "6547                                        22                   290622   \n",
       "6938                                         1                    68932   \n",
       "3115                                         0                    47246   \n",
       "3649                                        88                   339424   \n",
       "\n",
       "      Outstanding_Balance_Secured_Percentage  Outstanding_Balance_UnSecured  \\\n",
       "502                                       16                          81364   \n",
       "6547                                      69                          64832   \n",
       "6938                                      99                            364   \n",
       "3115                                     100                              0   \n",
       "3649                                      12                         298546   \n",
       "\n",
       "      Diff_dateBirth  State_nuniq  Birth_nuniq  TotalCAPSLast90Days  \\\n",
       "502            12949    28.486257    25.987506                    4   \n",
       "6547           10624    45.977511    30.990003                    1   \n",
       "6938            8226     3.498751     6.994006                    0   \n",
       "3115           11472     4.998667     3.749313                    5   \n",
       "3649           11260    20.990005     7.798640                    3   \n",
       "\n",
       "      TotalCAPSLast7Days  TotalCAPSLast30Days  TotalCAPSLast180Days  \\\n",
       "502                    3                    3                     5   \n",
       "6547                   1                    1                     2   \n",
       "6938                   0                    0                     0   \n",
       "3115                   2                    4                     6   \n",
       "3649                   2                    2                     3   \n",
       "\n",
       "      CAPSLast30Days  CAPSLast7Days  CAPSLast180Days  \\\n",
       "502                0              0                2   \n",
       "6547               0              0                1   \n",
       "6938               0              0                0   \n",
       "3115               2              0                4   \n",
       "3649               1              1                2   \n",
       "\n",
       "      NonCreditCAPSLast180Days  Pin_nuniq   Pan_nuniq  Ident_nuniq  \\\n",
       "502                          3  11.397920   65.935065     5.498875   \n",
       "6547                         1  23.244439  138.862138    12.997600   \n",
       "6938                         0   3.498751   10.990010     4.996004   \n",
       "3115                         2   4.998667   10.990010     2.499250   \n",
       "3649                         1   5.999286   52.948052     3.999250   \n",
       "\n",
       "      Name_nuniq2  Tel_nuniq2  Email_nuniq2  Pan_nuniq2  Account_nuniq2  \\\n",
       "502           214          86            93          14              14   \n",
       "6547          272          44            47          14              14   \n",
       "6938           57          14            25          14              14   \n",
       "3115          164          44            44          14              14   \n",
       "3649          258          62            87          14              14   \n",
       "\n",
       "      Ident_nuniq2  Gender_nuniq  Amount_Past_Due35_sum_30  \\\n",
       "502             60     25.987506                       NaN   \n",
       "6547            75     92.908092                       NaN   \n",
       "6938            15      6.994006                       NaN   \n",
       "3115            30     13.987013                       NaN   \n",
       "3649            60     37.963037                       NaN   \n",
       "\n",
       "      Amount_Past_Due35_min_30  Amount_Past_Due35_sum_90  \\\n",
       "502                        NaN                       NaN   \n",
       "6547                       NaN                       NaN   \n",
       "6938                       NaN                       0.0   \n",
       "3115                       NaN                       NaN   \n",
       "3649                       NaN                       NaN   \n",
       "\n",
       "      Amount_Past_Due35_mean_90  Amount_Past_Due35_max_90  \\\n",
       "502                         NaN                       NaN   \n",
       "6547                        NaN                       NaN   \n",
       "6938                        0.0                       0.0   \n",
       "3115                        NaN                       NaN   \n",
       "3649                        NaN                       NaN   \n",
       "\n",
       "      Amount_Past_Due35_min_90  Amount_Past_Due35_std_90  \\\n",
       "502                        NaN                       NaN   \n",
       "6547                       NaN                       NaN   \n",
       "6938                       0.0                       0.0   \n",
       "3115                       NaN                       NaN   \n",
       "3649                       NaN                       NaN   \n",
       "\n",
       "      Amount_Past_Due35_sum_360  Amount_Past_Due35_mean_360  \\\n",
       "502                         0.0                    0.000000   \n",
       "6547                        0.0                    0.000000   \n",
       "6938                     3922.0                  784.400000   \n",
       "3115                        0.0                    0.000000   \n",
       "3649                     4822.0                  803.666667   \n",
       "\n",
       "      Amount_Past_Due35_max_360  Amount_Past_Due35_std_360  \\\n",
       "502                         0.0                   0.000000   \n",
       "6547                        0.0                   0.000000   \n",
       "6938                     3922.0                1568.800000   \n",
       "3115                        0.0                   0.000000   \n",
       "3649                     4822.0                1797.053298   \n",
       "\n",
       "      Amount_Past_Due35_sum_9999  Amount_Past_Due35_max_9999  \\\n",
       "502                          0.0                         0.0   \n",
       "6547                     98741.0                     66750.0   \n",
       "6938                      3922.0                      3922.0   \n",
       "3115                         0.0                         0.0   \n",
       "3649                      4822.0                      4822.0   \n",
       "\n",
       "      Amount_Past_Due35_min_9999  Amount_Past_Due35_std_9999  \\\n",
       "502                          0.0                    0.000000   \n",
       "6547                         0.0                 8805.042136   \n",
       "6938                         0.0                 1568.800000   \n",
       "3115                         0.0                    0.000000   \n",
       "3649                         0.0                 1202.818128   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_30  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                              NaN   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_min_30  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                              NaN   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_30  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                              NaN   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_90  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                            350.0   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_mean_90  \\\n",
       "502                                                NaN   \n",
       "6547                                               NaN   \n",
       "6938                                             350.0   \n",
       "3115                                               NaN   \n",
       "3649                                               NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_90  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                            350.0   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_min_90  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                            350.0   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "502                                               NaN   \n",
       "6547                                              NaN   \n",
       "6938                                              0.0   \n",
       "3115                                              NaN   \n",
       "3649                                              NaN   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_360  \\\n",
       "502                                            87016.0   \n",
       "6547                                          543500.0   \n",
       "6938                                           25350.0   \n",
       "3115                                           43490.0   \n",
       "3649                                          331598.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_360  \\\n",
       "502                                            57000.0   \n",
       "6547                                          212000.0   \n",
       "6938                                           17000.0   \n",
       "3115                                           28000.0   \n",
       "3649                                           88000.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_360  \\\n",
       "502                                       13492.000000   \n",
       "6547                                      81793.398267   \n",
       "6938                                       6039.172129   \n",
       "3115                                       6255.000000   \n",
       "3649                                      28811.055984   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "502                                            604227.0   \n",
       "6547                                          2748243.0   \n",
       "6938                                            25350.0   \n",
       "3115                                           228499.0   \n",
       "3649                                           548219.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_mean_9999  \\\n",
       "502                                        33568.166667    \n",
       "6547                                       42280.661538    \n",
       "6938                                        5070.000000    \n",
       "3115                                       45699.800000    \n",
       "3649                                       34263.687500    \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "502                                            195000.0   \n",
       "6547                                           237771.0   \n",
       "6938                                            17000.0   \n",
       "3115                                            85485.0   \n",
       "3649                                            88000.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_9999  \\\n",
       "502                                        42007.514571   \n",
       "6547                                       50555.892598   \n",
       "6938                                        6039.172129   \n",
       "3115                                       23840.693366   \n",
       "3649                                       27368.428373   \n",
       "\n",
       "      Terms_Duration34_sum_30  Terms_Duration34_std_30  \\\n",
       "502                       NaN                      NaN   \n",
       "6547                      NaN                      NaN   \n",
       "6938                      NaN                      NaN   \n",
       "3115                      NaN                      NaN   \n",
       "3649                      NaN                      NaN   \n",
       "\n",
       "      Terms_Duration34_sum_90  Terms_Duration34_std_90  \\\n",
       "502                       NaN                      NaN   \n",
       "6547                      NaN                      NaN   \n",
       "6938                      0.0                      NaN   \n",
       "3115                      NaN                      NaN   \n",
       "3649                      NaN                      NaN   \n",
       "\n",
       "      Terms_Duration34_mean_360  Terms_Duration34_max_360  \\\n",
       "502                         4.5                       8.0   \n",
       "6547                        4.8                      13.0   \n",
       "6938                       30.0                      30.0   \n",
       "3115                       11.0                      12.0   \n",
       "3649                       24.0                      24.0   \n",
       "\n",
       "      Terms_Duration34_min_360  Terms_Duration34_std_360  \\\n",
       "502                        1.0                  3.500000   \n",
       "6547                       2.0                  4.118252   \n",
       "6938                      30.0                  0.000000   \n",
       "3115                      10.0                  1.000000   \n",
       "3649                      24.0                  0.000000   \n",
       "\n",
       "      Terms_Duration34_sum_9999  Terms_Duration34_mean_9999  \\\n",
       "502                       260.0                   17.333333   \n",
       "6547                      224.0                    5.600000   \n",
       "6938                       30.0                   30.000000   \n",
       "3115                       58.0                   14.500000   \n",
       "3649                       31.0                   15.500000   \n",
       "\n",
       "      Terms_Duration34_max_9999  Terms_Duration34_min_9999  \\\n",
       "502                        47.0                        1.0   \n",
       "6547                       40.0                        0.0   \n",
       "6938                       30.0                       30.0   \n",
       "3115                       24.0                       10.0   \n",
       "3649                       24.0                        7.0   \n",
       "\n",
       "      Terms_Duration34_std_9999  Payment_Rating34_sum_90  \\\n",
       "502                   17.334615                      NaN   \n",
       "6547                   7.647876                      NaN   \n",
       "6938                   0.000000                      0.0   \n",
       "3115                   5.545268                      NaN   \n",
       "3649                   8.500000                      NaN   \n",
       "\n",
       "      Payment_Rating34_mean_90  Payment_Rating34_max_90  \\\n",
       "502                        NaN                      NaN   \n",
       "6547                       NaN                      NaN   \n",
       "6938                       0.0                      0.0   \n",
       "3115                       NaN                      NaN   \n",
       "3649                       NaN                      NaN   \n",
       "\n",
       "      Payment_Rating34_min_90  Payment_Rating34_std_90  \\\n",
       "502                       NaN                      NaN   \n",
       "6547                      NaN                      NaN   \n",
       "6938                      0.0                      0.0   \n",
       "3115                      NaN                      NaN   \n",
       "3649                      NaN                      NaN   \n",
       "\n",
       "      Payment_Rating34_sum_360  Payment_Rating34_mean_360  \\\n",
       "502                        0.0                        0.0   \n",
       "6547                       0.0                        0.0   \n",
       "6938                       0.0                        0.0   \n",
       "3115                       0.0                        0.0   \n",
       "3649                       0.0                        0.0   \n",
       "\n",
       "      Payment_Rating34_max_360  Payment_Rating34_min_360  \\\n",
       "502                        0.0                       0.0   \n",
       "6547                       0.0                       0.0   \n",
       "6938                       0.0                       0.0   \n",
       "3115                       0.0                       0.0   \n",
       "3649                       0.0                       0.0   \n",
       "\n",
       "      Payment_Rating34_std_360  Payment_Rating34_sum_9999  \\\n",
       "502                        0.0                        0.0   \n",
       "6547                       0.0                       17.0   \n",
       "6938                       0.0                        0.0   \n",
       "3115                       0.0                        0.0   \n",
       "3649                       0.0                        0.0   \n",
       "\n",
       "      Payment_Rating34_mean_9999  Payment_Rating34_max_9999  \\\n",
       "502                     0.000000                        0.0   \n",
       "6547                    0.269841                        6.0   \n",
       "6938                    0.000000                        0.0   \n",
       "3115                    0.000000                        0.0   \n",
       "3649                    0.000000                        0.0   \n",
       "\n",
       "      Payment_Rating34_min_9999  Payment_Rating34_std_9999  \\\n",
       "502                         0.0                   0.000000   \n",
       "6547                        0.0                   1.101317   \n",
       "6938                        0.0                   0.000000   \n",
       "3115                        0.0                   0.000000   \n",
       "3649                        0.0                   0.000000   \n",
       "\n",
       "      Current_Balance35_mean_30  Current_Balance35_min_30  \\\n",
       "502                         NaN                       NaN   \n",
       "6547                        NaN                       NaN   \n",
       "6938                        NaN                       NaN   \n",
       "3115                        NaN                       NaN   \n",
       "3649                        NaN                       NaN   \n",
       "\n",
       "      Current_Balance35_std_30  Current_Balance35_sum_90  \\\n",
       "502                        NaN                       NaN   \n",
       "6547                       NaN                       NaN   \n",
       "6938                       NaN                     364.0   \n",
       "3115                       NaN                       NaN   \n",
       "3649                       NaN                       NaN   \n",
       "\n",
       "      Current_Balance35_mean_90  Current_Balance35_max_90  \\\n",
       "502                         NaN                       NaN   \n",
       "6547                        NaN                       NaN   \n",
       "6938                      364.0                     364.0   \n",
       "3115                        NaN                       NaN   \n",
       "3649                        NaN                       NaN   \n",
       "\n",
       "      Current_Balance35_std_90  Current_Balance35_sum_360  \\\n",
       "502                        NaN                    85432.0   \n",
       "6547                       NaN                    21779.0   \n",
       "6938                       0.0                    68932.0   \n",
       "3115                       NaN                    29098.0   \n",
       "3649                       NaN                   278210.0   \n",
       "\n",
       "      Current_Balance35_max_360  Current_Balance35_std_360  \\\n",
       "502                     59011.0               16295.000000   \n",
       "6547                    21779.0                8711.600000   \n",
       "6938                    68568.0               27391.162791   \n",
       "3115                    29098.0               14549.000000   \n",
       "3649                    75464.0               29261.683648   \n",
       "\n",
       "      Current_Balance35_max_9999  Current_Balance35_std_9999  \\\n",
       "502                     224089.0                47740.988110   \n",
       "6547                    164164.0                21030.920771   \n",
       "6938                     68568.0                27391.162791   \n",
       "3115                     29098.0                12079.789773   \n",
       "3649                     75464.0                28188.354776   \n",
       "\n",
       "      Settlement_Amount37_max_360  Settlement_Amount37_min_360  \\\n",
       "502                           NaN                          NaN   \n",
       "6547                          NaN                          NaN   \n",
       "6938                          0.0                          0.0   \n",
       "3115                          NaN                          NaN   \n",
       "3649                          NaN                          NaN   \n",
       "\n",
       "      Settlement_Amount37_std_360  Settlement_Amount37_sum_9999  \\\n",
       "502                           NaN                           0.0   \n",
       "6547                          NaN                           0.0   \n",
       "6938                          0.0                           0.0   \n",
       "3115                          NaN                           0.0   \n",
       "3649                          NaN                           0.0   \n",
       "\n",
       "      Settlement_Amount37_mean_9999  Settlement_Amount37_max_9999  \\\n",
       "502                             0.0                           0.0   \n",
       "6547                            0.0                           0.0   \n",
       "6938                            0.0                           0.0   \n",
       "3115                            NaN                           NaN   \n",
       "3649                            0.0                           0.0   \n",
       "\n",
       "      Settlement_Amount37_min_9999  Settlement_Amount37_std_9999  \\\n",
       "502                            0.0                           0.0   \n",
       "6547                           0.0                           0.0   \n",
       "6938                           0.0                           0.0   \n",
       "3115                           NaN                           NaN   \n",
       "3649                           0.0                           0.0   \n",
       "\n",
       "      Value_of_Collateral39_std_90  Value_of_Collateral39_std_360  \\\n",
       "502                            NaN                            0.0   \n",
       "6547                           NaN                            NaN   \n",
       "6938                           NaN                            NaN   \n",
       "3115                           NaN                            0.0   \n",
       "3649                           NaN                            0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_sum_360  Written_Off_Amt_Total41_mean_360  \\\n",
       "502                               0.0                               NaN   \n",
       "6547                              0.0                               NaN   \n",
       "6938                              0.0                               0.0   \n",
       "3115                              0.0                               NaN   \n",
       "3649                              0.0                               0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_min_360  Written_Off_Amt_Total41_std_360  \\\n",
       "502                               NaN                              NaN   \n",
       "6547                              NaN                              NaN   \n",
       "6938                              0.0                              0.0   \n",
       "3115                              NaN                              NaN   \n",
       "3649                              0.0                              0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_sum_9999  Written_Off_Amt_Total41_mean_9999  \\\n",
       "502                                0.0                                0.0   \n",
       "6547                               0.0                                0.0   \n",
       "6938                               0.0                                0.0   \n",
       "3115                               0.0                                NaN   \n",
       "3649                               0.0                                0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_max_9999  Written_Off_Amt_Total41_min_9999  \\\n",
       "502                                0.0                               0.0   \n",
       "6547                               0.0                               0.0   \n",
       "6938                               0.0                               0.0   \n",
       "3115                               NaN                               NaN   \n",
       "3649                               0.0                               0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_std_9999  Written_Off_Amt_Principal45_sum_360  \\\n",
       "502                                0.0                                  0.0   \n",
       "6547                               0.0                                  0.0   \n",
       "6938                               0.0                                  0.0   \n",
       "3115                               NaN                                  0.0   \n",
       "3649                               0.0                                  0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_mean_360  \\\n",
       "502                                    NaN   \n",
       "6547                                   NaN   \n",
       "6938                                   0.0   \n",
       "3115                                   NaN   \n",
       "3649                                   NaN   \n",
       "\n",
       "      Written_Off_Amt_Principal45_min_360  \\\n",
       "502                                   NaN   \n",
       "6547                                  NaN   \n",
       "6938                                  0.0   \n",
       "3115                                  NaN   \n",
       "3649                                  NaN   \n",
       "\n",
       "      Written_Off_Amt_Principal45_std_360  \\\n",
       "502                                   NaN   \n",
       "6547                                  NaN   \n",
       "6938                                  0.0   \n",
       "3115                                  NaN   \n",
       "3649                                  NaN   \n",
       "\n",
       "      Written_Off_Amt_Principal45_max_9999  \\\n",
       "502                                    0.0   \n",
       "6547                                   0.0   \n",
       "6938                                   0.0   \n",
       "3115                                   0.0   \n",
       "3649                                   0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_min_9999  Rate_of_Interest36_sum_30  \\\n",
       "502                                    0.0                        NaN   \n",
       "6547                                   0.0                        NaN   \n",
       "6938                                   0.0                        NaN   \n",
       "3115                                   0.0                        NaN   \n",
       "3649                                   0.0                        NaN   \n",
       "\n",
       "      Rate_of_Interest36_std_30  Rate_of_Interest36_sum_90  \\\n",
       "502                         NaN                        NaN   \n",
       "6547                        NaN                        NaN   \n",
       "6938                        NaN                        0.0   \n",
       "3115                        NaN                        NaN   \n",
       "3649                        NaN                        NaN   \n",
       "\n",
       "      Rate_of_Interest36_mean_90  Rate_of_Interest36_max_90  \\\n",
       "502                          NaN                        NaN   \n",
       "6547                         NaN                        NaN   \n",
       "6938                         NaN                        NaN   \n",
       "3115                         NaN                        NaN   \n",
       "3649                         NaN                        NaN   \n",
       "\n",
       "      Rate_of_Interest36_std_90  Rate_of_Interest36_sum_360  \\\n",
       "502                         NaN                        7.40   \n",
       "6547                        NaN                       92.00   \n",
       "6938                        NaN                        0.00   \n",
       "3115                        NaN                        9.95   \n",
       "3649                        NaN                       62.00   \n",
       "\n",
       "      Rate_of_Interest36_mean_360  Rate_of_Interest36_max_360  \\\n",
       "502                          7.40                        7.40   \n",
       "6547                        18.40                       32.00   \n",
       "6938                          NaN                         NaN   \n",
       "3115                         9.95                        9.95   \n",
       "3649                        31.00                       42.00   \n",
       "\n",
       "      Rate_of_Interest36_min_360  Rate_of_Interest36_std_360  \\\n",
       "502                         7.40                    0.000000   \n",
       "6547                       14.50                    6.843975   \n",
       "6938                         NaN                         NaN   \n",
       "3115                        9.95                    0.000000   \n",
       "3649                       20.00                   11.000000   \n",
       "\n",
       "      Rate_of_Interest36_sum_9999  Rate_of_Interest36_mean_9999  \\\n",
       "502                         98.40                      9.840000   \n",
       "6547                       583.80                     12.973333   \n",
       "6938                         0.00                           NaN   \n",
       "3115                        47.44                     15.813333   \n",
       "3649                        62.00                     31.000000   \n",
       "\n",
       "      Rate_of_Interest36_max_9999  Rate_of_Interest36_min_9999  \\\n",
       "502                         24.35                         1.00   \n",
       "6547                        32.00                         1.40   \n",
       "6938                          NaN                          NaN   \n",
       "3115                        25.00                         9.95   \n",
       "3649                        42.00                        20.00   \n",
       "\n",
       "      Rate_of_Interest36_std_9999  Repayment_Tenure36_std_30  \\\n",
       "502                      5.559937                        NaN   \n",
       "6547                     6.082344                        NaN   \n",
       "6938                          NaN                        NaN   \n",
       "3115                     6.578198                        NaN   \n",
       "3649                    11.000000                        NaN   \n",
       "\n",
       "      Repayment_Tenure36_mean_90  Repayment_Tenure36_max_90  \\\n",
       "502                          NaN                        NaN   \n",
       "6547                         NaN                        NaN   \n",
       "6938                         0.0                        0.0   \n",
       "3115                         NaN                        NaN   \n",
       "3649                         NaN                        NaN   \n",
       "\n",
       "      Repayment_Tenure36_min_90  Repayment_Tenure36_std_90  \\\n",
       "502                         NaN                        NaN   \n",
       "6547                        NaN                        NaN   \n",
       "6938                        0.0                        0.0   \n",
       "3115                        NaN                        NaN   \n",
       "3649                        NaN                        NaN   \n",
       "\n",
       "      Repayment_Tenure36_sum_360  Repayment_Tenure36_mean_360  \\\n",
       "502                          9.0                          4.5   \n",
       "6547                        24.0                          4.8   \n",
       "6938                        30.0                          6.0   \n",
       "3115                        22.0                         11.0   \n",
       "3649                        24.0                          4.0   \n",
       "\n",
       "      Repayment_Tenure36_min_360  Repayment_Tenure36_std_360  \\\n",
       "502                          1.0                    3.500000   \n",
       "6547                         2.0                    4.118252   \n",
       "6938                         0.0                   12.000000   \n",
       "3115                        10.0                    1.000000   \n",
       "3649                         0.0                    8.944272   \n",
       "\n",
       "      Repayment_Tenure36_mean_9999  Repayment_Tenure36_min_9999  \\\n",
       "502                      11.818182                          0.0   \n",
       "6547                      3.446154                          0.0   \n",
       "6938                      6.000000                          0.0   \n",
       "3115                     11.600000                          0.0   \n",
       "3649                      1.937500                          0.0   \n",
       "\n",
       "      Repayment_Tenure36_std_9999  Income26_count_360  Income26_std_360  \\\n",
       "502                     16.433437                 2.0               NaN   \n",
       "6547                     6.589107                 5.0               NaN   \n",
       "6938                    12.000000                 5.0               NaN   \n",
       "3115                     7.631514                 2.0               NaN   \n",
       "3649                     5.942103                 6.0               NaN   \n",
       "\n",
       "      Open_Date29_max_30  Open_Date29_min_30  Open_Date29_mean_30  \\\n",
       "502                  NaN                 NaN                  NaN   \n",
       "6547                 NaN                 NaN                  NaN   \n",
       "6938                 NaN                 NaN                  NaN   \n",
       "3115                 NaN                 NaN                  NaN   \n",
       "3649                 NaN                 NaN                  NaN   \n",
       "\n",
       "      Open_Date29_nuniq_30  Open_Date29_maxcount_30  Open_Date29_max_90  \\\n",
       "502                    NaN                      NaN                 NaN   \n",
       "6547                   NaN                      NaN                 NaN   \n",
       "6938                   NaN                      NaN                89.0   \n",
       "3115                   NaN                      NaN                 NaN   \n",
       "3649                   NaN                      NaN                 NaN   \n",
       "\n",
       "      Open_Date29_mean_90  Open_Date29_mode_90  Open_Date29_nuniq_90  \\\n",
       "502                   NaN                  NaN                   NaN   \n",
       "6547                  NaN                  NaN                   NaN   \n",
       "6938                 89.0                 89.0                   1.0   \n",
       "3115                  NaN                  NaN                   NaN   \n",
       "3649                  NaN                  NaN                   NaN   \n",
       "\n",
       "      Open_Date29_maxcount_90  Open_Date29_max_360  Open_Date29_mean_360  \\\n",
       "502                       NaN                217.0            164.500000   \n",
       "6547                      NaN                353.0            300.800000   \n",
       "6938                      1.0                307.0            194.400000   \n",
       "3115                      NaN                304.0            219.000000   \n",
       "3649                      NaN                332.0            268.333333   \n",
       "\n",
       "      Open_Date29_mode_360  Open_Date29_nuniq_360  Open_Date29_maxcount_360  \\\n",
       "502                  112.0                    2.0                       1.0   \n",
       "6547                 212.0                    5.0                       1.0   \n",
       "6938                  89.0                    5.0                       1.0   \n",
       "3115                 134.0                    2.0                       1.0   \n",
       "3649                 244.0                    6.0                       1.0   \n",
       "\n",
       "      Open_Date29_max_9999  Open_Date29_mean_9999  Open_Date29_mode_9999  \\\n",
       "502                 2400.0            1173.500000                 1627.0   \n",
       "6547                1940.0             709.092308                  430.0   \n",
       "6938                 307.0             194.400000                   89.0   \n",
       "3115                1019.0             524.200000                  134.0   \n",
       "3649                1156.0             584.000000                  244.0   \n",
       "\n",
       "      Open_Date29_maxcount_9999  Portfolio_Type34_nuniq_30  \\\n",
       "502                         4.0                        NaN   \n",
       "6547                        3.0                        NaN   \n",
       "6938                        1.0                        NaN   \n",
       "3115                        1.0                        NaN   \n",
       "3649                        1.0                        NaN   \n",
       "\n",
       "      Portfolio_Type34_nuniq_90  Portfolio_Type34_nuniq_360  \\\n",
       "502                         NaN                         1.0   \n",
       "6547                        NaN                         1.0   \n",
       "6938                        1.0                         1.0   \n",
       "3115                        NaN                         1.0   \n",
       "3649                        NaN                         2.0   \n",
       "\n",
       "      Portfolio_Type34_nuniq_9999  Account_Type32_nuniq_30  \\\n",
       "502                           2.0                      NaN   \n",
       "6547                          3.0                      NaN   \n",
       "6938                          1.0                      NaN   \n",
       "3115                          1.0                      NaN   \n",
       "3649                          2.0                      NaN   \n",
       "\n",
       "      Account_Type32_nuniq_90  Account_Type32_nuniq_360  \\\n",
       "502                       NaN                       2.0   \n",
       "6547                      NaN                       2.0   \n",
       "6938                      1.0                       2.0   \n",
       "3115                      NaN                       2.0   \n",
       "3649                      NaN                       4.0   \n",
       "\n",
       "      Account_Type32_nuniq_9999  Occupation_Code35_nuniq_30  \\\n",
       "502                         5.0                         NaN   \n",
       "6547                        8.0                         NaN   \n",
       "6938                        2.0                         NaN   \n",
       "3115                        5.0                         NaN   \n",
       "3649                        4.0                         NaN   \n",
       "\n",
       "      Occupation_Code35_nuniq_90  Occupation_Code35_nuniq_360  \\\n",
       "502                          NaN                          1.0   \n",
       "6547                         NaN                          1.0   \n",
       "6938                         1.0                          1.0   \n",
       "3115                         NaN                          1.0   \n",
       "3649                         NaN                          1.0   \n",
       "\n",
       "      Occupation_Code35_nuniq_9999  AccountHoldertypeCode41_nuniq_90  \\\n",
       "502                            1.0                               NaN   \n",
       "6547                           1.0                               NaN   \n",
       "6938                           1.0                               1.0   \n",
       "3115                           1.0                               NaN   \n",
       "3649                           2.0                               NaN   \n",
       "\n",
       "      AccountHoldertypeCode41_nuniq_360  AccountHoldertypeCode41_nuniq_9999  \\\n",
       "502                                 1.0                                 2.0   \n",
       "6547                                1.0                                 2.0   \n",
       "6938                                1.0                                 1.0   \n",
       "3115                                1.0                                 1.0   \n",
       "3649                                1.0                                 1.0   \n",
       "\n",
       "      Payment_History_Profile43_mode_30  Payment_History_Profile43_mode_90  \\\n",
       "502                                   0                                  0   \n",
       "6547                                  0                                  0   \n",
       "6938                                  0                                  1   \n",
       "3115                                  0                                  0   \n",
       "3649                                  0                                  0   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_90  Payment_History_Profile43_mode_360  \\\n",
       "502                                  NaN                                  36   \n",
       "6547                                 NaN                                  36   \n",
       "6938                                 1.0                                   1   \n",
       "3115                                 NaN                                  36   \n",
       "3649                                 NaN                                  36   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_360  \\\n",
       "502                                   2.0   \n",
       "6547                                  4.0   \n",
       "6938                                  4.0   \n",
       "3115                                  2.0   \n",
       "3649                                  4.0   \n",
       "\n",
       "      Payment_History_Profile43_mode_9999  \\\n",
       "502                                    36   \n",
       "6547                                   36   \n",
       "6938                                    1   \n",
       "3115                                   36   \n",
       "3649                                   36   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_9999  Date_Closed31_nuniq_30  \\\n",
       "502                                   19.0                     NaN   \n",
       "6547                                  30.0                     NaN   \n",
       "6938                                   4.0                     NaN   \n",
       "3115                                   5.0                     NaN   \n",
       "3649                                  12.0                     NaN   \n",
       "\n",
       "      Date_Closed31_maxcount_30  Date_Closed31_max_90  Date_Closed31_min_90  \\\n",
       "502                         NaN                   NaN                   NaN   \n",
       "6547                        NaN                   NaN                   NaN   \n",
       "6938                        NaN                   NaN                   NaN   \n",
       "3115                        NaN                   NaN                   NaN   \n",
       "3649                        NaN                   NaN                   NaN   \n",
       "\n",
       "      Date_Closed31_mean_90  Date_Closed31_mode_90  Date_Closed31_nuniq_90  \\\n",
       "502                     NaN                    NaN                     NaN   \n",
       "6547                    NaN                    NaN                     NaN   \n",
       "6938                    NaN                    0.0                     1.0   \n",
       "3115                    NaN                    NaN                     NaN   \n",
       "3649                    NaN                    NaN                     NaN   \n",
       "\n",
       "      Date_Closed31_maxcount_90  Date_Closed31_min_360  \\\n",
       "502                         NaN                    NaN   \n",
       "6547                        NaN                   30.0   \n",
       "6938                        0.0                   91.0   \n",
       "3115                        NaN                    NaN   \n",
       "3649                        NaN                   74.0   \n",
       "\n",
       "      Date_Closed31_mode_360  Date_Closed31_nuniq_360  \\\n",
       "502                      0.0                      1.0   \n",
       "6547                    30.0                      3.0   \n",
       "6938                    91.0                      4.0   \n",
       "3115                     0.0                      1.0   \n",
       "3649                    74.0                      2.0   \n",
       "\n",
       "      Date_Closed31_maxcount_360  Date_Closed31_max_9999  \\\n",
       "502                          0.0                  1790.0   \n",
       "6547                         3.0                  1327.0   \n",
       "6938                         1.0                   222.0   \n",
       "3115                         0.0                   660.0   \n",
       "3649                         1.0                   939.0   \n",
       "\n",
       "      Date_Closed31_min_9999  Date_Closed31_mean_9999  \\\n",
       "502                    217.0               792.642857   \n",
       "6547                    30.0               504.517241   \n",
       "6938                    91.0               156.666667   \n",
       "3115                   124.0               392.000000   \n",
       "3649                    51.0               523.777778   \n",
       "\n",
       "      Date_Closed31_mode_9999  Date_Closed31_nuniq_9999  \\\n",
       "502                     217.0                      15.0   \n",
       "6547                     30.0                      38.0   \n",
       "6938                     91.0                       4.0   \n",
       "3115                    124.0                       3.0   \n",
       "3649                     51.0                      10.0   \n",
       "\n",
       "      Date_of_Last_Payment40_nuniq_30  Date_of_Last_Payment40_maxcount_30  \\\n",
       "502                               NaN                                 NaN   \n",
       "6547                              NaN                                 NaN   \n",
       "6938                              NaN                                 NaN   \n",
       "3115                              NaN                                 NaN   \n",
       "3649                              NaN                                 NaN   \n",
       "\n",
       "      Date_of_Last_Payment40_min_90  Date_of_Last_Payment40_nuniq_90  \\\n",
       "502                             NaN                              NaN   \n",
       "6547                            NaN                              NaN   \n",
       "6938                            NaN                              1.0   \n",
       "3115                            NaN                              NaN   \n",
       "3649                            NaN                              NaN   \n",
       "\n",
       "      Date_of_Last_Payment40_maxcount_90  Date_of_Last_Payment40_max_360  \\\n",
       "502                                  NaN                            73.0   \n",
       "6547                                 NaN                           212.0   \n",
       "6938                                 0.0                           222.0   \n",
       "3115                                 NaN                           119.0   \n",
       "3649                                 NaN                           100.0   \n",
       "\n",
       "      Date_of_Last_Payment40_min_360  Date_of_Last_Payment40_mean_360  \\\n",
       "502                             73.0                            73.00   \n",
       "6547                            31.0                           101.40   \n",
       "6938                            91.0                           154.25   \n",
       "3115                            33.0                            76.00   \n",
       "3649                            50.0                            69.20   \n",
       "\n",
       "      Date_of_Last_Payment40_mode_360  Date_of_Last_Payment40_nuniq_360  \\\n",
       "502                              73.0                               2.0   \n",
       "6547                             31.0                               3.0   \n",
       "6938                             91.0                               5.0   \n",
       "3115                             33.0                               2.0   \n",
       "3649                             50.0                               6.0   \n",
       "\n",
       "      Date_of_Last_Payment40_maxcount_360  Date_of_Last_Payment40_max_9999  \\\n",
       "502                                   1.0                           1957.0   \n",
       "6547                                  3.0                           1327.0   \n",
       "6938                                  1.0                            222.0   \n",
       "3115                                  1.0                            660.0   \n",
       "3649                                  1.0                            941.0   \n",
       "\n",
       "      Date_of_Last_Payment40_min_9999  Date_of_Last_Payment40_mean_9999  \\\n",
       "502                              73.0                        713.952381   \n",
       "6547                             31.0                        490.000000   \n",
       "6938                             91.0                        154.250000   \n",
       "3115                             33.0                        197.400000   \n",
       "3649                             35.0                        285.461538   \n",
       "\n",
       "      Date_of_Last_Payment40_mode_9999  Date_of_Last_Payment40_maxcount_9999  \\\n",
       "502                              564.0                                   2.0   \n",
       "6547                              31.0                                   8.0   \n",
       "6938                              91.0                                   1.0   \n",
       "3115                              33.0                                   1.0   \n",
       "3649                              53.0                                   2.0   \n",
       "\n",
       "      Date_Reported33_nuniq_30  Date_Reported33_max_90  \\\n",
       "502                        NaN                     NaN   \n",
       "6547                       NaN                     NaN   \n",
       "6938                       NaN                    60.0   \n",
       "3115                       NaN                     NaN   \n",
       "3649                       NaN                     NaN   \n",
       "\n",
       "      Date_Reported33_mean_90  Date_Reported33_mode_90  \\\n",
       "502                       NaN                      NaN   \n",
       "6547                      NaN                      NaN   \n",
       "6938                     60.0                     60.0   \n",
       "3115                      NaN                      NaN   \n",
       "3649                      NaN                      NaN   \n",
       "\n",
       "      Date_Reported33_nuniq_90  Date_Reported33_maxcount_90  \\\n",
       "502                        NaN                          NaN   \n",
       "6547                       NaN                          NaN   \n",
       "6938                       1.0                          1.0   \n",
       "3115                       NaN                          NaN   \n",
       "3649                       NaN                          NaN   \n",
       "\n",
       "      Date_Reported33_max_360  Date_Reported33_mean_360  \\\n",
       "502                      44.0                      44.0   \n",
       "6547                    181.0                      64.8   \n",
       "6938                    213.0                     115.2   \n",
       "3115                     58.0                      42.5   \n",
       "3649                     58.0                      48.0   \n",
       "\n",
       "      Date_Reported33_mode_360  Date_Reported33_nuniq_360  \\\n",
       "502                       44.0                        1.0   \n",
       "6547                      28.0                        3.0   \n",
       "6938                      60.0                        4.0   \n",
       "3115                      27.0                        2.0   \n",
       "3649                      58.0                        2.0   \n",
       "\n",
       "      Date_Reported33_maxcount_360  Date_Reported33_max_9999  \\\n",
       "502                            2.0                     989.0   \n",
       "6547                           3.0                    1854.0   \n",
       "6938                           2.0                     213.0   \n",
       "3115                           1.0                     576.0   \n",
       "3649                           4.0                     912.0   \n",
       "\n",
       "      Date_Reported33_mean_9999  Date_Reported33_mode_9999  \\\n",
       "502                  281.136364                      258.0   \n",
       "6547                 431.246154                      303.0   \n",
       "6938                 115.200000                       60.0   \n",
       "3115                 161.400000                       27.0   \n",
       "3649                 269.625000                       28.0   \n",
       "\n",
       "      Date_Reported33_nuniq_9999  Date_Reported33_maxcount_9999  \\\n",
       "502                         11.0                            5.0   \n",
       "6547                        26.0                           12.0   \n",
       "6938                         4.0                            2.0   \n",
       "3115                         4.0                            2.0   \n",
       "3649                         8.0                            5.0   \n",
       "\n",
       "      DateOfAddition34_nuniq_30  DateOfAddition34_max_90  \\\n",
       "502                         NaN                      NaN   \n",
       "6547                        NaN                      NaN   \n",
       "6938                        NaN                     60.0   \n",
       "3115                        NaN                      NaN   \n",
       "3649                        NaN                      NaN   \n",
       "\n",
       "      DateOfAddition34_mean_90  DateOfAddition34_mode_90  \\\n",
       "502                        NaN                       NaN   \n",
       "6547                       NaN                       NaN   \n",
       "6938                      60.0                      60.0   \n",
       "3115                       NaN                       NaN   \n",
       "3649                       NaN                       NaN   \n",
       "\n",
       "      DateOfAddition34_nuniq_90  DateOfAddition34_maxcount_90  \\\n",
       "502                         NaN                           NaN   \n",
       "6547                        NaN                           NaN   \n",
       "6938                        1.0                           1.0   \n",
       "3115                        NaN                           NaN   \n",
       "3649                        NaN                           NaN   \n",
       "\n",
       "      DateOfAddition34_max_360  DateOfAddition34_mean_360  \\\n",
       "502                      197.0                 151.000000   \n",
       "6547                     303.0                 272.600000   \n",
       "6938                     303.0                 182.200000   \n",
       "3115                     300.0                 209.500000   \n",
       "3649                     301.0                 246.666667   \n",
       "\n",
       "      DateOfAddition34_mode_360  DateOfAddition34_nuniq_360  \\\n",
       "502                       105.0                         2.0   \n",
       "6547                      303.0                         3.0   \n",
       "6938                      213.0                         4.0   \n",
       "3115                      119.0                         2.0   \n",
       "3649                      242.0                         3.0   \n",
       "\n",
       "      DateOfAddition34_maxcount_360  DateOfAddition34_max_9999  \\\n",
       "502                             1.0                     2115.0   \n",
       "6547                            3.0                     1885.0   \n",
       "6938                            2.0                      303.0   \n",
       "3115                            1.0                     1003.0   \n",
       "3649                            4.0                     1154.0   \n",
       "\n",
       "      DateOfAddition34_mean_9999  DateOfAddition34_mode_9999  \\\n",
       "502                   771.045455                       197.0   \n",
       "6547                  658.938462                       485.0   \n",
       "6938                  182.200000                       213.0   \n",
       "3115                  508.600000                       119.0   \n",
       "3649                  560.937500                       242.0   \n",
       "\n",
       "      DateOfAddition34_nuniq_9999  DateOfAddition34_maxcount_9999  \\\n",
       "502                          15.0                             5.0   \n",
       "6547                         27.0                             5.0   \n",
       "6938                          4.0                             2.0   \n",
       "3115                          5.0                             1.0   \n",
       "3649                         12.0                             4.0   \n",
       "\n",
       "      Account_Status34_mode_30  Account_Status34_nuniq_30  \\\n",
       "502                        NaN                        NaN   \n",
       "6547                       NaN                        NaN   \n",
       "6938                       NaN                        NaN   \n",
       "3115                       NaN                        NaN   \n",
       "3649                       NaN                        NaN   \n",
       "\n",
       "      Account_Status34_mode_90  Account_Status34_nuniq_90  \\\n",
       "502                        NaN                        NaN   \n",
       "6547                       NaN                        NaN   \n",
       "6938                      11.0                        1.0   \n",
       "3115                       NaN                        NaN   \n",
       "3649                       NaN                        NaN   \n",
       "\n",
       "      Account_Status34_mode_360  Account_Status34_nuniq_360  \\\n",
       "502                        11.0                         2.0   \n",
       "6547                       13.0                         2.0   \n",
       "6938                       13.0                         2.0   \n",
       "3115                       11.0                         1.0   \n",
       "3649                       11.0                         2.0   \n",
       "\n",
       "      Account_Status34_nuniq_9999  Month50_sum_30  Month50_max_30  \\\n",
       "502                           4.0             NaN             NaN   \n",
       "6547                          8.0             NaN             NaN   \n",
       "6938                          2.0             NaN             NaN   \n",
       "3115                          2.0             NaN             NaN   \n",
       "3649                          2.0             NaN             NaN   \n",
       "\n",
       "      Month50_std_30  Month50_sum_90  Month50_mean_90  Month50_max_90  \\\n",
       "502              NaN             NaN              NaN             NaN   \n",
       "6547             NaN             NaN              NaN             NaN   \n",
       "6938             NaN             8.0              8.0             8.0   \n",
       "3115             NaN             NaN              NaN             NaN   \n",
       "3649             NaN             NaN              NaN             NaN   \n",
       "\n",
       "      Month50_min_90  Month50_std_90  Month50_sum_360  Month50_min_360  \\\n",
       "502              NaN             NaN             20.0             10.0   \n",
       "6547             NaN             NaN             54.0              7.0   \n",
       "6938             8.0             0.0             35.0              3.0   \n",
       "3115             NaN             NaN             19.0              9.0   \n",
       "3649             NaN             NaN             54.0              8.0   \n",
       "\n",
       "      Month50_std_360  Month50_sum_9999  Month50_mean_9999  Month50_max_9999  \\\n",
       "502          0.000000             239.0          10.863636              12.0   \n",
       "6547         1.939072             681.0          10.476923              12.0   \n",
       "6938         3.033150              35.0           7.000000              12.0   \n",
       "3115         0.500000              55.0          11.000000              12.0   \n",
       "3649         1.414214             165.0          10.312500              12.0   \n",
       "\n",
       "      Month50_min_9999  Month50_std_9999  Days_Past_Due58_max_30  \\\n",
       "502                3.0          2.095351                     NaN   \n",
       "6547               1.0          2.637643                     NaN   \n",
       "6938               3.0          3.033150                     NaN   \n",
       "3115               9.0          1.264911                     NaN   \n",
       "3649               4.0          2.310810                     NaN   \n",
       "\n",
       "      Days_Past_Due58_min_30  Days_Past_Due58_mean_90  Days_Past_Due58_max_90  \\\n",
       "502                      NaN                      NaN                     NaN   \n",
       "6547                     NaN                      NaN                     NaN   \n",
       "6938                     NaN                      0.0                     0.0   \n",
       "3115                     NaN                      NaN                     NaN   \n",
       "3649                     NaN                      NaN                     NaN   \n",
       "\n",
       "      Days_Past_Due58_min_90  Days_Past_Due58_std_90  Days_Past_Due58_sum_360  \\\n",
       "502                      NaN                     NaN                      0.0   \n",
       "6547                     NaN                     NaN                    389.0   \n",
       "6938                     0.0                     0.0                     26.0   \n",
       "3115                     NaN                     NaN                      0.0   \n",
       "3649                     NaN                     NaN                     23.0   \n",
       "\n",
       "      Days_Past_Due58_mean_360  Days_Past_Due58_max_360  ...  \\\n",
       "502                   0.000000                      0.0  ...   \n",
       "6547                 77.800000                    206.0  ...   \n",
       "6938                  5.200000                     26.0  ...   \n",
       "3115                  0.000000                      0.0  ...   \n",
       "3649                  3.833333                     22.0  ...   \n",
       "\n",
       "      feature_1031_sms  feature_1032_sms  feature_1033_sms  feature_1034_sms  \\\n",
       "502                  7               783                21                 3   \n",
       "6547                 1               251                21                17   \n",
       "6938                 5               327                21                 0   \n",
       "3115                 6               381                21                 6   \n",
       "3649                 6               482                21                29   \n",
       "\n",
       "      feature_1035_sms  feature_1036_sms  feature_1037_sms  feature_1038_sms  \\\n",
       "502                  4               192                 1                 4   \n",
       "6547                 1                98                 3                 4   \n",
       "6938                 0                96                 2                17   \n",
       "3115                 8                42                 2                 9   \n",
       "3649                10               141                 0                 5   \n",
       "\n",
       "      feature_1039_sms  feature_1040_sms  feature_1041_sms  feature_1042_sms  \\\n",
       "502                 69                 1                 1                87   \n",
       "6547                33                 0                 1                16   \n",
       "6938                46                 0                 1                28   \n",
       "3115                75                 2                 1                19   \n",
       "3649                14                 0                 1                44   \n",
       "\n",
       "      feature_1043_sms  feature_1044_sms  feature_1045_sms  feature_1046_sms  \\\n",
       "502                  0               290                 5                52   \n",
       "6547                 0                34                11                29   \n",
       "6938                 9                83                11                20   \n",
       "3115                 0               154                 7                43   \n",
       "3649                 0               138                 5                59   \n",
       "\n",
       "      feature_1047_sms  feature_1048_sms  feature_1049_sms  feature_1050_sms  \\\n",
       "502                 65                 9               905                30   \n",
       "6547                 2                 2               303                30   \n",
       "6938                 8                 6               464                30   \n",
       "3115                 7                 6               441                30   \n",
       "3649                27                 9               677                30   \n",
       "\n",
       "      feature_1051_sms  feature_1052_sms  feature_1053_sms  feature_1054_sms  \\\n",
       "502                  5                 5               220                 1   \n",
       "6547                20                 3               111                 4   \n",
       "6938                 1                 0               157                 2   \n",
       "3115                 9                 9                53                 2   \n",
       "3649                41                16               178                 3   \n",
       "\n",
       "      feature_1055_sms  feature_1056_sms  feature_1057_sms  feature_1058_sms  \\\n",
       "502                  4                74                 1                 1   \n",
       "6547                 4                38                 0                 1   \n",
       "6938                22                58                 0                 1   \n",
       "3115                11                87                 2                 2   \n",
       "3649                 8                29                 0                 3   \n",
       "\n",
       "      feature_1059_sms  feature_1060_sms  feature_1061_sms  feature_1062_sms  \\\n",
       "502                 89                 0               330                 5   \n",
       "6547                17                 1                36                16   \n",
       "6938                36                11               114                17   \n",
       "3115                22                 0               167                 9   \n",
       "3649                66                 0               174                 7   \n",
       "\n",
       "      feature_1063_sms  feature_1064_sms  feature_1065_sms  feature_1066_sms  \\\n",
       "502                 60               101                 9              1227   \n",
       "6547                39                10                 3               568   \n",
       "6938                24                14                 7               972   \n",
       "3115                53                 9                 6               629   \n",
       "3649                93                40                19              1121   \n",
       "\n",
       "      feature_1067_sms  feature_1068_sms  feature_1069_sms  feature_1070_sms  \\\n",
       "502                 56                 6                 5               271   \n",
       "6547                60                36                 4               184   \n",
       "6938                60                 2                 0               374   \n",
       "3115                60                12                12                87   \n",
       "3649                60                75                25               266   \n",
       "\n",
       "      feature_1071_sms  feature_1072_sms  feature_1073_sms  feature_1074_sms  \\\n",
       "502                  4                 5                98                 1   \n",
       "6547                 7                 7                63                 0   \n",
       "6938                 2                22               112                 0   \n",
       "3115                 2                17               115                 2   \n",
       "3649                 3                13                52                 0   \n",
       "\n",
       "      feature_1075_sms  feature_1076_sms  feature_1077_sms  feature_1078_sms  \\\n",
       "502                  1               119                 2               416   \n",
       "6547                 1                34                 1                84   \n",
       "6938                 2                48                21               260   \n",
       "3115                 2                39                 1               207   \n",
       "3649                 7               124                 0               316   \n",
       "\n",
       "      feature_1079_sms  feature_1080_sms  feature_1081_sms  feature_1082_sms  \\\n",
       "502                 26                91               166                16   \n",
       "6547                32                83                23                 9   \n",
       "6938                36                48                33                12   \n",
       "3115                32                71                20                10   \n",
       "3649                16               130                67                27   \n",
       "\n",
       "      feature_1083_sms  feature_1084_sms  feature_1085_sms  feature_1086_sms  \\\n",
       "502               2999               173                28                 9   \n",
       "6547              3000               283               291                88   \n",
       "6938              2975               167                11                10   \n",
       "3115              1129               265                28                27   \n",
       "3649              3000               159               156                57   \n",
       "\n",
       "      feature_1087_sms  feature_1088_sms  feature_1089_sms  feature_1090_sms  \\\n",
       "502                723                 7                 6               265   \n",
       "6547               719                13                39               212   \n",
       "6938              1199                 2                25               395   \n",
       "3115               138                 3                21               129   \n",
       "3649               725                14                31               143   \n",
       "\n",
       "      feature_1091_sms  feature_1092_sms  feature_1093_sms  feature_1094_sms  \\\n",
       "502                  1                 2               171                12   \n",
       "6547                 0                 3               186                 6   \n",
       "6938                 0                 6               102                89   \n",
       "3115                 2                 3                59                 6   \n",
       "3649                 0                13               252                 1   \n",
       "\n",
       "      feature_1095_sms  feature_1096_sms  feature_1097_sms  feature_1098_sms  \\\n",
       "502               1088                49               201               390   \n",
       "6547               461               141               424               378   \n",
       "6938               669               162               185                84   \n",
       "3115               295                42               168               181   \n",
       "3649              1047                52               256               174   \n",
       "\n",
       "      feature_1099_sms  feature_1100_sms  feature_1101_sms  feature_1102_sms  \\\n",
       "502                 42         45.666667         45.666667          0.045682   \n",
       "6547                35         13.333333         13.333333          0.013333   \n",
       "6938                36         24.000000         24.000000          0.024202   \n",
       "3115                27         24.333333         24.333333          0.064659   \n",
       "3649                79         19.000000         19.000000          0.019000   \n",
       "\n",
       "      feature_1103_sms  feature_1104_sms  feature_1105_sms  feature_1106_sms  \\\n",
       "502           0.333333          0.007299          0.000000          0.000000   \n",
       "6547          0.666667          0.050000          0.333333          0.025000   \n",
       "6938          0.000000          0.000000          0.000000          0.000000   \n",
       "3115          0.333333          0.013699          0.666667          0.027397   \n",
       "3649          2.666667          0.140351          0.666667          0.035088   \n",
       "\n",
       "      feature_1107_sms  feature_1108_sms  feature_1109_sms  feature_1110_sms  \\\n",
       "502           7.000000          0.153285          0.000000          0.000000   \n",
       "6547          4.333333          0.325000          0.000000          0.000000   \n",
       "6938          6.000000          0.250000          0.333333          0.013889   \n",
       "3115          3.333333          0.136986          0.000000          0.000000   \n",
       "3649          6.000000          0.315789          0.000000          0.000000   \n",
       "\n",
       "      feature_1111_sms  feature_1112_sms  feature_1113_sms  feature_1114_sms  \\\n",
       "502           0.000000          0.000000          8.000000          0.175182   \n",
       "6547          1.000000          0.075000          2.333333          0.175000   \n",
       "6938          0.000000          0.000000          3.000000          0.125000   \n",
       "3115          0.333333          0.013699          4.000000          0.164384   \n",
       "3649          0.000000          0.000000          0.333333          0.017544   \n",
       "\n",
       "      feature_1115_sms  feature_1116_sms  feature_1117_sms  feature_1118_sms  \\\n",
       "502           0.333333          0.007299          0.333333          0.007299   \n",
       "6547          0.000000          0.000000          0.000000          0.000000   \n",
       "6938          0.000000          0.000000          0.333333          0.013889   \n",
       "3115          0.000000          0.000000          0.000000          0.000000   \n",
       "3649          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "      feature_1119_sms  feature_1120_sms  feature_1121_sms  feature_1122_sms  \\\n",
       "502           5.000000          0.109489          0.000000          0.000000   \n",
       "6547          2.000000          0.150000          0.000000          0.000000   \n",
       "6938          2.333333          0.097222          0.666667          0.027778   \n",
       "3115          0.666667          0.027397          0.000000          0.000000   \n",
       "3649          1.333333          0.070175          0.000000          0.000000   \n",
       "\n",
       "      feature_1123_sms  feature_1124_sms  feature_1125_sms  feature_1126_sms  \\\n",
       "502          14.000000          0.306569          1.000000          0.021898   \n",
       "6547          1.333333          0.100000          0.000000          0.000000   \n",
       "6938          8.000000          0.333333          0.666667          0.027778   \n",
       "3115         10.666667          0.438356          0.666667          0.027397   \n",
       "3649          4.333333          0.228070          0.000000          0.000000   \n",
       "\n",
       "      feature_1127_sms  feature_1128_sms  feature_1129_sms  feature_1130_sms  \\\n",
       "502           5.666667          0.124088          2.333333          0.051095   \n",
       "6547          1.333333          0.100000          0.000000          0.000000   \n",
       "6938          2.000000          0.083333          0.000000          0.000000   \n",
       "3115          3.333333          0.136986          0.333333          0.013699   \n",
       "3649          0.666667          0.035088          2.333333          0.122807   \n",
       "\n",
       "      feature_1131_sms  feature_1132_sms  feature_1133_sms  feature_1134_sms  \\\n",
       "502           1.666667          0.036496         42.142857         42.142857   \n",
       "6547          0.000000          0.000000         12.571429         12.571429   \n",
       "6938          0.666667          0.027778         19.285714         19.285714   \n",
       "3115          0.000000          0.000000         21.714286         21.714286   \n",
       "3649          0.666667          0.035088         23.142857         23.142857   \n",
       "\n",
       "      feature_1135_sms  feature_1136_sms  feature_1137_sms  feature_1138_sms  \\\n",
       "502           0.098366          0.142857          0.003390          0.142857   \n",
       "6547          0.029333          1.428571          0.113636          0.142857   \n",
       "6938          0.045378          0.000000          0.000000          0.000000   \n",
       "3115          0.134632          0.285714          0.013158          1.000000   \n",
       "3649          0.054000          2.000000          0.086420          0.428571   \n",
       "\n",
       "      feature_1139_sms  feature_1140_sms  feature_1141_sms  feature_1142_sms  \\\n",
       "502           0.003390          8.857143          0.210169          0.000000   \n",
       "6547          0.011364          4.571429          0.363636          0.000000   \n",
       "6938          0.000000          5.000000          0.259259          0.285714   \n",
       "3115          0.046053          2.000000          0.092105          0.285714   \n",
       "3649          0.018519          9.285714          0.401235          0.000000   \n",
       "\n",
       "      feature_1143_sms  feature_1144_sms  feature_1145_sms  feature_1146_sms  \\\n",
       "502           0.000000          0.142857          0.003390          4.142857   \n",
       "6547          0.000000          0.428571          0.034091          1.571429   \n",
       "6938          0.014815          0.571429          0.029630          2.571429   \n",
       "3115          0.013158          0.142857          0.006579          3.571429   \n",
       "3649          0.000000          0.000000          0.000000          0.571429   \n",
       "\n",
       "      feature_1147_sms  feature_1148_sms  feature_1149_sms  feature_1150_sms  \\\n",
       "502           0.098305          0.142857           0.00339          0.142857   \n",
       "6547          0.125000          0.000000           0.00000          0.000000   \n",
       "6938          0.133333          0.000000           0.00000          0.142857   \n",
       "3115          0.164474          0.000000           0.00000          0.142857   \n",
       "3649          0.024691          0.000000           0.00000          0.000000   \n",
       "\n",
       "      feature_1151_sms  feature_1152_sms  feature_1153_sms  feature_1154_sms  \\\n",
       "502           0.003390          4.428571          0.105085          0.000000   \n",
       "6547          0.000000          1.428571          0.113636          0.000000   \n",
       "6938          0.007407          1.714286          0.088889          0.428571   \n",
       "3115          0.006579          1.285714          0.059211          0.000000   \n",
       "3649          0.000000          1.285714          0.055556          0.000000   \n",
       "\n",
       "      feature_1155_sms  feature_1156_sms  feature_1157_sms  feature_1158_sms  \\\n",
       "502           0.000000         15.857143          0.376271          0.714286   \n",
       "6547          0.000000          1.714286          0.136364          0.428571   \n",
       "6938          0.022222          5.428571          0.281481          0.571429   \n",
       "3115          0.000000          8.142857          0.375000          0.285714   \n",
       "3649          0.000000          6.714286          0.290123          0.000000   \n",
       "\n",
       "      feature_1159_sms  feature_1160_sms  feature_1161_sms  feature_1162_sms  \\\n",
       "502           0.016949          3.857143          0.091525          2.857143   \n",
       "6547          0.034091          0.714286          0.056818          0.000000   \n",
       "6938          0.029630          1.571429          0.081481          0.571429   \n",
       "3115          0.013158          3.000000          0.138158          0.714286   \n",
       "3649          0.000000          1.571429          0.067901          1.000000   \n",
       "\n",
       "      feature_1163_sms  feature_1164_sms  feature_1165_sms  feature_1166_sms  \\\n",
       "502           0.067797          0.714286          0.016949         38.214286   \n",
       "6547          0.000000          0.142857          0.011364         13.071429   \n",
       "6938          0.029630          0.428571          0.022222         18.357143   \n",
       "3115          0.032895          0.857143          0.039474         19.571429   \n",
       "3649          0.043210          0.285714          0.012346         24.000000   \n",
       "\n",
       "      feature_1167_sms  feature_1168_sms  feature_1169_sms  feature_1170_sms  \\\n",
       "502          38.214286          0.178393          0.214286          0.005607   \n",
       "6547         13.071429          0.061000          1.214286          0.092896   \n",
       "6938         18.357143          0.086387          0.000000          0.000000   \n",
       "3115         19.571429          0.242693          0.357143          0.018248   \n",
       "3649         24.000000          0.112000          1.428571          0.059524   \n",
       "\n",
       "      feature_1171_sms  feature_1172_sms  feature_1173_sms  feature_1174_sms  \\\n",
       "502           0.071429          0.001869          9.714286          0.254206   \n",
       "6547          0.071429          0.005464          5.142857          0.393443   \n",
       "6938          0.000000          0.000000          4.928571          0.268482   \n",
       "3115          0.500000          0.025547          1.857143          0.094891   \n",
       "3649          0.214286          0.008929          8.285714          0.345238   \n",
       "\n",
       "      feature_1175_sms  feature_1176_sms  feature_1177_sms  feature_1178_sms  \\\n",
       "502           0.071429          0.001869          0.071429          0.001869   \n",
       "6547          0.142857          0.010929          0.285714          0.021858   \n",
       "6938          0.142857          0.007782          0.714286          0.038911   \n",
       "3115          0.142857          0.007299          0.642857          0.032847   \n",
       "3649          0.000000          0.000000          0.071429          0.002976   \n",
       "\n",
       "      feature_1179_sms  feature_1180_sms  feature_1181_sms  feature_1182_sms  \\\n",
       "502           3.071429          0.080374          0.071429          0.001869   \n",
       "6547          1.428571          0.109290          0.000000          0.000000   \n",
       "6938          2.571429          0.140078          0.000000          0.000000   \n",
       "3115          3.571429          0.182482          0.071429          0.003650   \n",
       "3649          0.642857          0.026786          0.000000          0.000000   \n",
       "\n",
       "      feature_1183_sms  feature_1184_sms  feature_1185_sms  feature_1186_sms  \\\n",
       "502           0.071429          0.001869          4.785714          0.125234   \n",
       "6547          0.000000          0.000000          1.142857          0.087432   \n",
       "6938          0.071429          0.003891          1.714286          0.093385   \n",
       "3115          0.071429          0.003650          1.071429          0.054745   \n",
       "3649          0.000000          0.000000          1.857143          0.077381   \n",
       "\n",
       "      feature_1187_sms  feature_1188_sms  feature_1189_sms  feature_1190_sms  \\\n",
       "502                0.0          0.000000         14.071429          0.368224   \n",
       "6547               0.0          0.000000          1.785714          0.136612   \n",
       "6938               0.5          0.027237          5.285714          0.287938   \n",
       "3115               0.0          0.000000          7.714286          0.394161   \n",
       "3649               0.0          0.000000          6.857143          0.285714   \n",
       "\n",
       "      feature_1191_sms  feature_1192_sms  feature_1193_sms  feature_1194_sms  \\\n",
       "502           0.357143          0.009346          2.642857          0.069159   \n",
       "6547          0.642857          0.049180          1.142857          0.087432   \n",
       "6938          0.500000          0.027237          1.142857          0.062257   \n",
       "3115          0.285714          0.014599          2.357143          0.120438   \n",
       "3649          0.071429          0.002976          3.000000          0.125000   \n",
       "\n",
       "      feature_1195_sms  feature_1196_sms  feature_1197_sms  feature_1198_sms  \\\n",
       "502           2.500000          0.065421          0.500000          0.013084   \n",
       "6547          0.000000          0.000000          0.071429          0.005464   \n",
       "6938          0.428571          0.023346          0.357143          0.019455   \n",
       "3115          0.500000          0.025547          0.428571          0.021898   \n",
       "3649          1.142857          0.047619          0.428571          0.017857   \n",
       "\n",
       "      feature_1199_sms  feature_1200_sms  feature_1201_sms  feature_1202_sms  \\\n",
       "502          37.285714         37.285714          0.261087          0.142857   \n",
       "6547         11.952381         11.952381          0.083667          0.809524   \n",
       "6938         15.571429         15.571429          0.109916          0.000000   \n",
       "3115         18.142857         18.142857          0.337467          0.285714   \n",
       "3649         22.952381         22.952381          0.160667          1.380952   \n",
       "\n",
       "      feature_1203_sms  feature_1204_sms  feature_1205_sms  feature_1206_sms  \\\n",
       "502           0.003831          0.190476          0.005109          9.142857   \n",
       "6547          0.067729          0.047619          0.003984          4.666667   \n",
       "6938          0.000000          0.000000          0.000000          4.571429   \n",
       "3115          0.015748          0.380952          0.020997          2.000000   \n",
       "3649          0.060166          0.476190          0.020747          6.714286   \n",
       "\n",
       "      feature_1207_sms  feature_1208_sms  feature_1209_sms  feature_1210_sms  \\\n",
       "502           0.245211          0.047619          0.001277          0.190476   \n",
       "6547          0.390438          0.142857          0.011952          0.190476   \n",
       "6938          0.293578          0.095238          0.006116          0.809524   \n",
       "3115          0.110236          0.095238          0.005249          0.428571   \n",
       "3649          0.292531          0.000000          0.000000          0.238095   \n",
       "\n",
       "      feature_1211_sms  feature_1212_sms  feature_1213_sms  feature_1214_sms  \\\n",
       "502           0.005109          3.285714          0.088123          0.047619   \n",
       "6547          0.015936          1.571429          0.131474          0.000000   \n",
       "6938          0.051988          2.190476          0.140673          0.000000   \n",
       "3115          0.023622          3.571429          0.196850          0.095238   \n",
       "3649          0.010373          0.666667          0.029046          0.000000   \n",
       "\n",
       "      feature_1215_sms  feature_1216_sms  feature_1217_sms  feature_1218_sms  \\\n",
       "502           0.001277          0.047619          0.001277          4.142857   \n",
       "6547          0.000000          0.047619          0.003984          0.761905   \n",
       "6938          0.000000          0.047619          0.003058          1.333333   \n",
       "3115          0.005249          0.047619          0.002625          0.904762   \n",
       "3649          0.000000          0.047619          0.002075          2.095238   \n",
       "\n",
       "      feature_1219_sms  feature_1220_sms  feature_1221_sms  feature_1222_sms  \\\n",
       "502           0.111111          0.000000          0.000000         13.809524   \n",
       "6547          0.063745          0.000000          0.000000          1.619048   \n",
       "6938          0.085627          0.428571          0.027523          3.952381   \n",
       "3115          0.049869          0.000000          0.000000          7.333333   \n",
       "3649          0.091286          0.000000          0.000000          6.571429   \n",
       "\n",
       "      feature_1223_sms  feature_1224_sms  feature_1225_sms  feature_1226_sms  \\\n",
       "502           0.370370          0.238095          0.006386          2.476190   \n",
       "6547          0.135458          0.523810          0.043825          1.380952   \n",
       "6938          0.253823          0.523810          0.033639          0.952381   \n",
       "3115          0.404199          0.333333          0.018373          2.047619   \n",
       "3649          0.286307          0.238095          0.010373          2.809524   \n",
       "\n",
       "      feature_1227_sms  feature_1228_sms  feature_1229_sms  feature_1230_sms  \\\n",
       "502           0.066411          3.095238          0.083014          0.428571   \n",
       "6547          0.115538          0.095238          0.007968          0.095238   \n",
       "6938          0.061162          0.380952          0.024465          0.285714   \n",
       "3115          0.112861          0.333333          0.018373          0.285714   \n",
       "3649          0.122407          1.285714          0.056017          0.428571   \n",
       "\n",
       "      feature_1231_sms  feature_1232_sms  feature_1233_sms  feature_1234_sms  \\\n",
       "502           0.011494         30.166667         30.166667          0.301767   \n",
       "6547          0.007968         10.100000         10.100000          0.101000   \n",
       "6938          0.018349         15.466667         15.466667          0.155966   \n",
       "3115          0.015748         14.700000         14.700000          0.390611   \n",
       "3649          0.018672         22.566667         22.566667          0.225667   \n",
       "\n",
       "      feature_1235_sms  feature_1236_sms  feature_1237_sms  feature_1238_sms  \\\n",
       "502           0.166667          0.005525          0.166667          0.005525   \n",
       "6547          0.666667          0.066007          0.100000          0.009901   \n",
       "6938          0.033333          0.002155          0.000000          0.000000   \n",
       "3115          0.300000          0.020408          0.300000          0.020408   \n",
       "3649          1.366667          0.060561          0.533333          0.023634   \n",
       "\n",
       "      feature_1239_sms  feature_1240_sms  feature_1241_sms  feature_1242_sms  \\\n",
       "502           7.333333          0.243094          0.033333          0.001105   \n",
       "6547          3.700000          0.366337          0.133333          0.013201   \n",
       "6938          5.233333          0.338362          0.066667          0.004310   \n",
       "3115          1.766667          0.120181          0.066667          0.004535   \n",
       "3649          5.933333          0.262925          0.100000          0.004431   \n",
       "\n",
       "      feature_1243_sms  feature_1244_sms  feature_1245_sms  feature_1246_sms  \\\n",
       "502           0.133333          0.004420          2.466667          0.081768   \n",
       "6547          0.133333          0.013201          1.266667          0.125413   \n",
       "6938          0.733333          0.047414          1.933333          0.125000   \n",
       "3115          0.366667          0.024943          2.900000          0.197279   \n",
       "3649          0.266667          0.011817          0.966667          0.042836   \n",
       "\n",
       "      feature_1247_sms  feature_1248_sms  feature_1249_sms  feature_1250_sms  \\\n",
       "502           0.033333          0.001105          0.033333          0.001105   \n",
       "6547          0.000000          0.000000          0.033333          0.003300   \n",
       "6938          0.000000          0.000000          0.033333          0.002155   \n",
       "3115          0.066667          0.004535          0.066667          0.004535   \n",
       "3649          0.000000          0.000000          0.100000          0.004431   \n",
       "\n",
       "      feature_1251_sms  feature_1252_sms  feature_1253_sms  feature_1254_sms  \\\n",
       "502           2.966667          0.098343          0.000000          0.000000   \n",
       "6547          0.566667          0.056106          0.033333          0.003300   \n",
       "6938          1.200000          0.077586          0.366667          0.023707   \n",
       "3115          0.733333          0.049887          0.000000          0.000000   \n",
       "3649          2.200000          0.097489          0.000000          0.000000   \n",
       "\n",
       "      feature_1255_sms  feature_1256_sms  feature_1257_sms  feature_1258_sms  \\\n",
       "502          11.000000          0.364641          0.166667          0.005525   \n",
       "6547          1.200000          0.118812          0.533333          0.052805   \n",
       "6938          3.800000          0.245690          0.566667          0.036638   \n",
       "3115          5.566667          0.378685          0.300000          0.020408   \n",
       "3649          5.800000          0.257016          0.233333          0.010340   \n",
       "\n",
       "      feature_1259_sms  feature_1260_sms  feature_1261_sms  feature_1262_sms  \\\n",
       "502           2.000000          0.066298          3.366667          0.111602   \n",
       "6547          1.300000          0.128713          0.333333          0.033003   \n",
       "6938          0.800000          0.051724          0.466667          0.030172   \n",
       "3115          1.766667          0.120181          0.300000          0.020408   \n",
       "3649          3.100000          0.137371          1.333333          0.059084   \n",
       "\n",
       "      feature_1263_sms  feature_1264_sms  feature_1265_sms  feature_1266_sms  \\\n",
       "502           0.300000          0.009945         20.450000         21.910714   \n",
       "6547          0.100000          0.009901          9.466667          9.466667   \n",
       "6938          0.233333          0.015086         16.200000         16.200000   \n",
       "3115          0.200000          0.013605         10.483333         10.483333   \n",
       "3649          0.633333          0.028065         18.683333         18.683333   \n",
       "\n",
       "      feature_1267_sms  feature_1268_sms  feature_1269_sms  feature_1270_sms  \\\n",
       "502           0.409136          0.100000          0.004890          0.083333   \n",
       "6547          0.189333          0.600000          0.063380          0.066667   \n",
       "6938          0.326723          0.033333          0.002058          0.000000   \n",
       "3115          0.557130          0.200000          0.019078          0.200000   \n",
       "3649          0.373667          1.250000          0.066905          0.416667   \n",
       "\n",
       "      feature_1271_sms  feature_1272_sms  feature_1273_sms  feature_1274_sms  \\\n",
       "502           0.004075          4.516667          0.220864          0.066667   \n",
       "6547          0.007042          3.066667          0.323944          0.116667   \n",
       "6938          0.000000          6.233333          0.384774          0.033333   \n",
       "3115          0.019078          1.450000          0.138315          0.033333   \n",
       "3649          0.022302          4.433333          0.237288          0.050000   \n",
       "\n",
       "      feature_1275_sms  feature_1276_sms  feature_1277_sms  feature_1278_sms  \\\n",
       "502           0.003260          0.083333          0.004075          1.633333   \n",
       "6547          0.012324          0.116667          0.012324          1.050000   \n",
       "6938          0.002058          0.366667          0.022634          1.866667   \n",
       "3115          0.003180          0.283333          0.027027          1.916667   \n",
       "3649          0.002676          0.216667          0.011597          0.866667   \n",
       "\n",
       "      feature_1279_sms  feature_1280_sms  feature_1281_sms  feature_1282_sms  \\\n",
       "502           0.079870          0.016667          0.000815          0.016667   \n",
       "6547          0.110915          0.000000          0.000000          0.016667   \n",
       "6938          0.115226          0.000000          0.000000          0.033333   \n",
       "3115          0.182830          0.033333          0.003180          0.033333   \n",
       "3649          0.046387          0.000000          0.000000          0.116667   \n",
       "\n",
       "      feature_1283_sms  feature_1284_sms  feature_1285_sms  feature_1286_sms  \\\n",
       "502           0.000815          1.983333          0.096985          0.033333   \n",
       "6547          0.001761          0.566667          0.059859          0.016667   \n",
       "6938          0.002058          0.800000          0.049383          0.350000   \n",
       "3115          0.003180          0.650000          0.062003          0.016667   \n",
       "3649          0.006244          2.066667          0.110616          0.000000   \n",
       "\n",
       "      feature_1287_sms  feature_1288_sms  feature_1289_sms  feature_1290_sms  \\\n",
       "502           0.001630          6.933333          0.339038          0.433333   \n",
       "6547          0.001761          1.400000          0.147887          0.533333   \n",
       "6938          0.021605          4.333333          0.267490          0.600000   \n",
       "3115          0.001590          3.450000          0.329094          0.533333   \n",
       "3649          0.000000          5.266667          0.281891          0.266667   \n",
       "\n",
       "      feature_1291_sms  feature_1292_sms  feature_1293_sms  feature_1294_sms  \\\n",
       "502           0.021190          1.516667          0.074165          2.766667   \n",
       "6547          0.056338          1.383333          0.146127          0.383333   \n",
       "6938          0.037037          0.800000          0.049383          0.550000   \n",
       "3115          0.050874          1.183333          0.112878          0.333333   \n",
       "3649          0.014273          2.166667          0.115968          1.116667   \n",
       "\n",
       "      feature_1295_sms  feature_1296_sms  feature_1297_sms  feature_1298_sms  \\\n",
       "502           0.135289          0.266667          0.013040             2.999   \n",
       "6547          0.040493          0.150000          0.015845             3.000   \n",
       "6938          0.033951          0.200000          0.012346             2.975   \n",
       "3115          0.031797          0.166667          0.015898             1.129   \n",
       "3649          0.059768          0.450000          0.024086             3.000   \n",
       "\n",
       "      feature_1299_sms  feature_1300_sms  feature_1301_sms  feature_1302_sms  \\\n",
       "502          17.335260               1.0             0.028          0.009336   \n",
       "6547         10.600707               1.0             0.291          0.097000   \n",
       "6938         17.814371               1.0             0.011          0.003697   \n",
       "3115          4.260377               1.0             0.028          0.024801   \n",
       "3649         18.867925               1.0             0.156          0.052000   \n",
       "\n",
       "      feature_1303_sms  feature_1304_sms  feature_1305_sms  feature_1306_sms  \\\n",
       "502              0.009          0.003001             0.723          0.241080   \n",
       "6547             0.088          0.029333             0.719          0.239667   \n",
       "6938             0.010          0.003361             1.199          0.403025   \n",
       "3115             0.027          0.023915             0.138          0.122232   \n",
       "3649             0.057          0.019000             0.725          0.241667   \n",
       "\n",
       "      feature_1307_sms  feature_1308_sms  feature_1309_sms  feature_1310_sms  \\\n",
       "502              0.007          0.002334             0.006          0.002001   \n",
       "6547             0.013          0.004333             0.039          0.013000   \n",
       "6938             0.002          0.000672             0.025          0.008403   \n",
       "3115             0.003          0.002657             0.021          0.018601   \n",
       "3649             0.014          0.004667             0.031          0.010333   \n",
       "\n",
       "      feature_1311_sms  feature_1312_sms  feature_1313_sms  feature_1314_sms  \\\n",
       "502              0.265          0.088363             0.001          0.000333   \n",
       "6547             0.212          0.070667             0.000          0.000000   \n",
       "6938             0.395          0.132773             0.000          0.000000   \n",
       "3115             0.129          0.114260             0.002          0.001771   \n",
       "3649             0.143          0.047667             0.000          0.000000   \n",
       "\n",
       "      feature_1315_sms  feature_1316_sms  feature_1317_sms  feature_1318_sms  \\\n",
       "502              0.002          0.000667             0.171          0.057019   \n",
       "6547             0.003          0.001000             0.186          0.062000   \n",
       "6938             0.006          0.002017             0.102          0.034286   \n",
       "3115             0.003          0.002657             0.059          0.052259   \n",
       "3649             0.013          0.004333             0.252          0.084000   \n",
       "\n",
       "      feature_1319_sms  feature_1320_sms  feature_1321_sms  feature_1322_sms  \\\n",
       "502              0.012          0.004001             1.088          0.362788   \n",
       "6547             0.006          0.002000             0.461          0.153667   \n",
       "6938             0.089          0.029916             0.669          0.224874   \n",
       "3115             0.006          0.005314             0.295          0.261293   \n",
       "3649             0.001          0.000333             1.047          0.349000   \n",
       "\n",
       "      feature_1323_sms  feature_1324_sms  feature_1325_sms  feature_1326_sms  \\\n",
       "502              0.049          0.016339             0.201          0.067022   \n",
       "6547             0.141          0.047000             0.424          0.141333   \n",
       "6938             0.162          0.054454             0.185          0.062185   \n",
       "3115             0.042          0.037201             0.168          0.148804   \n",
       "3649             0.052          0.017333             0.256          0.085333   \n",
       "\n",
       "      feature_1327_sms  feature_1328_sms  feature_1329_sms  feature_1330_sms  \n",
       "502              0.390          0.130043             0.042          0.014005  \n",
       "6547             0.378          0.126000             0.035          0.011667  \n",
       "6938             0.084          0.028235             0.036          0.012101  \n",
       "3115             0.181          0.160319             0.027          0.023915  \n",
       "3649             0.174          0.058000             0.079          0.026333  \n",
       "\n",
       "[5 rows x 1761 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6136, 1761)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y,oot_x, oot_y,df,final_feas = read_train('./data/filter_feas_df_0403_n_old.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e2712a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayes超参数优化 \n",
    "\n",
    "\n",
    "from scipy.misc import derivative\n",
    "\n",
    "def custom_asymmetric_train(y_true, y_pred):\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    grad = np.where(residual<0, -2*10.0*residual, -2*residual)\n",
    "    hess = np.where(residual<0, 2*10.0, 2.0)\n",
    "    return grad, hess\n",
    "\n",
    "def f1_loss(y, pred):\n",
    "    beta = 2\n",
    "    p = 1. / (1 + np.exp(-pred))\n",
    "    grad = p * ((beta - 1) * y + 1) - beta * y\n",
    "    hess = ((beta - 1) * y + 1) * p * (1.0 - p)\n",
    " \n",
    "    return grad, hess\n",
    "\n",
    "def focal_loss_lgb(y_true, y_pred):\n",
    "    a,g = 0.25, 1.0\n",
    "    def fl(x,t):\n",
    "        p = 1/(1+np.exp(-x))\n",
    "        return -( a*t + (1-a)*(1-t) ) * (( 1 - ( t*p + (1-t)*(1-p)) )**g) * ( t*np.log(p)+(1-t)*np.log(1-p) )\n",
    "    \n",
    "    partial_fl = lambda x: fl(x, y_true)\n",
    "    grad = derivative(partial_fl, y_pred, n=1, dx=1e-6)\n",
    "    hess = derivative(partial_fl, y_pred, n=2, dx=1e-6)\n",
    "    return grad, hess\n",
    "#https://towardsdatascience.com/custom-loss-functions-for-gradient-boosting_type-f79c1b40466d\n",
    "# https://blog.csdn.net/u013714645/article/details/105285038\n",
    "# https://towardsdatascience.com/lightgbm-with-the-focal-loss-for-imbalanced-datasets-9836a9ae00ca\n",
    "\n",
    "def lgb_f2_score(y_true, y_pred):\n",
    "    _,f2 = find_best_threshold(y_true, y_pred,bins_num=20)  #阈值精度20\n",
    "    return 'f2', f2, True\n",
    "\n",
    "# clf = LGBMClassifier(num_leaves=lvs,#300 #610\n",
    "#                      boosting_type= 'goss',\n",
    "#                      max_depth=-1,\n",
    "#                      n_estimators=1000,  #200\n",
    "#                      learning_rate=0.01, # 0.01\n",
    "#                      verbose=-1,\n",
    "#                      reg_alpha=1,\n",
    "#                      reg_lambda=1, \n",
    "#                      class_weight=None,\n",
    "#                      subsample=0.7,\n",
    "#                      colsample_bytree=0.7,\n",
    "#                      n_jobs=-1,\n",
    "#                      random_state=2) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def model_metrics(model, x, y,tp='auc'):\n",
    "    \"\"\" 评估 \"\"\"\n",
    "    # 动态阈值评估 \n",
    "    yprob = model.predict_proba(x)\n",
    "    fpr,tpr,_ = roc_curve(y, yprob,pos_label=1)\n",
    "    score = auc(fpr, tpr) \n",
    "    if tp=='ks':\n",
    "        return auc(fpr, tpr),max(tpr-fpr)\n",
    "    return score\n",
    "\n",
    "\n",
    "def bayes_fmin(train_x, test_x, train_y, test_y, eval_iters):\n",
    "    \"\"\"\n",
    "    bayes 优化超参数\n",
    "    \"\"\"\n",
    "    \n",
    "    def lgb_factory(params):\n",
    "        \"\"\"\n",
    "        定义调参目标函数\n",
    "        \"\"\"\n",
    "        fit_params = {\n",
    "            \"boosting_type\":params[\"boosting_type\"],\n",
    "            'max_depth':int(params['max_depth']),\n",
    "            'n_estimators':int(params['n_estimators']),\n",
    "            \"learning_rate\":params[\"learning_rate\"],\n",
    "            \"num_leaves\": int(params[\"num_leaves\"]),\n",
    "            #\"class_weight\":{0:1,  1:float(params['class_weight'])}, \n",
    "            \"class_weight\": params['class_weight'],\n",
    "            \"reg_alpha\":params[\"reg_alpha\"],\n",
    "            \"reg_lambda\":params[\"reg_lambda\"],\n",
    "            'subsample_for_bin':int(params['subsample_for_bin']),            \n",
    "            'subsample':params['subsample'],\n",
    "            \"feature_fraction\":params[\"feature_fraction\"],\n",
    "            \"min_child_samples\":int(params[\"min_child_samples\"]),            \n",
    "            'min_child_weight': params['min_child_weight'],\n",
    "            \"min_split_gain\":params[\"min_split_gain\"]\n",
    "            }\n",
    "        fit_params.update(base_params)\n",
    "        # 模型训练\n",
    "        model=lgb.LGBMClassifier(**fit_params)\n",
    "        model.set_params(**{\"objective\": focal_loss_lgb})   #focal loss\n",
    "\n",
    "        model.fit(train_x, train_y,\n",
    "                  eval_set=[(test_x, test_y)],\n",
    "                  eval_metric='auc',   # 'f1'\n",
    "                  early_stopping_rounds=50, #  30round\n",
    "                  verbose=-1)\n",
    "        print('***\\n',fit_params)\n",
    "        # 测试集最小化为目标\n",
    "        metric = model_metrics(model, test_x, test_y)\n",
    "        print(metric)\n",
    "        return {\"loss\": -metric, \"status\":STATUS_OK}\n",
    "\n",
    "    ########start 参数空间1\n",
    "    base_params = {\n",
    "            \"n_jobs\":-1, \n",
    "            \"verbose\":-1,\n",
    "            \"random_state\":0        \n",
    "            }\n",
    "    space = {\n",
    "        'max_depth': hp.quniform('max_depth', 2, 22, 1),\n",
    "        'n_estimators': hp.quniform('n_estimators', 10, 2424, 10),\n",
    "        'boosting_type': hp.choice('boosting_type', ['gbdt','dart','goss']),\n",
    "        #'class_weight':hp.uniform('class_weight', 0.005, 300) ,   # None\n",
    "        'class_weight':hp.choice('class_weight', [None,'balanced']),\n",
    "        'num_leaves': hp.quniform('num_leaves', 4, 2424, 8),\n",
    "        'learning_rate': hp.uniform('learning_rate', 1e-4, 1),\n",
    "        'subsample_for_bin': hp.quniform('subsample_for_bin', 10000, 350000, 20000),\n",
    "        'feature_fraction': hp.uniform('feature_fraction', 0.1, 1),\n",
    "        'subsample': hp.uniform('subsample', 0.1, 1), \n",
    "        'min_child_samples': hp.qloguniform('min_child_samples', 0, 10, 1),  \n",
    "        'reg_alpha': hp.uniform('reg_alpha', 0, 10),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 0, 10),\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', -16, 5), \n",
    "        'min_split_gain': hp.uniform('min_split_gain', 0, 10)\n",
    "            }\n",
    "    # 2、优化\n",
    "    best_params = fmin(lgb_factory, space, algo=partial(anneal.suggest,), max_evals=eval_iters, trials=Trials(),return_argmin=True,verbose=-1)\n",
    "    \n",
    "    # 3、优化后取最优参数,规范格式\n",
    "    best_params.update(base_params)\n",
    "    best_params[\"boosting_type\"] = ['gbdt','dart','goss'][int(best_params[\"boosting_type\"])]\n",
    "    best_params['class_weight'] =  [None,'balanced'][int(best_params['class_weight'])]\n",
    "    best_params[\"n_estimators\"] = int(best_params[\"n_estimators\"])\n",
    "    #best_params['class_weight'] = {0:1,  1:float(params['class_weight'])}\n",
    "    best_params[\"min_child_samples\"] = int(best_params[\"min_child_samples\"])\n",
    "    best_params[\"subsample_for_bin\"] = int(best_params[\"subsample_for_bin\"])\n",
    "    best_params[\"num_leaves\"] = int(best_params[\"num_leaves\"])\n",
    "    best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07527650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                   \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 5, 'n_estimators': 2410, 'learning_rate': 0.36100755502409587, 'num_leaves': 1096, 'class_weight': None, 'reg_alpha': 6.58555325488917, 'reg_lambda': 4.005371799954408, 'subsample_for_bin': 20000, 'subsample': 0.9238574696917753, 'feature_fraction': 0.4149593261945237, 'min_child_samples': 34, 'min_child_weight': 10.558352556785001, 'min_split_gain': 8.489887397429305, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.4001554519209416                                    \n",
      "[LightGBM] [Warning] feature_fraction is set=0.5651595533012445, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5651595533012445\n",
      "  2%|▏         | 1/50 [00:14<11:28, 14.04s/trial, best loss: -0.4001554519209416]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 15, 'n_estimators': 1300, 'learning_rate': 0.4895392876439481, 'num_leaves': 648, 'class_weight': 'balanced', 'reg_alpha': 4.475738074783454, 'reg_lambda': 2.0593359024600373, 'subsample_for_bin': 300000, 'subsample': 0.8827231985656736, 'feature_fraction': 0.5651595533012445, 'min_child_samples': 2, 'min_child_weight': 3.9288170435613086e-05, 'min_split_gain': 9.91188834183188, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.6665056628914058                                                               \n",
      "[LightGBM] [Warning] feature_fraction is set=0.455946375781849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.455946375781849\n",
      "  4%|▍         | 2/50 [00:15<05:10,  6.46s/trial, best loss: -0.6665056628914058]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 17, 'n_estimators': 860, 'learning_rate': 0.7333508190216884, 'num_leaves': 1168, 'class_weight': None, 'reg_alpha': 6.076983816585323, 'reg_lambda': 5.157924511670449, 'subsample_for_bin': 120000, 'subsample': 0.7451822486100889, 'feature_fraction': 0.455946375781849, 'min_child_samples': 1, 'min_child_weight': 0.00397181871972156, 'min_split_gain': 6.0697711818367726, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.6560648456584499                                                               \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6376678442656547, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6376678442656547\n",
      "  6%|▌         | 3/50 [00:21<04:57,  6.33s/trial, best loss: -0.6665056628914058]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 12, 'n_estimators': 1800, 'learning_rate': 0.4841218960099777, 'num_leaves': 520, 'class_weight': None, 'reg_alpha': 7.309425632663227, 'reg_lambda': 1.9674468334113384, 'subsample_for_bin': 40000, 'subsample': 0.9310509975977195, 'feature_fraction': 0.6376678442656547, 'min_child_samples': 137, 'min_child_weight': 0.19133623177280845, 'min_split_gain': 9.281289260892066, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.4602442815900511                                                               \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7486262518024793, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7486262518024793\n",
      "  8%|▊         | 4/50 [00:30<05:46,  7.54s/trial, best loss: -0.6665056628914058]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 17, 'n_estimators': 1020, 'learning_rate': 0.7725371215382209, 'num_leaves': 1296, 'class_weight': None, 'reg_alpha': 4.6460801395087445, 'reg_lambda': 1.0000227916639142, 'subsample_for_bin': 280000, 'subsample': 0.4125860931416897, 'feature_fraction': 0.7486262518024793, 'min_child_samples': 57, 'min_child_weight': 0.008705904518455267, 'min_split_gain': 3.3590554007738596, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.641266933155674                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6238326792966125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6238326792966125\n",
      " 10%|█         | 5/50 [00:37<05:25,  7.23s/trial, best loss: -0.6665056628914058]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 10, 'n_estimators': 1090, 'learning_rate': 0.22710805642408333, 'num_leaves': 944, 'class_weight': None, 'reg_alpha': 1.4701766175131454, 'reg_lambda': 2.170410531324404, 'subsample_for_bin': 160000, 'subsample': 0.8162746919037949, 'feature_fraction': 0.6238326792966125, 'min_child_samples': 1, 'min_child_weight': 0.00051195215947707, 'min_split_gain': 4.229594827560254, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7163202309571397                                                               \n",
      "[LightGBM] [Warning] feature_fraction is set=0.568574038042482, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.568574038042482\n",
      " 12%|█▏        | 6/50 [00:45<05:24,  7.36s/trial, best loss: -0.7163202309571397]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 19, 'n_estimators': 820, 'learning_rate': 0.7418471820702259, 'num_leaves': 792, 'class_weight': 'balanced', 'reg_alpha': 6.363657693456535, 'reg_lambda': 4.5365950138928675, 'subsample_for_bin': 160000, 'subsample': 0.7737134874633164, 'feature_fraction': 0.568574038042482, 'min_child_samples': 168, 'min_child_weight': 1.0735920189033408, 'min_split_gain': 6.279572839836265, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.646469020652898                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6582935311505391, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6582935311505391\n",
      " 14%|█▍        | 7/50 [00:46<03:48,  5.31s/trial, best loss: -0.7163202309571397]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 10, 'n_estimators': 1780, 'learning_rate': 0.5402961627571652, 'num_leaves': 408, 'class_weight': 'balanced', 'reg_alpha': 4.864139120986852, 'reg_lambda': 4.534431276141474, 'subsample_for_bin': 140000, 'subsample': 0.8299997810198885, 'feature_fraction': 0.6582935311505391, 'min_child_samples': 3, 'min_child_weight': 1.3730004261263923e-05, 'min_split_gain': 1.5364064609286738, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7202509438152342                                                               \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6958601655625982, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6958601655625982\n",
      " 16%|█▌        | 8/50 [00:58<05:10,  7.39s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 9, 'n_estimators': 1710, 'learning_rate': 0.43394701120623863, 'num_leaves': 656, 'class_weight': 'balanced', 'reg_alpha': 0.16350456437459038, 'reg_lambda': 4.450402668443272, 'subsample_for_bin': 140000, 'subsample': 0.7405254007097591, 'feature_fraction': 0.6958601655625982, 'min_child_samples': 77, 'min_child_weight': 0.11211234865459523, 'min_split_gain': 3.060881719954164, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.694046191427937                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.5568605355028476, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5568605355028476\n",
      " 18%|█▊        | 9/50 [00:59<03:40,  5.37s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                              \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 5, 'n_estimators': 2270, 'learning_rate': 0.3310361512877421, 'num_leaves': 1248, 'class_weight': 'balanced', 'reg_alpha': 3.8130041390157543, 'reg_lambda': 3.365545929901516, 'subsample_for_bin': 200000, 'subsample': 0.879781492430718, 'feature_fraction': 0.5568605355028476, 'min_child_samples': 78, 'min_child_weight': 0.0004900922045019515, 'min_split_gain': 4.349225072383552, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.6835842771485676                                                               \n",
      "[LightGBM] [Warning] feature_fraction is set=0.5744820438029912, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5744820438029912\n",
      " 20%|██        | 10/50 [00:59<02:39,  3.98s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 9, 'n_estimators': 1560, 'learning_rate': 0.17592152455533033, 'num_leaves': 1496, 'class_weight': None, 'reg_alpha': 2.2509397562030475, 'reg_lambda': 3.4473352834005673, 'subsample_for_bin': 180000, 'subsample': 0.8565832532083126, 'feature_fraction': 0.5744820438029912, 'min_child_samples': 2, 'min_child_weight': 0.06208907547250118, 'min_split_gain': 5.0002313336254565, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.6940139906728848                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.4693325265997424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4693325265997424\n",
      " 22%|██▏       | 11/50 [01:00<01:59,  3.06s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 11, 'n_estimators': 760, 'learning_rate': 0.12276830274758896, 'num_leaves': 408, 'class_weight': 'balanced', 'reg_alpha': 2.5236309422202403, 'reg_lambda': 1.573542320792155, 'subsample_for_bin': 140000, 'subsample': 0.6114643882253535, 'feature_fraction': 0.4693325265997424, 'min_child_samples': 2, 'min_child_weight': 5.338903293621151e-06, 'min_split_gain': 4.840111351809295, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7105385298689761                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.5659775185266147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5659775185266147\n",
      " 24%|██▍       | 12/50 [01:06<02:26,  3.86s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 14, 'n_estimators': 2310, 'learning_rate': 0.5178749755595136, 'num_leaves': 792, 'class_weight': 'balanced', 'reg_alpha': 3.513080271994378, 'reg_lambda': 5.601005203212554, 'subsample_for_bin': 80000, 'subsample': 0.7355884982586757, 'feature_fraction': 0.5659775185266147, 'min_child_samples': 51, 'min_child_weight': 1.0454155808437335e-06, 'min_split_gain': 0.02222989020637263, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.6577059737952476                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.5292002078997193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5292002078997193\n",
      " 26%|██▌       | 13/50 [01:08<01:59,  3.24s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'gbdt', 'max_depth': 10, 'n_estimators': 1620, 'learning_rate': 0.4455151957380866, 'num_leaves': 408, 'class_weight': 'balanced', 'reg_alpha': 3.2838785803832016, 'reg_lambda': 5.77804596023739, 'subsample_for_bin': 140000, 'subsample': 0.8535731909775479, 'feature_fraction': 0.5292002078997193, 'min_child_samples': 11, 'min_child_weight': 4.578454388119294e-05, 'min_split_gain': 1.964826712175548, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.66836109260493                                                                  \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7024568994457026, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7024568994457026\n",
      " 28%|██▊       | 14/50 [01:09<01:31,  2.55s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 13, 'n_estimators': 2220, 'learning_rate': 0.4925235997601125, 'num_leaves': 984, 'class_weight': 'balanced', 'reg_alpha': 5.558074966518181, 'reg_lambda': 3.7995099729830937, 'subsample_for_bin': 140000, 'subsample': 0.7135778012387235, 'feature_fraction': 0.7024568994457026, 'min_child_samples': 4, 'min_child_weight': 4.923793904226836e-07, 'min_split_gain': 1.6195130108793345, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.6913557628247834                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.641506530438924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.641506530438924\n",
      " 30%|███       | 15/50 [01:10<01:16,  2.20s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 7, 'n_estimators': 1810, 'learning_rate': 0.45390767507743657, 'num_leaves': 424, 'class_weight': 'balanced', 'reg_alpha': 3.56135305745173, 'reg_lambda': 3.741101887000232, 'subsample_for_bin': 140000, 'subsample': 0.9271617804869455, 'feature_fraction': 0.641506530438924, 'min_child_samples': 31, 'min_child_weight': 7.445558378558065e-06, 'min_split_gain': 0.455112132546291, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7127470575172108                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7916962981778761, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7916962981778761\n",
      " 32%|███▏      | 16/50 [01:25<03:22,  5.94s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 10, 'n_estimators': 2240, 'learning_rate': 0.5907567240971391, 'num_leaves': 64, 'class_weight': 'balanced', 'reg_alpha': 5.3498233579671055, 'reg_lambda': 2.510081386354608, 'subsample_for_bin': 180000, 'subsample': 0.7730512585850943, 'feature_fraction': 0.7916962981778761, 'min_child_samples': 19, 'min_child_weight': 0.00011512248659874883, 'min_split_gain': 1.484083870643673, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7157650455252055                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.5525787085465381, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5525787085465381\n",
      " 34%|███▍      | 17/50 [01:40<04:48,  8.75s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 11, 'n_estimators': 820, 'learning_rate': 0.2706535874717825, 'num_leaves': 512, 'class_weight': 'balanced', 'reg_alpha': 2.253322184492225, 'reg_lambda': 3.859604427793261, 'subsample_for_bin': 180000, 'subsample': 0.8541324526335397, 'feature_fraction': 0.5525787085465381, 'min_child_samples': 4, 'min_child_weight': 0.017532985429450733, 'min_split_gain': 2.9143020704091995, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7141594492560516                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6010244191402124, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6010244191402124\n",
      " 36%|███▌      | 18/50 [01:52<05:05,  9.55s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 8, 'n_estimators': 700, 'learning_rate': 0.19237758382115389, 'num_leaves': 552, 'class_weight': None, 'reg_alpha': 2.8429369008794003, 'reg_lambda': 2.9291587672782278, 'subsample_for_bin': 180000, 'subsample': 0.9395139185746961, 'feature_fraction': 0.6010244191402124, 'min_child_samples': 5, 'min_child_weight': 2.436057476654143e-05, 'min_split_gain': 3.8918730918276516, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.716806573395514                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6964658372292515, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6964658372292515\n",
      " 38%|███▊      | 19/50 [01:57<04:17,  8.32s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 11, 'n_estimators': 2170, 'learning_rate': 0.45595207609791366, 'num_leaves': 200, 'class_weight': 'balanced', 'reg_alpha': 6.68820262423184, 'reg_lambda': 2.466619532407754, 'subsample_for_bin': 240000, 'subsample': 0.8481308120280605, 'feature_fraction': 0.6964658372292515, 'min_child_samples': 14, 'min_child_weight': 0.00403758773174869, 'min_split_gain': 0.42844199579161246, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.6771952031978681                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.5923114009697013, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5923114009697013\n",
      " 40%|████      | 20/50 [01:58<03:06,  6.22s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 11, 'n_estimators': 1930, 'learning_rate': 0.5650264561600499, 'num_leaves': 72, 'class_weight': 'balanced', 'reg_alpha': 6.359747916885342, 'reg_lambda': 5.208304924157636, 'subsample_for_bin': 120000, 'subsample': 0.9297003591296235, 'feature_fraction': 0.5923114009697013, 'min_child_samples': 2, 'min_child_weight': 0.0002807543222549002, 'min_split_gain': 1.334456133163375, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.6746824339329337                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6681957628555846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6681957628555846\n",
      " 42%|████▏     | 21/50 [01:59<02:14,  4.64s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 12, 'n_estimators': 1770, 'learning_rate': 0.49576383032235766, 'num_leaves': 752, 'class_weight': 'balanced', 'reg_alpha': 6.253173818363071, 'reg_lambda': 5.6656087147843, 'subsample_for_bin': 180000, 'subsample': 0.7290406983868768, 'feature_fraction': 0.6681957628555846, 'min_child_samples': 2, 'min_child_weight': 0.0003518031739179492, 'min_split_gain': 1.522120578961175, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7124805685098823                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.38671000375525444, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.38671000375525444\n",
      " 44%|████▍     | 22/50 [02:15<03:40,  7.88s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 12, 'n_estimators': 770, 'learning_rate': 0.2039019399104105, 'num_leaves': 352, 'class_weight': 'balanced', 'reg_alpha': 1.347573976864266, 'reg_lambda': 1.8201645959387198, 'subsample_for_bin': 120000, 'subsample': 0.5000784360932472, 'feature_fraction': 0.38671000375525444, 'min_child_samples': 13, 'min_child_weight': 7.151032720907937e-07, 'min_split_gain': 5.849585530695945, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.4912713746391295                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.5064313618457439, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5064313618457439\n",
      " 46%|████▌     | 23/50 [02:20<03:09,  7.03s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 11, 'n_estimators': 390, 'learning_rate': 0.09430119029223433, 'num_leaves': 488, 'class_weight': None, 'reg_alpha': 3.977234358928891, 'reg_lambda': 4.050913248052344, 'subsample_for_bin': 140000, 'subsample': 0.7323321146146996, 'feature_fraction': 0.5064313618457439, 'min_child_samples': 2, 'min_child_weight': 4.322832751287136e-06, 'min_split_gain': 4.087287425689763, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7164790139906729                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.5750724058816586, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5750724058816586\n",
      " 48%|████▊     | 24/50 [02:23<02:33,  5.90s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 9, 'n_estimators': 1460, 'learning_rate': 0.6565950984775579, 'num_leaves': 360, 'class_weight': 'balanced', 'reg_alpha': 4.672554652268221, 'reg_lambda': 4.011304884047229, 'subsample_for_bin': 140000, 'subsample': 0.7245011327220492, 'feature_fraction': 0.5750724058816586, 'min_child_samples': 1, 'min_child_weight': 7.331063890475708e-07, 'min_split_gain': 1.8991440189293458, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.6162447257383966                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.4787776558011141, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4787776558011141\n",
      " 50%|█████     | 25/50 [02:34<03:06,  7.46s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 9, 'n_estimators': 620, 'learning_rate': 0.20132722617827548, 'num_leaves': 320, 'class_weight': None, 'reg_alpha': 4.284175762941921, 'reg_lambda': 4.3336542345237365, 'subsample_for_bin': 160000, 'subsample': 0.7747544457845511, 'feature_fraction': 0.4787776558011141, 'min_child_samples': 3, 'min_child_weight': 3.5053525783558293e-07, 'min_split_gain': 4.007324072789825, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7152831445702864                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.543868099392675, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.543868099392675\n",
      " 52%|█████▏    | 26/50 [02:39<02:37,  6.58s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 12, 'n_estimators': 170, 'learning_rate': 0.023457805697898192, 'num_leaves': 584, 'class_weight': None, 'reg_alpha': 3.2507846329308476, 'reg_lambda': 3.260681540701365, 'subsample_for_bin': 160000, 'subsample': 0.7115127027739799, 'feature_fraction': 0.543868099392675, 'min_child_samples': 9, 'min_child_weight': 4.145547748355308e-06, 'min_split_gain': 3.5059273831714197, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.712170775038863                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6343176673547846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6343176673547846\n",
      " 54%|█████▍    | 27/50 [02:41<01:59,  5.19s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 9, 'n_estimators': 720, 'learning_rate': 0.09418507528420594, 'num_leaves': 456, 'class_weight': None, 'reg_alpha': 2.3456006333783987, 'reg_lambda': 3.627726550235802, 'subsample_for_bin': 180000, 'subsample': 0.9241834806047824, 'feature_fraction': 0.6343176673547846, 'min_child_samples': 1, 'min_child_weight': 2.8963864127925262e-05, 'min_split_gain': 3.4826123103354476, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7183433266711081                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6501471461247089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6501471461247089\n",
      " 56%|█████▌    | 28/50 [02:46<01:53,  5.18s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 9, 'n_estimators': 2040, 'learning_rate': 0.42408656973835046, 'num_leaves': 408, 'class_weight': 'balanced', 'reg_alpha': 4.718859442856108, 'reg_lambda': 4.754143927531919, 'subsample_for_bin': 140000, 'subsample': 0.8211289798375264, 'feature_fraction': 0.6501471461247089, 'min_child_samples': 2, 'min_child_weight': 3.617429436956443e-05, 'min_split_gain': 0.9697533604656262, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7189651343548745                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6162991121632312, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6162991121632312\n",
      " 58%|█████▊    | 29/50 [03:00<02:45,  7.88s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 11, 'n_estimators': 1670, 'learning_rate': 0.4239751624761775, 'num_leaves': 328, 'class_weight': 'balanced', 'reg_alpha': 4.199000030896185, 'reg_lambda': 3.4438052607357474, 'subsample_for_bin': 160000, 'subsample': 0.8998065601368488, 'feature_fraction': 0.6162991121632312, 'min_child_samples': 12, 'min_child_weight': 2.7180876252158356e-06, 'min_split_gain': 2.7290108157865003, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.712322895847213                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6913143014078845, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6913143014078845\n",
      " 60%|██████    | 30/50 [03:11<02:56,  8.81s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 10, 'n_estimators': 1610, 'learning_rate': 0.5268608397115941, 'num_leaves': 192, 'class_weight': 'balanced', 'reg_alpha': 5.144811415968386, 'reg_lambda': 5.728151469901638, 'subsample_for_bin': 140000, 'subsample': 0.7814205564645998, 'feature_fraction': 0.6913143014078845, 'min_child_samples': 11, 'min_child_weight': 5.614537728798622e-06, 'min_split_gain': 0.6314617263999631, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7137197423939596                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6510626875639128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6510626875639128\n",
      " 62%|██████▏   | 31/50 [03:23<03:04,  9.70s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 9, 'n_estimators': 2220, 'learning_rate': 0.319809934721746, 'num_leaves': 176, 'class_weight': 'balanced', 'reg_alpha': 4.8912155815370255, 'reg_lambda': 5.536674684208199, 'subsample_for_bin': 180000, 'subsample': 0.841277397502937, 'feature_fraction': 0.6510626875639128, 'min_child_samples': 2, 'min_child_weight': 5.0215618602555044e-05, 'min_split_gain': 0.3416062243056172, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7125893848545415                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.5708670381128494, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5708670381128494\n",
      " 64%|██████▍   | 32/50 [03:41<03:38, 12.15s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 8, 'n_estimators': 2020, 'learning_rate': 0.5169005210399932, 'num_leaves': 408, 'class_weight': 'balanced', 'reg_alpha': 3.6937377204858026, 'reg_lambda': 4.072318132561168, 'subsample_for_bin': 180000, 'subsample': 0.7504298835594062, 'feature_fraction': 0.5708670381128494, 'min_child_samples': 2, 'min_child_weight': 0.00034730280685095954, 'min_split_gain': 0.34091525808954454, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7160248723073506                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.707038041425383, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.707038041425383\n",
      " 66%|██████▌   | 33/50 [04:00<04:04, 14.36s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 8, 'n_estimators': 1770, 'learning_rate': 0.6036937063572995, 'num_leaves': 528, 'class_weight': 'balanced', 'reg_alpha': 4.335682523343763, 'reg_lambda': 3.661542903121776, 'subsample_for_bin': 140000, 'subsample': 0.8413308945706968, 'feature_fraction': 0.707038041425383, 'min_child_samples': 2, 'min_child_weight': 0.00012493944340603454, 'min_split_gain': 1.4407995967658291, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7191250277592716                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.635929250898449, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.635929250898449\n",
      " 68%|██████▊   | 34/50 [04:12<03:37, 13.61s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 9, 'n_estimators': 1620, 'learning_rate': 0.631166819962551, 'num_leaves': 640, 'class_weight': 'balanced', 'reg_alpha': 5.141376352599227, 'reg_lambda': 5.28392376756015, 'subsample_for_bin': 140000, 'subsample': 0.8686039352810996, 'feature_fraction': 0.635929250898449, 'min_child_samples': 1, 'min_child_weight': 6.65533824463572e-05, 'min_split_gain': 1.302650035855305, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.6650521874306018                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6549349059022159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6549349059022159\n",
      " 70%|███████   | 35/50 [04:13<02:27,  9.85s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 11, 'n_estimators': 1990, 'learning_rate': 0.6488673404401857, 'num_leaves': 288, 'class_weight': 'balanced', 'reg_alpha': 3.9933513596894246, 'reg_lambda': 4.716200358709964, 'subsample_for_bin': 180000, 'subsample': 0.7856307738980252, 'feature_fraction': 0.6549349059022159, 'min_child_samples': 3, 'min_child_weight': 4.294199614458887e-05, 'min_split_gain': 0.45659167188453664, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7146124805685099                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7471987570062519, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7471987570062519\n",
      " 72%|███████▏  | 36/50 [04:28<02:41, 11.50s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 11, 'n_estimators': 1560, 'learning_rate': 0.6103720939552879, 'num_leaves': 264, 'class_weight': 'balanced', 'reg_alpha': 5.927276870758482, 'reg_lambda': 4.627412518112096, 'subsample_for_bin': 120000, 'subsample': 0.8587589999288514, 'feature_fraction': 0.7471987570062519, 'min_child_samples': 1, 'min_child_weight': 7.145780877728167e-05, 'min_split_gain': 0.8560226897805909, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7176815456362424                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6056691480491021, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6056691480491021\n",
      " 74%|███████▍  | 37/50 [04:42<02:37, 12.14s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 9, 'n_estimators': 1970, 'learning_rate': 0.5654428544188774, 'num_leaves': 328, 'class_weight': 'balanced', 'reg_alpha': 4.921750567278861, 'reg_lambda': 4.851959723429155, 'subsample_for_bin': 160000, 'subsample': 0.8469917890977433, 'feature_fraction': 0.6056691480491021, 'min_child_samples': 3, 'min_child_weight': 1.2912988775782239e-05, 'min_split_gain': 1.1975142641666583, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7197801465689541                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.5912028769859304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5912028769859304\n",
      " 76%|███████▌  | 38/50 [04:56<02:32, 12.74s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 10, 'n_estimators': 1880, 'learning_rate': 0.569522495997444, 'num_leaves': 224, 'class_weight': 'balanced', 'reg_alpha': 4.8900336191351474, 'reg_lambda': 3.552208485519925, 'subsample_for_bin': 160000, 'subsample': 0.811396891454309, 'feature_fraction': 0.5912028769859304, 'min_child_samples': 1, 'min_child_weight': 3.1566571967707914e-06, 'min_split_gain': 2.103864492901708, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7052031978680879                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7402191951555392, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7402191951555392\n",
      " 78%|███████▊  | 39/50 [05:10<02:22, 12.94s/trial, best loss: -0.7202509438152342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 7, 'n_estimators': 1920, 'learning_rate': 0.5915395046412429, 'num_leaves': 712, 'class_weight': 'balanced', 'reg_alpha': 3.3743706795384254, 'reg_lambda': 3.376493434477243, 'subsample_for_bin': 120000, 'subsample': 0.7982660247799438, 'feature_fraction': 0.7402191951555392, 'min_child_samples': 3, 'min_child_weight': 4.577060363790685e-05, 'min_split_gain': 1.2487060464543078, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7211814345991561                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6628099542888857, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6628099542888857\n",
      " 80%|████████  | 40/50 [05:23<02:10, 13.06s/trial, best loss: -0.7211814345991561]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 6, 'n_estimators': 2010, 'learning_rate': 0.6798595371406166, 'num_leaves': 888, 'class_weight': 'balanced', 'reg_alpha': 4.310960315544623, 'reg_lambda': 3.515142432048324, 'subsample_for_bin': 140000, 'subsample': 0.8264077029839001, 'feature_fraction': 0.6628099542888857, 'min_child_samples': 8, 'min_child_weight': 0.00010043860141343804, 'min_split_gain': 1.2537106589705294, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7202220741727736                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.719105799112862, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.719105799112862\n",
      " 82%|████████▏ | 41/50 [05:36<01:58, 13.18s/trial, best loss: -0.7211814345991561]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 8, 'n_estimators': 1760, 'learning_rate': 0.6248781611113733, 'num_leaves': 688, 'class_weight': None, 'reg_alpha': 2.6461915814287793, 'reg_lambda': 3.69130827448475, 'subsample_for_bin': 100000, 'subsample': 0.7769479238041384, 'feature_fraction': 0.719105799112862, 'min_child_samples': 2, 'min_child_weight': 8.795614657110906e-05, 'min_split_gain': 1.801395266646712, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.493530979347102                                                                 \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7405636125942159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7405636125942159\n",
      " 84%|████████▍ | 42/50 [05:47<01:40, 12.58s/trial, best loss: -0.7211814345991561]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 6, 'n_estimators': 2110, 'learning_rate': 0.5145273748229445, 'num_leaves': 880, 'class_weight': None, 'reg_alpha': 3.3754610358680157, 'reg_lambda': 2.6850442974828375, 'subsample_for_bin': 140000, 'subsample': 0.8564340763185345, 'feature_fraction': 0.7405636125942159, 'min_child_samples': 2, 'min_child_weight': 2.7290119114568135e-05, 'min_split_gain': 2.19393174899208, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7140350877192982                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.682947233989087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.682947233989087\n",
      " 86%|████████▌ | 43/50 [06:03<01:34, 13.48s/trial, best loss: -0.7211814345991561]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 8, 'n_estimators': 1690, 'learning_rate': 0.6639275109501606, 'num_leaves': 520, 'class_weight': 'balanced', 'reg_alpha': 2.5256123100512675, 'reg_lambda': 2.538469330674682, 'subsample_for_bin': 160000, 'subsample': 0.767602472322798, 'feature_fraction': 0.682947233989087, 'min_child_samples': 3, 'min_child_weight': 9.723680735788575e-06, 'min_split_gain': 1.4673738431736998, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7186808794137242                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8032991349589458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8032991349589458\n",
      " 88%|████████▊ | 44/50 [06:14<01:16, 12.83s/trial, best loss: -0.7211814345991561]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 7, 'n_estimators': 1960, 'learning_rate': 0.6174168267480264, 'num_leaves': 792, 'class_weight': 'balanced', 'reg_alpha': 3.701523068370313, 'reg_lambda': 4.018527676448826, 'subsample_for_bin': 140000, 'subsample': 0.8749011500386992, 'feature_fraction': 0.8032991349589458, 'min_child_samples': 5, 'min_child_weight': 6.915327050298391e-05, 'min_split_gain': 1.2196138917523693, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7201932045303131                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.8170296789495408, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8170296789495408\n",
      " 90%|█████████ | 45/50 [06:28<01:05, 13.13s/trial, best loss: -0.7211814345991561]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 6, 'n_estimators': 2110, 'learning_rate': 0.5789087962603954, 'num_leaves': 680, 'class_weight': 'balanced', 'reg_alpha': 3.1134835727100474, 'reg_lambda': 2.7743473555647653, 'subsample_for_bin': 120000, 'subsample': 0.8542867013682378, 'feature_fraction': 0.8170296789495408, 'min_child_samples': 2, 'min_child_weight': 0.0001966005829109845, 'min_split_gain': 0.7562054774422633, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7171840994892293                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7853233166599293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7853233166599293\n",
      " 92%|█████████▏| 46/50 [06:45<00:56, 14.20s/trial, best loss: -0.7211814345991561]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'goss', 'max_depth': 6, 'n_estimators': 1800, 'learning_rate': 0.5577641007037283, 'num_leaves': 664, 'class_weight': 'balanced', 'reg_alpha': 3.185385452827459, 'reg_lambda': 2.768839600470616, 'subsample_for_bin': 100000, 'subsample': 0.7835823786311781, 'feature_fraction': 0.7853233166599293, 'min_child_samples': 6, 'min_child_weight': 9.975122181184976e-05, 'min_split_gain': 1.4577868594257959, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.6753753053519875                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7832321416279471, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7832321416279471\n",
      " 94%|█████████▍| 47/50 [06:46<00:30, 10.23s/trial, best loss: -0.7211814345991561]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 7, 'n_estimators': 1850, 'learning_rate': 0.6720315685489561, 'num_leaves': 744, 'class_weight': 'balanced', 'reg_alpha': 3.321991212607815, 'reg_lambda': 2.745902854349492, 'subsample_for_bin': 100000, 'subsample': 0.798257867472925, 'feature_fraction': 0.7832321416279471, 'min_child_samples': 3, 'min_child_weight': 1.4975496383317989e-05, 'min_split_gain': 0.5996488737103657, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7179080612924718                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.7852357498595781, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7852357498595781\n",
      " 96%|█████████▌| 48/50 [07:00<00:22, 11.40s/trial, best loss: -0.7211814345991561]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 6, 'n_estimators': 1840, 'learning_rate': 0.6684473729439491, 'num_leaves': 808, 'class_weight': 'balanced', 'reg_alpha': 4.0983605140356945, 'reg_lambda': 3.5247813590046424, 'subsample_for_bin': 120000, 'subsample': 0.8386007593936433, 'feature_fraction': 0.7852357498595781, 'min_child_samples': 5, 'min_child_weight': 1.0844836049376398e-05, 'min_split_gain': 0.4090409714928712, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7130957139684655                                                                \n",
      "[LightGBM] [Warning] feature_fraction is set=0.6202069645637742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6202069645637742\n",
      " 98%|█████████▊| 49/50 [07:15<00:12, 12.38s/trial, best loss: -0.7211814345991561]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***                                                                               \n",
      "\n",
      "{'boosting_type': 'dart', 'max_depth': 8, 'n_estimators': 2000, 'learning_rate': 0.6924392633855037, 'num_leaves': 1032, 'class_weight': 'balanced', 'reg_alpha': 5.127443573835752, 'reg_lambda': 3.5677003400475678, 'subsample_for_bin': 120000, 'subsample': 0.810533198399399, 'feature_fraction': 0.6202069645637742, 'min_child_samples': 9, 'min_child_weight': 0.0002609056602337313, 'min_split_gain': 1.3126370333417618, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "0.7208683100155452                                                                \n",
      "100%|██████████| 50/50 [07:28<00:00,  8.97s/trial, best loss: -0.7211814345991561]\n",
      "------------best_params------------ {'boosting_type': 'dart', 'class_weight': 'balanced', 'feature_fraction': 0.7402191951555392, 'learning_rate': 0.5915395046412429, 'max_depth': 7, 'min_child_samples': 3, 'min_child_weight': 4.577060363790685e-05, 'min_split_gain': 1.2487060464543078, 'n_estimators': 1920, 'num_leaves': 712, 'reg_alpha': 3.3743706795384254, 'reg_lambda': 3.376493434477243, 'subsample': 0.7982660247799438, 'subsample_for_bin': 120000, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7402191951555392, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7402191951555392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (6136, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c3101bc11ac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         early_stopping_rounds=50,verbose=-1)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'------------train------------\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-58b450ac57e4>\u001b[0m in \u001b[0;36mmodel_metrics\u001b[0;34m(model, x, y, tp)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# 动态阈值评估\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0myprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'ks'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \"\"\"\n\u001b[1;32m    913\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 914\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    864\u001b[0m     raise ValueError(\n\u001b[1;32m    865\u001b[0m         \u001b[0;34m\"y should be a 1d array, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m         \"got an array of shape {} instead.\".format(shape))\n\u001b[0m\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (6136, 2) instead."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 贝叶斯调参 \n",
    "best_params = bayes_fmin(train_x, test_x , train_y, test_y ,50)  \n",
    "\n",
    "\n",
    "print('------------best_params------------',best_params)\n",
    "\n",
    "\n",
    "# 验证\n",
    "clf = LGBMClassifier(**best_params)\n",
    "clf.set_params(**{\"objective\": focal_loss_lgb})   #focal loss\n",
    "\n",
    "clf.fit(train_x, train_y,\n",
    "        eval_set=[(test_x,test_y)],\n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=50,verbose=-1)\n",
    "\n",
    "print('------------train------------\\n',model_metrics(clf, train_x,train_y))\n",
    "\n",
    "\n",
    "print('------------test------------\\n',model_metrics(clf, test_x,test_y))\n",
    "\n",
    "print('------------oot------------\\n',model_metrics(clf, oot_x,oot_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4558721e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7402191951555392, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7402191951555392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " 0.7811826286818826\n",
      "------------test------------\n",
      " 0.7211814345991561\n",
      "------------oot------------\n",
      " 0.7279370706333484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:999: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
      "Returning raw scores instead.\n",
      "  _log_warning(\"Cannot compute class probabilities or labels \"\n"
     ]
    }
   ],
   "source": [
    "# 验证\n",
    "best_params={'boosting_type': 'dart', 'class_weight': 'balanced', 'feature_fraction': 0.7402191951555392, 'learning_rate': 0.5915395046412429, 'max_depth': 7, 'min_child_samples': 3, 'min_child_weight': 4.577060363790685e-05, 'min_split_gain': 1.2487060464543078, 'n_estimators': 1920, 'num_leaves': 712, 'reg_alpha': 3.3743706795384254, 'reg_lambda': 3.376493434477243, 'subsample': 0.7982660247799438, 'subsample_for_bin': 120000, 'n_jobs': -1, 'verbose': -1, 'random_state': 0}\n",
    "clf = LGBMClassifier(**best_params)\n",
    "clf.set_params(**{\"objective\": focal_loss_lgb})   #focal loss\n",
    "\n",
    "clf.fit(train_x, train_y,\n",
    "        eval_set=[(test_x,test_y)],\n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=50,verbose=-1)\n",
    "\n",
    "print('------------train------------\\n',model_metrics(clf, train_x,train_y))\n",
    "\n",
    "\n",
    "print('------------test------------\\n',model_metrics(clf, test_x,test_y))\n",
    "\n",
    "print('------------oot------------\\n',model_metrics(clf, oot_x,oot_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2909c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "from lightgbm import plot_importance,plot_tree\n",
    "def get_importance(model):\n",
    "    plot_importance(model, max_num_features=100,figsize=(10,30),importance_type='gain')\n",
    "    plt.show()\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': model.booster_.feature_name(),\n",
    "        'gain': model.booster_.feature_importance('gain'),\n",
    "        'split': model.booster_.feature_importance('split')\n",
    "\n",
    "    }).sort_values('gain',ascending=False)\n",
    "    \n",
    "    return feature_importance\n",
    "\n",
    "\n",
    "feature_importance = get_importance(clf)\n",
    "\n",
    "\n",
    "\n",
    "ax = lgb.plot_tree(clf, tree_index=0, figsize=(10, 8), show_info=['split_gain'])\n",
    "plt.show()\n",
    "\n",
    "# graph = lgb.create_tree_digraph(clf, tree_index=0, name='Tree3')\n",
    "# graph.render(view=True)\n",
    "# clf.booster_.dump_model()\n",
    "# feature_importance.to_pickle('./data/feature_importance.pkl')\n",
    "print('------------oot------------\\n',model_metrics(clf, oot_x,oot_y,tp='ks'))\n",
    "feature_importance.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b172aad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2947031809327042, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2947031809327042\n",
      "------------train------------\n",
      " 0.8057854987245683\n",
      "------------test------------\n",
      " 0.7137819231623364\n",
      "------------oot------------\n",
      " 0.7099665195379928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BureauScore',\n",
       " 'MissingRate',\n",
       " 'Len_Name',\n",
       " 'Tel_nuniq',\n",
       " 'Email_nuniq',\n",
       " 'Len_of_addrs',\n",
       " 'City_nuniq',\n",
       " 'Current_State',\n",
       " 'CreditAccountActive',\n",
       " 'CreditAccountTotal',\n",
       " 'CreditAccountActivePor',\n",
       " 'Outstanding_Balance_Secured',\n",
       " 'Outstanding_Balance_UnSecured_Percentage',\n",
       " 'Outstanding_Balance_All',\n",
       " 'Outstanding_Balance_Secured_Percentage',\n",
       " 'Outstanding_Balance_UnSecured',\n",
       " 'Diff_dateBirth',\n",
       " 'State_nuniq',\n",
       " 'Birth_nuniq',\n",
       " 'TotalCAPSLast90Days',\n",
       " 'TotalCAPSLast7Days',\n",
       " 'TotalCAPSLast30Days',\n",
       " 'TotalCAPSLast180Days',\n",
       " 'CAPSLast30Days',\n",
       " 'CAPSLast7Days',\n",
       " 'CAPSLast180Days',\n",
       " 'NonCreditCAPSLast180Days',\n",
       " 'Pin_nuniq',\n",
       " 'Pan_nuniq',\n",
       " 'Ident_nuniq',\n",
       " 'Name_nuniq2',\n",
       " 'Tel_nuniq2',\n",
       " 'Email_nuniq2',\n",
       " 'Pan_nuniq2',\n",
       " 'Account_nuniq2',\n",
       " 'Ident_nuniq2',\n",
       " 'Gender_nuniq',\n",
       " 'Amount_Past_Due35_sum_30',\n",
       " 'Amount_Past_Due35_min_30',\n",
       " 'Amount_Past_Due35_sum_90',\n",
       " 'Amount_Past_Due35_mean_90',\n",
       " 'Amount_Past_Due35_max_90',\n",
       " 'Amount_Past_Due35_min_90',\n",
       " 'Amount_Past_Due35_std_90',\n",
       " 'Amount_Past_Due35_sum_360',\n",
       " 'Amount_Past_Due35_mean_360',\n",
       " 'Amount_Past_Due35_max_360',\n",
       " 'Amount_Past_Due35_std_360',\n",
       " 'Amount_Past_Due35_sum_9999',\n",
       " 'Amount_Past_Due35_max_9999',\n",
       " 'Amount_Past_Due35_min_9999',\n",
       " 'Amount_Past_Due35_std_9999',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_max_30',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_min_30',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_std_30',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_sum_90',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_mean_90',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_max_90',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_min_90',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_std_90',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_sum_360',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_max_360',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_std_360',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_sum_9999',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_mean_9999',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_max_9999',\n",
       " 'Highest_Credit_or_Original_Loan_Amount58_std_9999',\n",
       " 'Terms_Duration34_sum_30',\n",
       " 'Terms_Duration34_std_30',\n",
       " 'Terms_Duration34_sum_90',\n",
       " 'Terms_Duration34_std_90',\n",
       " 'Terms_Duration34_mean_360',\n",
       " 'Terms_Duration34_max_360',\n",
       " 'Terms_Duration34_min_360',\n",
       " 'Terms_Duration34_std_360',\n",
       " 'Terms_Duration34_sum_9999',\n",
       " 'Terms_Duration34_mean_9999',\n",
       " 'Terms_Duration34_max_9999',\n",
       " 'Terms_Duration34_min_9999',\n",
       " 'Terms_Duration34_std_9999',\n",
       " 'Payment_Rating34_sum_90',\n",
       " 'Payment_Rating34_mean_90',\n",
       " 'Payment_Rating34_max_90',\n",
       " 'Payment_Rating34_min_90',\n",
       " 'Payment_Rating34_std_90',\n",
       " 'Payment_Rating34_sum_360',\n",
       " 'Payment_Rating34_mean_360',\n",
       " 'Payment_Rating34_max_360',\n",
       " 'Payment_Rating34_min_360',\n",
       " 'Payment_Rating34_std_360',\n",
       " 'Payment_Rating34_sum_9999',\n",
       " 'Payment_Rating34_mean_9999',\n",
       " 'Payment_Rating34_max_9999',\n",
       " 'Payment_Rating34_min_9999',\n",
       " 'Payment_Rating34_std_9999',\n",
       " 'Current_Balance35_mean_30',\n",
       " 'Current_Balance35_min_30',\n",
       " 'Current_Balance35_std_30',\n",
       " 'Current_Balance35_sum_90',\n",
       " 'Current_Balance35_mean_90',\n",
       " 'Current_Balance35_max_90',\n",
       " 'Current_Balance35_std_90',\n",
       " 'Current_Balance35_sum_360',\n",
       " 'Current_Balance35_max_360',\n",
       " 'Current_Balance35_std_360',\n",
       " 'Current_Balance35_max_9999',\n",
       " 'Current_Balance35_std_9999',\n",
       " 'Settlement_Amount37_max_360',\n",
       " 'Settlement_Amount37_min_360',\n",
       " 'Settlement_Amount37_std_360',\n",
       " 'Settlement_Amount37_sum_9999',\n",
       " 'Settlement_Amount37_mean_9999',\n",
       " 'Settlement_Amount37_max_9999',\n",
       " 'Settlement_Amount37_min_9999',\n",
       " 'Settlement_Amount37_std_9999',\n",
       " 'Value_of_Collateral39_std_90',\n",
       " 'Value_of_Collateral39_std_360',\n",
       " 'Written_Off_Amt_Total41_sum_360',\n",
       " 'Written_Off_Amt_Total41_mean_360',\n",
       " 'Written_Off_Amt_Total41_min_360',\n",
       " 'Written_Off_Amt_Total41_std_360',\n",
       " 'Written_Off_Amt_Total41_sum_9999',\n",
       " 'Written_Off_Amt_Total41_mean_9999',\n",
       " 'Written_Off_Amt_Total41_max_9999',\n",
       " 'Written_Off_Amt_Total41_min_9999',\n",
       " 'Written_Off_Amt_Total41_std_9999',\n",
       " 'Written_Off_Amt_Principal45_sum_360',\n",
       " 'Written_Off_Amt_Principal45_mean_360',\n",
       " 'Written_Off_Amt_Principal45_min_360',\n",
       " 'Written_Off_Amt_Principal45_std_360',\n",
       " 'Written_Off_Amt_Principal45_max_9999',\n",
       " 'Written_Off_Amt_Principal45_min_9999',\n",
       " 'Rate_of_Interest36_sum_30',\n",
       " 'Rate_of_Interest36_std_30',\n",
       " 'Rate_of_Interest36_sum_90',\n",
       " 'Rate_of_Interest36_mean_90',\n",
       " 'Rate_of_Interest36_max_90',\n",
       " 'Rate_of_Interest36_std_90',\n",
       " 'Rate_of_Interest36_sum_360',\n",
       " 'Rate_of_Interest36_mean_360',\n",
       " 'Rate_of_Interest36_max_360',\n",
       " 'Rate_of_Interest36_min_360',\n",
       " 'Rate_of_Interest36_std_360',\n",
       " 'Rate_of_Interest36_sum_9999',\n",
       " 'Rate_of_Interest36_mean_9999',\n",
       " 'Rate_of_Interest36_max_9999',\n",
       " 'Rate_of_Interest36_min_9999',\n",
       " 'Rate_of_Interest36_std_9999',\n",
       " 'Repayment_Tenure36_std_30',\n",
       " 'Repayment_Tenure36_mean_90',\n",
       " 'Repayment_Tenure36_max_90',\n",
       " 'Repayment_Tenure36_min_90',\n",
       " 'Repayment_Tenure36_std_90',\n",
       " 'Repayment_Tenure36_sum_360',\n",
       " 'Repayment_Tenure36_mean_360',\n",
       " 'Repayment_Tenure36_min_360',\n",
       " 'Repayment_Tenure36_std_360',\n",
       " 'Repayment_Tenure36_mean_9999',\n",
       " 'Repayment_Tenure36_min_9999',\n",
       " 'Repayment_Tenure36_std_9999',\n",
       " 'Income26_count_360',\n",
       " 'Income26_std_360',\n",
       " 'Open_Date29_max_30',\n",
       " 'Open_Date29_min_30',\n",
       " 'Open_Date29_mean_30',\n",
       " 'Open_Date29_nuniq_30',\n",
       " 'Open_Date29_maxcount_30',\n",
       " 'Open_Date29_max_90',\n",
       " 'Open_Date29_mean_90',\n",
       " 'Open_Date29_mode_90',\n",
       " 'Open_Date29_nuniq_90',\n",
       " 'Open_Date29_maxcount_90',\n",
       " 'Open_Date29_max_360',\n",
       " 'Open_Date29_mean_360',\n",
       " 'Open_Date29_mode_360',\n",
       " 'Open_Date29_nuniq_360',\n",
       " 'Open_Date29_maxcount_360',\n",
       " 'Open_Date29_max_9999',\n",
       " 'Open_Date29_mean_9999',\n",
       " 'Open_Date29_mode_9999',\n",
       " 'Open_Date29_maxcount_9999',\n",
       " 'Portfolio_Type34_nuniq_30',\n",
       " 'Portfolio_Type34_nuniq_90',\n",
       " 'Portfolio_Type34_nuniq_360',\n",
       " 'Portfolio_Type34_nuniq_9999',\n",
       " 'Account_Type32_nuniq_30',\n",
       " 'Account_Type32_nuniq_90',\n",
       " 'Account_Type32_nuniq_360',\n",
       " 'Account_Type32_nuniq_9999',\n",
       " 'Occupation_Code35_nuniq_30',\n",
       " 'Occupation_Code35_nuniq_90',\n",
       " 'Occupation_Code35_nuniq_360',\n",
       " 'Occupation_Code35_nuniq_9999',\n",
       " 'AccountHoldertypeCode41_nuniq_90',\n",
       " 'AccountHoldertypeCode41_nuniq_360',\n",
       " 'AccountHoldertypeCode41_nuniq_9999',\n",
       " 'Payment_History_Profile43_mode_30',\n",
       " 'Payment_History_Profile43_mode_90',\n",
       " 'Payment_History_Profile43_nuniq_90',\n",
       " 'Payment_History_Profile43_mode_360',\n",
       " 'Payment_History_Profile43_nuniq_360',\n",
       " 'Payment_History_Profile43_mode_9999',\n",
       " 'Payment_History_Profile43_nuniq_9999',\n",
       " 'Date_Closed31_nuniq_30',\n",
       " 'Date_Closed31_maxcount_30',\n",
       " 'Date_Closed31_max_90',\n",
       " 'Date_Closed31_min_90',\n",
       " 'Date_Closed31_mean_90',\n",
       " 'Date_Closed31_mode_90',\n",
       " 'Date_Closed31_nuniq_90',\n",
       " 'Date_Closed31_maxcount_90',\n",
       " 'Date_Closed31_min_360',\n",
       " 'Date_Closed31_mode_360',\n",
       " 'Date_Closed31_nuniq_360',\n",
       " 'Date_Closed31_maxcount_360',\n",
       " 'Date_Closed31_max_9999',\n",
       " 'Date_Closed31_min_9999',\n",
       " 'Date_Closed31_mean_9999',\n",
       " 'Date_Closed31_mode_9999',\n",
       " 'Date_Closed31_nuniq_9999',\n",
       " 'Date_of_Last_Payment40_nuniq_30',\n",
       " 'Date_of_Last_Payment40_maxcount_30',\n",
       " 'Date_of_Last_Payment40_min_90',\n",
       " 'Date_of_Last_Payment40_nuniq_90',\n",
       " 'Date_of_Last_Payment40_maxcount_90',\n",
       " 'Date_of_Last_Payment40_max_360',\n",
       " 'Date_of_Last_Payment40_min_360',\n",
       " 'Date_of_Last_Payment40_mean_360',\n",
       " 'Date_of_Last_Payment40_mode_360',\n",
       " 'Date_of_Last_Payment40_nuniq_360',\n",
       " 'Date_of_Last_Payment40_maxcount_360',\n",
       " 'Date_of_Last_Payment40_max_9999',\n",
       " 'Date_of_Last_Payment40_min_9999',\n",
       " 'Date_of_Last_Payment40_mean_9999',\n",
       " 'Date_of_Last_Payment40_mode_9999',\n",
       " 'Date_of_Last_Payment40_maxcount_9999',\n",
       " 'Date_Reported33_nuniq_30',\n",
       " 'Date_Reported33_max_90',\n",
       " 'Date_Reported33_mean_90',\n",
       " 'Date_Reported33_mode_90',\n",
       " 'Date_Reported33_nuniq_90',\n",
       " 'Date_Reported33_maxcount_90',\n",
       " 'Date_Reported33_max_360',\n",
       " 'Date_Reported33_mean_360',\n",
       " 'Date_Reported33_mode_360',\n",
       " 'Date_Reported33_nuniq_360',\n",
       " 'Date_Reported33_maxcount_360',\n",
       " 'Date_Reported33_max_9999',\n",
       " 'Date_Reported33_mean_9999',\n",
       " 'Date_Reported33_mode_9999',\n",
       " 'Date_Reported33_nuniq_9999',\n",
       " 'Date_Reported33_maxcount_9999',\n",
       " 'DateOfAddition34_nuniq_30',\n",
       " 'DateOfAddition34_max_90',\n",
       " 'DateOfAddition34_mean_90',\n",
       " 'DateOfAddition34_mode_90',\n",
       " 'DateOfAddition34_nuniq_90',\n",
       " 'DateOfAddition34_maxcount_90',\n",
       " 'DateOfAddition34_max_360',\n",
       " 'DateOfAddition34_mean_360',\n",
       " 'DateOfAddition34_mode_360',\n",
       " 'DateOfAddition34_nuniq_360',\n",
       " 'DateOfAddition34_maxcount_360',\n",
       " 'DateOfAddition34_max_9999',\n",
       " 'DateOfAddition34_mean_9999',\n",
       " 'DateOfAddition34_mode_9999',\n",
       " 'DateOfAddition34_nuniq_9999',\n",
       " 'DateOfAddition34_maxcount_9999',\n",
       " 'Account_Status34_mode_30',\n",
       " 'Account_Status34_nuniq_30',\n",
       " 'Account_Status34_mode_90',\n",
       " 'Account_Status34_nuniq_90',\n",
       " 'Account_Status34_mode_360',\n",
       " 'Account_Status34_nuniq_360',\n",
       " 'Account_Status34_nuniq_9999',\n",
       " 'Month50_sum_30',\n",
       " 'Month50_max_30',\n",
       " 'Month50_std_30',\n",
       " 'Month50_sum_90',\n",
       " 'Month50_mean_90',\n",
       " 'Month50_max_90',\n",
       " 'Month50_min_90',\n",
       " 'Month50_std_90',\n",
       " 'Month50_sum_360',\n",
       " 'Month50_min_360',\n",
       " 'Month50_std_360',\n",
       " 'Month50_sum_9999',\n",
       " 'Month50_mean_9999',\n",
       " 'Month50_max_9999',\n",
       " 'Month50_min_9999',\n",
       " 'Month50_std_9999',\n",
       " 'Days_Past_Due58_max_30',\n",
       " 'Days_Past_Due58_min_30',\n",
       " 'Days_Past_Due58_mean_90',\n",
       " 'Days_Past_Due58_max_90',\n",
       " 'Days_Past_Due58_min_90',\n",
       " 'Days_Past_Due58_std_90',\n",
       " 'Days_Past_Due58_sum_360',\n",
       " 'Days_Past_Due58_mean_360',\n",
       " 'Days_Past_Due58_max_360',\n",
       " 'Days_Past_Due58_min_360',\n",
       " 'Days_Past_Due58_std_360',\n",
       " 'Days_Past_Due58_sum_9999',\n",
       " 'Days_Past_Due58_mean_9999',\n",
       " 'Days_Past_Due58_max_9999',\n",
       " 'Days_Past_Due58_min_9999',\n",
       " 'Days_Past_Due58_std_9999',\n",
       " 'Duecount53_sum_30',\n",
       " 'Duecount53_mean_30',\n",
       " 'Duecount53_max_30',\n",
       " 'Duecount53_min_30',\n",
       " 'Duecount53_std_30',\n",
       " 'Duecount53_sum_90',\n",
       " 'Duecount53_mean_90',\n",
       " 'Duecount53_max_90',\n",
       " 'Duecount53_min_90',\n",
       " 'Duecount53_std_90',\n",
       " 'Duecount53_sum_360',\n",
       " 'Duecount53_mean_360',\n",
       " 'Duecount53_max_360',\n",
       " 'Duecount53_min_360',\n",
       " 'Duecount53_std_360',\n",
       " 'Duecount53_sum_9999',\n",
       " 'Duecount53_mean_9999',\n",
       " 'Duecount53_max_9999',\n",
       " 'Duecount53_min_9999',\n",
       " 'Duecount53_std_9999',\n",
       " 'Duesum51_sum_90',\n",
       " 'Duesum51_mean_90',\n",
       " 'Duesum51_min_90',\n",
       " 'Duesum51_std_90',\n",
       " 'Duesum51_sum_360',\n",
       " 'Duesum51_mean_360',\n",
       " 'Duesum51_max_360',\n",
       " 'Duesum51_min_360',\n",
       " 'Duesum51_std_360',\n",
       " 'Duesum51_sum_9999',\n",
       " 'Duesum51_mean_9999',\n",
       " 'Duesum51_max_9999',\n",
       " 'Duesum51_min_9999',\n",
       " 'Duesum51_std_9999',\n",
       " 'Amount_Financed35_count_7',\n",
       " 'Amount_Financed35_std_7',\n",
       " 'Amount_Financed35_count_30',\n",
       " 'Amount_Financed35_sum_30',\n",
       " 'Amount_Financed35_mean_30',\n",
       " 'Amount_Financed35_max_30',\n",
       " 'Amount_Financed35_min_30',\n",
       " 'Amount_Financed35_std_30',\n",
       " 'Amount_Financed35_count_90',\n",
       " 'Amount_Financed35_sum_90',\n",
       " 'Amount_Financed35_median_90',\n",
       " 'Amount_Financed35_mean_90',\n",
       " 'Amount_Financed35_max_90',\n",
       " 'Amount_Financed35_min_90',\n",
       " 'Amount_Financed35_std_90',\n",
       " 'Amount_Financed35_count_360',\n",
       " 'Amount_Financed35_sum_360',\n",
       " 'Amount_Financed35_median_360',\n",
       " 'Amount_Financed35_mean_360',\n",
       " 'Amount_Financed35_max_360',\n",
       " 'Amount_Financed35_min_360',\n",
       " 'Amount_Financed35_std_360',\n",
       " 'Amount_Financed35_sum_9999',\n",
       " 'Amount_Financed35_median_9999',\n",
       " 'Amount_Financed35_mean_9999',\n",
       " 'Amount_Financed35_max_9999',\n",
       " 'Amount_Financed35_min_9999',\n",
       " 'Amount_Financed35_std_9999',\n",
       " 'Duration_Of_Agreement41_min_7',\n",
       " 'Duration_Of_Agreement41_std_7',\n",
       " 'Duration_Of_Agreement41_sum_30',\n",
       " 'Duration_Of_Agreement41_mean_30',\n",
       " 'Duration_Of_Agreement41_max_30',\n",
       " 'Duration_Of_Agreement41_min_30',\n",
       " 'Duration_Of_Agreement41_std_30',\n",
       " 'Duration_Of_Agreement41_sum_90',\n",
       " 'Duration_Of_Agreement41_mean_90',\n",
       " 'Duration_Of_Agreement41_max_90',\n",
       " 'Duration_Of_Agreement41_min_90',\n",
       " 'Duration_Of_Agreement41_std_90',\n",
       " 'Duration_Of_Agreement41_sum_360',\n",
       " 'Duration_Of_Agreement41_mean_360',\n",
       " 'Duration_Of_Agreement41_max_360',\n",
       " 'Duration_Of_Agreement41_min_360',\n",
       " 'Duration_Of_Agreement41_std_360',\n",
       " 'Duration_Of_Agreement41_sum_9999',\n",
       " 'Duration_Of_Agreement41_mean_9999',\n",
       " 'Duration_Of_Agreement41_max_9999',\n",
       " 'Duration_Of_Agreement41_min_9999',\n",
       " 'Duration_Of_Agreement41_std_9999',\n",
       " 'Date_of_Request35_nuniq_7',\n",
       " 'Date_of_Request35_mode_30',\n",
       " 'Date_of_Request35_nuniq_30',\n",
       " 'Date_of_Request35_mode_90',\n",
       " 'Date_of_Request35_nuniq_90',\n",
       " 'Date_of_Request35_mode_360',\n",
       " 'Date_of_Request35_nuniq_360',\n",
       " 'Date_of_Request35_mode_9999',\n",
       " 'Date_of_Request35_nuniq_9999',\n",
       " 'Enquiry_Reason34_nuniq_7',\n",
       " 'Enquiry_Reason34_nuniq_30',\n",
       " 'Enquiry_Reason34_mode_90',\n",
       " 'Enquiry_Reason34_nuniq_90',\n",
       " 'Enquiry_Reason34_nuniq_360',\n",
       " 'Enquiry_Reason34_mode_9999',\n",
       " 'Enquiry_Reason34_nuniq_9999',\n",
       " 'Finance_Purpose35_mode_7',\n",
       " 'Finance_Purpose35_nuniq_7',\n",
       " 'Finance_Purpose35_mode_30',\n",
       " 'Finance_Purpose35_nuniq_30',\n",
       " 'Finance_Purpose35_mode_90',\n",
       " 'Finance_Purpose35_nuniq_90',\n",
       " 'Finance_Purpose35_mode_360',\n",
       " 'Finance_Purpose35_nuniq_360',\n",
       " 'Finance_Purpose35_mode_9999',\n",
       " 'Finance_Purpose35_nuniq_9999',\n",
       " 'Number_of_Major_Credit_Card_Held62_sum_7',\n",
       " 'Number_of_Major_Credit_Card_Held62_sum_9999',\n",
       " 'Income36_sum_9999',\n",
       " 'Marital_Status44_nuniq_7',\n",
       " 'Marital_Status44_nuniq_30',\n",
       " 'Marital_Status44_nuniq_90',\n",
       " 'Marital_Status44_nuniq_360',\n",
       " 'Marital_Status44_nuniq_9999',\n",
       " 'Current_Balance_Income_por',\n",
       " 'Current_Balance_Income_diff',\n",
       " 'CAPSLast180Days_nocrt_por',\n",
       " 'CAPSLast180Days_apply_por',\n",
       " 'Duesum_days_mean',\n",
       " 'Duesum_amt_mean',\n",
       " 'feature_1',\n",
       " 'feature_2',\n",
       " 'feature_3',\n",
       " 'feature_4',\n",
       " 'feature_5',\n",
       " 'feature_6',\n",
       " 'feature_7',\n",
       " 'feature_8',\n",
       " 'feature_9',\n",
       " 'feature_10',\n",
       " 'feature_11',\n",
       " 'feature_12',\n",
       " 'feature_13',\n",
       " 'feature_14',\n",
       " 'feature_15',\n",
       " 'feature_16',\n",
       " 'feature_17',\n",
       " 'feature_18',\n",
       " 'feature_19',\n",
       " 'feature_20',\n",
       " 'feature_21',\n",
       " 'feature_22',\n",
       " 'feature_23',\n",
       " 'feature_24',\n",
       " 'feature_25',\n",
       " 'feature_26',\n",
       " 'feature_27',\n",
       " 'feature_28',\n",
       " 'feature_29',\n",
       " 'feature_30',\n",
       " 'feature_31',\n",
       " 'feature_32',\n",
       " 'feature_33',\n",
       " 'feature_34',\n",
       " 'feature_35',\n",
       " 'feature_36',\n",
       " 'feature_37',\n",
       " 'feature_38',\n",
       " 'feature_39',\n",
       " 'feature_40',\n",
       " 'feature_41',\n",
       " 'feature_42',\n",
       " 'feature_43',\n",
       " 'feature_44',\n",
       " 'feature_45',\n",
       " 'feature_46',\n",
       " 'feature_47',\n",
       " 'feature_48',\n",
       " 'feature_49',\n",
       " 'feature_50',\n",
       " 'feature_51',\n",
       " 'feature_52',\n",
       " 'feature_53',\n",
       " 'feature_54',\n",
       " 'feature_55',\n",
       " 'feature_56',\n",
       " 'feature_57',\n",
       " 'feature_58',\n",
       " 'feature_59',\n",
       " 'feature_60',\n",
       " 'feature_61',\n",
       " 'feature_62',\n",
       " 'feature_63',\n",
       " 'feature_64',\n",
       " 'feature_65',\n",
       " 'feature_66',\n",
       " 'feature_67',\n",
       " 'feature_68',\n",
       " 'feature_69',\n",
       " 'feature_70',\n",
       " 'feature_71',\n",
       " 'feature_72',\n",
       " 'feature_73',\n",
       " 'feature_74',\n",
       " 'feature_75',\n",
       " 'feature_76',\n",
       " 'feature_77',\n",
       " 'feature_78',\n",
       " 'feature_79',\n",
       " 'feature_80',\n",
       " 'feature_81',\n",
       " 'feature_82',\n",
       " 'feature_83',\n",
       " 'feature_84',\n",
       " 'feature_85',\n",
       " 'feature_86',\n",
       " 'feature_87',\n",
       " 'feature_88',\n",
       " 'feature_89',\n",
       " 'feature_90',\n",
       " 'feature_91',\n",
       " 'feature_92',\n",
       " 'feature_93',\n",
       " 'feature_94',\n",
       " 'feature_95',\n",
       " 'feature_96',\n",
       " 'feature_97',\n",
       " 'feature_98',\n",
       " 'feature_99',\n",
       " 'feature_100',\n",
       " 'feature_101',\n",
       " 'feature_102',\n",
       " 'feature_103',\n",
       " 'feature_104',\n",
       " 'feature_105',\n",
       " 'feature_106',\n",
       " 'feature_107',\n",
       " 'feature_108',\n",
       " 'feature_109',\n",
       " 'feature_110',\n",
       " 'feature_111',\n",
       " 'feature_112',\n",
       " 'feature_113',\n",
       " 'feature_114',\n",
       " 'feature_115',\n",
       " 'feature_116',\n",
       " 'feature_117',\n",
       " 'feature_118',\n",
       " 'feature_119',\n",
       " 'feature_120',\n",
       " 'feature_121',\n",
       " 'feature_122',\n",
       " 'feature_123',\n",
       " 'feature_124',\n",
       " 'feature_125',\n",
       " 'feature_126',\n",
       " 'feature_127',\n",
       " 'feature_128',\n",
       " 'feature_129',\n",
       " 'feature_130',\n",
       " 'feature_131',\n",
       " 'feature_132',\n",
       " 'feature_133',\n",
       " 'feature_134',\n",
       " 'feature_135',\n",
       " 'feature_136',\n",
       " 'feature_137',\n",
       " 'feature_138',\n",
       " 'feature_139',\n",
       " 'feature_140',\n",
       " 'feature_141',\n",
       " 'feature_142',\n",
       " 'feature_143',\n",
       " 'feature_144',\n",
       " 'feature_145',\n",
       " 'feature_146',\n",
       " 'feature_147',\n",
       " 'feature_148',\n",
       " 'feature_149',\n",
       " 'feature_150',\n",
       " 'feature_151',\n",
       " 'feature_152',\n",
       " 'feature_153',\n",
       " 'feature_154',\n",
       " 'feature_155',\n",
       " 'feature_156',\n",
       " 'feature_157',\n",
       " 'feature_158',\n",
       " 'feature_159',\n",
       " 'feature_160',\n",
       " 'feature_161',\n",
       " 'feature_162',\n",
       " 'feature_163',\n",
       " 'feature_164',\n",
       " 'feature_165',\n",
       " 'feature_166',\n",
       " 'feature_167',\n",
       " 'feature_168',\n",
       " 'feature_169',\n",
       " 'feature_170',\n",
       " 'feature_171',\n",
       " 'feature_172',\n",
       " 'feature_173',\n",
       " 'feature_174',\n",
       " 'feature_175',\n",
       " 'feature_176',\n",
       " 'feature_177',\n",
       " 'feature_178',\n",
       " 'feature_179',\n",
       " 'feature_180',\n",
       " 'feature_181',\n",
       " 'feature_182',\n",
       " 'feature_183',\n",
       " 'feature_184',\n",
       " 'feature_185',\n",
       " 'feature_186',\n",
       " 'feature_187',\n",
       " 'feature_188',\n",
       " 'feature_189',\n",
       " 'feature_190',\n",
       " 'feature_191',\n",
       " 'feature_192',\n",
       " 'feature_193',\n",
       " 'feature_194',\n",
       " 'feature_195',\n",
       " 'feature_196',\n",
       " 'feature_197',\n",
       " 'feature_198',\n",
       " 'feature_199',\n",
       " 'feature_200',\n",
       " 'feature_201',\n",
       " 'feature_202',\n",
       " 'feature_203',\n",
       " 'feature_204',\n",
       " 'feature_205',\n",
       " 'feature_206',\n",
       " 'feature_207',\n",
       " 'feature_208',\n",
       " 'feature_209',\n",
       " 'feature_210',\n",
       " 'feature_211',\n",
       " 'feature_212',\n",
       " 'feature_213',\n",
       " 'feature_214',\n",
       " 'feature_215',\n",
       " 'feature_216',\n",
       " 'feature_217',\n",
       " 'feature_218',\n",
       " 'feature_219',\n",
       " 'feature_220',\n",
       " 'feature_221',\n",
       " 'feature_222',\n",
       " 'feature_223',\n",
       " 'feature_224',\n",
       " 'feature_225',\n",
       " 'feature_226',\n",
       " 'feature_227',\n",
       " 'feature_228',\n",
       " 'feature_229',\n",
       " 'feature_230',\n",
       " 'feature_231',\n",
       " 'feature_232',\n",
       " 'feature_233',\n",
       " 'feature_234',\n",
       " 'feature_235',\n",
       " 'feature_236',\n",
       " 'feature_237',\n",
       " 'feature_238',\n",
       " 'feature_239',\n",
       " 'feature_240',\n",
       " 'feature_241',\n",
       " 'feature_242',\n",
       " 'feature_243',\n",
       " 'feature_244',\n",
       " 'feature_245',\n",
       " 'feature_246',\n",
       " 'feature_247',\n",
       " 'feature_248',\n",
       " 'feature_249',\n",
       " 'feature_250',\n",
       " 'feature_251',\n",
       " 'feature_252',\n",
       " 'feature_253',\n",
       " 'feature_254',\n",
       " 'feature_255',\n",
       " 'feature_256',\n",
       " 'feature_257',\n",
       " 'feature_258',\n",
       " 'feature_259',\n",
       " 'feature_260',\n",
       " 'feature_261',\n",
       " 'feature_262',\n",
       " 'feature_263',\n",
       " 'feature_264',\n",
       " 'feature_265',\n",
       " 'feature_266',\n",
       " 'feature_267',\n",
       " 'feature_268',\n",
       " 'feature_269',\n",
       " 'feature_270',\n",
       " 'feature_271',\n",
       " 'feature_272',\n",
       " 'feature_273',\n",
       " 'feature_274',\n",
       " 'feature_275',\n",
       " 'feature_276',\n",
       " 'feature_277',\n",
       " 'feature_278',\n",
       " 'feature_279',\n",
       " 'feature_280',\n",
       " 'feature_281',\n",
       " 'feature_282',\n",
       " 'feature_283',\n",
       " 'feature_284',\n",
       " 'feature_285',\n",
       " 'feature_286',\n",
       " 'feature_287',\n",
       " 'feature_288',\n",
       " 'feature_289',\n",
       " 'feature_290',\n",
       " 'feature_291',\n",
       " 'feature_292',\n",
       " 'feature_293',\n",
       " 'feature_294',\n",
       " 'feature_295',\n",
       " 'feature_296',\n",
       " 'feature_297',\n",
       " 'feature_298',\n",
       " 'feature_299',\n",
       " 'feature_300',\n",
       " 'feature_301',\n",
       " 'feature_302',\n",
       " 'feature_303',\n",
       " 'feature_304',\n",
       " 'feature_305',\n",
       " 'feature_306',\n",
       " 'feature_307',\n",
       " 'feature_308',\n",
       " 'feature_309',\n",
       " 'feature_310',\n",
       " 'feature_311',\n",
       " 'feature_312',\n",
       " 'feature_313',\n",
       " 'feature_314',\n",
       " 'feature_315',\n",
       " 'feature_316',\n",
       " 'feature_317',\n",
       " 'feature_318',\n",
       " 'feature_319',\n",
       " 'feature_320',\n",
       " 'feature_321',\n",
       " 'feature_322',\n",
       " 'feature_323',\n",
       " 'feature_324',\n",
       " 'feature_325',\n",
       " 'feature_326',\n",
       " 'feature_327',\n",
       " 'feature_328',\n",
       " 'feature_329',\n",
       " 'feature_330',\n",
       " 'feature_331',\n",
       " 'feature_332',\n",
       " 'feature_333',\n",
       " 'feature_334',\n",
       " 'feature_335',\n",
       " 'feature_336',\n",
       " 'feature_337',\n",
       " 'feature_338',\n",
       " 'feature_339',\n",
       " 'feature_340',\n",
       " 'feature_341',\n",
       " 'feature_342',\n",
       " 'feature_343',\n",
       " 'feature_344',\n",
       " 'feature_345',\n",
       " 'feature_346',\n",
       " 'feature_347',\n",
       " 'feature_348',\n",
       " 'feature_349',\n",
       " 'feature_350',\n",
       " 'feature_351',\n",
       " 'feature_352',\n",
       " 'feature_353',\n",
       " 'feature_354',\n",
       " 'feature_355',\n",
       " 'feature_356',\n",
       " 'feature_357',\n",
       " 'feature_358',\n",
       " 'feature_359',\n",
       " 'feature_360',\n",
       " 'feature_361',\n",
       " 'feature_362',\n",
       " 'feature_363',\n",
       " 'feature_364',\n",
       " 'feature_365',\n",
       " 'feature_366',\n",
       " 'feature_367',\n",
       " 'feature_368',\n",
       " 'feature_369',\n",
       " 'feature_370',\n",
       " 'feature_371',\n",
       " 'feature_372',\n",
       " 'feature_373',\n",
       " 'feature_374',\n",
       " 'feature_375',\n",
       " 'feature_376',\n",
       " 'feature_377',\n",
       " 'feature_378',\n",
       " 'feature_379',\n",
       " 'feature_380',\n",
       " 'feature_381',\n",
       " 'feature_382',\n",
       " 'feature_383',\n",
       " 'feature_384',\n",
       " 'feature_385',\n",
       " 'feature_386',\n",
       " 'feature_387',\n",
       " 'feature_388',\n",
       " 'feature_389',\n",
       " 'feature_390',\n",
       " 'feature_391',\n",
       " 'feature_392',\n",
       " 'feature_393',\n",
       " 'feature_394',\n",
       " 'feature_395',\n",
       " 'feature_396',\n",
       " 'feature_397',\n",
       " 'feature_398',\n",
       " 'feature_399',\n",
       " 'feature_400',\n",
       " 'feature_401',\n",
       " 'feature_402',\n",
       " 'feature_403',\n",
       " 'feature_404',\n",
       " 'feature_405',\n",
       " 'feature_406',\n",
       " 'feature_407',\n",
       " 'feature_408',\n",
       " 'feature_409',\n",
       " 'feature_410',\n",
       " 'feature_411',\n",
       " 'feature_412',\n",
       " 'feature_413',\n",
       " 'feature_414',\n",
       " 'feature_415',\n",
       " 'feature_416',\n",
       " 'feature_417',\n",
       " 'feature_418',\n",
       " 'feature_419',\n",
       " 'feature_420',\n",
       " 'feature_421',\n",
       " 'feature_422',\n",
       " 'feature_423',\n",
       " 'feature_424',\n",
       " 'feature_425',\n",
       " 'feature_426',\n",
       " 'feature_427',\n",
       " 'feature_428',\n",
       " 'feature_429',\n",
       " 'feature_430',\n",
       " 'feature_431',\n",
       " 'feature_432',\n",
       " 'feature_433',\n",
       " 'feature_434',\n",
       " 'feature_435',\n",
       " 'feature_436',\n",
       " 'feature_437',\n",
       " 'feature_438',\n",
       " 'feature_439',\n",
       " 'feature_440',\n",
       " 'feature_441',\n",
       " 'feature_442',\n",
       " 'feature_443',\n",
       " 'feature_444',\n",
       " 'feature_445',\n",
       " 'feature_446',\n",
       " 'feature_447',\n",
       " 'feature_448',\n",
       " 'feature_449',\n",
       " 'feature_450',\n",
       " 'feature_451',\n",
       " 'feature_452',\n",
       " 'feature_453',\n",
       " 'feature_454',\n",
       " 'feature_455',\n",
       " 'feature_456',\n",
       " 'feature_457',\n",
       " 'feature_458',\n",
       " 'feature_459',\n",
       " 'feature_460',\n",
       " 'feature_461',\n",
       " 'feature_462',\n",
       " 'feature_463',\n",
       " 'feature_464',\n",
       " 'feature_465',\n",
       " 'feature_466',\n",
       " 'feature_467',\n",
       " 'feature_468',\n",
       " 'feature_469',\n",
       " 'feature_470',\n",
       " 'feature_471',\n",
       " 'feature_472',\n",
       " 'feature_473',\n",
       " 'feature_474',\n",
       " 'feature_475',\n",
       " 'feature_476',\n",
       " 'feature_477',\n",
       " 'feature_478',\n",
       " 'feature_479',\n",
       " 'feature_480',\n",
       " 'feature_481',\n",
       " 'feature_482',\n",
       " 'feature_483',\n",
       " 'feature_484',\n",
       " 'feature_485',\n",
       " 'feature_486',\n",
       " 'feature_487',\n",
       " 'feature_488',\n",
       " 'feature_489',\n",
       " 'feature_490',\n",
       " 'feature_491',\n",
       " 'feature_492',\n",
       " 'feature_493',\n",
       " 'feature_494',\n",
       " 'feature_495',\n",
       " 'feature_496',\n",
       " 'feature_497',\n",
       " 'feature_498',\n",
       " 'feature_499',\n",
       " 'feature_500',\n",
       " 'feature_501',\n",
       " 'feature_502',\n",
       " 'feature_503',\n",
       " 'feature_504',\n",
       " 'feature_505',\n",
       " 'feature_506',\n",
       " 'feature_507',\n",
       " 'feature_508',\n",
       " 'feature_509',\n",
       " 'feature_510',\n",
       " 'feature_511',\n",
       " 'feature_512',\n",
       " 'feature_513',\n",
       " 'feature_514',\n",
       " 'feature_515',\n",
       " 'feature_516',\n",
       " 'feature_517',\n",
       " 'feature_518',\n",
       " 'feature_519',\n",
       " 'feature_520',\n",
       " 'feature_521',\n",
       " 'feature_522',\n",
       " 'feature_523',\n",
       " 'feature_524',\n",
       " 'feature_525',\n",
       " 'feature_526',\n",
       " 'feature_527',\n",
       " 'feature_528',\n",
       " 'feature_529',\n",
       " 'feature_530',\n",
       " 'feature_531',\n",
       " 'feature_532',\n",
       " 'feature_533',\n",
       " 'feature_534',\n",
       " 'feature_535',\n",
       " 'feature_536',\n",
       " 'feature_537',\n",
       " 'feature_538',\n",
       " 'feature_539',\n",
       " 'feature_540',\n",
       " 'feature_541',\n",
       " 'feature_542',\n",
       " 'feature_543',\n",
       " 'feature_544',\n",
       " 'feature_545',\n",
       " 'feature_546',\n",
       " 'feature_547',\n",
       " 'feature_548',\n",
       " 'feature_549',\n",
       " 'feature_550',\n",
       " 'feature_551',\n",
       " 'feature_552',\n",
       " 'feature_553',\n",
       " 'feature_554',\n",
       " 'feature_555',\n",
       " 'feature_556',\n",
       " 'feature_557',\n",
       " 'feature_558',\n",
       " 'feature_559',\n",
       " 'feature_560',\n",
       " 'feature_561',\n",
       " 'feature_562',\n",
       " 'feature_563',\n",
       " 'feature_564',\n",
       " 'feature_565',\n",
       " 'feature_566',\n",
       " 'feature_567',\n",
       " 'feature_568',\n",
       " 'feature_569',\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params={'boosting_type': 'dart', 'max_depth': 11, 'n_estimators': 1010, 'learning_rate': 0.2896725270248636, 'num_leaves': 1144, 'class_weight': None, 'reg_alpha': 4.215612812184543, 'reg_lambda': 0.44772383819316397, 'subsample_for_bin': 220000, 'subsample': 0.8562357844168368, 'feature_fraction': 0.4775606601751762, 'min_child_samples': 10, 'min_child_weight': 0.00011360202014521585, 'min_split_gain': 6.008916845569482, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "\n",
    "clf = LGBMClassifier(**best_params)\n",
    "clf.fit(train_x, train_y,\n",
    "        eval_set=[(test_x,test_y)],\n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=50,verbose=-1)\n",
    "\n",
    "print('------------train------------\\n',model_metrics(clf, train_x,train_y))\n",
    "\n",
    "\n",
    "print('------------test------------\\n',model_metrics(clf, test_x,test_y))\n",
    "\n",
    "print('------------oot------------\\n',model_metrics(clf, oot_x,oot_y))\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "# pickle.dump(clf, open('./saved_models/SMS_ZX_NSMS.pkl', 'wb'))\n",
    "# pickle.dump(clf, open('./saved_models/ZX_NSMS.pkl', 'wb'))\n",
    "# pickle.dump(clf, open('./saved_models/SMS_NSMS.pkl', 'wb'))\n",
    "\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "# model = pickle.load(open('./saved_models/SMS_ZX_NSMS.pkl', 'rb'))\n",
    "\n",
    "model.feature_name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7149d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feccb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b25bead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13384706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1761"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.feature_name_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "522e9b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25791da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "0407######################################################################征信模型v2\n",
    "#### 纯征信nocate\n",
    "best_params= {'boosting_type': 'gbdt', 'max_depth': 11, 'n_estimators': 1730, 'learning_rate': 0.1291868482369266, 'num_leaves': 1584, 'class_weight': None, 'reg_alpha': 4.191420786845277, 'reg_lambda': 8.571864740877707, 'subsample_for_bin': 120000, 'subsample': 0.24917130389729128, 'feature_fraction': 0.2502338763355014, 'min_child_samples': 21, 'min_child_weight': 11.029313629457622, 'min_split_gain': 1.4021163489891033, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "------------oot------------\n",
    " 0.5524426835343319\n",
    "feature\tgain\tsplit\n",
    "232\tDate_of_Last_Payment40_min_9999\t212.067219\t13\n",
    "279\tMonth50_mean_90\t150.353552\t14\n",
    "398\tDate_of_Request35_mode_9999\t107.792249\t25\n",
    "394\tDate_of_Request35_mode_90\t94.797440\t25\n",
    "225\tDate_of_Last_Payment40_max_360\t91.386570\t22\n",
    "\n",
    "####纯非短信\n",
    "{'boosting_type': 'dart', 'max_depth': 9, 'n_estimators': 180, 'learning_rate': 0.5743342145344562, 'num_leaves': 1688, 'class_weight': None, 'reg_alpha': 2.835217636179232, 'reg_lambda': 4.9760732788644075, 'subsample_for_bin': 220000, 'subsample': 0.2568609211119177, 'feature_fraction': 0.3896673716718368, 'min_child_samples': 35, 'min_child_weight': 2.459470973780215, 'min_split_gain': 4.0201798822125765, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "------------train------------\n",
    " 0.7827683736266859\n",
    "------------test------------\n",
    " 0.7191583388851877\n",
    "------------oot------------\n",
    " 0.7104102225466005\n",
    "feature\tgain\tsplit\n",
    "1\tfeature_2\t1818.608220\t94\n",
    "644\tfeature_645\t112.530722\t3\n",
    "761\tfeature_762\t111.568910\t18\n",
    "253\tfeature_254\t92.183211\t13\n",
    "780\tfeature_781\t82.409350\t15\n",
    " \n",
    "####全旧短信模型\n",
    "{'boosting_type': 'dart', 'max_depth': 11, 'n_estimators': 1010, 'learning_rate': 0.2896725270248636, 'num_leaves': 1144, 'class_weight': None, 'reg_alpha': 4.215612812184543, 'reg_lambda': 0.44772383819316397, 'subsample_for_bin': 220000, 'subsample': 0.8562357844168368, 'feature_fraction': 0.4775606601751762, 'min_child_samples': 10, 'min_child_weight': 0.00011360202014521585, 'min_split_gain': 6.008916845569482, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "------------train------------\n",
    " 0.7611966926084524\n",
    "------------test------------\n",
    " 0.7172573839662447\n",
    "------------oot------------\n",
    " 0.7184327899998841\n",
    "feature\tgain\tsplit\n",
    "1\tfeature_2\t1017.962109\t9\n",
    "147\tfeature_148\t63.685699\t1\n",
    "253\tfeature_254\t40.906101\t1\n",
    "644\tfeature_645\t33.428999\t2\n",
    "322\tfeature_323\t26.262199\t1\n",
    "\n",
    "####纯短信模型\n",
    "{'boosting_type': 'goss', 'max_depth': 21, 'n_estimators': 1490, 'learning_rate': 0.21930551278322413, 'num_leaves': 1800, 'class_weight': 'balanced', 'reg_alpha': 8.067758774301975, 'reg_lambda': 5.5502301875718985, 'subsample_for_bin': 120000, 'subsample': 0.45881373515492696, 'feature_fraction': 0.4266373931982871, 'min_child_samples': 380, 'min_child_weight': 0.07111103164297841, 'min_split_gain': 2.3939541961285906, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "------------oot------------\n",
    " 0.5705453028881242\n",
    "feature\tgain\tsplit\n",
    "221\tfeature_1200_sms\t67.078499\t1\n",
    "244\tfeature_1223_sms\t63.761200\t1\n",
    "300\tfeature_1279_sms\t56.925898\t2\n",
    "113\tfeature_1092_sms\t55.080101\t1\n",
    "210\tfeature_1189_sms\t42.302898\t1\n",
    " \n",
    "####征信+非短信\n",
    "{'boosting_type': 'gbdt', 'max_depth': 8, 'n_estimators': 750, 'learning_rate': 0.1296823658012421, 'num_leaves': 688, 'class_weight': 'balanced', 'reg_alpha': 5.074138878618853, 'reg_lambda': 7.598729510431946, 'subsample_for_bin': 180000, 'subsample': 0.6760794529948264, 'feature_fraction': 0.2947031809327042, 'min_child_samples': 16, 'min_child_weight': 0.21358223805839294, 'min_split_gain': 3.873755769678977, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "best_params2={'boosting_type': 'dart', 'max_depth': 11, 'n_estimators': 1010, 'learning_rate': 0.2896725270248636, 'num_leaves': 1144, 'class_weight': None, 'reg_alpha': 4.215612812184543, 'reg_lambda': 0.44772383819316397, 'subsample_for_bin': 220000, 'subsample': 0.8562357844168368, 'feature_fraction': 0.4775606601751762, 'min_child_samples': 10, 'min_child_weight': 0.00011360202014521585, 'min_split_gain': 6.008916845569482, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "------------train------------\n",
    " (0.7757365457020085, 0.40966377198842124)\n",
    "------------test------------\n",
    " (0.727230735065512, 0.35149900066622247)\n",
    "------------oot------------\n",
    " (0.7249412064551257, 0.3437111180620721)\n",
    "feature\tgain\tsplit\n",
    "432\tfeature_2\t13061.886389\t717\n",
    "91\tPayment_Rating34_mean_9999\t1377.554522\t153\n",
    "63\tHighest_Credit_or_Original_Loan_Amount58_sum_9999\t1009.247422\t126\n",
    "232\tDate_of_Last_Payment40_min_9999\t759.438452\t81\n",
    "684\tfeature_254\t715.694582\t76\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "####征信+非短信+删feature2\n",
    "------------oot------------\n",
    " (0.6444050556656125, 0.23184930316616276)\n",
    "###仅feature2\n",
    "------------oot------------\n",
    " 0.6585664801492139\n",
    "\n",
    "####征信+旧模型全量特征\n",
    "{'boosting_type': 'dart', 'class_weight': None, 'feature_fraction': 0.5292621851563598, 'learning_rate': 0.23938665909933876, 'max_depth': 14, 'min_child_samples': 91, 'min_child_weight': 0.13614638467767243, 'min_split_gain': 3.983261344288425, 'n_estimators': 2110, 'num_leaves': 736, 'reg_alpha': 6.683254293882608, 'reg_lambda': 9.003622043307438, 'subsample': 0.8646544005048526, 'subsample_for_bin': 340000, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "------------train------------\n",
    " 0.7969966275001877\n",
    "------------test------------\n",
    " 0.7310259826782145\n",
    "------------oot------------\n",
    " 0.7241094081256734\n",
    "    \tfeature\tgain\tsplit\n",
    "432\tfeature_2\t13278.014326\t1026\n",
    "91\tPayment_Rating34_mean_9999\t2055.987793\t325\n",
    "63\tHighest_Credit_or_Original_Loan_Amount58_sum_9999\t1120.851019\t194\n",
    "684\tfeature_254\t1081.867901\t151\n",
    "434\tfeature_4\t981.386679\t162\n",
    "1666\tfeature_1236_sms\t924.502141\t145\n",
    "232\tDate_of_Last_Payment40_min_9999\t865.378960\t122\n",
    "--lgb +cate 0.71 firstnm过拟合\n",
    "--lgb+孤立森林 0.7241719667744064\n",
    "--autoglun 0.7300130909764941 0.3458033573141487\n",
    "--DNN ['bestval, layer_nums, k, norm', 0.6400850334225374, 2, 16, 0.01]\n",
    "--transformer(0.6019485860586893, 0.1655510374309248)\n",
    "--tabnet 1 1 7 (0.6177689732272154, 0.18599381364473638)\n",
    "0327######################################################################征信模型v1\n",
    "------------train------------\n",
    " 0.5955648848848103\n",
    "------------test------------\n",
    " 0.6020843981653152\n",
    "------------oot------------\n",
    " 0.5509538161177687   0.5572\n",
    " \n",
    " feature\tgain\tsplit\n",
    "75\tPayment_Rating34_mean_9999\t49.402302\t1\n",
    "17\tOutstanding_Balance_All\t18.478901\t1\n",
    "288\tDuesum51_max_360\t17.084700\t1\n",
    "57\tHighest_Credit_or_Original_Loan_Amount58_sum_9999\t13.311400\t1\n",
    "201\tDate_of_Last_Payment40_min_9999\t13.146600\t1\n",
    "\n",
    "############原短信模型\n",
    "------------train------------\n",
    " 0.7120853595132949\n",
    "------------test------------\n",
    " 0.6249807618958398\n",
    "------------oot------------\n",
    " 0.5929736057969629\n",
    " \n",
    "feature\tgain\tsplit\n",
    "1091\tfeature_1092_sms\t56.609210\t4\n",
    "637\tfeature_638\t52.878950\t3\n",
    "1195\tfeature_1196_sms\t52.133701\t3\n",
    "255\tfeature_256\t50.603701\t2\n",
    "147\tfeature_148\t39.322701\t1\n",
    "\n",
    "############## all feas 征信\n",
    "------------train------------\n",
    " 0.7853083217441518\n",
    "------------test------------\n",
    " 0.6151015121696859\n",
    "------------oot------------\n",
    " 0.5476976322696694\n",
    " \n",
    "feature\tgain\tsplit\n",
    "119\tHighest_Credit_or_Original_Loan_Amount58_sum_9999\t507.115121\t115\n",
    "121\tHighest_Credit_or_Original_Loan_Amount58_max_9999\t380.598070\t94\n",
    "1256\tDuesum_days_mean\t289.224108\t77\n",
    "689\tDate_of_Last_Payment40_min_9999\t287.205211\t74\n",
    "10\tFirst_Name1\t268.579750\t54\n",
    "\n",
    "#### no cate\n",
    "------------train------------\n",
    " 0.6136383342685391\n",
    "------------test------------\n",
    " 0.5851689136991731\n",
    "------------oot------------\n",
    " 0.5700932824995477  0.576\n",
    "\n",
    "feature\tgain\tsplit\n",
    "75\tPayment_Rating34_mean_9999\t58.121599\t2  \n",
    "286\tDuesum51_sum_360\t28.412300\t1\n",
    "57\tHighest_Credit_or_Original_Loan_Amount58_sum_9999\t26.575100\t1\n",
    "187\tDate_Closed31_min_9999\t14.249900\t1\n",
    "18\tOutstanding_Balance_UnSecured\t13.894300\t1\n",
    "201\tDate_of_Last_Payment40_min_9999\t13.299500\t1\n",
    "279\tDuecount53_max_9999\t8.855690\t1\n",
    "21\tBirth_nuniq\t7.208710\t1\n",
    "0\tBureauScore\t0.000000\t0\n",
    "{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'feature_fraction': 0.8627221849600804, 'learning_rate': 0.34384893394376054, 'max_depth': 11, 'min_child_samples': 1198, 'min_child_weight': 0.003952236654749962, 'min_split_gain': 0.05949040934772148, 'n_estimators': 600, 'num_leaves': 688, 'reg_alpha': 3.5594821118603353, 'reg_lambda': 0.602149615246626, 'subsample': 0.8276897177180422, 'subsample_for_bin': 240000, 'n_jobs': -1, 'objective': 'binary', 'silent': True, 'verbose': -1, 'random_state': 0}\n",
    "#### catst cat\n",
    "------------train------------\n",
    " 0.7142082720221239\n",
    "------------test------------\n",
    " 0.6097048242750667\n",
    "------------oot------------\n",
    " 0.5540017953382643\n",
    " \tfeature\tgain\tsplit\n",
    "55\tHighest_Credit_or_Original_Loan_Amount58_sum_9999\t96.336401\t4\n",
    "73\tPayment_Rating34_mean_9999\t85.414260\t6\n",
    "374\tFirst_Name1_cb\t55.024140\t7\n",
    "72\tPayment_Rating34_sum_9999\t44.194199\t1\n",
    "268\tDuecount53_std_90\t43.439360\t4\n",
    " ------------train------------\n",
    " 0.6576732034576184\n",
    "------------test------------\n",
    " 0.596752167506254\n",
    "------------oot------------\n",
    " 0.5608230567852523\n",
    " 55\tHighest_Credit_or_Original_Loan_Amount58_sum_9999\t390.087529\t64\n",
    "20\tOutstanding_Balance_UnSecured\t341.853791\t59\n",
    "73\tPayment_Rating34_mean_9999\t301.705399\t53\n",
    "276\tDuecount53_max_9999\t212.709760\t39\n",
    "72\tPayment_Rating34_sum_9999\t203.015642\t3\n",
    " \n",
    "###征信+全旧特征  \n",
    "------------best_params------------ {'boosting_type': 'dart', 'class_weight': None, 'feature_fraction': 0.991392744378254, 'learning_rate': 0.4510972062848847, 'max_depth': 7, 'min_child_samples': 3, 'min_child_weight': 0.06580338317188161, 'min_split_gain': 3.521483184411901, 'n_estimators': 620, 'num_leaves': 536, 'reg_alpha': 3.7218762172324906, 'reg_lambda': 3.473122296406963, 'subsample': 0.47024140562740857, 'subsample_for_bin': 300000, 'n_jobs': -1, 'objective': 'binary', 'silent': True, 'verbose': -1, 'random_state': 0}\n",
    "------------train------------\n",
    " 0.8271731112970069\n",
    "------------test------------\n",
    " 0.612970887668147\n",
    "------------oot------------2.2%提升\n",
    " 0.6150194039886545\n",
    "\n",
    "66\tPayment_Rating34_mean_9999\t874.495518\t127\n",
    "1552\tfeature_1196_sms\t466.063108\t78\n",
    "49\tHighest_Credit_or_Original_Loan_Amount58_max_9999\t416.588179\t71\n",
    "364\tfeature_8\t414.652489\t60\n",
    "178\tDate_of_Last_Payment40_min_360\t323.697860\t54\n",
    "\n",
    "####征信+非短信\n",
    "{'boosting_type': 'dart', 'class_weight': 'balanced', 'feature_fraction': 0.17995978970954704, 'learning_rate': 0.07690886698935129, 'max_depth': 14, 'min_child_samples': 3, 'min_child_weight': 35.61164739586946, 'min_split_gain': 1.702474867184973, 'n_estimators': 120, 'num_leaves': 1904, 'reg_alpha': 6.286057155945472, 'reg_lambda': 5.4600895052199885, 'subsample': 0.2767001565456063, 'subsample_for_bin': 320000, 'n_jobs': -1, 'objective': 'binary', 'silent': True, 'verbose': -1, 'random_state': 0}\n",
    "------------train------------\n",
    " 0.7832807147506298\n",
    "------------test------------\n",
    " 0.6358589213031557\n",
    "------------oot------------2.1%提升\n",
    " 0.6114492066038413\n",
    " feature\tgain\tsplit\n",
    "610\tfeature_254\t275.991280\t18\n",
    "66\tPayment_Rating34_mean_9999\t246.923480\t23\n",
    "13\tOutstanding_Balance_UnSecured\t207.914050\t16\n",
    "502\tfeature_146\t196.294701\t14\n",
    "358\tfeature_2\t181.366581\t17\n",
    "{'boosting_type': 'dart', 'class_weight': 'balanced', 'feature_fraction': 0.6321724090841454, 'learning_rate': 0.35706456691656796, 'max_depth': 12, 'min_child_samples': 2, 'min_child_weight': 0.002290570255954292, 'min_split_gain': 1.23684757609968, 'n_estimators': 1700, 'num_leaves': 1640, 'reg_alpha': 8.94729123569297, 'reg_lambda': 7.85980599994622, 'subsample': 0.7809264483077517, 'subsample_for_bin': 20000, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "------------train------------\n",
    " 0.8414409134323174\n",
    "------------test------------\n",
    " 0.6170694712311154\n",
    "------------oot------------\n",
    " 0.6172994153204474][base]\n",
    " \n",
    "####纯非短信\n",
    "------------train------------\n",
    " 0.7256212490982487\n",
    "------------test------------\n",
    " 0.6035682530527892\n",
    "------------oot------------\n",
    " 0.6027984749864326\n",
    " \n",
    " ------------train------------\n",
    " 0.6423776717894365\n",
    "------------test------------\n",
    " 0.6160434794366807\n",
    "------------oot------------\n",
    " 0.5935999262750826\n",
    " \n",
    " \tfeature\tgain\tsplit\n",
    "252\tfeature_253\t67.532101\t2\n",
    "255\tfeature_256\t57.024399\t2\n",
    "7\tfeature_8\t38.250450\t4\n",
    "1\tfeature_2\t31.335800\t2\n",
    "3\tfeature_4\t28.566200\t2\n",
    "\n",
    "####纯短信\n",
    "------------train------------\n",
    " 0.6513204252509733\n",
    "------------test------------\n",
    " 0.5819320469286919\n",
    "------------oot------------\n",
    " 0.5721036517726407\n",
    "\tfeature\tgain\tsplit\n",
    "113\tfeature_1092_sms\t30.375099\t2\n",
    "34\tfeature_1013_sms\t22.397099\t2\n",
    "265\tfeature_1244_sms\t19.532010\t2\n",
    "257\tfeature_1236_sms\t17.757660\t2\n",
    "189\tfeature_1168_sms\t11.141960\t2\n",
    "\n",
    "######### 征信+非短信优化验证\n",
    "###ft50-filtert\n",
    " 0.6107017178588373\n",
    "--- ft60-nofilt\n",
    " ------------train------------\n",
    " 0.7776614271344713\n",
    "------------test------------\n",
    " 0.6380635077328068\n",
    "------------oot------------\n",
    " 0.6180195985405197\n",
    "2464\tfeature_2_+_Payment_Rating34_mean_9999\t71.528502\t2\n",
    "2259\tDuesum51_sum_360_+_feature_254\t66.058098\t1\n",
    "2260\tDuesum51_sum_360_+_feature_322\t58.763901\t1\n",
    "3492\tBureauScore_/_feature_254\t56.664170\t2\n",
    "3420\tBirth_nuniq_/_Email_nuniq2\t37.157701\t2\n",
    "--ft60-filter\n",
    " 0.6087835047323888\n",
    "### focal loss+lgb\n",
    "\n",
    "\n",
    "### qcut4+oh + lgb\n",
    "------------oot------------\n",
    " 0.6169734556165758\n",
    "feature\tgain\tsplit\n",
    "66\tPayment_Rating34_mean_9999\t1414.136241\t181\n",
    "501\tfeature_145\t998.096571\t120\n",
    "65\tPayment_Rating34_sum_9999\t925.031363\t123\n",
    "358\tfeature_2\t854.604890\t108\n",
    "16\tBirth_nuniq\t550.947980\t76\n",
    "### 征信+旧特征+qcut4+DNN\n",
    "隐藏层vs神经元数vs norm 1 60 0.01\n",
    "验证集最优结果： 1.0151114463806152 1.0118298530578613\n",
    "------------train------------\n",
    " (0.6183410050043374, 0.1792503681475925)\n",
    "------------test------------\n",
    " (0.6012399560179311, 0.16452676985536663)\n",
    "------------oot------------\n",
    " (0.6188490038603186, 0.17209307088172954)\n",
    " --qcut50 15847cols\n",
    " ['bestval, layer_nums, k, norm', 0.6226751905413662, 1, 22, 0.01]\n",
    "### 征信+旧特征+ DNN\n",
    "oot参与搜索参数： 隐藏层vs神经元数vs norm 1 12 0.01\n",
    "验证集最优结果： 0.6594440937042236 0.6678001284599304\n",
    "------------train------------\n",
    " (0.6623875104578614, 0.2434398723137574)\n",
    "------------test------------\n",
    " (0.6166708957117484, 0.19025966336801153)\n",
    "------------oot------------\n",
    " (0.6311501428420273, 0.21031397940480784)\n",
    " --pytorch_tabular-dnn-transformer纯oot: 0.60\n",
    " --AutoGluon 21models--纯oot:0.6290817493284547 0.21659425013908756\n",
    "{'roc_auc': 0.6290817493284547, 'accuracy': 0.6513274336283186, 'balanced_accuracy': 0.5299661070171786, 'mcc': 0.1139253842762341, 'f1': 0.7786516853932586, 'precision': 0.6581196581196581, 'recall': 0.953232462173315}\n",
    "### 征信+旧特征+LGB+DNN\n",
    "base LGB 0.617 \n",
    "--DNN oot参与搜索参数：['bestval, layer_nums, k, norm', 0.6285083333048902, 1, 40, 0.4]\n",
    "--tabnet  oot参与搜索参数0.59：nd,nd,ns1, 1, 7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f630c9",
   "metadata": {},
   "source": [
    "#### 评分卡分数分布 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08dd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame()\n",
    "res_df['score'] = clf.predict_proba(x)[:,1]*100\n",
    "res_df['y'] = y\n",
    "\n",
    "\n",
    "#分数区间计算\n",
    "score_bin = np.arange(10,100,10)\n",
    "good_total = sum(res_df.y == 0)\n",
    "bad_total = sum(res_df.y == 1)\n",
    "bin_rate = []\n",
    "bad_rate = []\n",
    "ks = []\n",
    "good_num = []\n",
    "bad_num = []\n",
    "for i in range(len(score_bin)-1):\n",
    "    #取出分数区间的样本\n",
    "    if score_bin[i+1] == 61:\n",
    "        index_1 = (res_df.score >= score_bin[i]) & (res_df.score <= score_bin[i+1]) \n",
    "    else:\n",
    "        index_1 = (res_df.score >= score_bin[i]) & (res_df.score < score_bin[i+1]) \n",
    "    res_df_temp = res_df.loc[index_1,['y','score']]\n",
    "    #计算该分数区间的指标\n",
    "    good_num.append(sum(res_df_temp.y==0))\n",
    "    bad_num.append(sum(res_df_temp.y==1))\n",
    "    #区间样本率\n",
    "    bin_rate.append(res_df_temp.shape[0]/res_df.shape[0]*100)\n",
    "    #坏样本率\n",
    "    bad_rate.append(res_df_temp.y.sum()/res_df_temp.shape[0]*100)\n",
    "    #以该分数为注入分数的ks值\n",
    "    ks.append(sum(bad_num[0:i+1])/bad_total - sum(good_num[0:i+1])/good_total )\n",
    "res_df_result = pd.DataFrame({'好信用数量':good_num,'坏信用数量':bad_num,'区间样本率':bin_rate,\n",
    "                            '坏信用率':bad_rate,'KS值(真正率-假正率)':ks},index=zip( (score_bin[1:] -10 ),(score_bin[1:]  )) )\n",
    "print('评分卡10个区间分数统计结果如下：')\n",
    "res_df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ef1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c1edb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2802dde2",
   "metadata": {},
   "source": [
    "#### 暴力加工ft top50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880df4dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "start3\n",
      "['Account_Type32_mode_360vcount', 'Amount_Financed35_mean_90', 'Amount_Past_Due35_max_360', 'Amount_Past_Due35_mean_9999', 'Birth_nuniq', 'BureauScore', 'CAPSLast180Days_nocrt_por', 'Current_Balance35_sum_9999', 'Date_of_Last_Payment40_max_360', 'Date_of_Last_Payment40_mean_360', 'Date_of_Request35_mode_90', 'Date_of_Request35_mode_9999', 'Duecount53_sum_9999', 'Duesum51_max_360', 'Duration_Of_Agreement41_sum_9999', 'Email_nuniq', 'Email_nuniq2', 'Highest_Credit_or_Original_Loan_Amount58_max_9999', 'Highest_Credit_or_Original_Loan_Amount58_std_90', 'Highest_Credit_or_Original_Loan_Amount58_sum_9999', 'Name_nuniq2', 'Outstanding_Balance_UnSecured', 'Payment_Rating34_mean_9999', 'Rate_of_Interest36_min_9999', 'Tel_nuniq2', 'feature_2', 'feature_254', 'feature_322', 'feature_329', 'feature_4', 'feature_407', 'feature_409', 'feature_410', 'feature_638', 'feature_643', 'feature_669', 'feature_700', 'feature_701', 'feature_702', 'feature_710', 'feature_762', 'feature_778', 'feature_779', 'feature_781', 'feature_8', 'feature_804', 'feature_846', 'feature_874', 'feature_888', 'feature_9']\n",
      "Built 6175 features\n",
      "EntitySet scattered to 16 workers in 4 seconds\n",
      "Elapsed: 00:12 | Progress: 100%|██████████\n",
      "(6506, 6175)\n",
      "1246    0.734251\n",
      "6281    0.732211\n",
      "472     0.725835\n",
      "4355    0.671640\n",
      "5275    0.665519\n",
      "          ...   \n",
      "152     0.014665\n",
      "5783    0.014410\n",
      "5733    0.014410\n",
      "1471    0.014282\n",
      "414     0.014155\n",
      "Length: 6506, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "feature_10     0.990317\n",
       "feature_527    0.989702\n",
       "feature_528    0.989702\n",
       "feature_532    0.989702\n",
       "feature_531    0.989702\n",
       "feature_533    0.989548\n",
       "feature_529    0.989548\n",
       "feature_530    0.989394\n",
       "feature_534    0.989394\n",
       "feature_538    0.988933\n",
       "feature_524    0.988933\n",
       "feature_526    0.987396\n",
       "feature_540    0.987396\n",
       "feature_521    0.986474\n",
       "feature_535    0.986474\n",
       "feature_522    0.986013\n",
       "feature_536    0.986013\n",
       "feature_537    0.985706\n",
       "feature_523    0.985706\n",
       "feature_539    0.983861\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single [('feature_7', 1.0), ('feature_13', 1.0), ('feature_14', 1.0), ('feature_17', 1.0), ('feature_264', 1.0), ('feature_265', 1.0), ('feature_266', 1.0), ('feature_267', 1.0), ('feature_268', 1.0), ('feature_269', 1.0), ('feature_270', 1.0), ('feature_271', 1.0), ('feature_327', 1.0), ('feature_328', 1.0), ('feature_338', 1.0), ('feature_339', 1.0), ('feature_341', 1.0), ('feature_342', 1.0), ('feature_361', 1.0), ('feature_362', 1.0)]\n",
      "varance feature_552                                0.0\n",
      "feature_1300_sms                           0.0\n",
      "feature_327                                0.0\n",
      "feature_547                                0.0\n",
      "feature_548                                0.0\n",
      "                                          ... \n",
      "CAPSLast180Days_nocrt_por - feature_804    NaN\n",
      "CAPSLast180Days_nocrt_por - feature_846    NaN\n",
      "CAPSLast180Days_nocrt_por - feature_874    NaN\n",
      "CAPSLast180Days_nocrt_por - feature_888    NaN\n",
      "CAPSLast180Days_nocrt_por - feature_9      NaN\n",
      "Length: 7822, dtype: float64\n",
      "miss_drop 21\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_drop 409\n",
      "single_drop 95\n",
      "corr_drop1 3847\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_drop2 0\n",
      "4211 drop_list\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>report_timestamp</th>\n",
       "      <th>BureauScoreConfidLevel</th>\n",
       "      <th>MissingRate</th>\n",
       "      <th>Current_Finance_Purpose</th>\n",
       "      <th>Current_Amount_Financed</th>\n",
       "      <th>Current_Gender_Code</th>\n",
       "      <th>First_Name1</th>\n",
       "      <th>Len_Name</th>\n",
       "      <th>Name_nuniq</th>\n",
       "      <th>Tel_nuniq</th>\n",
       "      <th>IncomeTaxPAN_5</th>\n",
       "      <th>Len_of_addrs</th>\n",
       "      <th>City_nuniq</th>\n",
       "      <th>PinCode3</th>\n",
       "      <th>Current_State</th>\n",
       "      <th>Current_City</th>\n",
       "      <th>CreditAccountActive</th>\n",
       "      <th>CreditAccountActivePor</th>\n",
       "      <th>State_nuniq</th>\n",
       "      <th>TotalCAPSLast90Days</th>\n",
       "      <th>TotalCAPSLast7Days</th>\n",
       "      <th>TotalCAPSLast30Days</th>\n",
       "      <th>TotalCAPSLast180Days</th>\n",
       "      <th>CAPSLast7Days</th>\n",
       "      <th>CAPSLast180Days</th>\n",
       "      <th>Pin_nuniq</th>\n",
       "      <th>Pan_nuniq</th>\n",
       "      <th>Ident_nuniq</th>\n",
       "      <th>Pan_nuniq2</th>\n",
       "      <th>Account_nuniq2</th>\n",
       "      <th>Ident_nuniq2</th>\n",
       "      <th>Gender_nuniq</th>\n",
       "      <th>Amount_Past_Due35_max_30</th>\n",
       "      <th>Amount_Past_Due35_mean_90</th>\n",
       "      <th>Amount_Past_Due35_max_90</th>\n",
       "      <th>Amount_Past_Due35_min_90</th>\n",
       "      <th>Amount_Past_Due35_std_90</th>\n",
       "      <th>Amount_Past_Due35_max_9999</th>\n",
       "      <th>Amount_Past_Due35_min_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_360</th>\n",
       "      <th>Terms_Duration34_std_30</th>\n",
       "      <th>Terms_Duration34_std_90</th>\n",
       "      <th>Terms_Duration34_sum_360</th>\n",
       "      <th>Terms_Duration34_max_360</th>\n",
       "      <th>Terms_Duration34_mean_9999</th>\n",
       "      <th>Terms_Duration34_std_9999</th>\n",
       "      <th>Payment_Rating34_sum_90</th>\n",
       "      <th>Payment_Rating34_mean_90</th>\n",
       "      <th>Payment_Rating34_min_90</th>\n",
       "      <th>Payment_Rating34_std_90</th>\n",
       "      <th>Payment_Rating34_sum_360</th>\n",
       "      <th>Payment_Rating34_mean_360</th>\n",
       "      <th>Payment_Rating34_max_360</th>\n",
       "      <th>Payment_Rating34_min_360</th>\n",
       "      <th>Payment_Rating34_std_360</th>\n",
       "      <th>Payment_Rating34_sum_9999</th>\n",
       "      <th>Payment_Rating34_max_9999</th>\n",
       "      <th>Payment_Rating34_min_9999</th>\n",
       "      <th>Payment_Rating34_std_9999</th>\n",
       "      <th>Current_Balance35_sum_360</th>\n",
       "      <th>Current_Balance35_max_360</th>\n",
       "      <th>Current_Balance35_std_360</th>\n",
       "      <th>Current_Balance35_mean_9999</th>\n",
       "      <th>Settlement_Amount37_mean_360</th>\n",
       "      <th>Settlement_Amount37_std_360</th>\n",
       "      <th>Settlement_Amount37_mean_9999</th>\n",
       "      <th>Settlement_Amount37_max_9999</th>\n",
       "      <th>Settlement_Amount37_min_9999</th>\n",
       "      <th>Value_of_Collateral39_std_90</th>\n",
       "      <th>Value_of_Collateral39_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_360</th>\n",
       "      <th>Written_Off_Amt_Total41_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_max_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_min_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_std_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_std_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_max_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_9999</th>\n",
       "      <th>Rate_of_Interest36_sum_30</th>\n",
       "      <th>Rate_of_Interest36_max_30</th>\n",
       "      <th>Rate_of_Interest36_min_30</th>\n",
       "      <th>Rate_of_Interest36_std_30</th>\n",
       "      <th>Rate_of_Interest36_sum_90</th>\n",
       "      <th>Rate_of_Interest36_mean_90</th>\n",
       "      <th>Rate_of_Interest36_max_90</th>\n",
       "      <th>Rate_of_Interest36_min_90</th>\n",
       "      <th>Rate_of_Interest36_std_90</th>\n",
       "      <th>Rate_of_Interest36_sum_360</th>\n",
       "      <th>Rate_of_Interest36_sum_9999</th>\n",
       "      <th>Rate_of_Interest36_mean_9999</th>\n",
       "      <th>Rate_of_Interest36_max_9999</th>\n",
       "      <th>Rate_of_Interest36_std_9999</th>\n",
       "      <th>Repayment_Tenure36_std_30</th>\n",
       "      <th>Repayment_Tenure36_std_90</th>\n",
       "      <th>Repayment_Tenure36_mean_360</th>\n",
       "      <th>Repayment_Tenure36_min_360</th>\n",
       "      <th>Repayment_Tenure36_std_360</th>\n",
       "      <th>Repayment_Tenure36_sum_9999</th>\n",
       "      <th>Repayment_Tenure36_mean_9999</th>\n",
       "      <th>Repayment_Tenure36_max_9999</th>\n",
       "      <th>Repayment_Tenure36_min_9999</th>\n",
       "      <th>Repayment_Tenure36_std_9999</th>\n",
       "      <th>Income26_count_30</th>\n",
       "      <th>Income26_min_9999</th>\n",
       "      <th>Income26_std_9999</th>\n",
       "      <th>Open_Date29_max_30</th>\n",
       "      <th>Open_Date29_mean_30</th>\n",
       "      <th>Open_Date29_mode_30</th>\n",
       "      <th>Open_Date29_nuniq_30</th>\n",
       "      <th>Open_Date29_maxcount_30</th>\n",
       "      <th>Open_Date29_mode_90</th>\n",
       "      <th>Open_Date29_nuniq_90</th>\n",
       "      <th>Open_Date29_max_360</th>\n",
       "      <th>Open_Date29_mode_360</th>\n",
       "      <th>Open_Date29_maxcount_360</th>\n",
       "      <th>Open_Date29_max_9999</th>\n",
       "      <th>Open_Date29_mean_9999</th>\n",
       "      <th>Open_Date29_mode_9999</th>\n",
       "      <th>Open_Date29_maxcount_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_30</th>\n",
       "      <th>Portfolio_Type34_nuniq_90</th>\n",
       "      <th>Portfolio_Type34_nuniq_360</th>\n",
       "      <th>Portfolio_Type34_mode_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_9999</th>\n",
       "      <th>Account_Type32_mode_30</th>\n",
       "      <th>Account_Type32_nuniq_30</th>\n",
       "      <th>Account_Type32_mode_90</th>\n",
       "      <th>Account_Type32_nuniq_90</th>\n",
       "      <th>Account_Type32_mode_360</th>\n",
       "      <th>Account_Type32_nuniq_360</th>\n",
       "      <th>Account_Type32_mode_9999</th>\n",
       "      <th>Account_Type32_nuniq_9999</th>\n",
       "      <th>Occupation_Code35_nuniq_30</th>\n",
       "      <th>Occupation_Code35_nuniq_90</th>\n",
       "      <th>Occupation_Code35_nuniq_360</th>\n",
       "      <th>CurrencyCode32_mode_360</th>\n",
       "      <th>CurrencyCode32_mode_9999</th>\n",
       "      <th>AccountHoldertypeCode41_mode_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_360</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_9999</th>\n",
       "      <th>Payment_History_Profile43_mode_30</th>\n",
       "      <th>Payment_History_Profile43_mode_90</th>\n",
       "      <th>Payment_History_Profile43_nuniq_90</th>\n",
       "      <th>Payment_History_Profile43_mode_360</th>\n",
       "      <th>Payment_History_Profile43_nuniq_360</th>\n",
       "      <th>Payment_History_Profile43_mode_9999</th>\n",
       "      <th>Payment_History_Profile43_nuniq_9999</th>\n",
       "      <th>Date_Closed31_mode_30</th>\n",
       "      <th>Date_Closed31_nuniq_30</th>\n",
       "      <th>Date_Closed31_maxcount_30</th>\n",
       "      <th>Date_Closed31_max_90</th>\n",
       "      <th>Date_Closed31_min_90</th>\n",
       "      <th>Date_Closed31_mean_90</th>\n",
       "      <th>Date_Closed31_mode_90</th>\n",
       "      <th>Date_Closed31_nuniq_90</th>\n",
       "      <th>Date_Closed31_maxcount_90</th>\n",
       "      <th>Date_Closed31_mode_360</th>\n",
       "      <th>Date_Closed31_nuniq_360</th>\n",
       "      <th>Date_Closed31_maxcount_360</th>\n",
       "      <th>Date_Closed31_mean_9999</th>\n",
       "      <th>Date_Closed31_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_30</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_30</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_90</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_90</th>\n",
       "      <th>Date_of_Last_Payment40_min_360</th>\n",
       "      <th>Date_of_Last_Payment40_mode_360</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_360</th>\n",
       "      <th>Date_of_Last_Payment40_mean_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_9999</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_9999</th>\n",
       "      <th>Date_Reported33_nuniq_30</th>\n",
       "      <th>Date_Reported33_max_90</th>\n",
       "      <th>Date_Reported33_mode_90</th>\n",
       "      <th>Date_Reported33_nuniq_90</th>\n",
       "      <th>Date_Reported33_maxcount_90</th>\n",
       "      <th>Date_Reported33_max_360</th>\n",
       "      <th>Date_Reported33_mean_360</th>\n",
       "      <th>Date_Reported33_mode_360</th>\n",
       "      <th>Date_Reported33_nuniq_360</th>\n",
       "      <th>Date_Reported33_max_9999</th>\n",
       "      <th>Date_Reported33_mode_9999</th>\n",
       "      <th>Date_Reported33_nuniq_9999</th>\n",
       "      <th>Date_Reported33_maxcount_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_30</th>\n",
       "      <th>DateOfAddition34_max_90</th>\n",
       "      <th>DateOfAddition34_mean_90</th>\n",
       "      <th>DateOfAddition34_nuniq_90</th>\n",
       "      <th>DateOfAddition34_maxcount_90</th>\n",
       "      <th>DateOfAddition34_max_360</th>\n",
       "      <th>DateOfAddition34_mean_360</th>\n",
       "      <th>DateOfAddition34_mode_360</th>\n",
       "      <th>DateOfAddition34_maxcount_360</th>\n",
       "      <th>DateOfAddition34_max_9999</th>\n",
       "      <th>DateOfAddition34_min_9999</th>\n",
       "      <th>DateOfAddition34_mode_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_9999</th>\n",
       "      <th>DateOfAddition34_maxcount_9999</th>\n",
       "      <th>Account_Status34_mode_30</th>\n",
       "      <th>Account_Status34_nuniq_30</th>\n",
       "      <th>Account_Status34_mode_90</th>\n",
       "      <th>Account_Status34_nuniq_90</th>\n",
       "      <th>Account_Status34_nuniq_360</th>\n",
       "      <th>Account_Status34_mode_9999</th>\n",
       "      <th>Account_Status34_nuniq_9999</th>\n",
       "      <th>Month50_sum_30</th>\n",
       "      <th>Month50_mean_30</th>\n",
       "      <th>Month50_std_30</th>\n",
       "      <th>Month50_sum_90</th>\n",
       "      <th>Month50_mean_90</th>\n",
       "      <th>Month50_max_90</th>\n",
       "      <th>Month50_std_90</th>\n",
       "      <th>Month50_max_360</th>\n",
       "      <th>Month50_min_360</th>\n",
       "      <th>Month50_mean_9999</th>\n",
       "      <th>Month50_max_9999</th>\n",
       "      <th>Month50_min_9999</th>\n",
       "      <th>Month50_std_9999</th>\n",
       "      <th>Days_Past_Due58_sum_90</th>\n",
       "      <th>Days_Past_Due58_min_90</th>\n",
       "      <th>Days_Past_Due58_std_90</th>\n",
       "      <th>Days_Past_Due58_sum_360</th>\n",
       "      <th>Days_Past_Due58_mean_360</th>\n",
       "      <th>Days_Past_Due58_max_360</th>\n",
       "      <th>Days_Past_Due58_min_360</th>\n",
       "      <th>Days_Past_Due58_std_360</th>\n",
       "      <th>Days_Past_Due58_sum_9999</th>\n",
       "      <th>Days_Past_Due58_max_9999</th>\n",
       "      <th>Days_Past_Due58_min_9999</th>\n",
       "      <th>Days_Past_Due58_std_9999</th>\n",
       "      <th>Duecount53_mean_30</th>\n",
       "      <th>Duecount53_min_30</th>\n",
       "      <th>Duecount53_std_30</th>\n",
       "      <th>Duecount53_sum_90</th>\n",
       "      <th>Duecount53_mean_90</th>\n",
       "      <th>Duecount53_max_90</th>\n",
       "      <th>Duecount53_min_90</th>\n",
       "      <th>Duecount53_std_90</th>\n",
       "      <th>Duecount53_sum_360</th>\n",
       "      <th>Duecount53_mean_360</th>\n",
       "      <th>Duecount53_max_360</th>\n",
       "      <th>Duecount53_min_360</th>\n",
       "      <th>Duecount53_std_360</th>\n",
       "      <th>Duecount53_mean_9999</th>\n",
       "      <th>Duecount53_max_9999</th>\n",
       "      <th>Duecount53_min_9999</th>\n",
       "      <th>Duecount53_std_9999</th>\n",
       "      <th>Duesum51_mean_30</th>\n",
       "      <th>Duesum51_std_30</th>\n",
       "      <th>Duesum51_mean_90</th>\n",
       "      <th>Duesum51_max_90</th>\n",
       "      <th>Duesum51_sum_360</th>\n",
       "      <th>Duesum51_mean_360</th>\n",
       "      <th>Duesum51_min_360</th>\n",
       "      <th>Duesum51_std_360</th>\n",
       "      <th>Duesum51_sum_9999</th>\n",
       "      <th>Duesum51_mean_9999</th>\n",
       "      <th>Duesum51_max_9999</th>\n",
       "      <th>Duesum51_min_9999</th>\n",
       "      <th>Duesum51_std_9999</th>\n",
       "      <th>Amount_Financed35_std_7</th>\n",
       "      <th>Amount_Financed35_max_30</th>\n",
       "      <th>Amount_Financed35_min_30</th>\n",
       "      <th>Amount_Financed35_std_30</th>\n",
       "      <th>Amount_Financed35_count_90</th>\n",
       "      <th>Amount_Financed35_min_90</th>\n",
       "      <th>Amount_Financed35_count_360</th>\n",
       "      <th>Amount_Financed35_sum_360</th>\n",
       "      <th>Amount_Financed35_mean_360</th>\n",
       "      <th>Amount_Financed35_max_360</th>\n",
       "      <th>Amount_Financed35_min_360</th>\n",
       "      <th>Amount_Financed35_count_9999</th>\n",
       "      <th>Amount_Financed35_sum_9999</th>\n",
       "      <th>Amount_Financed35_max_9999</th>\n",
       "      <th>Amount_Financed35_min_9999</th>\n",
       "      <th>Amount_Financed35_std_9999</th>\n",
       "      <th>Duration_Of_Agreement41_std_7</th>\n",
       "      <th>Duration_Of_Agreement41_min_30</th>\n",
       "      <th>Duration_Of_Agreement41_min_90</th>\n",
       "      <th>Duration_Of_Agreement41_mean_360</th>\n",
       "      <th>Duration_Of_Agreement41_max_360</th>\n",
       "      <th>Duration_Of_Agreement41_min_360</th>\n",
       "      <th>Duration_Of_Agreement41_std_360</th>\n",
       "      <th>Duration_Of_Agreement41_mean_9999</th>\n",
       "      <th>Duration_Of_Agreement41_max_9999</th>\n",
       "      <th>Duration_Of_Agreement41_min_9999</th>\n",
       "      <th>Duration_Of_Agreement41_std_9999</th>\n",
       "      <th>Date_of_Request35_mode_7</th>\n",
       "      <th>Date_of_Request35_nuniq_7</th>\n",
       "      <th>Date_of_Request35_nuniq_90</th>\n",
       "      <th>Enquiry_Reason34_nuniq_7</th>\n",
       "      <th>Enquiry_Reason34_mode_30</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_409 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_409 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_409 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_409 * Tel_nuniq2</th>\n",
       "      <th>feature_409 * feature_638</th>\n",
       "      <th>feature_409 * feature_643</th>\n",
       "      <th>feature_409 * feature_701</th>\n",
       "      <th>feature_409 * feature_710</th>\n",
       "      <th>feature_409 * feature_778</th>\n",
       "      <th>feature_409 * feature_781</th>\n",
       "      <th>feature_409 * feature_8</th>\n",
       "      <th>feature_409 * feature_888</th>\n",
       "      <th>feature_410 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_410 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_410 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_410 * Name_nuniq2</th>\n",
       "      <th>feature_410 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_410 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_410 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_410 * Tel_nuniq2</th>\n",
       "      <th>feature_410 * feature_638</th>\n",
       "      <th>feature_410 * feature_643</th>\n",
       "      <th>feature_410 * feature_701</th>\n",
       "      <th>feature_410 * feature_710</th>\n",
       "      <th>feature_410 * feature_778</th>\n",
       "      <th>feature_410 * feature_781</th>\n",
       "      <th>feature_410 * feature_8</th>\n",
       "      <th>feature_410 * feature_888</th>\n",
       "      <th>feature_410 * feature_9</th>\n",
       "      <th>feature_638 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_638 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_638 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_638 * Name_nuniq2</th>\n",
       "      <th>feature_638 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_638 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_638 * Tel_nuniq2</th>\n",
       "      <th>feature_638 * feature_669</th>\n",
       "      <th>feature_638 * feature_701</th>\n",
       "      <th>feature_638 * feature_710</th>\n",
       "      <th>feature_638 * feature_762</th>\n",
       "      <th>feature_638 * feature_781</th>\n",
       "      <th>feature_638 * feature_8</th>\n",
       "      <th>feature_638 * feature_804</th>\n",
       "      <th>feature_638 * feature_846</th>\n",
       "      <th>feature_638 * feature_874</th>\n",
       "      <th>feature_638 * feature_888</th>\n",
       "      <th>feature_643 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_643 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_643 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_643 * Name_nuniq2</th>\n",
       "      <th>feature_643 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_643 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_643 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_643 * Tel_nuniq2</th>\n",
       "      <th>feature_643 * feature_700</th>\n",
       "      <th>feature_643 * feature_701</th>\n",
       "      <th>feature_643 * feature_702</th>\n",
       "      <th>feature_643 * feature_710</th>\n",
       "      <th>feature_643 * feature_778</th>\n",
       "      <th>feature_643 * feature_781</th>\n",
       "      <th>feature_643 * feature_8</th>\n",
       "      <th>feature_669 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_669 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_669 * Name_nuniq2</th>\n",
       "      <th>feature_669 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_669 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_669 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_669 * Tel_nuniq2</th>\n",
       "      <th>feature_669 * feature_710</th>\n",
       "      <th>feature_669 * feature_8</th>\n",
       "      <th>feature_700 * Name_nuniq2</th>\n",
       "      <th>feature_700 * feature_701</th>\n",
       "      <th>feature_700 * feature_779</th>\n",
       "      <th>feature_701 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_701 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_701 * Name_nuniq2</th>\n",
       "      <th>feature_701 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_701 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_701 * Tel_nuniq2</th>\n",
       "      <th>feature_701 * feature_710</th>\n",
       "      <th>feature_701 * feature_762</th>\n",
       "      <th>feature_701 * feature_778</th>\n",
       "      <th>feature_701 * feature_781</th>\n",
       "      <th>feature_701 * feature_888</th>\n",
       "      <th>feature_702 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_702 * Tel_nuniq2</th>\n",
       "      <th>feature_702 * feature_762</th>\n",
       "      <th>feature_702 * feature_778</th>\n",
       "      <th>feature_702 * feature_779</th>\n",
       "      <th>feature_702 * feature_781</th>\n",
       "      <th>feature_702 * feature_888</th>\n",
       "      <th>feature_702 * feature_9</th>\n",
       "      <th>feature_710 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_710 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_710 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_710 * Name_nuniq2</th>\n",
       "      <th>feature_710 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_710 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_710 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_710 * Tel_nuniq2</th>\n",
       "      <th>feature_710 * feature_762</th>\n",
       "      <th>feature_710 * feature_779</th>\n",
       "      <th>feature_710 * feature_8</th>\n",
       "      <th>feature_710 * feature_804</th>\n",
       "      <th>feature_710 * feature_846</th>\n",
       "      <th>feature_710 * feature_874</th>\n",
       "      <th>feature_710 * feature_888</th>\n",
       "      <th>feature_762 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_762 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_762 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_762 * Name_nuniq2</th>\n",
       "      <th>feature_762 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_762 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_762 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_762 * Tel_nuniq2</th>\n",
       "      <th>feature_762 * feature_8</th>\n",
       "      <th>feature_778 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_778 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_778 * Tel_nuniq2</th>\n",
       "      <th>feature_778 * feature_781</th>\n",
       "      <th>feature_778 * feature_888</th>\n",
       "      <th>feature_779 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_779 * Name_nuniq2</th>\n",
       "      <th>feature_779 * feature_888</th>\n",
       "      <th>feature_781 * Name_nuniq2</th>\n",
       "      <th>feature_781 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_781 * Tel_nuniq2</th>\n",
       "      <th>feature_8 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_8 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_8 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_8 * Name_nuniq2</th>\n",
       "      <th>feature_8 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_8 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_8 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_8 * Tel_nuniq2</th>\n",
       "      <th>feature_8 * feature_804</th>\n",
       "      <th>feature_8 * feature_846</th>\n",
       "      <th>feature_8 * feature_874</th>\n",
       "      <th>feature_8 * feature_888</th>\n",
       "      <th>feature_804 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_804 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_804 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_804 * Name_nuniq2</th>\n",
       "      <th>feature_804 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_804 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_804 * Tel_nuniq2</th>\n",
       "      <th>feature_846 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_846 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_846 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_846 * Name_nuniq2</th>\n",
       "      <th>feature_846 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_846 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_846 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_846 * Tel_nuniq2</th>\n",
       "      <th>feature_874 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_874 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_874 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_874 * Name_nuniq2</th>\n",
       "      <th>feature_874 * Outstanding_Balance_UnSecured</th>\n",
       "      <th>feature_874 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_874 * Tel_nuniq2</th>\n",
       "      <th>feature_888 * Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>feature_888 * Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>feature_888 * Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_888 * Name_nuniq2</th>\n",
       "      <th>feature_888 * Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_888 * Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_888 * Tel_nuniq2</th>\n",
       "      <th>Account_Type32_mode_360vcount - Payment_Rating34_mean_9999</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_407</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_409</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_410</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_643</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_700</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_701</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_779</th>\n",
       "      <th>Account_Type32_mode_360vcount - feature_781</th>\n",
       "      <th>Amount_Past_Due35_max_360 - Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>Amount_Past_Due35_mean_9999 - Date_of_Last_Payment40_max_360</th>\n",
       "      <th>Amount_Past_Due35_mean_9999 - feature_804</th>\n",
       "      <th>Birth_nuniq - Date_of_Request35_mode_90</th>\n",
       "      <th>Birth_nuniq - Email_nuniq</th>\n",
       "      <th>Birth_nuniq - Email_nuniq2</th>\n",
       "      <th>Birth_nuniq - Rate_of_Interest36_min_9999</th>\n",
       "      <th>Birth_nuniq - Tel_nuniq2</th>\n",
       "      <th>Birth_nuniq - feature_254</th>\n",
       "      <th>Birth_nuniq - feature_778</th>\n",
       "      <th>BureauScore - Duecount53_sum_9999</th>\n",
       "      <th>BureauScore - Duesum51_max_360</th>\n",
       "      <th>BureauScore - Duration_Of_Agreement41_sum_9999</th>\n",
       "      <th>BureauScore - Name_nuniq2</th>\n",
       "      <th>BureauScore - feature_2</th>\n",
       "      <th>CAPSLast180Days_nocrt_por - Payment_Rating34_mean_9999</th>\n",
       "      <th>CAPSLast180Days_nocrt_por - feature_4</th>\n",
       "      <th>CAPSLast180Days_nocrt_por - feature_638</th>\n",
       "      <th>CAPSLast180Days_nocrt_por - feature_9</th>\n",
       "      <th>Current_Balance35_sum_9999 - Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>Current_Balance35_sum_9999 - Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>Current_Balance35_sum_9999 - feature_762</th>\n",
       "      <th>Date_of_Last_Payment40_max_360 - Date_of_Request35_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mean_360 - feature_8</th>\n",
       "      <th>Date_of_Request35_mode_90 - Email_nuniq</th>\n",
       "      <th>Date_of_Request35_mode_90 - Email_nuniq2</th>\n",
       "      <th>Date_of_Request35_mode_90 - Name_nuniq2</th>\n",
       "      <th>Date_of_Request35_mode_90 - Rate_of_Interest36_min_9999</th>\n",
       "      <th>Date_of_Request35_mode_90 - Tel_nuniq2</th>\n",
       "      <th>Date_of_Request35_mode_9999 - Duecount53_sum_9999</th>\n",
       "      <th>Date_of_Request35_mode_9999 - Duesum51_max_360</th>\n",
       "      <th>Date_of_Request35_mode_9999 - Duration_Of_Agreement41_sum_9999</th>\n",
       "      <th>Date_of_Request35_mode_9999 - Email_nuniq</th>\n",
       "      <th>Date_of_Request35_mode_9999 - Name_nuniq2</th>\n",
       "      <th>Date_of_Request35_mode_9999 - feature_322</th>\n",
       "      <th>Date_of_Request35_mode_9999 - feature_329</th>\n",
       "      <th>Duecount53_sum_9999 - Duesum51_max_360</th>\n",
       "      <th>Duecount53_sum_9999 - Duration_Of_Agreement41_sum_9999</th>\n",
       "      <th>Duecount53_sum_9999 - Name_nuniq2</th>\n",
       "      <th>Duecount53_sum_9999 - feature_2</th>\n",
       "      <th>Duesum51_max_360 - Duration_Of_Agreement41_sum_9999</th>\n",
       "      <th>Duesum51_max_360 - Name_nuniq2</th>\n",
       "      <th>Duesum51_max_360 - feature_2</th>\n",
       "      <th>Duesum51_max_360 - feature_322</th>\n",
       "      <th>Duesum51_max_360 - feature_329</th>\n",
       "      <th>Duration_Of_Agreement41_sum_9999 - Name_nuniq2</th>\n",
       "      <th>Duration_Of_Agreement41_sum_9999 - feature_2</th>\n",
       "      <th>Duration_Of_Agreement41_sum_9999 - feature_322</th>\n",
       "      <th>Duration_Of_Agreement41_sum_9999 - feature_329</th>\n",
       "      <th>Email_nuniq - Rate_of_Interest36_min_9999</th>\n",
       "      <th>Email_nuniq - Tel_nuniq2</th>\n",
       "      <th>Email_nuniq2 - Name_nuniq2</th>\n",
       "      <th>Email_nuniq2 - Rate_of_Interest36_min_9999</th>\n",
       "      <th>Email_nuniq2 - Tel_nuniq2</th>\n",
       "      <th>Email_nuniq2 - feature_2</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_9999 - Outstanding_Balance_UnSecured</th>\n",
       "      <th>Rate_of_Interest36_min_9999 - Tel_nuniq2</th>\n",
       "      <th>feature_2 - Name_nuniq2</th>\n",
       "      <th>feature_254 - feature_638</th>\n",
       "      <th>feature_254 - feature_710</th>\n",
       "      <th>feature_322 - feature_329</th>\n",
       "      <th>feature_329 - feature_409</th>\n",
       "      <th>feature_4 - Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_4 - feature_638</th>\n",
       "      <th>feature_4 - feature_9</th>\n",
       "      <th>feature_407 - feature_409</th>\n",
       "      <th>feature_407 - feature_410</th>\n",
       "      <th>feature_407 - feature_638</th>\n",
       "      <th>feature_407 - feature_643</th>\n",
       "      <th>feature_407 - feature_700</th>\n",
       "      <th>feature_407 - feature_701</th>\n",
       "      <th>feature_407 - feature_702</th>\n",
       "      <th>feature_407 - feature_778</th>\n",
       "      <th>feature_407 - feature_779</th>\n",
       "      <th>feature_407 - feature_781</th>\n",
       "      <th>feature_409 - feature_410</th>\n",
       "      <th>feature_409 - feature_643</th>\n",
       "      <th>feature_409 - feature_701</th>\n",
       "      <th>feature_409 - feature_702</th>\n",
       "      <th>feature_409 - feature_778</th>\n",
       "      <th>feature_409 - feature_781</th>\n",
       "      <th>feature_410 - Payment_Rating34_mean_9999</th>\n",
       "      <th>feature_410 - feature_643</th>\n",
       "      <th>feature_410 - feature_701</th>\n",
       "      <th>feature_410 - feature_702</th>\n",
       "      <th>feature_410 - feature_778</th>\n",
       "      <th>feature_410 - feature_9</th>\n",
       "      <th>feature_638 - feature_9</th>\n",
       "      <th>feature_643 - feature_702</th>\n",
       "      <th>feature_643 - feature_778</th>\n",
       "      <th>feature_643 - feature_779</th>\n",
       "      <th>feature_643 - feature_781</th>\n",
       "      <th>feature_643 - feature_804</th>\n",
       "      <th>feature_669 - feature_762</th>\n",
       "      <th>feature_700 - feature_701</th>\n",
       "      <th>feature_700 - feature_702</th>\n",
       "      <th>feature_700 - feature_778</th>\n",
       "      <th>feature_700 - feature_781</th>\n",
       "      <th>feature_701 - feature_702</th>\n",
       "      <th>feature_701 - feature_778</th>\n",
       "      <th>feature_701 - feature_781</th>\n",
       "      <th>feature_702 - feature_762</th>\n",
       "      <th>feature_702 - feature_779</th>\n",
       "      <th>feature_702 - feature_781</th>\n",
       "      <th>feature_702 - feature_888</th>\n",
       "      <th>feature_710 - feature_9</th>\n",
       "      <th>feature_762 - Rate_of_Interest36_min_9999</th>\n",
       "      <th>feature_762 - feature_804</th>\n",
       "      <th>feature_762 - feature_846</th>\n",
       "      <th>feature_762 - feature_874</th>\n",
       "      <th>feature_762 - feature_888</th>\n",
       "      <th>feature_778 - feature_779</th>\n",
       "      <th>feature_778 - feature_781</th>\n",
       "      <th>feature_778 - feature_874</th>\n",
       "      <th>feature_779 - feature_781</th>\n",
       "      <th>feature_804 - feature_846</th>\n",
       "      <th>feature_804 - feature_888</th>\n",
       "      <th>feature_846 - feature_874</th>\n",
       "      <th>feature_846 - feature_888</th>\n",
       "      <th>feature_874 - Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>feature_874 - feature_888</th>\n",
       "      <th>feature_888 - feature_9</th>\n",
       "      <th>feature_9 - Payment_Rating34_mean_9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAHPO6801A</td>\n",
       "      <td>20220121153515</td>\n",
       "      <td>H</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>1.999889</td>\n",
       "      <td>2.999667</td>\n",
       "      <td>O</td>\n",
       "      <td>46</td>\n",
       "      <td>1.285673</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>9</td>\n",
       "      <td>0.749938</td>\n",
       "      <td>2.599680</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.166139</td>\n",
       "      <td>32.968032</td>\n",
       "      <td>2.999500</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>16.984016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5308000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>135.750000</td>\n",
       "      <td>65.086001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.149919</td>\n",
       "      <td>5146651.0</td>\n",
       "      <td>4371915.0</td>\n",
       "      <td>1.798590e+06</td>\n",
       "      <td>461866.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27173.666667</td>\n",
       "      <td>81521.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38429.367939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49982.0</td>\n",
       "      <td>16660.666667</td>\n",
       "      <td>49982.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>543.0</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.210427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4203.0</td>\n",
       "      <td>1028.750000</td>\n",
       "      <td>888.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>R</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.333333</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.416667</td>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>296.0</td>\n",
       "      <td>250.500000</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>752.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>267.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.132402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>22.166667</td>\n",
       "      <td>55.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.408554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>107.833333</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.475276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1177000.0</td>\n",
       "      <td>294250.000000</td>\n",
       "      <td>867000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1237000.0</td>\n",
       "      <td>867000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330259.049838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.146900</td>\n",
       "      <td>55.200000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.666529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4441000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8304111.0</td>\n",
       "      <td>234</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>45.00</td>\n",
       "      <td>86</td>\n",
       "      <td>0.045234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>423</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>2.018636e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.774596e+06</td>\n",
       "      <td>106.363636</td>\n",
       "      <td>153609.090909</td>\n",
       "      <td>0.165289</td>\n",
       "      <td>20.454545</td>\n",
       "      <td>39.090909</td>\n",
       "      <td>0.240642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268595</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.244755</td>\n",
       "      <td>192.272727</td>\n",
       "      <td>200885.298869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.584814</td>\n",
       "      <td>15286.462036</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>2.035541</td>\n",
       "      <td>3.890145</td>\n",
       "      <td>0.045234</td>\n",
       "      <td>19.134087</td>\n",
       "      <td>123.882353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.818182</td>\n",
       "      <td>0.026860</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.328283</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.038371</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>4441000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8304111.0</td>\n",
       "      <td>234</td>\n",
       "      <td>337940</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>45.00</td>\n",
       "      <td>86</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>423</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>201863.636364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>377459.590909</td>\n",
       "      <td>10.636364</td>\n",
       "      <td>15360.909091</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>2.045455</td>\n",
       "      <td>3.909091</td>\n",
       "      <td>19.227273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>57.333333</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>4613395.0</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>0.036075</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>24.230769</td>\n",
       "      <td>46.307692</td>\n",
       "      <td>1.878543e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.512639e+09</td>\n",
       "      <td>98982</td>\n",
       "      <td>142948620</td>\n",
       "      <td>153.818182</td>\n",
       "      <td>19035.0</td>\n",
       "      <td>36378</td>\n",
       "      <td>10.987013</td>\n",
       "      <td>10.987013</td>\n",
       "      <td>8.240260</td>\n",
       "      <td>27.467532</td>\n",
       "      <td>115350.649351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215691.194805</td>\n",
       "      <td>6.077922</td>\n",
       "      <td>8777.662338</td>\n",
       "      <td>1.168831</td>\n",
       "      <td>2.233766</td>\n",
       "      <td>115350.649351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215691.194805</td>\n",
       "      <td>6.077922</td>\n",
       "      <td>8777.662338</td>\n",
       "      <td>0.009445</td>\n",
       "      <td>1.168831</td>\n",
       "      <td>2.233766</td>\n",
       "      <td>86512.987013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161768.396104</td>\n",
       "      <td>4.558442</td>\n",
       "      <td>6583.246753</td>\n",
       "      <td>0.876623</td>\n",
       "      <td>1.675325</td>\n",
       "      <td>288376.623377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>539227.987013</td>\n",
       "      <td>15.194805</td>\n",
       "      <td>0.023613</td>\n",
       "      <td>2.922078</td>\n",
       "      <td>5.584416</td>\n",
       "      <td>-0.358404</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>-0.449314</td>\n",
       "      <td>-0.524180</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>-0.550324</td>\n",
       "      <td>-0.533230</td>\n",
       "      <td>-4441000.0</td>\n",
       "      <td>4623.916667</td>\n",
       "      <td>4644.890693</td>\n",
       "      <td>-65.500875</td>\n",
       "      <td>-5.497876</td>\n",
       "      <td>-66.500875</td>\n",
       "      <td>-40.500875</td>\n",
       "      <td>-81.500875</td>\n",
       "      <td>-0.500875</td>\n",
       "      <td>3.832459</td>\n",
       "      <td>297.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>329</td>\n",
       "      <td>-2937</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>1101401.0</td>\n",
       "      <td>-2761710.0</td>\n",
       "      <td>5.542401e+06</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-402.000000</td>\n",
       "      <td>60.002999</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-196.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-206.0</td>\n",
       "      <td>60.002999</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-3234.0</td>\n",
       "      <td>-276.0</td>\n",
       "      <td>-234.0</td>\n",
       "      <td>-3500.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-3224.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>-35.002999</td>\n",
       "      <td>-76.002999</td>\n",
       "      <td>-163</td>\n",
       "      <td>26.00</td>\n",
       "      <td>-15</td>\n",
       "      <td>-3429</td>\n",
       "      <td>4103060.0</td>\n",
       "      <td>-41.00</td>\n",
       "      <td>3266</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-14</td>\n",
       "      <td>46.00</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>3</td>\n",
       "      <td>-7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>-0.529412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.590909</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.538462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.590909</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.538462</td>\n",
       "      <td>-0.363636</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.590909</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>-10</td>\n",
       "      <td>-0.136364</td>\n",
       "      <td>-0.212121</td>\n",
       "      <td>-0.101010</td>\n",
       "      <td>-0.083916</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>-0.061497</td>\n",
       "      <td>-0.137255</td>\n",
       "      <td>-0.009050</td>\n",
       "      <td>-0.590909</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.538462</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.035354</td>\n",
       "      <td>0.052448</td>\n",
       "      <td>0.525974</td>\n",
       "      <td>-10</td>\n",
       "      <td>-44.954545</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>-0.019481</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.647186</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.038961</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>-0.038961</td>\n",
       "      <td>-8.304111e+06</td>\n",
       "      <td>-0.045455</td>\n",
       "      <td>-10.935065</td>\n",
       "      <td>10.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAIPI5141G</td>\n",
       "      <td>20211116185506</td>\n",
       "      <td>H</td>\n",
       "      <td>0.420485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>14</td>\n",
       "      <td>1.499917</td>\n",
       "      <td>3.498751</td>\n",
       "      <td>I</td>\n",
       "      <td>46</td>\n",
       "      <td>1.333278</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333222</td>\n",
       "      <td>2.999334</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.332556</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>1.499750</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>8.992008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>298700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120251.0</td>\n",
       "      <td>120251.0</td>\n",
       "      <td>6.012550e+04</td>\n",
       "      <td>40083.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15944.000000</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>15944.000000</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>238.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>231.500000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.132034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.887841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450.0</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.132034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10530.379333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>10666.666667</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>233000.0</td>\n",
       "      <td>201000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77739.565216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.076580</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.816846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>308700.0</td>\n",
       "      <td>181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>0.019763</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>2033</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>3.011667e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.145000e+04</td>\n",
       "      <td>30.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.120370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>338.833333</td>\n",
       "      <td>3571.146245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.577075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592885</td>\n",
       "      <td>0.118577</td>\n",
       "      <td>40.177866</td>\n",
       "      <td>116.357143</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.035000e+04</td>\n",
       "      <td>1.543500e+05</td>\n",
       "      <td>90.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.561728</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1084200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1852200.0</td>\n",
       "      <td>1086</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>12198</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>240100.0</td>\n",
       "      <td>140.777778</td>\n",
       "      <td>0.079772</td>\n",
       "      <td>111.384615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.461538</td>\n",
       "      <td>3.673631e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.275871e+08</td>\n",
       "      <td>367973</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60990</td>\n",
       "      <td>52.128205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>208.512821</td>\n",
       "      <td>4633.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7915.384615</td>\n",
       "      <td>4.641026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18533.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31661.538462</td>\n",
       "      <td>18.564103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>0.060880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.105787</td>\n",
       "      <td>-0.581977</td>\n",
       "      <td>-0.439120</td>\n",
       "      <td>-0.716898</td>\n",
       "      <td>-0.554505</td>\n",
       "      <td>-180700.0</td>\n",
       "      <td>-153.000000</td>\n",
       "      <td>-0.025641</td>\n",
       "      <td>-9.501749</td>\n",
       "      <td>1.999000</td>\n",
       "      <td>-40.501749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-25.501749</td>\n",
       "      <td>4.498251</td>\n",
       "      <td>3.623251</td>\n",
       "      <td>748.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>591</td>\n",
       "      <td>-2728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-60449.0</td>\n",
       "      <td>-188449.0</td>\n",
       "      <td>1.202510e+05</td>\n",
       "      <td>139.0</td>\n",
       "      <td>-1880.000000</td>\n",
       "      <td>11.500750</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>11.500750</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-157.0</td>\n",
       "      <td>-3476.0</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-3500.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>-114.0</td>\n",
       "      <td>-3433.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-27.500750</td>\n",
       "      <td>-136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>-3455</td>\n",
       "      <td>180700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3319</td>\n",
       "      <td>-1</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.708333</td>\n",
       "      <td>-0.611111</td>\n",
       "      <td>-0.448718</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.019763</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.079365</td>\n",
       "      <td>-0.232143</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>-0.222222</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.115385</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>0.106838</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.102564</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.259615</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.162393</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.102564</td>\n",
       "      <td>-3.087000e+05</td>\n",
       "      <td>-0.102564</td>\n",
       "      <td>-8.897436</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAIPZ7980L</td>\n",
       "      <td>20211017185940</td>\n",
       "      <td>H</td>\n",
       "      <td>0.409987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>28</td>\n",
       "      <td>4.454441</td>\n",
       "      <td>8.070924</td>\n",
       "      <td>Z</td>\n",
       "      <td>46</td>\n",
       "      <td>3.999842</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>45</td>\n",
       "      <td>0.542162</td>\n",
       "      <td>26.162473</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>14.544223</td>\n",
       "      <td>112.444278</td>\n",
       "      <td>20.745064</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>145.855145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1446850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.959592</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.258065</td>\n",
       "      <td>13.276143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124020</td>\n",
       "      <td>1006101.0</td>\n",
       "      <td>230787.0</td>\n",
       "      <td>4.062192e+04</td>\n",
       "      <td>56694.951220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.8</td>\n",
       "      <td>33.56</td>\n",
       "      <td>94.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.622449</td>\n",
       "      <td>710.292</td>\n",
       "      <td>827.172</td>\n",
       "      <td>30.636</td>\n",
       "      <td>94.8</td>\n",
       "      <td>19.035488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.641304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.966940</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.084337</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.043676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46200.0</td>\n",
       "      <td>155465.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5048.0</td>\n",
       "      <td>461.120482</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>61.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>269.052632</td>\n",
       "      <td>106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>176.122807</td>\n",
       "      <td>73.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>100.131148</td>\n",
       "      <td>78.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>57.214286</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>129.524590</td>\n",
       "      <td>78.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2543.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>7.785714</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.557875</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.879518</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.730451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2.619048</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.493171</td>\n",
       "      <td>110.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.393263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.257539</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1.950820</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.562115</td>\n",
       "      <td>7.819277</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.668312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.803279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.613549</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.325301</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.279905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34692.298217</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1156010.0</td>\n",
       "      <td>26883.953488</td>\n",
       "      <td>310000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3019520.0</td>\n",
       "      <td>593511.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101655.448885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.191489</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.883857</td>\n",
       "      <td>24.120690</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.028395</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>597688.8</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>1.35</td>\n",
       "      <td>39.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>107.6</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>1.211429e+06</td>\n",
       "      <td>35442.171865</td>\n",
       "      <td>5.062902e+06</td>\n",
       "      <td>634.285714</td>\n",
       "      <td>2.134603e+06</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>4.821429</td>\n",
       "      <td>140.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.47619</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>384.285714</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>7.857143</td>\n",
       "      <td>1696000.0</td>\n",
       "      <td>49619.040611</td>\n",
       "      <td>7088063.0</td>\n",
       "      <td>888</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>6.75</td>\n",
       "      <td>197</td>\n",
       "      <td>0.022333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>5.653333e+05</td>\n",
       "      <td>16539.680204</td>\n",
       "      <td>2.362688e+06</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>996148.000000</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>65.666667</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>179.333333</td>\n",
       "      <td>37875.930521</td>\n",
       "      <td>1108.117532</td>\n",
       "      <td>19.831266</td>\n",
       "      <td>66739.444169</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.150744</td>\n",
       "      <td>4.399504</td>\n",
       "      <td>0.066998</td>\n",
       "      <td>12.014888</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.130667e+06</td>\n",
       "      <td>4.725375e+06</td>\n",
       "      <td>592.00</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>4.5</td>\n",
       "      <td>131.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>45802.191333</td>\n",
       "      <td>181.846154</td>\n",
       "      <td>0.014652</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.043956</td>\n",
       "      <td>10.153846</td>\n",
       "      <td>5088000.0</td>\n",
       "      <td>148857.121833</td>\n",
       "      <td>21264189.0</td>\n",
       "      <td>2664</td>\n",
       "      <td>8965332</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>20.25</td>\n",
       "      <td>591</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>26920.634921</td>\n",
       "      <td>787.603819</td>\n",
       "      <td>112508.936508</td>\n",
       "      <td>14.095238</td>\n",
       "      <td>47435.619048</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>3.126984</td>\n",
       "      <td>8.539683</td>\n",
       "      <td>49619.040611</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>4252837.8</td>\n",
       "      <td>532.800000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>5.062500</td>\n",
       "      <td>147.750000</td>\n",
       "      <td>9.124480e+08</td>\n",
       "      <td>2.669504e+07</td>\n",
       "      <td>3.813378e+09</td>\n",
       "      <td>477744</td>\n",
       "      <td>1607782872</td>\n",
       "      <td>8.406250</td>\n",
       "      <td>3631.5</td>\n",
       "      <td>105986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.079365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.619048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53841.269841</td>\n",
       "      <td>1575.207638</td>\n",
       "      <td>225017.873016</td>\n",
       "      <td>28.190476</td>\n",
       "      <td>94871.238095</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>6.253968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80761.904762</td>\n",
       "      <td>2362.811458</td>\n",
       "      <td>337526.809524</td>\n",
       "      <td>42.285714</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>9.380952</td>\n",
       "      <td>0.704232</td>\n",
       "      <td>0.719857</td>\n",
       "      <td>0.519857</td>\n",
       "      <td>0.005572</td>\n",
       "      <td>0.386524</td>\n",
       "      <td>-0.113476</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.119857</td>\n",
       "      <td>-0.030143</td>\n",
       "      <td>-1694955.0</td>\n",
       "      <td>-264.278689</td>\n",
       "      <td>31.721311</td>\n",
       "      <td>22.491127</td>\n",
       "      <td>5.097206</td>\n",
       "      <td>-88.508873</td>\n",
       "      <td>29.741127</td>\n",
       "      <td>-160.508873</td>\n",
       "      <td>35.491127</td>\n",
       "      <td>35.491127</td>\n",
       "      <td>61.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>-689.0</td>\n",
       "      <td>-178</td>\n",
       "      <td>-2790</td>\n",
       "      <td>0.620739</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-0.363636</td>\n",
       "      <td>-10.363636</td>\n",
       "      <td>2952986.0</td>\n",
       "      <td>-2439077.0</td>\n",
       "      <td>4.648986e+06</td>\n",
       "      <td>-641.0</td>\n",
       "      <td>-418.473684</td>\n",
       "      <td>-17.393921</td>\n",
       "      <td>-111.0</td>\n",
       "      <td>-874.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>-183.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>883.0</td>\n",
       "      <td>-462.0</td>\n",
       "      <td>905.606079</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>-750.0</td>\n",
       "      <td>-239.0</td>\n",
       "      <td>-2851.0</td>\n",
       "      <td>-1345.0</td>\n",
       "      <td>-834.0</td>\n",
       "      <td>-3446.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>-2101.0</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>24.643921</td>\n",
       "      <td>-165.606079</td>\n",
       "      <td>-763</td>\n",
       "      <td>118.25</td>\n",
       "      <td>-72</td>\n",
       "      <td>-3375</td>\n",
       "      <td>-1292444.0</td>\n",
       "      <td>-190.25</td>\n",
       "      <td>2612</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-999</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>4.984375</td>\n",
       "      <td>4</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.923077</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.514286</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.723077</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>0.698661</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-0.208791</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-10.285714</td>\n",
       "      <td>-10</td>\n",
       "      <td>-0.589744</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.089744</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.256410</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.907204</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.875458</td>\n",
       "      <td>-8</td>\n",
       "      <td>-6.734127</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>-0.015873</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>-0.031746</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.031746</td>\n",
       "      <td>-0.047619</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>-0.015873</td>\n",
       "      <td>-7.088063e+06</td>\n",
       "      <td>-0.047619</td>\n",
       "      <td>-10.952381</td>\n",
       "      <td>10.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AALPF3903A</td>\n",
       "      <td>20220201134326</td>\n",
       "      <td>H</td>\n",
       "      <td>0.341053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>33</td>\n",
       "      <td>12.597680</td>\n",
       "      <td>5.999500</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>3.499583</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>6</td>\n",
       "      <td>0.113205</td>\n",
       "      <td>22.659447</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18.745564</td>\n",
       "      <td>29.971029</td>\n",
       "      <td>13.246938</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>31.484758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77711.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85509.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.545455</td>\n",
       "      <td>31.230415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.486069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8909.075472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3360.363636</td>\n",
       "      <td>36964.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10626.402857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15280.0</td>\n",
       "      <td>2182.857143</td>\n",
       "      <td>15280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.800</td>\n",
       "      <td>10.900</td>\n",
       "      <td>13.8</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>303.0</td>\n",
       "      <td>5.716981</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.089273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>305.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5685.0</td>\n",
       "      <td>1510.981132</td>\n",
       "      <td>696.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1145.893617</td>\n",
       "      <td>630.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1139.510638</td>\n",
       "      <td>630.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2438.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277.0</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2536.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.566038</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.339356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>329.0</td>\n",
       "      <td>109.666667</td>\n",
       "      <td>150.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>57.039947</td>\n",
       "      <td>2918.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.385284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.357023</td>\n",
       "      <td>11.075472</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.513601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>747.0</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>155.563492</td>\n",
       "      <td>81524.0</td>\n",
       "      <td>1538.188679</td>\n",
       "      <td>59071.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8193.472586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>23333.333333</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>184270.332814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.456031</td>\n",
       "      <td>28.777778</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.562840</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97501.5</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>36.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>460.0</td>\n",
       "      <td>0.026923</td>\n",
       "      <td>1.374000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999528e+05</td>\n",
       "      <td>41.100000</td>\n",
       "      <td>1.170018e+05</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.07500</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.207692</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>0.032308</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>1374000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999528.0</td>\n",
       "      <td>411</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>24.00</td>\n",
       "      <td>435</td>\n",
       "      <td>0.086093</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>1.043478</td>\n",
       "      <td>5520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>1.357037e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.876077e+05</td>\n",
       "      <td>40.592593</td>\n",
       "      <td>115557.333333</td>\n",
       "      <td>0.136296</td>\n",
       "      <td>2.370370</td>\n",
       "      <td>42.962963</td>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.200436</td>\n",
       "      <td>1.185185</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.103060</td>\n",
       "      <td>545.185185</td>\n",
       "      <td>13143.487859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.931567</td>\n",
       "      <td>11192.225166</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.229581</td>\n",
       "      <td>4.161148</td>\n",
       "      <td>0.114790</td>\n",
       "      <td>52.803532</td>\n",
       "      <td>66.424242</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.145000e+05</td>\n",
       "      <td>8.332940e+05</td>\n",
       "      <td>34.25</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011538</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.026923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.088235</td>\n",
       "      <td>0.031222</td>\n",
       "      <td>0.468326</td>\n",
       "      <td>0.380515</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.072851</td>\n",
       "      <td>7.441176</td>\n",
       "      <td>1832000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13332704.0</td>\n",
       "      <td>548</td>\n",
       "      <td>1560024</td>\n",
       "      <td>1.840000</td>\n",
       "      <td>32.00</td>\n",
       "      <td>580</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>7360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>21138.461538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153838.892308</td>\n",
       "      <td>6.323077</td>\n",
       "      <td>18000.276923</td>\n",
       "      <td>0.021231</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>6.692308</td>\n",
       "      <td>84.923077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.318462</td>\n",
       "      <td>100.384615</td>\n",
       "      <td>0.240803</td>\n",
       "      <td>0.074556</td>\n",
       "      <td>1874911.5</td>\n",
       "      <td>77.062500</td>\n",
       "      <td>0.060577</td>\n",
       "      <td>47.652174</td>\n",
       "      <td>2.782609</td>\n",
       "      <td>50.434783</td>\n",
       "      <td>8.427200e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.133044e+09</td>\n",
       "      <td>252080</td>\n",
       "      <td>717611040</td>\n",
       "      <td>846.400000</td>\n",
       "      <td>14720.0</td>\n",
       "      <td>266800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.923077</td>\n",
       "      <td>28.307692</td>\n",
       "      <td>198.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21138.461538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153838.892308</td>\n",
       "      <td>6.323077</td>\n",
       "      <td>18000.276923</td>\n",
       "      <td>0.021231</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>6.692308</td>\n",
       "      <td>7046.153846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51279.630769</td>\n",
       "      <td>2.107692</td>\n",
       "      <td>6000.092308</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>2.230769</td>\n",
       "      <td>49323.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>358957.415385</td>\n",
       "      <td>14.753846</td>\n",
       "      <td>0.049538</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>15.615385</td>\n",
       "      <td>-0.399120</td>\n",
       "      <td>-0.081977</td>\n",
       "      <td>-0.189120</td>\n",
       "      <td>-0.239120</td>\n",
       "      <td>-0.235416</td>\n",
       "      <td>-0.423969</td>\n",
       "      <td>-0.189120</td>\n",
       "      <td>-0.501620</td>\n",
       "      <td>-0.286946</td>\n",
       "      <td>-458000.0</td>\n",
       "      <td>2810.679245</td>\n",
       "      <td>2886.679245</td>\n",
       "      <td>14.993336</td>\n",
       "      <td>19.326891</td>\n",
       "      <td>-44.006664</td>\n",
       "      <td>12.993336</td>\n",
       "      <td>-124.006664</td>\n",
       "      <td>17.993336</td>\n",
       "      <td>20.301028</td>\n",
       "      <td>-109.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>341</td>\n",
       "      <td>-3022</td>\n",
       "      <td>-0.460000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>14181.0</td>\n",
       "      <td>-2860995.0</td>\n",
       "      <td>4.721810e+05</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-1779.333333</td>\n",
       "      <td>4.333555</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-131.0</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>-581.0</td>\n",
       "      <td>-353.0</td>\n",
       "      <td>-253.0</td>\n",
       "      <td>4.333555</td>\n",
       "      <td>-131.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>-2913.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>-3141.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>-3241.0</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>-6.333555</td>\n",
       "      <td>-143.333555</td>\n",
       "      <td>-72</td>\n",
       "      <td>57.00</td>\n",
       "      <td>-80</td>\n",
       "      <td>-3435</td>\n",
       "      <td>67994.0</td>\n",
       "      <td>-137.00</td>\n",
       "      <td>3363</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1003</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.540000</td>\n",
       "      <td>2</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.107143</td>\n",
       "      <td>-0.157143</td>\n",
       "      <td>-2.857143</td>\n",
       "      <td>-0.153439</td>\n",
       "      <td>-0.341991</td>\n",
       "      <td>-0.107143</td>\n",
       "      <td>-0.533613</td>\n",
       "      <td>-0.549451</td>\n",
       "      <td>-0.419643</td>\n",
       "      <td>-0.204969</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>-0.046296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.426471</td>\n",
       "      <td>-0.442308</td>\n",
       "      <td>-0.097826</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.376471</td>\n",
       "      <td>-0.392308</td>\n",
       "      <td>-10.700000</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.380174</td>\n",
       "      <td>-0.396011</td>\n",
       "      <td>-0.266204</td>\n",
       "      <td>-0.051530</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>-0.017456</td>\n",
       "      <td>0.234848</td>\n",
       "      <td>-0.191622</td>\n",
       "      <td>-0.207459</td>\n",
       "      <td>0.137022</td>\n",
       "      <td>-0.426471</td>\n",
       "      <td>-0.442308</td>\n",
       "      <td>-0.097826</td>\n",
       "      <td>0.630317</td>\n",
       "      <td>0.113971</td>\n",
       "      <td>0.328645</td>\n",
       "      <td>0.568778</td>\n",
       "      <td>-7</td>\n",
       "      <td>-7.953846</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>-0.061538</td>\n",
       "      <td>0.129808</td>\n",
       "      <td>0.344482</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>0.214674</td>\n",
       "      <td>-0.046154</td>\n",
       "      <td>-0.107692</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>-0.061538</td>\n",
       "      <td>-3.333176e+06</td>\n",
       "      <td>-0.092308</td>\n",
       "      <td>-10.892308</td>\n",
       "      <td>10.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AALPF4279M</td>\n",
       "      <td>20211105155431</td>\n",
       "      <td>H</td>\n",
       "      <td>0.442491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>3.076763</td>\n",
       "      <td>11.994503</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>1.999889</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>12</td>\n",
       "      <td>0.499979</td>\n",
       "      <td>13.995668</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.999000</td>\n",
       "      <td>59.941059</td>\n",
       "      <td>11.994503</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>18.491254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6907.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>586317.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.238430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399653</td>\n",
       "      <td>414804.0</td>\n",
       "      <td>255341.0</td>\n",
       "      <td>5.516924e+04</td>\n",
       "      <td>17571.291667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000</td>\n",
       "      <td>180.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.550095</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.041667</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.668323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>266.541667</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>182.250000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>163.250000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>78.523810</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>144.761905</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.625000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.269591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.977416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.095238</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.974571</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.639005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.959682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>387000.0</td>\n",
       "      <td>48375.000000</td>\n",
       "      <td>310000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>597188.0</td>\n",
       "      <td>310000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83891.500247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.444444</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.596548</td>\n",
       "      <td>16.866667</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.161999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7444.344023</td>\n",
       "      <td>110.215304</td>\n",
       "      <td>6.151603</td>\n",
       "      <td>2150.845481</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.524781</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.239067</td>\n",
       "      <td>150.714286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2749.370853</td>\n",
       "      <td>20.363636</td>\n",
       "      <td>0.039669</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.079339</td>\n",
       "      <td>7.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13927.690909</td>\n",
       "      <td>206.202814</td>\n",
       "      <td>33149.618182</td>\n",
       "      <td>11.509091</td>\n",
       "      <td>4024.036364</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>1.527273</td>\n",
       "      <td>49.090909</td>\n",
       "      <td>945.096231</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>121548.6</td>\n",
       "      <td>42.200000</td>\n",
       "      <td>0.021818</td>\n",
       "      <td>105.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.298069e+08</td>\n",
       "      <td>3.402346e+06</td>\n",
       "      <td>5.469687e+08</td>\n",
       "      <td>189900</td>\n",
       "      <td>66396600</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>25200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.454545</td>\n",
       "      <td>16.363636</td>\n",
       "      <td>98.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18570.254545</td>\n",
       "      <td>274.937085</td>\n",
       "      <td>44199.490909</td>\n",
       "      <td>15.345455</td>\n",
       "      <td>5365.381818</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>1.309091</td>\n",
       "      <td>2.036364</td>\n",
       "      <td>4642.563636</td>\n",
       "      <td>68.734271</td>\n",
       "      <td>11049.872727</td>\n",
       "      <td>3.836364</td>\n",
       "      <td>1341.345455</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>27855.381818</td>\n",
       "      <td>412.405628</td>\n",
       "      <td>66299.236364</td>\n",
       "      <td>23.018182</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>1.963636</td>\n",
       "      <td>3.054545</td>\n",
       "      <td>0.636524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.719857</td>\n",
       "      <td>0.719857</td>\n",
       "      <td>0.719857</td>\n",
       "      <td>0.005572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519857</td>\n",
       "      <td>0.219857</td>\n",
       "      <td>-255341.0</td>\n",
       "      <td>103.791667</td>\n",
       "      <td>287.791667</td>\n",
       "      <td>8.329224</td>\n",
       "      <td>3.331023</td>\n",
       "      <td>-98.670776</td>\n",
       "      <td>-4.670776</td>\n",
       "      <td>-14.670776</td>\n",
       "      <td>11.329224</td>\n",
       "      <td>13.079224</td>\n",
       "      <td>632.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>527</td>\n",
       "      <td>-2762</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>166370.0</td>\n",
       "      <td>-186032.0</td>\n",
       "      <td>4.217109e+05</td>\n",
       "      <td>179.0</td>\n",
       "      <td>-802.222222</td>\n",
       "      <td>-4.998200</td>\n",
       "      <td>-107.0</td>\n",
       "      <td>-206.0</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-248.0</td>\n",
       "      <td>-4.998200</td>\n",
       "      <td>-206.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-147.0</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>-3394.0</td>\n",
       "      <td>-253.0</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>-3500.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-3247.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>-8.001800</td>\n",
       "      <td>-18.001800</td>\n",
       "      <td>-99</td>\n",
       "      <td>94.00</td>\n",
       "      <td>84</td>\n",
       "      <td>-3388</td>\n",
       "      <td>181567.0</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>3289</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1006</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.727273</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.727273</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10</td>\n",
       "      <td>-0.727273</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.012987</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>-10</td>\n",
       "      <td>-17.945455</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>-0.018182</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>-0.054545</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.231818</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.072727</td>\n",
       "      <td>-0.109091</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>-0.036364</td>\n",
       "      <td>-6.077430e+05</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-9.890909</td>\n",
       "      <td>9.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3631 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID report_timestamp BureauScoreConfidLevel  MissingRate  \\\n",
       "0  AAHPO6801A   20220121153515                      H     0.297000   \n",
       "1  AAIPI5141G   20211116185506                      H     0.420485   \n",
       "2  AAIPZ7980L   20211017185940                      H     0.409987   \n",
       "3  AALPF3903A   20220201134326                      H     0.341053   \n",
       "4  AALPF4279M   20211105155431                      H     0.442491   \n",
       "\n",
       "  Current_Finance_Purpose  Current_Amount_Financed Current_Gender_Code  \\\n",
       "0                     NaN                   310000                   1   \n",
       "1                     NaN                   310000                   1   \n",
       "2                     NaN                   310000                   1   \n",
       "3                     NaN                   310000                   1   \n",
       "4                     NaN                   310000                   1   \n",
       "\n",
       "  First_Name1  Len_Name  Name_nuniq  Tel_nuniq IncomeTaxPAN_5  Len_of_addrs  \\\n",
       "0           O        32    1.999889   2.999667              O            46   \n",
       "1           P        14    1.499917   3.498751              I            46   \n",
       "2           C        28    4.454441   8.070924              Z            46   \n",
       "3           P        33   12.597680   5.999500              F            46   \n",
       "4           F        15    3.076763  11.994503              F            46   \n",
       "\n",
       "   City_nuniq PinCode3  Current_State Current_City  CreditAccountActive  \\\n",
       "0    1.285673      422             27       MUMBAI                    9   \n",
       "1    1.333278      422             27       MUMBAI                    1   \n",
       "2    3.999842      422             27       MUMBAI                   45   \n",
       "3    3.499583      422             27       MUMBAI                    6   \n",
       "4    1.999889      422             27       MUMBAI                   12   \n",
       "\n",
       "   CreditAccountActivePor  State_nuniq  TotalCAPSLast90Days  \\\n",
       "0                0.749938     2.599680                   12   \n",
       "1                0.333222     2.999334                    3   \n",
       "2                0.542162    26.162473                   37   \n",
       "3                0.113205    22.659447                    2   \n",
       "4                0.499979    13.995668                    4   \n",
       "\n",
       "   TotalCAPSLast7Days  TotalCAPSLast30Days  TotalCAPSLast180Days  \\\n",
       "0                   9                    9                    12   \n",
       "1                   0                    3                     3   \n",
       "2                  22                   28                    54   \n",
       "3                   1                    1                     2   \n",
       "4                   1                    2                     5   \n",
       "\n",
       "   CAPSLast7Days  CAPSLast180Days  Pin_nuniq   Pan_nuniq  Ident_nuniq  \\\n",
       "0              0                3   4.166139   32.968032     2.999500   \n",
       "1              0                3   3.332556   10.990010     1.499750   \n",
       "2              1               33  14.544223  112.444278    20.745064   \n",
       "3              1                2  18.745564   29.971029    13.246938   \n",
       "4              1                5   6.999000   59.941059    11.994503   \n",
       "\n",
       "   Pan_nuniq2  Account_nuniq2  Ident_nuniq2  Gender_nuniq  \\\n",
       "0          14              14            60     16.984016   \n",
       "1          14              14            30      8.992008   \n",
       "2          28              14            60    145.855145   \n",
       "3          14              14            60     31.484758   \n",
       "4          14              14            30     18.491254   \n",
       "\n",
       "   Amount_Past_Due35_max_30  Amount_Past_Due35_mean_90  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        0.0   \n",
       "3                       NaN                        NaN   \n",
       "4                       NaN                        0.0   \n",
       "\n",
       "   Amount_Past_Due35_max_90  Amount_Past_Due35_min_90  \\\n",
       "0                       NaN                       NaN   \n",
       "1                       NaN                       NaN   \n",
       "2                       0.0                       0.0   \n",
       "3                       NaN                       NaN   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Amount_Past_Due35_std_90  Amount_Past_Due35_max_9999  \\\n",
       "0                       NaN                     44737.0   \n",
       "1                       NaN                         0.0   \n",
       "2                       0.0                      1045.0   \n",
       "3                       NaN                     77711.0   \n",
       "4                       0.0                      6907.0   \n",
       "\n",
       "   Amount_Past_Due35_min_9999  \\\n",
       "0                         0.0   \n",
       "1                         0.0   \n",
       "2                         0.0   \n",
       "3                         0.0   \n",
       "4                         0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_sum_360  Terms_Duration34_std_30  \\\n",
       "0                                         5308000.0                      NaN   \n",
       "1                                          298700.0                      NaN   \n",
       "2                                         1446850.0                      NaN   \n",
       "3                                           85509.0                      NaN   \n",
       "4                                          586317.0                      NaN   \n",
       "\n",
       "   Terms_Duration34_std_90  Terms_Duration34_sum_360  \\\n",
       "0                      NaN                     360.0   \n",
       "1                      NaN                       0.0   \n",
       "2                 1.959592                      61.0   \n",
       "3                      NaN                       6.0   \n",
       "4                 0.000000                      35.0   \n",
       "\n",
       "   Terms_Duration34_max_360  Terms_Duration34_mean_9999  \\\n",
       "0                     180.0                  135.750000   \n",
       "1                       NaN                         NaN   \n",
       "2                      12.0                    8.258065   \n",
       "3                       6.0                   27.545455   \n",
       "4                      13.0                    3.500000   \n",
       "\n",
       "   Terms_Duration34_std_9999  Payment_Rating34_sum_90  \\\n",
       "0                  65.086001                      NaN   \n",
       "1                        NaN                      NaN   \n",
       "2                  13.276143                      0.0   \n",
       "3                  31.230415                      NaN   \n",
       "4                   4.238430                      0.0   \n",
       "\n",
       "   Payment_Rating34_mean_90  Payment_Rating34_min_90  Payment_Rating34_std_90  \\\n",
       "0                       NaN                      NaN                      NaN   \n",
       "1                       NaN                      NaN                      NaN   \n",
       "2                       0.0                      0.0                      0.0   \n",
       "3                       NaN                      NaN                      NaN   \n",
       "4                       0.0                      0.0                      0.0   \n",
       "\n",
       "   Payment_Rating34_sum_360  Payment_Rating34_mean_360  \\\n",
       "0                       0.0                    0.00000   \n",
       "1                       0.0                    0.00000   \n",
       "2                       1.0                    0.02381   \n",
       "3                       0.0                    0.00000   \n",
       "4                       0.0                    0.00000   \n",
       "\n",
       "   Payment_Rating34_max_360  Payment_Rating34_min_360  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       1.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Payment_Rating34_std_360  Payment_Rating34_sum_9999  \\\n",
       "0                  0.000000                        4.0   \n",
       "1                  0.000000                        0.0   \n",
       "2                  0.152455                        1.0   \n",
       "3                  0.000000                       23.0   \n",
       "4                  0.000000                        2.0   \n",
       "\n",
       "   Payment_Rating34_max_9999  Payment_Rating34_min_9999  \\\n",
       "0                        4.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        1.0                        0.0   \n",
       "3                        6.0                        0.0   \n",
       "4                        2.0                        0.0   \n",
       "\n",
       "   Payment_Rating34_std_9999  Current_Balance35_sum_360  \\\n",
       "0                   1.149919                  5146651.0   \n",
       "1                   0.000000                   120251.0   \n",
       "2                   0.124020                  1006101.0   \n",
       "3                   1.486069                        0.0   \n",
       "4                   0.399653                   414804.0   \n",
       "\n",
       "   Current_Balance35_max_360  Current_Balance35_std_360  \\\n",
       "0                  4371915.0               1.798590e+06   \n",
       "1                   120251.0               6.012550e+04   \n",
       "2                   230787.0               4.062192e+04   \n",
       "3                        0.0               0.000000e+00   \n",
       "4                   255341.0               5.516924e+04   \n",
       "\n",
       "   Current_Balance35_mean_9999  Settlement_Amount37_mean_360  \\\n",
       "0                461866.750000                           NaN   \n",
       "1                 40083.666667                           NaN   \n",
       "2                 56694.951220                           0.0   \n",
       "3                  8909.075472                           NaN   \n",
       "4                 17571.291667                           NaN   \n",
       "\n",
       "   Settlement_Amount37_std_360  Settlement_Amount37_mean_9999  \\\n",
       "0                          NaN                        67000.0   \n",
       "1                          NaN                            NaN   \n",
       "2                          0.0                            0.0   \n",
       "3                          NaN                            0.0   \n",
       "4                          NaN                            NaN   \n",
       "\n",
       "   Settlement_Amount37_max_9999  Settlement_Amount37_min_9999  \\\n",
       "0                       67000.0                       67000.0   \n",
       "1                           NaN                           NaN   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           NaN                           NaN   \n",
       "\n",
       "   Value_of_Collateral39_std_90  Value_of_Collateral39_std_360  \\\n",
       "0                           NaN                            NaN   \n",
       "1                           NaN                            NaN   \n",
       "2                           0.0                            0.0   \n",
       "3                           NaN                            NaN   \n",
       "4                           NaN                            NaN   \n",
       "\n",
       "   Written_Off_Amt_Total41_sum_360  Written_Off_Amt_Total41_std_360  \\\n",
       "0                              0.0                              0.0   \n",
       "1                              0.0                              NaN   \n",
       "2                              0.0                              0.0   \n",
       "3                              0.0                              NaN   \n",
       "4                              0.0                              NaN   \n",
       "\n",
       "   Written_Off_Amt_Total41_mean_9999  Written_Off_Amt_Total41_max_9999  \\\n",
       "0                       27173.666667                           81521.0   \n",
       "1                       15944.000000                           15944.0   \n",
       "2                           0.000000                               0.0   \n",
       "3                        3360.363636                           36964.0   \n",
       "4                                NaN                               NaN   \n",
       "\n",
       "   Written_Off_Amt_Total41_min_9999  Written_Off_Amt_Total41_std_9999  \\\n",
       "0                               0.0                      38429.367939   \n",
       "1                           15944.0                          0.000000   \n",
       "2                               0.0                          0.000000   \n",
       "3                               0.0                      10626.402857   \n",
       "4                               NaN                               NaN   \n",
       "\n",
       "   Written_Off_Amt_Principal45_sum_360  Written_Off_Amt_Principal45_min_360  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  NaN   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  NaN   \n",
       "4                                  0.0                                  NaN   \n",
       "\n",
       "   Written_Off_Amt_Principal45_std_360  Written_Off_Amt_Principal45_sum_9999  \\\n",
       "0                                  0.0                               49982.0   \n",
       "1                                  NaN                               15944.0   \n",
       "2                                  0.0                                   0.0   \n",
       "3                                  NaN                               15280.0   \n",
       "4                                  NaN                                   0.0   \n",
       "\n",
       "   Written_Off_Amt_Principal45_mean_9999  \\\n",
       "0                           16660.666667   \n",
       "1                           15944.000000   \n",
       "2                               0.000000   \n",
       "3                            2182.857143   \n",
       "4                                    NaN   \n",
       "\n",
       "   Written_Off_Amt_Principal45_max_9999  Written_Off_Amt_Principal45_min_9999  \\\n",
       "0                               49982.0                                   0.0   \n",
       "1                               15944.0                               15944.0   \n",
       "2                                   0.0                                   0.0   \n",
       "3                               15280.0                                   0.0   \n",
       "4                                   NaN                                   NaN   \n",
       "\n",
       "   Rate_of_Interest36_sum_30  Rate_of_Interest36_max_30  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                        NaN   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   Rate_of_Interest36_min_30  Rate_of_Interest36_std_30  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                        NaN   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   Rate_of_Interest36_sum_90  Rate_of_Interest36_mean_90  \\\n",
       "0                        NaN                         NaN   \n",
       "1                        NaN                         NaN   \n",
       "2                      167.8                       33.56   \n",
       "3                        NaN                         NaN   \n",
       "4                       54.0                       18.00   \n",
       "\n",
       "   Rate_of_Interest36_max_90  Rate_of_Interest36_min_90  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                       94.8                       18.0   \n",
       "3                        NaN                        NaN   \n",
       "4                       18.0                       18.0   \n",
       "\n",
       "   Rate_of_Interest36_std_90  Rate_of_Interest36_sum_360  \\\n",
       "0                        NaN                       0.000   \n",
       "1                        NaN                       0.000   \n",
       "2                  30.622449                     710.292   \n",
       "3                        NaN                       0.000   \n",
       "4                   0.000000                     180.000   \n",
       "\n",
       "   Rate_of_Interest36_sum_9999  Rate_of_Interest36_mean_9999  \\\n",
       "0                       45.000                        45.000   \n",
       "1                        0.000                           NaN   \n",
       "2                      827.172                        30.636   \n",
       "3                       21.800                        10.900   \n",
       "4                      180.000                        18.000   \n",
       "\n",
       "   Rate_of_Interest36_max_9999  Rate_of_Interest36_std_9999  \\\n",
       "0                         45.0                     0.000000   \n",
       "1                          NaN                          NaN   \n",
       "2                         94.8                    19.035488   \n",
       "3                         13.8                     2.900000   \n",
       "4                         18.0                     0.000000   \n",
       "\n",
       "   Repayment_Tenure36_std_30  Repayment_Tenure36_std_90  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                   1.641304   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                   0.489898   \n",
       "\n",
       "   Repayment_Tenure36_mean_360  Repayment_Tenure36_min_360  \\\n",
       "0                   180.000000                       180.0   \n",
       "1                     0.000000                         0.0   \n",
       "2                     1.000000                         0.0   \n",
       "3                     2.000000                         0.0   \n",
       "4                     1.666667                         0.0   \n",
       "\n",
       "   Repayment_Tenure36_std_360  Repayment_Tenure36_sum_9999  \\\n",
       "0                    0.000000                        543.0   \n",
       "1                    0.000000                          0.0   \n",
       "2                    1.966940                        256.0   \n",
       "3                    2.828427                        303.0   \n",
       "4                    3.550095                         49.0   \n",
       "\n",
       "   Repayment_Tenure36_mean_9999  Repayment_Tenure36_max_9999  \\\n",
       "0                     45.250000                        180.0   \n",
       "1                      0.000000                          0.0   \n",
       "2                      3.084337                         60.0   \n",
       "3                      5.716981                         94.0   \n",
       "4                      2.041667                         13.0   \n",
       "\n",
       "   Repayment_Tenure36_min_9999  Repayment_Tenure36_std_9999  \\\n",
       "0                          0.0                    74.210427   \n",
       "1                          0.0                     0.000000   \n",
       "2                          0.0                     9.043676   \n",
       "3                          0.0                    18.089273   \n",
       "4                          0.0                     3.668323   \n",
       "\n",
       "   Income26_count_30  Income26_min_9999  Income26_std_9999  \\\n",
       "0                NaN           480000.0                0.0   \n",
       "1                NaN                NaN                NaN   \n",
       "2                NaN            46200.0           155465.5   \n",
       "3                NaN                NaN                NaN   \n",
       "4                NaN            17000.0            11500.0   \n",
       "\n",
       "   Open_Date29_max_30  Open_Date29_mean_30  Open_Date29_mode_30  \\\n",
       "0                 NaN                  NaN                  NaN   \n",
       "1                 NaN                  NaN                  NaN   \n",
       "2                 NaN                  NaN                  NaN   \n",
       "3                 NaN                  NaN                  NaN   \n",
       "4                 NaN                  NaN                  NaN   \n",
       "\n",
       "   Open_Date29_nuniq_30  Open_Date29_maxcount_30  Open_Date29_mode_90  \\\n",
       "0                   NaN                      NaN                  NaN   \n",
       "1                   NaN                      NaN                  NaN   \n",
       "2                   NaN                      NaN                 78.0   \n",
       "3                   NaN                      NaN                  NaN   \n",
       "4                   NaN                      NaN                 49.0   \n",
       "\n",
       "   Open_Date29_nuniq_90  Open_Date29_max_360  Open_Date29_mode_360  \\\n",
       "0                   NaN                310.0                 192.0   \n",
       "1                   NaN                238.0                 124.0   \n",
       "2                  10.0                326.0                  78.0   \n",
       "3                   NaN                305.0                 302.0   \n",
       "4                   4.0                354.0                  49.0   \n",
       "\n",
       "   Open_Date29_maxcount_360  Open_Date29_max_9999  Open_Date29_mean_9999  \\\n",
       "0                       1.0                4203.0            1028.750000   \n",
       "1                       1.0                 955.0             439.000000   \n",
       "2                       4.0                5048.0             461.120482   \n",
       "3                       2.0                5685.0            1510.981132   \n",
       "4                       2.0                1087.0             266.541667   \n",
       "\n",
       "   Open_Date29_mode_9999  Open_Date29_maxcount_9999  \\\n",
       "0                  888.0                        2.0   \n",
       "1                  124.0                        1.0   \n",
       "2                   78.0                        4.0   \n",
       "3                  696.0                        4.0   \n",
       "4                   49.0                        2.0   \n",
       "\n",
       "   Portfolio_Type34_nuniq_30  Portfolio_Type34_nuniq_90  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                        2.0   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        1.0   \n",
       "\n",
       "   Portfolio_Type34_nuniq_360 Portfolio_Type34_mode_9999  \\\n",
       "0                         2.0                          R   \n",
       "1                         1.0                          I   \n",
       "2                         2.0                          I   \n",
       "3                         1.0                          I   \n",
       "4                         1.0                          I   \n",
       "\n",
       "   Portfolio_Type34_nuniq_9999 Account_Type32_mode_30  \\\n",
       "0                          3.0                    NaN   \n",
       "1                          1.0                    NaN   \n",
       "2                          3.0                    NaN   \n",
       "3                          2.0                    NaN   \n",
       "4                          1.0                    NaN   \n",
       "\n",
       "   Account_Type32_nuniq_30 Account_Type32_mode_90  Account_Type32_nuniq_90  \\\n",
       "0                      NaN                    NaN                      NaN   \n",
       "1                      NaN                    NaN                      NaN   \n",
       "2                      NaN                    5.0                      4.0   \n",
       "3                      NaN                    NaN                      NaN   \n",
       "4                      NaN                    5.0                      2.0   \n",
       "\n",
       "  Account_Type32_mode_360  Account_Type32_nuniq_360 Account_Type32_mode_9999  \\\n",
       "0                     2.0                       2.0                     10.0   \n",
       "1                     7.0                       1.0                      7.0   \n",
       "2                     5.0                       5.0                      5.0   \n",
       "3                     7.0                       2.0                      7.0   \n",
       "4                     5.0                       4.0                      5.0   \n",
       "\n",
       "   Account_Type32_nuniq_9999  Occupation_Code35_nuniq_30  \\\n",
       "0                        6.0                         NaN   \n",
       "1                        2.0                         NaN   \n",
       "2                        9.0                         NaN   \n",
       "3                        6.0                         NaN   \n",
       "4                        4.0                         NaN   \n",
       "\n",
       "   Occupation_Code35_nuniq_90  Occupation_Code35_nuniq_360  \\\n",
       "0                         NaN                          1.0   \n",
       "1                         NaN                          1.0   \n",
       "2                         1.0                          1.0   \n",
       "3                         NaN                          1.0   \n",
       "4                         1.0                          2.0   \n",
       "\n",
       "  CurrencyCode32_mode_360 CurrencyCode32_mode_9999  \\\n",
       "0                     INR                      INR   \n",
       "1                     INR                      INR   \n",
       "2                     INR                      INR   \n",
       "3                     INR                      INR   \n",
       "4                     INR                      INR   \n",
       "\n",
       "  AccountHoldertypeCode41_mode_90  AccountHoldertypeCode41_nuniq_90  \\\n",
       "0                             NaN                               NaN   \n",
       "1                             NaN                               NaN   \n",
       "2                             1.0                               1.0   \n",
       "3                             NaN                               NaN   \n",
       "4                             1.0                               1.0   \n",
       "\n",
       "   AccountHoldertypeCode41_nuniq_360  AccountHoldertypeCode41_nuniq_9999  \\\n",
       "0                                1.0                                 2.0   \n",
       "1                                1.0                                 1.0   \n",
       "2                                1.0                                 2.0   \n",
       "3                                1.0                                 1.0   \n",
       "4                                1.0                                 1.0   \n",
       "\n",
       "   Payment_History_Profile43_mode_30  Payment_History_Profile43_mode_90  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  0   \n",
       "2                                  0                                  1   \n",
       "3                                  0                                  0   \n",
       "4                                  0                                  1   \n",
       "\n",
       "   Payment_History_Profile43_nuniq_90  Payment_History_Profile43_mode_360  \\\n",
       "0                                 NaN                                  36   \n",
       "1                                 NaN                                  36   \n",
       "2                                 2.0                                   1   \n",
       "3                                 NaN                                  36   \n",
       "4                                 1.0                                   1   \n",
       "\n",
       "   Payment_History_Profile43_nuniq_360  Payment_History_Profile43_mode_9999  \\\n",
       "0                                  2.0                                   36   \n",
       "1                                  2.0                                   36   \n",
       "2                                 12.0                                    1   \n",
       "3                                  2.0                                    1   \n",
       "4                                  6.0                                    1   \n",
       "\n",
       "   Payment_History_Profile43_nuniq_9999  Date_Closed31_mode_30  \\\n",
       "0                                  12.0                    NaN   \n",
       "1                                   3.0                    NaN   \n",
       "2                                  27.0                    NaN   \n",
       "3                                  23.0                    NaN   \n",
       "4                                   8.0                    NaN   \n",
       "\n",
       "   Date_Closed31_nuniq_30  Date_Closed31_maxcount_30  Date_Closed31_max_90  \\\n",
       "0                     NaN                        NaN                   NaN   \n",
       "1                     NaN                        NaN                   NaN   \n",
       "2                     NaN                        NaN                  69.0   \n",
       "3                     NaN                        NaN                   NaN   \n",
       "4                     NaN                        NaN                  66.0   \n",
       "\n",
       "   Date_Closed31_min_90  Date_Closed31_mean_90  Date_Closed31_mode_90  \\\n",
       "0                   NaN                    NaN                    NaN   \n",
       "1                   NaN                    NaN                    NaN   \n",
       "2                  54.0                   61.5                   54.0   \n",
       "3                   NaN                    NaN                    NaN   \n",
       "4                  44.0                   55.0                   44.0   \n",
       "\n",
       "   Date_Closed31_nuniq_90  Date_Closed31_maxcount_90  Date_Closed31_mode_360  \\\n",
       "0                     NaN                        NaN                     0.0   \n",
       "1                     NaN                        NaN                   153.0   \n",
       "2                     3.0                        1.0                   106.0   \n",
       "3                     NaN                        NaN                    53.0   \n",
       "4                     3.0                        1.0                    44.0   \n",
       "\n",
       "   Date_Closed31_nuniq_360  Date_Closed31_maxcount_360  \\\n",
       "0                      1.0                         0.0   \n",
       "1                      2.0                         1.0   \n",
       "2                     24.0                         3.0   \n",
       "3                      2.0                         2.0   \n",
       "4                     12.0                         1.0   \n",
       "\n",
       "   Date_Closed31_mean_9999  Date_Closed31_mode_9999  \\\n",
       "0               281.333333                     88.0   \n",
       "1               231.500000                    153.0   \n",
       "2               269.052632                    106.0   \n",
       "3              1145.893617                    630.0   \n",
       "4               182.250000                     44.0   \n",
       "\n",
       "   Date_of_Last_Payment40_nuniq_30  Date_of_Last_Payment40_maxcount_30  \\\n",
       "0                              NaN                                 NaN   \n",
       "1                              NaN                                 NaN   \n",
       "2                              NaN                                 NaN   \n",
       "3                              NaN                                 NaN   \n",
       "4                              NaN                                 NaN   \n",
       "\n",
       "   Date_of_Last_Payment40_nuniq_90  Date_of_Last_Payment40_maxcount_90  \\\n",
       "0                              NaN                                 NaN   \n",
       "1                              NaN                                 NaN   \n",
       "2                              4.0                                 2.0   \n",
       "3                              NaN                                 NaN   \n",
       "4                              4.0                                 2.0   \n",
       "\n",
       "   Date_of_Last_Payment40_min_360  Date_of_Last_Payment40_mode_360  \\\n",
       "0                            21.0                             21.0   \n",
       "1                           153.0                            153.0   \n",
       "2                            54.0                            106.0   \n",
       "3                            53.0                             53.0   \n",
       "4                            34.0                             34.0   \n",
       "\n",
       "   Date_of_Last_Payment40_maxcount_360  Date_of_Last_Payment40_mean_9999  \\\n",
       "0                                  2.0                        129.416667   \n",
       "1                                  1.0                        153.000000   \n",
       "2                                  3.0                        176.122807   \n",
       "3                                  2.0                       1139.510638   \n",
       "4                                  4.0                        163.250000   \n",
       "\n",
       "   Date_of_Last_Payment40_mode_9999  Date_of_Last_Payment40_nuniq_9999  \\\n",
       "0                              46.0                                8.0   \n",
       "1                             153.0                                2.0   \n",
       "2                              73.0                               42.0   \n",
       "3                             630.0                               28.0   \n",
       "4                              34.0                               16.0   \n",
       "\n",
       "   Date_of_Last_Payment40_maxcount_9999  Date_Reported33_nuniq_30  \\\n",
       "0                                   4.0                       NaN   \n",
       "1                                   1.0                       NaN   \n",
       "2                                   4.0                       NaN   \n",
       "3                                   4.0                       NaN   \n",
       "4                                   4.0                       NaN   \n",
       "\n",
       "   Date_Reported33_max_90  Date_Reported33_mode_90  Date_Reported33_nuniq_90  \\\n",
       "0                     NaN                      NaN                       NaN   \n",
       "1                     NaN                      NaN                       NaN   \n",
       "2                    78.0                     47.0                       3.0   \n",
       "3                     NaN                      NaN                       NaN   \n",
       "4                    66.0                     36.0                       2.0   \n",
       "\n",
       "   Date_Reported33_maxcount_90  Date_Reported33_max_360  \\\n",
       "0                          NaN                     21.0   \n",
       "1                          NaN                     77.0   \n",
       "2                          9.0                    269.0   \n",
       "3                          NaN                     32.0   \n",
       "4                          4.0                    158.0   \n",
       "\n",
       "   Date_Reported33_mean_360  Date_Reported33_mode_360  \\\n",
       "0                 21.000000                      21.0   \n",
       "1                 77.000000                      77.0   \n",
       "2                100.131148                      78.0   \n",
       "3                 32.000000                      32.0   \n",
       "4                 78.523810                      66.0   \n",
       "\n",
       "   Date_Reported33_nuniq_360  Date_Reported33_max_9999  \\\n",
       "0                        1.0                     418.0   \n",
       "1                        1.0                     310.0   \n",
       "2                       11.0                    1692.0   \n",
       "3                        1.0                    2438.0   \n",
       "4                        6.0                     889.0   \n",
       "\n",
       "   Date_Reported33_mode_9999  Date_Reported33_nuniq_9999  \\\n",
       "0                       21.0                         7.0   \n",
       "1                       77.0                         2.0   \n",
       "2                       47.0                        22.0   \n",
       "3                      611.0                        24.0   \n",
       "4                       66.0                         8.0   \n",
       "\n",
       "   Date_Reported33_maxcount_9999  DateOfAddition34_nuniq_30  \\\n",
       "0                            6.0                        NaN   \n",
       "1                            2.0                        NaN   \n",
       "2                           22.0                        NaN   \n",
       "3                            9.0                        NaN   \n",
       "4                            8.0                        NaN   \n",
       "\n",
       "   DateOfAddition34_max_90  DateOfAddition34_mean_90  \\\n",
       "0                      NaN                       NaN   \n",
       "1                      NaN                       NaN   \n",
       "2                     78.0                 57.214286   \n",
       "3                      NaN                       NaN   \n",
       "4                     66.0                 42.000000   \n",
       "\n",
       "   DateOfAddition34_nuniq_90  DateOfAddition34_maxcount_90  \\\n",
       "0                        NaN                           NaN   \n",
       "1                        NaN                           NaN   \n",
       "2                        3.0                           8.0   \n",
       "3                        NaN                           NaN   \n",
       "4                        2.0                           4.0   \n",
       "\n",
       "   DateOfAddition34_max_360  DateOfAddition34_mean_360  \\\n",
       "0                     296.0                 250.500000   \n",
       "1                     230.0                 169.000000   \n",
       "2                     300.0                 129.524590   \n",
       "3                     277.0                 175.000000   \n",
       "4                     340.0                 144.761905   \n",
       "\n",
       "   DateOfAddition34_mode_360  DateOfAddition34_maxcount_360  \\\n",
       "0                      205.0                            1.0   \n",
       "1                      108.0                            1.0   \n",
       "2                       78.0                           14.0   \n",
       "3                      124.0                            2.0   \n",
       "4                       97.0                            6.0   \n",
       "\n",
       "   DateOfAddition34_max_9999  DateOfAddition34_min_9999  \\\n",
       "0                     1878.0                      205.0   \n",
       "1                      808.0                      108.0   \n",
       "2                     2543.0                       35.0   \n",
       "3                     2536.0                      124.0   \n",
       "4                     1071.0                       36.0   \n",
       "\n",
       "   DateOfAddition34_mode_9999  DateOfAddition34_nuniq_9999  \\\n",
       "0                       752.0                         11.0   \n",
       "1                       108.0                          3.0   \n",
       "2                        78.0                         29.0   \n",
       "3                       611.0                         26.0   \n",
       "4                        97.0                         11.0   \n",
       "\n",
       "   DateOfAddition34_maxcount_9999  Account_Status34_mode_30  \\\n",
       "0                             2.0                       NaN   \n",
       "1                             1.0                       NaN   \n",
       "2                            14.0                       NaN   \n",
       "3                             9.0                       NaN   \n",
       "4                             6.0                       NaN   \n",
       "\n",
       "   Account_Status34_nuniq_30  Account_Status34_mode_90  \\\n",
       "0                        NaN                       NaN   \n",
       "1                        NaN                       NaN   \n",
       "2                        NaN                      11.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        NaN                      11.0   \n",
       "\n",
       "   Account_Status34_nuniq_90  Account_Status34_nuniq_360  \\\n",
       "0                        NaN                         1.0   \n",
       "1                        NaN                         2.0   \n",
       "2                        3.0                         6.0   \n",
       "3                        NaN                         2.0   \n",
       "4                        2.0                         2.0   \n",
       "\n",
       "  Account_Status34_mode_9999  Account_Status34_nuniq_9999  Month50_sum_30  \\\n",
       "0                         11                          4.0             NaN   \n",
       "1                         13                          2.0             NaN   \n",
       "2                         11                          6.0             NaN   \n",
       "3                         13                          9.0             NaN   \n",
       "4                         13                          3.0             NaN   \n",
       "\n",
       "   Month50_mean_30  Month50_std_30  Month50_sum_90  Month50_mean_90  \\\n",
       "0              NaN             NaN             NaN              NaN   \n",
       "1              NaN             NaN             NaN              NaN   \n",
       "2              NaN             NaN           109.0         7.785714   \n",
       "3              NaN             NaN             NaN              NaN   \n",
       "4              NaN             NaN            44.0         8.800000   \n",
       "\n",
       "   Month50_max_90  Month50_std_90  Month50_max_360  Month50_min_360  \\\n",
       "0             NaN             NaN             12.0             12.0   \n",
       "1             NaN             NaN              8.0              8.0   \n",
       "2             9.0        0.557875             12.0              3.0   \n",
       "3             NaN             NaN             12.0             12.0   \n",
       "4             9.0        0.400000             12.0              5.0   \n",
       "\n",
       "   Month50_mean_9999  Month50_max_9999  Month50_min_9999  Month50_std_9999  \\\n",
       "0          12.000000              12.0              12.0          0.000000   \n",
       "1           9.000000              11.0               8.0          1.414214   \n",
       "2           7.879518              12.0               3.0          2.730451   \n",
       "3           8.566038              12.0               3.0          3.339356   \n",
       "4           8.625000              12.0               5.0          2.269591   \n",
       "\n",
       "   Days_Past_Due58_sum_90  Days_Past_Due58_min_90  Days_Past_Due58_std_90  \\\n",
       "0                     NaN                     NaN                     NaN   \n",
       "1                     NaN                     NaN                     NaN   \n",
       "2                     0.0                     0.0                     0.0   \n",
       "3                     NaN                     NaN                     NaN   \n",
       "4                     0.0                     0.0                     0.0   \n",
       "\n",
       "   Days_Past_Due58_sum_360  Days_Past_Due58_mean_360  Days_Past_Due58_max_360  \\\n",
       "0                      0.0                  0.000000                      0.0   \n",
       "1                      0.0                  0.000000                      0.0   \n",
       "2                    110.0                  2.619048                     54.0   \n",
       "3                    329.0                109.666667                    150.0   \n",
       "4                      0.0                  0.000000                      0.0   \n",
       "\n",
       "   Days_Past_Due58_min_360  Days_Past_Due58_std_360  Days_Past_Due58_sum_9999  \\\n",
       "0                      0.0                 0.000000                     267.0   \n",
       "1                      0.0                 0.000000                     450.0   \n",
       "2                      0.0                11.493171                     110.0   \n",
       "3                     29.0                57.039947                    2918.0   \n",
       "4                      0.0                 0.000000                     114.0   \n",
       "\n",
       "   Days_Past_Due58_max_9999  Days_Past_Due58_min_9999  \\\n",
       "0                     129.0                       0.0   \n",
       "1                     450.0                       0.0   \n",
       "2                      54.0                       0.0   \n",
       "3                     900.0                       0.0   \n",
       "4                      87.0                       0.0   \n",
       "\n",
       "   Days_Past_Due58_std_9999  Duecount53_mean_30  Duecount53_min_30  \\\n",
       "0                 34.132402                 NaN                NaN   \n",
       "1                212.132034                 NaN                NaN   \n",
       "2                  9.393263                 NaN                NaN   \n",
       "3                144.385284                 NaN                NaN   \n",
       "4                 17.977416                 NaN                NaN   \n",
       "\n",
       "   Duecount53_std_30  Duecount53_sum_90  Duecount53_mean_90  \\\n",
       "0                NaN                NaN                 NaN   \n",
       "1                NaN                NaN                 NaN   \n",
       "2                NaN               15.0            1.071429   \n",
       "3                NaN                NaN                 NaN   \n",
       "4                NaN                5.0            1.000000   \n",
       "\n",
       "   Duecount53_max_90  Duecount53_min_90  Duecount53_std_90  \\\n",
       "0                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN   \n",
       "2                2.0                1.0           0.257539   \n",
       "3                NaN                NaN                NaN   \n",
       "4                1.0                1.0           0.000000   \n",
       "\n",
       "   Duecount53_sum_360  Duecount53_mean_360  Duecount53_max_360  \\\n",
       "0                17.0             8.500000                10.0   \n",
       "1                 8.0             4.000000                 6.0   \n",
       "2               119.0             1.950820                 8.0   \n",
       "3                17.0             5.666667                 9.0   \n",
       "4                65.0             3.095238                 9.0   \n",
       "\n",
       "   Duecount53_min_360  Duecount53_std_360  Duecount53_mean_9999  \\\n",
       "0                 7.0            1.500000             22.166667   \n",
       "1                 2.0            2.000000              8.000000   \n",
       "2                 1.0            1.562115              7.819277   \n",
       "3                 4.0            2.357023             11.075472   \n",
       "4                 1.0            2.974571              4.416667   \n",
       "\n",
       "   Duecount53_max_9999  Duecount53_min_9999  Duecount53_std_9999  \\\n",
       "0                 55.0                  7.0            12.408554   \n",
       "1                 16.0                  2.0             5.887841   \n",
       "2                 83.0                  1.0            13.668312   \n",
       "3                 83.0                  1.0            22.513601   \n",
       "4                 33.0                  1.0             6.639005   \n",
       "\n",
       "   Duesum51_mean_30  Duesum51_std_30  Duesum51_mean_90  Duesum51_max_90  \\\n",
       "0               NaN              NaN               NaN              NaN   \n",
       "1               NaN              NaN               NaN              NaN   \n",
       "2               NaN              NaN               0.0              0.0   \n",
       "3               NaN              NaN               NaN              NaN   \n",
       "4               NaN              NaN               0.0              0.0   \n",
       "\n",
       "   Duesum51_sum_360  Duesum51_mean_360  Duesum51_min_360  Duesum51_std_360  \\\n",
       "0               0.0           0.000000               0.0          0.000000   \n",
       "1               0.0           0.000000               0.0          0.000000   \n",
       "2             110.0           1.803279               0.0          9.613549   \n",
       "3             747.0         249.000000              29.0        155.563492   \n",
       "4               0.0           0.000000               0.0          0.000000   \n",
       "\n",
       "   Duesum51_sum_9999  Duesum51_mean_9999  Duesum51_max_9999  \\\n",
       "0             1294.0          107.833333             1085.0   \n",
       "1              450.0          150.000000              450.0   \n",
       "2              110.0            1.325301               54.0   \n",
       "3            81524.0         1538.188679            59071.0   \n",
       "4              140.0            5.833333               87.0   \n",
       "\n",
       "   Duesum51_min_9999  Duesum51_std_9999  Amount_Financed35_std_7  \\\n",
       "0                0.0         295.475276                      NaN   \n",
       "1                0.0         212.132034                      NaN   \n",
       "2                0.0           8.279905                      0.0   \n",
       "3                0.0        8193.472586                      0.0   \n",
       "4                0.0          19.959682                      0.0   \n",
       "\n",
       "   Amount_Financed35_max_30  Amount_Financed35_min_30  \\\n",
       "0                       NaN                       NaN   \n",
       "1                   25000.0                       0.0   \n",
       "2                  100000.0                       0.0   \n",
       "3                   50000.0                   50000.0   \n",
       "4                   50000.0                       0.0   \n",
       "\n",
       "   Amount_Financed35_std_30  Amount_Financed35_count_90  \\\n",
       "0                       NaN                         3.0   \n",
       "1              10530.379333                         3.0   \n",
       "2              34692.298217                        16.0   \n",
       "3                  0.000000                         2.0   \n",
       "4              25000.000000                         4.0   \n",
       "\n",
       "   Amount_Financed35_min_90  Amount_Financed35_count_360  \\\n",
       "0                       0.0                          4.0   \n",
       "1                       0.0                          3.0   \n",
       "2                       0.0                         47.0   \n",
       "3                   10000.0                          3.0   \n",
       "4                       0.0                          9.0   \n",
       "\n",
       "   Amount_Financed35_sum_360  Amount_Financed35_mean_360  \\\n",
       "0                  1177000.0               294250.000000   \n",
       "1                    32000.0                10666.666667   \n",
       "2                  1156010.0                26883.953488   \n",
       "3                    70000.0                23333.333333   \n",
       "4                   387000.0                48375.000000   \n",
       "\n",
       "   Amount_Financed35_max_360  Amount_Financed35_min_360  \\\n",
       "0                   867000.0                        0.0   \n",
       "1                    25000.0                        0.0   \n",
       "2                   310000.0                        0.0   \n",
       "3                    50000.0                    10000.0   \n",
       "4                   310000.0                        0.0   \n",
       "\n",
       "   Amount_Financed35_count_9999  Amount_Financed35_sum_9999  \\\n",
       "0                           5.0                   1237000.0   \n",
       "1                           5.0                    233000.0   \n",
       "2                          58.0                   3019520.0   \n",
       "3                           9.0                    720000.0   \n",
       "4                          15.0                    597188.0   \n",
       "\n",
       "   Amount_Financed35_max_9999  Amount_Financed35_min_9999  \\\n",
       "0                    867000.0                         0.0   \n",
       "1                    201000.0                         0.0   \n",
       "2                    593511.0                         0.0   \n",
       "3                    600000.0                     10000.0   \n",
       "4                    310000.0                         0.0   \n",
       "\n",
       "   Amount_Financed35_std_9999  Duration_Of_Agreement41_std_7  \\\n",
       "0               330259.049838                            NaN   \n",
       "1                77739.565216                            NaN   \n",
       "2               101655.448885                            0.0   \n",
       "3               184270.332814                            0.0   \n",
       "4                83891.500247                            0.0   \n",
       "\n",
       "   Duration_Of_Agreement41_min_30  Duration_Of_Agreement41_min_90  \\\n",
       "0                             NaN                             0.0   \n",
       "1                             1.0                             1.0   \n",
       "2                             0.0                             0.0   \n",
       "3                             1.0                             1.0   \n",
       "4                             0.0                             0.0   \n",
       "\n",
       "   Duration_Of_Agreement41_mean_360  Duration_Of_Agreement41_max_360  \\\n",
       "0                         66.000000                            180.0   \n",
       "1                         18.333333                             48.0   \n",
       "2                         20.191489                            150.0   \n",
       "3                         14.333333                             36.0   \n",
       "4                         19.444444                             48.0   \n",
       "\n",
       "   Duration_Of_Agreement41_min_360  Duration_Of_Agreement41_std_360  \\\n",
       "0                              0.0                        68.146900   \n",
       "1                              1.0                        21.076580   \n",
       "2                              0.0                        31.883857   \n",
       "3                              1.0                        15.456031   \n",
       "4                              0.0                        19.596548   \n",
       "\n",
       "   Duration_Of_Agreement41_mean_9999  Duration_Of_Agreement41_max_9999  \\\n",
       "0                          55.200000                             180.0   \n",
       "1                          13.400000                              48.0   \n",
       "2                          24.120690                             150.0   \n",
       "3                          28.777778                              36.0   \n",
       "4                          16.866667                              48.0   \n",
       "\n",
       "   Duration_Of_Agreement41_min_9999  Duration_Of_Agreement41_std_9999  \\\n",
       "0                               0.0                         64.666529   \n",
       "1                               0.0                         17.816846   \n",
       "2                               0.0                         31.028395   \n",
       "3                               1.0                         13.562840   \n",
       "4                               0.0                         19.161999   \n",
       "\n",
       "   Date_of_Request35_mode_7  Date_of_Request35_nuniq_7  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       1.0                        1.0   \n",
       "3                       6.0                        1.0   \n",
       "4                       5.0                        1.0   \n",
       "\n",
       "   Date_of_Request35_nuniq_90  Enquiry_Reason34_nuniq_7  \\\n",
       "0                         3.0                       NaN   \n",
       "1                         3.0                       NaN   \n",
       "2                        12.0                       1.0   \n",
       "3                         2.0                       1.0   \n",
       "4                         4.0                       1.0   \n",
       "\n",
       "   Enquiry_Reason34_mode_30  ...  feature_409 * Outstanding_Balance_UnSecured  \\\n",
       "0                       NaN  ...                                          0.0   \n",
       "1                      13.0  ...                                          NaN   \n",
       "2                      13.0  ...                                     597688.8   \n",
       "3                      13.0  ...                                      97501.5   \n",
       "4                      13.0  ...                                          0.0   \n",
       "\n",
       "   feature_409 * Payment_Rating34_mean_9999  \\\n",
       "0                                  0.000000   \n",
       "1                                       NaN   \n",
       "2                                  0.003125   \n",
       "3                                  0.115000   \n",
       "4                                  0.000000   \n",
       "\n",
       "   feature_409 * Rate_of_Interest36_min_9999  feature_409 * Tel_nuniq2  \\\n",
       "0                                       0.00                      0.00   \n",
       "1                                        NaN                       NaN   \n",
       "2                                       1.35                     39.40   \n",
       "3                                       2.00                     36.25   \n",
       "4                                       0.00                      0.00   \n",
       "\n",
       "   feature_409 * feature_638  feature_409 * feature_643  \\\n",
       "0                       0.00                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                       0.20                   0.066667   \n",
       "3                       0.75                   0.074074   \n",
       "4                       0.00                   0.000000   \n",
       "\n",
       "   feature_409 * feature_701  feature_409 * feature_710  \\\n",
       "0                   0.000000                        0.0   \n",
       "1                        NaN                        NaN   \n",
       "2                   0.133333                        0.6   \n",
       "3                   0.062500                        1.0   \n",
       "4                        NaN                        0.0   \n",
       "\n",
       "   feature_409 * feature_778  feature_409 * feature_781  \\\n",
       "0                   0.000000                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                   0.200000                   0.150000   \n",
       "3                   0.173077                   0.086957   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_409 * feature_8  feature_409 * feature_888  \\\n",
       "0                      0.0                   0.000000   \n",
       "1                      NaN                        NaN   \n",
       "2                    107.6                   0.009524   \n",
       "3                    460.0                   0.026923   \n",
       "4                      0.0                   0.000000   \n",
       "\n",
       "   feature_410 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                       0.000000e+00                 \n",
       "1                                                NaN                 \n",
       "2                                       1.211429e+06                 \n",
       "3                                       1.374000e+05                 \n",
       "4                                       0.000000e+00                 \n",
       "\n",
       "   feature_410 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                       35442.171865               \n",
       "3                                                NaN               \n",
       "4                                           0.000000               \n",
       "\n",
       "   feature_410 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                       0.000000e+00                 \n",
       "1                                                NaN                 \n",
       "2                                       5.062902e+06                 \n",
       "3                                       9.999528e+05                 \n",
       "4                                       0.000000e+00                 \n",
       "\n",
       "   feature_410 * Name_nuniq2  feature_410 * Outstanding_Balance_UnSecured  \\\n",
       "0                   0.000000                                 0.000000e+00   \n",
       "1                        NaN                                          NaN   \n",
       "2                 634.285714                                 2.134603e+06   \n",
       "3                  41.100000                                 1.170018e+05   \n",
       "4                   0.000000                                 0.000000e+00   \n",
       "\n",
       "   feature_410 * Payment_Rating34_mean_9999  \\\n",
       "0                                  0.000000   \n",
       "1                                       NaN   \n",
       "2                                  0.011161   \n",
       "3                                  0.138000   \n",
       "4                                  0.000000   \n",
       "\n",
       "   feature_410 * Rate_of_Interest36_min_9999  feature_410 * Tel_nuniq2  \\\n",
       "0                                   0.000000                  0.000000   \n",
       "1                                        NaN                       NaN   \n",
       "2                                   4.821429                140.714286   \n",
       "3                                   2.400000                 43.500000   \n",
       "4                                   0.000000                  0.000000   \n",
       "\n",
       "   feature_410 * feature_638  feature_410 * feature_643  \\\n",
       "0                   0.000000                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                   0.714286                   0.238095   \n",
       "3                   0.900000                   0.088889   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_410 * feature_701  feature_410 * feature_710  \\\n",
       "0                    0.00000                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                    0.47619                   2.142857   \n",
       "3                    0.07500                   1.200000   \n",
       "4                        NaN                   0.000000   \n",
       "\n",
       "   feature_410 * feature_778  feature_410 * feature_781  \\\n",
       "0                   0.000000                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                   0.714286                   0.535714   \n",
       "3                   0.207692                   0.104348   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_410 * feature_8  feature_410 * feature_888  \\\n",
       "0                 0.000000                   0.000000   \n",
       "1                      NaN                        NaN   \n",
       "2               384.285714                   0.034014   \n",
       "3               552.000000                   0.032308   \n",
       "4                 0.000000                   0.000000   \n",
       "\n",
       "   feature_410 * feature_9  \\\n",
       "0                 0.000000   \n",
       "1                      NaN   \n",
       "2                 7.857143   \n",
       "3                 3.300000   \n",
       "4                 0.000000   \n",
       "\n",
       "   feature_638 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                          4441000.0                 \n",
       "1                                           180700.0                 \n",
       "2                                          1696000.0                 \n",
       "3                                          1374000.0                 \n",
       "4                                                0.0                 \n",
       "\n",
       "   feature_638 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                       49619.040611               \n",
       "3                                                NaN               \n",
       "4                                           0.000000               \n",
       "\n",
       "   feature_638 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                          8304111.0                 \n",
       "1                                           308700.0                 \n",
       "2                                          7088063.0                 \n",
       "3                                          9999528.0                 \n",
       "4                                                0.0                 \n",
       "\n",
       "   feature_638 * Name_nuniq2  feature_638 * Payment_Rating34_mean_9999  \\\n",
       "0                        234                                  0.363636   \n",
       "1                        181                                  0.000000   \n",
       "2                        888                                  0.015625   \n",
       "3                        411                                  1.380000   \n",
       "4                          0                                  0.000000   \n",
       "\n",
       "   feature_638 * Rate_of_Interest36_min_9999  feature_638 * Tel_nuniq2  \\\n",
       "0                                      45.00                        86   \n",
       "1                                        NaN                        30   \n",
       "2                                       6.75                       197   \n",
       "3                                      24.00                       435   \n",
       "4                                       0.00                         0   \n",
       "\n",
       "   feature_638 * feature_669  feature_638 * feature_701  \\\n",
       "0                   0.045234                   0.000000   \n",
       "1                   0.019763                   0.500000   \n",
       "2                   0.022333                   0.666667   \n",
       "3                   0.086093                   0.750000   \n",
       "4                   0.000000                        NaN   \n",
       "\n",
       "   feature_638 * feature_710  feature_638 * feature_762  \\\n",
       "0                          1                   0.045455   \n",
       "1                          6                   0.000000   \n",
       "2                          3                   0.015873   \n",
       "3                         12                   0.138462   \n",
       "4                          0                   0.000000   \n",
       "\n",
       "   feature_638 * feature_781  feature_638 * feature_8  \\\n",
       "0                   0.538462                      423   \n",
       "1                   0.615385                     2033   \n",
       "2                   0.750000                      538   \n",
       "3                   1.043478                     5520   \n",
       "4                   0.000000                        0   \n",
       "\n",
       "   feature_638 * feature_804  feature_638 * feature_846  \\\n",
       "0                   0.025974                   0.025974   \n",
       "1                   0.025641                   0.000000   \n",
       "2                   0.000000                   0.031746   \n",
       "3                   0.000000                   0.138462   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_638 * feature_874  feature_638 * feature_888  \\\n",
       "0                   0.019481                   0.064935   \n",
       "1                   0.000000                   0.102564   \n",
       "2                   0.000000                   0.047619   \n",
       "3                   0.046154                   0.323077   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_643 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                       2.018636e+06                 \n",
       "1                                       3.011667e+04                 \n",
       "2                                       5.653333e+05                 \n",
       "3                                       1.357037e+05                 \n",
       "4                                       0.000000e+00                 \n",
       "\n",
       "   feature_643 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                       16539.680204               \n",
       "3                                                NaN               \n",
       "4                                           0.000000               \n",
       "\n",
       "   feature_643 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                       3.774596e+06                 \n",
       "1                                       5.145000e+04                 \n",
       "2                                       2.362688e+06                 \n",
       "3                                       9.876077e+05                 \n",
       "4                                       0.000000e+00                 \n",
       "\n",
       "   feature_643 * Name_nuniq2  feature_643 * Outstanding_Balance_UnSecured  \\\n",
       "0                 106.363636                                153609.090909   \n",
       "1                  30.166667                                     0.000000   \n",
       "2                 296.000000                                996148.000000   \n",
       "3                  40.592593                                115557.333333   \n",
       "4                   0.000000                                     0.000000   \n",
       "\n",
       "   feature_643 * Payment_Rating34_mean_9999  \\\n",
       "0                                  0.165289   \n",
       "1                                  0.000000   \n",
       "2                                  0.005208   \n",
       "3                                  0.136296   \n",
       "4                                  0.000000   \n",
       "\n",
       "   feature_643 * Rate_of_Interest36_min_9999  feature_643 * Tel_nuniq2  \\\n",
       "0                                  20.454545                 39.090909   \n",
       "1                                        NaN                  5.000000   \n",
       "2                                   2.250000                 65.666667   \n",
       "3                                   2.370370                 42.962963   \n",
       "4                                   0.000000                  0.000000   \n",
       "\n",
       "   feature_643 * feature_700  feature_643 * feature_701  \\\n",
       "0                   0.240642                   0.000000   \n",
       "1                   0.107143                   0.083333   \n",
       "2                   0.277778                   0.222222   \n",
       "3                   0.143659                   0.074074   \n",
       "4                   0.000000                        NaN   \n",
       "\n",
       "   feature_643 * feature_702  feature_643 * feature_710  \\\n",
       "0                   0.268595                   0.454545   \n",
       "1                   0.120370                   1.000000   \n",
       "2                   0.307692                   1.000000   \n",
       "3                   0.200436                   1.185185   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_643 * feature_778  feature_643 * feature_781  \\\n",
       "0                   0.303030                   0.244755   \n",
       "1                   0.145833                   0.102564   \n",
       "2                   0.333333                   0.250000   \n",
       "3                   0.205128                   0.103060   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_643 * feature_8  \\\n",
       "0               192.272727   \n",
       "1               338.833333   \n",
       "2               179.333333   \n",
       "3               545.185185   \n",
       "4                 0.000000   \n",
       "\n",
       "   feature_669 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                      200885.298869                 \n",
       "1                                        3571.146245                 \n",
       "2                                       37875.930521                 \n",
       "3                                       13143.487859                 \n",
       "4                                        7444.344023                 \n",
       "\n",
       "   feature_669 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                        1108.117532               \n",
       "3                                                NaN               \n",
       "4                                         110.215304               \n",
       "\n",
       "   feature_669 * Name_nuniq2  feature_669 * Outstanding_Balance_UnSecured  \\\n",
       "0                  10.584814                                 15286.462036   \n",
       "1                   3.577075                                     0.000000   \n",
       "2                  19.831266                                 66739.444169   \n",
       "3                   3.931567                                 11192.225166   \n",
       "4                   6.151603                                  2150.845481   \n",
       "\n",
       "   feature_669 * Payment_Rating34_mean_9999  \\\n",
       "0                                  0.016449   \n",
       "1                                  0.000000   \n",
       "2                                  0.000349   \n",
       "3                                  0.013201   \n",
       "4                                  0.002430   \n",
       "\n",
       "   feature_669 * Rate_of_Interest36_min_9999  feature_669 * Tel_nuniq2  \\\n",
       "0                                   2.035541                  3.890145   \n",
       "1                                        NaN                  0.592885   \n",
       "2                                   0.150744                  4.399504   \n",
       "3                                   0.229581                  4.161148   \n",
       "4                                   0.524781                  0.816327   \n",
       "\n",
       "   feature_669 * feature_710  feature_669 * feature_8  \\\n",
       "0                   0.045234                19.134087   \n",
       "1                   0.118577                40.177866   \n",
       "2                   0.066998                12.014888   \n",
       "3                   0.114790                52.803532   \n",
       "4                   0.000000                26.239067   \n",
       "\n",
       "   feature_700 * Name_nuniq2  feature_700 * feature_701  \\\n",
       "0                 123.882353                   0.000000   \n",
       "1                 116.357143                   0.321429   \n",
       "2                 740.000000                   0.555556   \n",
       "3                  66.424242                   0.121212   \n",
       "4                 150.714286                        NaN   \n",
       "\n",
       "   feature_700 * feature_779  \\\n",
       "0                   0.294118   \n",
       "1                   0.500000   \n",
       "2                   0.500000   \n",
       "3                   0.272727   \n",
       "4                   0.142857   \n",
       "\n",
       "   feature_701 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                       0.000000e+00                 \n",
       "1                                       9.035000e+04                 \n",
       "2                                       1.130667e+06                 \n",
       "3                                       1.145000e+05                 \n",
       "4                                                NaN                 \n",
       "\n",
       "   feature_701 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                       0.000000e+00                 \n",
       "1                                       1.543500e+05                 \n",
       "2                                       4.725375e+06                 \n",
       "3                                       8.332940e+05                 \n",
       "4                                                NaN                 \n",
       "\n",
       "   feature_701 * Name_nuniq2  feature_701 * Payment_Rating34_mean_9999  \\\n",
       "0                       0.00                                  0.000000   \n",
       "1                      90.50                                  0.000000   \n",
       "2                     592.00                                  0.010417   \n",
       "3                      34.25                                  0.115000   \n",
       "4                        NaN                                       NaN   \n",
       "\n",
       "   feature_701 * Rate_of_Interest36_min_9999  feature_701 * Tel_nuniq2  \\\n",
       "0                                        0.0                  0.000000   \n",
       "1                                        NaN                 15.000000   \n",
       "2                                        4.5                131.333333   \n",
       "3                                        2.0                 36.250000   \n",
       "4                                        NaN                       NaN   \n",
       "\n",
       "   feature_701 * feature_710  feature_701 * feature_762  \\\n",
       "0                        0.0                   0.000000   \n",
       "1                        3.0                   0.000000   \n",
       "2                        2.0                   0.010582   \n",
       "3                        1.0                   0.011538   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   feature_701 * feature_778  feature_701 * feature_781  \\\n",
       "0                   0.000000                   0.000000   \n",
       "1                   0.437500                   0.307692   \n",
       "2                   0.666667                   0.500000   \n",
       "3                   0.173077                   0.086957   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   feature_701 * feature_888  \\\n",
       "0                   0.000000   \n",
       "1                   0.051282   \n",
       "2                   0.031746   \n",
       "3                   0.026923   \n",
       "4                        NaN   \n",
       "\n",
       "   feature_702 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                       45802.191333               \n",
       "3                                                NaN               \n",
       "4                                        2749.370853               \n",
       "\n",
       "   feature_702 * Tel_nuniq2  feature_702 * feature_762  \\\n",
       "0                 50.818182                   0.026860   \n",
       "1                 21.666667                   0.000000   \n",
       "2                181.846154                   0.014652   \n",
       "3                 98.088235                   0.031222   \n",
       "4                 20.363636                   0.039669   \n",
       "\n",
       "   feature_702 * feature_778  feature_702 * feature_779  \\\n",
       "0                   0.393939                   0.328283   \n",
       "1                   0.631944                   0.561728   \n",
       "2                   0.923077                   0.553846   \n",
       "3                   0.468326                   0.380515   \n",
       "4                   0.181818                   0.145455   \n",
       "\n",
       "   feature_702 * feature_781  feature_702 * feature_888  \\\n",
       "0                   0.318182                   0.038371   \n",
       "1                   0.444444                   0.074074   \n",
       "2                   0.692308                   0.043956   \n",
       "3                   0.235294                   0.072851   \n",
       "4                   0.363636                   0.079339   \n",
       "\n",
       "   feature_702 * feature_9  \\\n",
       "0                 6.500000   \n",
       "1                 6.500000   \n",
       "2                10.153846   \n",
       "3                 7.441176   \n",
       "4                 7.272727   \n",
       "\n",
       "   feature_710 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                          4441000.0                 \n",
       "1                                          1084200.0                 \n",
       "2                                          5088000.0                 \n",
       "3                                          1832000.0                 \n",
       "4                                                0.0                 \n",
       "\n",
       "   feature_710 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                      148857.121833               \n",
       "3                                                NaN               \n",
       "4                                           0.000000               \n",
       "\n",
       "   feature_710 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                          8304111.0                 \n",
       "1                                          1852200.0                 \n",
       "2                                         21264189.0                 \n",
       "3                                         13332704.0                 \n",
       "4                                                0.0                 \n",
       "\n",
       "   feature_710 * Name_nuniq2  feature_710 * Outstanding_Balance_UnSecured  \\\n",
       "0                        234                                       337940   \n",
       "1                       1086                                            0   \n",
       "2                       2664                                      8965332   \n",
       "3                        548                                      1560024   \n",
       "4                          0                                            0   \n",
       "\n",
       "   feature_710 * Payment_Rating34_mean_9999  \\\n",
       "0                                  0.363636   \n",
       "1                                  0.000000   \n",
       "2                                  0.046875   \n",
       "3                                  1.840000   \n",
       "4                                  0.000000   \n",
       "\n",
       "   feature_710 * Rate_of_Interest36_min_9999  feature_710 * Tel_nuniq2  \\\n",
       "0                                      45.00                        86   \n",
       "1                                        NaN                       180   \n",
       "2                                      20.25                       591   \n",
       "3                                      32.00                       580   \n",
       "4                                       0.00                         0   \n",
       "\n",
       "   feature_710 * feature_762  feature_710 * feature_779  \\\n",
       "0                   0.045455                   0.555556   \n",
       "1                   0.000000                   4.666667   \n",
       "2                   0.047619                   1.800000   \n",
       "3                   0.184615                   2.250000   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_710 * feature_8  feature_710 * feature_804  \\\n",
       "0                      423                   0.025974   \n",
       "1                    12198                   0.153846   \n",
       "2                     1614                   0.000000   \n",
       "3                     7360                   0.000000   \n",
       "4                        0                   0.000000   \n",
       "\n",
       "   feature_710 * feature_846  feature_710 * feature_874  \\\n",
       "0                   0.025974                   0.019481   \n",
       "1                   0.000000                   0.000000   \n",
       "2                   0.095238                   0.000000   \n",
       "3                   0.184615                   0.061538   \n",
       "4                   0.000000                   0.000000   \n",
       "\n",
       "   feature_710 * feature_888  \\\n",
       "0                   0.064935   \n",
       "1                   0.615385   \n",
       "2                   0.142857   \n",
       "3                   0.430769   \n",
       "4                   0.000000   \n",
       "\n",
       "   feature_762 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                      201863.636364                 \n",
       "1                                           0.000000                 \n",
       "2                                       26920.634921                 \n",
       "3                                       21138.461538                 \n",
       "4                                       13927.690909                 \n",
       "\n",
       "   feature_762 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                         787.603819               \n",
       "3                                                NaN               \n",
       "4                                         206.202814               \n",
       "\n",
       "   feature_762 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                      377459.590909                 \n",
       "1                                           0.000000                 \n",
       "2                                      112508.936508                 \n",
       "3                                      153838.892308                 \n",
       "4                                       33149.618182                 \n",
       "\n",
       "   feature_762 * Name_nuniq2  feature_762 * Outstanding_Balance_UnSecured  \\\n",
       "0                  10.636364                                 15360.909091   \n",
       "1                   0.000000                                     0.000000   \n",
       "2                  14.095238                                 47435.619048   \n",
       "3                   6.323077                                 18000.276923   \n",
       "4                  11.509091                                  4024.036364   \n",
       "\n",
       "   feature_762 * Payment_Rating34_mean_9999  \\\n",
       "0                                  0.016529   \n",
       "1                                  0.000000   \n",
       "2                                  0.000248   \n",
       "3                                  0.021231   \n",
       "4                                  0.004545   \n",
       "\n",
       "   feature_762 * Rate_of_Interest36_min_9999  feature_762 * Tel_nuniq2  \\\n",
       "0                                   2.045455                  3.909091   \n",
       "1                                        NaN                  0.000000   \n",
       "2                                   0.107143                  3.126984   \n",
       "3                                   0.369231                  6.692308   \n",
       "4                                   0.981818                  1.527273   \n",
       "\n",
       "   feature_762 * feature_8  \\\n",
       "0                19.227273   \n",
       "1                 0.000000   \n",
       "2                 8.539683   \n",
       "3                84.923077   \n",
       "4                49.090909   \n",
       "\n",
       "   feature_778 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                       49619.040611               \n",
       "3                                                NaN               \n",
       "4                                         945.096231               \n",
       "\n",
       "   feature_778 * Payment_Rating34_mean_9999  feature_778 * Tel_nuniq2  \\\n",
       "0                                  0.242424                 57.333333   \n",
       "1                                  0.000000                 26.250000   \n",
       "2                                  0.015625                197.000000   \n",
       "3                                  0.318462                100.384615   \n",
       "4                                  0.020833                  7.000000   \n",
       "\n",
       "   feature_778 * feature_781  feature_778 * feature_888  \\\n",
       "0                   0.358974                   0.043290   \n",
       "1                   0.538462                   0.089744   \n",
       "2                   0.750000                   0.047619   \n",
       "3                   0.240803                   0.074556   \n",
       "4                   0.125000                   0.027273   \n",
       "\n",
       "   feature_779 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                          4613395.0                 \n",
       "1                                           240100.0                 \n",
       "2                                          4252837.8                 \n",
       "3                                          1874911.5                 \n",
       "4                                           121548.6                 \n",
       "\n",
       "   feature_779 * Name_nuniq2  feature_779 * feature_888  \\\n",
       "0                 130.000000                   0.036075   \n",
       "1                 140.777778                   0.079772   \n",
       "2                 532.800000                   0.028571   \n",
       "3                  77.062500                   0.060577   \n",
       "4                  42.200000                   0.021818   \n",
       "\n",
       "   feature_781 * Name_nuniq2  feature_781 * Rate_of_Interest36_min_9999  \\\n",
       "0                 126.000000                                  24.230769   \n",
       "1                 111.384615                                        NaN   \n",
       "2                 666.000000                                   5.062500   \n",
       "3                  47.652174                                   2.782609   \n",
       "4                 105.500000                                   9.000000   \n",
       "\n",
       "   feature_781 * Tel_nuniq2  \\\n",
       "0                 46.307692   \n",
       "1                 18.461538   \n",
       "2                147.750000   \n",
       "3                 50.434783   \n",
       "4                 14.000000   \n",
       "\n",
       "   feature_8 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                       1.878543e+09               \n",
       "1                                       3.673631e+08               \n",
       "2                                       9.124480e+08               \n",
       "3                                       8.427200e+08               \n",
       "4                                       2.298069e+08               \n",
       "\n",
       "   feature_8 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN             \n",
       "1                                                NaN             \n",
       "2                                       2.669504e+07             \n",
       "3                                                NaN             \n",
       "4                                       3.402346e+06             \n",
       "\n",
       "   feature_8 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                       3.512639e+09               \n",
       "1                                       6.275871e+08               \n",
       "2                                       3.813378e+09               \n",
       "3                                       6.133044e+09               \n",
       "4                                       5.469687e+08               \n",
       "\n",
       "   feature_8 * Name_nuniq2  feature_8 * Outstanding_Balance_UnSecured  \\\n",
       "0                    98982                                  142948620   \n",
       "1                   367973                                          0   \n",
       "2                   477744                                 1607782872   \n",
       "3                   252080                                  717611040   \n",
       "4                   189900                                   66396600   \n",
       "\n",
       "   feature_8 * Payment_Rating34_mean_9999  \\\n",
       "0                              153.818182   \n",
       "1                                0.000000   \n",
       "2                                8.406250   \n",
       "3                              846.400000   \n",
       "4                               75.000000   \n",
       "\n",
       "   feature_8 * Rate_of_Interest36_min_9999  feature_8 * Tel_nuniq2  \\\n",
       "0                                  19035.0                   36378   \n",
       "1                                      NaN                   60990   \n",
       "2                                   3631.5                  105986   \n",
       "3                                  14720.0                  266800   \n",
       "4                                  16200.0                   25200   \n",
       "\n",
       "   feature_8 * feature_804  feature_8 * feature_846  feature_8 * feature_874  \\\n",
       "0                10.987013                10.987013                 8.240260   \n",
       "1                52.128205                 0.000000                 0.000000   \n",
       "2                 0.000000                17.079365                 0.000000   \n",
       "3                 0.000000                84.923077                28.307692   \n",
       "4                 0.000000                65.454545                16.363636   \n",
       "\n",
       "   feature_8 * feature_888  \\\n",
       "0                27.467532   \n",
       "1               208.512821   \n",
       "2                25.619048   \n",
       "3               198.153846   \n",
       "4                98.181818   \n",
       "\n",
       "   feature_804 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                      115350.649351                 \n",
       "1                                        4633.333333                 \n",
       "2                                           0.000000                 \n",
       "3                                           0.000000                 \n",
       "4                                           0.000000                 \n",
       "\n",
       "   feature_804 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                                0.0               \n",
       "3                                                NaN               \n",
       "4                                                0.0               \n",
       "\n",
       "   feature_804 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                      215691.194805                 \n",
       "1                                        7915.384615                 \n",
       "2                                           0.000000                 \n",
       "3                                           0.000000                 \n",
       "4                                           0.000000                 \n",
       "\n",
       "   feature_804 * Name_nuniq2  feature_804 * Outstanding_Balance_UnSecured  \\\n",
       "0                   6.077922                                  8777.662338   \n",
       "1                   4.641026                                     0.000000   \n",
       "2                   0.000000                                     0.000000   \n",
       "3                   0.000000                                     0.000000   \n",
       "4                   0.000000                                     0.000000   \n",
       "\n",
       "   feature_804 * Rate_of_Interest36_min_9999  feature_804 * Tel_nuniq2  \\\n",
       "0                                   1.168831                  2.233766   \n",
       "1                                        NaN                  0.769231   \n",
       "2                                   0.000000                  0.000000   \n",
       "3                                   0.000000                  0.000000   \n",
       "4                                   0.000000                  0.000000   \n",
       "\n",
       "   feature_846 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                      115350.649351                 \n",
       "1                                           0.000000                 \n",
       "2                                       53841.269841                 \n",
       "3                                       21138.461538                 \n",
       "4                                       18570.254545                 \n",
       "\n",
       "   feature_846 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                        1575.207638               \n",
       "3                                                NaN               \n",
       "4                                         274.937085               \n",
       "\n",
       "   feature_846 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                      215691.194805                 \n",
       "1                                           0.000000                 \n",
       "2                                      225017.873016                 \n",
       "3                                      153838.892308                 \n",
       "4                                       44199.490909                 \n",
       "\n",
       "   feature_846 * Name_nuniq2  feature_846 * Outstanding_Balance_UnSecured  \\\n",
       "0                   6.077922                                  8777.662338   \n",
       "1                   0.000000                                     0.000000   \n",
       "2                  28.190476                                 94871.238095   \n",
       "3                   6.323077                                 18000.276923   \n",
       "4                  15.345455                                  5365.381818   \n",
       "\n",
       "   feature_846 * Payment_Rating34_mean_9999  \\\n",
       "0                                  0.009445   \n",
       "1                                  0.000000   \n",
       "2                                  0.000496   \n",
       "3                                  0.021231   \n",
       "4                                  0.006061   \n",
       "\n",
       "   feature_846 * Rate_of_Interest36_min_9999  feature_846 * Tel_nuniq2  \\\n",
       "0                                   1.168831                  2.233766   \n",
       "1                                        NaN                  0.000000   \n",
       "2                                   0.214286                  6.253968   \n",
       "3                                   0.369231                  6.692308   \n",
       "4                                   1.309091                  2.036364   \n",
       "\n",
       "   feature_874 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                       86512.987013                 \n",
       "1                                           0.000000                 \n",
       "2                                           0.000000                 \n",
       "3                                        7046.153846                 \n",
       "4                                        4642.563636                 \n",
       "\n",
       "   feature_874 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                           0.000000               \n",
       "3                                                NaN               \n",
       "4                                          68.734271               \n",
       "\n",
       "   feature_874 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                      161768.396104                 \n",
       "1                                           0.000000                 \n",
       "2                                           0.000000                 \n",
       "3                                       51279.630769                 \n",
       "4                                       11049.872727                 \n",
       "\n",
       "   feature_874 * Name_nuniq2  feature_874 * Outstanding_Balance_UnSecured  \\\n",
       "0                   4.558442                                  6583.246753   \n",
       "1                   0.000000                                     0.000000   \n",
       "2                   0.000000                                     0.000000   \n",
       "3                   2.107692                                  6000.092308   \n",
       "4                   3.836364                                  1341.345455   \n",
       "\n",
       "   feature_874 * Rate_of_Interest36_min_9999  feature_874 * Tel_nuniq2  \\\n",
       "0                                   0.876623                  1.675325   \n",
       "1                                        NaN                  0.000000   \n",
       "2                                   0.000000                  0.000000   \n",
       "3                                   0.123077                  2.230769   \n",
       "4                                   0.327273                  0.509091   \n",
       "\n",
       "   feature_888 * Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                      288376.623377                 \n",
       "1                                       18533.333333                 \n",
       "2                                       80761.904762                 \n",
       "3                                       49323.076923                 \n",
       "4                                       27855.381818                 \n",
       "\n",
       "   feature_888 * Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                                NaN               \n",
       "1                                                NaN               \n",
       "2                                        2362.811458               \n",
       "3                                                NaN               \n",
       "4                                         412.405628               \n",
       "\n",
       "   feature_888 * Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                      539227.987013                 \n",
       "1                                       31661.538462                 \n",
       "2                                      337526.809524                 \n",
       "3                                      358957.415385                 \n",
       "4                                       66299.236364                 \n",
       "\n",
       "   feature_888 * Name_nuniq2  feature_888 * Payment_Rating34_mean_9999  \\\n",
       "0                  15.194805                                  0.023613   \n",
       "1                  18.564103                                  0.000000   \n",
       "2                  42.285714                                  0.000744   \n",
       "3                  14.753846                                  0.049538   \n",
       "4                  23.018182                                  0.009091   \n",
       "\n",
       "   feature_888 * Rate_of_Interest36_min_9999  feature_888 * Tel_nuniq2  \\\n",
       "0                                   2.922078                  5.584416   \n",
       "1                                        NaN                  3.076923   \n",
       "2                                   0.321429                  9.380952   \n",
       "3                                   0.861538                 15.615385   \n",
       "4                                   1.963636                  3.054545   \n",
       "\n",
       "   Account_Type32_mode_360vcount - Payment_Rating34_mean_9999  \\\n",
       "0                                          -0.358404            \n",
       "1                                           0.060880            \n",
       "2                                           0.704232            \n",
       "3                                          -0.399120            \n",
       "4                                           0.636524            \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_407  \\\n",
       "0                                     0.005232   \n",
       "1                                          NaN   \n",
       "2                                     0.719857   \n",
       "3                                    -0.081977   \n",
       "4                                          NaN   \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_409  \\\n",
       "0                                     0.005232   \n",
       "1                                          NaN   \n",
       "2                                     0.519857   \n",
       "3                                    -0.189120   \n",
       "4                                     0.719857   \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_410  \\\n",
       "0                                     0.005232   \n",
       "1                                          NaN   \n",
       "2                                     0.005572   \n",
       "3                                    -0.239120   \n",
       "4                                     0.719857   \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_643  \\\n",
       "0                                    -0.449314   \n",
       "1                                    -0.105787   \n",
       "2                                     0.386524   \n",
       "3                                    -0.235416   \n",
       "4                                     0.719857   \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_700  \\\n",
       "0                                    -0.524180   \n",
       "1                                    -0.581977   \n",
       "2                                    -0.113476   \n",
       "3                                    -0.423969   \n",
       "4                                     0.005572   \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_701  \\\n",
       "0                                     0.005232   \n",
       "1                                    -0.439120   \n",
       "2                                     0.053191   \n",
       "3                                    -0.189120   \n",
       "4                                          NaN   \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_779  \\\n",
       "0                                    -0.550324   \n",
       "1                                    -0.716898   \n",
       "2                                     0.119857   \n",
       "3                                    -0.501620   \n",
       "4                                     0.519857   \n",
       "\n",
       "   Account_Type32_mode_360vcount - feature_781  \\\n",
       "0                                    -0.533230   \n",
       "1                                    -0.554505   \n",
       "2                                    -0.030143   \n",
       "3                                    -0.286946   \n",
       "4                                     0.219857   \n",
       "\n",
       "   Amount_Past_Due35_max_360 - Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                         -4441000.0                               \n",
       "1                                          -180700.0                               \n",
       "2                                         -1694955.0                               \n",
       "3                                          -458000.0                               \n",
       "4                                          -255341.0                               \n",
       "\n",
       "   Amount_Past_Due35_mean_9999 - Date_of_Last_Payment40_max_360  \\\n",
       "0                                        4623.916667              \n",
       "1                                        -153.000000              \n",
       "2                                        -264.278689              \n",
       "3                                        2810.679245              \n",
       "4                                         103.791667              \n",
       "\n",
       "   Amount_Past_Due35_mean_9999 - feature_804  \\\n",
       "0                                4644.890693   \n",
       "1                                  -0.025641   \n",
       "2                                  31.721311   \n",
       "3                                2886.679245   \n",
       "4                                 287.791667   \n",
       "\n",
       "   Birth_nuniq - Date_of_Request35_mode_90  Birth_nuniq - Email_nuniq  \\\n",
       "0                               -65.500875                  -5.497876   \n",
       "1                                -9.501749                   1.999000   \n",
       "2                                22.491127                   5.097206   \n",
       "3                                14.993336                  19.326891   \n",
       "4                                 8.329224                   3.331023   \n",
       "\n",
       "   Birth_nuniq - Email_nuniq2  Birth_nuniq - Rate_of_Interest36_min_9999  \\\n",
       "0                  -66.500875                                 -40.500875   \n",
       "1                  -40.501749                                        NaN   \n",
       "2                  -88.508873                                  29.741127   \n",
       "3                  -44.006664                                  12.993336   \n",
       "4                  -98.670776                                  -4.670776   \n",
       "\n",
       "   Birth_nuniq - Tel_nuniq2  Birth_nuniq - feature_254  \\\n",
       "0                -81.500875                  -0.500875   \n",
       "1                -25.501749                   4.498251   \n",
       "2               -160.508873                  35.491127   \n",
       "3               -124.006664                  17.993336   \n",
       "4                -14.670776                  11.329224   \n",
       "\n",
       "   Birth_nuniq - feature_778  BureauScore - Duecount53_sum_9999  \\\n",
       "0                   3.832459                              297.0   \n",
       "1                   3.623251                              748.0   \n",
       "2                  35.491127                               61.0   \n",
       "3                  20.301028                             -109.0   \n",
       "4                  13.079224                              632.0   \n",
       "\n",
       "   BureauScore - Duesum51_max_360  \\\n",
       "0                           563.0   \n",
       "1                           772.0   \n",
       "2                           656.0   \n",
       "3                           119.0   \n",
       "4                           738.0   \n",
       "\n",
       "   BureauScore - Duration_Of_Agreement41_sum_9999  BureauScore - Name_nuniq2  \\\n",
       "0                                           287.0                        329   \n",
       "1                                           705.0                        591   \n",
       "2                                          -689.0                       -178   \n",
       "3                                           219.0                        341   \n",
       "4                                           485.0                        527   \n",
       "\n",
       "   BureauScore - feature_2  \\\n",
       "0                    -2937   \n",
       "1                    -2728   \n",
       "2                    -2790   \n",
       "3                    -3022   \n",
       "4                    -2762   \n",
       "\n",
       "   CAPSLast180Days_nocrt_por - Payment_Rating34_mean_9999  \\\n",
       "0                                           2.636364        \n",
       "1                                           0.000000        \n",
       "2                                           0.620739        \n",
       "3                                          -0.460000        \n",
       "4                                          -0.083333        \n",
       "\n",
       "   CAPSLast180Days_nocrt_por - feature_4  \\\n",
       "0                              -1.000000   \n",
       "1                              -4.000000   \n",
       "2                              -4.363636   \n",
       "3                              -5.000000   \n",
       "4                              -1.000000   \n",
       "\n",
       "   CAPSLast180Days_nocrt_por - feature_638  \\\n",
       "0                                 2.000000   \n",
       "1                                -1.000000   \n",
       "2                                -0.363636   \n",
       "3                                -3.000000   \n",
       "4                                 0.000000   \n",
       "\n",
       "   CAPSLast180Days_nocrt_por - feature_9  \\\n",
       "0                              -8.000000   \n",
       "1                              -9.000000   \n",
       "2                             -10.363636   \n",
       "3                             -11.000000   \n",
       "4                             -10.000000   \n",
       "\n",
       "   Current_Balance35_sum_9999 - Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                          1101401.0                                \n",
       "1                                           -60449.0                                \n",
       "2                                          2952986.0                                \n",
       "3                                            14181.0                                \n",
       "4                                           166370.0                                \n",
       "\n",
       "   Current_Balance35_sum_9999 - Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                         -2761710.0                                \n",
       "1                                          -188449.0                                \n",
       "2                                         -2439077.0                                \n",
       "3                                         -2860995.0                                \n",
       "4                                          -186032.0                                \n",
       "\n",
       "   Current_Balance35_sum_9999 - feature_762  \\\n",
       "0                              5.542401e+06   \n",
       "1                              1.202510e+05   \n",
       "2                              4.648986e+06   \n",
       "3                              4.721810e+05   \n",
       "4                              4.217109e+05   \n",
       "\n",
       "   Date_of_Last_Payment40_max_360 - Date_of_Request35_mode_9999  \\\n",
       "0                                              -49.0              \n",
       "1                                              139.0              \n",
       "2                                             -641.0              \n",
       "3                                               70.0              \n",
       "4                                              179.0              \n",
       "\n",
       "   Date_of_Last_Payment40_mean_360 - feature_8  \\\n",
       "0                                  -402.000000   \n",
       "1                                 -1880.000000   \n",
       "2                                  -418.473684   \n",
       "3                                 -1779.333333   \n",
       "4                                  -802.222222   \n",
       "\n",
       "   Date_of_Request35_mode_90 - Email_nuniq  \\\n",
       "0                                60.002999   \n",
       "1                                11.500750   \n",
       "2                               -17.393921   \n",
       "3                                 4.333555   \n",
       "4                                -4.998200   \n",
       "\n",
       "   Date_of_Request35_mode_90 - Email_nuniq2  \\\n",
       "0                                      -1.0   \n",
       "1                                     -31.0   \n",
       "2                                    -111.0   \n",
       "3                                     -59.0   \n",
       "4                                    -107.0   \n",
       "\n",
       "   Date_of_Request35_mode_90 - Name_nuniq2  \\\n",
       "0                                   -164.0   \n",
       "1                                   -167.0   \n",
       "2                                   -874.0   \n",
       "3                                   -131.0   \n",
       "4                                   -206.0   \n",
       "\n",
       "   Date_of_Request35_mode_90 - Rate_of_Interest36_min_9999  \\\n",
       "0                                              25.00         \n",
       "1                                                NaN         \n",
       "2                                               7.25         \n",
       "3                                              -2.00         \n",
       "4                                             -13.00         \n",
       "\n",
       "   Date_of_Request35_mode_90 - Tel_nuniq2  \\\n",
       "0                                   -16.0   \n",
       "1                                   -16.0   \n",
       "2                                  -183.0   \n",
       "3                                  -139.0   \n",
       "4                                   -23.0   \n",
       "\n",
       "   Date_of_Request35_mode_9999 - Duecount53_sum_9999  \\\n",
       "0                                             -196.0   \n",
       "1                                              -10.0   \n",
       "2                                              288.0   \n",
       "3                                             -581.0   \n",
       "4                                             -101.0   \n",
       "\n",
       "   Date_of_Request35_mode_9999 - Duesum51_max_360  \\\n",
       "0                                            70.0   \n",
       "1                                            14.0   \n",
       "2                                           883.0   \n",
       "3                                          -353.0   \n",
       "4                                             5.0   \n",
       "\n",
       "   Date_of_Request35_mode_9999 - Duration_Of_Agreement41_sum_9999  \\\n",
       "0                                             -206.0                \n",
       "1                                              -53.0                \n",
       "2                                             -462.0                \n",
       "3                                             -253.0                \n",
       "4                                             -248.0                \n",
       "\n",
       "   Date_of_Request35_mode_9999 - Email_nuniq  \\\n",
       "0                                  60.002999   \n",
       "1                                  11.500750   \n",
       "2                                 905.606079   \n",
       "3                                   4.333555   \n",
       "4                                  -4.998200   \n",
       "\n",
       "   Date_of_Request35_mode_9999 - Name_nuniq2  \\\n",
       "0                                     -164.0   \n",
       "1                                     -167.0   \n",
       "2                                       49.0   \n",
       "3                                     -131.0   \n",
       "4                                     -206.0   \n",
       "\n",
       "   Date_of_Request35_mode_9999 - feature_322  \\\n",
       "0                                       38.0   \n",
       "1                                     1013.0   \n",
       "2                                     1936.0   \n",
       "3                                     1005.0   \n",
       "4                                     1004.0   \n",
       "\n",
       "   Date_of_Request35_mode_9999 - feature_329  \\\n",
       "0                                       24.0   \n",
       "1                                     1013.0   \n",
       "2                                      937.0   \n",
       "3                                        2.0   \n",
       "4                                       -2.0   \n",
       "\n",
       "   Duecount53_sum_9999 - Duesum51_max_360  \\\n",
       "0                                   266.0   \n",
       "1                                    24.0   \n",
       "2                                   595.0   \n",
       "3                                   228.0   \n",
       "4                                   106.0   \n",
       "\n",
       "   Duecount53_sum_9999 - Duration_Of_Agreement41_sum_9999  \\\n",
       "0                                              -10.0        \n",
       "1                                              -43.0        \n",
       "2                                             -750.0        \n",
       "3                                              328.0        \n",
       "4                                             -147.0        \n",
       "\n",
       "   Duecount53_sum_9999 - Name_nuniq2  Duecount53_sum_9999 - feature_2  \\\n",
       "0                               32.0                          -3234.0   \n",
       "1                             -157.0                          -3476.0   \n",
       "2                             -239.0                          -2851.0   \n",
       "3                              450.0                          -2913.0   \n",
       "4                             -105.0                          -3394.0   \n",
       "\n",
       "   Duesum51_max_360 - Duration_Of_Agreement41_sum_9999  \\\n",
       "0                                             -276.0     \n",
       "1                                              -67.0     \n",
       "2                                            -1345.0     \n",
       "3                                              100.0     \n",
       "4                                             -253.0     \n",
       "\n",
       "   Duesum51_max_360 - Name_nuniq2  Duesum51_max_360 - feature_2  \\\n",
       "0                          -234.0                       -3500.0   \n",
       "1                          -181.0                       -3500.0   \n",
       "2                          -834.0                       -3446.0   \n",
       "3                           222.0                       -3141.0   \n",
       "4                          -211.0                       -3500.0   \n",
       "\n",
       "   Duesum51_max_360 - feature_322  Duesum51_max_360 - feature_329  \\\n",
       "0                           -32.0                           -46.0   \n",
       "1                           999.0                           999.0   \n",
       "2                          1053.0                            54.0   \n",
       "3                          1358.0                           355.0   \n",
       "4                           999.0                            -7.0   \n",
       "\n",
       "   Duration_Of_Agreement41_sum_9999 - Name_nuniq2  \\\n",
       "0                                            42.0   \n",
       "1                                          -114.0   \n",
       "2                                           511.0   \n",
       "3                                           122.0   \n",
       "4                                            42.0   \n",
       "\n",
       "   Duration_Of_Agreement41_sum_9999 - feature_2  \\\n",
       "0                                       -3224.0   \n",
       "1                                       -3433.0   \n",
       "2                                       -2101.0   \n",
       "3                                       -3241.0   \n",
       "4                                       -3247.0   \n",
       "\n",
       "   Duration_Of_Agreement41_sum_9999 - feature_322  \\\n",
       "0                                           244.0   \n",
       "1                                          1066.0   \n",
       "2                                          2398.0   \n",
       "3                                          1258.0   \n",
       "4                                          1252.0   \n",
       "\n",
       "   Duration_Of_Agreement41_sum_9999 - feature_329  \\\n",
       "0                                           230.0   \n",
       "1                                          1066.0   \n",
       "2                                          1399.0   \n",
       "3                                           255.0   \n",
       "4                                           246.0   \n",
       "\n",
       "   Email_nuniq - Rate_of_Interest36_min_9999  Email_nuniq - Tel_nuniq2  \\\n",
       "0                                 -35.002999                -76.002999   \n",
       "1                                        NaN                -27.500750   \n",
       "2                                  24.643921               -165.606079   \n",
       "3                                  -6.333555               -143.333555   \n",
       "4                                  -8.001800                -18.001800   \n",
       "\n",
       "   Email_nuniq2 - Name_nuniq2  Email_nuniq2 - Rate_of_Interest36_min_9999  \\\n",
       "0                        -163                                       26.00   \n",
       "1                        -136                                         NaN   \n",
       "2                        -763                                      118.25   \n",
       "3                         -72                                       57.00   \n",
       "4                         -99                                       94.00   \n",
       "\n",
       "   Email_nuniq2 - Tel_nuniq2  Email_nuniq2 - feature_2  \\\n",
       "0                        -15                     -3429   \n",
       "1                         15                     -3455   \n",
       "2                        -72                     -3375   \n",
       "3                        -80                     -3435   \n",
       "4                         84                     -3388   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_max_9999 - Outstanding_Balance_UnSecured  \\\n",
       "0                                          4103060.0                                   \n",
       "1                                           180700.0                                   \n",
       "2                                         -1292444.0                                   \n",
       "3                                            67994.0                                   \n",
       "4                                           181567.0                                   \n",
       "\n",
       "   Rate_of_Interest36_min_9999 - Tel_nuniq2  feature_2 - Name_nuniq2  \\\n",
       "0                                    -41.00                     3266   \n",
       "1                                       NaN                     3319   \n",
       "2                                   -190.25                     2612   \n",
       "3                                   -137.00                     3363   \n",
       "4                                    -10.00                     3289   \n",
       "\n",
       "   feature_254 - feature_638  feature_254 - feature_710  \\\n",
       "0                          4                          4   \n",
       "1                         -1                         -6   \n",
       "2                          0                         -2   \n",
       "3                          0                         -1   \n",
       "4                          2                          2   \n",
       "\n",
       "   feature_322 - feature_329  feature_329 - feature_409  \\\n",
       "0                        -14                      46.00   \n",
       "1                          0                        NaN   \n",
       "2                       -999                      -0.20   \n",
       "3                      -1003                       3.75   \n",
       "4                      -1006                       7.00   \n",
       "\n",
       "   feature_4 - Payment_Rating34_mean_9999  feature_4 - feature_638  \\\n",
       "0                                3.636364                        3   \n",
       "1                                4.000000                        3   \n",
       "2                                4.984375                        4   \n",
       "3                                4.540000                        2   \n",
       "4                                0.916667                        1   \n",
       "\n",
       "   feature_4 - feature_9  feature_407 - feature_409  \\\n",
       "0                     -7                   0.000000   \n",
       "1                     -5                        NaN   \n",
       "2                     -6                  -0.200000   \n",
       "3                     -6                  -0.107143   \n",
       "4                     -9                        NaN   \n",
       "\n",
       "   feature_407 - feature_410  feature_407 - feature_638  \\\n",
       "0                   0.000000                  -1.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                  -0.714286                  -1.000000   \n",
       "3                  -0.157143                  -2.857143   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   feature_407 - feature_643  feature_407 - feature_700  \\\n",
       "0                  -0.454545                  -0.529412   \n",
       "1                        NaN                        NaN   \n",
       "2                  -0.333333                  -0.833333   \n",
       "3                  -0.153439                  -0.341991   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   feature_407 - feature_701  feature_407 - feature_702  \\\n",
       "0                   0.000000                  -0.590909   \n",
       "1                        NaN                        NaN   \n",
       "2                  -0.666667                  -0.923077   \n",
       "3                  -0.107143                  -0.533613   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   feature_407 - feature_778  feature_407 - feature_779  \\\n",
       "0                  -0.666667                  -0.555556   \n",
       "1                        NaN                        NaN   \n",
       "2                  -1.000000                  -0.600000   \n",
       "3                  -0.549451                  -0.419643   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   feature_407 - feature_781  feature_409 - feature_410  \\\n",
       "0                  -0.538462                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                  -0.750000                  -0.514286   \n",
       "3                  -0.204969                  -0.050000   \n",
       "4                        NaN                   0.000000   \n",
       "\n",
       "   feature_409 - feature_643  feature_409 - feature_701  \\\n",
       "0                  -0.454545                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                  -0.133333                  -0.466667   \n",
       "3                  -0.046296                   0.000000   \n",
       "4                   0.000000                        NaN   \n",
       "\n",
       "   feature_409 - feature_702  feature_409 - feature_778  \\\n",
       "0                  -0.590909                  -0.666667   \n",
       "1                        NaN                        NaN   \n",
       "2                  -0.723077                  -0.800000   \n",
       "3                  -0.426471                  -0.442308   \n",
       "4                  -0.727273                  -0.250000   \n",
       "\n",
       "   feature_409 - feature_781  feature_410 - Payment_Rating34_mean_9999  \\\n",
       "0                  -0.538462                                 -0.363636   \n",
       "1                        NaN                                       NaN   \n",
       "2                  -0.550000                                  0.698661   \n",
       "3                  -0.097826                                 -0.160000   \n",
       "4                  -0.500000                                 -0.083333   \n",
       "\n",
       "   feature_410 - feature_643  feature_410 - feature_701  \\\n",
       "0                  -0.454545                   0.000000   \n",
       "1                        NaN                        NaN   \n",
       "2                   0.380952                   0.047619   \n",
       "3                   0.003704                   0.050000   \n",
       "4                   0.000000                        NaN   \n",
       "\n",
       "   feature_410 - feature_702  feature_410 - feature_778  \\\n",
       "0                  -0.590909                  -0.666667   \n",
       "1                        NaN                        NaN   \n",
       "2                  -0.208791                  -0.285714   \n",
       "3                  -0.376471                  -0.392308   \n",
       "4                  -0.727273                  -0.250000   \n",
       "\n",
       "   feature_410 - feature_9  feature_638 - feature_9  \\\n",
       "0               -11.000000                      -10   \n",
       "1                      NaN                       -8   \n",
       "2               -10.285714                      -10   \n",
       "3               -10.700000                       -8   \n",
       "4               -10.000000                      -10   \n",
       "\n",
       "   feature_643 - feature_702  feature_643 - feature_778  \\\n",
       "0                  -0.136364                  -0.212121   \n",
       "1                  -0.555556                  -0.708333   \n",
       "2                  -0.589744                  -0.666667   \n",
       "3                  -0.380174                  -0.396011   \n",
       "4                  -0.727273                  -0.250000   \n",
       "\n",
       "   feature_643 - feature_779  feature_643 - feature_781  \\\n",
       "0                  -0.101010                  -0.083916   \n",
       "1                  -0.611111                  -0.448718   \n",
       "2                  -0.266667                  -0.416667   \n",
       "3                  -0.266204                  -0.051530   \n",
       "4                  -0.200000                  -0.500000   \n",
       "\n",
       "   feature_643 - feature_804  feature_669 - feature_762  \\\n",
       "0                   0.428571                  -0.000220   \n",
       "1                   0.141026                   0.019763   \n",
       "2                   0.333333                   0.006459   \n",
       "3                   0.296296                  -0.017456   \n",
       "4                   0.000000                  -0.025391   \n",
       "\n",
       "   feature_700 - feature_701  feature_700 - feature_702  \\\n",
       "0                   0.529412                  -0.061497   \n",
       "1                   0.142857                  -0.079365   \n",
       "2                   0.166667                  -0.089744   \n",
       "3                   0.234848                  -0.191622   \n",
       "4                        NaN                  -0.012987   \n",
       "\n",
       "   feature_700 - feature_778  feature_700 - feature_781  \\\n",
       "0                  -0.137255                  -0.009050   \n",
       "1                  -0.232143                   0.027473   \n",
       "2                  -0.166667                   0.083333   \n",
       "3                  -0.207459                   0.137022   \n",
       "4                   0.464286                   0.214286   \n",
       "\n",
       "   feature_701 - feature_702  feature_701 - feature_778  \\\n",
       "0                  -0.590909                  -0.666667   \n",
       "1                  -0.222222                  -0.375000   \n",
       "2                  -0.256410                  -0.333333   \n",
       "3                  -0.426471                  -0.442308   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   feature_701 - feature_781  feature_702 - feature_762  \\\n",
       "0                  -0.538462                   0.545455   \n",
       "1                  -0.115385                   0.722222   \n",
       "2                  -0.083333                   0.907204   \n",
       "3                  -0.097826                   0.630317   \n",
       "4                        NaN                   0.672727   \n",
       "\n",
       "   feature_702 - feature_779  feature_702 - feature_781  \\\n",
       "0                   0.035354                   0.052448   \n",
       "1                  -0.055556                   0.106838   \n",
       "2                   0.323077                   0.173077   \n",
       "3                   0.113971                   0.328645   \n",
       "4                   0.527273                   0.227273   \n",
       "\n",
       "   feature_702 - feature_888  feature_710 - feature_9  \\\n",
       "0                   0.525974                      -10   \n",
       "1                   0.619658                       -3   \n",
       "2                   0.875458                       -8   \n",
       "3                   0.568778                       -7   \n",
       "4                   0.618182                      -10   \n",
       "\n",
       "   feature_762 - Rate_of_Interest36_min_9999  feature_762 - feature_804  \\\n",
       "0                                 -44.954545                   0.019481   \n",
       "1                                        NaN                  -0.025641   \n",
       "2                                  -6.734127                   0.015873   \n",
       "3                                  -7.953846                   0.046154   \n",
       "4                                 -17.945455                   0.054545   \n",
       "\n",
       "   feature_762 - feature_846  feature_762 - feature_874  \\\n",
       "0                   0.019481                   0.025974   \n",
       "1                   0.000000                   0.000000   \n",
       "2                  -0.015873                   0.015873   \n",
       "3                   0.000000                   0.030769   \n",
       "4                  -0.018182                   0.036364   \n",
       "\n",
       "   feature_762 - feature_888  feature_778 - feature_779  \\\n",
       "0                  -0.019481                   0.111111   \n",
       "1                  -0.102564                   0.097222   \n",
       "2                  -0.031746                   0.400000   \n",
       "3                  -0.061538                   0.129808   \n",
       "4                  -0.054545                   0.050000   \n",
       "\n",
       "   feature_778 - feature_781  feature_778 - feature_874  \\\n",
       "0                   0.128205                   0.647186   \n",
       "1                   0.259615                   0.875000   \n",
       "2                   0.250000                   1.000000   \n",
       "3                   0.344482                   0.676923   \n",
       "4                  -0.250000                   0.231818   \n",
       "\n",
       "   feature_779 - feature_781  feature_804 - feature_846  \\\n",
       "0                   0.017094                   0.000000   \n",
       "1                   0.162393                   0.025641   \n",
       "2                  -0.150000                  -0.031746   \n",
       "3                   0.214674                  -0.046154   \n",
       "4                  -0.300000                  -0.072727   \n",
       "\n",
       "   feature_804 - feature_888  feature_846 - feature_874  \\\n",
       "0                  -0.038961                   0.006494   \n",
       "1                  -0.076923                   0.000000   \n",
       "2                  -0.047619                   0.031746   \n",
       "3                  -0.107692                   0.030769   \n",
       "4                  -0.109091                   0.054545   \n",
       "\n",
       "   feature_846 - feature_888  \\\n",
       "0                  -0.038961   \n",
       "1                  -0.102564   \n",
       "2                  -0.015873   \n",
       "3                  -0.061538   \n",
       "4                  -0.036364   \n",
       "\n",
       "   feature_874 - Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                      -8.304111e+06                 \n",
       "1                                      -3.087000e+05                 \n",
       "2                                      -7.088063e+06                 \n",
       "3                                      -3.333176e+06                 \n",
       "4                                      -6.077430e+05                 \n",
       "\n",
       "   feature_874 - feature_888  feature_888 - feature_9  \\\n",
       "0                  -0.045455               -10.935065   \n",
       "1                  -0.102564                -8.897436   \n",
       "2                  -0.047619               -10.952381   \n",
       "3                  -0.092308               -10.892308   \n",
       "4                  -0.090909                -9.890909   \n",
       "\n",
       "   feature_9 - Payment_Rating34_mean_9999  \n",
       "0                               10.636364  \n",
       "1                                9.000000  \n",
       "2                               10.984375  \n",
       "3                               10.540000  \n",
       "4                                9.916667  \n",
       "\n",
       "[5 rows x 3631 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/top30_tofeaturetools.pkl ok\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%reload_ext autoreload\n",
    "import feas_ft\n",
    "import imp\n",
    "imp.reload(feas_ft)\n",
    "\n",
    "\n",
    "feas_ft.featuretools_topfeas(basedf_file='./data/filter_feas_df32n_old.pkl', importance_file='./data/feature_importance.pkl', catefeas=[],join_key='ID',final_file='./data/top30_tofeaturetools.pkl',topn=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757fc38b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11ea8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f88e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "188ee814",
   "metadata": {},
   "source": [
    "### 原特征+ 等频4分箱onehot+  lgb特征--》3DNN or tabnet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cc9b3932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>report_timestamp</th>\n",
       "      <th>BureauScore</th>\n",
       "      <th>BureauScoreConfidLevel</th>\n",
       "      <th>MissingRate</th>\n",
       "      <th>Current_Finance_Purpose</th>\n",
       "      <th>Current_Amount_Financed</th>\n",
       "      <th>Current_Gender_Code</th>\n",
       "      <th>First_Name1</th>\n",
       "      <th>Len_Name</th>\n",
       "      <th>Name_nuniq</th>\n",
       "      <th>Tel_nuniq</th>\n",
       "      <th>Email_nuniq</th>\n",
       "      <th>IncomeTaxPAN_5</th>\n",
       "      <th>Len_of_addrs</th>\n",
       "      <th>City_nuniq</th>\n",
       "      <th>PinCode3</th>\n",
       "      <th>Current_State</th>\n",
       "      <th>Current_City</th>\n",
       "      <th>CreditAccountActive</th>\n",
       "      <th>CreditAccountActivePor</th>\n",
       "      <th>Outstanding_Balance_UnSecured_Percentage</th>\n",
       "      <th>Outstanding_Balance_UnSecured</th>\n",
       "      <th>Diff_dateBirth</th>\n",
       "      <th>State_nuniq</th>\n",
       "      <th>Birth_nuniq</th>\n",
       "      <th>TotalCAPSLast90Days</th>\n",
       "      <th>TotalCAPSLast7Days</th>\n",
       "      <th>TotalCAPSLast30Days</th>\n",
       "      <th>TotalCAPSLast180Days</th>\n",
       "      <th>CAPSLast7Days</th>\n",
       "      <th>CAPSLast180Days</th>\n",
       "      <th>Pin_nuniq</th>\n",
       "      <th>Pan_nuniq</th>\n",
       "      <th>Ident_nuniq</th>\n",
       "      <th>Name_nuniq2</th>\n",
       "      <th>Tel_nuniq2</th>\n",
       "      <th>Email_nuniq2</th>\n",
       "      <th>Pan_nuniq2</th>\n",
       "      <th>Account_nuniq2</th>\n",
       "      <th>Ident_nuniq2</th>\n",
       "      <th>Gender_nuniq</th>\n",
       "      <th>Amount_Past_Due35_max_30</th>\n",
       "      <th>Amount_Past_Due35_mean_90</th>\n",
       "      <th>Amount_Past_Due35_max_90</th>\n",
       "      <th>Amount_Past_Due35_min_90</th>\n",
       "      <th>Amount_Past_Due35_std_90</th>\n",
       "      <th>Amount_Past_Due35_sum_360</th>\n",
       "      <th>Amount_Past_Due35_max_360</th>\n",
       "      <th>Amount_Past_Due35_min_360</th>\n",
       "      <th>Amount_Past_Due35_std_360</th>\n",
       "      <th>Amount_Past_Due35_mean_9999</th>\n",
       "      <th>Amount_Past_Due35_max_9999</th>\n",
       "      <th>Amount_Past_Due35_min_9999</th>\n",
       "      <th>Amount_Past_Due35_std_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>Terms_Duration34_std_30</th>\n",
       "      <th>Terms_Duration34_std_90</th>\n",
       "      <th>Terms_Duration34_sum_360</th>\n",
       "      <th>Terms_Duration34_max_360</th>\n",
       "      <th>Terms_Duration34_mean_9999</th>\n",
       "      <th>Terms_Duration34_std_9999</th>\n",
       "      <th>Payment_Rating34_sum_90</th>\n",
       "      <th>Payment_Rating34_mean_90</th>\n",
       "      <th>Payment_Rating34_min_90</th>\n",
       "      <th>Payment_Rating34_std_90</th>\n",
       "      <th>Payment_Rating34_sum_360</th>\n",
       "      <th>Payment_Rating34_mean_360</th>\n",
       "      <th>Payment_Rating34_max_360</th>\n",
       "      <th>Payment_Rating34_min_360</th>\n",
       "      <th>Payment_Rating34_std_360</th>\n",
       "      <th>Payment_Rating34_sum_9999</th>\n",
       "      <th>Payment_Rating34_mean_9999</th>\n",
       "      <th>Payment_Rating34_max_9999</th>\n",
       "      <th>Payment_Rating34_min_9999</th>\n",
       "      <th>Payment_Rating34_std_9999</th>\n",
       "      <th>Current_Balance35_sum_360</th>\n",
       "      <th>Current_Balance35_max_360</th>\n",
       "      <th>Current_Balance35_std_360</th>\n",
       "      <th>Current_Balance35_sum_9999</th>\n",
       "      <th>Current_Balance35_mean_9999</th>\n",
       "      <th>Settlement_Amount37_mean_360</th>\n",
       "      <th>Settlement_Amount37_std_360</th>\n",
       "      <th>Settlement_Amount37_mean_9999</th>\n",
       "      <th>Settlement_Amount37_max_9999</th>\n",
       "      <th>Settlement_Amount37_min_9999</th>\n",
       "      <th>Value_of_Collateral39_std_90</th>\n",
       "      <th>Value_of_Collateral39_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_360</th>\n",
       "      <th>Written_Off_Amt_Total41_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_max_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_min_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_std_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_std_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_max_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_9999</th>\n",
       "      <th>Rate_of_Interest36_sum_30</th>\n",
       "      <th>Rate_of_Interest36_max_30</th>\n",
       "      <th>Rate_of_Interest36_min_30</th>\n",
       "      <th>Rate_of_Interest36_std_30</th>\n",
       "      <th>Rate_of_Interest36_sum_90</th>\n",
       "      <th>Rate_of_Interest36_mean_90</th>\n",
       "      <th>Rate_of_Interest36_max_90</th>\n",
       "      <th>Rate_of_Interest36_min_90</th>\n",
       "      <th>Rate_of_Interest36_std_90</th>\n",
       "      <th>Rate_of_Interest36_sum_360</th>\n",
       "      <th>Rate_of_Interest36_sum_9999</th>\n",
       "      <th>Rate_of_Interest36_mean_9999</th>\n",
       "      <th>Rate_of_Interest36_max_9999</th>\n",
       "      <th>Rate_of_Interest36_min_9999</th>\n",
       "      <th>Rate_of_Interest36_std_9999</th>\n",
       "      <th>Repayment_Tenure36_std_30</th>\n",
       "      <th>Repayment_Tenure36_std_90</th>\n",
       "      <th>Repayment_Tenure36_mean_360</th>\n",
       "      <th>Repayment_Tenure36_min_360</th>\n",
       "      <th>Repayment_Tenure36_std_360</th>\n",
       "      <th>Repayment_Tenure36_sum_9999</th>\n",
       "      <th>Repayment_Tenure36_mean_9999</th>\n",
       "      <th>Repayment_Tenure36_max_9999</th>\n",
       "      <th>Repayment_Tenure36_min_9999</th>\n",
       "      <th>Repayment_Tenure36_std_9999</th>\n",
       "      <th>Income26_count_30</th>\n",
       "      <th>Income26_std_90</th>\n",
       "      <th>Income26_min_9999</th>\n",
       "      <th>Income26_std_9999</th>\n",
       "      <th>Open_Date29_max_30</th>\n",
       "      <th>Open_Date29_mean_30</th>\n",
       "      <th>Open_Date29_mode_30</th>\n",
       "      <th>Open_Date29_nuniq_30</th>\n",
       "      <th>Open_Date29_maxcount_30</th>\n",
       "      <th>Open_Date29_mode_90</th>\n",
       "      <th>Open_Date29_nuniq_90</th>\n",
       "      <th>Open_Date29_max_360</th>\n",
       "      <th>Open_Date29_mode_360</th>\n",
       "      <th>Open_Date29_maxcount_360</th>\n",
       "      <th>Open_Date29_max_9999</th>\n",
       "      <th>Open_Date29_mean_9999</th>\n",
       "      <th>Open_Date29_mode_9999</th>\n",
       "      <th>Open_Date29_maxcount_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_30</th>\n",
       "      <th>Portfolio_Type34_nuniq_90</th>\n",
       "      <th>Portfolio_Type34_nuniq_360</th>\n",
       "      <th>Portfolio_Type34_mode_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_9999</th>\n",
       "      <th>Account_Type32_mode_30</th>\n",
       "      <th>Account_Type32_nuniq_30</th>\n",
       "      <th>Account_Type32_mode_90</th>\n",
       "      <th>Account_Type32_nuniq_90</th>\n",
       "      <th>Account_Type32_mode_360</th>\n",
       "      <th>Account_Type32_nuniq_360</th>\n",
       "      <th>Account_Type32_mode_9999</th>\n",
       "      <th>Account_Type32_nuniq_9999</th>\n",
       "      <th>Occupation_Code35_nuniq_30</th>\n",
       "      <th>Occupation_Code35_nuniq_90</th>\n",
       "      <th>Occupation_Code35_nuniq_360</th>\n",
       "      <th>CurrencyCode32_mode_360</th>\n",
       "      <th>CurrencyCode32_mode_9999</th>\n",
       "      <th>AccountHoldertypeCode41_mode_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_360</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_9999</th>\n",
       "      <th>Payment_History_Profile43_mode_30</th>\n",
       "      <th>Payment_History_Profile43_mode_90</th>\n",
       "      <th>Payment_History_Profile43_nuniq_90</th>\n",
       "      <th>Payment_History_Profile43_mode_360</th>\n",
       "      <th>Payment_History_Profile43_nuniq_360</th>\n",
       "      <th>Payment_History_Profile43_mode_9999</th>\n",
       "      <th>Payment_History_Profile43_nuniq_9999</th>\n",
       "      <th>Date_Closed31_mode_30</th>\n",
       "      <th>Date_Closed31_nuniq_30</th>\n",
       "      <th>Date_Closed31_maxcount_30</th>\n",
       "      <th>Date_Closed31_max_90</th>\n",
       "      <th>Date_Closed31_min_90</th>\n",
       "      <th>Date_Closed31_mean_90</th>\n",
       "      <th>Date_Closed31_mode_90</th>\n",
       "      <th>Date_Closed31_nuniq_90</th>\n",
       "      <th>Date_Closed31_maxcount_90</th>\n",
       "      <th>Date_Closed31_mode_360</th>\n",
       "      <th>Date_Closed31_nuniq_360</th>\n",
       "      <th>Date_Closed31_maxcount_360</th>\n",
       "      <th>Date_Closed31_mean_9999</th>\n",
       "      <th>Date_Closed31_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_30</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_30</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_90</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_90</th>\n",
       "      <th>Date_of_Last_Payment40_max_360</th>\n",
       "      <th>Date_of_Last_Payment40_min_360</th>\n",
       "      <th>Date_of_Last_Payment40_mean_360</th>\n",
       "      <th>Date_of_Last_Payment40_mode_360</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_360</th>\n",
       "      <th>Date_of_Last_Payment40_max_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mean_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_9999</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_9999</th>\n",
       "      <th>Date_Reported33_nuniq_30</th>\n",
       "      <th>Date_Reported33_max_90</th>\n",
       "      <th>Date_Reported33_mode_90</th>\n",
       "      <th>Date_Reported33_nuniq_90</th>\n",
       "      <th>Date_Reported33_maxcount_90</th>\n",
       "      <th>Date_Reported33_max_360</th>\n",
       "      <th>Date_Reported33_mean_360</th>\n",
       "      <th>Date_Reported33_mode_360</th>\n",
       "      <th>Date_Reported33_nuniq_360</th>\n",
       "      <th>Date_Reported33_max_9999</th>\n",
       "      <th>Date_Reported33_mode_9999</th>\n",
       "      <th>Date_Reported33_nuniq_9999</th>\n",
       "      <th>Date_Reported33_maxcount_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_30</th>\n",
       "      <th>DateOfAddition34_max_90</th>\n",
       "      <th>DateOfAddition34_mean_90</th>\n",
       "      <th>DateOfAddition34_nuniq_90</th>\n",
       "      <th>DateOfAddition34_maxcount_90</th>\n",
       "      <th>DateOfAddition34_max_360</th>\n",
       "      <th>DateOfAddition34_mean_360</th>\n",
       "      <th>DateOfAddition34_mode_360</th>\n",
       "      <th>DateOfAddition34_maxcount_360</th>\n",
       "      <th>DateOfAddition34_max_9999</th>\n",
       "      <th>DateOfAddition34_min_9999</th>\n",
       "      <th>DateOfAddition34_mode_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_9999</th>\n",
       "      <th>DateOfAddition34_maxcount_9999</th>\n",
       "      <th>Account_Status34_mode_30</th>\n",
       "      <th>Account_Status34_nuniq_30</th>\n",
       "      <th>Account_Status34_mode_90</th>\n",
       "      <th>Account_Status34_nuniq_90</th>\n",
       "      <th>Account_Status34_nuniq_360</th>\n",
       "      <th>Account_Status34_mode_9999</th>\n",
       "      <th>Account_Status34_nuniq_9999</th>\n",
       "      <th>Month50_sum_30</th>\n",
       "      <th>Month50_mean_30</th>\n",
       "      <th>Month50_std_30</th>\n",
       "      <th>Month50_sum_90</th>\n",
       "      <th>Month50_mean_90</th>\n",
       "      <th>Month50_max_90</th>\n",
       "      <th>Month50_std_90</th>\n",
       "      <th>Month50_max_360</th>\n",
       "      <th>Month50_min_360</th>\n",
       "      <th>Month50_mean_9999</th>\n",
       "      <th>Month50_max_9999</th>\n",
       "      <th>Month50_min_9999</th>\n",
       "      <th>Month50_std_9999</th>\n",
       "      <th>Days_Past_Due58_sum_90</th>\n",
       "      <th>Days_Past_Due58_min_90</th>\n",
       "      <th>Days_Past_Due58_std_90</th>\n",
       "      <th>Days_Past_Due58_sum_360</th>\n",
       "      <th>Days_Past_Due58_mean_360</th>\n",
       "      <th>Days_Past_Due58_max_360</th>\n",
       "      <th>Days_Past_Due58_min_360</th>\n",
       "      <th>Days_Past_Due58_std_360</th>\n",
       "      <th>Days_Past_Due58_sum_9999</th>\n",
       "      <th>Days_Past_Due58_max_9999</th>\n",
       "      <th>Days_Past_Due58_min_9999</th>\n",
       "      <th>Days_Past_Due58_std_9999</th>\n",
       "      <th>Duecount53_mean_30</th>\n",
       "      <th>Duecount53_min_30</th>\n",
       "      <th>Duecount53_std_30</th>\n",
       "      <th>Duecount53_sum_90</th>\n",
       "      <th>Duecount53_mean_90</th>\n",
       "      <th>Duecount53_max_90</th>\n",
       "      <th>Duecount53_min_90</th>\n",
       "      <th>Duecount53_std_90</th>\n",
       "      <th>Duecount53_sum_360</th>\n",
       "      <th>Duecount53_mean_360</th>\n",
       "      <th>Duecount53_max_360</th>\n",
       "      <th>Duecount53_min_360</th>\n",
       "      <th>Duecount53_std_360</th>\n",
       "      <th>Duecount53_sum_9999</th>\n",
       "      <th>Duecount53_mean_9999</th>\n",
       "      <th>Duecount53_max_9999</th>\n",
       "      <th>Duecount53_min_9999</th>\n",
       "      <th>Duecount53_std_9999</th>\n",
       "      <th>Duesum51_mean_30</th>\n",
       "      <th>Duesum51_std_30</th>\n",
       "      <th>Duesum51_mean_90</th>\n",
       "      <th>Duesum51_max_90</th>\n",
       "      <th>Duesum51_sum_360</th>\n",
       "      <th>Duesum51_mean_360</th>\n",
       "      <th>Duesum51_max_360</th>\n",
       "      <th>Duesum51_min_360</th>\n",
       "      <th>Duesum51_std_360</th>\n",
       "      <th>Duesum51_sum_9999</th>\n",
       "      <th>Duesum51_mean_9999</th>\n",
       "      <th>Duesum51_max_9999</th>\n",
       "      <th>Duesum51_min_9999</th>\n",
       "      <th>Duesum51_std_9999</th>\n",
       "      <th>Amount_Financed35_std_7</th>\n",
       "      <th>Amount_Financed35_max_30</th>\n",
       "      <th>Amount_Financed35_min_30</th>\n",
       "      <th>Amount_Financed35_std_30</th>\n",
       "      <th>Amount_Financed35_count_90</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_1034_sms</th>\n",
       "      <th>feature_1035_sms</th>\n",
       "      <th>feature_1036_sms</th>\n",
       "      <th>feature_1037_sms</th>\n",
       "      <th>feature_1038_sms</th>\n",
       "      <th>feature_1039_sms</th>\n",
       "      <th>feature_1040_sms</th>\n",
       "      <th>feature_1041_sms</th>\n",
       "      <th>feature_1042_sms</th>\n",
       "      <th>feature_1043_sms</th>\n",
       "      <th>feature_1044_sms</th>\n",
       "      <th>feature_1045_sms</th>\n",
       "      <th>feature_1046_sms</th>\n",
       "      <th>feature_1047_sms</th>\n",
       "      <th>feature_1048_sms</th>\n",
       "      <th>feature_1049_sms</th>\n",
       "      <th>feature_1050_sms</th>\n",
       "      <th>feature_1051_sms</th>\n",
       "      <th>feature_1052_sms</th>\n",
       "      <th>feature_1053_sms</th>\n",
       "      <th>feature_1054_sms</th>\n",
       "      <th>feature_1055_sms</th>\n",
       "      <th>feature_1056_sms</th>\n",
       "      <th>feature_1057_sms</th>\n",
       "      <th>feature_1058_sms</th>\n",
       "      <th>feature_1059_sms</th>\n",
       "      <th>feature_1060_sms</th>\n",
       "      <th>feature_1061_sms</th>\n",
       "      <th>feature_1062_sms</th>\n",
       "      <th>feature_1063_sms</th>\n",
       "      <th>feature_1064_sms</th>\n",
       "      <th>feature_1065_sms</th>\n",
       "      <th>feature_1066_sms</th>\n",
       "      <th>feature_1067_sms</th>\n",
       "      <th>feature_1068_sms</th>\n",
       "      <th>feature_1069_sms</th>\n",
       "      <th>feature_1070_sms</th>\n",
       "      <th>feature_1071_sms</th>\n",
       "      <th>feature_1072_sms</th>\n",
       "      <th>feature_1073_sms</th>\n",
       "      <th>feature_1074_sms</th>\n",
       "      <th>feature_1075_sms</th>\n",
       "      <th>feature_1076_sms</th>\n",
       "      <th>feature_1077_sms</th>\n",
       "      <th>feature_1078_sms</th>\n",
       "      <th>feature_1079_sms</th>\n",
       "      <th>feature_1080_sms</th>\n",
       "      <th>feature_1081_sms</th>\n",
       "      <th>feature_1082_sms</th>\n",
       "      <th>feature_1083_sms</th>\n",
       "      <th>feature_1084_sms</th>\n",
       "      <th>feature_1085_sms</th>\n",
       "      <th>feature_1086_sms</th>\n",
       "      <th>feature_1087_sms</th>\n",
       "      <th>feature_1088_sms</th>\n",
       "      <th>feature_1089_sms</th>\n",
       "      <th>feature_1090_sms</th>\n",
       "      <th>feature_1091_sms</th>\n",
       "      <th>feature_1092_sms</th>\n",
       "      <th>feature_1093_sms</th>\n",
       "      <th>feature_1094_sms</th>\n",
       "      <th>feature_1095_sms</th>\n",
       "      <th>feature_1096_sms</th>\n",
       "      <th>feature_1097_sms</th>\n",
       "      <th>feature_1098_sms</th>\n",
       "      <th>feature_1099_sms</th>\n",
       "      <th>feature_1100_sms</th>\n",
       "      <th>feature_1101_sms</th>\n",
       "      <th>feature_1102_sms</th>\n",
       "      <th>feature_1103_sms</th>\n",
       "      <th>feature_1104_sms</th>\n",
       "      <th>feature_1105_sms</th>\n",
       "      <th>feature_1106_sms</th>\n",
       "      <th>feature_1107_sms</th>\n",
       "      <th>feature_1108_sms</th>\n",
       "      <th>feature_1109_sms</th>\n",
       "      <th>feature_1110_sms</th>\n",
       "      <th>feature_1111_sms</th>\n",
       "      <th>feature_1112_sms</th>\n",
       "      <th>feature_1113_sms</th>\n",
       "      <th>feature_1114_sms</th>\n",
       "      <th>feature_1115_sms</th>\n",
       "      <th>feature_1116_sms</th>\n",
       "      <th>feature_1117_sms</th>\n",
       "      <th>feature_1118_sms</th>\n",
       "      <th>feature_1119_sms</th>\n",
       "      <th>feature_1120_sms</th>\n",
       "      <th>feature_1121_sms</th>\n",
       "      <th>feature_1122_sms</th>\n",
       "      <th>feature_1123_sms</th>\n",
       "      <th>feature_1124_sms</th>\n",
       "      <th>feature_1125_sms</th>\n",
       "      <th>feature_1126_sms</th>\n",
       "      <th>feature_1127_sms</th>\n",
       "      <th>feature_1128_sms</th>\n",
       "      <th>feature_1129_sms</th>\n",
       "      <th>feature_1130_sms</th>\n",
       "      <th>feature_1131_sms</th>\n",
       "      <th>feature_1132_sms</th>\n",
       "      <th>feature_1133_sms</th>\n",
       "      <th>feature_1134_sms</th>\n",
       "      <th>feature_1135_sms</th>\n",
       "      <th>feature_1136_sms</th>\n",
       "      <th>feature_1137_sms</th>\n",
       "      <th>feature_1138_sms</th>\n",
       "      <th>feature_1139_sms</th>\n",
       "      <th>feature_1140_sms</th>\n",
       "      <th>feature_1141_sms</th>\n",
       "      <th>feature_1142_sms</th>\n",
       "      <th>feature_1143_sms</th>\n",
       "      <th>feature_1144_sms</th>\n",
       "      <th>feature_1145_sms</th>\n",
       "      <th>feature_1146_sms</th>\n",
       "      <th>feature_1147_sms</th>\n",
       "      <th>feature_1148_sms</th>\n",
       "      <th>feature_1149_sms</th>\n",
       "      <th>feature_1150_sms</th>\n",
       "      <th>feature_1151_sms</th>\n",
       "      <th>feature_1152_sms</th>\n",
       "      <th>feature_1153_sms</th>\n",
       "      <th>feature_1154_sms</th>\n",
       "      <th>feature_1155_sms</th>\n",
       "      <th>feature_1156_sms</th>\n",
       "      <th>feature_1157_sms</th>\n",
       "      <th>feature_1158_sms</th>\n",
       "      <th>feature_1159_sms</th>\n",
       "      <th>feature_1160_sms</th>\n",
       "      <th>feature_1161_sms</th>\n",
       "      <th>feature_1162_sms</th>\n",
       "      <th>feature_1163_sms</th>\n",
       "      <th>feature_1164_sms</th>\n",
       "      <th>feature_1165_sms</th>\n",
       "      <th>feature_1166_sms</th>\n",
       "      <th>feature_1167_sms</th>\n",
       "      <th>feature_1168_sms</th>\n",
       "      <th>feature_1169_sms</th>\n",
       "      <th>feature_1170_sms</th>\n",
       "      <th>feature_1171_sms</th>\n",
       "      <th>feature_1172_sms</th>\n",
       "      <th>feature_1173_sms</th>\n",
       "      <th>feature_1174_sms</th>\n",
       "      <th>feature_1175_sms</th>\n",
       "      <th>feature_1176_sms</th>\n",
       "      <th>feature_1177_sms</th>\n",
       "      <th>feature_1178_sms</th>\n",
       "      <th>feature_1179_sms</th>\n",
       "      <th>feature_1180_sms</th>\n",
       "      <th>feature_1181_sms</th>\n",
       "      <th>feature_1182_sms</th>\n",
       "      <th>feature_1183_sms</th>\n",
       "      <th>feature_1184_sms</th>\n",
       "      <th>feature_1185_sms</th>\n",
       "      <th>feature_1186_sms</th>\n",
       "      <th>feature_1187_sms</th>\n",
       "      <th>feature_1188_sms</th>\n",
       "      <th>feature_1189_sms</th>\n",
       "      <th>feature_1190_sms</th>\n",
       "      <th>feature_1191_sms</th>\n",
       "      <th>feature_1192_sms</th>\n",
       "      <th>feature_1193_sms</th>\n",
       "      <th>feature_1194_sms</th>\n",
       "      <th>feature_1195_sms</th>\n",
       "      <th>feature_1196_sms</th>\n",
       "      <th>feature_1197_sms</th>\n",
       "      <th>feature_1198_sms</th>\n",
       "      <th>feature_1199_sms</th>\n",
       "      <th>feature_1200_sms</th>\n",
       "      <th>feature_1201_sms</th>\n",
       "      <th>feature_1202_sms</th>\n",
       "      <th>feature_1203_sms</th>\n",
       "      <th>feature_1204_sms</th>\n",
       "      <th>feature_1205_sms</th>\n",
       "      <th>feature_1206_sms</th>\n",
       "      <th>feature_1207_sms</th>\n",
       "      <th>feature_1208_sms</th>\n",
       "      <th>feature_1209_sms</th>\n",
       "      <th>feature_1210_sms</th>\n",
       "      <th>feature_1211_sms</th>\n",
       "      <th>feature_1212_sms</th>\n",
       "      <th>feature_1213_sms</th>\n",
       "      <th>feature_1214_sms</th>\n",
       "      <th>feature_1215_sms</th>\n",
       "      <th>feature_1216_sms</th>\n",
       "      <th>feature_1217_sms</th>\n",
       "      <th>feature_1218_sms</th>\n",
       "      <th>feature_1219_sms</th>\n",
       "      <th>feature_1220_sms</th>\n",
       "      <th>feature_1221_sms</th>\n",
       "      <th>feature_1222_sms</th>\n",
       "      <th>feature_1223_sms</th>\n",
       "      <th>feature_1224_sms</th>\n",
       "      <th>feature_1225_sms</th>\n",
       "      <th>feature_1226_sms</th>\n",
       "      <th>feature_1227_sms</th>\n",
       "      <th>feature_1228_sms</th>\n",
       "      <th>feature_1229_sms</th>\n",
       "      <th>feature_1230_sms</th>\n",
       "      <th>feature_1231_sms</th>\n",
       "      <th>feature_1232_sms</th>\n",
       "      <th>feature_1233_sms</th>\n",
       "      <th>feature_1234_sms</th>\n",
       "      <th>feature_1235_sms</th>\n",
       "      <th>feature_1236_sms</th>\n",
       "      <th>feature_1237_sms</th>\n",
       "      <th>feature_1238_sms</th>\n",
       "      <th>feature_1239_sms</th>\n",
       "      <th>feature_1240_sms</th>\n",
       "      <th>feature_1241_sms</th>\n",
       "      <th>feature_1242_sms</th>\n",
       "      <th>feature_1243_sms</th>\n",
       "      <th>feature_1244_sms</th>\n",
       "      <th>feature_1245_sms</th>\n",
       "      <th>feature_1246_sms</th>\n",
       "      <th>feature_1247_sms</th>\n",
       "      <th>feature_1248_sms</th>\n",
       "      <th>feature_1249_sms</th>\n",
       "      <th>feature_1250_sms</th>\n",
       "      <th>feature_1251_sms</th>\n",
       "      <th>feature_1252_sms</th>\n",
       "      <th>feature_1253_sms</th>\n",
       "      <th>feature_1254_sms</th>\n",
       "      <th>feature_1255_sms</th>\n",
       "      <th>feature_1256_sms</th>\n",
       "      <th>feature_1257_sms</th>\n",
       "      <th>feature_1258_sms</th>\n",
       "      <th>feature_1259_sms</th>\n",
       "      <th>feature_1260_sms</th>\n",
       "      <th>feature_1261_sms</th>\n",
       "      <th>feature_1262_sms</th>\n",
       "      <th>feature_1263_sms</th>\n",
       "      <th>feature_1264_sms</th>\n",
       "      <th>feature_1265_sms</th>\n",
       "      <th>feature_1266_sms</th>\n",
       "      <th>feature_1267_sms</th>\n",
       "      <th>feature_1268_sms</th>\n",
       "      <th>feature_1269_sms</th>\n",
       "      <th>feature_1270_sms</th>\n",
       "      <th>feature_1271_sms</th>\n",
       "      <th>feature_1272_sms</th>\n",
       "      <th>feature_1273_sms</th>\n",
       "      <th>feature_1274_sms</th>\n",
       "      <th>feature_1275_sms</th>\n",
       "      <th>feature_1276_sms</th>\n",
       "      <th>feature_1277_sms</th>\n",
       "      <th>feature_1278_sms</th>\n",
       "      <th>feature_1279_sms</th>\n",
       "      <th>feature_1280_sms</th>\n",
       "      <th>feature_1281_sms</th>\n",
       "      <th>feature_1282_sms</th>\n",
       "      <th>feature_1283_sms</th>\n",
       "      <th>feature_1284_sms</th>\n",
       "      <th>feature_1285_sms</th>\n",
       "      <th>feature_1286_sms</th>\n",
       "      <th>feature_1287_sms</th>\n",
       "      <th>feature_1288_sms</th>\n",
       "      <th>feature_1289_sms</th>\n",
       "      <th>feature_1290_sms</th>\n",
       "      <th>feature_1291_sms</th>\n",
       "      <th>feature_1292_sms</th>\n",
       "      <th>feature_1293_sms</th>\n",
       "      <th>feature_1294_sms</th>\n",
       "      <th>feature_1295_sms</th>\n",
       "      <th>feature_1296_sms</th>\n",
       "      <th>feature_1297_sms</th>\n",
       "      <th>feature_1298_sms</th>\n",
       "      <th>feature_1299_sms</th>\n",
       "      <th>feature_1300_sms</th>\n",
       "      <th>feature_1301_sms</th>\n",
       "      <th>feature_1302_sms</th>\n",
       "      <th>feature_1303_sms</th>\n",
       "      <th>feature_1304_sms</th>\n",
       "      <th>feature_1305_sms</th>\n",
       "      <th>feature_1306_sms</th>\n",
       "      <th>feature_1307_sms</th>\n",
       "      <th>feature_1308_sms</th>\n",
       "      <th>feature_1309_sms</th>\n",
       "      <th>feature_1310_sms</th>\n",
       "      <th>feature_1311_sms</th>\n",
       "      <th>feature_1312_sms</th>\n",
       "      <th>feature_1313_sms</th>\n",
       "      <th>feature_1314_sms</th>\n",
       "      <th>feature_1315_sms</th>\n",
       "      <th>feature_1316_sms</th>\n",
       "      <th>feature_1317_sms</th>\n",
       "      <th>feature_1318_sms</th>\n",
       "      <th>feature_1319_sms</th>\n",
       "      <th>feature_1320_sms</th>\n",
       "      <th>feature_1321_sms</th>\n",
       "      <th>feature_1322_sms</th>\n",
       "      <th>feature_1323_sms</th>\n",
       "      <th>feature_1324_sms</th>\n",
       "      <th>feature_1325_sms</th>\n",
       "      <th>feature_1326_sms</th>\n",
       "      <th>feature_1327_sms</th>\n",
       "      <th>feature_1328_sms</th>\n",
       "      <th>feature_1329_sms</th>\n",
       "      <th>feature_1330_sms</th>\n",
       "      <th>order_id</th>\n",
       "      <th>pan</th>\n",
       "      <th>label_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAHPO6801A</td>\n",
       "      <td>20220121153515</td>\n",
       "      <td>563</td>\n",
       "      <td>H</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>1.999889</td>\n",
       "      <td>2.999667</td>\n",
       "      <td>9.997001</td>\n",
       "      <td>O</td>\n",
       "      <td>46</td>\n",
       "      <td>1.285673</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>9</td>\n",
       "      <td>0.749938</td>\n",
       "      <td>6</td>\n",
       "      <td>337940</td>\n",
       "      <td>16826</td>\n",
       "      <td>2.599680</td>\n",
       "      <td>4.499125</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.166139</td>\n",
       "      <td>32.968032</td>\n",
       "      <td>2.999500</td>\n",
       "      <td>234</td>\n",
       "      <td>86</td>\n",
       "      <td>71</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>16.984016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4644.916667</td>\n",
       "      <td>44737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12262.508447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5308000.0</td>\n",
       "      <td>8304111.0</td>\n",
       "      <td>4441000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>135.750000</td>\n",
       "      <td>65.086001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.149919</td>\n",
       "      <td>5146651.0</td>\n",
       "      <td>4371915.0</td>\n",
       "      <td>1.798590e+06</td>\n",
       "      <td>5542401.0</td>\n",
       "      <td>461866.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27173.666667</td>\n",
       "      <td>81521.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38429.367939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49982.0</td>\n",
       "      <td>16660.666667</td>\n",
       "      <td>49982.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>543.0</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.210427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4203.0</td>\n",
       "      <td>1028.750000</td>\n",
       "      <td>888.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>R</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.333333</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>129.416667</td>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>296.0</td>\n",
       "      <td>250.500000</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>752.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>267.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.132402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>266.0</td>\n",
       "      <td>22.166667</td>\n",
       "      <td>55.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.408554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>107.833333</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.475276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>23</td>\n",
       "      <td>215</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1076</td>\n",
       "      <td>30</td>\n",
       "      <td>117</td>\n",
       "      <td>31</td>\n",
       "      <td>299</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>108</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1510</td>\n",
       "      <td>54</td>\n",
       "      <td>185</td>\n",
       "      <td>42</td>\n",
       "      <td>429</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>154</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>4</td>\n",
       "      <td>204</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3000</td>\n",
       "      <td>269</td>\n",
       "      <td>230</td>\n",
       "      <td>55</td>\n",
       "      <td>1019</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>184</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>715</td>\n",
       "      <td>61</td>\n",
       "      <td>369</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>38.666667</td>\n",
       "      <td>38.666667</td>\n",
       "      <td>0.038667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>0.267241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.112069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.032143</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.857143</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>0.117857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>0.170333</td>\n",
       "      <td>3.357143</td>\n",
       "      <td>0.091977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>11.071429</td>\n",
       "      <td>0.303327</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.113503</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>0.072407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.214286</td>\n",
       "      <td>0.225049</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>3.642857</td>\n",
       "      <td>0.099804</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>34.761905</td>\n",
       "      <td>34.761905</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>3.238095</td>\n",
       "      <td>0.093151</td>\n",
       "      <td>1.095238</td>\n",
       "      <td>0.031507</td>\n",
       "      <td>10.238095</td>\n",
       "      <td>0.294521</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.026027</td>\n",
       "      <td>3.619048</td>\n",
       "      <td>0.104110</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>2.619048</td>\n",
       "      <td>0.075342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.380952</td>\n",
       "      <td>0.212329</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>4.476190</td>\n",
       "      <td>0.128767</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>35.866667</td>\n",
       "      <td>35.866667</td>\n",
       "      <td>0.358667</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.108736</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.028810</td>\n",
       "      <td>9.966667</td>\n",
       "      <td>0.277881</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.100372</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.008364</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.064126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.133333</td>\n",
       "      <td>0.226766</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.139405</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.002788</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>25.166667</td>\n",
       "      <td>27.962963</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>0.122517</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.027815</td>\n",
       "      <td>7.150000</td>\n",
       "      <td>0.284106</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>0.101987</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.433333</td>\n",
       "      <td>0.215894</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.135099</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>3.000</td>\n",
       "      <td>11.152416</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>1.019</td>\n",
       "      <td>0.339667</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.014667</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.061333</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.238333</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.020333</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>XQDI8W8E</td>\n",
       "      <td>AAHPO6801A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAIPI5141G</td>\n",
       "      <td>20211116185506</td>\n",
       "      <td>772</td>\n",
       "      <td>H</td>\n",
       "      <td>0.420485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>14</td>\n",
       "      <td>1.499917</td>\n",
       "      <td>3.498751</td>\n",
       "      <td>2.499250</td>\n",
       "      <td>I</td>\n",
       "      <td>46</td>\n",
       "      <td>1.333278</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16178</td>\n",
       "      <td>2.999334</td>\n",
       "      <td>4.498251</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.332556</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>1.499750</td>\n",
       "      <td>181</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>8.992008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298700.0</td>\n",
       "      <td>308700.0</td>\n",
       "      <td>180700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120251.0</td>\n",
       "      <td>120251.0</td>\n",
       "      <td>6.012550e+04</td>\n",
       "      <td>120251.0</td>\n",
       "      <td>40083.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15944.000000</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>15944.000000</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>15944.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>238.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>231.500000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.132034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.887841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450.0</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.132034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10530.379333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>75</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>653</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>14</td>\n",
       "      <td>62</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>70</td>\n",
       "      <td>56</td>\n",
       "      <td>1395</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>232</td>\n",
       "      <td>33</td>\n",
       "      <td>151</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "      <td>145</td>\n",
       "      <td>126</td>\n",
       "      <td>3000</td>\n",
       "      <td>100</td>\n",
       "      <td>158</td>\n",
       "      <td>77</td>\n",
       "      <td>638</td>\n",
       "      <td>49</td>\n",
       "      <td>226</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>303</td>\n",
       "      <td>9</td>\n",
       "      <td>678</td>\n",
       "      <td>14</td>\n",
       "      <td>132</td>\n",
       "      <td>292</td>\n",
       "      <td>208</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>0.029667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.056180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.224719</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>23.571429</td>\n",
       "      <td>23.571429</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>0.115152</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042424</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>0.096970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>0.103030</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>20.714286</td>\n",
       "      <td>20.714286</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>0.065517</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.020690</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>1.642857</td>\n",
       "      <td>0.079310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>0.196552</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>2.071429</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>0.127586</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>0.113793</td>\n",
       "      <td>21.571429</td>\n",
       "      <td>21.571429</td>\n",
       "      <td>0.151000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.052980</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.041943</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.165563</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.086093</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.022075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>2.238095</td>\n",
       "      <td>0.103753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.904762</td>\n",
       "      <td>0.181015</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>2.047619</td>\n",
       "      <td>0.094923</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>2.238095</td>\n",
       "      <td>0.103753</td>\n",
       "      <td>21.766667</td>\n",
       "      <td>21.766667</td>\n",
       "      <td>0.217667</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.055130</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.041348</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.188361</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>0.094946</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.026034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.105666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.179173</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.088821</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.107198</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>0.085758</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.035842</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>0.166308</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>2.516667</td>\n",
       "      <td>0.108244</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.026523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>2.516667</td>\n",
       "      <td>0.108244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>0.195699</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>1.616667</td>\n",
       "      <td>0.069534</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>0.103943</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.090323</td>\n",
       "      <td>3.000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.052667</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.212667</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.016333</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.075333</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.226000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.097333</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.069333</td>\n",
       "      <td>NKNSPUYG</td>\n",
       "      <td>AAIPI5141G</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAIPZ7980L</td>\n",
       "      <td>20211017185940</td>\n",
       "      <td>710</td>\n",
       "      <td>H</td>\n",
       "      <td>0.409987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>28</td>\n",
       "      <td>4.454441</td>\n",
       "      <td>8.070924</td>\n",
       "      <td>31.393921</td>\n",
       "      <td>Z</td>\n",
       "      <td>46</td>\n",
       "      <td>3.999842</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>45</td>\n",
       "      <td>0.542162</td>\n",
       "      <td>64</td>\n",
       "      <td>2988444</td>\n",
       "      <td>12875</td>\n",
       "      <td>26.162473</td>\n",
       "      <td>36.491127</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>14.544223</td>\n",
       "      <td>112.444278</td>\n",
       "      <td>20.745064</td>\n",
       "      <td>888</td>\n",
       "      <td>197</td>\n",
       "      <td>125</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>145.855145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.051105</td>\n",
       "      <td>31.721311</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.861371</td>\n",
       "      <td>49619.040611</td>\n",
       "      <td>1446850.0</td>\n",
       "      <td>7088063.0</td>\n",
       "      <td>1696000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.959592</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.258065</td>\n",
       "      <td>13.276143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124020</td>\n",
       "      <td>1006101.0</td>\n",
       "      <td>230787.0</td>\n",
       "      <td>4.062192e+04</td>\n",
       "      <td>4648986.0</td>\n",
       "      <td>56694.951220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.8</td>\n",
       "      <td>33.56</td>\n",
       "      <td>94.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.622449</td>\n",
       "      <td>710.292</td>\n",
       "      <td>827.172</td>\n",
       "      <td>30.636</td>\n",
       "      <td>94.8</td>\n",
       "      <td>6.75</td>\n",
       "      <td>19.035488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.641304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.966940</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.084337</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.043676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46200.0</td>\n",
       "      <td>155465.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5048.0</td>\n",
       "      <td>461.120482</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>61.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>269.052632</td>\n",
       "      <td>106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>119.526316</td>\n",
       "      <td>106.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>176.122807</td>\n",
       "      <td>73.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>100.131148</td>\n",
       "      <td>78.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>57.214286</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>129.524590</td>\n",
       "      <td>78.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2543.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>7.785714</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.557875</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.879518</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.730451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2.619048</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.493171</td>\n",
       "      <td>110.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.393263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.257539</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1.950820</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.562115</td>\n",
       "      <td>649.0</td>\n",
       "      <td>7.819277</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.668312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.803279</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.613549</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.325301</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.279905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34692.298217</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>641</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>6</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>886</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>216</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>225</td>\n",
       "      <td>9</td>\n",
       "      <td>102</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1931</td>\n",
       "      <td>400</td>\n",
       "      <td>73</td>\n",
       "      <td>49</td>\n",
       "      <td>551</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>208</td>\n",
       "      <td>5</td>\n",
       "      <td>518</td>\n",
       "      <td>163</td>\n",
       "      <td>171</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>0.044537</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>23.857143</td>\n",
       "      <td>23.857143</td>\n",
       "      <td>0.086484</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.065868</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.047904</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>0.245509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.107784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.428571</td>\n",
       "      <td>0.269461</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.149701</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>24.285714</td>\n",
       "      <td>24.285714</td>\n",
       "      <td>0.176075</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.123529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>0.311765</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>2.928571</td>\n",
       "      <td>0.120588</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>23.238095</td>\n",
       "      <td>23.238095</td>\n",
       "      <td>0.252719</td>\n",
       "      <td>1.619048</td>\n",
       "      <td>0.069672</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.186475</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.014344</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.122951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>0.104508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.809524</td>\n",
       "      <td>0.293033</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.012295</td>\n",
       "      <td>2.809524</td>\n",
       "      <td>0.120902</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006148</td>\n",
       "      <td>21.366667</td>\n",
       "      <td>21.366667</td>\n",
       "      <td>0.331952</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0.063963</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.045242</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>0.173167</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.015601</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>0.120125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>0.138846</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.00156</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>0.288612</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.009360</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>0.120125</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>14.766667</td>\n",
       "      <td>15.275862</td>\n",
       "      <td>0.458830</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.059819</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.044018</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.243792</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.011287</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.101580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.011287</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.128668</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>0.253950</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.010158</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.115124</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.010158</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>1.931</td>\n",
       "      <td>4.827500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.037804</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.025375</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.285344</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.008286</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.071983</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.009839</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.107716</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.268255</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.084412</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.088555</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>3WXC1GIM</td>\n",
       "      <td>AAIPZ7980L</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AALPF3903A</td>\n",
       "      <td>20220201134326</td>\n",
       "      <td>478</td>\n",
       "      <td>H</td>\n",
       "      <td>0.341053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>33</td>\n",
       "      <td>12.597680</td>\n",
       "      <td>5.999500</td>\n",
       "      <td>1.666445</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>3.499583</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>6</td>\n",
       "      <td>0.113205</td>\n",
       "      <td>83</td>\n",
       "      <td>390006</td>\n",
       "      <td>13095</td>\n",
       "      <td>22.659447</td>\n",
       "      <td>20.993336</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18.745564</td>\n",
       "      <td>29.971029</td>\n",
       "      <td>13.246938</td>\n",
       "      <td>137</td>\n",
       "      <td>145</td>\n",
       "      <td>65</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>31.484758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2886.679245</td>\n",
       "      <td>77711.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12215.442972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85509.0</td>\n",
       "      <td>3333176.0</td>\n",
       "      <td>458000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.545455</td>\n",
       "      <td>31.230415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.486069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>472181.0</td>\n",
       "      <td>8909.075472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3360.363636</td>\n",
       "      <td>36964.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10626.402857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15280.0</td>\n",
       "      <td>2182.857143</td>\n",
       "      <td>15280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.800</td>\n",
       "      <td>10.900</td>\n",
       "      <td>13.8</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>303.0</td>\n",
       "      <td>5.716981</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.089273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>305.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5685.0</td>\n",
       "      <td>1510.981132</td>\n",
       "      <td>696.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1145.893617</td>\n",
       "      <td>630.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3918.0</td>\n",
       "      <td>1139.510638</td>\n",
       "      <td>630.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2438.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277.0</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2536.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.566038</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.339356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>329.0</td>\n",
       "      <td>109.666667</td>\n",
       "      <td>150.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>57.039947</td>\n",
       "      <td>2918.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.385284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.357023</td>\n",
       "      <td>587.0</td>\n",
       "      <td>11.075472</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.513601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>747.0</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>359.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>155.563492</td>\n",
       "      <td>81524.0</td>\n",
       "      <td>1538.188679</td>\n",
       "      <td>59071.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8193.472586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>142</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>906</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>201</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>6</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>1182</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>369</td>\n",
       "      <td>14</td>\n",
       "      <td>85</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>1182</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>369</td>\n",
       "      <td>14</td>\n",
       "      <td>85</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>0.100677</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.184874</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0.319328</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>36.428571</td>\n",
       "      <td>36.428571</td>\n",
       "      <td>0.215736</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.714286</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>40.642857</td>\n",
       "      <td>40.642857</td>\n",
       "      <td>0.481387</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>0.029877</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.010545</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>0.156415</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.172232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>0.130053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.571429</td>\n",
       "      <td>0.333919</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>3.785714</td>\n",
       "      <td>0.093146</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.035149</td>\n",
       "      <td>34.619048</td>\n",
       "      <td>34.619048</td>\n",
       "      <td>0.615059</td>\n",
       "      <td>1.095238</td>\n",
       "      <td>0.031637</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>6.761905</td>\n",
       "      <td>0.195323</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>4.809524</td>\n",
       "      <td>0.138927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.095238</td>\n",
       "      <td>0.147180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.238095</td>\n",
       "      <td>0.324622</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.006878</td>\n",
       "      <td>2.809524</td>\n",
       "      <td>0.081155</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.026135</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.033012</td>\n",
       "      <td>30.200000</td>\n",
       "      <td>30.200000</td>\n",
       "      <td>0.766497</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.032009</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>0.221854</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>0.118102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.143488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0.320088</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.077263</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.029801</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.030905</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>26.266667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.036379</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.010998</td>\n",
       "      <td>5.016667</td>\n",
       "      <td>0.254653</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>0.094755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>0.134518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.150000</td>\n",
       "      <td>0.312183</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.011844</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>0.071912</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.034687</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.028765</td>\n",
       "      <td>1.182</td>\n",
       "      <td>26.266667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.036379</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010998</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.254653</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.094755</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.134518</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.312183</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.011844</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.071912</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.034687</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028765</td>\n",
       "      <td>OYD0NERZ</td>\n",
       "      <td>AALPF3903A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AALPF4279M</td>\n",
       "      <td>20211105155431</td>\n",
       "      <td>738</td>\n",
       "      <td>H</td>\n",
       "      <td>0.442491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>3.076763</td>\n",
       "      <td>11.994503</td>\n",
       "      <td>9.998200</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>1.999889</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>12</td>\n",
       "      <td>0.499979</td>\n",
       "      <td>17</td>\n",
       "      <td>73774</td>\n",
       "      <td>14940</td>\n",
       "      <td>13.995668</td>\n",
       "      <td>13.329224</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.999000</td>\n",
       "      <td>59.941059</td>\n",
       "      <td>11.994503</td>\n",
       "      <td>211</td>\n",
       "      <td>28</td>\n",
       "      <td>112</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>18.491254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>287.791667</td>\n",
       "      <td>6907.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1380.200347</td>\n",
       "      <td>3780.384922</td>\n",
       "      <td>586317.0</td>\n",
       "      <td>607743.0</td>\n",
       "      <td>255341.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.238430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399653</td>\n",
       "      <td>414804.0</td>\n",
       "      <td>255341.0</td>\n",
       "      <td>5.516924e+04</td>\n",
       "      <td>421711.0</td>\n",
       "      <td>17571.291667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000</td>\n",
       "      <td>180.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.550095</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.041667</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.668323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>266.541667</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>INR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>182.250000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>97.777778</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>163.250000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>78.523810</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>144.761905</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.625000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.269591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.977416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.095238</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.974571</td>\n",
       "      <td>106.0</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.639005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.959682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>141</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>628</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2912</td>\n",
       "      <td>168</td>\n",
       "      <td>144</td>\n",
       "      <td>84</td>\n",
       "      <td>807</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>425</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "      <td>895</td>\n",
       "      <td>17</td>\n",
       "      <td>208</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.619048</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.011676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>10.846154</td>\n",
       "      <td>0.048420</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0.290780</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.099291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.099291</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>10.466667</td>\n",
       "      <td>14.604651</td>\n",
       "      <td>0.215659</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.017516</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.318471</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.009554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>0.140127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>0.103503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.016667</td>\n",
       "      <td>0.288217</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>2.912</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.049451</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.277129</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.145948</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.063874</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.307349</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.005838</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.029876</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>U67MOCC1</td>\n",
       "      <td>AALPF4279M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1717 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID report_timestamp  BureauScore BureauScoreConfidLevel  \\\n",
       "0  AAHPO6801A   20220121153515          563                      H   \n",
       "1  AAIPI5141G   20211116185506          772                      H   \n",
       "2  AAIPZ7980L   20211017185940          710                      H   \n",
       "3  AALPF3903A   20220201134326          478                      H   \n",
       "4  AALPF4279M   20211105155431          738                      H   \n",
       "\n",
       "   MissingRate Current_Finance_Purpose  Current_Amount_Financed  \\\n",
       "0     0.297000                     NaN                   310000   \n",
       "1     0.420485                     NaN                   310000   \n",
       "2     0.409987                     NaN                   310000   \n",
       "3     0.341053                     NaN                   310000   \n",
       "4     0.442491                     NaN                   310000   \n",
       "\n",
       "  Current_Gender_Code First_Name1  Len_Name  Name_nuniq  Tel_nuniq  \\\n",
       "0                   1           O        32    1.999889   2.999667   \n",
       "1                   1           P        14    1.499917   3.498751   \n",
       "2                   1           C        28    4.454441   8.070924   \n",
       "3                   1           P        33   12.597680   5.999500   \n",
       "4                   1           F        15    3.076763  11.994503   \n",
       "\n",
       "   Email_nuniq IncomeTaxPAN_5  Len_of_addrs  City_nuniq PinCode3  \\\n",
       "0     9.997001              O            46    1.285673      422   \n",
       "1     2.499250              I            46    1.333278      422   \n",
       "2    31.393921              Z            46    3.999842      422   \n",
       "3     1.666445              F            46    3.499583      422   \n",
       "4     9.998200              F            46    1.999889      422   \n",
       "\n",
       "   Current_State Current_City  CreditAccountActive  CreditAccountActivePor  \\\n",
       "0             27       MUMBAI                    9                0.749938   \n",
       "1             27       MUMBAI                    1                0.333222   \n",
       "2             27       MUMBAI                   45                0.542162   \n",
       "3             27       MUMBAI                    6                0.113205   \n",
       "4             27       MUMBAI                   12                0.499979   \n",
       "\n",
       "   Outstanding_Balance_UnSecured_Percentage  Outstanding_Balance_UnSecured  \\\n",
       "0                                         6                         337940   \n",
       "1                                         0                              0   \n",
       "2                                        64                        2988444   \n",
       "3                                        83                         390006   \n",
       "4                                        17                          73774   \n",
       "\n",
       "   Diff_dateBirth  State_nuniq  Birth_nuniq  TotalCAPSLast90Days  \\\n",
       "0           16826     2.599680     4.499125                   12   \n",
       "1           16178     2.999334     4.498251                    3   \n",
       "2           12875    26.162473    36.491127                   37   \n",
       "3           13095    22.659447    20.993336                    2   \n",
       "4           14940    13.995668    13.329224                    4   \n",
       "\n",
       "   TotalCAPSLast7Days  TotalCAPSLast30Days  TotalCAPSLast180Days  \\\n",
       "0                   9                    9                    12   \n",
       "1                   0                    3                     3   \n",
       "2                  22                   28                    54   \n",
       "3                   1                    1                     2   \n",
       "4                   1                    2                     5   \n",
       "\n",
       "   CAPSLast7Days  CAPSLast180Days  Pin_nuniq   Pan_nuniq  Ident_nuniq  \\\n",
       "0              0                3   4.166139   32.968032     2.999500   \n",
       "1              0                3   3.332556   10.990010     1.499750   \n",
       "2              1               33  14.544223  112.444278    20.745064   \n",
       "3              1                2  18.745564   29.971029    13.246938   \n",
       "4              1                5   6.999000   59.941059    11.994503   \n",
       "\n",
       "   Name_nuniq2  Tel_nuniq2  Email_nuniq2  Pan_nuniq2  Account_nuniq2  \\\n",
       "0          234          86            71          14              14   \n",
       "1          181          30            45          14              14   \n",
       "2          888         197           125          28              14   \n",
       "3          137         145            65          14              14   \n",
       "4          211          28           112          14              14   \n",
       "\n",
       "   Ident_nuniq2  Gender_nuniq  Amount_Past_Due35_max_30  \\\n",
       "0            60     16.984016                       NaN   \n",
       "1            30      8.992008                       NaN   \n",
       "2            60    145.855145                       NaN   \n",
       "3            60     31.484758                       NaN   \n",
       "4            30     18.491254                       NaN   \n",
       "\n",
       "   Amount_Past_Due35_mean_90  Amount_Past_Due35_max_90  \\\n",
       "0                        NaN                       NaN   \n",
       "1                        NaN                       NaN   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   Amount_Past_Due35_min_90  Amount_Past_Due35_std_90  \\\n",
       "0                       NaN                       NaN   \n",
       "1                       NaN                       NaN   \n",
       "2                       0.0                       0.0   \n",
       "3                       NaN                       NaN   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Amount_Past_Due35_sum_360  Amount_Past_Due35_max_360  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                     1935.0                     1045.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Amount_Past_Due35_min_360  Amount_Past_Due35_std_360  \\\n",
       "0                        0.0                   0.000000   \n",
       "1                        0.0                   0.000000   \n",
       "2                        0.0                 200.051105   \n",
       "3                        0.0                   0.000000   \n",
       "4                        0.0                   0.000000   \n",
       "\n",
       "   Amount_Past_Due35_mean_9999  Amount_Past_Due35_max_9999  \\\n",
       "0                  4644.916667                     44737.0   \n",
       "1                     0.000000                         0.0   \n",
       "2                    31.721311                      1045.0   \n",
       "3                  2886.679245                     77711.0   \n",
       "4                   287.791667                      6907.0   \n",
       "\n",
       "   Amount_Past_Due35_min_9999  Amount_Past_Due35_std_9999  \\\n",
       "0                         0.0                12262.508447   \n",
       "1                         0.0                    0.000000   \n",
       "2                         0.0                  172.861371   \n",
       "3                         0.0                12215.442972   \n",
       "4                         0.0                 1380.200347   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                     49619.040611   \n",
       "3                                              NaN   \n",
       "4                                      3780.384922   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_sum_360  \\\n",
       "0                                         5308000.0   \n",
       "1                                          298700.0   \n",
       "2                                         1446850.0   \n",
       "3                                           85509.0   \n",
       "4                                          586317.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                          8304111.0   \n",
       "1                                           308700.0   \n",
       "2                                          7088063.0   \n",
       "3                                          3333176.0   \n",
       "4                                           607743.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_max_9999  Terms_Duration34_std_30  \\\n",
       "0                                          4441000.0                      NaN   \n",
       "1                                           180700.0                      NaN   \n",
       "2                                          1696000.0                      NaN   \n",
       "3                                           458000.0                      NaN   \n",
       "4                                           255341.0                      NaN   \n",
       "\n",
       "   Terms_Duration34_std_90  Terms_Duration34_sum_360  \\\n",
       "0                      NaN                     360.0   \n",
       "1                      NaN                       0.0   \n",
       "2                 1.959592                      61.0   \n",
       "3                      NaN                       6.0   \n",
       "4                 0.000000                      35.0   \n",
       "\n",
       "   Terms_Duration34_max_360  Terms_Duration34_mean_9999  \\\n",
       "0                     180.0                  135.750000   \n",
       "1                       NaN                         NaN   \n",
       "2                      12.0                    8.258065   \n",
       "3                       6.0                   27.545455   \n",
       "4                      13.0                    3.500000   \n",
       "\n",
       "   Terms_Duration34_std_9999  Payment_Rating34_sum_90  \\\n",
       "0                  65.086001                      NaN   \n",
       "1                        NaN                      NaN   \n",
       "2                  13.276143                      0.0   \n",
       "3                  31.230415                      NaN   \n",
       "4                   4.238430                      0.0   \n",
       "\n",
       "   Payment_Rating34_mean_90  Payment_Rating34_min_90  Payment_Rating34_std_90  \\\n",
       "0                       NaN                      NaN                      NaN   \n",
       "1                       NaN                      NaN                      NaN   \n",
       "2                       0.0                      0.0                      0.0   \n",
       "3                       NaN                      NaN                      NaN   \n",
       "4                       0.0                      0.0                      0.0   \n",
       "\n",
       "   Payment_Rating34_sum_360  Payment_Rating34_mean_360  \\\n",
       "0                       0.0                    0.00000   \n",
       "1                       0.0                    0.00000   \n",
       "2                       1.0                    0.02381   \n",
       "3                       0.0                    0.00000   \n",
       "4                       0.0                    0.00000   \n",
       "\n",
       "   Payment_Rating34_max_360  Payment_Rating34_min_360  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       1.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Payment_Rating34_std_360  Payment_Rating34_sum_9999  \\\n",
       "0                  0.000000                        4.0   \n",
       "1                  0.000000                        0.0   \n",
       "2                  0.152455                        1.0   \n",
       "3                  0.000000                       23.0   \n",
       "4                  0.000000                        2.0   \n",
       "\n",
       "   Payment_Rating34_mean_9999  Payment_Rating34_max_9999  \\\n",
       "0                    0.363636                        4.0   \n",
       "1                    0.000000                        0.0   \n",
       "2                    0.015625                        1.0   \n",
       "3                    0.460000                        6.0   \n",
       "4                    0.083333                        2.0   \n",
       "\n",
       "   Payment_Rating34_min_9999  Payment_Rating34_std_9999  \\\n",
       "0                        0.0                   1.149919   \n",
       "1                        0.0                   0.000000   \n",
       "2                        0.0                   0.124020   \n",
       "3                        0.0                   1.486069   \n",
       "4                        0.0                   0.399653   \n",
       "\n",
       "   Current_Balance35_sum_360  Current_Balance35_max_360  \\\n",
       "0                  5146651.0                  4371915.0   \n",
       "1                   120251.0                   120251.0   \n",
       "2                  1006101.0                   230787.0   \n",
       "3                        0.0                        0.0   \n",
       "4                   414804.0                   255341.0   \n",
       "\n",
       "   Current_Balance35_std_360  Current_Balance35_sum_9999  \\\n",
       "0               1.798590e+06                   5542401.0   \n",
       "1               6.012550e+04                    120251.0   \n",
       "2               4.062192e+04                   4648986.0   \n",
       "3               0.000000e+00                    472181.0   \n",
       "4               5.516924e+04                    421711.0   \n",
       "\n",
       "   Current_Balance35_mean_9999  Settlement_Amount37_mean_360  \\\n",
       "0                461866.750000                           NaN   \n",
       "1                 40083.666667                           NaN   \n",
       "2                 56694.951220                           0.0   \n",
       "3                  8909.075472                           NaN   \n",
       "4                 17571.291667                           NaN   \n",
       "\n",
       "   Settlement_Amount37_std_360  Settlement_Amount37_mean_9999  \\\n",
       "0                          NaN                        67000.0   \n",
       "1                          NaN                            NaN   \n",
       "2                          0.0                            0.0   \n",
       "3                          NaN                            0.0   \n",
       "4                          NaN                            NaN   \n",
       "\n",
       "   Settlement_Amount37_max_9999  Settlement_Amount37_min_9999  \\\n",
       "0                       67000.0                       67000.0   \n",
       "1                           NaN                           NaN   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           NaN                           NaN   \n",
       "\n",
       "   Value_of_Collateral39_std_90  Value_of_Collateral39_std_360  \\\n",
       "0                           NaN                            NaN   \n",
       "1                           NaN                            NaN   \n",
       "2                           0.0                            0.0   \n",
       "3                           NaN                            NaN   \n",
       "4                           NaN                            NaN   \n",
       "\n",
       "   Written_Off_Amt_Total41_sum_360  Written_Off_Amt_Total41_std_360  \\\n",
       "0                              0.0                              0.0   \n",
       "1                              0.0                              NaN   \n",
       "2                              0.0                              0.0   \n",
       "3                              0.0                              NaN   \n",
       "4                              0.0                              NaN   \n",
       "\n",
       "   Written_Off_Amt_Total41_mean_9999  Written_Off_Amt_Total41_max_9999  \\\n",
       "0                       27173.666667                           81521.0   \n",
       "1                       15944.000000                           15944.0   \n",
       "2                           0.000000                               0.0   \n",
       "3                        3360.363636                           36964.0   \n",
       "4                                NaN                               NaN   \n",
       "\n",
       "   Written_Off_Amt_Total41_min_9999  Written_Off_Amt_Total41_std_9999  \\\n",
       "0                               0.0                      38429.367939   \n",
       "1                           15944.0                          0.000000   \n",
       "2                               0.0                          0.000000   \n",
       "3                               0.0                      10626.402857   \n",
       "4                               NaN                               NaN   \n",
       "\n",
       "   Written_Off_Amt_Principal45_sum_360  Written_Off_Amt_Principal45_min_360  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  NaN   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  NaN   \n",
       "4                                  0.0                                  NaN   \n",
       "\n",
       "   Written_Off_Amt_Principal45_std_360  Written_Off_Amt_Principal45_sum_9999  \\\n",
       "0                                  0.0                               49982.0   \n",
       "1                                  NaN                               15944.0   \n",
       "2                                  0.0                                   0.0   \n",
       "3                                  NaN                               15280.0   \n",
       "4                                  NaN                                   0.0   \n",
       "\n",
       "   Written_Off_Amt_Principal45_mean_9999  \\\n",
       "0                           16660.666667   \n",
       "1                           15944.000000   \n",
       "2                               0.000000   \n",
       "3                            2182.857143   \n",
       "4                                    NaN   \n",
       "\n",
       "   Written_Off_Amt_Principal45_max_9999  Written_Off_Amt_Principal45_min_9999  \\\n",
       "0                               49982.0                                   0.0   \n",
       "1                               15944.0                               15944.0   \n",
       "2                                   0.0                                   0.0   \n",
       "3                               15280.0                                   0.0   \n",
       "4                                   NaN                                   NaN   \n",
       "\n",
       "   Rate_of_Interest36_sum_30  Rate_of_Interest36_max_30  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                        NaN   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   Rate_of_Interest36_min_30  Rate_of_Interest36_std_30  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                        NaN   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   Rate_of_Interest36_sum_90  Rate_of_Interest36_mean_90  \\\n",
       "0                        NaN                         NaN   \n",
       "1                        NaN                         NaN   \n",
       "2                      167.8                       33.56   \n",
       "3                        NaN                         NaN   \n",
       "4                       54.0                       18.00   \n",
       "\n",
       "   Rate_of_Interest36_max_90  Rate_of_Interest36_min_90  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                       94.8                       18.0   \n",
       "3                        NaN                        NaN   \n",
       "4                       18.0                       18.0   \n",
       "\n",
       "   Rate_of_Interest36_std_90  Rate_of_Interest36_sum_360  \\\n",
       "0                        NaN                       0.000   \n",
       "1                        NaN                       0.000   \n",
       "2                  30.622449                     710.292   \n",
       "3                        NaN                       0.000   \n",
       "4                   0.000000                     180.000   \n",
       "\n",
       "   Rate_of_Interest36_sum_9999  Rate_of_Interest36_mean_9999  \\\n",
       "0                       45.000                        45.000   \n",
       "1                        0.000                           NaN   \n",
       "2                      827.172                        30.636   \n",
       "3                       21.800                        10.900   \n",
       "4                      180.000                        18.000   \n",
       "\n",
       "   Rate_of_Interest36_max_9999  Rate_of_Interest36_min_9999  \\\n",
       "0                         45.0                        45.00   \n",
       "1                          NaN                          NaN   \n",
       "2                         94.8                         6.75   \n",
       "3                         13.8                         8.00   \n",
       "4                         18.0                        18.00   \n",
       "\n",
       "   Rate_of_Interest36_std_9999  Repayment_Tenure36_std_30  \\\n",
       "0                     0.000000                        NaN   \n",
       "1                          NaN                        NaN   \n",
       "2                    19.035488                        NaN   \n",
       "3                     2.900000                        NaN   \n",
       "4                     0.000000                        NaN   \n",
       "\n",
       "   Repayment_Tenure36_std_90  Repayment_Tenure36_mean_360  \\\n",
       "0                        NaN                   180.000000   \n",
       "1                        NaN                     0.000000   \n",
       "2                   1.641304                     1.000000   \n",
       "3                        NaN                     2.000000   \n",
       "4                   0.489898                     1.666667   \n",
       "\n",
       "   Repayment_Tenure36_min_360  Repayment_Tenure36_std_360  \\\n",
       "0                       180.0                    0.000000   \n",
       "1                         0.0                    0.000000   \n",
       "2                         0.0                    1.966940   \n",
       "3                         0.0                    2.828427   \n",
       "4                         0.0                    3.550095   \n",
       "\n",
       "   Repayment_Tenure36_sum_9999  Repayment_Tenure36_mean_9999  \\\n",
       "0                        543.0                     45.250000   \n",
       "1                          0.0                      0.000000   \n",
       "2                        256.0                      3.084337   \n",
       "3                        303.0                      5.716981   \n",
       "4                         49.0                      2.041667   \n",
       "\n",
       "   Repayment_Tenure36_max_9999  Repayment_Tenure36_min_9999  \\\n",
       "0                        180.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                         60.0                          0.0   \n",
       "3                         94.0                          0.0   \n",
       "4                         13.0                          0.0   \n",
       "\n",
       "   Repayment_Tenure36_std_9999  Income26_count_30  Income26_std_90  \\\n",
       "0                    74.210427                NaN              NaN   \n",
       "1                     0.000000                NaN              NaN   \n",
       "2                     9.043676                NaN              NaN   \n",
       "3                    18.089273                NaN              NaN   \n",
       "4                     3.668323                NaN              NaN   \n",
       "\n",
       "   Income26_min_9999  Income26_std_9999  Open_Date29_max_30  \\\n",
       "0           480000.0                0.0                 NaN   \n",
       "1                NaN                NaN                 NaN   \n",
       "2            46200.0           155465.5                 NaN   \n",
       "3                NaN                NaN                 NaN   \n",
       "4            17000.0            11500.0                 NaN   \n",
       "\n",
       "   Open_Date29_mean_30  Open_Date29_mode_30  Open_Date29_nuniq_30  \\\n",
       "0                  NaN                  NaN                   NaN   \n",
       "1                  NaN                  NaN                   NaN   \n",
       "2                  NaN                  NaN                   NaN   \n",
       "3                  NaN                  NaN                   NaN   \n",
       "4                  NaN                  NaN                   NaN   \n",
       "\n",
       "   Open_Date29_maxcount_30  Open_Date29_mode_90  Open_Date29_nuniq_90  \\\n",
       "0                      NaN                  NaN                   NaN   \n",
       "1                      NaN                  NaN                   NaN   \n",
       "2                      NaN                 78.0                  10.0   \n",
       "3                      NaN                  NaN                   NaN   \n",
       "4                      NaN                 49.0                   4.0   \n",
       "\n",
       "   Open_Date29_max_360  Open_Date29_mode_360  Open_Date29_maxcount_360  \\\n",
       "0                310.0                 192.0                       1.0   \n",
       "1                238.0                 124.0                       1.0   \n",
       "2                326.0                  78.0                       4.0   \n",
       "3                305.0                 302.0                       2.0   \n",
       "4                354.0                  49.0                       2.0   \n",
       "\n",
       "   Open_Date29_max_9999  Open_Date29_mean_9999  Open_Date29_mode_9999  \\\n",
       "0                4203.0            1028.750000                  888.0   \n",
       "1                 955.0             439.000000                  124.0   \n",
       "2                5048.0             461.120482                   78.0   \n",
       "3                5685.0            1510.981132                  696.0   \n",
       "4                1087.0             266.541667                   49.0   \n",
       "\n",
       "   Open_Date29_maxcount_9999  Portfolio_Type34_nuniq_30  \\\n",
       "0                        2.0                        NaN   \n",
       "1                        1.0                        NaN   \n",
       "2                        4.0                        NaN   \n",
       "3                        4.0                        NaN   \n",
       "4                        2.0                        NaN   \n",
       "\n",
       "   Portfolio_Type34_nuniq_90  Portfolio_Type34_nuniq_360  \\\n",
       "0                        NaN                         2.0   \n",
       "1                        NaN                         1.0   \n",
       "2                        2.0                         2.0   \n",
       "3                        NaN                         1.0   \n",
       "4                        1.0                         1.0   \n",
       "\n",
       "  Portfolio_Type34_mode_9999  Portfolio_Type34_nuniq_9999  \\\n",
       "0                          R                          3.0   \n",
       "1                          I                          1.0   \n",
       "2                          I                          3.0   \n",
       "3                          I                          2.0   \n",
       "4                          I                          1.0   \n",
       "\n",
       "  Account_Type32_mode_30  Account_Type32_nuniq_30 Account_Type32_mode_90  \\\n",
       "0                    NaN                      NaN                    NaN   \n",
       "1                    NaN                      NaN                    NaN   \n",
       "2                    NaN                      NaN                    5.0   \n",
       "3                    NaN                      NaN                    NaN   \n",
       "4                    NaN                      NaN                    5.0   \n",
       "\n",
       "   Account_Type32_nuniq_90 Account_Type32_mode_360  Account_Type32_nuniq_360  \\\n",
       "0                      NaN                     2.0                       2.0   \n",
       "1                      NaN                     7.0                       1.0   \n",
       "2                      4.0                     5.0                       5.0   \n",
       "3                      NaN                     7.0                       2.0   \n",
       "4                      2.0                     5.0                       4.0   \n",
       "\n",
       "  Account_Type32_mode_9999  Account_Type32_nuniq_9999  \\\n",
       "0                     10.0                        6.0   \n",
       "1                      7.0                        2.0   \n",
       "2                      5.0                        9.0   \n",
       "3                      7.0                        6.0   \n",
       "4                      5.0                        4.0   \n",
       "\n",
       "   Occupation_Code35_nuniq_30  Occupation_Code35_nuniq_90  \\\n",
       "0                         NaN                         NaN   \n",
       "1                         NaN                         NaN   \n",
       "2                         NaN                         1.0   \n",
       "3                         NaN                         NaN   \n",
       "4                         NaN                         1.0   \n",
       "\n",
       "   Occupation_Code35_nuniq_360 CurrencyCode32_mode_360  \\\n",
       "0                          1.0                     INR   \n",
       "1                          1.0                     INR   \n",
       "2                          1.0                     INR   \n",
       "3                          1.0                     INR   \n",
       "4                          2.0                     INR   \n",
       "\n",
       "  CurrencyCode32_mode_9999 AccountHoldertypeCode41_mode_90  \\\n",
       "0                      INR                             NaN   \n",
       "1                      INR                             NaN   \n",
       "2                      INR                             1.0   \n",
       "3                      INR                             NaN   \n",
       "4                      INR                             1.0   \n",
       "\n",
       "   AccountHoldertypeCode41_nuniq_90  AccountHoldertypeCode41_nuniq_360  \\\n",
       "0                               NaN                                1.0   \n",
       "1                               NaN                                1.0   \n",
       "2                               1.0                                1.0   \n",
       "3                               NaN                                1.0   \n",
       "4                               1.0                                1.0   \n",
       "\n",
       "   AccountHoldertypeCode41_nuniq_9999  Payment_History_Profile43_mode_30  \\\n",
       "0                                 2.0                                  0   \n",
       "1                                 1.0                                  0   \n",
       "2                                 2.0                                  0   \n",
       "3                                 1.0                                  0   \n",
       "4                                 1.0                                  0   \n",
       "\n",
       "   Payment_History_Profile43_mode_90  Payment_History_Profile43_nuniq_90  \\\n",
       "0                                  0                                 NaN   \n",
       "1                                  0                                 NaN   \n",
       "2                                  1                                 2.0   \n",
       "3                                  0                                 NaN   \n",
       "4                                  1                                 1.0   \n",
       "\n",
       "   Payment_History_Profile43_mode_360  Payment_History_Profile43_nuniq_360  \\\n",
       "0                                  36                                  2.0   \n",
       "1                                  36                                  2.0   \n",
       "2                                   1                                 12.0   \n",
       "3                                  36                                  2.0   \n",
       "4                                   1                                  6.0   \n",
       "\n",
       "   Payment_History_Profile43_mode_9999  Payment_History_Profile43_nuniq_9999  \\\n",
       "0                                   36                                  12.0   \n",
       "1                                   36                                   3.0   \n",
       "2                                    1                                  27.0   \n",
       "3                                    1                                  23.0   \n",
       "4                                    1                                   8.0   \n",
       "\n",
       "   Date_Closed31_mode_30  Date_Closed31_nuniq_30  Date_Closed31_maxcount_30  \\\n",
       "0                    NaN                     NaN                        NaN   \n",
       "1                    NaN                     NaN                        NaN   \n",
       "2                    NaN                     NaN                        NaN   \n",
       "3                    NaN                     NaN                        NaN   \n",
       "4                    NaN                     NaN                        NaN   \n",
       "\n",
       "   Date_Closed31_max_90  Date_Closed31_min_90  Date_Closed31_mean_90  \\\n",
       "0                   NaN                   NaN                    NaN   \n",
       "1                   NaN                   NaN                    NaN   \n",
       "2                  69.0                  54.0                   61.5   \n",
       "3                   NaN                   NaN                    NaN   \n",
       "4                  66.0                  44.0                   55.0   \n",
       "\n",
       "   Date_Closed31_mode_90  Date_Closed31_nuniq_90  Date_Closed31_maxcount_90  \\\n",
       "0                    NaN                     NaN                        NaN   \n",
       "1                    NaN                     NaN                        NaN   \n",
       "2                   54.0                     3.0                        1.0   \n",
       "3                    NaN                     NaN                        NaN   \n",
       "4                   44.0                     3.0                        1.0   \n",
       "\n",
       "   Date_Closed31_mode_360  Date_Closed31_nuniq_360  \\\n",
       "0                     0.0                      1.0   \n",
       "1                   153.0                      2.0   \n",
       "2                   106.0                     24.0   \n",
       "3                    53.0                      2.0   \n",
       "4                    44.0                     12.0   \n",
       "\n",
       "   Date_Closed31_maxcount_360  Date_Closed31_mean_9999  \\\n",
       "0                         0.0               281.333333   \n",
       "1                         1.0               231.500000   \n",
       "2                         3.0               269.052632   \n",
       "3                         2.0              1145.893617   \n",
       "4                         1.0               182.250000   \n",
       "\n",
       "   Date_Closed31_mode_9999  Date_of_Last_Payment40_nuniq_30  \\\n",
       "0                     88.0                              NaN   \n",
       "1                    153.0                              NaN   \n",
       "2                    106.0                              NaN   \n",
       "3                    630.0                              NaN   \n",
       "4                     44.0                              NaN   \n",
       "\n",
       "   Date_of_Last_Payment40_maxcount_30  Date_of_Last_Payment40_nuniq_90  \\\n",
       "0                                 NaN                              NaN   \n",
       "1                                 NaN                              NaN   \n",
       "2                                 NaN                              4.0   \n",
       "3                                 NaN                              NaN   \n",
       "4                                 NaN                              4.0   \n",
       "\n",
       "   Date_of_Last_Payment40_maxcount_90  Date_of_Last_Payment40_max_360  \\\n",
       "0                                 NaN                            21.0   \n",
       "1                                 NaN                           153.0   \n",
       "2                                 2.0                           296.0   \n",
       "3                                 NaN                            76.0   \n",
       "4                                 2.0                           184.0   \n",
       "\n",
       "   Date_of_Last_Payment40_min_360  Date_of_Last_Payment40_mean_360  \\\n",
       "0                            21.0                        21.000000   \n",
       "1                           153.0                       153.000000   \n",
       "2                            54.0                       119.526316   \n",
       "3                            53.0                        60.666667   \n",
       "4                            34.0                        97.777778   \n",
       "\n",
       "   Date_of_Last_Payment40_mode_360  Date_of_Last_Payment40_maxcount_360  \\\n",
       "0                             21.0                                  2.0   \n",
       "1                            153.0                                  1.0   \n",
       "2                            106.0                                  3.0   \n",
       "3                             53.0                                  2.0   \n",
       "4                             34.0                                  4.0   \n",
       "\n",
       "   Date_of_Last_Payment40_max_9999  Date_of_Last_Payment40_mean_9999  \\\n",
       "0                            461.0                        129.416667   \n",
       "1                            153.0                        153.000000   \n",
       "2                           1716.0                        176.122807   \n",
       "3                           3918.0                       1139.510638   \n",
       "4                            901.0                        163.250000   \n",
       "\n",
       "   Date_of_Last_Payment40_mode_9999  Date_of_Last_Payment40_nuniq_9999  \\\n",
       "0                              46.0                                8.0   \n",
       "1                             153.0                                2.0   \n",
       "2                              73.0                               42.0   \n",
       "3                             630.0                               28.0   \n",
       "4                              34.0                               16.0   \n",
       "\n",
       "   Date_of_Last_Payment40_maxcount_9999  Date_Reported33_nuniq_30  \\\n",
       "0                                   4.0                       NaN   \n",
       "1                                   1.0                       NaN   \n",
       "2                                   4.0                       NaN   \n",
       "3                                   4.0                       NaN   \n",
       "4                                   4.0                       NaN   \n",
       "\n",
       "   Date_Reported33_max_90  Date_Reported33_mode_90  Date_Reported33_nuniq_90  \\\n",
       "0                     NaN                      NaN                       NaN   \n",
       "1                     NaN                      NaN                       NaN   \n",
       "2                    78.0                     47.0                       3.0   \n",
       "3                     NaN                      NaN                       NaN   \n",
       "4                    66.0                     36.0                       2.0   \n",
       "\n",
       "   Date_Reported33_maxcount_90  Date_Reported33_max_360  \\\n",
       "0                          NaN                     21.0   \n",
       "1                          NaN                     77.0   \n",
       "2                          9.0                    269.0   \n",
       "3                          NaN                     32.0   \n",
       "4                          4.0                    158.0   \n",
       "\n",
       "   Date_Reported33_mean_360  Date_Reported33_mode_360  \\\n",
       "0                 21.000000                      21.0   \n",
       "1                 77.000000                      77.0   \n",
       "2                100.131148                      78.0   \n",
       "3                 32.000000                      32.0   \n",
       "4                 78.523810                      66.0   \n",
       "\n",
       "   Date_Reported33_nuniq_360  Date_Reported33_max_9999  \\\n",
       "0                        1.0                     418.0   \n",
       "1                        1.0                     310.0   \n",
       "2                       11.0                    1692.0   \n",
       "3                        1.0                    2438.0   \n",
       "4                        6.0                     889.0   \n",
       "\n",
       "   Date_Reported33_mode_9999  Date_Reported33_nuniq_9999  \\\n",
       "0                       21.0                         7.0   \n",
       "1                       77.0                         2.0   \n",
       "2                       47.0                        22.0   \n",
       "3                      611.0                        24.0   \n",
       "4                       66.0                         8.0   \n",
       "\n",
       "   Date_Reported33_maxcount_9999  DateOfAddition34_nuniq_30  \\\n",
       "0                            6.0                        NaN   \n",
       "1                            2.0                        NaN   \n",
       "2                           22.0                        NaN   \n",
       "3                            9.0                        NaN   \n",
       "4                            8.0                        NaN   \n",
       "\n",
       "   DateOfAddition34_max_90  DateOfAddition34_mean_90  \\\n",
       "0                      NaN                       NaN   \n",
       "1                      NaN                       NaN   \n",
       "2                     78.0                 57.214286   \n",
       "3                      NaN                       NaN   \n",
       "4                     66.0                 42.000000   \n",
       "\n",
       "   DateOfAddition34_nuniq_90  DateOfAddition34_maxcount_90  \\\n",
       "0                        NaN                           NaN   \n",
       "1                        NaN                           NaN   \n",
       "2                        3.0                           8.0   \n",
       "3                        NaN                           NaN   \n",
       "4                        2.0                           4.0   \n",
       "\n",
       "   DateOfAddition34_max_360  DateOfAddition34_mean_360  \\\n",
       "0                     296.0                 250.500000   \n",
       "1                     230.0                 169.000000   \n",
       "2                     300.0                 129.524590   \n",
       "3                     277.0                 175.000000   \n",
       "4                     340.0                 144.761905   \n",
       "\n",
       "   DateOfAddition34_mode_360  DateOfAddition34_maxcount_360  \\\n",
       "0                      205.0                            1.0   \n",
       "1                      108.0                            1.0   \n",
       "2                       78.0                           14.0   \n",
       "3                      124.0                            2.0   \n",
       "4                       97.0                            6.0   \n",
       "\n",
       "   DateOfAddition34_max_9999  DateOfAddition34_min_9999  \\\n",
       "0                     1878.0                      205.0   \n",
       "1                      808.0                      108.0   \n",
       "2                     2543.0                       35.0   \n",
       "3                     2536.0                      124.0   \n",
       "4                     1071.0                       36.0   \n",
       "\n",
       "   DateOfAddition34_mode_9999  DateOfAddition34_nuniq_9999  \\\n",
       "0                       752.0                         11.0   \n",
       "1                       108.0                          3.0   \n",
       "2                        78.0                         29.0   \n",
       "3                       611.0                         26.0   \n",
       "4                        97.0                         11.0   \n",
       "\n",
       "   DateOfAddition34_maxcount_9999  Account_Status34_mode_30  \\\n",
       "0                             2.0                       NaN   \n",
       "1                             1.0                       NaN   \n",
       "2                            14.0                       NaN   \n",
       "3                             9.0                       NaN   \n",
       "4                             6.0                       NaN   \n",
       "\n",
       "   Account_Status34_nuniq_30  Account_Status34_mode_90  \\\n",
       "0                        NaN                       NaN   \n",
       "1                        NaN                       NaN   \n",
       "2                        NaN                      11.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        NaN                      11.0   \n",
       "\n",
       "   Account_Status34_nuniq_90  Account_Status34_nuniq_360  \\\n",
       "0                        NaN                         1.0   \n",
       "1                        NaN                         2.0   \n",
       "2                        3.0                         6.0   \n",
       "3                        NaN                         2.0   \n",
       "4                        2.0                         2.0   \n",
       "\n",
       "  Account_Status34_mode_9999  Account_Status34_nuniq_9999  Month50_sum_30  \\\n",
       "0                         11                          4.0             NaN   \n",
       "1                         13                          2.0             NaN   \n",
       "2                         11                          6.0             NaN   \n",
       "3                         13                          9.0             NaN   \n",
       "4                         13                          3.0             NaN   \n",
       "\n",
       "   Month50_mean_30  Month50_std_30  Month50_sum_90  Month50_mean_90  \\\n",
       "0              NaN             NaN             NaN              NaN   \n",
       "1              NaN             NaN             NaN              NaN   \n",
       "2              NaN             NaN           109.0         7.785714   \n",
       "3              NaN             NaN             NaN              NaN   \n",
       "4              NaN             NaN            44.0         8.800000   \n",
       "\n",
       "   Month50_max_90  Month50_std_90  Month50_max_360  Month50_min_360  \\\n",
       "0             NaN             NaN             12.0             12.0   \n",
       "1             NaN             NaN              8.0              8.0   \n",
       "2             9.0        0.557875             12.0              3.0   \n",
       "3             NaN             NaN             12.0             12.0   \n",
       "4             9.0        0.400000             12.0              5.0   \n",
       "\n",
       "   Month50_mean_9999  Month50_max_9999  Month50_min_9999  Month50_std_9999  \\\n",
       "0          12.000000              12.0              12.0          0.000000   \n",
       "1           9.000000              11.0               8.0          1.414214   \n",
       "2           7.879518              12.0               3.0          2.730451   \n",
       "3           8.566038              12.0               3.0          3.339356   \n",
       "4           8.625000              12.0               5.0          2.269591   \n",
       "\n",
       "   Days_Past_Due58_sum_90  Days_Past_Due58_min_90  Days_Past_Due58_std_90  \\\n",
       "0                     NaN                     NaN                     NaN   \n",
       "1                     NaN                     NaN                     NaN   \n",
       "2                     0.0                     0.0                     0.0   \n",
       "3                     NaN                     NaN                     NaN   \n",
       "4                     0.0                     0.0                     0.0   \n",
       "\n",
       "   Days_Past_Due58_sum_360  Days_Past_Due58_mean_360  Days_Past_Due58_max_360  \\\n",
       "0                      0.0                  0.000000                      0.0   \n",
       "1                      0.0                  0.000000                      0.0   \n",
       "2                    110.0                  2.619048                     54.0   \n",
       "3                    329.0                109.666667                    150.0   \n",
       "4                      0.0                  0.000000                      0.0   \n",
       "\n",
       "   Days_Past_Due58_min_360  Days_Past_Due58_std_360  Days_Past_Due58_sum_9999  \\\n",
       "0                      0.0                 0.000000                     267.0   \n",
       "1                      0.0                 0.000000                     450.0   \n",
       "2                      0.0                11.493171                     110.0   \n",
       "3                     29.0                57.039947                    2918.0   \n",
       "4                      0.0                 0.000000                     114.0   \n",
       "\n",
       "   Days_Past_Due58_max_9999  Days_Past_Due58_min_9999  \\\n",
       "0                     129.0                       0.0   \n",
       "1                     450.0                       0.0   \n",
       "2                      54.0                       0.0   \n",
       "3                     900.0                       0.0   \n",
       "4                      87.0                       0.0   \n",
       "\n",
       "   Days_Past_Due58_std_9999  Duecount53_mean_30  Duecount53_min_30  \\\n",
       "0                 34.132402                 NaN                NaN   \n",
       "1                212.132034                 NaN                NaN   \n",
       "2                  9.393263                 NaN                NaN   \n",
       "3                144.385284                 NaN                NaN   \n",
       "4                 17.977416                 NaN                NaN   \n",
       "\n",
       "   Duecount53_std_30  Duecount53_sum_90  Duecount53_mean_90  \\\n",
       "0                NaN                NaN                 NaN   \n",
       "1                NaN                NaN                 NaN   \n",
       "2                NaN               15.0            1.071429   \n",
       "3                NaN                NaN                 NaN   \n",
       "4                NaN                5.0            1.000000   \n",
       "\n",
       "   Duecount53_max_90  Duecount53_min_90  Duecount53_std_90  \\\n",
       "0                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN   \n",
       "2                2.0                1.0           0.257539   \n",
       "3                NaN                NaN                NaN   \n",
       "4                1.0                1.0           0.000000   \n",
       "\n",
       "   Duecount53_sum_360  Duecount53_mean_360  Duecount53_max_360  \\\n",
       "0                17.0             8.500000                10.0   \n",
       "1                 8.0             4.000000                 6.0   \n",
       "2               119.0             1.950820                 8.0   \n",
       "3                17.0             5.666667                 9.0   \n",
       "4                65.0             3.095238                 9.0   \n",
       "\n",
       "   Duecount53_min_360  Duecount53_std_360  Duecount53_sum_9999  \\\n",
       "0                 7.0            1.500000                266.0   \n",
       "1                 2.0            2.000000                 24.0   \n",
       "2                 1.0            1.562115                649.0   \n",
       "3                 4.0            2.357023                587.0   \n",
       "4                 1.0            2.974571                106.0   \n",
       "\n",
       "   Duecount53_mean_9999  Duecount53_max_9999  Duecount53_min_9999  \\\n",
       "0             22.166667                 55.0                  7.0   \n",
       "1              8.000000                 16.0                  2.0   \n",
       "2              7.819277                 83.0                  1.0   \n",
       "3             11.075472                 83.0                  1.0   \n",
       "4              4.416667                 33.0                  1.0   \n",
       "\n",
       "   Duecount53_std_9999  Duesum51_mean_30  Duesum51_std_30  Duesum51_mean_90  \\\n",
       "0            12.408554               NaN              NaN               NaN   \n",
       "1             5.887841               NaN              NaN               NaN   \n",
       "2            13.668312               NaN              NaN               0.0   \n",
       "3            22.513601               NaN              NaN               NaN   \n",
       "4             6.639005               NaN              NaN               0.0   \n",
       "\n",
       "   Duesum51_max_90  Duesum51_sum_360  Duesum51_mean_360  Duesum51_max_360  \\\n",
       "0              NaN               0.0           0.000000               0.0   \n",
       "1              NaN               0.0           0.000000               0.0   \n",
       "2              0.0             110.0           1.803279              54.0   \n",
       "3              NaN             747.0         249.000000             359.0   \n",
       "4              0.0               0.0           0.000000               0.0   \n",
       "\n",
       "   Duesum51_min_360  Duesum51_std_360  Duesum51_sum_9999  Duesum51_mean_9999  \\\n",
       "0               0.0          0.000000             1294.0          107.833333   \n",
       "1               0.0          0.000000              450.0          150.000000   \n",
       "2               0.0          9.613549              110.0            1.325301   \n",
       "3              29.0        155.563492            81524.0         1538.188679   \n",
       "4               0.0          0.000000              140.0            5.833333   \n",
       "\n",
       "   Duesum51_max_9999  Duesum51_min_9999  Duesum51_std_9999  \\\n",
       "0             1085.0                0.0         295.475276   \n",
       "1              450.0                0.0         212.132034   \n",
       "2               54.0                0.0           8.279905   \n",
       "3            59071.0                0.0        8193.472586   \n",
       "4               87.0                0.0          19.959682   \n",
       "\n",
       "   Amount_Financed35_std_7  Amount_Financed35_max_30  \\\n",
       "0                      NaN                       NaN   \n",
       "1                      NaN                   25000.0   \n",
       "2                      0.0                  100000.0   \n",
       "3                      0.0                   50000.0   \n",
       "4                      0.0                   50000.0   \n",
       "\n",
       "   Amount_Financed35_min_30  Amount_Financed35_std_30  \\\n",
       "0                       NaN                       NaN   \n",
       "1                       0.0              10530.379333   \n",
       "2                       0.0              34692.298217   \n",
       "3                   50000.0                  0.000000   \n",
       "4                       0.0              25000.000000   \n",
       "\n",
       "   Amount_Financed35_count_90  ...  feature_1034_sms  feature_1035_sms  \\\n",
       "0                         3.0  ...                68                23   \n",
       "1                         3.0  ...                24                19   \n",
       "2                        16.0  ...                34                24   \n",
       "3                         2.0  ...                23                 6   \n",
       "4                         4.0  ...                 0                 0   \n",
       "\n",
       "   feature_1036_sms  feature_1037_sms  feature_1038_sms  feature_1039_sms  \\\n",
       "0               215                 7                19                76   \n",
       "1                75                 9                39                10   \n",
       "2                91                 2                 7                60   \n",
       "3               142                 3                 1               101   \n",
       "4                11                 1                 0                 0   \n",
       "\n",
       "   feature_1040_sms  feature_1041_sms  feature_1042_sms  feature_1043_sms  \\\n",
       "0                 9                 1                55                 0   \n",
       "1                 0                 2                47                 0   \n",
       "2                 0                 4                51                 0   \n",
       "3                 0                 0               107                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   feature_1044_sms  feature_1045_sms  feature_1046_sms  feature_1047_sms  \\\n",
       "0               155                 2                94                 1   \n",
       "1                82                 2                43                54   \n",
       "2               143                 6                59                 4   \n",
       "3               236                 5                59                19   \n",
       "4                 4                 0                 2                13   \n",
       "\n",
       "   feature_1048_sms  feature_1049_sms  feature_1050_sms  feature_1051_sms  \\\n",
       "0                 3              1076                30               117   \n",
       "1                47               653                30                36   \n",
       "2                 3               641                30                41   \n",
       "3                24               906                30                29   \n",
       "4                 3               141                13                 1   \n",
       "\n",
       "   feature_1052_sms  feature_1053_sms  feature_1054_sms  feature_1055_sms  \\\n",
       "0                31               299                 8                27   \n",
       "1                27               123                14                62   \n",
       "2                29               111                 2                10   \n",
       "3                 9               201                 4                 2   \n",
       "4                 9                41                 2                 0   \n",
       "\n",
       "   feature_1056_sms  feature_1057_sms  feature_1058_sms  feature_1059_sms  \\\n",
       "0               108                 9                 2                69   \n",
       "1                17                 0                 2                69   \n",
       "2                77                 0                 5                89   \n",
       "3               107                 0                 0               130   \n",
       "4                21                 0                 0                14   \n",
       "\n",
       "   feature_1060_sms  feature_1061_sms  feature_1062_sms  feature_1063_sms  \\\n",
       "0                 0               244                 2               150   \n",
       "1                 0               117                 2                58   \n",
       "2                 1               185                 6                77   \n",
       "3                 0               290                 6                70   \n",
       "4                 0                28                 1                 6   \n",
       "\n",
       "   feature_1064_sms  feature_1065_sms  feature_1066_sms  feature_1067_sms  \\\n",
       "0                 3                 4              1510                54   \n",
       "1                70                56              1395                60   \n",
       "2                 5                 3               886                58   \n",
       "3                27                28              1182                45   \n",
       "4                14                 4               628                43   \n",
       "\n",
       "   feature_1068_sms  feature_1069_sms  feature_1070_sms  feature_1071_sms  \\\n",
       "0               185                42               429                10   \n",
       "1                90                50               232                33   \n",
       "2                53                39               216                 2   \n",
       "3                43                13               301                 5   \n",
       "4                 3                11               200                 6   \n",
       "\n",
       "   feature_1072_sms  feature_1073_sms  feature_1074_sms  feature_1075_sms  \\\n",
       "0                30               154                10                 3   \n",
       "1               151                37                 0                 3   \n",
       "2                10                90                 0                10   \n",
       "3                 3               112                 0                 0   \n",
       "4                 0                88                 0                 1   \n",
       "\n",
       "   feature_1076_sms  feature_1077_sms  feature_1078_sms  feature_1079_sms  \\\n",
       "0               100                 0               326                 4   \n",
       "1               151                 0               273                 7   \n",
       "2               114                 2               225                 9   \n",
       "3               159                 0               369                14   \n",
       "4                65                 0               181                 5   \n",
       "\n",
       "   feature_1080_sms  feature_1081_sms  feature_1082_sms  feature_1083_sms  \\\n",
       "0               204                 4                 6              3000   \n",
       "1                97               145               126              3000   \n",
       "2               102                 9                 5              1931   \n",
       "3                85                41                34              1182   \n",
       "4                40                24                 4              2912   \n",
       "\n",
       "   feature_1084_sms  feature_1085_sms  feature_1086_sms  feature_1087_sms  \\\n",
       "0               269               230                55              1019   \n",
       "1               100               158                77               638   \n",
       "2               400                73                49               551   \n",
       "3                45                43                13               301   \n",
       "4               168               144                84               807   \n",
       "\n",
       "   feature_1088_sms  feature_1089_sms  feature_1090_sms  feature_1091_sms  \\\n",
       "0                11                44               184                12   \n",
       "1                49               226               201                 0   \n",
       "2                 4                16               139                 0   \n",
       "3                 5                 3               112                 0   \n",
       "4                21                 6               425                 1   \n",
       "\n",
       "   feature_1092_sms  feature_1093_sms  feature_1094_sms  feature_1095_sms  \\\n",
       "0                 9               243                 0               715   \n",
       "1                15               303                 9               678   \n",
       "2                19               208                 5               518   \n",
       "3                 0               159                 0               369   \n",
       "4                13               186                 2               895   \n",
       "\n",
       "   feature_1096_sms  feature_1097_sms  feature_1098_sms  feature_1099_sms  \\\n",
       "0                61               369                32                13   \n",
       "1                14               132               292               208   \n",
       "2               163               171                 9                 5   \n",
       "3                14                85                41                34   \n",
       "4                17               208                87                15   \n",
       "\n",
       "   feature_1100_sms  feature_1101_sms  feature_1102_sms  feature_1103_sms  \\\n",
       "0         38.666667         38.666667          0.038667          1.666667   \n",
       "1         29.666667         29.666667          0.029667          1.000000   \n",
       "2         28.666667         28.666667          0.044537          2.333333   \n",
       "3         39.666667         39.666667          0.100677          2.333333   \n",
       "4          0.000000               NaN          0.000000          0.000000   \n",
       "\n",
       "   feature_1104_sms  feature_1105_sms  feature_1106_sms  feature_1107_sms  \\\n",
       "0          0.043103          1.666667          0.043103         10.333333   \n",
       "1          0.033708          2.000000          0.067416          2.666667   \n",
       "2          0.081395          2.000000          0.069767          9.333333   \n",
       "3          0.058824          0.666667          0.016807          7.333333   \n",
       "4               NaN          0.000000               NaN          0.000000   \n",
       "\n",
       "   feature_1108_sms  feature_1109_sms  feature_1110_sms  feature_1111_sms  \\\n",
       "0          0.267241          0.000000          0.000000          1.000000   \n",
       "1          0.089888          1.000000          0.033708          1.333333   \n",
       "2          0.325581          0.000000          0.000000          0.000000   \n",
       "3          0.184874          0.333333          0.008403          0.000000   \n",
       "4               NaN          0.000000               NaN          0.000000   \n",
       "\n",
       "   feature_1112_sms  feature_1113_sms  feature_1114_sms  feature_1115_sms  \\\n",
       "0          0.025862          5.666667          0.146552          0.333333   \n",
       "1          0.044944          1.666667          0.056180          0.000000   \n",
       "2          0.000000          2.333333          0.081395          0.000000   \n",
       "3          0.000000         10.000000          0.252101          0.000000   \n",
       "4               NaN          0.000000               NaN          0.000000   \n",
       "\n",
       "   feature_1116_sms  feature_1117_sms  feature_1118_sms  feature_1119_sms  \\\n",
       "0          0.008621          0.000000          0.000000          1.333333   \n",
       "1          0.000000          0.333333          0.011236          4.333333   \n",
       "2          0.000000          0.000000          0.000000          1.333333   \n",
       "3          0.000000          0.000000          0.000000          1.333333   \n",
       "4               NaN          0.000000               NaN          0.000000   \n",
       "\n",
       "   feature_1120_sms  feature_1121_sms  feature_1122_sms  feature_1123_sms  \\\n",
       "0          0.034483               0.0               0.0         12.000000   \n",
       "1          0.146067               0.0               0.0          6.666667   \n",
       "2          0.046512               0.0               0.0          6.666667   \n",
       "3          0.033613               0.0               0.0         12.666667   \n",
       "4               NaN               0.0               NaN          0.000000   \n",
       "\n",
       "   feature_1124_sms  feature_1125_sms  feature_1126_sms  feature_1127_sms  \\\n",
       "0          0.310345          0.000000          0.000000          4.333333   \n",
       "1          0.224719          0.333333          0.011236          2.000000   \n",
       "2          0.232558          0.333333          0.011628          3.333333   \n",
       "3          0.319328          0.333333          0.008403          2.666667   \n",
       "4               NaN          0.000000               NaN          0.000000   \n",
       "\n",
       "   feature_1128_sms  feature_1129_sms  feature_1130_sms  feature_1131_sms  \\\n",
       "0          0.112069          0.000000          0.000000          0.000000   \n",
       "1          0.067416          2.666667          0.089888          3.666667   \n",
       "2          0.116279          0.666667          0.023256          0.333333   \n",
       "3          0.067227          1.000000          0.025210          1.000000   \n",
       "4               NaN          0.000000               NaN          0.000000   \n",
       "\n",
       "   feature_1132_sms  feature_1133_sms  feature_1134_sms  feature_1135_sms  \\\n",
       "0          0.000000         40.000000         40.000000          0.093333   \n",
       "1          0.123596         23.571429         23.571429          0.055000   \n",
       "2          0.011628         23.857143         23.857143          0.086484   \n",
       "3          0.025210         36.428571         36.428571          0.215736   \n",
       "4               NaN          1.000000          7.000000          0.002404   \n",
       "\n",
       "   feature_1136_sms  feature_1137_sms  feature_1138_sms  feature_1139_sms  \\\n",
       "0          2.857143          0.071429          1.285714          0.032143   \n",
       "1          0.714286          0.030303          1.142857          0.048485   \n",
       "2          1.571429          0.065868          1.142857          0.047904   \n",
       "3          1.714286          0.047059          0.714286          0.019608   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1140_sms  feature_1141_sms  feature_1142_sms  feature_1143_sms  \\\n",
       "0         11.142857          0.278571          0.428571          0.010714   \n",
       "1          2.714286          0.115152          0.428571          0.018182   \n",
       "2          5.857143          0.245509          0.000000          0.000000   \n",
       "3          5.857143          0.160784          0.285714          0.007843   \n",
       "4          0.714286          0.714286          0.000000          0.000000   \n",
       "\n",
       "   feature_1144_sms  feature_1145_sms  feature_1146_sms  feature_1147_sms  \\\n",
       "0          1.000000          0.025000          4.285714          0.107143   \n",
       "1          1.000000          0.042424          0.714286          0.030303   \n",
       "2          0.428571          0.017964          2.571429          0.107784   \n",
       "3          0.000000          0.000000          8.714286          0.239216   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1148_sms  feature_1149_sms  feature_1150_sms  feature_1151_sms  \\\n",
       "0          0.571429          0.014286          0.142857          0.003571   \n",
       "1          0.000000          0.000000          0.142857          0.006061   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.000000          0.000000          0.000000          0.000000   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1152_sms  feature_1153_sms  feature_1154_sms  feature_1155_sms  \\\n",
       "0          2.142857          0.053571               0.0               0.0   \n",
       "1          2.285714          0.096970               0.0               0.0   \n",
       "2          1.000000          0.041916               0.0               0.0   \n",
       "3          2.000000          0.054902               0.0               0.0   \n",
       "4          0.000000          0.000000               0.0               0.0   \n",
       "\n",
       "   feature_1156_sms  feature_1157_sms  feature_1158_sms  feature_1159_sms  \\\n",
       "0         10.857143          0.271429          0.142857          0.003571   \n",
       "1          6.285714          0.266667          0.285714          0.012121   \n",
       "2          6.428571          0.269461          0.428571          0.017964   \n",
       "3         11.428571          0.313725          0.142857          0.003922   \n",
       "4          0.285714          0.285714          0.000000          0.000000   \n",
       "\n",
       "   feature_1160_sms  feature_1161_sms  feature_1162_sms  feature_1163_sms  \\\n",
       "0          4.714286          0.117857          0.000000          0.000000   \n",
       "1          2.571429          0.109091          2.428571          0.103030   \n",
       "2          3.571429          0.149701          0.428571          0.017964   \n",
       "3          2.571429          0.070588          0.857143          0.023529   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1164_sms  feature_1165_sms  feature_1166_sms  feature_1167_sms  \\\n",
       "0          0.285714          0.007143         36.500000         36.500000   \n",
       "1          2.857143          0.121212         20.714286         20.714286   \n",
       "2          0.428571          0.017964         24.285714         24.285714   \n",
       "3          2.142857          0.058824         40.642857         40.642857   \n",
       "4          0.000000          0.000000          0.928571          6.500000   \n",
       "\n",
       "   feature_1168_sms  feature_1169_sms  feature_1170_sms  feature_1171_sms  \\\n",
       "0          0.170333          3.357143          0.091977          1.000000   \n",
       "1          0.096667          1.357143          0.065517          0.714286   \n",
       "2          0.176075          1.428571          0.058824          1.214286   \n",
       "3          0.481387          1.214286          0.029877          0.428571   \n",
       "4          0.004464          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1172_sms  feature_1173_sms  feature_1174_sms  feature_1175_sms  \\\n",
       "0          0.027397         11.071429          0.303327          0.357143   \n",
       "1          0.034483          3.571429          0.172414          0.428571   \n",
       "2          0.050000          4.857143          0.200000          0.071429   \n",
       "3          0.010545          6.357143          0.156415          0.214286   \n",
       "4          0.000000          0.714286          0.769231          0.000000   \n",
       "\n",
       "   feature_1176_sms  feature_1177_sms  feature_1178_sms  feature_1179_sms  \\\n",
       "0          0.009785          0.785714          0.021526          4.142857   \n",
       "1          0.020690          1.071429          0.051724          0.500000   \n",
       "2          0.002941          0.428571          0.017647          3.000000   \n",
       "3          0.005272          0.071429          0.001757          7.000000   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1180_sms  feature_1181_sms  feature_1182_sms  feature_1183_sms  \\\n",
       "0          0.113503          0.642857          0.017613          0.071429   \n",
       "1          0.024138          0.000000          0.000000          0.142857   \n",
       "2          0.123529          0.000000          0.000000          0.285714   \n",
       "3          0.172232          0.000000          0.000000          0.000000   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1184_sms  feature_1185_sms  feature_1186_sms  feature_1187_sms  \\\n",
       "0          0.001957          2.642857          0.072407               0.0   \n",
       "1          0.006897          1.642857          0.079310               0.0   \n",
       "2          0.011765          1.714286          0.070588               0.0   \n",
       "3          0.000000          5.285714          0.130053               0.0   \n",
       "4          0.000000          0.000000          0.000000               0.0   \n",
       "\n",
       "   feature_1188_sms  feature_1189_sms  feature_1190_sms  feature_1191_sms  \\\n",
       "0               0.0          8.214286          0.225049          0.142857   \n",
       "1               0.0          4.071429          0.196552          0.142857   \n",
       "2               0.0          7.571429          0.311765          0.285714   \n",
       "3               0.0         13.571429          0.333919          0.285714   \n",
       "4               0.0          0.214286          0.230769          0.000000   \n",
       "\n",
       "   feature_1192_sms  feature_1193_sms  feature_1194_sms  feature_1195_sms  \\\n",
       "0          0.003914          3.642857          0.099804          0.071429   \n",
       "1          0.006897          2.071429          0.100000          2.642857   \n",
       "2          0.011765          2.928571          0.120588          0.285714   \n",
       "3          0.007030          3.785714          0.093146          0.928571   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1196_sms  feature_1197_sms  feature_1198_sms  feature_1199_sms  \\\n",
       "0          0.001957          0.214286          0.005871         34.761905   \n",
       "1          0.127586          2.357143          0.113793         21.571429   \n",
       "2          0.011765          0.214286          0.008824         23.238095   \n",
       "3          0.022847          1.428571          0.035149         34.619048   \n",
       "4          0.000000          0.000000          0.000000          1.619048   \n",
       "\n",
       "   feature_1200_sms  feature_1201_sms  feature_1202_sms  feature_1203_sms  \\\n",
       "0         34.761905          0.243333          3.238095          0.093151   \n",
       "1         21.571429          0.151000          1.142857          0.052980   \n",
       "2         23.238095          0.252719          1.619048          0.069672   \n",
       "3         34.619048          0.615059          1.095238          0.031637   \n",
       "4          5.666667          0.011676          0.000000          0.000000   \n",
       "\n",
       "   feature_1204_sms  feature_1205_sms  feature_1206_sms  feature_1207_sms  \\\n",
       "0          1.095238          0.031507         10.238095          0.294521   \n",
       "1          0.904762          0.041943          3.571429          0.165563   \n",
       "2          1.142857          0.049180          4.333333          0.186475   \n",
       "3          0.285714          0.008253          6.761905          0.195323   \n",
       "4          0.000000          0.000000          0.523810          0.323529   \n",
       "\n",
       "   feature_1208_sms  feature_1209_sms  feature_1210_sms  feature_1211_sms  \\\n",
       "0          0.333333          0.009589          0.904762          0.026027   \n",
       "1          0.428571          0.019868          1.857143          0.086093   \n",
       "2          0.095238          0.004098          0.333333          0.014344   \n",
       "3          0.142857          0.004127          0.047619          0.001376   \n",
       "4          0.047619          0.029412          0.000000          0.000000   \n",
       "\n",
       "   feature_1212_sms  feature_1213_sms  feature_1214_sms  feature_1215_sms  \\\n",
       "0          3.619048          0.104110          0.428571          0.012329   \n",
       "1          0.476190          0.022075          0.000000          0.000000   \n",
       "2          2.857143          0.122951          0.000000          0.000000   \n",
       "3          4.809524          0.138927          0.000000          0.000000   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1216_sms  feature_1217_sms  feature_1218_sms  feature_1219_sms  \\\n",
       "0          0.047619          0.001370          2.619048          0.075342   \n",
       "1          0.095238          0.004415          2.238095          0.103753   \n",
       "2          0.190476          0.008197          2.428571          0.104508   \n",
       "3          0.000000          0.000000          5.095238          0.147180   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1220_sms  feature_1221_sms  feature_1222_sms  feature_1223_sms  \\\n",
       "0               0.0               0.0          7.380952          0.212329   \n",
       "1               0.0               0.0          3.904762          0.181015   \n",
       "2               0.0               0.0          6.809524          0.293033   \n",
       "3               0.0               0.0         11.238095          0.324622   \n",
       "4               0.0               0.0          0.190476          0.117647   \n",
       "\n",
       "   feature_1224_sms  feature_1225_sms  feature_1226_sms  feature_1227_sms  \\\n",
       "0          0.095238          0.002740          4.476190          0.128767   \n",
       "1          0.095238          0.004415          2.047619          0.094923   \n",
       "2          0.285714          0.012295          2.809524          0.120902   \n",
       "3          0.238095          0.006878          2.809524          0.081155   \n",
       "4          0.000000          0.000000          0.095238          0.058824   \n",
       "\n",
       "   feature_1228_sms  feature_1229_sms  feature_1230_sms  feature_1231_sms  \\\n",
       "0          0.047619          0.001370          0.142857          0.004110   \n",
       "1          2.571429          0.119205          2.238095          0.103753   \n",
       "2          0.190476          0.008197          0.142857          0.006148   \n",
       "3          0.904762          0.026135          1.142857          0.033012   \n",
       "4          0.619048          0.382353          0.142857          0.088235   \n",
       "\n",
       "   feature_1232_sms  feature_1233_sms  feature_1234_sms  feature_1235_sms  \\\n",
       "0         35.866667         35.866667          0.358667          3.900000   \n",
       "1         21.766667         21.766667          0.217667          1.200000   \n",
       "2         21.366667         21.366667          0.331952          1.366667   \n",
       "3         30.200000         30.200000          0.766497          0.966667   \n",
       "4          4.700000         10.846154          0.048420          0.033333   \n",
       "\n",
       "   feature_1236_sms  feature_1237_sms  feature_1238_sms  feature_1239_sms  \\\n",
       "0          0.108736          1.033333          0.028810          9.966667   \n",
       "1          0.055130          0.900000          0.041348          4.100000   \n",
       "2          0.063963          0.966667          0.045242          3.700000   \n",
       "3          0.032009          0.300000          0.009934          6.700000   \n",
       "4          0.007092          0.300000          0.063830          1.366667   \n",
       "\n",
       "   feature_1240_sms  feature_1241_sms  feature_1242_sms  feature_1243_sms  \\\n",
       "0          0.277881          0.266667          0.007435          0.900000   \n",
       "1          0.188361          0.466667          0.021440          2.066667   \n",
       "2          0.173167          0.066667          0.003120          0.333333   \n",
       "3          0.221854          0.133333          0.004415          0.066667   \n",
       "4          0.290780          0.066667          0.014184          0.000000   \n",
       "\n",
       "   feature_1244_sms  feature_1245_sms  feature_1246_sms  feature_1247_sms  \\\n",
       "0          0.025093          3.600000          0.100372               0.3   \n",
       "1          0.094946          0.566667          0.026034               0.0   \n",
       "2          0.015601          2.566667          0.120125               0.0   \n",
       "3          0.002208          3.566667          0.118102               0.0   \n",
       "4          0.000000          0.700000          0.148936               0.0   \n",
       "\n",
       "   feature_1248_sms  feature_1249_sms  feature_1250_sms  feature_1251_sms  \\\n",
       "0          0.008364          0.066667          0.001859          2.300000   \n",
       "1          0.000000          0.066667          0.003063          2.300000   \n",
       "2          0.000000          0.166667          0.007800          2.966667   \n",
       "3          0.000000          0.000000          0.000000          4.333333   \n",
       "4          0.000000          0.000000          0.000000          0.466667   \n",
       "\n",
       "   feature_1252_sms  feature_1253_sms  feature_1254_sms  feature_1255_sms  \\\n",
       "0          0.064126          0.000000           0.00000          8.133333   \n",
       "1          0.105666          0.000000           0.00000          3.900000   \n",
       "2          0.138846          0.033333           0.00156          6.166667   \n",
       "3          0.143488          0.000000           0.00000          9.666667   \n",
       "4          0.099291          0.000000           0.00000          0.933333   \n",
       "\n",
       "   feature_1256_sms  feature_1257_sms  feature_1258_sms  feature_1259_sms  \\\n",
       "0          0.226766          0.066667          0.001859          5.000000   \n",
       "1          0.179173          0.066667          0.003063          1.933333   \n",
       "2          0.288612          0.200000          0.009360          2.566667   \n",
       "3          0.320088          0.200000          0.006623          2.333333   \n",
       "4          0.198582          0.033333          0.007092          0.200000   \n",
       "\n",
       "   feature_1260_sms  feature_1261_sms  feature_1262_sms  feature_1263_sms  \\\n",
       "0          0.139405          0.100000          0.002788          0.133333   \n",
       "1          0.088821          2.333333          0.107198          1.866667   \n",
       "2          0.120125          0.166667          0.007800          0.100000   \n",
       "3          0.077263          0.900000          0.029801          0.933333   \n",
       "4          0.042553          0.466667          0.099291          0.133333   \n",
       "\n",
       "   feature_1264_sms  feature_1265_sms  feature_1266_sms  feature_1267_sms  \\\n",
       "0          0.003717         25.166667         27.962963          0.503333   \n",
       "1          0.085758         23.250000         23.250000          0.465000   \n",
       "2          0.004680         14.766667         15.275862          0.458830   \n",
       "3          0.030905         19.700000         26.266667          1.000000   \n",
       "4          0.028369         10.466667         14.604651          0.215659   \n",
       "\n",
       "   feature_1268_sms  feature_1269_sms  feature_1270_sms  feature_1271_sms  \\\n",
       "0          3.083333          0.122517          0.700000          0.027815   \n",
       "1          1.500000          0.064516          0.833333          0.035842   \n",
       "2          0.883333          0.059819          0.650000          0.044018   \n",
       "3          0.716667          0.036379          0.216667          0.010998   \n",
       "4          0.050000          0.004777          0.183333          0.017516   \n",
       "\n",
       "   feature_1272_sms  feature_1273_sms  feature_1274_sms  feature_1275_sms  \\\n",
       "0          7.150000          0.284106          0.166667          0.006623   \n",
       "1          3.866667          0.166308          0.550000          0.023656   \n",
       "2          3.600000          0.243792          0.033333          0.002257   \n",
       "3          5.016667          0.254653          0.083333          0.004230   \n",
       "4          3.333333          0.318471          0.100000          0.009554   \n",
       "\n",
       "   feature_1276_sms  feature_1277_sms  feature_1278_sms  feature_1279_sms  \\\n",
       "0          0.500000          0.019868          2.566667          0.101987   \n",
       "1          2.516667          0.108244          0.616667          0.026523   \n",
       "2          0.166667          0.011287          1.500000          0.101580   \n",
       "3          0.050000          0.002538          1.866667          0.094755   \n",
       "4          0.000000          0.000000          1.466667          0.140127   \n",
       "\n",
       "   feature_1280_sms  feature_1281_sms  feature_1282_sms  feature_1283_sms  \\\n",
       "0          0.166667          0.006623          0.050000          0.001987   \n",
       "1          0.000000          0.000000          0.050000          0.002151   \n",
       "2          0.000000          0.000000          0.166667          0.011287   \n",
       "3          0.000000          0.000000          0.000000          0.000000   \n",
       "4          0.000000          0.000000          0.016667          0.001592   \n",
       "\n",
       "   feature_1284_sms  feature_1285_sms  feature_1286_sms  feature_1287_sms  \\\n",
       "0          1.666667          0.066225          0.000000          0.000000   \n",
       "1          2.516667          0.108244          0.000000          0.000000   \n",
       "2          1.900000          0.128668          0.033333          0.002257   \n",
       "3          2.650000          0.134518          0.000000          0.000000   \n",
       "4          1.083333          0.103503          0.000000          0.000000   \n",
       "\n",
       "   feature_1288_sms  feature_1289_sms  feature_1290_sms  feature_1291_sms  \\\n",
       "0          5.433333          0.215894          0.066667          0.002649   \n",
       "1          4.550000          0.195699          0.116667          0.005018   \n",
       "2          3.750000          0.253950          0.150000          0.010158   \n",
       "3          6.150000          0.312183          0.233333          0.011844   \n",
       "4          3.016667          0.288217          0.083333          0.007962   \n",
       "\n",
       "   feature_1292_sms  feature_1293_sms  feature_1294_sms  feature_1295_sms  \\\n",
       "0          3.400000          0.135099          0.066667          0.002649   \n",
       "1          1.616667          0.069534          2.416667          0.103943   \n",
       "2          1.700000          0.115124          0.150000          0.010158   \n",
       "3          1.416667          0.071912          0.683333          0.034687   \n",
       "4          0.666667          0.063694          0.400000          0.038217   \n",
       "\n",
       "   feature_1296_sms  feature_1297_sms  feature_1298_sms  feature_1299_sms  \\\n",
       "0          0.100000          0.003974             3.000         11.152416   \n",
       "1          2.100000          0.090323             3.000         30.000000   \n",
       "2          0.083333          0.005643             1.931          4.827500   \n",
       "3          0.566667          0.028765             1.182         26.266667   \n",
       "4          0.066667          0.006369             2.912         17.333333   \n",
       "\n",
       "   feature_1300_sms  feature_1301_sms  feature_1302_sms  feature_1303_sms  \\\n",
       "0               1.0             0.230          0.076667             0.055   \n",
       "1               1.0             0.158          0.052667             0.077   \n",
       "2               1.0             0.073          0.037804             0.049   \n",
       "3               1.0             0.043          0.036379             0.013   \n",
       "4               1.0             0.144          0.049451             0.084   \n",
       "\n",
       "   feature_1304_sms  feature_1305_sms  feature_1306_sms  feature_1307_sms  \\\n",
       "0          0.018333             1.019          0.339667             0.011   \n",
       "1          0.025667             0.638          0.212667             0.049   \n",
       "2          0.025375             0.551          0.285344             0.004   \n",
       "3          0.010998             0.301          0.254653             0.005   \n",
       "4          0.028846             0.807          0.277129             0.021   \n",
       "\n",
       "   feature_1308_sms  feature_1309_sms  feature_1310_sms  feature_1311_sms  \\\n",
       "0          0.003667             0.044          0.014667             0.184   \n",
       "1          0.016333             0.226          0.075333             0.201   \n",
       "2          0.002071             0.016          0.008286             0.139   \n",
       "3          0.004230             0.003          0.002538             0.112   \n",
       "4          0.007212             0.006          0.002060             0.425   \n",
       "\n",
       "   feature_1312_sms  feature_1313_sms  feature_1314_sms  feature_1315_sms  \\\n",
       "0          0.061333             0.012          0.004000             0.009   \n",
       "1          0.067000             0.000          0.000000             0.015   \n",
       "2          0.071983             0.000          0.000000             0.019   \n",
       "3          0.094755             0.000          0.000000             0.000   \n",
       "4          0.145948             0.001          0.000343             0.013   \n",
       "\n",
       "   feature_1316_sms  feature_1317_sms  feature_1318_sms  feature_1319_sms  \\\n",
       "0          0.003000             0.243          0.081000             0.000   \n",
       "1          0.005000             0.303          0.101000             0.009   \n",
       "2          0.009839             0.208          0.107716             0.005   \n",
       "3          0.000000             0.159          0.134518             0.000   \n",
       "4          0.004464             0.186          0.063874             0.002   \n",
       "\n",
       "   feature_1320_sms  feature_1321_sms  feature_1322_sms  feature_1323_sms  \\\n",
       "0          0.000000             0.715          0.238333             0.061   \n",
       "1          0.003000             0.678          0.226000             0.014   \n",
       "2          0.002589             0.518          0.268255             0.163   \n",
       "3          0.000000             0.369          0.312183             0.014   \n",
       "4          0.000687             0.895          0.307349             0.017   \n",
       "\n",
       "   feature_1324_sms  feature_1325_sms  feature_1326_sms  feature_1327_sms  \\\n",
       "0          0.020333             0.369          0.123000             0.032   \n",
       "1          0.004667             0.132          0.044000             0.292   \n",
       "2          0.084412             0.171          0.088555             0.009   \n",
       "3          0.011844             0.085          0.071912             0.041   \n",
       "4          0.005838             0.208          0.071429             0.087   \n",
       "\n",
       "   feature_1328_sms  feature_1329_sms  feature_1330_sms  order_id         pan  \\\n",
       "0          0.010667             0.013          0.004333  XQDI8W8E  AAHPO6801A   \n",
       "1          0.097333             0.208          0.069333  NKNSPUYG  AAIPI5141G   \n",
       "2          0.004661             0.005          0.002589  3WXC1GIM  AAIPZ7980L   \n",
       "3          0.034687             0.034          0.028765  OYD0NERZ  AALPF3903A   \n",
       "4          0.029876             0.015          0.005151  U67MOCC1  AALPF4279M   \n",
       "\n",
       "   label_y  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 1717 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e831527f",
   "metadata": {},
   "source": [
    "##### 验证神经网络模型，取开头代码的逻辑 加工出trainx ootx，如下训练神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "989d8bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9123, 1802)\n",
      "1.0    5631\n",
      "0.0    2040\n",
      "Name: label, dtype: int64\n",
      "1.0    1035\n",
      "0.0     417\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BureauScore</th>\n",
       "      <th>MissingRate</th>\n",
       "      <th>Len_Name</th>\n",
       "      <th>Tel_nuniq</th>\n",
       "      <th>Email_nuniq</th>\n",
       "      <th>Len_of_addrs</th>\n",
       "      <th>City_nuniq</th>\n",
       "      <th>Current_State</th>\n",
       "      <th>CreditAccountActive</th>\n",
       "      <th>CreditAccountTotal</th>\n",
       "      <th>CreditAccountActivePor</th>\n",
       "      <th>Outstanding_Balance_Secured</th>\n",
       "      <th>Outstanding_Balance_UnSecured_Percentage</th>\n",
       "      <th>Outstanding_Balance_All</th>\n",
       "      <th>Outstanding_Balance_Secured_Percentage</th>\n",
       "      <th>Outstanding_Balance_UnSecured</th>\n",
       "      <th>Diff_dateBirth</th>\n",
       "      <th>State_nuniq</th>\n",
       "      <th>Birth_nuniq</th>\n",
       "      <th>TotalCAPSLast90Days</th>\n",
       "      <th>TotalCAPSLast7Days</th>\n",
       "      <th>TotalCAPSLast30Days</th>\n",
       "      <th>TotalCAPSLast180Days</th>\n",
       "      <th>CAPSLast30Days</th>\n",
       "      <th>CAPSLast7Days</th>\n",
       "      <th>CAPSLast180Days</th>\n",
       "      <th>NonCreditCAPSLast180Days</th>\n",
       "      <th>Pin_nuniq</th>\n",
       "      <th>Pan_nuniq</th>\n",
       "      <th>Ident_nuniq</th>\n",
       "      <th>Name_nuniq2</th>\n",
       "      <th>Tel_nuniq2</th>\n",
       "      <th>Email_nuniq2</th>\n",
       "      <th>Pan_nuniq2</th>\n",
       "      <th>Account_nuniq2</th>\n",
       "      <th>Ident_nuniq2</th>\n",
       "      <th>Gender_nuniq</th>\n",
       "      <th>Amount_Past_Due35_sum_30</th>\n",
       "      <th>Amount_Past_Due35_min_30</th>\n",
       "      <th>Amount_Past_Due35_sum_90</th>\n",
       "      <th>Amount_Past_Due35_mean_90</th>\n",
       "      <th>Amount_Past_Due35_max_90</th>\n",
       "      <th>Amount_Past_Due35_min_90</th>\n",
       "      <th>Amount_Past_Due35_std_90</th>\n",
       "      <th>Amount_Past_Due35_sum_360</th>\n",
       "      <th>Amount_Past_Due35_mean_360</th>\n",
       "      <th>Amount_Past_Due35_max_360</th>\n",
       "      <th>Amount_Past_Due35_std_360</th>\n",
       "      <th>Amount_Past_Due35_sum_9999</th>\n",
       "      <th>Amount_Past_Due35_max_9999</th>\n",
       "      <th>Amount_Past_Due35_min_9999</th>\n",
       "      <th>Amount_Past_Due35_std_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_9999</th>\n",
       "      <th>Terms_Duration34_sum_30</th>\n",
       "      <th>Terms_Duration34_std_30</th>\n",
       "      <th>Terms_Duration34_sum_90</th>\n",
       "      <th>Terms_Duration34_std_90</th>\n",
       "      <th>Terms_Duration34_mean_360</th>\n",
       "      <th>Terms_Duration34_max_360</th>\n",
       "      <th>Terms_Duration34_min_360</th>\n",
       "      <th>Terms_Duration34_std_360</th>\n",
       "      <th>Terms_Duration34_sum_9999</th>\n",
       "      <th>Terms_Duration34_mean_9999</th>\n",
       "      <th>Terms_Duration34_max_9999</th>\n",
       "      <th>Terms_Duration34_min_9999</th>\n",
       "      <th>Terms_Duration34_std_9999</th>\n",
       "      <th>Payment_Rating34_sum_90</th>\n",
       "      <th>Payment_Rating34_mean_90</th>\n",
       "      <th>Payment_Rating34_max_90</th>\n",
       "      <th>Payment_Rating34_min_90</th>\n",
       "      <th>Payment_Rating34_std_90</th>\n",
       "      <th>Payment_Rating34_sum_360</th>\n",
       "      <th>Payment_Rating34_mean_360</th>\n",
       "      <th>Payment_Rating34_max_360</th>\n",
       "      <th>Payment_Rating34_min_360</th>\n",
       "      <th>Payment_Rating34_std_360</th>\n",
       "      <th>Payment_Rating34_sum_9999</th>\n",
       "      <th>Payment_Rating34_mean_9999</th>\n",
       "      <th>Payment_Rating34_max_9999</th>\n",
       "      <th>Payment_Rating34_min_9999</th>\n",
       "      <th>Payment_Rating34_std_9999</th>\n",
       "      <th>Current_Balance35_mean_30</th>\n",
       "      <th>Current_Balance35_min_30</th>\n",
       "      <th>Current_Balance35_std_30</th>\n",
       "      <th>Current_Balance35_sum_90</th>\n",
       "      <th>Current_Balance35_mean_90</th>\n",
       "      <th>Current_Balance35_max_90</th>\n",
       "      <th>Current_Balance35_std_90</th>\n",
       "      <th>Current_Balance35_sum_360</th>\n",
       "      <th>Current_Balance35_max_360</th>\n",
       "      <th>Current_Balance35_std_360</th>\n",
       "      <th>Current_Balance35_max_9999</th>\n",
       "      <th>Current_Balance35_std_9999</th>\n",
       "      <th>Settlement_Amount37_max_360</th>\n",
       "      <th>Settlement_Amount37_min_360</th>\n",
       "      <th>Settlement_Amount37_std_360</th>\n",
       "      <th>Settlement_Amount37_sum_9999</th>\n",
       "      <th>Settlement_Amount37_mean_9999</th>\n",
       "      <th>Settlement_Amount37_max_9999</th>\n",
       "      <th>Settlement_Amount37_min_9999</th>\n",
       "      <th>Settlement_Amount37_std_9999</th>\n",
       "      <th>Value_of_Collateral39_std_90</th>\n",
       "      <th>Value_of_Collateral39_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_360</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_360</th>\n",
       "      <th>Written_Off_Amt_Total41_min_360</th>\n",
       "      <th>Written_Off_Amt_Total41_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_max_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_min_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_std_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_mean_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_std_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_max_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_9999</th>\n",
       "      <th>Rate_of_Interest36_sum_30</th>\n",
       "      <th>Rate_of_Interest36_std_30</th>\n",
       "      <th>Rate_of_Interest36_sum_90</th>\n",
       "      <th>Rate_of_Interest36_mean_90</th>\n",
       "      <th>Rate_of_Interest36_max_90</th>\n",
       "      <th>Rate_of_Interest36_std_90</th>\n",
       "      <th>Rate_of_Interest36_sum_360</th>\n",
       "      <th>Rate_of_Interest36_mean_360</th>\n",
       "      <th>Rate_of_Interest36_max_360</th>\n",
       "      <th>Rate_of_Interest36_min_360</th>\n",
       "      <th>Rate_of_Interest36_std_360</th>\n",
       "      <th>Rate_of_Interest36_sum_9999</th>\n",
       "      <th>Rate_of_Interest36_mean_9999</th>\n",
       "      <th>Rate_of_Interest36_max_9999</th>\n",
       "      <th>Rate_of_Interest36_min_9999</th>\n",
       "      <th>Rate_of_Interest36_std_9999</th>\n",
       "      <th>Repayment_Tenure36_std_30</th>\n",
       "      <th>Repayment_Tenure36_mean_90</th>\n",
       "      <th>Repayment_Tenure36_max_90</th>\n",
       "      <th>Repayment_Tenure36_min_90</th>\n",
       "      <th>Repayment_Tenure36_std_90</th>\n",
       "      <th>Repayment_Tenure36_sum_360</th>\n",
       "      <th>Repayment_Tenure36_mean_360</th>\n",
       "      <th>Repayment_Tenure36_min_360</th>\n",
       "      <th>Repayment_Tenure36_std_360</th>\n",
       "      <th>Repayment_Tenure36_mean_9999</th>\n",
       "      <th>Repayment_Tenure36_min_9999</th>\n",
       "      <th>Repayment_Tenure36_std_9999</th>\n",
       "      <th>Income26_count_360</th>\n",
       "      <th>Income26_std_360</th>\n",
       "      <th>Open_Date29_max_30</th>\n",
       "      <th>Open_Date29_min_30</th>\n",
       "      <th>Open_Date29_mean_30</th>\n",
       "      <th>Open_Date29_nuniq_30</th>\n",
       "      <th>Open_Date29_maxcount_30</th>\n",
       "      <th>Open_Date29_max_90</th>\n",
       "      <th>Open_Date29_mean_90</th>\n",
       "      <th>Open_Date29_mode_90</th>\n",
       "      <th>Open_Date29_nuniq_90</th>\n",
       "      <th>Open_Date29_maxcount_90</th>\n",
       "      <th>Open_Date29_max_360</th>\n",
       "      <th>Open_Date29_mean_360</th>\n",
       "      <th>Open_Date29_mode_360</th>\n",
       "      <th>Open_Date29_nuniq_360</th>\n",
       "      <th>Open_Date29_maxcount_360</th>\n",
       "      <th>Open_Date29_max_9999</th>\n",
       "      <th>Open_Date29_mean_9999</th>\n",
       "      <th>Open_Date29_mode_9999</th>\n",
       "      <th>Open_Date29_maxcount_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_30</th>\n",
       "      <th>Portfolio_Type34_nuniq_90</th>\n",
       "      <th>Portfolio_Type34_nuniq_360</th>\n",
       "      <th>Portfolio_Type34_nuniq_9999</th>\n",
       "      <th>Account_Type32_nuniq_30</th>\n",
       "      <th>Account_Type32_nuniq_90</th>\n",
       "      <th>Account_Type32_nuniq_360</th>\n",
       "      <th>Account_Type32_nuniq_9999</th>\n",
       "      <th>Occupation_Code35_nuniq_30</th>\n",
       "      <th>Occupation_Code35_nuniq_90</th>\n",
       "      <th>Occupation_Code35_nuniq_360</th>\n",
       "      <th>Occupation_Code35_nuniq_9999</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_360</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_9999</th>\n",
       "      <th>Payment_History_Profile43_mode_30</th>\n",
       "      <th>Payment_History_Profile43_mode_90</th>\n",
       "      <th>Payment_History_Profile43_nuniq_90</th>\n",
       "      <th>Payment_History_Profile43_mode_360</th>\n",
       "      <th>Payment_History_Profile43_nuniq_360</th>\n",
       "      <th>Payment_History_Profile43_mode_9999</th>\n",
       "      <th>Payment_History_Profile43_nuniq_9999</th>\n",
       "      <th>Date_Closed31_nuniq_30</th>\n",
       "      <th>Date_Closed31_maxcount_30</th>\n",
       "      <th>Date_Closed31_max_90</th>\n",
       "      <th>Date_Closed31_min_90</th>\n",
       "      <th>Date_Closed31_mean_90</th>\n",
       "      <th>Date_Closed31_mode_90</th>\n",
       "      <th>Date_Closed31_nuniq_90</th>\n",
       "      <th>Date_Closed31_maxcount_90</th>\n",
       "      <th>Date_Closed31_min_360</th>\n",
       "      <th>Date_Closed31_mode_360</th>\n",
       "      <th>Date_Closed31_nuniq_360</th>\n",
       "      <th>Date_Closed31_maxcount_360</th>\n",
       "      <th>Date_Closed31_max_9999</th>\n",
       "      <th>Date_Closed31_min_9999</th>\n",
       "      <th>Date_Closed31_mean_9999</th>\n",
       "      <th>Date_Closed31_mode_9999</th>\n",
       "      <th>Date_Closed31_nuniq_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_30</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_30</th>\n",
       "      <th>Date_of_Last_Payment40_min_90</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_90</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_90</th>\n",
       "      <th>Date_of_Last_Payment40_max_360</th>\n",
       "      <th>Date_of_Last_Payment40_min_360</th>\n",
       "      <th>Date_of_Last_Payment40_mean_360</th>\n",
       "      <th>Date_of_Last_Payment40_mode_360</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_360</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_360</th>\n",
       "      <th>Date_of_Last_Payment40_max_9999</th>\n",
       "      <th>Date_of_Last_Payment40_min_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mean_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_9999</th>\n",
       "      <th>Date_Reported33_nuniq_30</th>\n",
       "      <th>Date_Reported33_max_90</th>\n",
       "      <th>Date_Reported33_mean_90</th>\n",
       "      <th>Date_Reported33_mode_90</th>\n",
       "      <th>Date_Reported33_nuniq_90</th>\n",
       "      <th>Date_Reported33_maxcount_90</th>\n",
       "      <th>Date_Reported33_max_360</th>\n",
       "      <th>Date_Reported33_mean_360</th>\n",
       "      <th>Date_Reported33_mode_360</th>\n",
       "      <th>Date_Reported33_nuniq_360</th>\n",
       "      <th>Date_Reported33_maxcount_360</th>\n",
       "      <th>Date_Reported33_max_9999</th>\n",
       "      <th>Date_Reported33_mean_9999</th>\n",
       "      <th>Date_Reported33_mode_9999</th>\n",
       "      <th>Date_Reported33_nuniq_9999</th>\n",
       "      <th>Date_Reported33_maxcount_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_30</th>\n",
       "      <th>DateOfAddition34_max_90</th>\n",
       "      <th>DateOfAddition34_mean_90</th>\n",
       "      <th>DateOfAddition34_mode_90</th>\n",
       "      <th>DateOfAddition34_nuniq_90</th>\n",
       "      <th>DateOfAddition34_maxcount_90</th>\n",
       "      <th>DateOfAddition34_max_360</th>\n",
       "      <th>DateOfAddition34_mean_360</th>\n",
       "      <th>DateOfAddition34_mode_360</th>\n",
       "      <th>DateOfAddition34_nuniq_360</th>\n",
       "      <th>DateOfAddition34_maxcount_360</th>\n",
       "      <th>DateOfAddition34_max_9999</th>\n",
       "      <th>DateOfAddition34_mean_9999</th>\n",
       "      <th>DateOfAddition34_mode_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_9999</th>\n",
       "      <th>DateOfAddition34_maxcount_9999</th>\n",
       "      <th>Account_Status34_mode_30</th>\n",
       "      <th>Account_Status34_nuniq_30</th>\n",
       "      <th>Account_Status34_mode_90</th>\n",
       "      <th>Account_Status34_nuniq_90</th>\n",
       "      <th>Account_Status34_mode_360</th>\n",
       "      <th>Account_Status34_nuniq_360</th>\n",
       "      <th>Account_Status34_nuniq_9999</th>\n",
       "      <th>Month50_sum_30</th>\n",
       "      <th>Month50_max_30</th>\n",
       "      <th>Month50_std_30</th>\n",
       "      <th>Month50_sum_90</th>\n",
       "      <th>Month50_mean_90</th>\n",
       "      <th>Month50_max_90</th>\n",
       "      <th>Month50_min_90</th>\n",
       "      <th>Month50_std_90</th>\n",
       "      <th>Month50_sum_360</th>\n",
       "      <th>Month50_min_360</th>\n",
       "      <th>Month50_std_360</th>\n",
       "      <th>Month50_sum_9999</th>\n",
       "      <th>Month50_mean_9999</th>\n",
       "      <th>Month50_max_9999</th>\n",
       "      <th>Month50_min_9999</th>\n",
       "      <th>Month50_std_9999</th>\n",
       "      <th>Days_Past_Due58_max_30</th>\n",
       "      <th>Days_Past_Due58_min_30</th>\n",
       "      <th>Days_Past_Due58_mean_90</th>\n",
       "      <th>Days_Past_Due58_max_90</th>\n",
       "      <th>Days_Past_Due58_min_90</th>\n",
       "      <th>Days_Past_Due58_std_90</th>\n",
       "      <th>Days_Past_Due58_sum_360</th>\n",
       "      <th>Days_Past_Due58_mean_360</th>\n",
       "      <th>Days_Past_Due58_max_360</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_1031_sms</th>\n",
       "      <th>feature_1032_sms</th>\n",
       "      <th>feature_1033_sms</th>\n",
       "      <th>feature_1034_sms</th>\n",
       "      <th>feature_1035_sms</th>\n",
       "      <th>feature_1036_sms</th>\n",
       "      <th>feature_1037_sms</th>\n",
       "      <th>feature_1038_sms</th>\n",
       "      <th>feature_1039_sms</th>\n",
       "      <th>feature_1040_sms</th>\n",
       "      <th>feature_1041_sms</th>\n",
       "      <th>feature_1042_sms</th>\n",
       "      <th>feature_1043_sms</th>\n",
       "      <th>feature_1044_sms</th>\n",
       "      <th>feature_1045_sms</th>\n",
       "      <th>feature_1046_sms</th>\n",
       "      <th>feature_1047_sms</th>\n",
       "      <th>feature_1048_sms</th>\n",
       "      <th>feature_1049_sms</th>\n",
       "      <th>feature_1050_sms</th>\n",
       "      <th>feature_1051_sms</th>\n",
       "      <th>feature_1052_sms</th>\n",
       "      <th>feature_1053_sms</th>\n",
       "      <th>feature_1054_sms</th>\n",
       "      <th>feature_1055_sms</th>\n",
       "      <th>feature_1056_sms</th>\n",
       "      <th>feature_1057_sms</th>\n",
       "      <th>feature_1058_sms</th>\n",
       "      <th>feature_1059_sms</th>\n",
       "      <th>feature_1060_sms</th>\n",
       "      <th>feature_1061_sms</th>\n",
       "      <th>feature_1062_sms</th>\n",
       "      <th>feature_1063_sms</th>\n",
       "      <th>feature_1064_sms</th>\n",
       "      <th>feature_1065_sms</th>\n",
       "      <th>feature_1066_sms</th>\n",
       "      <th>feature_1067_sms</th>\n",
       "      <th>feature_1068_sms</th>\n",
       "      <th>feature_1069_sms</th>\n",
       "      <th>feature_1070_sms</th>\n",
       "      <th>feature_1071_sms</th>\n",
       "      <th>feature_1072_sms</th>\n",
       "      <th>feature_1073_sms</th>\n",
       "      <th>feature_1074_sms</th>\n",
       "      <th>feature_1075_sms</th>\n",
       "      <th>feature_1076_sms</th>\n",
       "      <th>feature_1077_sms</th>\n",
       "      <th>feature_1078_sms</th>\n",
       "      <th>feature_1079_sms</th>\n",
       "      <th>feature_1080_sms</th>\n",
       "      <th>feature_1081_sms</th>\n",
       "      <th>feature_1082_sms</th>\n",
       "      <th>feature_1083_sms</th>\n",
       "      <th>feature_1084_sms</th>\n",
       "      <th>feature_1085_sms</th>\n",
       "      <th>feature_1086_sms</th>\n",
       "      <th>feature_1087_sms</th>\n",
       "      <th>feature_1088_sms</th>\n",
       "      <th>feature_1089_sms</th>\n",
       "      <th>feature_1090_sms</th>\n",
       "      <th>feature_1091_sms</th>\n",
       "      <th>feature_1092_sms</th>\n",
       "      <th>feature_1093_sms</th>\n",
       "      <th>feature_1094_sms</th>\n",
       "      <th>feature_1095_sms</th>\n",
       "      <th>feature_1096_sms</th>\n",
       "      <th>feature_1097_sms</th>\n",
       "      <th>feature_1098_sms</th>\n",
       "      <th>feature_1099_sms</th>\n",
       "      <th>feature_1100_sms</th>\n",
       "      <th>feature_1101_sms</th>\n",
       "      <th>feature_1102_sms</th>\n",
       "      <th>feature_1103_sms</th>\n",
       "      <th>feature_1104_sms</th>\n",
       "      <th>feature_1105_sms</th>\n",
       "      <th>feature_1106_sms</th>\n",
       "      <th>feature_1107_sms</th>\n",
       "      <th>feature_1108_sms</th>\n",
       "      <th>feature_1109_sms</th>\n",
       "      <th>feature_1110_sms</th>\n",
       "      <th>feature_1111_sms</th>\n",
       "      <th>feature_1112_sms</th>\n",
       "      <th>feature_1113_sms</th>\n",
       "      <th>feature_1114_sms</th>\n",
       "      <th>feature_1115_sms</th>\n",
       "      <th>feature_1116_sms</th>\n",
       "      <th>feature_1117_sms</th>\n",
       "      <th>feature_1118_sms</th>\n",
       "      <th>feature_1119_sms</th>\n",
       "      <th>feature_1120_sms</th>\n",
       "      <th>feature_1121_sms</th>\n",
       "      <th>feature_1122_sms</th>\n",
       "      <th>feature_1123_sms</th>\n",
       "      <th>feature_1124_sms</th>\n",
       "      <th>feature_1125_sms</th>\n",
       "      <th>feature_1126_sms</th>\n",
       "      <th>feature_1127_sms</th>\n",
       "      <th>feature_1128_sms</th>\n",
       "      <th>feature_1129_sms</th>\n",
       "      <th>feature_1130_sms</th>\n",
       "      <th>feature_1131_sms</th>\n",
       "      <th>feature_1132_sms</th>\n",
       "      <th>feature_1133_sms</th>\n",
       "      <th>feature_1134_sms</th>\n",
       "      <th>feature_1135_sms</th>\n",
       "      <th>feature_1136_sms</th>\n",
       "      <th>feature_1137_sms</th>\n",
       "      <th>feature_1138_sms</th>\n",
       "      <th>feature_1139_sms</th>\n",
       "      <th>feature_1140_sms</th>\n",
       "      <th>feature_1141_sms</th>\n",
       "      <th>feature_1142_sms</th>\n",
       "      <th>feature_1143_sms</th>\n",
       "      <th>feature_1144_sms</th>\n",
       "      <th>feature_1145_sms</th>\n",
       "      <th>feature_1146_sms</th>\n",
       "      <th>feature_1147_sms</th>\n",
       "      <th>feature_1148_sms</th>\n",
       "      <th>feature_1149_sms</th>\n",
       "      <th>feature_1150_sms</th>\n",
       "      <th>feature_1151_sms</th>\n",
       "      <th>feature_1152_sms</th>\n",
       "      <th>feature_1153_sms</th>\n",
       "      <th>feature_1154_sms</th>\n",
       "      <th>feature_1155_sms</th>\n",
       "      <th>feature_1156_sms</th>\n",
       "      <th>feature_1157_sms</th>\n",
       "      <th>feature_1158_sms</th>\n",
       "      <th>feature_1159_sms</th>\n",
       "      <th>feature_1160_sms</th>\n",
       "      <th>feature_1161_sms</th>\n",
       "      <th>feature_1162_sms</th>\n",
       "      <th>feature_1163_sms</th>\n",
       "      <th>feature_1164_sms</th>\n",
       "      <th>feature_1165_sms</th>\n",
       "      <th>feature_1166_sms</th>\n",
       "      <th>feature_1167_sms</th>\n",
       "      <th>feature_1168_sms</th>\n",
       "      <th>feature_1169_sms</th>\n",
       "      <th>feature_1170_sms</th>\n",
       "      <th>feature_1171_sms</th>\n",
       "      <th>feature_1172_sms</th>\n",
       "      <th>feature_1173_sms</th>\n",
       "      <th>feature_1174_sms</th>\n",
       "      <th>feature_1175_sms</th>\n",
       "      <th>feature_1176_sms</th>\n",
       "      <th>feature_1177_sms</th>\n",
       "      <th>feature_1178_sms</th>\n",
       "      <th>feature_1179_sms</th>\n",
       "      <th>feature_1180_sms</th>\n",
       "      <th>feature_1181_sms</th>\n",
       "      <th>feature_1182_sms</th>\n",
       "      <th>feature_1183_sms</th>\n",
       "      <th>feature_1184_sms</th>\n",
       "      <th>feature_1185_sms</th>\n",
       "      <th>feature_1186_sms</th>\n",
       "      <th>feature_1187_sms</th>\n",
       "      <th>feature_1188_sms</th>\n",
       "      <th>feature_1189_sms</th>\n",
       "      <th>feature_1190_sms</th>\n",
       "      <th>feature_1191_sms</th>\n",
       "      <th>feature_1192_sms</th>\n",
       "      <th>feature_1193_sms</th>\n",
       "      <th>feature_1194_sms</th>\n",
       "      <th>feature_1195_sms</th>\n",
       "      <th>feature_1196_sms</th>\n",
       "      <th>feature_1197_sms</th>\n",
       "      <th>feature_1198_sms</th>\n",
       "      <th>feature_1199_sms</th>\n",
       "      <th>feature_1200_sms</th>\n",
       "      <th>feature_1201_sms</th>\n",
       "      <th>feature_1202_sms</th>\n",
       "      <th>feature_1203_sms</th>\n",
       "      <th>feature_1204_sms</th>\n",
       "      <th>feature_1205_sms</th>\n",
       "      <th>feature_1206_sms</th>\n",
       "      <th>feature_1207_sms</th>\n",
       "      <th>feature_1208_sms</th>\n",
       "      <th>feature_1209_sms</th>\n",
       "      <th>feature_1210_sms</th>\n",
       "      <th>feature_1211_sms</th>\n",
       "      <th>feature_1212_sms</th>\n",
       "      <th>feature_1213_sms</th>\n",
       "      <th>feature_1214_sms</th>\n",
       "      <th>feature_1215_sms</th>\n",
       "      <th>feature_1216_sms</th>\n",
       "      <th>feature_1217_sms</th>\n",
       "      <th>feature_1218_sms</th>\n",
       "      <th>feature_1219_sms</th>\n",
       "      <th>feature_1220_sms</th>\n",
       "      <th>feature_1221_sms</th>\n",
       "      <th>feature_1222_sms</th>\n",
       "      <th>feature_1223_sms</th>\n",
       "      <th>feature_1224_sms</th>\n",
       "      <th>feature_1225_sms</th>\n",
       "      <th>feature_1226_sms</th>\n",
       "      <th>feature_1227_sms</th>\n",
       "      <th>feature_1228_sms</th>\n",
       "      <th>feature_1229_sms</th>\n",
       "      <th>feature_1230_sms</th>\n",
       "      <th>feature_1231_sms</th>\n",
       "      <th>feature_1232_sms</th>\n",
       "      <th>feature_1233_sms</th>\n",
       "      <th>feature_1234_sms</th>\n",
       "      <th>feature_1235_sms</th>\n",
       "      <th>feature_1236_sms</th>\n",
       "      <th>feature_1237_sms</th>\n",
       "      <th>feature_1238_sms</th>\n",
       "      <th>feature_1239_sms</th>\n",
       "      <th>feature_1240_sms</th>\n",
       "      <th>feature_1241_sms</th>\n",
       "      <th>feature_1242_sms</th>\n",
       "      <th>feature_1243_sms</th>\n",
       "      <th>feature_1244_sms</th>\n",
       "      <th>feature_1245_sms</th>\n",
       "      <th>feature_1246_sms</th>\n",
       "      <th>feature_1247_sms</th>\n",
       "      <th>feature_1248_sms</th>\n",
       "      <th>feature_1249_sms</th>\n",
       "      <th>feature_1250_sms</th>\n",
       "      <th>feature_1251_sms</th>\n",
       "      <th>feature_1252_sms</th>\n",
       "      <th>feature_1253_sms</th>\n",
       "      <th>feature_1254_sms</th>\n",
       "      <th>feature_1255_sms</th>\n",
       "      <th>feature_1256_sms</th>\n",
       "      <th>feature_1257_sms</th>\n",
       "      <th>feature_1258_sms</th>\n",
       "      <th>feature_1259_sms</th>\n",
       "      <th>feature_1260_sms</th>\n",
       "      <th>feature_1261_sms</th>\n",
       "      <th>feature_1262_sms</th>\n",
       "      <th>feature_1263_sms</th>\n",
       "      <th>feature_1264_sms</th>\n",
       "      <th>feature_1265_sms</th>\n",
       "      <th>feature_1266_sms</th>\n",
       "      <th>feature_1267_sms</th>\n",
       "      <th>feature_1268_sms</th>\n",
       "      <th>feature_1269_sms</th>\n",
       "      <th>feature_1270_sms</th>\n",
       "      <th>feature_1271_sms</th>\n",
       "      <th>feature_1272_sms</th>\n",
       "      <th>feature_1273_sms</th>\n",
       "      <th>feature_1274_sms</th>\n",
       "      <th>feature_1275_sms</th>\n",
       "      <th>feature_1276_sms</th>\n",
       "      <th>feature_1277_sms</th>\n",
       "      <th>feature_1278_sms</th>\n",
       "      <th>feature_1279_sms</th>\n",
       "      <th>feature_1280_sms</th>\n",
       "      <th>feature_1281_sms</th>\n",
       "      <th>feature_1282_sms</th>\n",
       "      <th>feature_1283_sms</th>\n",
       "      <th>feature_1284_sms</th>\n",
       "      <th>feature_1285_sms</th>\n",
       "      <th>feature_1286_sms</th>\n",
       "      <th>feature_1287_sms</th>\n",
       "      <th>feature_1288_sms</th>\n",
       "      <th>feature_1289_sms</th>\n",
       "      <th>feature_1290_sms</th>\n",
       "      <th>feature_1291_sms</th>\n",
       "      <th>feature_1292_sms</th>\n",
       "      <th>feature_1293_sms</th>\n",
       "      <th>feature_1294_sms</th>\n",
       "      <th>feature_1295_sms</th>\n",
       "      <th>feature_1296_sms</th>\n",
       "      <th>feature_1297_sms</th>\n",
       "      <th>feature_1298_sms</th>\n",
       "      <th>feature_1299_sms</th>\n",
       "      <th>feature_1300_sms</th>\n",
       "      <th>feature_1301_sms</th>\n",
       "      <th>feature_1302_sms</th>\n",
       "      <th>feature_1303_sms</th>\n",
       "      <th>feature_1304_sms</th>\n",
       "      <th>feature_1305_sms</th>\n",
       "      <th>feature_1306_sms</th>\n",
       "      <th>feature_1307_sms</th>\n",
       "      <th>feature_1308_sms</th>\n",
       "      <th>feature_1309_sms</th>\n",
       "      <th>feature_1310_sms</th>\n",
       "      <th>feature_1311_sms</th>\n",
       "      <th>feature_1312_sms</th>\n",
       "      <th>feature_1313_sms</th>\n",
       "      <th>feature_1314_sms</th>\n",
       "      <th>feature_1315_sms</th>\n",
       "      <th>feature_1316_sms</th>\n",
       "      <th>feature_1317_sms</th>\n",
       "      <th>feature_1318_sms</th>\n",
       "      <th>feature_1319_sms</th>\n",
       "      <th>feature_1320_sms</th>\n",
       "      <th>feature_1321_sms</th>\n",
       "      <th>feature_1322_sms</th>\n",
       "      <th>feature_1323_sms</th>\n",
       "      <th>feature_1324_sms</th>\n",
       "      <th>feature_1325_sms</th>\n",
       "      <th>feature_1326_sms</th>\n",
       "      <th>feature_1327_sms</th>\n",
       "      <th>feature_1328_sms</th>\n",
       "      <th>feature_1329_sms</th>\n",
       "      <th>feature_1330_sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>732.0</td>\n",
       "      <td>0.400396</td>\n",
       "      <td>17</td>\n",
       "      <td>6.665722</td>\n",
       "      <td>5.998750</td>\n",
       "      <td>46</td>\n",
       "      <td>6.998800</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>0.363620</td>\n",
       "      <td>59011</td>\n",
       "      <td>22</td>\n",
       "      <td>364464</td>\n",
       "      <td>16</td>\n",
       "      <td>81364</td>\n",
       "      <td>12949</td>\n",
       "      <td>28.486257</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11.397920</td>\n",
       "      <td>65.935065</td>\n",
       "      <td>5.498875</td>\n",
       "      <td>214</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87016.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>13492.000000</td>\n",
       "      <td>604227.0</td>\n",
       "      <td>33568.166667</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>42007.514571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>260.0</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.334615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85432.0</td>\n",
       "      <td>59011.0</td>\n",
       "      <td>16295.000000</td>\n",
       "      <td>224089.0</td>\n",
       "      <td>47740.988110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.40</td>\n",
       "      <td>9.840000</td>\n",
       "      <td>24.35</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.559937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.433437</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>164.500000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1173.500000</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>792.642857</td>\n",
       "      <td>217.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>713.952381</td>\n",
       "      <td>564.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>281.136364</td>\n",
       "      <td>258.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>771.045455</td>\n",
       "      <td>197.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>239.0</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.095351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>783</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>905</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>101</td>\n",
       "      <td>9</td>\n",
       "      <td>1227</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>271</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>416</td>\n",
       "      <td>26</td>\n",
       "      <td>91</td>\n",
       "      <td>166</td>\n",
       "      <td>16</td>\n",
       "      <td>2999</td>\n",
       "      <td>173</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>723</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>171</td>\n",
       "      <td>12</td>\n",
       "      <td>1088</td>\n",
       "      <td>49</td>\n",
       "      <td>201</td>\n",
       "      <td>390</td>\n",
       "      <td>42</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>0.045682</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.175182</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.306569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.124088</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.051095</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.036496</td>\n",
       "      <td>42.142857</td>\n",
       "      <td>42.142857</td>\n",
       "      <td>0.098366</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>0.210169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.098305</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>0.105085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.857143</td>\n",
       "      <td>0.376271</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>0.091525</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>38.214286</td>\n",
       "      <td>38.214286</td>\n",
       "      <td>0.178393</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>9.714286</td>\n",
       "      <td>0.254206</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>0.080374</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>4.785714</td>\n",
       "      <td>0.125234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.071429</td>\n",
       "      <td>0.368224</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>0.069159</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.065421</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>37.285714</td>\n",
       "      <td>37.285714</td>\n",
       "      <td>0.261087</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>9.142857</td>\n",
       "      <td>0.245211</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>0.088123</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.809524</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>2.476190</td>\n",
       "      <td>0.066411</td>\n",
       "      <td>3.095238</td>\n",
       "      <td>0.083014</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>30.166667</td>\n",
       "      <td>30.166667</td>\n",
       "      <td>0.301767</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.243094</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>0.081768</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>0.098343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.364641</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>0.111602</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>20.450000</td>\n",
       "      <td>21.910714</td>\n",
       "      <td>0.409136</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>4.516667</td>\n",
       "      <td>0.220864</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>0.079870</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>1.983333</td>\n",
       "      <td>0.096985</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>6.933333</td>\n",
       "      <td>0.339038</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.021190</td>\n",
       "      <td>1.516667</td>\n",
       "      <td>0.074165</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>0.135289</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>2.999</td>\n",
       "      <td>17.335260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.241080</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.057019</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.362788</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.067022</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.130043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.014005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6547</th>\n",
       "      <td>518.0</td>\n",
       "      <td>0.370718</td>\n",
       "      <td>42</td>\n",
       "      <td>34.988670</td>\n",
       "      <td>25.987506</td>\n",
       "      <td>46</td>\n",
       "      <td>11.797840</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>0.107691</td>\n",
       "      <td>201224</td>\n",
       "      <td>22</td>\n",
       "      <td>290622</td>\n",
       "      <td>69</td>\n",
       "      <td>64832</td>\n",
       "      <td>10624</td>\n",
       "      <td>45.977511</td>\n",
       "      <td>30.990003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.244439</td>\n",
       "      <td>138.862138</td>\n",
       "      <td>12.997600</td>\n",
       "      <td>272</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>75</td>\n",
       "      <td>92.908092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98741.0</td>\n",
       "      <td>66750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8805.042136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>543500.0</td>\n",
       "      <td>212000.0</td>\n",
       "      <td>81793.398267</td>\n",
       "      <td>2748243.0</td>\n",
       "      <td>42280.661538</td>\n",
       "      <td>237771.0</td>\n",
       "      <td>50555.892598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.118252</td>\n",
       "      <td>224.0</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.647876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.101317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21779.0</td>\n",
       "      <td>21779.0</td>\n",
       "      <td>8711.600000</td>\n",
       "      <td>164164.0</td>\n",
       "      <td>21030.920771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.00</td>\n",
       "      <td>18.40</td>\n",
       "      <td>32.00</td>\n",
       "      <td>14.50</td>\n",
       "      <td>6.843975</td>\n",
       "      <td>583.80</td>\n",
       "      <td>12.973333</td>\n",
       "      <td>32.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>6.082344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.118252</td>\n",
       "      <td>3.446154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.589107</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>300.800000</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>709.092308</td>\n",
       "      <td>430.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>504.517241</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>101.40</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>431.246154</td>\n",
       "      <td>303.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>272.600000</td>\n",
       "      <td>303.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>658.938462</td>\n",
       "      <td>485.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.939072</td>\n",
       "      <td>681.0</td>\n",
       "      <td>10.476923</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.637643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>77.800000</td>\n",
       "      <td>206.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>568</td>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>184</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>32</td>\n",
       "      <td>83</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>3000</td>\n",
       "      <td>283</td>\n",
       "      <td>291</td>\n",
       "      <td>88</td>\n",
       "      <td>719</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>6</td>\n",
       "      <td>461</td>\n",
       "      <td>141</td>\n",
       "      <td>424</td>\n",
       "      <td>378</td>\n",
       "      <td>35</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.571429</td>\n",
       "      <td>12.571429</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>13.071429</td>\n",
       "      <td>13.071429</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>0.092896</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.109290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.087432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.136612</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.087432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>11.952381</td>\n",
       "      <td>11.952381</td>\n",
       "      <td>0.083667</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.067729</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.390438</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.011952</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.131474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.063745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.619048</td>\n",
       "      <td>0.135458</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.043825</td>\n",
       "      <td>1.380952</td>\n",
       "      <td>0.115538</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.066007</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>0.366337</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>0.125413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.118812</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.052805</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.033003</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>9.466667</td>\n",
       "      <td>9.466667</td>\n",
       "      <td>0.189333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.063380</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>0.323944</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.110915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.059859</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.147887</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>1.383333</td>\n",
       "      <td>0.146127</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.040493</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>3.000</td>\n",
       "      <td>10.600707</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.239667</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.070667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.141333</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.011667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>762.0</td>\n",
       "      <td>0.420800</td>\n",
       "      <td>12</td>\n",
       "      <td>2.998002</td>\n",
       "      <td>8.992008</td>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.399920</td>\n",
       "      <td>68568</td>\n",
       "      <td>1</td>\n",
       "      <td>68932</td>\n",
       "      <td>99</td>\n",
       "      <td>364</td>\n",
       "      <td>8226</td>\n",
       "      <td>3.498751</td>\n",
       "      <td>6.994006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.498751</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>4.996004</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>6.994006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>784.400000</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>1568.800000</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1568.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25350.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>6039.172129</td>\n",
       "      <td>25350.0</td>\n",
       "      <td>5070.000000</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>6039.172129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68932.0</td>\n",
       "      <td>68568.0</td>\n",
       "      <td>27391.162791</td>\n",
       "      <td>68568.0</td>\n",
       "      <td>27391.162791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>194.400000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>194.400000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>156.666667</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>154.25</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>154.250000</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>115.2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>115.200000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>182.200000</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>182.200000</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.033150</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.033150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>327</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>464</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>114</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>972</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>21</td>\n",
       "      <td>260</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>2975</td>\n",
       "      <td>167</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1199</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>395</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>102</td>\n",
       "      <td>89</td>\n",
       "      <td>669</td>\n",
       "      <td>162</td>\n",
       "      <td>185</td>\n",
       "      <td>84</td>\n",
       "      <td>36</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>0.045378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>0.281481</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.081481</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>18.357143</td>\n",
       "      <td>18.357143</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>0.268482</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.038911</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.140078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.093385</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.027237</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>0.287938</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.027237</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.023346</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>15.571429</td>\n",
       "      <td>15.571429</td>\n",
       "      <td>0.109916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>0.293578</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.051988</td>\n",
       "      <td>2.190476</td>\n",
       "      <td>0.140673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.085627</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>3.952381</td>\n",
       "      <td>0.253823</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.033639</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.061162</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.024465</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>15.466667</td>\n",
       "      <td>15.466667</td>\n",
       "      <td>0.155966</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.233333</td>\n",
       "      <td>0.338362</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.047414</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.023707</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.245690</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.036638</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>0.326723</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.233333</td>\n",
       "      <td>0.384774</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.022634</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>0.115226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.021605</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.267490</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.033951</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>2.975</td>\n",
       "      <td>17.814371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>1.199</td>\n",
       "      <td>0.403025</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.132773</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.029916</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.224874</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.062185</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.028235</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.012101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>746.0</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>27</td>\n",
       "      <td>5.998334</td>\n",
       "      <td>4.498251</td>\n",
       "      <td>46</td>\n",
       "      <td>2.749563</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.599880</td>\n",
       "      <td>47246</td>\n",
       "      <td>0</td>\n",
       "      <td>47246</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>11472</td>\n",
       "      <td>4.998667</td>\n",
       "      <td>3.749313</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.998667</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>2.499250</td>\n",
       "      <td>164</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>13.987013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43490.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>6255.000000</td>\n",
       "      <td>228499.0</td>\n",
       "      <td>45699.800000</td>\n",
       "      <td>85485.0</td>\n",
       "      <td>23840.693366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.545268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>14549.000000</td>\n",
       "      <td>29098.0</td>\n",
       "      <td>12079.789773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.44</td>\n",
       "      <td>15.813333</td>\n",
       "      <td>25.00</td>\n",
       "      <td>9.95</td>\n",
       "      <td>6.578198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.631514</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>524.200000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>76.00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>197.400000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>161.400000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>209.500000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>508.600000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>381</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>441</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>629</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>207</td>\n",
       "      <td>32</td>\n",
       "      <td>71</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1129</td>\n",
       "      <td>265</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>129</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>295</td>\n",
       "      <td>42</td>\n",
       "      <td>168</td>\n",
       "      <td>181</td>\n",
       "      <td>27</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>0.064659</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.714286</td>\n",
       "      <td>21.714286</td>\n",
       "      <td>0.134632</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046053</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.059211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.138158</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>19.571429</td>\n",
       "      <td>19.571429</td>\n",
       "      <td>0.242693</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.018248</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.094891</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.182482</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.054745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>0.394161</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>0.120438</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>18.142857</td>\n",
       "      <td>18.142857</td>\n",
       "      <td>0.337467</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.020997</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.110236</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.196850</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.049869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.404199</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.018373</td>\n",
       "      <td>2.047619</td>\n",
       "      <td>0.112861</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.018373</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>0.390611</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>0.120181</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.024943</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.197279</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.049887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.566667</td>\n",
       "      <td>0.378685</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>0.120181</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>10.483333</td>\n",
       "      <td>10.483333</td>\n",
       "      <td>0.557130</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.138315</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.182830</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.062003</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>0.329094</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.050874</td>\n",
       "      <td>1.183333</td>\n",
       "      <td>0.112878</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.031797</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>1.129</td>\n",
       "      <td>4.260377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.024801</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.023915</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.122232</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.114260</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.052259</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.261293</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.037201</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.148804</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.160319</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.023915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>700.0</td>\n",
       "      <td>0.385723</td>\n",
       "      <td>52</td>\n",
       "      <td>7.748313</td>\n",
       "      <td>12.497126</td>\n",
       "      <td>46</td>\n",
       "      <td>3.666222</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.437473</td>\n",
       "      <td>40878</td>\n",
       "      <td>88</td>\n",
       "      <td>339424</td>\n",
       "      <td>12</td>\n",
       "      <td>298546</td>\n",
       "      <td>11260</td>\n",
       "      <td>20.990005</td>\n",
       "      <td>7.798640</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.999286</td>\n",
       "      <td>52.948052</td>\n",
       "      <td>3.999250</td>\n",
       "      <td>258</td>\n",
       "      <td>62</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>37.963037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>803.666667</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>1797.053298</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1202.818128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>331598.0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>28811.055984</td>\n",
       "      <td>548219.0</td>\n",
       "      <td>34263.687500</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>27368.428373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278210.0</td>\n",
       "      <td>75464.0</td>\n",
       "      <td>29261.683648</td>\n",
       "      <td>75464.0</td>\n",
       "      <td>28188.354776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>62.00</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>42.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.944272</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.942103</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>268.333333</td>\n",
       "      <td>244.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>244.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>523.777778</td>\n",
       "      <td>51.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>69.20</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>285.461538</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>269.625000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>246.666667</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>560.937500</td>\n",
       "      <td>242.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>165.0</td>\n",
       "      <td>10.312500</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.310810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>482</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>677</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>40</td>\n",
       "      <td>19</td>\n",
       "      <td>1121</td>\n",
       "      <td>60</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>266</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>16</td>\n",
       "      <td>130</td>\n",
       "      <td>67</td>\n",
       "      <td>27</td>\n",
       "      <td>3000</td>\n",
       "      <td>159</td>\n",
       "      <td>156</td>\n",
       "      <td>57</td>\n",
       "      <td>725</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>1047</td>\n",
       "      <td>52</td>\n",
       "      <td>256</td>\n",
       "      <td>174</td>\n",
       "      <td>79</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>23.142857</td>\n",
       "      <td>23.142857</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>9.285714</td>\n",
       "      <td>0.401235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>0.290123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>22.952381</td>\n",
       "      <td>22.952381</td>\n",
       "      <td>0.160667</td>\n",
       "      <td>1.380952</td>\n",
       "      <td>0.060166</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>0.292531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.029046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>2.095238</td>\n",
       "      <td>0.091286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>0.286307</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>2.809524</td>\n",
       "      <td>0.122407</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.056017</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.018672</td>\n",
       "      <td>22.566667</td>\n",
       "      <td>22.566667</td>\n",
       "      <td>0.225667</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0.060561</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.023634</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>0.262925</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.011817</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.097489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.257016</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.137371</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.059084</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.028065</td>\n",
       "      <td>18.683333</td>\n",
       "      <td>18.683333</td>\n",
       "      <td>0.373667</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.066905</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.022302</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.046387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>0.110616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.266667</td>\n",
       "      <td>0.281891</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.014273</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.115968</td>\n",
       "      <td>1.116667</td>\n",
       "      <td>0.059768</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.024086</td>\n",
       "      <td>3.000</td>\n",
       "      <td>18.867925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.047667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>1.047</td>\n",
       "      <td>0.349000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.026333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1761 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BureauScore  MissingRate  Len_Name  Tel_nuniq  Email_nuniq  \\\n",
       "502         732.0     0.400396        17   6.665722     5.998750   \n",
       "6547        518.0     0.370718        42  34.988670    25.987506   \n",
       "6938        762.0     0.420800        12   2.998002     8.992008   \n",
       "3115        746.0     0.396552        27   5.998334     4.498251   \n",
       "3649        700.0     0.385723        52   7.748313    12.497126   \n",
       "\n",
       "      Len_of_addrs  City_nuniq  Current_State  CreditAccountActive  \\\n",
       "502             46    6.998800             27                    8   \n",
       "6547            46   11.797840             27                    7   \n",
       "6938            46    1.000000             27                    2   \n",
       "3115            46    2.749563             27                    3   \n",
       "3649            46    3.666222             27                    7   \n",
       "\n",
       "      CreditAccountTotal  CreditAccountActivePor  Outstanding_Balance_Secured  \\\n",
       "502                   22                0.363620                        59011   \n",
       "6547                  65                0.107691                       201224   \n",
       "6938                   5                0.399920                        68568   \n",
       "3115                   5                0.599880                        47246   \n",
       "3649                  16                0.437473                        40878   \n",
       "\n",
       "      Outstanding_Balance_UnSecured_Percentage  Outstanding_Balance_All  \\\n",
       "502                                         22                   364464   \n",
       "6547                                        22                   290622   \n",
       "6938                                         1                    68932   \n",
       "3115                                         0                    47246   \n",
       "3649                                        88                   339424   \n",
       "\n",
       "      Outstanding_Balance_Secured_Percentage  Outstanding_Balance_UnSecured  \\\n",
       "502                                       16                          81364   \n",
       "6547                                      69                          64832   \n",
       "6938                                      99                            364   \n",
       "3115                                     100                              0   \n",
       "3649                                      12                         298546   \n",
       "\n",
       "      Diff_dateBirth  State_nuniq  Birth_nuniq  TotalCAPSLast90Days  \\\n",
       "502            12949    28.486257    25.987506                    4   \n",
       "6547           10624    45.977511    30.990003                    1   \n",
       "6938            8226     3.498751     6.994006                    0   \n",
       "3115           11472     4.998667     3.749313                    5   \n",
       "3649           11260    20.990005     7.798640                    3   \n",
       "\n",
       "      TotalCAPSLast7Days  TotalCAPSLast30Days  TotalCAPSLast180Days  \\\n",
       "502                    3                    3                     5   \n",
       "6547                   1                    1                     2   \n",
       "6938                   0                    0                     0   \n",
       "3115                   2                    4                     6   \n",
       "3649                   2                    2                     3   \n",
       "\n",
       "      CAPSLast30Days  CAPSLast7Days  CAPSLast180Days  \\\n",
       "502                0              0                2   \n",
       "6547               0              0                1   \n",
       "6938               0              0                0   \n",
       "3115               2              0                4   \n",
       "3649               1              1                2   \n",
       "\n",
       "      NonCreditCAPSLast180Days  Pin_nuniq   Pan_nuniq  Ident_nuniq  \\\n",
       "502                          3  11.397920   65.935065     5.498875   \n",
       "6547                         1  23.244439  138.862138    12.997600   \n",
       "6938                         0   3.498751   10.990010     4.996004   \n",
       "3115                         2   4.998667   10.990010     2.499250   \n",
       "3649                         1   5.999286   52.948052     3.999250   \n",
       "\n",
       "      Name_nuniq2  Tel_nuniq2  Email_nuniq2  Pan_nuniq2  Account_nuniq2  \\\n",
       "502           214          86            93          14              14   \n",
       "6547          272          44            47          14              14   \n",
       "6938           57          14            25          14              14   \n",
       "3115          164          44            44          14              14   \n",
       "3649          258          62            87          14              14   \n",
       "\n",
       "      Ident_nuniq2  Gender_nuniq  Amount_Past_Due35_sum_30  \\\n",
       "502             60     25.987506                       0.0   \n",
       "6547            75     92.908092                       0.0   \n",
       "6938            15      6.994006                       0.0   \n",
       "3115            30     13.987013                       0.0   \n",
       "3649            60     37.963037                       0.0   \n",
       "\n",
       "      Amount_Past_Due35_min_30  Amount_Past_Due35_sum_90  \\\n",
       "502                        0.0                       0.0   \n",
       "6547                       0.0                       0.0   \n",
       "6938                       0.0                       0.0   \n",
       "3115                       0.0                       0.0   \n",
       "3649                       0.0                       0.0   \n",
       "\n",
       "      Amount_Past_Due35_mean_90  Amount_Past_Due35_max_90  \\\n",
       "502                         0.0                       0.0   \n",
       "6547                        0.0                       0.0   \n",
       "6938                        0.0                       0.0   \n",
       "3115                        0.0                       0.0   \n",
       "3649                        0.0                       0.0   \n",
       "\n",
       "      Amount_Past_Due35_min_90  Amount_Past_Due35_std_90  \\\n",
       "502                        0.0                       0.0   \n",
       "6547                       0.0                       0.0   \n",
       "6938                       0.0                       0.0   \n",
       "3115                       0.0                       0.0   \n",
       "3649                       0.0                       0.0   \n",
       "\n",
       "      Amount_Past_Due35_sum_360  Amount_Past_Due35_mean_360  \\\n",
       "502                         0.0                    0.000000   \n",
       "6547                        0.0                    0.000000   \n",
       "6938                     3922.0                  784.400000   \n",
       "3115                        0.0                    0.000000   \n",
       "3649                     4822.0                  803.666667   \n",
       "\n",
       "      Amount_Past_Due35_max_360  Amount_Past_Due35_std_360  \\\n",
       "502                         0.0                   0.000000   \n",
       "6547                        0.0                   0.000000   \n",
       "6938                     3922.0                1568.800000   \n",
       "3115                        0.0                   0.000000   \n",
       "3649                     4822.0                1797.053298   \n",
       "\n",
       "      Amount_Past_Due35_sum_9999  Amount_Past_Due35_max_9999  \\\n",
       "502                          0.0                         0.0   \n",
       "6547                     98741.0                     66750.0   \n",
       "6938                      3922.0                      3922.0   \n",
       "3115                         0.0                         0.0   \n",
       "3649                      4822.0                      4822.0   \n",
       "\n",
       "      Amount_Past_Due35_min_9999  Amount_Past_Due35_std_9999  \\\n",
       "502                          0.0                    0.000000   \n",
       "6547                         0.0                 8805.042136   \n",
       "6938                         0.0                 1568.800000   \n",
       "3115                         0.0                    0.000000   \n",
       "3649                         0.0                 1202.818128   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_30  \\\n",
       "502                                               0.0   \n",
       "6547                                              0.0   \n",
       "6938                                              0.0   \n",
       "3115                                              0.0   \n",
       "3649                                              0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_min_30  \\\n",
       "502                                               0.0   \n",
       "6547                                              0.0   \n",
       "6938                                              0.0   \n",
       "3115                                              0.0   \n",
       "3649                                              0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_30  \\\n",
       "502                                               0.0   \n",
       "6547                                              0.0   \n",
       "6938                                              0.0   \n",
       "3115                                              0.0   \n",
       "3649                                              0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_90  \\\n",
       "502                                               0.0   \n",
       "6547                                              0.0   \n",
       "6938                                            350.0   \n",
       "3115                                              0.0   \n",
       "3649                                              0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_mean_90  \\\n",
       "502                                                0.0   \n",
       "6547                                               0.0   \n",
       "6938                                             350.0   \n",
       "3115                                               0.0   \n",
       "3649                                               0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_90  \\\n",
       "502                                               0.0   \n",
       "6547                                              0.0   \n",
       "6938                                            350.0   \n",
       "3115                                              0.0   \n",
       "3649                                              0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_min_90  \\\n",
       "502                                               0.0   \n",
       "6547                                              0.0   \n",
       "6938                                            350.0   \n",
       "3115                                              0.0   \n",
       "3649                                              0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "502                                               0.0   \n",
       "6547                                              0.0   \n",
       "6938                                              0.0   \n",
       "3115                                              0.0   \n",
       "3649                                              0.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_360  \\\n",
       "502                                            87016.0   \n",
       "6547                                          543500.0   \n",
       "6938                                           25350.0   \n",
       "3115                                           43490.0   \n",
       "3649                                          331598.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_360  \\\n",
       "502                                            57000.0   \n",
       "6547                                          212000.0   \n",
       "6938                                           17000.0   \n",
       "3115                                           28000.0   \n",
       "3649                                           88000.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_360  \\\n",
       "502                                       13492.000000   \n",
       "6547                                      81793.398267   \n",
       "6938                                       6039.172129   \n",
       "3115                                       6255.000000   \n",
       "3649                                      28811.055984   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "502                                            604227.0   \n",
       "6547                                          2748243.0   \n",
       "6938                                            25350.0   \n",
       "3115                                           228499.0   \n",
       "3649                                           548219.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_mean_9999  \\\n",
       "502                                        33568.166667    \n",
       "6547                                       42280.661538    \n",
       "6938                                        5070.000000    \n",
       "3115                                       45699.800000    \n",
       "3649                                       34263.687500    \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "502                                            195000.0   \n",
       "6547                                           237771.0   \n",
       "6938                                            17000.0   \n",
       "3115                                            85485.0   \n",
       "3649                                            88000.0   \n",
       "\n",
       "      Highest_Credit_or_Original_Loan_Amount58_std_9999  \\\n",
       "502                                        42007.514571   \n",
       "6547                                       50555.892598   \n",
       "6938                                        6039.172129   \n",
       "3115                                       23840.693366   \n",
       "3649                                       27368.428373   \n",
       "\n",
       "      Terms_Duration34_sum_30  Terms_Duration34_std_30  \\\n",
       "502                       0.0                      0.0   \n",
       "6547                      0.0                      0.0   \n",
       "6938                      0.0                      0.0   \n",
       "3115                      0.0                      0.0   \n",
       "3649                      0.0                      0.0   \n",
       "\n",
       "      Terms_Duration34_sum_90  Terms_Duration34_std_90  \\\n",
       "502                       0.0                      0.0   \n",
       "6547                      0.0                      0.0   \n",
       "6938                      0.0                      0.0   \n",
       "3115                      0.0                      0.0   \n",
       "3649                      0.0                      0.0   \n",
       "\n",
       "      Terms_Duration34_mean_360  Terms_Duration34_max_360  \\\n",
       "502                         4.5                       8.0   \n",
       "6547                        4.8                      13.0   \n",
       "6938                       30.0                      30.0   \n",
       "3115                       11.0                      12.0   \n",
       "3649                       24.0                      24.0   \n",
       "\n",
       "      Terms_Duration34_min_360  Terms_Duration34_std_360  \\\n",
       "502                        1.0                  3.500000   \n",
       "6547                       2.0                  4.118252   \n",
       "6938                      30.0                  0.000000   \n",
       "3115                      10.0                  1.000000   \n",
       "3649                      24.0                  0.000000   \n",
       "\n",
       "      Terms_Duration34_sum_9999  Terms_Duration34_mean_9999  \\\n",
       "502                       260.0                   17.333333   \n",
       "6547                      224.0                    5.600000   \n",
       "6938                       30.0                   30.000000   \n",
       "3115                       58.0                   14.500000   \n",
       "3649                       31.0                   15.500000   \n",
       "\n",
       "      Terms_Duration34_max_9999  Terms_Duration34_min_9999  \\\n",
       "502                        47.0                        1.0   \n",
       "6547                       40.0                        0.0   \n",
       "6938                       30.0                       30.0   \n",
       "3115                       24.0                       10.0   \n",
       "3649                       24.0                        7.0   \n",
       "\n",
       "      Terms_Duration34_std_9999  Payment_Rating34_sum_90  \\\n",
       "502                   17.334615                      0.0   \n",
       "6547                   7.647876                      0.0   \n",
       "6938                   0.000000                      0.0   \n",
       "3115                   5.545268                      0.0   \n",
       "3649                   8.500000                      0.0   \n",
       "\n",
       "      Payment_Rating34_mean_90  Payment_Rating34_max_90  \\\n",
       "502                        0.0                      0.0   \n",
       "6547                       0.0                      0.0   \n",
       "6938                       0.0                      0.0   \n",
       "3115                       0.0                      0.0   \n",
       "3649                       0.0                      0.0   \n",
       "\n",
       "      Payment_Rating34_min_90  Payment_Rating34_std_90  \\\n",
       "502                       0.0                      0.0   \n",
       "6547                      0.0                      0.0   \n",
       "6938                      0.0                      0.0   \n",
       "3115                      0.0                      0.0   \n",
       "3649                      0.0                      0.0   \n",
       "\n",
       "      Payment_Rating34_sum_360  Payment_Rating34_mean_360  \\\n",
       "502                        0.0                        0.0   \n",
       "6547                       0.0                        0.0   \n",
       "6938                       0.0                        0.0   \n",
       "3115                       0.0                        0.0   \n",
       "3649                       0.0                        0.0   \n",
       "\n",
       "      Payment_Rating34_max_360  Payment_Rating34_min_360  \\\n",
       "502                        0.0                       0.0   \n",
       "6547                       0.0                       0.0   \n",
       "6938                       0.0                       0.0   \n",
       "3115                       0.0                       0.0   \n",
       "3649                       0.0                       0.0   \n",
       "\n",
       "      Payment_Rating34_std_360  Payment_Rating34_sum_9999  \\\n",
       "502                        0.0                        0.0   \n",
       "6547                       0.0                       17.0   \n",
       "6938                       0.0                        0.0   \n",
       "3115                       0.0                        0.0   \n",
       "3649                       0.0                        0.0   \n",
       "\n",
       "      Payment_Rating34_mean_9999  Payment_Rating34_max_9999  \\\n",
       "502                     0.000000                        0.0   \n",
       "6547                    0.269841                        6.0   \n",
       "6938                    0.000000                        0.0   \n",
       "3115                    0.000000                        0.0   \n",
       "3649                    0.000000                        0.0   \n",
       "\n",
       "      Payment_Rating34_min_9999  Payment_Rating34_std_9999  \\\n",
       "502                         0.0                   0.000000   \n",
       "6547                        0.0                   1.101317   \n",
       "6938                        0.0                   0.000000   \n",
       "3115                        0.0                   0.000000   \n",
       "3649                        0.0                   0.000000   \n",
       "\n",
       "      Current_Balance35_mean_30  Current_Balance35_min_30  \\\n",
       "502                         0.0                       0.0   \n",
       "6547                        0.0                       0.0   \n",
       "6938                        0.0                       0.0   \n",
       "3115                        0.0                       0.0   \n",
       "3649                        0.0                       0.0   \n",
       "\n",
       "      Current_Balance35_std_30  Current_Balance35_sum_90  \\\n",
       "502                        0.0                       0.0   \n",
       "6547                       0.0                       0.0   \n",
       "6938                       0.0                     364.0   \n",
       "3115                       0.0                       0.0   \n",
       "3649                       0.0                       0.0   \n",
       "\n",
       "      Current_Balance35_mean_90  Current_Balance35_max_90  \\\n",
       "502                         0.0                       0.0   \n",
       "6547                        0.0                       0.0   \n",
       "6938                      364.0                     364.0   \n",
       "3115                        0.0                       0.0   \n",
       "3649                        0.0                       0.0   \n",
       "\n",
       "      Current_Balance35_std_90  Current_Balance35_sum_360  \\\n",
       "502                        0.0                    85432.0   \n",
       "6547                       0.0                    21779.0   \n",
       "6938                       0.0                    68932.0   \n",
       "3115                       0.0                    29098.0   \n",
       "3649                       0.0                   278210.0   \n",
       "\n",
       "      Current_Balance35_max_360  Current_Balance35_std_360  \\\n",
       "502                     59011.0               16295.000000   \n",
       "6547                    21779.0                8711.600000   \n",
       "6938                    68568.0               27391.162791   \n",
       "3115                    29098.0               14549.000000   \n",
       "3649                    75464.0               29261.683648   \n",
       "\n",
       "      Current_Balance35_max_9999  Current_Balance35_std_9999  \\\n",
       "502                     224089.0                47740.988110   \n",
       "6547                    164164.0                21030.920771   \n",
       "6938                     68568.0                27391.162791   \n",
       "3115                     29098.0                12079.789773   \n",
       "3649                     75464.0                28188.354776   \n",
       "\n",
       "      Settlement_Amount37_max_360  Settlement_Amount37_min_360  \\\n",
       "502                           0.0                          0.0   \n",
       "6547                          0.0                          0.0   \n",
       "6938                          0.0                          0.0   \n",
       "3115                          0.0                          0.0   \n",
       "3649                          0.0                          0.0   \n",
       "\n",
       "      Settlement_Amount37_std_360  Settlement_Amount37_sum_9999  \\\n",
       "502                           0.0                           0.0   \n",
       "6547                          0.0                           0.0   \n",
       "6938                          0.0                           0.0   \n",
       "3115                          0.0                           0.0   \n",
       "3649                          0.0                           0.0   \n",
       "\n",
       "      Settlement_Amount37_mean_9999  Settlement_Amount37_max_9999  \\\n",
       "502                             0.0                           0.0   \n",
       "6547                            0.0                           0.0   \n",
       "6938                            0.0                           0.0   \n",
       "3115                            0.0                           0.0   \n",
       "3649                            0.0                           0.0   \n",
       "\n",
       "      Settlement_Amount37_min_9999  Settlement_Amount37_std_9999  \\\n",
       "502                            0.0                           0.0   \n",
       "6547                           0.0                           0.0   \n",
       "6938                           0.0                           0.0   \n",
       "3115                           0.0                           0.0   \n",
       "3649                           0.0                           0.0   \n",
       "\n",
       "      Value_of_Collateral39_std_90  Value_of_Collateral39_std_360  \\\n",
       "502                            0.0                            0.0   \n",
       "6547                           0.0                            0.0   \n",
       "6938                           0.0                            0.0   \n",
       "3115                           0.0                            0.0   \n",
       "3649                           0.0                            0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_sum_360  Written_Off_Amt_Total41_mean_360  \\\n",
       "502                               0.0                               0.0   \n",
       "6547                              0.0                               0.0   \n",
       "6938                              0.0                               0.0   \n",
       "3115                              0.0                               0.0   \n",
       "3649                              0.0                               0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_min_360  Written_Off_Amt_Total41_std_360  \\\n",
       "502                               0.0                              0.0   \n",
       "6547                              0.0                              0.0   \n",
       "6938                              0.0                              0.0   \n",
       "3115                              0.0                              0.0   \n",
       "3649                              0.0                              0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_sum_9999  Written_Off_Amt_Total41_mean_9999  \\\n",
       "502                                0.0                                0.0   \n",
       "6547                               0.0                                0.0   \n",
       "6938                               0.0                                0.0   \n",
       "3115                               0.0                                0.0   \n",
       "3649                               0.0                                0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_max_9999  Written_Off_Amt_Total41_min_9999  \\\n",
       "502                                0.0                               0.0   \n",
       "6547                               0.0                               0.0   \n",
       "6938                               0.0                               0.0   \n",
       "3115                               0.0                               0.0   \n",
       "3649                               0.0                               0.0   \n",
       "\n",
       "      Written_Off_Amt_Total41_std_9999  Written_Off_Amt_Principal45_sum_360  \\\n",
       "502                                0.0                                  0.0   \n",
       "6547                               0.0                                  0.0   \n",
       "6938                               0.0                                  0.0   \n",
       "3115                               0.0                                  0.0   \n",
       "3649                               0.0                                  0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_mean_360  \\\n",
       "502                                    0.0   \n",
       "6547                                   0.0   \n",
       "6938                                   0.0   \n",
       "3115                                   0.0   \n",
       "3649                                   0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_min_360  \\\n",
       "502                                   0.0   \n",
       "6547                                  0.0   \n",
       "6938                                  0.0   \n",
       "3115                                  0.0   \n",
       "3649                                  0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_std_360  \\\n",
       "502                                   0.0   \n",
       "6547                                  0.0   \n",
       "6938                                  0.0   \n",
       "3115                                  0.0   \n",
       "3649                                  0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_max_9999  \\\n",
       "502                                    0.0   \n",
       "6547                                   0.0   \n",
       "6938                                   0.0   \n",
       "3115                                   0.0   \n",
       "3649                                   0.0   \n",
       "\n",
       "      Written_Off_Amt_Principal45_min_9999  Rate_of_Interest36_sum_30  \\\n",
       "502                                    0.0                        0.0   \n",
       "6547                                   0.0                        0.0   \n",
       "6938                                   0.0                        0.0   \n",
       "3115                                   0.0                        0.0   \n",
       "3649                                   0.0                        0.0   \n",
       "\n",
       "      Rate_of_Interest36_std_30  Rate_of_Interest36_sum_90  \\\n",
       "502                         0.0                        0.0   \n",
       "6547                        0.0                        0.0   \n",
       "6938                        0.0                        0.0   \n",
       "3115                        0.0                        0.0   \n",
       "3649                        0.0                        0.0   \n",
       "\n",
       "      Rate_of_Interest36_mean_90  Rate_of_Interest36_max_90  \\\n",
       "502                          0.0                        0.0   \n",
       "6547                         0.0                        0.0   \n",
       "6938                         0.0                        0.0   \n",
       "3115                         0.0                        0.0   \n",
       "3649                         0.0                        0.0   \n",
       "\n",
       "      Rate_of_Interest36_std_90  Rate_of_Interest36_sum_360  \\\n",
       "502                         0.0                        7.40   \n",
       "6547                        0.0                       92.00   \n",
       "6938                        0.0                        0.00   \n",
       "3115                        0.0                        9.95   \n",
       "3649                        0.0                       62.00   \n",
       "\n",
       "      Rate_of_Interest36_mean_360  Rate_of_Interest36_max_360  \\\n",
       "502                          7.40                        7.40   \n",
       "6547                        18.40                       32.00   \n",
       "6938                         0.00                        0.00   \n",
       "3115                         9.95                        9.95   \n",
       "3649                        31.00                       42.00   \n",
       "\n",
       "      Rate_of_Interest36_min_360  Rate_of_Interest36_std_360  \\\n",
       "502                         7.40                    0.000000   \n",
       "6547                       14.50                    6.843975   \n",
       "6938                        0.00                    0.000000   \n",
       "3115                        9.95                    0.000000   \n",
       "3649                       20.00                   11.000000   \n",
       "\n",
       "      Rate_of_Interest36_sum_9999  Rate_of_Interest36_mean_9999  \\\n",
       "502                         98.40                      9.840000   \n",
       "6547                       583.80                     12.973333   \n",
       "6938                         0.00                      0.000000   \n",
       "3115                        47.44                     15.813333   \n",
       "3649                        62.00                     31.000000   \n",
       "\n",
       "      Rate_of_Interest36_max_9999  Rate_of_Interest36_min_9999  \\\n",
       "502                         24.35                         1.00   \n",
       "6547                        32.00                         1.40   \n",
       "6938                         0.00                         0.00   \n",
       "3115                        25.00                         9.95   \n",
       "3649                        42.00                        20.00   \n",
       "\n",
       "      Rate_of_Interest36_std_9999  Repayment_Tenure36_std_30  \\\n",
       "502                      5.559937                        0.0   \n",
       "6547                     6.082344                        0.0   \n",
       "6938                     0.000000                        0.0   \n",
       "3115                     6.578198                        0.0   \n",
       "3649                    11.000000                        0.0   \n",
       "\n",
       "      Repayment_Tenure36_mean_90  Repayment_Tenure36_max_90  \\\n",
       "502                          0.0                        0.0   \n",
       "6547                         0.0                        0.0   \n",
       "6938                         0.0                        0.0   \n",
       "3115                         0.0                        0.0   \n",
       "3649                         0.0                        0.0   \n",
       "\n",
       "      Repayment_Tenure36_min_90  Repayment_Tenure36_std_90  \\\n",
       "502                         0.0                        0.0   \n",
       "6547                        0.0                        0.0   \n",
       "6938                        0.0                        0.0   \n",
       "3115                        0.0                        0.0   \n",
       "3649                        0.0                        0.0   \n",
       "\n",
       "      Repayment_Tenure36_sum_360  Repayment_Tenure36_mean_360  \\\n",
       "502                          9.0                          4.5   \n",
       "6547                        24.0                          4.8   \n",
       "6938                        30.0                          6.0   \n",
       "3115                        22.0                         11.0   \n",
       "3649                        24.0                          4.0   \n",
       "\n",
       "      Repayment_Tenure36_min_360  Repayment_Tenure36_std_360  \\\n",
       "502                          1.0                    3.500000   \n",
       "6547                         2.0                    4.118252   \n",
       "6938                         0.0                   12.000000   \n",
       "3115                        10.0                    1.000000   \n",
       "3649                         0.0                    8.944272   \n",
       "\n",
       "      Repayment_Tenure36_mean_9999  Repayment_Tenure36_min_9999  \\\n",
       "502                      11.818182                          0.0   \n",
       "6547                      3.446154                          0.0   \n",
       "6938                      6.000000                          0.0   \n",
       "3115                     11.600000                          0.0   \n",
       "3649                      1.937500                          0.0   \n",
       "\n",
       "      Repayment_Tenure36_std_9999  Income26_count_360  Income26_std_360  \\\n",
       "502                     16.433437                 2.0               0.0   \n",
       "6547                     6.589107                 5.0               0.0   \n",
       "6938                    12.000000                 5.0               0.0   \n",
       "3115                     7.631514                 2.0               0.0   \n",
       "3649                     5.942103                 6.0               0.0   \n",
       "\n",
       "      Open_Date29_max_30  Open_Date29_min_30  Open_Date29_mean_30  \\\n",
       "502                  0.0                 0.0                  0.0   \n",
       "6547                 0.0                 0.0                  0.0   \n",
       "6938                 0.0                 0.0                  0.0   \n",
       "3115                 0.0                 0.0                  0.0   \n",
       "3649                 0.0                 0.0                  0.0   \n",
       "\n",
       "      Open_Date29_nuniq_30  Open_Date29_maxcount_30  Open_Date29_max_90  \\\n",
       "502                    0.0                      0.0                 0.0   \n",
       "6547                   0.0                      0.0                 0.0   \n",
       "6938                   0.0                      0.0                89.0   \n",
       "3115                   0.0                      0.0                 0.0   \n",
       "3649                   0.0                      0.0                 0.0   \n",
       "\n",
       "      Open_Date29_mean_90  Open_Date29_mode_90  Open_Date29_nuniq_90  \\\n",
       "502                   0.0                  0.0                   0.0   \n",
       "6547                  0.0                  0.0                   0.0   \n",
       "6938                 89.0                 89.0                   1.0   \n",
       "3115                  0.0                  0.0                   0.0   \n",
       "3649                  0.0                  0.0                   0.0   \n",
       "\n",
       "      Open_Date29_maxcount_90  Open_Date29_max_360  Open_Date29_mean_360  \\\n",
       "502                       0.0                217.0            164.500000   \n",
       "6547                      0.0                353.0            300.800000   \n",
       "6938                      1.0                307.0            194.400000   \n",
       "3115                      0.0                304.0            219.000000   \n",
       "3649                      0.0                332.0            268.333333   \n",
       "\n",
       "      Open_Date29_mode_360  Open_Date29_nuniq_360  Open_Date29_maxcount_360  \\\n",
       "502                  112.0                    2.0                       1.0   \n",
       "6547                 212.0                    5.0                       1.0   \n",
       "6938                  89.0                    5.0                       1.0   \n",
       "3115                 134.0                    2.0                       1.0   \n",
       "3649                 244.0                    6.0                       1.0   \n",
       "\n",
       "      Open_Date29_max_9999  Open_Date29_mean_9999  Open_Date29_mode_9999  \\\n",
       "502                 2400.0            1173.500000                 1627.0   \n",
       "6547                1940.0             709.092308                  430.0   \n",
       "6938                 307.0             194.400000                   89.0   \n",
       "3115                1019.0             524.200000                  134.0   \n",
       "3649                1156.0             584.000000                  244.0   \n",
       "\n",
       "      Open_Date29_maxcount_9999  Portfolio_Type34_nuniq_30  \\\n",
       "502                         4.0                        0.0   \n",
       "6547                        3.0                        0.0   \n",
       "6938                        1.0                        0.0   \n",
       "3115                        1.0                        0.0   \n",
       "3649                        1.0                        0.0   \n",
       "\n",
       "      Portfolio_Type34_nuniq_90  Portfolio_Type34_nuniq_360  \\\n",
       "502                         0.0                         1.0   \n",
       "6547                        0.0                         1.0   \n",
       "6938                        1.0                         1.0   \n",
       "3115                        0.0                         1.0   \n",
       "3649                        0.0                         2.0   \n",
       "\n",
       "      Portfolio_Type34_nuniq_9999  Account_Type32_nuniq_30  \\\n",
       "502                           2.0                      0.0   \n",
       "6547                          3.0                      0.0   \n",
       "6938                          1.0                      0.0   \n",
       "3115                          1.0                      0.0   \n",
       "3649                          2.0                      0.0   \n",
       "\n",
       "      Account_Type32_nuniq_90  Account_Type32_nuniq_360  \\\n",
       "502                       0.0                       2.0   \n",
       "6547                      0.0                       2.0   \n",
       "6938                      1.0                       2.0   \n",
       "3115                      0.0                       2.0   \n",
       "3649                      0.0                       4.0   \n",
       "\n",
       "      Account_Type32_nuniq_9999  Occupation_Code35_nuniq_30  \\\n",
       "502                         5.0                         0.0   \n",
       "6547                        8.0                         0.0   \n",
       "6938                        2.0                         0.0   \n",
       "3115                        5.0                         0.0   \n",
       "3649                        4.0                         0.0   \n",
       "\n",
       "      Occupation_Code35_nuniq_90  Occupation_Code35_nuniq_360  \\\n",
       "502                          0.0                          1.0   \n",
       "6547                         0.0                          1.0   \n",
       "6938                         1.0                          1.0   \n",
       "3115                         0.0                          1.0   \n",
       "3649                         0.0                          1.0   \n",
       "\n",
       "      Occupation_Code35_nuniq_9999  AccountHoldertypeCode41_nuniq_90  \\\n",
       "502                            1.0                               0.0   \n",
       "6547                           1.0                               0.0   \n",
       "6938                           1.0                               1.0   \n",
       "3115                           1.0                               0.0   \n",
       "3649                           2.0                               0.0   \n",
       "\n",
       "      AccountHoldertypeCode41_nuniq_360  AccountHoldertypeCode41_nuniq_9999  \\\n",
       "502                                 1.0                                 2.0   \n",
       "6547                                1.0                                 2.0   \n",
       "6938                                1.0                                 1.0   \n",
       "3115                                1.0                                 1.0   \n",
       "3649                                1.0                                 1.0   \n",
       "\n",
       "      Payment_History_Profile43_mode_30  Payment_History_Profile43_mode_90  \\\n",
       "502                                   0                                  0   \n",
       "6547                                  0                                  0   \n",
       "6938                                  0                                  1   \n",
       "3115                                  0                                  0   \n",
       "3649                                  0                                  0   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_90  Payment_History_Profile43_mode_360  \\\n",
       "502                                  0.0                                  36   \n",
       "6547                                 0.0                                  36   \n",
       "6938                                 1.0                                   1   \n",
       "3115                                 0.0                                  36   \n",
       "3649                                 0.0                                  36   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_360  \\\n",
       "502                                   2.0   \n",
       "6547                                  4.0   \n",
       "6938                                  4.0   \n",
       "3115                                  2.0   \n",
       "3649                                  4.0   \n",
       "\n",
       "      Payment_History_Profile43_mode_9999  \\\n",
       "502                                    36   \n",
       "6547                                   36   \n",
       "6938                                    1   \n",
       "3115                                   36   \n",
       "3649                                   36   \n",
       "\n",
       "      Payment_History_Profile43_nuniq_9999  Date_Closed31_nuniq_30  \\\n",
       "502                                   19.0                     0.0   \n",
       "6547                                  30.0                     0.0   \n",
       "6938                                   4.0                     0.0   \n",
       "3115                                   5.0                     0.0   \n",
       "3649                                  12.0                     0.0   \n",
       "\n",
       "      Date_Closed31_maxcount_30  Date_Closed31_max_90  Date_Closed31_min_90  \\\n",
       "502                         0.0                   0.0                   0.0   \n",
       "6547                        0.0                   0.0                   0.0   \n",
       "6938                        0.0                   0.0                   0.0   \n",
       "3115                        0.0                   0.0                   0.0   \n",
       "3649                        0.0                   0.0                   0.0   \n",
       "\n",
       "      Date_Closed31_mean_90  Date_Closed31_mode_90  Date_Closed31_nuniq_90  \\\n",
       "502                     0.0                    0.0                     0.0   \n",
       "6547                    0.0                    0.0                     0.0   \n",
       "6938                    0.0                    0.0                     1.0   \n",
       "3115                    0.0                    0.0                     0.0   \n",
       "3649                    0.0                    0.0                     0.0   \n",
       "\n",
       "      Date_Closed31_maxcount_90  Date_Closed31_min_360  \\\n",
       "502                         0.0                    0.0   \n",
       "6547                        0.0                   30.0   \n",
       "6938                        0.0                   91.0   \n",
       "3115                        0.0                    0.0   \n",
       "3649                        0.0                   74.0   \n",
       "\n",
       "      Date_Closed31_mode_360  Date_Closed31_nuniq_360  \\\n",
       "502                      0.0                      1.0   \n",
       "6547                    30.0                      3.0   \n",
       "6938                    91.0                      4.0   \n",
       "3115                     0.0                      1.0   \n",
       "3649                    74.0                      2.0   \n",
       "\n",
       "      Date_Closed31_maxcount_360  Date_Closed31_max_9999  \\\n",
       "502                          0.0                  1790.0   \n",
       "6547                         3.0                  1327.0   \n",
       "6938                         1.0                   222.0   \n",
       "3115                         0.0                   660.0   \n",
       "3649                         1.0                   939.0   \n",
       "\n",
       "      Date_Closed31_min_9999  Date_Closed31_mean_9999  \\\n",
       "502                    217.0               792.642857   \n",
       "6547                    30.0               504.517241   \n",
       "6938                    91.0               156.666667   \n",
       "3115                   124.0               392.000000   \n",
       "3649                    51.0               523.777778   \n",
       "\n",
       "      Date_Closed31_mode_9999  Date_Closed31_nuniq_9999  \\\n",
       "502                     217.0                      15.0   \n",
       "6547                     30.0                      38.0   \n",
       "6938                     91.0                       4.0   \n",
       "3115                    124.0                       3.0   \n",
       "3649                     51.0                      10.0   \n",
       "\n",
       "      Date_of_Last_Payment40_nuniq_30  Date_of_Last_Payment40_maxcount_30  \\\n",
       "502                               0.0                                 0.0   \n",
       "6547                              0.0                                 0.0   \n",
       "6938                              0.0                                 0.0   \n",
       "3115                              0.0                                 0.0   \n",
       "3649                              0.0                                 0.0   \n",
       "\n",
       "      Date_of_Last_Payment40_min_90  Date_of_Last_Payment40_nuniq_90  \\\n",
       "502                             0.0                              0.0   \n",
       "6547                            0.0                              0.0   \n",
       "6938                            0.0                              1.0   \n",
       "3115                            0.0                              0.0   \n",
       "3649                            0.0                              0.0   \n",
       "\n",
       "      Date_of_Last_Payment40_maxcount_90  Date_of_Last_Payment40_max_360  \\\n",
       "502                                  0.0                            73.0   \n",
       "6547                                 0.0                           212.0   \n",
       "6938                                 0.0                           222.0   \n",
       "3115                                 0.0                           119.0   \n",
       "3649                                 0.0                           100.0   \n",
       "\n",
       "      Date_of_Last_Payment40_min_360  Date_of_Last_Payment40_mean_360  \\\n",
       "502                             73.0                            73.00   \n",
       "6547                            31.0                           101.40   \n",
       "6938                            91.0                           154.25   \n",
       "3115                            33.0                            76.00   \n",
       "3649                            50.0                            69.20   \n",
       "\n",
       "      Date_of_Last_Payment40_mode_360  Date_of_Last_Payment40_nuniq_360  \\\n",
       "502                              73.0                               2.0   \n",
       "6547                             31.0                               3.0   \n",
       "6938                             91.0                               5.0   \n",
       "3115                             33.0                               2.0   \n",
       "3649                             50.0                               6.0   \n",
       "\n",
       "      Date_of_Last_Payment40_maxcount_360  Date_of_Last_Payment40_max_9999  \\\n",
       "502                                   1.0                           1957.0   \n",
       "6547                                  3.0                           1327.0   \n",
       "6938                                  1.0                            222.0   \n",
       "3115                                  1.0                            660.0   \n",
       "3649                                  1.0                            941.0   \n",
       "\n",
       "      Date_of_Last_Payment40_min_9999  Date_of_Last_Payment40_mean_9999  \\\n",
       "502                              73.0                        713.952381   \n",
       "6547                             31.0                        490.000000   \n",
       "6938                             91.0                        154.250000   \n",
       "3115                             33.0                        197.400000   \n",
       "3649                             35.0                        285.461538   \n",
       "\n",
       "      Date_of_Last_Payment40_mode_9999  Date_of_Last_Payment40_maxcount_9999  \\\n",
       "502                              564.0                                   2.0   \n",
       "6547                              31.0                                   8.0   \n",
       "6938                              91.0                                   1.0   \n",
       "3115                              33.0                                   1.0   \n",
       "3649                              53.0                                   2.0   \n",
       "\n",
       "      Date_Reported33_nuniq_30  Date_Reported33_max_90  \\\n",
       "502                        0.0                     0.0   \n",
       "6547                       0.0                     0.0   \n",
       "6938                       0.0                    60.0   \n",
       "3115                       0.0                     0.0   \n",
       "3649                       0.0                     0.0   \n",
       "\n",
       "      Date_Reported33_mean_90  Date_Reported33_mode_90  \\\n",
       "502                       0.0                      0.0   \n",
       "6547                      0.0                      0.0   \n",
       "6938                     60.0                     60.0   \n",
       "3115                      0.0                      0.0   \n",
       "3649                      0.0                      0.0   \n",
       "\n",
       "      Date_Reported33_nuniq_90  Date_Reported33_maxcount_90  \\\n",
       "502                        0.0                          0.0   \n",
       "6547                       0.0                          0.0   \n",
       "6938                       1.0                          1.0   \n",
       "3115                       0.0                          0.0   \n",
       "3649                       0.0                          0.0   \n",
       "\n",
       "      Date_Reported33_max_360  Date_Reported33_mean_360  \\\n",
       "502                      44.0                      44.0   \n",
       "6547                    181.0                      64.8   \n",
       "6938                    213.0                     115.2   \n",
       "3115                     58.0                      42.5   \n",
       "3649                     58.0                      48.0   \n",
       "\n",
       "      Date_Reported33_mode_360  Date_Reported33_nuniq_360  \\\n",
       "502                       44.0                        1.0   \n",
       "6547                      28.0                        3.0   \n",
       "6938                      60.0                        4.0   \n",
       "3115                      27.0                        2.0   \n",
       "3649                      58.0                        2.0   \n",
       "\n",
       "      Date_Reported33_maxcount_360  Date_Reported33_max_9999  \\\n",
       "502                            2.0                     989.0   \n",
       "6547                           3.0                    1854.0   \n",
       "6938                           2.0                     213.0   \n",
       "3115                           1.0                     576.0   \n",
       "3649                           4.0                     912.0   \n",
       "\n",
       "      Date_Reported33_mean_9999  Date_Reported33_mode_9999  \\\n",
       "502                  281.136364                      258.0   \n",
       "6547                 431.246154                      303.0   \n",
       "6938                 115.200000                       60.0   \n",
       "3115                 161.400000                       27.0   \n",
       "3649                 269.625000                       28.0   \n",
       "\n",
       "      Date_Reported33_nuniq_9999  Date_Reported33_maxcount_9999  \\\n",
       "502                         11.0                            5.0   \n",
       "6547                        26.0                           12.0   \n",
       "6938                         4.0                            2.0   \n",
       "3115                         4.0                            2.0   \n",
       "3649                         8.0                            5.0   \n",
       "\n",
       "      DateOfAddition34_nuniq_30  DateOfAddition34_max_90  \\\n",
       "502                         0.0                      0.0   \n",
       "6547                        0.0                      0.0   \n",
       "6938                        0.0                     60.0   \n",
       "3115                        0.0                      0.0   \n",
       "3649                        0.0                      0.0   \n",
       "\n",
       "      DateOfAddition34_mean_90  DateOfAddition34_mode_90  \\\n",
       "502                        0.0                       0.0   \n",
       "6547                       0.0                       0.0   \n",
       "6938                      60.0                      60.0   \n",
       "3115                       0.0                       0.0   \n",
       "3649                       0.0                       0.0   \n",
       "\n",
       "      DateOfAddition34_nuniq_90  DateOfAddition34_maxcount_90  \\\n",
       "502                         0.0                           0.0   \n",
       "6547                        0.0                           0.0   \n",
       "6938                        1.0                           1.0   \n",
       "3115                        0.0                           0.0   \n",
       "3649                        0.0                           0.0   \n",
       "\n",
       "      DateOfAddition34_max_360  DateOfAddition34_mean_360  \\\n",
       "502                      197.0                 151.000000   \n",
       "6547                     303.0                 272.600000   \n",
       "6938                     303.0                 182.200000   \n",
       "3115                     300.0                 209.500000   \n",
       "3649                     301.0                 246.666667   \n",
       "\n",
       "      DateOfAddition34_mode_360  DateOfAddition34_nuniq_360  \\\n",
       "502                       105.0                         2.0   \n",
       "6547                      303.0                         3.0   \n",
       "6938                      213.0                         4.0   \n",
       "3115                      119.0                         2.0   \n",
       "3649                      242.0                         3.0   \n",
       "\n",
       "      DateOfAddition34_maxcount_360  DateOfAddition34_max_9999  \\\n",
       "502                             1.0                     2115.0   \n",
       "6547                            3.0                     1885.0   \n",
       "6938                            2.0                      303.0   \n",
       "3115                            1.0                     1003.0   \n",
       "3649                            4.0                     1154.0   \n",
       "\n",
       "      DateOfAddition34_mean_9999  DateOfAddition34_mode_9999  \\\n",
       "502                   771.045455                       197.0   \n",
       "6547                  658.938462                       485.0   \n",
       "6938                  182.200000                       213.0   \n",
       "3115                  508.600000                       119.0   \n",
       "3649                  560.937500                       242.0   \n",
       "\n",
       "      DateOfAddition34_nuniq_9999  DateOfAddition34_maxcount_9999  \\\n",
       "502                          15.0                             5.0   \n",
       "6547                         27.0                             5.0   \n",
       "6938                          4.0                             2.0   \n",
       "3115                          5.0                             1.0   \n",
       "3649                         12.0                             4.0   \n",
       "\n",
       "      Account_Status34_mode_30  Account_Status34_nuniq_30  \\\n",
       "502                        0.0                        0.0   \n",
       "6547                       0.0                        0.0   \n",
       "6938                       0.0                        0.0   \n",
       "3115                       0.0                        0.0   \n",
       "3649                       0.0                        0.0   \n",
       "\n",
       "      Account_Status34_mode_90  Account_Status34_nuniq_90  \\\n",
       "502                        0.0                        0.0   \n",
       "6547                       0.0                        0.0   \n",
       "6938                      11.0                        1.0   \n",
       "3115                       0.0                        0.0   \n",
       "3649                       0.0                        0.0   \n",
       "\n",
       "      Account_Status34_mode_360  Account_Status34_nuniq_360  \\\n",
       "502                        11.0                         2.0   \n",
       "6547                       13.0                         2.0   \n",
       "6938                       13.0                         2.0   \n",
       "3115                       11.0                         1.0   \n",
       "3649                       11.0                         2.0   \n",
       "\n",
       "      Account_Status34_nuniq_9999  Month50_sum_30  Month50_max_30  \\\n",
       "502                           4.0             0.0             0.0   \n",
       "6547                          8.0             0.0             0.0   \n",
       "6938                          2.0             0.0             0.0   \n",
       "3115                          2.0             0.0             0.0   \n",
       "3649                          2.0             0.0             0.0   \n",
       "\n",
       "      Month50_std_30  Month50_sum_90  Month50_mean_90  Month50_max_90  \\\n",
       "502              0.0             0.0              0.0             0.0   \n",
       "6547             0.0             0.0              0.0             0.0   \n",
       "6938             0.0             8.0              8.0             8.0   \n",
       "3115             0.0             0.0              0.0             0.0   \n",
       "3649             0.0             0.0              0.0             0.0   \n",
       "\n",
       "      Month50_min_90  Month50_std_90  Month50_sum_360  Month50_min_360  \\\n",
       "502              0.0             0.0             20.0             10.0   \n",
       "6547             0.0             0.0             54.0              7.0   \n",
       "6938             8.0             0.0             35.0              3.0   \n",
       "3115             0.0             0.0             19.0              9.0   \n",
       "3649             0.0             0.0             54.0              8.0   \n",
       "\n",
       "      Month50_std_360  Month50_sum_9999  Month50_mean_9999  Month50_max_9999  \\\n",
       "502          0.000000             239.0          10.863636              12.0   \n",
       "6547         1.939072             681.0          10.476923              12.0   \n",
       "6938         3.033150              35.0           7.000000              12.0   \n",
       "3115         0.500000              55.0          11.000000              12.0   \n",
       "3649         1.414214             165.0          10.312500              12.0   \n",
       "\n",
       "      Month50_min_9999  Month50_std_9999  Days_Past_Due58_max_30  \\\n",
       "502                3.0          2.095351                     0.0   \n",
       "6547               1.0          2.637643                     0.0   \n",
       "6938               3.0          3.033150                     0.0   \n",
       "3115               9.0          1.264911                     0.0   \n",
       "3649               4.0          2.310810                     0.0   \n",
       "\n",
       "      Days_Past_Due58_min_30  Days_Past_Due58_mean_90  Days_Past_Due58_max_90  \\\n",
       "502                      0.0                      0.0                     0.0   \n",
       "6547                     0.0                      0.0                     0.0   \n",
       "6938                     0.0                      0.0                     0.0   \n",
       "3115                     0.0                      0.0                     0.0   \n",
       "3649                     0.0                      0.0                     0.0   \n",
       "\n",
       "      Days_Past_Due58_min_90  Days_Past_Due58_std_90  Days_Past_Due58_sum_360  \\\n",
       "502                      0.0                     0.0                      0.0   \n",
       "6547                     0.0                     0.0                    389.0   \n",
       "6938                     0.0                     0.0                     26.0   \n",
       "3115                     0.0                     0.0                      0.0   \n",
       "3649                     0.0                     0.0                     23.0   \n",
       "\n",
       "      Days_Past_Due58_mean_360  Days_Past_Due58_max_360  ...  \\\n",
       "502                   0.000000                      0.0  ...   \n",
       "6547                 77.800000                    206.0  ...   \n",
       "6938                  5.200000                     26.0  ...   \n",
       "3115                  0.000000                      0.0  ...   \n",
       "3649                  3.833333                     22.0  ...   \n",
       "\n",
       "      feature_1031_sms  feature_1032_sms  feature_1033_sms  feature_1034_sms  \\\n",
       "502                  7               783                21                 3   \n",
       "6547                 1               251                21                17   \n",
       "6938                 5               327                21                 0   \n",
       "3115                 6               381                21                 6   \n",
       "3649                 6               482                21                29   \n",
       "\n",
       "      feature_1035_sms  feature_1036_sms  feature_1037_sms  feature_1038_sms  \\\n",
       "502                  4               192                 1                 4   \n",
       "6547                 1                98                 3                 4   \n",
       "6938                 0                96                 2                17   \n",
       "3115                 8                42                 2                 9   \n",
       "3649                10               141                 0                 5   \n",
       "\n",
       "      feature_1039_sms  feature_1040_sms  feature_1041_sms  feature_1042_sms  \\\n",
       "502                 69                 1                 1                87   \n",
       "6547                33                 0                 1                16   \n",
       "6938                46                 0                 1                28   \n",
       "3115                75                 2                 1                19   \n",
       "3649                14                 0                 1                44   \n",
       "\n",
       "      feature_1043_sms  feature_1044_sms  feature_1045_sms  feature_1046_sms  \\\n",
       "502                  0               290                 5                52   \n",
       "6547                 0                34                11                29   \n",
       "6938                 9                83                11                20   \n",
       "3115                 0               154                 7                43   \n",
       "3649                 0               138                 5                59   \n",
       "\n",
       "      feature_1047_sms  feature_1048_sms  feature_1049_sms  feature_1050_sms  \\\n",
       "502                 65                 9               905                30   \n",
       "6547                 2                 2               303                30   \n",
       "6938                 8                 6               464                30   \n",
       "3115                 7                 6               441                30   \n",
       "3649                27                 9               677                30   \n",
       "\n",
       "      feature_1051_sms  feature_1052_sms  feature_1053_sms  feature_1054_sms  \\\n",
       "502                  5                 5               220                 1   \n",
       "6547                20                 3               111                 4   \n",
       "6938                 1                 0               157                 2   \n",
       "3115                 9                 9                53                 2   \n",
       "3649                41                16               178                 3   \n",
       "\n",
       "      feature_1055_sms  feature_1056_sms  feature_1057_sms  feature_1058_sms  \\\n",
       "502                  4                74                 1                 1   \n",
       "6547                 4                38                 0                 1   \n",
       "6938                22                58                 0                 1   \n",
       "3115                11                87                 2                 2   \n",
       "3649                 8                29                 0                 3   \n",
       "\n",
       "      feature_1059_sms  feature_1060_sms  feature_1061_sms  feature_1062_sms  \\\n",
       "502                 89                 0               330                 5   \n",
       "6547                17                 1                36                16   \n",
       "6938                36                11               114                17   \n",
       "3115                22                 0               167                 9   \n",
       "3649                66                 0               174                 7   \n",
       "\n",
       "      feature_1063_sms  feature_1064_sms  feature_1065_sms  feature_1066_sms  \\\n",
       "502                 60               101                 9              1227   \n",
       "6547                39                10                 3               568   \n",
       "6938                24                14                 7               972   \n",
       "3115                53                 9                 6               629   \n",
       "3649                93                40                19              1121   \n",
       "\n",
       "      feature_1067_sms  feature_1068_sms  feature_1069_sms  feature_1070_sms  \\\n",
       "502                 56                 6                 5               271   \n",
       "6547                60                36                 4               184   \n",
       "6938                60                 2                 0               374   \n",
       "3115                60                12                12                87   \n",
       "3649                60                75                25               266   \n",
       "\n",
       "      feature_1071_sms  feature_1072_sms  feature_1073_sms  feature_1074_sms  \\\n",
       "502                  4                 5                98                 1   \n",
       "6547                 7                 7                63                 0   \n",
       "6938                 2                22               112                 0   \n",
       "3115                 2                17               115                 2   \n",
       "3649                 3                13                52                 0   \n",
       "\n",
       "      feature_1075_sms  feature_1076_sms  feature_1077_sms  feature_1078_sms  \\\n",
       "502                  1               119                 2               416   \n",
       "6547                 1                34                 1                84   \n",
       "6938                 2                48                21               260   \n",
       "3115                 2                39                 1               207   \n",
       "3649                 7               124                 0               316   \n",
       "\n",
       "      feature_1079_sms  feature_1080_sms  feature_1081_sms  feature_1082_sms  \\\n",
       "502                 26                91               166                16   \n",
       "6547                32                83                23                 9   \n",
       "6938                36                48                33                12   \n",
       "3115                32                71                20                10   \n",
       "3649                16               130                67                27   \n",
       "\n",
       "      feature_1083_sms  feature_1084_sms  feature_1085_sms  feature_1086_sms  \\\n",
       "502               2999               173                28                 9   \n",
       "6547              3000               283               291                88   \n",
       "6938              2975               167                11                10   \n",
       "3115              1129               265                28                27   \n",
       "3649              3000               159               156                57   \n",
       "\n",
       "      feature_1087_sms  feature_1088_sms  feature_1089_sms  feature_1090_sms  \\\n",
       "502                723                 7                 6               265   \n",
       "6547               719                13                39               212   \n",
       "6938              1199                 2                25               395   \n",
       "3115               138                 3                21               129   \n",
       "3649               725                14                31               143   \n",
       "\n",
       "      feature_1091_sms  feature_1092_sms  feature_1093_sms  feature_1094_sms  \\\n",
       "502                  1                 2               171                12   \n",
       "6547                 0                 3               186                 6   \n",
       "6938                 0                 6               102                89   \n",
       "3115                 2                 3                59                 6   \n",
       "3649                 0                13               252                 1   \n",
       "\n",
       "      feature_1095_sms  feature_1096_sms  feature_1097_sms  feature_1098_sms  \\\n",
       "502               1088                49               201               390   \n",
       "6547               461               141               424               378   \n",
       "6938               669               162               185                84   \n",
       "3115               295                42               168               181   \n",
       "3649              1047                52               256               174   \n",
       "\n",
       "      feature_1099_sms  feature_1100_sms  feature_1101_sms  feature_1102_sms  \\\n",
       "502                 42         45.666667         45.666667          0.045682   \n",
       "6547                35         13.333333         13.333333          0.013333   \n",
       "6938                36         24.000000         24.000000          0.024202   \n",
       "3115                27         24.333333         24.333333          0.064659   \n",
       "3649                79         19.000000         19.000000          0.019000   \n",
       "\n",
       "      feature_1103_sms  feature_1104_sms  feature_1105_sms  feature_1106_sms  \\\n",
       "502           0.333333          0.007299          0.000000          0.000000   \n",
       "6547          0.666667          0.050000          0.333333          0.025000   \n",
       "6938          0.000000          0.000000          0.000000          0.000000   \n",
       "3115          0.333333          0.013699          0.666667          0.027397   \n",
       "3649          2.666667          0.140351          0.666667          0.035088   \n",
       "\n",
       "      feature_1107_sms  feature_1108_sms  feature_1109_sms  feature_1110_sms  \\\n",
       "502           7.000000          0.153285          0.000000          0.000000   \n",
       "6547          4.333333          0.325000          0.000000          0.000000   \n",
       "6938          6.000000          0.250000          0.333333          0.013889   \n",
       "3115          3.333333          0.136986          0.000000          0.000000   \n",
       "3649          6.000000          0.315789          0.000000          0.000000   \n",
       "\n",
       "      feature_1111_sms  feature_1112_sms  feature_1113_sms  feature_1114_sms  \\\n",
       "502           0.000000          0.000000          8.000000          0.175182   \n",
       "6547          1.000000          0.075000          2.333333          0.175000   \n",
       "6938          0.000000          0.000000          3.000000          0.125000   \n",
       "3115          0.333333          0.013699          4.000000          0.164384   \n",
       "3649          0.000000          0.000000          0.333333          0.017544   \n",
       "\n",
       "      feature_1115_sms  feature_1116_sms  feature_1117_sms  feature_1118_sms  \\\n",
       "502           0.333333          0.007299          0.333333          0.007299   \n",
       "6547          0.000000          0.000000          0.000000          0.000000   \n",
       "6938          0.000000          0.000000          0.333333          0.013889   \n",
       "3115          0.000000          0.000000          0.000000          0.000000   \n",
       "3649          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "      feature_1119_sms  feature_1120_sms  feature_1121_sms  feature_1122_sms  \\\n",
       "502           5.000000          0.109489          0.000000          0.000000   \n",
       "6547          2.000000          0.150000          0.000000          0.000000   \n",
       "6938          2.333333          0.097222          0.666667          0.027778   \n",
       "3115          0.666667          0.027397          0.000000          0.000000   \n",
       "3649          1.333333          0.070175          0.000000          0.000000   \n",
       "\n",
       "      feature_1123_sms  feature_1124_sms  feature_1125_sms  feature_1126_sms  \\\n",
       "502          14.000000          0.306569          1.000000          0.021898   \n",
       "6547          1.333333          0.100000          0.000000          0.000000   \n",
       "6938          8.000000          0.333333          0.666667          0.027778   \n",
       "3115         10.666667          0.438356          0.666667          0.027397   \n",
       "3649          4.333333          0.228070          0.000000          0.000000   \n",
       "\n",
       "      feature_1127_sms  feature_1128_sms  feature_1129_sms  feature_1130_sms  \\\n",
       "502           5.666667          0.124088          2.333333          0.051095   \n",
       "6547          1.333333          0.100000          0.000000          0.000000   \n",
       "6938          2.000000          0.083333          0.000000          0.000000   \n",
       "3115          3.333333          0.136986          0.333333          0.013699   \n",
       "3649          0.666667          0.035088          2.333333          0.122807   \n",
       "\n",
       "      feature_1131_sms  feature_1132_sms  feature_1133_sms  feature_1134_sms  \\\n",
       "502           1.666667          0.036496         42.142857         42.142857   \n",
       "6547          0.000000          0.000000         12.571429         12.571429   \n",
       "6938          0.666667          0.027778         19.285714         19.285714   \n",
       "3115          0.000000          0.000000         21.714286         21.714286   \n",
       "3649          0.666667          0.035088         23.142857         23.142857   \n",
       "\n",
       "      feature_1135_sms  feature_1136_sms  feature_1137_sms  feature_1138_sms  \\\n",
       "502           0.098366          0.142857          0.003390          0.142857   \n",
       "6547          0.029333          1.428571          0.113636          0.142857   \n",
       "6938          0.045378          0.000000          0.000000          0.000000   \n",
       "3115          0.134632          0.285714          0.013158          1.000000   \n",
       "3649          0.054000          2.000000          0.086420          0.428571   \n",
       "\n",
       "      feature_1139_sms  feature_1140_sms  feature_1141_sms  feature_1142_sms  \\\n",
       "502           0.003390          8.857143          0.210169          0.000000   \n",
       "6547          0.011364          4.571429          0.363636          0.000000   \n",
       "6938          0.000000          5.000000          0.259259          0.285714   \n",
       "3115          0.046053          2.000000          0.092105          0.285714   \n",
       "3649          0.018519          9.285714          0.401235          0.000000   \n",
       "\n",
       "      feature_1143_sms  feature_1144_sms  feature_1145_sms  feature_1146_sms  \\\n",
       "502           0.000000          0.142857          0.003390          4.142857   \n",
       "6547          0.000000          0.428571          0.034091          1.571429   \n",
       "6938          0.014815          0.571429          0.029630          2.571429   \n",
       "3115          0.013158          0.142857          0.006579          3.571429   \n",
       "3649          0.000000          0.000000          0.000000          0.571429   \n",
       "\n",
       "      feature_1147_sms  feature_1148_sms  feature_1149_sms  feature_1150_sms  \\\n",
       "502           0.098305          0.142857           0.00339          0.142857   \n",
       "6547          0.125000          0.000000           0.00000          0.000000   \n",
       "6938          0.133333          0.000000           0.00000          0.142857   \n",
       "3115          0.164474          0.000000           0.00000          0.142857   \n",
       "3649          0.024691          0.000000           0.00000          0.000000   \n",
       "\n",
       "      feature_1151_sms  feature_1152_sms  feature_1153_sms  feature_1154_sms  \\\n",
       "502           0.003390          4.428571          0.105085          0.000000   \n",
       "6547          0.000000          1.428571          0.113636          0.000000   \n",
       "6938          0.007407          1.714286          0.088889          0.428571   \n",
       "3115          0.006579          1.285714          0.059211          0.000000   \n",
       "3649          0.000000          1.285714          0.055556          0.000000   \n",
       "\n",
       "      feature_1155_sms  feature_1156_sms  feature_1157_sms  feature_1158_sms  \\\n",
       "502           0.000000         15.857143          0.376271          0.714286   \n",
       "6547          0.000000          1.714286          0.136364          0.428571   \n",
       "6938          0.022222          5.428571          0.281481          0.571429   \n",
       "3115          0.000000          8.142857          0.375000          0.285714   \n",
       "3649          0.000000          6.714286          0.290123          0.000000   \n",
       "\n",
       "      feature_1159_sms  feature_1160_sms  feature_1161_sms  feature_1162_sms  \\\n",
       "502           0.016949          3.857143          0.091525          2.857143   \n",
       "6547          0.034091          0.714286          0.056818          0.000000   \n",
       "6938          0.029630          1.571429          0.081481          0.571429   \n",
       "3115          0.013158          3.000000          0.138158          0.714286   \n",
       "3649          0.000000          1.571429          0.067901          1.000000   \n",
       "\n",
       "      feature_1163_sms  feature_1164_sms  feature_1165_sms  feature_1166_sms  \\\n",
       "502           0.067797          0.714286          0.016949         38.214286   \n",
       "6547          0.000000          0.142857          0.011364         13.071429   \n",
       "6938          0.029630          0.428571          0.022222         18.357143   \n",
       "3115          0.032895          0.857143          0.039474         19.571429   \n",
       "3649          0.043210          0.285714          0.012346         24.000000   \n",
       "\n",
       "      feature_1167_sms  feature_1168_sms  feature_1169_sms  feature_1170_sms  \\\n",
       "502          38.214286          0.178393          0.214286          0.005607   \n",
       "6547         13.071429          0.061000          1.214286          0.092896   \n",
       "6938         18.357143          0.086387          0.000000          0.000000   \n",
       "3115         19.571429          0.242693          0.357143          0.018248   \n",
       "3649         24.000000          0.112000          1.428571          0.059524   \n",
       "\n",
       "      feature_1171_sms  feature_1172_sms  feature_1173_sms  feature_1174_sms  \\\n",
       "502           0.071429          0.001869          9.714286          0.254206   \n",
       "6547          0.071429          0.005464          5.142857          0.393443   \n",
       "6938          0.000000          0.000000          4.928571          0.268482   \n",
       "3115          0.500000          0.025547          1.857143          0.094891   \n",
       "3649          0.214286          0.008929          8.285714          0.345238   \n",
       "\n",
       "      feature_1175_sms  feature_1176_sms  feature_1177_sms  feature_1178_sms  \\\n",
       "502           0.071429          0.001869          0.071429          0.001869   \n",
       "6547          0.142857          0.010929          0.285714          0.021858   \n",
       "6938          0.142857          0.007782          0.714286          0.038911   \n",
       "3115          0.142857          0.007299          0.642857          0.032847   \n",
       "3649          0.000000          0.000000          0.071429          0.002976   \n",
       "\n",
       "      feature_1179_sms  feature_1180_sms  feature_1181_sms  feature_1182_sms  \\\n",
       "502           3.071429          0.080374          0.071429          0.001869   \n",
       "6547          1.428571          0.109290          0.000000          0.000000   \n",
       "6938          2.571429          0.140078          0.000000          0.000000   \n",
       "3115          3.571429          0.182482          0.071429          0.003650   \n",
       "3649          0.642857          0.026786          0.000000          0.000000   \n",
       "\n",
       "      feature_1183_sms  feature_1184_sms  feature_1185_sms  feature_1186_sms  \\\n",
       "502           0.071429          0.001869          4.785714          0.125234   \n",
       "6547          0.000000          0.000000          1.142857          0.087432   \n",
       "6938          0.071429          0.003891          1.714286          0.093385   \n",
       "3115          0.071429          0.003650          1.071429          0.054745   \n",
       "3649          0.000000          0.000000          1.857143          0.077381   \n",
       "\n",
       "      feature_1187_sms  feature_1188_sms  feature_1189_sms  feature_1190_sms  \\\n",
       "502                0.0          0.000000         14.071429          0.368224   \n",
       "6547               0.0          0.000000          1.785714          0.136612   \n",
       "6938               0.5          0.027237          5.285714          0.287938   \n",
       "3115               0.0          0.000000          7.714286          0.394161   \n",
       "3649               0.0          0.000000          6.857143          0.285714   \n",
       "\n",
       "      feature_1191_sms  feature_1192_sms  feature_1193_sms  feature_1194_sms  \\\n",
       "502           0.357143          0.009346          2.642857          0.069159   \n",
       "6547          0.642857          0.049180          1.142857          0.087432   \n",
       "6938          0.500000          0.027237          1.142857          0.062257   \n",
       "3115          0.285714          0.014599          2.357143          0.120438   \n",
       "3649          0.071429          0.002976          3.000000          0.125000   \n",
       "\n",
       "      feature_1195_sms  feature_1196_sms  feature_1197_sms  feature_1198_sms  \\\n",
       "502           2.500000          0.065421          0.500000          0.013084   \n",
       "6547          0.000000          0.000000          0.071429          0.005464   \n",
       "6938          0.428571          0.023346          0.357143          0.019455   \n",
       "3115          0.500000          0.025547          0.428571          0.021898   \n",
       "3649          1.142857          0.047619          0.428571          0.017857   \n",
       "\n",
       "      feature_1199_sms  feature_1200_sms  feature_1201_sms  feature_1202_sms  \\\n",
       "502          37.285714         37.285714          0.261087          0.142857   \n",
       "6547         11.952381         11.952381          0.083667          0.809524   \n",
       "6938         15.571429         15.571429          0.109916          0.000000   \n",
       "3115         18.142857         18.142857          0.337467          0.285714   \n",
       "3649         22.952381         22.952381          0.160667          1.380952   \n",
       "\n",
       "      feature_1203_sms  feature_1204_sms  feature_1205_sms  feature_1206_sms  \\\n",
       "502           0.003831          0.190476          0.005109          9.142857   \n",
       "6547          0.067729          0.047619          0.003984          4.666667   \n",
       "6938          0.000000          0.000000          0.000000          4.571429   \n",
       "3115          0.015748          0.380952          0.020997          2.000000   \n",
       "3649          0.060166          0.476190          0.020747          6.714286   \n",
       "\n",
       "      feature_1207_sms  feature_1208_sms  feature_1209_sms  feature_1210_sms  \\\n",
       "502           0.245211          0.047619          0.001277          0.190476   \n",
       "6547          0.390438          0.142857          0.011952          0.190476   \n",
       "6938          0.293578          0.095238          0.006116          0.809524   \n",
       "3115          0.110236          0.095238          0.005249          0.428571   \n",
       "3649          0.292531          0.000000          0.000000          0.238095   \n",
       "\n",
       "      feature_1211_sms  feature_1212_sms  feature_1213_sms  feature_1214_sms  \\\n",
       "502           0.005109          3.285714          0.088123          0.047619   \n",
       "6547          0.015936          1.571429          0.131474          0.000000   \n",
       "6938          0.051988          2.190476          0.140673          0.000000   \n",
       "3115          0.023622          3.571429          0.196850          0.095238   \n",
       "3649          0.010373          0.666667          0.029046          0.000000   \n",
       "\n",
       "      feature_1215_sms  feature_1216_sms  feature_1217_sms  feature_1218_sms  \\\n",
       "502           0.001277          0.047619          0.001277          4.142857   \n",
       "6547          0.000000          0.047619          0.003984          0.761905   \n",
       "6938          0.000000          0.047619          0.003058          1.333333   \n",
       "3115          0.005249          0.047619          0.002625          0.904762   \n",
       "3649          0.000000          0.047619          0.002075          2.095238   \n",
       "\n",
       "      feature_1219_sms  feature_1220_sms  feature_1221_sms  feature_1222_sms  \\\n",
       "502           0.111111          0.000000          0.000000         13.809524   \n",
       "6547          0.063745          0.000000          0.000000          1.619048   \n",
       "6938          0.085627          0.428571          0.027523          3.952381   \n",
       "3115          0.049869          0.000000          0.000000          7.333333   \n",
       "3649          0.091286          0.000000          0.000000          6.571429   \n",
       "\n",
       "      feature_1223_sms  feature_1224_sms  feature_1225_sms  feature_1226_sms  \\\n",
       "502           0.370370          0.238095          0.006386          2.476190   \n",
       "6547          0.135458          0.523810          0.043825          1.380952   \n",
       "6938          0.253823          0.523810          0.033639          0.952381   \n",
       "3115          0.404199          0.333333          0.018373          2.047619   \n",
       "3649          0.286307          0.238095          0.010373          2.809524   \n",
       "\n",
       "      feature_1227_sms  feature_1228_sms  feature_1229_sms  feature_1230_sms  \\\n",
       "502           0.066411          3.095238          0.083014          0.428571   \n",
       "6547          0.115538          0.095238          0.007968          0.095238   \n",
       "6938          0.061162          0.380952          0.024465          0.285714   \n",
       "3115          0.112861          0.333333          0.018373          0.285714   \n",
       "3649          0.122407          1.285714          0.056017          0.428571   \n",
       "\n",
       "      feature_1231_sms  feature_1232_sms  feature_1233_sms  feature_1234_sms  \\\n",
       "502           0.011494         30.166667         30.166667          0.301767   \n",
       "6547          0.007968         10.100000         10.100000          0.101000   \n",
       "6938          0.018349         15.466667         15.466667          0.155966   \n",
       "3115          0.015748         14.700000         14.700000          0.390611   \n",
       "3649          0.018672         22.566667         22.566667          0.225667   \n",
       "\n",
       "      feature_1235_sms  feature_1236_sms  feature_1237_sms  feature_1238_sms  \\\n",
       "502           0.166667          0.005525          0.166667          0.005525   \n",
       "6547          0.666667          0.066007          0.100000          0.009901   \n",
       "6938          0.033333          0.002155          0.000000          0.000000   \n",
       "3115          0.300000          0.020408          0.300000          0.020408   \n",
       "3649          1.366667          0.060561          0.533333          0.023634   \n",
       "\n",
       "      feature_1239_sms  feature_1240_sms  feature_1241_sms  feature_1242_sms  \\\n",
       "502           7.333333          0.243094          0.033333          0.001105   \n",
       "6547          3.700000          0.366337          0.133333          0.013201   \n",
       "6938          5.233333          0.338362          0.066667          0.004310   \n",
       "3115          1.766667          0.120181          0.066667          0.004535   \n",
       "3649          5.933333          0.262925          0.100000          0.004431   \n",
       "\n",
       "      feature_1243_sms  feature_1244_sms  feature_1245_sms  feature_1246_sms  \\\n",
       "502           0.133333          0.004420          2.466667          0.081768   \n",
       "6547          0.133333          0.013201          1.266667          0.125413   \n",
       "6938          0.733333          0.047414          1.933333          0.125000   \n",
       "3115          0.366667          0.024943          2.900000          0.197279   \n",
       "3649          0.266667          0.011817          0.966667          0.042836   \n",
       "\n",
       "      feature_1247_sms  feature_1248_sms  feature_1249_sms  feature_1250_sms  \\\n",
       "502           0.033333          0.001105          0.033333          0.001105   \n",
       "6547          0.000000          0.000000          0.033333          0.003300   \n",
       "6938          0.000000          0.000000          0.033333          0.002155   \n",
       "3115          0.066667          0.004535          0.066667          0.004535   \n",
       "3649          0.000000          0.000000          0.100000          0.004431   \n",
       "\n",
       "      feature_1251_sms  feature_1252_sms  feature_1253_sms  feature_1254_sms  \\\n",
       "502           2.966667          0.098343          0.000000          0.000000   \n",
       "6547          0.566667          0.056106          0.033333          0.003300   \n",
       "6938          1.200000          0.077586          0.366667          0.023707   \n",
       "3115          0.733333          0.049887          0.000000          0.000000   \n",
       "3649          2.200000          0.097489          0.000000          0.000000   \n",
       "\n",
       "      feature_1255_sms  feature_1256_sms  feature_1257_sms  feature_1258_sms  \\\n",
       "502          11.000000          0.364641          0.166667          0.005525   \n",
       "6547          1.200000          0.118812          0.533333          0.052805   \n",
       "6938          3.800000          0.245690          0.566667          0.036638   \n",
       "3115          5.566667          0.378685          0.300000          0.020408   \n",
       "3649          5.800000          0.257016          0.233333          0.010340   \n",
       "\n",
       "      feature_1259_sms  feature_1260_sms  feature_1261_sms  feature_1262_sms  \\\n",
       "502           2.000000          0.066298          3.366667          0.111602   \n",
       "6547          1.300000          0.128713          0.333333          0.033003   \n",
       "6938          0.800000          0.051724          0.466667          0.030172   \n",
       "3115          1.766667          0.120181          0.300000          0.020408   \n",
       "3649          3.100000          0.137371          1.333333          0.059084   \n",
       "\n",
       "      feature_1263_sms  feature_1264_sms  feature_1265_sms  feature_1266_sms  \\\n",
       "502           0.300000          0.009945         20.450000         21.910714   \n",
       "6547          0.100000          0.009901          9.466667          9.466667   \n",
       "6938          0.233333          0.015086         16.200000         16.200000   \n",
       "3115          0.200000          0.013605         10.483333         10.483333   \n",
       "3649          0.633333          0.028065         18.683333         18.683333   \n",
       "\n",
       "      feature_1267_sms  feature_1268_sms  feature_1269_sms  feature_1270_sms  \\\n",
       "502           0.409136          0.100000          0.004890          0.083333   \n",
       "6547          0.189333          0.600000          0.063380          0.066667   \n",
       "6938          0.326723          0.033333          0.002058          0.000000   \n",
       "3115          0.557130          0.200000          0.019078          0.200000   \n",
       "3649          0.373667          1.250000          0.066905          0.416667   \n",
       "\n",
       "      feature_1271_sms  feature_1272_sms  feature_1273_sms  feature_1274_sms  \\\n",
       "502           0.004075          4.516667          0.220864          0.066667   \n",
       "6547          0.007042          3.066667          0.323944          0.116667   \n",
       "6938          0.000000          6.233333          0.384774          0.033333   \n",
       "3115          0.019078          1.450000          0.138315          0.033333   \n",
       "3649          0.022302          4.433333          0.237288          0.050000   \n",
       "\n",
       "      feature_1275_sms  feature_1276_sms  feature_1277_sms  feature_1278_sms  \\\n",
       "502           0.003260          0.083333          0.004075          1.633333   \n",
       "6547          0.012324          0.116667          0.012324          1.050000   \n",
       "6938          0.002058          0.366667          0.022634          1.866667   \n",
       "3115          0.003180          0.283333          0.027027          1.916667   \n",
       "3649          0.002676          0.216667          0.011597          0.866667   \n",
       "\n",
       "      feature_1279_sms  feature_1280_sms  feature_1281_sms  feature_1282_sms  \\\n",
       "502           0.079870          0.016667          0.000815          0.016667   \n",
       "6547          0.110915          0.000000          0.000000          0.016667   \n",
       "6938          0.115226          0.000000          0.000000          0.033333   \n",
       "3115          0.182830          0.033333          0.003180          0.033333   \n",
       "3649          0.046387          0.000000          0.000000          0.116667   \n",
       "\n",
       "      feature_1283_sms  feature_1284_sms  feature_1285_sms  feature_1286_sms  \\\n",
       "502           0.000815          1.983333          0.096985          0.033333   \n",
       "6547          0.001761          0.566667          0.059859          0.016667   \n",
       "6938          0.002058          0.800000          0.049383          0.350000   \n",
       "3115          0.003180          0.650000          0.062003          0.016667   \n",
       "3649          0.006244          2.066667          0.110616          0.000000   \n",
       "\n",
       "      feature_1287_sms  feature_1288_sms  feature_1289_sms  feature_1290_sms  \\\n",
       "502           0.001630          6.933333          0.339038          0.433333   \n",
       "6547          0.001761          1.400000          0.147887          0.533333   \n",
       "6938          0.021605          4.333333          0.267490          0.600000   \n",
       "3115          0.001590          3.450000          0.329094          0.533333   \n",
       "3649          0.000000          5.266667          0.281891          0.266667   \n",
       "\n",
       "      feature_1291_sms  feature_1292_sms  feature_1293_sms  feature_1294_sms  \\\n",
       "502           0.021190          1.516667          0.074165          2.766667   \n",
       "6547          0.056338          1.383333          0.146127          0.383333   \n",
       "6938          0.037037          0.800000          0.049383          0.550000   \n",
       "3115          0.050874          1.183333          0.112878          0.333333   \n",
       "3649          0.014273          2.166667          0.115968          1.116667   \n",
       "\n",
       "      feature_1295_sms  feature_1296_sms  feature_1297_sms  feature_1298_sms  \\\n",
       "502           0.135289          0.266667          0.013040             2.999   \n",
       "6547          0.040493          0.150000          0.015845             3.000   \n",
       "6938          0.033951          0.200000          0.012346             2.975   \n",
       "3115          0.031797          0.166667          0.015898             1.129   \n",
       "3649          0.059768          0.450000          0.024086             3.000   \n",
       "\n",
       "      feature_1299_sms  feature_1300_sms  feature_1301_sms  feature_1302_sms  \\\n",
       "502          17.335260               1.0             0.028          0.009336   \n",
       "6547         10.600707               1.0             0.291          0.097000   \n",
       "6938         17.814371               1.0             0.011          0.003697   \n",
       "3115          4.260377               1.0             0.028          0.024801   \n",
       "3649         18.867925               1.0             0.156          0.052000   \n",
       "\n",
       "      feature_1303_sms  feature_1304_sms  feature_1305_sms  feature_1306_sms  \\\n",
       "502              0.009          0.003001             0.723          0.241080   \n",
       "6547             0.088          0.029333             0.719          0.239667   \n",
       "6938             0.010          0.003361             1.199          0.403025   \n",
       "3115             0.027          0.023915             0.138          0.122232   \n",
       "3649             0.057          0.019000             0.725          0.241667   \n",
       "\n",
       "      feature_1307_sms  feature_1308_sms  feature_1309_sms  feature_1310_sms  \\\n",
       "502              0.007          0.002334             0.006          0.002001   \n",
       "6547             0.013          0.004333             0.039          0.013000   \n",
       "6938             0.002          0.000672             0.025          0.008403   \n",
       "3115             0.003          0.002657             0.021          0.018601   \n",
       "3649             0.014          0.004667             0.031          0.010333   \n",
       "\n",
       "      feature_1311_sms  feature_1312_sms  feature_1313_sms  feature_1314_sms  \\\n",
       "502              0.265          0.088363             0.001          0.000333   \n",
       "6547             0.212          0.070667             0.000          0.000000   \n",
       "6938             0.395          0.132773             0.000          0.000000   \n",
       "3115             0.129          0.114260             0.002          0.001771   \n",
       "3649             0.143          0.047667             0.000          0.000000   \n",
       "\n",
       "      feature_1315_sms  feature_1316_sms  feature_1317_sms  feature_1318_sms  \\\n",
       "502              0.002          0.000667             0.171          0.057019   \n",
       "6547             0.003          0.001000             0.186          0.062000   \n",
       "6938             0.006          0.002017             0.102          0.034286   \n",
       "3115             0.003          0.002657             0.059          0.052259   \n",
       "3649             0.013          0.004333             0.252          0.084000   \n",
       "\n",
       "      feature_1319_sms  feature_1320_sms  feature_1321_sms  feature_1322_sms  \\\n",
       "502              0.012          0.004001             1.088          0.362788   \n",
       "6547             0.006          0.002000             0.461          0.153667   \n",
       "6938             0.089          0.029916             0.669          0.224874   \n",
       "3115             0.006          0.005314             0.295          0.261293   \n",
       "3649             0.001          0.000333             1.047          0.349000   \n",
       "\n",
       "      feature_1323_sms  feature_1324_sms  feature_1325_sms  feature_1326_sms  \\\n",
       "502              0.049          0.016339             0.201          0.067022   \n",
       "6547             0.141          0.047000             0.424          0.141333   \n",
       "6938             0.162          0.054454             0.185          0.062185   \n",
       "3115             0.042          0.037201             0.168          0.148804   \n",
       "3649             0.052          0.017333             0.256          0.085333   \n",
       "\n",
       "      feature_1327_sms  feature_1328_sms  feature_1329_sms  feature_1330_sms  \n",
       "502              0.390          0.130043             0.042          0.014005  \n",
       "6547             0.378          0.126000             0.035          0.011667  \n",
       "6938             0.084          0.028235             0.036          0.012101  \n",
       "3115             0.181          0.160319             0.027          0.023915  \n",
       "3649             0.174          0.058000             0.079          0.026333  \n",
       "\n",
       "[5 rows x 1761 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6136, 1761)\n"
     ]
    }
   ],
   "source": [
    "#  './data/filter_feas_df32n_old_qcut_oh.pkl' \n",
    "train_x, test_x, train_y, test_y,oot_x, oot_y,df,final_feas = read_train('./data/filter_feas_df_0403_n_old.pkl',model='nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437cedd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b4c515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 1 1 0.01\n",
      "验证集最优结果： 0.5632795691490173 0.5629227161407471\n",
      "------------train------------\n",
      " (0.6999401031038774, 0.2912448334697088)\n",
      "------------test------------\n",
      " (0.6653864090606263, 0.24184987785920498)\n",
      "------------oot------------\n",
      " (0.6427333495522423, 0.20558857262016472)\n",
      "隐藏层vs神经元数vs norm 1 1 0.05\n",
      "验证集最优结果： 0.5918880105018616 0.5820297002792358\n",
      "------------train------------\n",
      " (0.49988866622133155, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5007171074734416, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 1 1 0.1\n",
      "验证集最优结果： 0.6019687056541443 0.5919893383979797\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.4986842105263158, 0.0)\n",
      "------------oot------------\n",
      " (0.5031128720212236, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 1 1 0.2\n",
      "验证集最优结果： 0.6225577592849731 0.6120771765708923\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 1 1 0.3\n",
      "验证集最优结果： 0.6522127985954285 0.6379278898239136\n",
      "------------train------------\n",
      " (0.5501749192407104, 0.08228209204630127)\n",
      "------------test------------\n",
      " (0.5308871863202309, 0.07119697979125028)\n",
      "------------oot------------\n",
      " (0.5416084523685399, 0.0740902929830049)\n",
      "隐藏层vs神经元数vs norm 1 1 0.4\n",
      "验证集最优结果： 0.6689000129699707 0.6604722738265991\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 1 1 0.5\n",
      "验证集最优结果： 0.7091313004493713 0.6902035474777222\n",
      "------------train------------\n",
      " (0.5445361509916151, 0.07246279116828724)\n",
      "------------test------------\n",
      " (0.5101732178547634, 0.05052187430601823)\n",
      "------------oot------------\n",
      " (0.5485130735990917, 0.06978764814235572)\n",
      "隐藏层vs神经元数vs norm 1 1 0.8\n",
      "验证集最优结果： 0.7495088577270508 0.739313542842865\n",
      "------------train------------\n",
      " (0.49988866622133155, 0.0)\n",
      "------------test------------\n",
      " (0.4986842105263158, 0.0)\n",
      "------------oot------------\n",
      " (0.4995169082125604, 0.0)\n",
      "隐藏层vs神经元数vs norm 1 2 0.01\n",
      "验证集最优结果： 0.5695420503616333 0.5677931308746338\n",
      "------------train------------\n",
      " (0.6916667512668024, 0.28059036005140986)\n",
      "------------test------------\n",
      " (0.66450921607817, 0.24613590939373753)\n",
      "------------oot------------\n",
      " (0.6471865985472491, 0.22381399228443327)\n",
      "隐藏层vs神经元数vs norm 1 2 0.05\n",
      "验证集最优结果： 0.6022545695304871 0.5923532843589783\n",
      "------------train------------\n",
      " (0.49988866622133155, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5031128720212236, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 1 2 0.1\n",
      "验证集最优结果： 0.6298447251319885 0.6187960505485535\n",
      "------------train------------\n",
      " (0.6589884260246262, 0.23713377447228134)\n",
      "------------test------------\n",
      " (0.6456329113924051, 0.23174550299800134)\n",
      "------------oot------------\n",
      " (0.6404024606401835, 0.2169950995725159)\n",
      "隐藏层vs神经元数vs norm 1 2 0.2\n",
      "验证集最优结果： 0.6763433218002319 0.6603617668151855\n",
      "------------train------------\n",
      " (0.5981062428808986, 0.14519752101298172)\n",
      "------------test------------\n",
      " (0.5772729291583388, 0.12841439040639574)\n",
      "------------oot------------\n",
      " (0.6161748861780142, 0.1870086539464081)\n",
      "隐藏层vs神经元数vs norm 1 2 0.3\n",
      "验证集最优结果： 0.7119863033294678 0.7031996846199036\n",
      "------------train------------\n",
      " (0.5012158054711247, 0.002431610942249196)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5031128720212236, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 1 2 0.4\n",
      "验证集最优结果： 0.7517659664154053 0.7413060665130615\n",
      "------------train------------\n",
      " (0.49988866622133155, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019173067343227, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 1 2 0.5\n",
      "验证集最优结果： 0.8141341805458069 0.7955604791641235\n",
      "------------train------------\n",
      " (0.5561240684679051, 0.09791118880787575)\n",
      "------------test------------\n",
      " (0.5428036864312681, 0.08095713968465468)\n",
      "------------oot------------\n",
      " (0.5639731692906544, 0.11507315886421299)\n",
      "隐藏层vs神经元数vs norm 1 2 0.8\n",
      "验证集最优结果： 0.9399387836456299 0.9311032891273499\n",
      "------------train------------\n",
      " (0.5009118541033435, 0.0018237082066869803)\n",
      "------------test------------\n",
      " (0.4986842105263158, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 1 3 0.01\n",
      "验证集最优结果： 0.560943067073822 0.572981059551239\n",
      "------------train------------\n",
      " (0.7218104564414204, 0.3281683935246379)\n",
      "------------test------------\n",
      " (0.6597346213635354, 0.22938041305796136)\n",
      "------------oot------------\n",
      " (0.6497688805477357, 0.2436867896986758)\n",
      "隐藏层vs神经元数vs norm 1 3 0.05\n",
      "验证集最优结果： 0.6045428514480591 0.5977842211723328\n",
      "------------train------------\n",
      " (0.6714284360683542, 0.2488041263208619)\n",
      "------------test------------\n",
      " (0.6507705973795247, 0.2232733733066844)\n",
      "------------oot------------\n",
      " (0.6370092331931556, 0.21939318110728812)\n",
      "隐藏层vs神经元数vs norm 1 3 0.1\n",
      "验证集最优结果： 0.6515403985977173 0.6397795081138611\n",
      "------------train------------\n",
      " (0.6619226971335443, 0.239697361626326)\n",
      "------------test------------\n",
      " (0.6454674661336887, 0.21793248945147686)\n",
      "------------oot------------\n",
      " (0.6273891032101855, 0.18711291836096344)\n",
      "隐藏层vs神经元数vs norm 1 3 0.2\n",
      "验证集最优结果： 0.7198479771614075 0.7058066725730896\n",
      "------------train------------\n",
      " (0.6038191208489251, 0.15565707571847515)\n",
      "------------test------------\n",
      " (0.5962913613146791, 0.16058183433266715)\n",
      "------------oot------------\n",
      " (0.6034754804851771, 0.16514093073367397)\n",
      "隐藏层vs神经元数vs norm 1 3 0.3\n",
      "验证集最优结果： 0.782507061958313 0.7690427899360657\n",
      "------------train------------\n",
      " (0.5555613760448963, 0.08667250069202914)\n",
      "------------test------------\n",
      " (0.5335354208305574, 0.07563846324672441)\n",
      "------------oot------------\n",
      " (0.5573767073297884, 0.12392868314044414)\n",
      "隐藏层vs神经元数vs norm 1 3 0.4\n",
      "验证集最优结果： 0.8539813160896301 0.8364948630332947\n",
      "------------train------------\n",
      " (0.5656001635151424, 0.09030800540628708)\n",
      "------------test------------\n",
      " (0.553623140128803, 0.09020652898067955)\n",
      "------------oot------------\n",
      " (0.5875415609541352, 0.1367115003649254)\n",
      "隐藏层vs神经元数vs norm 1 3 0.5\n",
      "验证集最优结果： 0.9189782738685608 0.8977288603782654\n",
      "------------train------------\n",
      " (0.5332853481363267, 0.05287129476785385)\n",
      "------------test------------\n",
      " (0.5207339551410171, 0.057073062402842545)\n",
      "------------oot------------\n",
      " (0.5281977316697366, 0.058360268307093455)\n",
      "隐藏层vs神经元数vs norm 1 3 0.8\n",
      "验证集最优结果： 1.1143871545791626 1.0926878452301025\n",
      "------------train------------\n",
      " (0.5701150358806095, 0.11224285788733829)\n",
      "------------test------------\n",
      " (0.5476027093049078, 0.07762602709304911)\n",
      "------------oot------------\n",
      " (0.5700830639835957, 0.11128488513536999)\n",
      "隐藏层vs神经元数vs norm 1 4 0.01\n",
      "验证集最优结果： 0.5668055415153503 0.5719625353813171\n",
      "------------train------------\n",
      " (0.7156596881706676, 0.3170802259703466)\n",
      "------------test------------\n",
      " (0.6613280035531868, 0.22973573173439932)\n",
      "------------oot------------\n",
      " (0.6513143108701445, 0.2261078094046502)\n",
      "隐藏层vs神经元数vs norm 1 4 0.05\n",
      "验证集最优结果： 0.6224562525749207 0.6137968897819519\n",
      "------------train------------\n",
      " (0.6717876144047636, 0.25461811837115633)\n",
      "------------test------------\n",
      " (0.6560737286253608, 0.22855873861869863)\n",
      "------------oot------------\n",
      " (0.6328108527670617, 0.19820665206964866)\n",
      "隐藏层vs神经元数vs norm 1 4 0.1\n",
      "验证集最优结果： 0.6726613640785217 0.662016749382019\n",
      "------------train------------\n",
      " (0.6151900558970018, 0.164577584754108)\n",
      "------------test------------\n",
      " (0.5965312014212747, 0.17178547634910057)\n",
      "------------oot------------\n",
      " (0.6308414138254614, 0.19343134188301536)\n",
      "隐藏层vs神经元数vs norm 1 4 0.2\n",
      "验证集最优结果： 0.7596446871757507 0.7461434006690979\n",
      "------------train------------\n",
      " (0.597881951000955, 0.13985837260471634)\n",
      "------------test------------\n",
      " (0.5875705085498557, 0.15535198756384633)\n",
      "------------oot------------\n",
      " (0.5897392231142622, 0.13997845202099185)\n",
      "隐藏层vs神经元数vs norm 1 4 0.3\n",
      "验证集最优结果： 0.8470340371131897 0.8309351801872253\n",
      "------------train------------\n",
      " (0.5645797505175836, 0.10337838798163701)\n",
      "------------test------------\n",
      " (0.5760581834332668, 0.14053964023984006)\n",
      "------------oot------------\n",
      " (0.569930142842248, 0.13997150106002154)\n",
      "隐藏层vs神经元数vs norm 1 4 0.4\n",
      "验证集最优结果： 0.9340941309928894 0.9147763848304749\n",
      "------------train------------\n",
      " (0.5675067121747718, 0.10077324524090392)\n",
      "------------test------------\n",
      " (0.5965101043748612, 0.17035309793471026)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.5945933108585595, 0.14171619226358045)\n",
      "隐藏层vs神经元数vs norm 1 4 0.5\n",
      "验证集最优结果： 1.0289721488952637 1.0122432708740234\n",
      "------------train------------\n",
      " (0.5246064570884423, 0.04504842173370721)\n",
      "------------test------------\n",
      " (0.5375971574505884, 0.08112369531423502)\n",
      "------------oot------------\n",
      " (0.5260116544445603, 0.06216244395787718)\n",
      "隐藏层vs神经元数vs norm 1 4 0.8\n",
      "验证集最优结果： 1.2710920572280884 1.2460967302322388\n",
      "------------train------------\n",
      " (0.5605371499500182, 0.09602345521844097)\n",
      "------------test------------\n",
      " (0.5377315123251165, 0.07061958694203863)\n",
      "------------oot------------\n",
      " (0.5379418204566782, 0.09604837868835364)\n",
      "隐藏层vs神经元数vs norm 1 5 0.01\n",
      "验证集最优结果： 0.5756060481071472 0.577660083770752\n",
      "------------train------------\n",
      " (0.7081079416516247, 0.3099076234197541)\n",
      "------------test------------\n",
      " (0.6582656007106373, 0.24309349322673768)\n",
      "------------oot------------\n",
      " (0.6420255100267611, 0.21160810482049142)\n",
      "隐藏层vs神经元数vs norm 1 5 0.05\n",
      "验证集最优结果： 0.643292248249054 0.6294358968734741\n",
      "------------train------------\n",
      " (0.6572996042744049, 0.23578301486458225)\n",
      "------------test------------\n",
      " (0.6392405063291139, 0.21523428825227625)\n",
      "------------oot------------\n",
      " (0.6158574589603679, 0.19231918812775867)\n",
      "隐藏层vs神经元数vs norm 1 5 0.1\n",
      "验证集最优结果： 0.6889810562133789 0.6787121891975403\n",
      "------------train------------\n",
      " (0.6610123996726989, 0.24031717606100414)\n",
      "------------test------------\n",
      " (0.6356873195647346, 0.21144792360648454)\n",
      "------------oot------------\n",
      " (0.6280146896975174, 0.20239808153477218)\n",
      "隐藏层vs神经元数vs norm 1 5 0.2\n",
      "验证集最优结果： 0.7965410947799683 0.7825479507446289\n",
      "------------train------------\n",
      " (0.5822185404243136, 0.1327596767327292)\n",
      "------------test------------\n",
      " (0.5712780368643128, 0.12195203197868087)\n",
      "------------oot------------\n",
      " (0.5987546194928115, 0.15507593924860114)\n",
      "隐藏层vs神经元数vs norm 1 5 0.3\n",
      "验证集最优结果： 0.9063836932182312 0.891412615776062\n",
      "------------train------------\n",
      " (0.569607908826772, 0.1020905708749481)\n",
      "------------test------------\n",
      " (0.5743015767266267, 0.147812569398179)\n",
      "------------oot------------\n",
      " (0.6080955525434724, 0.16979807458381124)\n",
      "隐藏层vs神经元数vs norm 1 5 0.4\n",
      "验证集最优结果： 1.0151618719100952 0.9936647415161133\n",
      "------------train------------\n",
      " (0.5596050594941995, 0.09428042170122075)\n",
      "------------test------------\n",
      " (0.5388441039307128, 0.08320008882966912)\n",
      "------------oot------------\n",
      " (0.5278999988415065, 0.058318562541271324)\n",
      "隐藏层vs神经元数vs norm 1 5 0.5\n",
      "验证集最优结果： 1.1250171661376953 1.1030126810073853\n",
      "------------train------------\n",
      " (0.5736846201690784, 0.10100010896497486)\n",
      "------------test------------\n",
      " (0.5566711081501221, 0.11621141461248063)\n",
      "------------oot------------\n",
      " (0.5702568380078545, 0.11261946964167796)\n",
      "隐藏层vs神经元数vs norm 1 5 0.8\n",
      "验证集最优结果： 1.4310672283172607 1.4065170288085938\n",
      "------------train------------\n",
      " (0.5628883569232351, 0.09020242443685067)\n",
      "------------test------------\n",
      " (0.5542049744614701, 0.11001554519209411)\n",
      "------------oot------------\n",
      " (0.5844321644133968, 0.15089146074444793)\n",
      "隐藏层vs神经元数vs norm 1 6 0.01\n",
      "验证集最优结果： 0.5806083679199219 0.5827086567878723\n",
      "------------train------------\n",
      " (0.7089295104900785, 0.3143934610186262)\n",
      "------------test------------\n",
      " (0.654594714634688, 0.22809238285587388)\n",
      "------------oot------------\n",
      " (0.6441339681877686, 0.21378375560421226)\n",
      "隐藏层vs神经元数vs norm 1 6 0.05\n",
      "验证集最优结果： 0.652550458908081 0.6426043510437012\n",
      "------------train------------\n",
      " (0.6691680558008959, 0.25554614802045833)\n",
      "------------test------------\n",
      " (0.6406062624916722, 0.2092604930046636)\n",
      "------------oot------------\n",
      " (0.6266407164123773, 0.20765995898933032)\n",
      "隐藏层vs神经元数vs norm 1 6 0.1\n",
      "验证集最优结果： 0.7182993292808533 0.7079304456710815\n",
      "------------train------------\n",
      " (0.5969038380712794, 0.14980843145257083)\n",
      "------------test------------\n",
      " (0.5812114146124806, 0.15358649789029533)\n",
      "------------oot------------\n",
      " (0.610088161354974, 0.1815382476627394)\n",
      "隐藏层vs神经元数vs norm 1 6 0.2\n",
      "验证集最优结果： 0.8433364629745483 0.8284004926681519\n",
      "------------train------------\n",
      " (0.608344009870467, 0.1712555810709565)\n",
      "------------test------------\n",
      " (0.5769198312236287, 0.1269931157006441)\n",
      "------------oot------------\n",
      " (0.6232845607571913, 0.20444861502102668)\n",
      "隐藏层vs神经元数vs norm 1 6 0.3\n",
      "验证集最优结果： 0.9794207215309143 0.9615870714187622\n",
      "------------train------------\n",
      " (0.5817070141634163, 0.12605690949612836)\n",
      "------------test------------\n",
      " (0.5671518987341773, 0.12217410615145458)\n",
      "------------oot------------\n",
      " (0.596705244500052, 0.16066451186876585)\n",
      "隐藏层vs神经元数vs norm 1 6 0.4\n",
      "验证集最优结果： 1.1045923233032227 1.08480703830719\n",
      "------------train------------\n",
      " (0.5761950107577533, 0.11418256980018793)\n",
      "------------test------------\n",
      " (0.6089384854541416, 0.18201199200532975)\n",
      "------------oot------------\n",
      " (0.6004900427484099, 0.16368122892989956)\n",
      "隐藏层vs神经元数vs norm 1 6 0.5\n",
      "验证集最优结果： 1.2260923385620117 1.2011276483535767\n",
      "------------train------------\n",
      " (0.5307907270129587, 0.05182292988543791)\n",
      "------------test------------\n",
      " (0.542118587608261, 0.07314012880302023)\n",
      "------------oot------------\n",
      " (0.5348683372142865, 0.07792027247767008)\n",
      "隐藏层vs神经元数vs norm 1 6 0.8\n",
      "验证集最优结果： 1.6162303686141968 1.5862658023834229\n",
      "------------train------------\n",
      " (0.5198954477682146, 0.04495272206012835)\n",
      "------------test------------\n",
      " (0.5332234066178103, 0.06661114812347327)\n",
      "------------oot------------\n",
      " (0.5524484760018074, 0.09850901887185903)\n",
      "隐藏层vs神经元数vs norm 1 7 0.01\n",
      "验证集最优结果： 0.5818237066268921 0.5821614265441895\n",
      "------------train------------\n",
      " (0.7041444591310281, 0.3057586974015576)\n",
      "------------test------------\n",
      " (0.6644836775483012, 0.23887408394403736)\n",
      "------------oot------------\n",
      " (0.6502786176855617, 0.23445591353004547)\n",
      "隐藏层vs神经元数vs norm 1 7 0.05\n",
      "验证集最优结果： 0.657818078994751 0.6485077142715454\n",
      "------------train------------\n",
      " (0.6597995044462447, 0.2457133111207217)\n",
      "------------test------------\n",
      " (0.6475483011325782, 0.20779480346435708)\n",
      "------------oot------------\n",
      " (0.6403433774719356, 0.2377159142251416)\n",
      "隐藏层vs神经元数vs norm 1 7 0.1\n",
      "验证集最优结果： 0.735310435295105 0.7248817682266235\n",
      "------------train------------\n",
      " (0.600974187483376, 0.14924005390043849)\n",
      "------------test------------\n",
      " (0.6050721741061514, 0.16693315567399508)\n",
      "------------oot------------\n",
      " (0.6248728553389171, 0.20086191916032392)\n",
      "隐藏层vs神经元数vs norm 1 7 0.2\n",
      "验证集最优结果： 0.886544942855835 0.8733386397361755\n",
      "------------train------------\n",
      " (0.5848253751677621, 0.12443813665832182)\n",
      "------------test------------\n",
      " (0.568260048856318, 0.11077059737952477)\n",
      "------------oot------------\n",
      " (0.5995597724718775, 0.15582664303339933)\n",
      "隐藏层vs神经元数vs norm 1 7 0.3\n",
      "验证集最优结果： 1.0440102815628052 1.0272890329360962\n",
      "------------train------------\n",
      " (0.5483946616637531, 0.07929076660582224)\n",
      "------------test------------\n",
      " (0.5371463468798578, 0.08959582500555191)\n",
      "------------oot------------\n",
      " (0.50667292253154, 0.040037535189239915)\n",
      "隐藏层vs神经元数vs norm 1 7 0.4\n",
      "验证集最优结果： 1.1903321743011475 1.1663316488265991\n",
      "------------train------------\n",
      " (0.5680534997722565, 0.09582244529586026)\n",
      "------------test------------\n",
      " (0.5205185431934266, 0.05541860981567848)\n",
      "------------oot------------\n",
      " (0.5862857540054913, 0.14524728043652035)\n",
      "隐藏层vs神经元数vs norm 1 7 0.5\n",
      "验证集最优结果： 1.312117099761963 1.295201063156128\n",
      "------------train------------\n",
      " (0.5525397299157586, 0.08347908244723146)\n",
      "------------test------------\n",
      " (0.5484821230290917, 0.07989118365534087)\n",
      "------------oot------------\n",
      " (0.5716864189807573, 0.11557362805407845)\n",
      "隐藏层vs神经元数vs norm 1 7 0.8\n",
      "验证集最优结果： 1.7777514457702637 1.7462687492370605\n",
      "------------train------------\n",
      " (0.5644137988912645, 0.09971012609481034)\n",
      "------------test------------\n",
      " (0.5530524095047746, 0.10255385298689768)\n",
      "------------oot------------\n",
      " (0.582353827083261, 0.12087026031348824)\n",
      "隐藏层vs神经元数vs norm 1 8 0.01\n",
      "验证集最优结果： 0.5874437689781189 0.5860938429832458\n",
      "------------train------------\n",
      " (0.6980414730169558, 0.2852939922397988)\n",
      "------------test------------\n",
      " (0.6634021763268932, 0.2374194981123695)\n",
      "------------oot------------\n",
      " (0.6566572828693568, 0.23564452785597612)\n",
      "隐藏层vs神经元数vs norm 1 8 0.05\n",
      "验证集最优结果： 0.6730551719665527 0.6621007323265076\n",
      "------------train------------\n",
      " (0.6601935380385898, 0.23948944833266667)\n",
      "------------test------------\n",
      " (0.6437308461025983, 0.2018987341772152)\n",
      "------------oot------------\n",
      " (0.6234038855871824, 0.1919021304695374)\n",
      "隐藏层vs神经元数vs norm 1 8 0.1\n",
      "验证集最优结果： 0.7582581043243408 0.7465453743934631\n",
      "------------train------------\n",
      " (0.6077499815571704, 0.16346316408568567)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.5820286475682878, 0.1517543859649123)\n",
      "------------oot------------\n",
      " (0.6094058086863842, 0.15808570534876443)\n",
      "隐藏层vs神经元数vs norm 1 8 0.2\n",
      "验证集最优结果： 0.9278296828269958 0.9122298359870911\n",
      "------------train------------\n",
      " (0.5522772664545572, 0.08075198015077772)\n",
      "------------test------------\n",
      " (0.5212103042416167, 0.07297357317343994)\n",
      "------------oot------------\n",
      " (0.5731125244731751, 0.1336947833037918)\n",
      "隐藏层vs神经元数vs norm 1 8 0.3\n",
      "验证集最优结果： 1.1024572849273682 1.0837979316711426\n",
      "------------train------------\n",
      " (0.5738381186554128, 0.1197415432012286)\n",
      "------------test------------\n",
      " (0.5632778147901399, 0.10167666000444148)\n",
      "------------oot------------\n",
      " (0.5977061828797832, 0.16599589893302746)\n",
      "隐藏层vs神经元数vs norm 1 8 0.4\n",
      "验证集最优结果： 1.2668726444244385 1.2472553253173828\n",
      "------------train------------\n",
      " (0.5551349913606342, 0.0771656111953728)\n",
      "------------test------------\n",
      " (0.5120164334887852, 0.051565622918054665)\n",
      "------------oot------------\n",
      " (0.5280332255934383, 0.07200500469189863)\n",
      "隐藏层vs神经元数vs norm 1 8 0.5\n",
      "验证集最优结果： 1.4378927946090698 1.418985366821289\n",
      "------------train------------\n",
      " (0.5755191571931435, 0.11492353162928359)\n",
      "------------test------------\n",
      " (0.5663468798578726, 0.12604930046635576)\n",
      "------------oot------------\n",
      " (0.5829666701421472, 0.14676258992805752)\n",
      "隐藏层vs神经元数vs norm 1 8 0.8\n",
      "验证集最优结果： 1.9731857776641846 1.9413725137710571\n",
      "------------train------------\n",
      " (0.5300353493207286, 0.052566734279095195)\n",
      "------------test------------\n",
      " (0.5372929158338886, 0.08338885187652673)\n",
      "------------oot------------\n",
      " (0.5660306537378792, 0.10592569422722697)\n",
      "隐藏层vs神经元数vs norm 1 9 0.01\n",
      "验证集最优结果： 0.5992807745933533 0.5993983745574951\n",
      "------------train------------\n",
      " (0.6939449990829346, 0.28067414802587276)\n",
      "------------test------------\n",
      " (0.6506040417499445, 0.22835887186320225)\n",
      "------------oot------------\n",
      " (0.64494491363431, 0.2245855489521426)\n",
      "隐藏层vs神经元数vs norm 1 9 0.05\n",
      "验证集最优结果： 0.6855593919754028 0.6760532855987549\n",
      "------------train------------\n",
      " (0.6632407672487832, 0.24648378147717254)\n",
      "------------test------------\n",
      " (0.6453653120142128, 0.2139129469242727)\n",
      "------------oot------------\n",
      " (0.639372559923076, 0.23794529593716335)\n",
      "隐藏层vs神经元数vs norm 1 9 0.1\n",
      "验证集最优结果： 0.7723820209503174 0.760571300983429\n",
      "------------train------------\n",
      " (0.5954611688760838, 0.1504864507806562)\n",
      "------------test------------\n",
      " (0.5705673995114369, 0.10971574505884968)\n",
      "------------oot------------\n",
      " (0.6077873932737868, 0.15422097104924748)\n",
      "隐藏层vs神经元数vs norm 1 9 0.2\n",
      "验证集最优结果： 0.9683396220207214 0.9540813565254211\n",
      "------------train------------\n",
      " (0.5757099474193237, 0.11209599205164805)\n",
      "------------test------------\n",
      " (0.5899777925827226, 0.14073950699533644)\n",
      "------------oot------------\n",
      " (0.6007611302262538, 0.16055329649324024)\n",
      "隐藏层vs神经元数vs norm 1 9 0.3\n",
      "验证集最优结果： 1.1653060913085938 1.1496657133102417\n",
      "------------train------------\n",
      " (0.5688393335133624, 0.10933721546436337)\n",
      "------------test------------\n",
      " (0.5604197201865422, 0.10484121696646681)\n",
      "------------oot------------\n",
      " (0.5573523789663921, 0.11309908594863238)\n",
      "隐藏层vs神经元数vs norm 1 9 0.4\n",
      "验证集最优结果： 1.3447223901748657 1.3248636722564697\n",
      "------------train------------\n",
      " (0.544936005073301, 0.07114181080837806)\n",
      "------------test------------\n",
      " (0.518496557850322, 0.056695536309127215)\n",
      "------------oot------------\n",
      " (0.5322536173959383, 0.06750078198310916)\n",
      "隐藏层vs神经元数vs norm 1 9 0.5\n",
      "验证集最优结果： 1.5329238176345825 1.5163044929504395\n",
      "------------train------------\n",
      " (0.5469601817616997, 0.0710095638761481)\n",
      "------------test------------\n",
      " (0.5294781256939818, 0.0632245169886742)\n",
      "------------oot------------\n",
      " (0.550519584332534, 0.09116880408716505)\n",
      "隐藏层vs神经元数vs norm 1 9 0.8\n",
      "验证集最优结果： 2.075566291809082 2.0495126247406006\n",
      "------------train------------\n",
      " (0.5540529894642375, 0.08901423245004025)\n",
      "------------test------------\n",
      " (0.5663690872751499, 0.11321341328003554)\n",
      "------------oot------------\n",
      " (0.5740242588537865, 0.135877385048483)\n",
      "隐藏层vs神经元数vs norm 1 10 0.01\n",
      "验证集最优结果： 0.5891055464744568 0.5895059704780579\n",
      "------------train------------\n",
      " (0.7044982230587483, 0.30122751412991466)\n",
      "------------test------------\n",
      " (0.6609837885853875, 0.2447479458139018)\n",
      "------------oot------------\n",
      " (0.6434481400386938, 0.20370486219719877)\n",
      "隐藏层vs神经元数vs norm 1 10 0.05\n",
      "验证集最优结果： 0.6976340413093567 0.6881300210952759\n",
      "------------train------------\n",
      " (0.6648239403494595, 0.2528879440745726)\n",
      "------------test------------\n",
      " (0.6401587830335331, 0.21133688652009774)\n",
      "------------oot------------\n",
      " (0.6303108238047244, 0.20718034268237584)\n",
      "隐藏层vs神经元数vs norm 1 10 0.1\n",
      "验证集最优结果： 0.8030269742012024 0.7918744683265686\n",
      "------------train------------\n",
      " (0.6118402289211994, 0.1626573647125389)\n",
      "------------test------------\n",
      " (0.5958649789029535, 0.16322451698867418)\n",
      "------------oot------------\n",
      " (0.6089736906127272, 0.16411218851006154)\n",
      "隐藏层vs神经元数vs norm 1 10 0.2\n",
      "验证集最优结果： 1.0167158842086792 1.0023924112319946\n",
      "------------train------------\n",
      " (0.5986991883124574, 0.13519034015345793)\n",
      "------------test------------\n",
      " (0.5812103042416167, 0.1357428381079281)\n",
      "------------oot------------\n",
      " (0.5841043107542951, 0.13628054078476348)\n",
      "隐藏层vs神经元数vs norm 1 10 0.3\n",
      "验证集最优结果： 1.231260895729065 1.2153114080429077\n",
      "------------train------------\n",
      " (0.5478555219185416, 0.07480614724890511)\n",
      "------------test------------\n",
      " (0.5208572063069066, 0.0453253386631135)\n",
      "------------oot------------\n",
      " (0.5400757654745769, 0.08277899419594764)\n",
      "隐藏层vs神经元数vs norm 1 10 0.4\n",
      "验证集最优结果： 1.434253454208374 1.417651891708374\n",
      "------------train------------\n",
      " (0.5572813983251881, 0.091786815779482)\n",
      "------------test------------\n",
      " (0.5462702642682656, 0.08536531201421277)\n",
      "------------oot------------\n",
      " (0.5544538282417544, 0.1024641156639905)\n",
      "隐藏层vs神经元数vs norm 1 10 0.5\n",
      "验证集最优结果： 1.645274043083191 1.6272785663604736\n",
      "------------train------------\n",
      " (0.552821076127263, 0.08269670039166477)\n",
      "------------test------------\n",
      " (0.5515789473684211, 0.09284921163668663)\n",
      "------------oot------------\n",
      " (0.5787995690404198, 0.13985333472352557)\n",
      "隐藏层vs神经元数vs norm 1 10 0.8\n",
      "验证集最优结果： 2.254303455352783 2.230008602142334\n",
      "------------train------------\n",
      " (0.5140601364837071, 0.029135339236392443)\n",
      "------------test------------\n",
      " (0.4928070175438597, 0.027115256495669593)\n",
      "------------oot------------\n",
      " (0.4591144475723769, 0.005623327425016478)\n",
      "隐藏层vs神经元数vs norm 1 11 0.01\n",
      "验证集最优结果： 0.598888635635376 0.5964611768722534\n",
      "------------train------------\n",
      " (0.692671800879706, 0.28461218282563094)\n",
      "------------test------------\n",
      " (0.6514234954474795, 0.22217410615145455)\n",
      "------------oot------------\n",
      " (0.6393320126507489, 0.22365412018211522)\n",
      "隐藏层vs神经元数vs norm 1 11 0.05\n",
      "验证集最优结果： 0.7019213438034058 0.6918596029281616\n",
      "------------train------------\n",
      " (0.6638473840622818, 0.24947009858961428)\n",
      "------------test------------\n",
      " (0.6405851654452588, 0.20659560293137907)\n",
      "------------oot------------\n",
      " (0.6328676189483196, 0.2173913043478261)\n",
      "隐藏层vs神经元数vs norm 1 11 0.1\n",
      "验证集最优结果： 0.8225827217102051 0.8110705614089966\n",
      "------------train------------\n",
      " (0.5985649786570778, 0.1533092527506888)\n",
      "------------test------------\n",
      " (0.5587430601821008, 0.09704641350210963)\n",
      "------------oot------------\n",
      " (0.593740659646196, 0.15397073645431475)\n",
      "隐藏层vs神经元数vs norm 1 11 0.2\n",
      "验证集最优结果： 1.0601760149002075 1.0465370416641235\n",
      "------------train------------\n",
      " (0.591940720346468, 0.1229111380477943)\n",
      "------------test------------\n",
      " (0.5740173217854763, 0.11874306018210085)\n",
      "------------oot------------\n",
      " (0.5871488316593102, 0.14088207694713795)\n",
      "隐藏层vs神经元数vs norm 1 11 0.3\n",
      "验证集最优结果： 1.3025028705596924 1.2912343740463257\n",
      "------------train------------\n",
      " (0.5740221408707317, 0.11835816178117803)\n",
      "------------test------------\n",
      " (0.576367976904286, 0.12911392405063293)\n",
      "------------oot------------\n",
      " (0.5970713284444908, 0.14689465818649428)\n",
      "隐藏层vs神经元数vs norm 1 11 0.4\n",
      "验证集最优结果： 1.5295584201812744 1.5090608596801758\n",
      "------------train------------\n",
      " (0.584067357951296, 0.12682656769127587)\n",
      "------------test------------\n",
      " (0.5484188318898512, 0.08999555851654462)\n",
      "------------oot------------\n",
      " (0.5628308947045262, 0.11239008792965621)\n",
      "隐藏层vs神经元数vs norm 1 11 0.5\n",
      "验证集最优结果： 1.765329122543335 1.7420257329940796\n",
      "------------train------------\n",
      " (0.5439559971005841, 0.07615474109312859)\n",
      "------------test------------\n",
      " (0.5129913391072618, 0.041061514545858324)\n",
      "------------oot------------\n",
      " (0.5273960541711558, 0.052375490911618555)\n",
      "隐藏层vs神经元数vs norm 1 11 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集最优结果： 2.4401729106903076 2.413257598876953\n",
      "------------train------------\n",
      " (0.5350573487400332, 0.053217004762649234)\n",
      "------------test------------\n",
      " (0.5205984898956252, 0.06231401288030203)\n",
      "------------oot------------\n",
      " (0.5577149874303456, 0.11042296597504603)\n",
      "隐藏层vs神经元数vs norm 1 12 0.01\n",
      "验证集最优结果： 0.600651741027832 0.6008598804473877\n",
      "------------train------------\n",
      " (0.6952782295425026, 0.28307909300532846)\n",
      "------------test------------\n",
      " (0.6585409726848768, 0.2350322007550522)\n",
      "------------oot------------\n",
      " (0.6457465911328908, 0.21659194383623537)\n",
      "隐藏层vs神经元数vs norm 1 12 0.05\n",
      "验证集最优结果： 0.717868983745575 0.7086804509162903\n",
      "------------train------------\n",
      " (0.6599501603680173, 0.22633243521829205)\n",
      "------------test------------\n",
      " (0.6292493892960249, 0.20848323339995561)\n",
      "------------oot------------\n",
      " (0.6315921176102596, 0.19938136447363847)\n",
      "隐藏层vs神经元数vs norm 1 12 0.1\n",
      "验证集最优结果： 0.8477657437324524 0.8381556868553162\n",
      "------------train------------\n",
      " (0.5872985416966997, 0.12002728861979273)\n",
      "------------test------------\n",
      " (0.5715733955141017, 0.11804352653786362)\n",
      "------------oot------------\n",
      " (0.5875890591874326, 0.14624126785528097)\n",
      "隐藏层vs神经元数vs norm 1 12 0.2\n",
      "验证集最优结果： 1.097868800163269 1.0801668167114258\n",
      "------------train------------\n",
      " (0.5661545312847918, 0.0879061737118276)\n",
      "------------test------------\n",
      " (0.5353286697757051, 0.07194092827004223)\n",
      "------------oot------------\n",
      " (0.5817780558162166, 0.11440586661105889)\n",
      "隐藏层vs神经元数vs norm 1 12 0.3\n",
      "验证集最优结果： 1.346217393875122 1.329228162765503\n",
      "------------train------------\n",
      " (0.5397449407426809, 0.06421651137465745)\n",
      "------------test------------\n",
      " (0.5180557406173663, 0.04248278925161009)\n",
      "------------oot------------\n",
      " (0.5283715056939956, 0.06372641017620684)\n",
      "隐藏层vs神经元数vs norm 1 12 0.4\n",
      "验证集最优结果： 1.6131097078323364 1.5950554609298706\n",
      "------------train------------\n",
      " (0.5512000021657635, 0.07319779714782493)\n",
      "------------test------------\n",
      " (0.54076060404175, 0.08507661558960694)\n",
      "------------oot------------\n",
      " (0.5651525156686245, 0.11444062141591071)\n",
      "隐藏层vs神经元数vs norm 1 12 0.5\n",
      "验证集最优结果： 1.8433732986450195 1.8213106393814087\n",
      "------------train------------\n",
      " (0.5483738161903002, 0.08299936583738227)\n",
      "------------test------------\n",
      " (0.5325216522318454, 0.06565622918054637)\n",
      "------------oot------------\n",
      " (0.576782631865522, 0.13051819414033994)\n",
      "隐藏层vs神经元数vs norm 1 12 0.8\n",
      "验证集最优结果： 2.5598642826080322 2.529407501220703\n",
      "------------train------------\n",
      " (0.5474596609632638, 0.07927912562714079)\n",
      "------------test------------\n",
      " (0.5280957139684654, 0.06787697090828337)\n",
      "------------oot------------\n",
      " (0.5667083724324887, 0.1339241650158135)\n",
      "隐藏层vs神经元数vs norm 1 13 0.01\n",
      "验证集最优结果： 0.6059966087341309 0.603294849395752\n",
      "------------train------------\n",
      " (0.6926015489269657, 0.2842299255721846)\n",
      "------------test------------\n",
      " (0.6537930268709748, 0.21985343104596927)\n",
      "------------oot------------\n",
      " (0.6404383739385303, 0.22076947137941821)\n",
      "隐藏层vs神经元数vs norm 1 13 0.05\n",
      "验证集最优结果： 0.7290527820587158 0.7200176119804382\n",
      "------------train------------\n",
      " (0.6434684972782444, 0.21654196606654713)\n",
      "------------test------------\n",
      " (0.6238685320897179, 0.18617588274483676)\n",
      "------------oot------------\n",
      " (0.6235683916634809, 0.1920550516108852)\n",
      "隐藏层vs神经元数vs norm 1 13 0.1\n",
      "验证集最优结果： 0.8670117259025574 0.8569079637527466\n",
      "------------train------------\n",
      " (0.6113195658456393, 0.16098025162110774)\n",
      "------------test------------\n",
      " (0.6103342216300245, 0.17637130801687761)\n",
      "------------oot------------\n",
      " (0.628029750112953, 0.19684426371945923)\n",
      "隐藏层vs神经元数vs norm 1 13 0.2\n",
      "验证集最优结果： 1.1428420543670654 1.1294435262680054\n",
      "------------train------------\n",
      " (0.5869489739357134, 0.12378908441672265)\n",
      "------------test------------\n",
      " (0.5679757939151677, 0.10657339551410172)\n",
      "------------oot------------\n",
      " (0.618488397687647, 0.1702637889688249)\n",
      "隐藏层vs神经元数vs norm 1 13 0.3\n",
      "验证集最优结果： 1.4123468399047852 1.3938778638839722\n",
      "------------train------------\n",
      " (0.5794106280781759, 0.11764860352247897)\n",
      "------------test------------\n",
      " (0.5601865423051299, 0.09801243615367539)\n",
      "------------oot------------\n",
      " (0.5720420764837405, 0.11327285997289127)\n",
      "隐藏层vs神经元数vs norm 1 13 0.4\n",
      "验证集最优结果： 1.6781662702560425 1.6567598581314087\n",
      "------------train------------\n",
      " (0.5515976904839737, 0.0744011494789647)\n",
      "------------test------------\n",
      " (0.5303220075505218, 0.0652898067954697)\n",
      "------------oot------------\n",
      " (0.5339589198206652, 0.0669794599103326)\n",
      "隐藏层vs神经元数vs norm 1 13 0.5\n",
      "验证集最优结果： 1.9352048635482788 1.9138436317443848\n",
      "------------train------------\n",
      " (0.578621613371965, 0.12111098251890468)\n",
      "------------test------------\n",
      " (0.54957805907173, 0.1004108372196314)\n",
      "------------oot------------\n",
      " (0.5736848202597342, 0.12729989921106594)\n",
      "隐藏层vs神经元数vs norm 1 13 0.8\n",
      "验证集最优结果： 2.74916672706604 2.7145540714263916\n",
      "------------train------------\n",
      " (0.537740729686323, 0.0722956213000131)\n",
      "------------test------------\n",
      " (0.5289851210304242, 0.075194314901177)\n",
      "------------oot------------\n",
      " (0.5238360036608394, 0.054509435929517236)\n",
      "隐藏层vs神经元数vs norm 1 14 0.01\n",
      "验证集最优结果： 0.6063238382339478 0.6019089818000793\n",
      "------------train------------\n",
      " (0.6927537614912365, 0.27503747786014443)\n",
      "------------test------------\n",
      " (0.6593026870974905, 0.2435487452809238)\n",
      "------------oot------------\n",
      " (0.6405426383530857, 0.2113161644597366)\n",
      "隐藏层vs神经元数vs norm 1 14 0.05\n",
      "验证集最优结果： 0.7357997298240662 0.7267885208129883\n",
      "------------train------------\n",
      " (0.6640626068076714, 0.23481045170381287)\n",
      "------------test------------\n",
      " (0.6431812125249834, 0.21485676215856095)\n",
      "------------oot------------\n",
      " (0.6361195101889503, 0.21761373509887744)\n",
      "隐藏层vs神经元数vs norm 1 14 0.1\n",
      "验证集最优结果： 0.8893283605575562 0.8768819570541382\n",
      "------------train------------\n",
      " (0.6098040051734674, 0.15223719983025824)\n",
      "------------test------------\n",
      " (0.5942127470575171, 0.15377526093715294)\n",
      "------------oot------------\n",
      " (0.6120854041404558, 0.17385048482952775)\n",
      "隐藏层vs神经元数vs norm 1 14 0.2\n",
      "验证集最优结果： 1.1916917562484741 1.1771836280822754\n",
      "------------train------------\n",
      " (0.6065711971054571, 0.16998062318490414)\n",
      "------------test------------\n",
      " (0.6015323117921386, 0.16952031978680876)\n",
      "------------oot------------\n",
      " (0.6272095367184514, 0.19546797344732908)\n",
      "隐藏层vs神经元数vs norm 1 14 0.3\n",
      "验证集最优结果： 1.4876700639724731 1.474199652671814\n",
      "------------train------------\n",
      " (0.587513967482415, 0.12894982805868405)\n",
      "------------test------------\n",
      " (0.5647823673106818, 0.1033755274261603)\n",
      "------------oot------------\n",
      " (0.6140270392381746, 0.19982622597574112)\n",
      "隐藏层vs神经元数vs norm 1 14 0.4\n",
      "验证集最优结果： 1.7856460809707642 1.7667009830474854\n",
      "------------train------------\n",
      " (0.5644445933406834, 0.09428732507229931)\n",
      "------------test------------\n",
      " (0.5287386186986454, 0.05989340439706862)\n",
      "------------oot------------\n",
      " (0.5757121838760876, 0.12599311854863937)\n",
      "隐藏层vs神经元数vs norm 1 14 0.5\n",
      "验证集最优结果： 2.078847646713257 2.062267780303955\n",
      "------------train------------\n",
      " (0.555033741918149, 0.09897308971201435)\n",
      "------------test------------\n",
      " (0.5587630468576504, 0.1075283144570286)\n",
      "------------oot------------\n",
      " (0.5522990303409446, 0.08144440968963962)\n",
      "隐藏层vs神经元数vs norm 1 14 0.8\n",
      "验证集最优结果： 2.954908847808838 2.914036989212036\n",
      "------------train------------\n",
      " (0.5340225198793399, 0.06561356417664777)\n",
      "------------test------------\n",
      " (0.5142949145014435, 0.05589606928714186)\n",
      "------------oot------------\n",
      " (0.5000382302853369, 0.04601536162374453)\n",
      "隐藏层vs神经元数vs norm 1 15 0.01\n",
      "验证集最优结果： 0.6014004945755005 0.596364438533783\n",
      "------------train------------\n",
      " (0.6807929942965972, 0.26574459286692265)\n",
      "------------test------------\n",
      " (0.6561114812347324, 0.22660448589829008)\n",
      "------------oot------------\n",
      " (0.6415215653564106, 0.2163000034754805)\n",
      "隐藏层vs神经元数vs norm 1 15 0.05\n",
      "验证集最优结果： 0.747356653213501 0.7368528842926025\n",
      "------------train------------\n",
      " (0.6621413715644731, 0.23263115220647312)\n",
      "------------test------------\n",
      " (0.6438463246724405, 0.21687763713080166)\n",
      "------------oot------------\n",
      " (0.6431550411844438, 0.2250165085323046)\n",
      "隐藏层vs神经元数vs norm 1 15 0.1\n",
      "验证集最优结果： 0.904137909412384 0.8926860690116882\n",
      "------------train------------\n",
      " (0.6036554703462989, 0.14695138334758)\n",
      "------------test------------\n",
      " (0.5749755718409949, 0.11541194759049522)\n",
      "------------oot------------\n",
      " (0.6107195403097812, 0.16108156952698716)\n",
      "隐藏层vs神经元数vs norm 1 15 0.2\n",
      "验证集最优结果： 1.224644422531128 1.2101192474365234\n",
      "------------train------------\n",
      " (0.5957332429127082, 0.14539460548926286)\n",
      "------------test------------\n",
      " (0.5753153453253387, 0.14199422607150786)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.5930015407963484, 0.1422583672192681)\n",
      "隐藏层vs神经元数vs norm 1 15 0.3\n",
      "验证集最优结果： 1.5481128692626953 1.5303761959075928\n",
      "------------train------------\n",
      " (0.5675218725191009, 0.10462762742641651)\n",
      "------------test------------\n",
      " (0.5506906506773261, 0.08457694870086607)\n",
      "------------oot------------\n",
      " (0.5666168514463791, 0.11523303096653104)\n",
      "隐藏层vs神经元数vs norm 1 15 0.4\n",
      "验证集最优结果： 1.8410825729370117 1.8218938112258911\n",
      "------------train------------\n",
      " (0.5575197676677233, 0.09379759180637537)\n",
      "------------test------------\n",
      " (0.5420164334887853, 0.0861092604930046)\n",
      "------------oot------------\n",
      " (0.5801051912093513, 0.11842352205192369)\n",
      "隐藏层vs神经元数vs norm 1 15 0.5\n",
      "验证集最优结果： 2.1789653301239014 2.1437530517578125\n",
      "------------train------------\n",
      " (0.5443147016762333, 0.06975761722702417)\n",
      "------------test------------\n",
      " (0.5401754385964912, 0.10300910504108374)\n",
      "------------oot------------\n",
      " (0.5655834752487865, 0.11257776387585583)\n",
      "隐藏层vs神经元数vs norm 1 15 0.8\n",
      "验证集最优结果： 3.069934606552124 3.0358142852783203\n",
      "------------train------------\n",
      " (0.5050217286988702, 0.02658339306102908)\n",
      "------------test------------\n",
      " (0.5099233844103931, 0.03603153453253388)\n",
      "------------oot------------\n",
      " (0.4973586348312654, 0.02172175303235674)\n",
      "隐藏层vs神经元数vs norm 1 16 0.01\n",
      "验证集最优结果： 0.607234537601471 0.6031794548034668\n",
      "------------train------------\n",
      " (0.6967323366760538, 0.2816592996868441)\n",
      "------------test------------\n",
      " (0.6611669997779258, 0.24414834554741283)\n",
      "------------oot------------\n",
      " (0.6446089505207429, 0.21509053626663888)\n",
      "隐藏层vs神经元数vs norm 1 16 0.05\n",
      "验证集最优结果： 0.7588084936141968 0.7493510246276855\n",
      "------------train------------\n",
      " (0.6376773811046612, 0.1994279677220026)\n",
      "------------test------------\n",
      " (0.6165123251165889, 0.17666000444148344)\n",
      "------------oot------------\n",
      " (0.640215943187479, 0.21599416119278492)\n",
      "隐藏层vs神经元数vs norm 1 16 0.1\n",
      "验证集最优结果： 0.9314870238304138 0.9194961786270142\n",
      "------------train------------\n",
      " (0.6074861644937968, 0.15744234162346987)\n",
      "------------test------------\n",
      " (0.5901598934043971, 0.15172107483899627)\n",
      "------------oot------------\n",
      " (0.6027097162849431, 0.15695964967156706)\n",
      "隐藏层vs神经元数vs norm 1 16 0.2\n",
      "验证集最优结果： 1.2686586380004883 1.25234854221344\n",
      "------------train------------\n",
      " (0.589308099481638, 0.13689276560551028)\n",
      "------------test------------\n",
      " (0.5659604707972463, 0.11284699089495887)\n",
      "------------oot------------\n",
      " (0.5927431967469503, 0.1445938901053071)\n",
      "隐藏层vs神经元数vs norm 1 16 0.3\n",
      "验证集最优结果： 1.6180380582809448 1.6050044298171997\n",
      "------------train------------\n",
      " (0.5393535466745717, 0.07330540852051959)\n",
      "------------test------------\n",
      " (0.5373550966022651, 0.078369975571841)\n",
      "------------oot------------\n",
      " (0.5041694180887174, 0.040892503388593404)\n",
      "隐藏层vs神经元数vs norm 1 16 0.4\n",
      "验证集最优结果： 1.9448238611221313 1.923274040222168\n",
      "------------train------------\n",
      " (0.5563901866549715, 0.09038082920315471)\n",
      "------------test------------\n",
      " (0.5293448811903176, 0.07207417277370642)\n",
      "------------oot------------\n",
      " (0.5531563155272883, 0.11054113231154206)\n",
      "隐藏层vs神经元数vs norm 1 16 0.5\n",
      "验证集最优结果： 2.2740118503570557 2.251791000366211\n",
      "------------train------------\n",
      " (0.5614040644612426, 0.09805886680486942)\n",
      "------------test------------\n",
      " (0.5426271374639129, 0.08706417943593159)\n",
      "------------oot------------\n",
      " (0.5455496472387308, 0.09958641782226396)\n",
      "隐藏层vs神经元数vs norm 1 16 0.8\n",
      "验证集最优结果： 3.2709085941314697 3.2197320461273193\n",
      "------------train------------\n",
      " (0.5504331865351777, 0.07233677080604983)\n",
      "------------test------------\n",
      " (0.5534787919165001, 0.09871196979791252)\n",
      "------------oot------------\n",
      " (0.5828681981950672, 0.13942932610433395)\n",
      "隐藏层vs神经元数vs norm 1 17 0.01\n",
      "验证集最优结果： 0.6098888516426086 0.6056533455848694\n",
      "------------train------------\n",
      " (0.6948965814100339, 0.28824579249684784)\n",
      "------------test------------\n",
      " (0.6587741505662892, 0.23015767266266934)\n",
      "------------oot------------\n",
      " (0.6429523048228084, 0.21159420289855074)\n",
      "隐藏层vs神经元数vs norm 1 17 0.05\n",
      "验证集最优结果： 0.7692077159881592 0.759767472743988\n",
      "------------train------------\n",
      " (0.6404200498260959, 0.20477022941526418)\n",
      "------------test------------\n",
      " (0.6242493892960248, 0.19710193204530307)\n",
      "------------oot------------\n",
      " (0.6018698085010252, 0.15325478747436833)\n",
      "隐藏层vs神经元数vs norm 1 17 0.1\n",
      "验证集最优结果： 0.947956919670105 0.9356499314308167\n",
      "------------train------------\n",
      " (0.6029494314532475, 0.15487861910920797)\n",
      "------------test------------\n",
      " (0.595540750610704, 0.16189207195203198)\n",
      "------------oot------------\n",
      " (0.6229879864224562, 0.19533590518889243)\n",
      "隐藏层vs神经元数vs norm 1 17 0.2\n",
      "验证集最优结果： 1.3153554201126099 1.3001668453216553\n",
      "------------train------------\n",
      " (0.585501364092589, 0.13222960612207185)\n",
      "------------test------------\n",
      " (0.5836686653342217, 0.14707972462802577)\n",
      "------------oot------------\n",
      " (0.5465030873851642, 0.0996906822368192)\n",
      "隐藏层vs神经元数vs norm 1 17 0.3\n",
      "验证集最优结果： 1.6709550619125366 1.6557812690734863\n",
      "------------train------------\n",
      " (0.5693678474815216, 0.11071653607789711)\n",
      "------------test------------\n",
      " (0.5455396402398401, 0.08968465467466125)\n",
      "------------oot------------\n",
      " (0.6034604200697413, 0.1678031487853196)\n",
      "隐藏层vs神经元数vs norm 1 17 0.4\n",
      "验证集最优结果： 2.025169610977173 2.0050740242004395\n",
      "------------train------------\n",
      " (0.5852451948814887, 0.12108742984110737)\n",
      "------------test------------\n",
      " (0.5589529202753719, 0.09711303575394181)\n",
      "------------oot------------\n",
      " (0.5897786118930942, 0.13459145726896737)\n",
      "隐藏层vs神经元数vs norm 1 17 0.5\n",
      "验证集最优结果： 2.3470988273620605 2.3211445808410645\n",
      "------------train------------\n",
      " (0.562091897405077, 0.09963242933012262)\n",
      "------------test------------\n",
      " (0.5564967799244948, 0.11112591605596278)\n",
      "------------oot------------\n",
      " (0.5619156848434296, 0.11259166579779656)\n",
      "隐藏层vs神经元数vs norm 1 17 0.8\n",
      "验证集最优结果： 3.4048779010772705 3.380281448364258\n",
      "------------train------------\n",
      " (0.5078154282221993, 0.03294410502869982)\n",
      "------------test------------\n",
      " (0.510067732622696, 0.05851654452587163)\n",
      "------------oot------------\n",
      " (0.4748363627938229, 0.005588572620164767)\n",
      "隐藏层vs神经元数vs norm 1 18 0.01\n",
      "验证集最优结果： 0.6228463053703308 0.6190656423568726\n",
      "------------train------------\n",
      " (0.6832456537526251, 0.2658282454811684)\n",
      "------------test------------\n",
      " (0.6473639795691761, 0.21782145236508993)\n",
      "------------oot------------\n",
      " (0.6415829655116486, 0.2234108365481528)\n",
      "隐藏层vs神经元数vs norm 1 18 0.05\n",
      "验证集最优结果： 0.7808242440223694 0.7724371552467346\n",
      "------------train------------\n",
      " (0.6598844429825541, 0.2395762142319086)\n",
      "------------test------------\n",
      " (0.6282411725516323, 0.20055518543193426)\n",
      "------------oot------------\n",
      " (0.6344756079194616, 0.2135404719702499)\n",
      "隐藏层vs神经元数vs norm 1 18 0.1\n",
      "验证集最优结果： 0.9720507264137268 0.9597827196121216\n",
      "------------train------------\n",
      " (0.6001087619345411, 0.14497877890194433)\n",
      "------------test------------\n",
      " (0.5764345991561182, 0.13559848989562512)\n",
      "------------oot------------\n",
      " (0.6100557235371122, 0.14347478538908004)\n",
      "隐藏层vs神经元数vs norm 1 18 0.2\n",
      "验证集最优结果： 1.348292350769043 1.3339223861694336\n",
      "------------train------------\n",
      " (0.5856681278802116, 0.12980584607242174)\n",
      "------------test------------\n",
      " (0.567677104152787, 0.1385409726848768)\n",
      "------------oot------------\n",
      " (0.5900242125140467, 0.1280367010739235)\n",
      "隐藏层vs神经元数vs norm 1 18 0.3\n",
      "验证集最优结果： 1.7519639730453491 1.7357147932052612\n",
      "------------train------------\n",
      " (0.5625968586954389, 0.09737814027243946)\n",
      "------------test------------\n",
      " (0.5486808794137242, 0.09664667999111709)\n",
      "------------oot------------\n",
      " (0.5401336901493299, 0.07701664755152399)\n",
      "隐藏层vs神经元数vs norm 1 18 0.4\n",
      "验证集最优结果： 2.111199378967285 2.0980215072631836\n",
      "------------train------------\n",
      " (0.5609539917389659, 0.09091766782467325)\n",
      "------------test------------\n",
      " (0.5549589162780368, 0.12372862536087054)\n",
      "------------oot------------\n",
      " (0.5639673768231791, 0.09866889097417708)\n",
      "隐藏层vs神经元数vs norm 1 18 0.5\n",
      "验证集最优结果： 2.500293493270874 2.4799671173095703\n",
      "------------train------------\n",
      " (0.5599577405401819, 0.0952420206843948)\n",
      "------------test------------\n",
      " (0.5550910504108373, 0.10820564068398841)\n",
      "------------oot------------\n",
      " (0.5766714164899964, 0.12278177458033573)\n",
      "隐藏层vs神经元数vs norm 1 18 0.8\n",
      "验证集最优结果： 3.584139347076416 3.559119462966919\n",
      "------------train------------\n",
      " (0.5402212733470995, 0.08355799745387432)\n",
      "------------test------------\n",
      " (0.5206107039751278, 0.06749944481456804)\n",
      "------------oot------------\n",
      " (0.5221561880930038, 0.05075591700552601)\n",
      "隐藏层vs神经元数vs norm 1 19 0.01\n",
      "验证集最优结果： 0.6125974655151367 0.610116720199585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " (0.6966335237174788, 0.29068823225647517)\n",
      "------------test------------\n",
      " (0.6553320008882968, 0.2369753497668221)\n",
      "------------oot------------\n",
      " (0.6382175419085021, 0.21785701873283986)\n",
      "隐藏层vs神经元数vs norm 1 19 0.05\n",
      "验证集最优结果： 0.7881994843482971 0.7775835394859314\n",
      "------------train------------\n",
      " (0.600956184574485, 0.14696221216495808)\n",
      "------------test------------\n",
      " (0.5655796135909394, 0.11028203419942262)\n",
      "------------oot------------\n",
      " (0.6057414937615124, 0.18069023042435617)\n",
      "隐藏层vs神经元数vs norm 1 19 0.1\n",
      "验证集最优结果： 0.991708517074585 0.9796768426895142\n",
      "------------train------------\n",
      " (0.6121225226542243, 0.15909847388123083)\n",
      "------------test------------\n",
      " (0.5870508549855652, 0.14904508105707304)\n",
      "------------oot------------\n",
      " (0.6128106210683628, 0.17430924825357108)\n",
      "隐藏层vs神经元数vs norm 1 19 0.2\n",
      "验证集最优结果： 1.4057468175888062 1.3929623365402222\n",
      "------------train------------\n",
      " (0.6020538205759712, 0.1426664203110713)\n",
      "------------test------------\n",
      " (0.566528980679547, 0.10427492782589382)\n",
      "------------oot------------\n",
      " (0.5977571565935658, 0.15189935008514927)\n",
      "隐藏层vs神经元数vs norm 1 19 0.3\n",
      "验证集最优结果： 1.7968108654022217 1.7820985317230225\n",
      "------------train------------\n",
      " (0.573601441315593, 0.1106090600654196)\n",
      "------------test------------\n",
      " (0.5658849655785032, 0.11623362202975795)\n",
      "------------oot------------\n",
      " (0.5814559946245902, 0.13163034789559658)\n",
      "隐藏层vs神经元数vs norm 1 19 0.4\n",
      "验证集最优结果： 2.2003371715545654 2.1799776554107666\n",
      "------------train------------\n",
      " (0.587453799865858, 0.13265233608046895)\n",
      "------------test------------\n",
      " (0.5684987785920497, 0.12788141239173884)\n",
      "------------oot------------\n",
      " (0.5744876562518101, 0.11690126159941605)\n",
      "隐藏层vs神经元数vs norm 1 19 0.5\n",
      "验证集最优结果： 2.582324266433716 2.5537102222442627\n",
      "------------train------------\n",
      " (0.5331430168679134, 0.07120380578786745)\n",
      "------------test------------\n",
      " (0.5109182767044194, 0.04069509216078171)\n",
      "------------oot------------\n",
      " (0.5233355344709739, 0.061912209362944504)\n",
      "隐藏层vs神经元数vs norm 1 19 0.8\n",
      "验证集最优结果： 3.7508604526519775 3.7132487297058105\n",
      "------------train------------\n",
      " (0.5604603330267424, 0.09709320701517865)\n",
      "------------test------------\n",
      " (0.5495336442371752, 0.0857872529424828)\n",
      "------------oot------------\n",
      " (0.5702406190989238, 0.10709345567024642)\n",
      "隐藏层vs神经元数vs norm 1 20 0.01\n",
      "验证集最优结果： 0.6227898001670837 0.6177844405174255\n",
      "------------train------------\n",
      " (0.6883957039374258, 0.276642443955794)\n",
      "------------test------------\n",
      " (0.6538751943149012, 0.2155118809682434)\n",
      "------------oot------------\n",
      " (0.6429974860691157, 0.23379557223786185)\n",
      "隐藏层vs神经元数vs norm 1 20 0.05\n",
      "验证集最优结果： 0.8011239767074585 0.7916300892829895\n",
      "------------train------------\n",
      " (0.5784731232136682, 0.12011080587382128)\n",
      "------------test------------\n",
      " (0.5581157006440152, 0.10004441483455473)\n",
      "------------oot------------\n",
      " (0.5765764200234016, 0.1275640357279394)\n",
      "隐藏层vs神经元数vs norm 1 20 0.1\n",
      "验证集最优结果： 1.020027756690979 1.0084043741226196\n",
      "------------train------------\n",
      " (0.6065919072186927, 0.1602946521208577)\n",
      "------------test------------\n",
      " (0.581149233844104, 0.13958472129691324)\n",
      "------------oot------------\n",
      " (0.605611742490066, 0.16474472595836376)\n",
      "隐藏层vs神经元数vs norm 1 20 0.2\n",
      "验证集最优结果： 1.4439162015914917 1.4309300184249878\n",
      "------------train------------\n",
      " (0.5982384898131285, 0.1468724683409372)\n",
      "------------test------------\n",
      " (0.5699600266489007, 0.12715967133022432)\n",
      "------------oot------------\n",
      " (0.6049722540807934, 0.17921662669864113)\n",
      "隐藏层vs神经元数vs norm 1 20 0.3\n",
      "验证集最优结果： 1.8595422506332397 1.8446543216705322\n",
      "------------train------------\n",
      " (0.5876638789229929, 0.12467068551151611)\n",
      "------------test------------\n",
      " (0.5596779924494781, 0.1103597601598934)\n",
      "------------oot------------\n",
      " (0.60039388778832, 0.1401105202794286)\n",
      "隐藏层vs神经元数vs norm 1 20 0.4\n",
      "验证集最优结果： 2.279010057449341 2.252781391143799\n",
      "------------train------------\n",
      " (0.5553674725337199, 0.0971336797201292)\n",
      "------------test------------\n",
      " (0.5429447035309793, 0.08599822340661778)\n",
      "------------oot------------\n",
      " (0.5570870839560236, 0.0910158829458172)\n",
      "隐藏层vs神经元数vs norm 1 20 0.5\n",
      "验证集最优结果： 2.7121667861938477 2.6879899501800537\n",
      "------------train------------\n",
      " (0.5192986445704648, 0.03763920952340344)\n",
      "------------test------------\n",
      " (0.5465978236731068, 0.08838552076393513)\n",
      "------------oot------------\n",
      " (0.5403503284329059, 0.08557328050602997)\n",
      "隐藏层vs神经元数vs norm 1 20 0.8\n",
      "验证集最优结果： 3.876303195953369 3.8523988723754883\n",
      "------------train------------\n",
      " (0.4589187831928633, 0.003085806872102869)\n",
      "------------test------------\n",
      " (0.46710970464135015, 0.0)\n",
      "------------oot------------\n",
      " (0.4613874118096827, 0.0062975706391408615)\n",
      "隐藏层vs神经元数vs norm 1 22 0.01\n",
      "验证集最优结果： 0.6244457364082336 0.6192781329154968\n",
      "------------train------------\n",
      " (0.685635167667317, 0.2771310943399801)\n",
      "------------test------------\n",
      " (0.6548456584499223, 0.21903175660670665)\n",
      "------------oot------------\n",
      " (0.6456098889004738, 0.23493552983699995)\n",
      "隐藏层vs神经元数vs norm 1 22 0.05\n",
      "验证集最优结果： 0.8286001682281494 0.8182199001312256\n",
      "------------train------------\n",
      " (0.6187174754778046, 0.17592564392547344)\n",
      "------------test------------\n",
      " (0.6022962469464801, 0.15923828558738617)\n",
      "------------oot------------\n",
      " (0.6286078383669875, 0.22748409967678024)\n",
      "隐藏层vs神经元数vs norm 1 22 0.1\n",
      "验证集最优结果： 1.0556282997131348 1.0442500114440918\n",
      "------------train------------\n",
      " (0.591955948370906, 0.13251237361585716)\n",
      "------------test------------\n",
      " (0.5664823451032645, 0.11571174772373971)\n",
      "------------oot------------\n",
      " (0.5976621601269709, 0.15476314600493524)\n",
      "隐藏层vs神经元数vs norm 1 22 0.2\n",
      "验证集最优结果： 1.5231629610061646 1.5034016370773315\n",
      "------------train------------\n",
      " (0.5777729048099576, 0.10769164130354592)\n",
      "------------test------------\n",
      " (0.5537708194536975, 0.09601376859871191)\n",
      "------------oot------------\n",
      " (0.5956324795236275, 0.1461091995968442)\n",
      "隐藏层vs神经元数vs norm 1 22 0.3\n",
      "验证集最优结果： 1.9847126007080078 1.9705374240875244\n",
      "------------train------------\n",
      " (0.5983590280865683, 0.14240842373703844)\n",
      "------------test------------\n",
      " (0.5800155451920942, 0.14180546302465014)\n",
      "------------oot------------\n",
      " (0.6207520939769924, 0.17056268029055016)\n",
      "隐藏层vs神经元数vs norm 1 22 0.4\n",
      "验证集最优结果： 2.4255003929138184 2.4117679595947266\n",
      "------------train------------\n",
      " (0.58637186564957, 0.1274785978576538)\n",
      "------------test------------\n",
      " (0.5890262047523873, 0.14474794581390193)\n",
      "------------oot------------\n",
      " (0.6109720918917041, 0.15809960727070516)\n",
      "隐藏层vs神经元数vs norm 1 22 0.5\n",
      "验证集最优结果： 2.8798036575317383 2.852989435195923\n",
      "------------train------------\n",
      " (0.5428836057796105, 0.0664075872108959)\n",
      "------------test------------\n",
      " (0.5437841439040639, 0.09135021097046411)\n",
      "------------oot------------\n",
      " (0.5379232845607571, 0.07716956869287173)\n",
      "隐藏层vs神经元数vs norm 1 22 0.8\n",
      "验证集最优结果： 4.28270959854126 4.238918304443359\n",
      "------------train------------\n",
      " (0.47812098360855454, 0.012733470994674256)\n",
      "------------test------------\n",
      " (0.5117044192760383, 0.05542971352431708)\n",
      "------------oot------------\n",
      " (0.5080028730638677, 0.03639523164077432)\n",
      "隐藏层vs神经元数vs norm 1 24 0.01\n",
      "验证集最优结果： 0.6349003314971924 0.6304895877838135\n",
      "------------train------------\n",
      " (0.6821561393641724, 0.27337038142478814)\n",
      "------------test------------\n",
      " (0.6470908283366644, 0.21065956029313793)\n",
      "------------oot------------\n",
      " (0.6435755743231502, 0.2346783442810968)\n",
      "隐藏层vs神经元数vs norm 1 24 0.05\n",
      "验证集最优结果： 0.8475694060325623 0.8374404907226562\n",
      "------------train------------\n",
      " (0.6171918304694495, 0.17598181841562216)\n",
      "------------test------------\n",
      " (0.5899633577614923, 0.17791472351765492)\n",
      "------------oot------------\n",
      " (0.6470093490425051, 0.21344315851666495)\n",
      "隐藏层vs神经元数vs norm 1 24 0.1\n",
      "验证集最优结果： 1.1000678539276123 1.089051365852356\n",
      "------------train------------\n",
      " (0.5876682781300527, 0.13365224200511805)\n",
      "------------test------------\n",
      " (0.5711847657117477, 0.12548301132578277)\n",
      "------------oot------------\n",
      " (0.5956486984325583, 0.16400792409550619)\n",
      "隐藏层vs神经元数vs norm 1 24 0.2\n",
      "验证集最优结果： 1.6037064790725708 1.590261459350586\n",
      "------------train------------\n",
      " (0.554965181968124, 0.08496993987975948)\n",
      "------------test------------\n",
      " (0.527255163224517, 0.06660004441483458)\n",
      "------------oot------------\n",
      " (0.5454534922786408, 0.08608765161783616)\n",
      "隐藏层vs神经元数vs norm 1 24 0.3\n",
      "验证集最优结果： 2.1135940551757812 2.093742609024048\n",
      "------------train------------\n",
      " (0.5884524198684434, 0.1342995345638931)\n",
      "------------test------------\n",
      " (0.5691872085276483, 0.11171441261381299)\n",
      "------------oot------------\n",
      " (0.5919588966507953, 0.13702429360859136)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 1 24 0.4\n",
      "验证集最优结果： 2.586402654647827 2.559246301651001\n",
      "------------train------------\n",
      " (0.5504634395437278, 0.09295835845957368)\n",
      "------------test------------\n",
      " (0.540649566955363, 0.07793693093493226)\n",
      "------------oot------------\n",
      " (0.5692385222256977, 0.1206339276404963)\n",
      "隐藏层vs神经元数vs norm 1 24 0.5\n",
      "验证集最优结果： 3.1326842308044434 3.1106321811676025\n",
      "------------train------------\n",
      " (0.5306027116712316, 0.05385252098252569)\n",
      "------------test------------\n",
      " (0.5320131023761936, 0.07075283144570277)\n",
      "------------oot------------\n",
      " (0.5031707966959765, 0.031925763736836615)\n",
      "隐藏层vs神经元数vs norm 1 24 0.8\n",
      "验证集最优结果： 4.529725551605225 4.502154350280762\n",
      "------------train------------\n",
      " (0.5120559254273491, 0.03599052207758979)\n",
      "------------test------------\n",
      " (0.5058061292471685, 0.04196091494559173)\n",
      "------------oot------------\n",
      " (0.5194012905617535, 0.05209745247280437)\n",
      "隐藏层vs神经元数vs norm 1 26 0.01\n",
      "验证集最优结果： 0.6397935152053833 0.6356943845748901\n",
      "------------train------------\n",
      " (0.6818035936784071, 0.26997717149936484)\n",
      "------------test------------\n",
      " (0.646578947368421, 0.20579613590939377)\n",
      "------------oot------------\n",
      " (0.6452542313974907, 0.23761164981058636)\n",
      "隐藏层vs神经元数vs norm 1 26 0.05\n",
      "验证集最优结果： 0.8662289977073669 0.8578792214393616\n",
      "------------train------------\n",
      " (0.6234298384002046, 0.17769629092700767)\n",
      "------------test------------\n",
      " (0.5881789917832556, 0.13912946924272707)\n",
      "------------oot------------\n",
      " (0.6214182277366512, 0.1882667778820422)\n",
      "隐藏层vs神经元数vs norm 1 26 0.1\n",
      "验证集最优结果： 1.1445484161376953 1.1324048042297363\n",
      "------------train------------\n",
      " (0.5901258782340094, 0.1451600262328101)\n",
      "------------test------------\n",
      " (0.5619797912502776, 0.11887630468576504)\n",
      "------------oot------------\n",
      " (0.5919704815857458, 0.15100267611997353)\n",
      "隐藏层vs神经元数vs norm 1 26 0.2\n",
      "验证集最优结果： 1.6932573318481445 1.6785651445388794\n",
      "------------train------------\n",
      " (0.5602176998373647, 0.09393268130316701)\n",
      "------------test------------\n",
      " (0.5531767710415278, 0.10567399511436815)\n",
      "------------oot------------\n",
      " (0.5590484134431585, 0.10940812567337432)\n",
      "隐藏层vs神经元数vs norm 1 26 0.3\n",
      "验证集最优结果： 2.2099974155426025 2.1920619010925293\n",
      "------------train------------\n",
      " (0.5826792389236427, 0.12590029772479777)\n",
      "------------test------------\n",
      " (0.5633422163002444, 0.1259826782145237)\n",
      "------------oot------------\n",
      " (0.5982275049525596, 0.1575782851979286)\n",
      "隐藏层vs神经元数vs norm 1 26 0.4\n",
      "验证集最优结果： 2.7306835651397705 2.71392560005188\n",
      "------------train------------\n",
      " (0.533982453255041, 0.05777268823361004)\n",
      "------------test------------\n",
      " (0.5213701976460137, 0.06907617144126132)\n",
      "------------oot------------\n",
      " (0.5470070320555149, 0.08719980537309291)\n",
      "隐藏层vs神经元数vs norm 1 26 0.5\n",
      "验证集最优结果： 3.2786757946014404 3.2545883655548096\n",
      "------------train------------\n",
      " (0.5302363592433093, 0.053429655663911446)\n",
      "------------test------------\n",
      " (0.5400210970464134, 0.07838107928047972)\n",
      "------------oot------------\n",
      " (0.5637565310070783, 0.09783477565773468)\n",
      "隐藏层vs神经元数vs norm 1 26 0.8\n",
      "验证集最优结果： 4.876804351806641 4.828207015991211\n",
      "------------train------------\n",
      " (0.4810830035620041, 0.002350800892565272)\n",
      "------------test------------\n",
      " (0.49445258716411283, 0.04301576726626688)\n",
      "------------oot------------\n",
      " (0.4662472920214553, 0.005463455322698374)\n",
      "隐藏层vs神经元数vs norm 1 28 0.01\n",
      "验证集最优结果： 0.6350556015968323 0.6311345100402832\n",
      "------------train------------\n",
      " (0.6751905025857186, 0.258765961507615)\n",
      "------------test------------\n",
      " (0.6565778369975572, 0.22705973795247614)\n",
      "------------oot------------\n",
      " (0.6438003220611916, 0.23307267229694512)\n",
      "隐藏层vs神经元数vs norm 1 28 0.05\n",
      "验证集最优结果： 0.8953734040260315 0.8837572336196899\n",
      "------------train------------\n",
      " (0.6144321740407529, 0.17404386618559647)\n",
      "------------test------------\n",
      " (0.5919920053297801, 0.1493115700644015)\n",
      "------------oot------------\n",
      " (0.6137049780465482, 0.16868592082855455)\n",
      "隐藏层vs神经元数vs norm 1 28 0.1\n",
      "验证集最优结果： 1.1957942247390747 1.1846144199371338\n",
      "------------train------------\n",
      " (0.6028772167773575, 0.1373283547845438)\n",
      "------------test------------\n",
      " (0.5798001332445036, 0.14206084832333998)\n",
      "------------oot------------\n",
      " (0.6066358507396981, 0.16695513154693642)\n",
      "隐藏层vs神经元数vs norm 1 28 0.2\n",
      "验证集最优结果： 1.787831425666809 1.7681148052215576\n",
      "------------train------------\n",
      " (0.5987242976327529, 0.14267630160692885)\n",
      "------------test------------\n",
      " (0.5822607150788364, 0.13385520763935155)\n",
      "------------oot------------\n",
      " (0.6286252157694134, 0.19950648177110486)\n",
      "隐藏层vs神经元数vs norm 1 28 0.3\n",
      "验证集最优结果： 2.357961416244507 2.334721565246582\n",
      "------------train------------\n",
      " (0.5706446327305066, 0.09818610540906197)\n",
      "------------test------------\n",
      " (0.556833222296247, 0.09502553852986895)\n",
      "------------oot------------\n",
      " (0.5978313001772495, 0.13655162826260725)\n",
      "隐藏层vs神经元数vs norm 1 28 0.4\n",
      "验证集最优结果： 2.9383671283721924 2.9171321392059326\n",
      "------------train------------\n",
      " (0.5785280794618619, 0.11508718213190994)\n",
      "------------test------------\n",
      " (0.5396824339329336, 0.07832556073728625)\n",
      "------------oot------------\n",
      " (0.5975161899465935, 0.1485420359364682)\n",
      "隐藏层vs神经元数vs norm 1 28 0.5\n",
      "验证集最优结果： 3.525716781616211 3.500230550765991\n",
      "------------train------------\n",
      " (0.5669640530639124, 0.1015586052212496)\n",
      "------------test------------\n",
      " (0.5389040639573617, 0.07542749278258942)\n",
      "------------oot------------\n",
      " (0.6042169163220148, 0.16429986445626105)\n",
      "隐藏层vs神经元数vs norm 1 28 0.8\n",
      "验证集最优结果： 5.16112756729126 5.120815277099609\n",
      "------------train------------\n",
      " (0.5568714599073189, 0.09082805936086968)\n",
      "------------test------------\n",
      " (0.5665323117921386, 0.10660670664001776)\n",
      "------------oot------------\n",
      " (0.5608127990361333, 0.11253605811003364)\n",
      "隐藏层vs神经元数vs norm 1 30 0.01\n",
      "验证集最优结果： 0.6436561346054077 0.6398615837097168\n",
      "------------train------------\n",
      " (0.686284422949242, 0.2724709127813209)\n",
      "------------test------------\n",
      " (0.6545969353764157, 0.22441705529646902)\n",
      "------------oot------------\n",
      " (0.6439694621114703, 0.22489139123483823)\n",
      "隐藏层vs神经元数vs norm 1 30 0.05\n",
      "验证集最优结果： 0.9121450781822205 0.9011920690536499\n",
      "------------train------------\n",
      " (0.6143663212950724, 0.1665489709577886)\n",
      "------------test------------\n",
      " (0.5858483233399956, 0.14352653786364644)\n",
      "------------oot------------\n",
      " (0.6355576408438467, 0.21583428909046676)\n",
      "隐藏层vs神经元数vs norm 1 30 0.1\n",
      "验证集最优结果： 1.2290147542953491 1.2188811302185059\n",
      "------------train------------\n",
      " (0.6019252283696065, 0.13923855817003816)\n",
      "------------test------------\n",
      " (0.5813046857650455, 0.1410504108372196)\n",
      "------------oot------------\n",
      " (0.609243619597076, 0.1658777325965315)\n",
      "隐藏层vs神经元数vs norm 1 30 0.2\n",
      "验证集最优结果： 1.8505821228027344 1.834760069847107\n",
      "------------train------------\n",
      " (0.569396476167465, 0.10505441819133027)\n",
      "------------test------------\n",
      " (0.5563235620697313, 0.0960803908505441)\n",
      "------------oot------------\n",
      " (0.5538826909486902, 0.10167865707434054)\n",
      "隐藏层vs神经元数vs norm 1 30 0.3\n",
      "验证集最优结果： 2.4762203693389893 2.457190752029419\n",
      "------------train------------\n",
      " (0.5984041030389046, 0.15644527826338256)\n",
      "------------test------------\n",
      " (0.5758416611148123, 0.13144570286475676)\n",
      "------------oot------------\n",
      " (0.5781693485791077, 0.11884057971014494)\n",
      "隐藏层vs神经元数vs norm 1 30 0.4\n",
      "验证集最优结果： 3.0800914764404297 3.059824228286743\n",
      "------------train------------\n",
      " (0.5844286343710724, 0.11952564365475293)\n",
      "------------test------------\n",
      " (0.5515956029313791, 0.08717521652231841)\n",
      "------------oot------------\n",
      " (0.5942364948620813, 0.1595037013867167)\n",
      "隐藏层vs神经元数vs norm 1 30 0.5\n",
      "验证集最优结果： 3.7528202533721924 3.7222659587860107\n",
      "------------train------------\n",
      " (0.5512015588082615, 0.08362797868618016)\n",
      "------------test------------\n",
      " (0.5423051299133911, 0.07636020430823898)\n",
      "------------oot------------\n",
      " (0.5435755743231501, 0.09071699162409202)\n",
      "隐藏层vs神经元数vs norm 1 30 0.8\n",
      "验证集最优结果： 5.447537422180176 5.406637668609619\n",
      "------------train------------\n",
      " (0.514792096858357, 0.03650313122022497)\n",
      "------------test------------\n",
      " (0.5366011547856984, 0.07689318232289588)\n",
      "------------oot------------\n",
      " (0.4895364867526269, 0.009321238661244902)\n",
      "隐藏层vs神经元数vs norm 1 32 0.01\n",
      "验证集最优结果： 0.6469796299934387 0.6419521570205688\n",
      "------------train------------\n",
      " (0.678691933004814, 0.2612852858706267)\n",
      "------------test------------\n",
      " (0.6484699089495892, 0.214290473017988)\n",
      "------------oot------------\n",
      " (0.6389068455380623, 0.22337608174330098)\n",
      "隐藏层vs神经元数vs norm 1 32 0.05\n",
      "验证集最优结果： 0.9387515187263489 0.9287951588630676\n",
      "------------train------------\n",
      " (0.6156598912109934, 0.16759327503368782)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.5816366866533422, 0.14612480568509878)\n",
      "------------oot------------\n",
      " (0.6129681761836907, 0.1789733430646787)\n",
      "隐藏层vs神经元数vs norm 1 32 0.1\n",
      "验证集最优结果： 1.2668054103851318 1.2552183866500854\n",
      "------------train------------\n",
      " (0.6037117125165562, 0.15365509810570144)\n",
      "------------test------------\n",
      " (0.5600244281590051, 0.12244059515878303)\n",
      "------------oot------------\n",
      " (0.595876921651085, 0.14470510548083276)\n",
      "隐藏层vs神经元数vs norm 1 32 0.2\n",
      "验证集最优结果： 1.947908639907837 1.9304907321929932\n",
      "------------train------------\n",
      " (0.5519201185214062, 0.09050806780734721)\n",
      "------------test------------\n",
      " (0.536554519209416, 0.07873639795691756)\n",
      "------------oot------------\n",
      " (0.5456376927443553, 0.09087686372641018)\n",
      "隐藏层vs神经元数vs norm 1 32 0.3\n",
      "验证集最优结果： 2.6143252849578857 2.592398166656494\n",
      "------------train------------\n",
      " (0.5901888207350195, 0.13426109226220084)\n",
      "------------test------------\n",
      " (0.563514323784144, 0.11522318454363756)\n",
      "------------oot------------\n",
      " (0.5995991612507096, 0.14150766343446985)\n",
      "隐藏层vs神经元数vs norm 1 32 0.4\n",
      "验证集最优结果： 3.2518296241760254 3.225270986557007\n",
      "------------train------------\n",
      " (0.5982092520062076, 0.14457093856744224)\n",
      "------------test------------\n",
      " (0.587711525649567, 0.1444925605152121)\n",
      "------------oot------------\n",
      " (0.6087408334202205, 0.1775136412609043)\n",
      "隐藏层vs神经元数vs norm 1 32 0.5\n",
      "验证集最优结果： 3.926684617996216 3.9006457328796387\n",
      "------------train------------\n",
      " (0.5339825886152582, 0.057382715447781674)\n",
      "------------test------------\n",
      " (0.5411925383077948, 0.09087275149900065)\n",
      "------------oot------------\n",
      " (0.5561394362770653, 0.09333750390991558)\n",
      "隐藏层vs神经元数vs norm 1 32 0.8\n",
      "验证集最优结果： 5.876857757568359 5.8430280685424805\n",
      "------------train------------\n",
      " (0.4883438609742281, 0.010003390773441478)\n",
      "------------test------------\n",
      " (0.4755429713524317, 0.005551854319342575)\n",
      "------------oot------------\n",
      " (0.4940302830199609, 0.01578563236367425)\n",
      "隐藏层vs神经元数vs norm 1 34 0.01\n",
      "验证集最优结果： 0.653755784034729 0.6497803330421448\n",
      "------------train------------\n",
      " (0.679952271987406, 0.26707762028616505)\n",
      "------------test------------\n",
      " (0.6480624028425493, 0.21191427936930934)\n",
      "------------oot------------\n",
      " (0.6426638399425387, 0.2297431619921454)\n",
      "隐藏层vs神经元数vs norm 1 34 0.05\n",
      "验证集最优结果： 0.9527946710586548 0.9422288537025452\n",
      "------------train------------\n",
      " (0.5986464655078478, 0.1424437527537344)\n",
      "------------test------------\n",
      " (0.5627825893848546, 0.1012991339107262)\n",
      "------------oot------------\n",
      " (0.6053337040512519, 0.16875543043825803)\n",
      "隐藏层vs神经元数vs norm 1 34 0.1\n",
      "验证集最优结果： 1.3139493465423584 1.3019839525222778\n",
      "------------train------------\n",
      " (0.608105099087063, 0.15856055237797445)\n",
      "------------test------------\n",
      " (0.5799378192316234, 0.13537641572285142)\n",
      "------------oot------------\n",
      " (0.5974420463629097, 0.13774024258853784)\n",
      "隐藏层vs神经元数vs norm 1 34 0.2\n",
      "验证集最优结果： 2.0171799659729004 2.0011420249938965\n",
      "------------train------------\n",
      " (0.587472682616161, 0.13003054403301706)\n",
      "------------test------------\n",
      " (0.5650932711525649, 0.1052187430601822)\n",
      "------------oot------------\n",
      " (0.5920457836629247, 0.15660515066207903)\n",
      "隐藏层vs神经元数vs norm 1 34 0.3\n",
      "验证集最优结果： 2.730424404144287 2.710622549057007\n",
      "------------train------------\n",
      " (0.576241574672479, 0.12136518900685533)\n",
      "------------test------------\n",
      " (0.5633166777703753, 0.10106595602931379)\n",
      "------------oot------------\n",
      " (0.5719621404325814, 0.14352344211587253)\n",
      "隐藏层vs神经元数vs norm 1 34 0.4\n",
      "验证集最优结果： 3.4572432041168213 3.4281294345855713\n",
      "------------train------------\n",
      " (0.4893888418512134, 0.014809490646270573)\n",
      "------------test------------\n",
      " (0.480929380413058, 0.028070175438596467)\n",
      "------------oot------------\n",
      " (0.464671740868175, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 1 34 0.5\n",
      "验证集最优结果： 4.102117538452148 4.0824384689331055\n",
      "------------train------------\n",
      " (0.5518121687481684, 0.08537168900448644)\n",
      "------------test------------\n",
      " (0.5553719742393959, 0.11403508771929827)\n",
      "------------oot------------\n",
      " (0.5566016751815939, 0.08874291870851148)\n",
      "隐藏层vs神经元数vs norm 1 34 0.8\n",
      "验证集最优结果： 6.295925617218018 6.24922513961792\n",
      "------------train------------\n",
      " (0.49046333125555397, 0.01773476030074339)\n",
      "------------test------------\n",
      " (0.5146890961581169, 0.03726404619142798)\n",
      "------------oot------------\n",
      " (0.47949003116347505, 0.005970875473534216)\n",
      "隐藏层vs神经元数vs norm 1 36 0.01\n",
      "验证集最优结果： 0.6649516820907593 0.661977231502533\n",
      "------------train------------\n",
      " (0.6737801168023314, 0.24758723796799953)\n",
      "------------test------------\n",
      " (0.6551787697090828, 0.22882522762602708)\n",
      "------------oot------------\n",
      " (0.628518634367868, 0.18126716018489564)\n",
      "隐藏层vs神经元数vs norm 1 36 0.05\n",
      "验证集最优结果： 0.9750325679779053 0.9647859334945679\n",
      "------------train------------\n",
      " (0.619431703663998, 0.18417720276757504)\n",
      "------------test------------\n",
      " (0.6016944259382634, 0.16276926493448807)\n",
      "------------oot------------\n",
      " (0.6262873758963843, 0.2129565912487401)\n",
      "隐藏层vs神经元数vs norm 1 36 0.1\n",
      "验证集最优结果： 1.366168737411499 1.3551045656204224\n",
      "------------train------------\n",
      " (0.6102915049958072, 0.17102993558884055)\n",
      "------------test------------\n",
      " (0.5779924494781257, 0.1392405063291139)\n",
      "------------oot------------\n",
      " (0.598371158145947, 0.14469120355889203)\n",
      "隐藏层vs神经元数vs norm 1 36 0.2\n",
      "验证集最优结果： 2.1150994300842285 2.101766347885132\n",
      "------------train------------\n",
      " (0.5898052098794009, 0.12048453543358245)\n",
      "------------test------------\n",
      " (0.5593260048856318, 0.11324672440595157)\n",
      "------------oot------------\n",
      " (0.5859046096456169, 0.13591213985333467)\n",
      "隐藏层vs神经元数vs norm 1 36 0.3\n",
      "验证集最优结果： 2.853363513946533 2.837812900543213\n",
      "------------train------------\n",
      " (0.553016265560503, 0.08548593302782537)\n",
      "------------test------------\n",
      " (0.5443737508327782, 0.07668221185876078)\n",
      "------------oot------------\n",
      " (0.5494109060577625, 0.08585131894484416)\n",
      "隐藏层vs神经元数vs norm 1 36 0.4\n",
      "验证集最优结果： 3.6123714447021484 3.5929973125457764\n",
      "------------train------------\n",
      " (0.5565136351730817, 0.09003011088032192)\n",
      "------------test------------\n",
      " (0.5473406617810348, 0.08363313346657786)\n",
      "------------oot------------\n",
      " (0.5451210046455589, 0.08135404719702499)\n",
      "隐藏层vs神经元数vs norm 1 36 0.5\n",
      "验证集最优结果： 4.298619747161865 4.273565292358398\n",
      "------------train------------\n",
      " (0.4980786293965845, 0.020837351839782192)\n",
      "------------test------------\n",
      " (0.4863313346657783, 0.024439262713746412)\n",
      "------------oot------------\n",
      " (0.49114331723027377, 0.020081326243353237)\n",
      "隐藏层vs神经元数vs norm 1 36 0.8\n",
      "验证集最优结果： 6.475818157196045 6.452111721038818\n",
      "------------train------------\n",
      " (0.5210849933571973, 0.04822559675243765)\n",
      "------------test------------\n",
      " (0.5247357317343992, 0.07538307794803464)\n",
      "------------oot------------\n",
      " (0.5223160601953221, 0.04936572481145518)\n",
      "隐藏层vs神经元数vs norm 1 38 0.01\n",
      "验证集最优结果： 0.6719334721565247 0.6690093278884888\n",
      "------------train------------\n",
      " (0.6721513273084501, 0.2376194469316884)\n",
      "------------test------------\n",
      " (0.6557472795913835, 0.2328114590273151)\n",
      "------------oot------------\n",
      " (0.6263684704410385, 0.17638758558370699)\n",
      "隐藏层vs神经元数vs norm 1 38 0.05\n",
      "验证集最优结果： 1.0025789737701416 0.9918081760406494\n",
      "------------train------------\n",
      " (0.6019221150846102, 0.14873651389235754)\n",
      "------------test------------\n",
      " (0.5762069731290251, 0.12884743504330454)\n",
      "------------oot------------\n",
      " (0.5968210938495581, 0.1408542731032565)\n",
      "隐藏层vs神经元数vs norm 1 38 0.1\n",
      "验证集最优结果： 1.397455096244812 1.3864333629608154\n",
      "------------train------------\n",
      " (0.6053660850914934, 0.15812509855915818)\n",
      "------------test------------\n",
      " (0.593023539862314, 0.15853875194314904)\n",
      "------------oot------------\n",
      " (0.6144371459354256, 0.17031244569561738)\n",
      "隐藏层vs神经元数vs norm 1 38 0.2\n",
      "验证集最优结果： 2.192289352416992 2.177205801010132\n",
      "------------train------------\n",
      " (0.5888541689931703, 0.1287309505874295)\n",
      "------------test------------\n",
      " (0.563757495003331, 0.11583388851876525)\n",
      "------------oot------------\n",
      " (0.5819460373730001, 0.13778194835436008)\n",
      "隐藏层vs神经元数vs norm 1 38 0.3\n",
      "验证集最优结果： 2.964221715927124 2.942775249481201\n",
      "------------train------------\n",
      " (0.5479553500787459, 0.07416156189447454)\n",
      "------------test------------\n",
      " (0.5315911614479236, 0.07979125027759276)\n",
      "------------oot------------\n",
      " (0.5483566769772588, 0.09164146943314916)\n",
      "隐藏层vs神经元数vs norm 1 38 0.4\n",
      "验证集最优结果： 3.7388358116149902 3.7193000316619873\n",
      "------------train------------\n",
      " (0.5583374110598773, 0.08966951126163164)\n",
      "------------test------------\n",
      " (0.5411536753275594, 0.10375305351987557)\n",
      "------------oot------------\n",
      " (0.5740856590090246, 0.15201056546067493)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 1 38 0.5\n",
      "验证集最优结果： 4.536813259124756 4.504776477813721\n",
      "------------train------------\n",
      " (0.5161025868014313, 0.04020252595701368)\n",
      "------------test------------\n",
      " (0.5341083721963136, 0.08310015545192095)\n",
      "------------oot------------\n",
      " (0.5125348996165386, 0.046856427901157294)\n",
      "隐藏层vs神经元数vs norm 1 38 0.8\n",
      "验证集最优结果： 6.866541862487793 6.8228840827941895\n",
      "------------train------------\n",
      " (0.5238948684264849, 0.046784281159414354)\n",
      "------------test------------\n",
      " (0.5121385742838107, 0.058394403730846145)\n",
      "------------oot------------\n",
      " (0.5403595963808663, 0.08949362249330972)\n",
      "隐藏层vs神经元数vs norm 1 40 0.01\n",
      "验证集最优结果： 0.670731782913208 0.6771456003189087\n",
      "------------train------------\n",
      " (0.6761463487596605, 0.25855913109569356)\n",
      "------------test------------\n",
      " (0.6557317343992893, 0.22780368643126797)\n",
      "------------oot------------\n",
      " (0.637055572932958, 0.20910575887116395)\n",
      "隐藏层vs神经元数vs norm 1 40 0.05\n",
      "验证集最优结果： 1.0237762928009033 1.0121856927871704\n",
      "------------train------------\n",
      " (0.6156624630551207, 0.16828604862545082)\n",
      "------------test------------\n",
      " (0.6003864090606263, 0.16224739062846988)\n",
      "------------oot------------\n",
      " (0.6254335661905258, 0.20891808292496444)\n",
      "隐藏层vs神经元数vs norm 1 40 0.1\n",
      "验证集最优结果： 1.4457805156707764 1.4351352453231812\n",
      "------------train------------\n",
      " (0.5870767539807747, 0.12766688391981534)\n",
      "------------test------------\n",
      " (0.5831634465911615, 0.13789695758383297)\n",
      "------------oot------------\n",
      " (0.5877917955490681, 0.15213568275814132)\n",
      "隐藏层vs神经元数vs norm 1 40 0.2\n",
      "验证集最优结果： 2.272590398788452 2.257168769836426\n",
      "------------train------------\n",
      " (0.5743772584006243, 0.10753516489243264)\n",
      "------------test------------\n",
      " (0.5516211414612481, 0.08833000222074172)\n",
      "------------oot------------\n",
      " (0.5678182092007553, 0.11312688979251384)\n",
      "隐藏层vs神经元数vs norm 1 40 0.3\n",
      "验证集最优结果： 3.091616630554199 3.0734660625457764\n",
      "------------train------------\n",
      " (0.592302605887222, 0.13822200293867037)\n",
      "------------test------------\n",
      " (0.5525383077948035, 0.09504774594714638)\n",
      "------------oot------------\n",
      " (0.5891692443146932, 0.13614152156535642)\n",
      "隐藏层vs神经元数vs norm 1 40 0.4\n",
      "验证集最优结果： 3.9462358951568604 3.912865161895752\n",
      "------------train------------\n",
      " (0.5673130793840298, 0.1079903813029639)\n",
      "------------test------------\n",
      " (0.5377803686431268, 0.06888740839440377)\n",
      "------------oot------------\n",
      " (0.5848631239935588, 0.1568762381399228)\n",
      "隐藏层vs神经元数vs norm 1 40 0.5\n",
      "验证集最优结果： 4.7508087158203125 4.728736877441406\n",
      "------------train------------\n",
      " (0.5085866430598448, 0.0252457633944011)\n",
      "------------test------------\n",
      " (0.5123961803242283, 0.04270486342438376)\n",
      "------------oot------------\n",
      " (0.5173924628413211, 0.0468355750182462)\n",
      "隐藏层vs神经元数vs norm 1 40 0.8\n",
      "验证集最优结果： 7.236716270446777 7.186333656311035\n",
      "------------train------------\n",
      " (0.5046731761395131, 0.01702682636465097)\n",
      "------------test------------\n",
      " (0.508040195425272, 0.04595825005551857)\n",
      "------------oot------------\n",
      " (0.5366697945991034, 0.07922010217912626)\n",
      "隐藏层vs神经元数vs norm 1 42 0.01\n",
      "验证集最优结果： 0.6821872591972351 0.7499469518661499\n",
      "------------train------------\n",
      " (0.6727693143801957, 0.25394321232806716)\n",
      "------------test------------\n",
      " (0.6428036864312681, 0.21785476349100602)\n",
      "------------oot------------\n",
      " (0.632247824928463, 0.21212247593229766)\n",
      "隐藏层vs神经元数vs norm 1 42 0.05\n",
      "验证集最优结果： 1.0466994047164917 1.0365564823150635\n",
      "------------train------------\n",
      " (0.6080546774061464, 0.16285729175338176)\n",
      "------------test------------\n",
      " (0.5894148345547414, 0.150388629802354)\n",
      "------------oot------------\n",
      " (0.6222824638839652, 0.18714767316581515)\n",
      "隐藏层vs神经元数vs norm 1 42 0.1\n",
      "验证集最优结果： 1.4863736629486084 1.4748388528823853\n",
      "------------train------------\n",
      " (0.6009971987203044, 0.15216139810861173)\n",
      "------------test------------\n",
      " (0.5994314901176994, 0.1645680657339551)\n",
      "------------oot------------\n",
      " (0.6186563792444305, 0.20079240955062033)\n",
      "隐藏层vs神经元数vs norm 1 42 0.2\n",
      "验证集最优结果： 2.3654625415802 2.3479299545288086\n",
      "------------train------------\n",
      " (0.5773209370446397, 0.12078097430930751)\n",
      "------------test------------\n",
      " (0.5688074616922052, 0.11852098600932709)\n",
      "------------oot------------\n",
      " (0.5751039747911816, 0.11603239147812183)\n",
      "隐藏层vs神经元数vs norm 1 42 0.3\n",
      "验证集最优结果： 3.245426654815674 3.2350375652313232\n",
      "------------train------------\n",
      " (0.5753448809134649, 0.11954933169276755)\n",
      "------------test------------\n",
      " (0.5450510770597379, 0.0786031534532533)\n",
      "------------oot------------\n",
      " (0.5774418146642106, 0.11674138949709799)\n",
      "隐藏层vs神经元数vs norm 1 42 0.4\n",
      "验证集最优结果： 4.076498508453369 4.056734085083008\n",
      "------------train------------\n",
      " (0.5384106274013749, 0.09308925178963123)\n",
      "------------test------------\n",
      " (0.5443659782367309, 0.08726404619142791)\n",
      "------------oot------------\n",
      " (0.555759450410686, 0.11309213498766202)\n",
      "隐藏层vs神经元数vs norm 1 42 0.5\n",
      "验证集最优结果： 4.948666095733643 4.925886154174805\n",
      "------------train------------\n",
      " (0.5244717059921937, 0.04650232582693248)\n",
      "------------test------------\n",
      " (0.5384654674661337, 0.09411503442149677)\n",
      "------------oot------------\n",
      " (0.5396297454789791, 0.06681263684704403)\n",
      "隐藏层vs神经元数vs norm 1 42 0.8\n",
      "验证集最优结果： 7.419895648956299 7.348678112030029\n",
      "------------train------------\n",
      " (0.5275905407572997, 0.057971803113149645)\n",
      "------------test------------\n",
      " (0.5229680213191206, 0.05450810570730624)\n",
      "------------oot------------\n",
      " (0.5305691678541224, 0.06982240294720743)\n",
      "隐藏层vs神经元数vs norm 1 44 0.01\n",
      "验证集最优结果： 0.6802344918251038 0.6770809292793274\n",
      "------------train------------\n",
      " (0.66703004116981, 0.23145365367682347)\n",
      "------------test------------\n",
      " (0.651316899844548, 0.22591605596269154)\n",
      "------------oot------------\n",
      " (0.6245600620952513, 0.1828797831300177)\n",
      "隐藏层vs神经元数vs norm 1 44 0.05\n",
      "验证集最优结果： 1.062670350074768 1.0524827241897583\n",
      "------------train------------\n",
      " (0.5688357464676059, 0.10184123735481765)\n",
      "------------test------------\n",
      " (0.5503708638685321, 0.10934932267377306)\n",
      "------------oot------------\n",
      " (0.5366443077422121, 0.06804990789976711)\n",
      "隐藏层vs神经元数vs norm 1 44 0.1\n",
      "验证集最优结果： 1.524064064025879 1.5123428106307983\n",
      "------------train------------\n",
      " (0.5898559699608606, 0.13476273722724064)\n",
      "------------test------------\n",
      " (0.5604497001998667, 0.10344214967799248)\n",
      "------------oot------------\n",
      " (0.5815475156106998, 0.15702220832030028)\n",
      "隐藏层vs神经元数vs norm 1 44 0.2\n",
      "验证集最优结果： 2.448592185974121 2.4321627616882324\n",
      "------------train------------\n",
      " (0.6036687356475869, 0.14167422991880413)\n",
      "------------test------------\n",
      " (0.583530979347102, 0.1656340217632689)\n",
      "------------oot------------\n",
      " (0.6001320682584367, 0.16820630452160013)\n",
      "隐藏层vs神经元数vs norm 1 44 0.3\n",
      "验证集最优结果： 3.3267111778259277 3.3114562034606934\n",
      "------------train------------\n",
      " (0.5400699406242407, 0.07236072956449885)\n",
      "------------test------------\n",
      " (0.5402187430601821, 0.07689318232289588)\n",
      "------------oot------------\n",
      " (0.5628586985484076, 0.11543460883467138)\n",
      "隐藏层vs神经元数vs norm 1 44 0.4\n",
      "验证集最优结果： 4.243247032165527 4.218473434448242\n",
      "------------train------------\n",
      " (0.5215618674024849, 0.047699451588079866)\n",
      "------------test------------\n",
      " (0.5097868087941373, 0.03232289584721304)\n",
      "------------oot------------\n",
      " (0.5303699069729724, 0.07431272373405629)\n",
      "隐藏层vs神经元数vs norm 1 44 0.5\n",
      "验证集最优结果： 5.11995792388916 5.08126163482666\n",
      "------------train------------\n",
      " (0.5194119410722831, 0.040173288150092856)\n",
      "------------test------------\n",
      " (0.5047357317343992, 0.032400621807683765)\n",
      "------------oot------------\n",
      " (0.49732619701340375, 0.020873735793973558)\n",
      "隐藏层vs神经元数vs norm 1 44 0.8\n",
      "验证集最优结果： 7.750864028930664 7.709246635437012\n",
      "------------train------------\n",
      " (0.4821765787569736, 0.0026021648159541)\n",
      "------------test------------\n",
      " (0.5143471019320452, 0.0740395292027538)\n",
      "------------oot------------\n",
      " (0.48413674857215677, 0.029624995655649355)\n",
      "隐藏层vs神经元数vs norm 1 46 0.01\n",
      "验证集最优结果： 0.6888569593429565 0.6842483878135681\n",
      "------------train------------\n",
      " (0.6668966436757338, 0.23059939534590962)\n",
      "------------test------------\n",
      " (0.6492005329780146, 0.23027981345769483)\n",
      "------------oot------------\n",
      " (0.6213209142830662, 0.1699579466861294)\n",
      "隐藏层vs神经元数vs norm 1 46 0.05\n",
      "验证集最优结果： 1.089276909828186 1.0804836750030518\n",
      "------------train------------\n",
      " (0.6164409196643879, 0.18228554373184058)\n",
      "------------test------------\n",
      " (0.5874217188540973, 0.15078836331334666)\n",
      "------------oot------------\n",
      " (0.6108041103349204, 0.15999721961561186)\n",
      "隐藏层vs神经元数vs norm 1 46 0.1\n",
      "验证集最优结果： 1.5860216617584229 1.575012445449829\n",
      "------------train------------\n",
      " (0.6066903140966161, 0.16828415358240967)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.5864401510104376, 0.1524095047745947)\n",
      "------------oot------------\n",
      " (0.6119174225836722, 0.18123935634101418)\n",
      "隐藏层vs神经元数vs norm 1 46 0.2\n",
      "验证集最优结果： 2.518087387084961 2.500412940979004\n",
      "------------train------------\n",
      " (0.5723777849518693, 0.11943102686291196)\n",
      "------------test------------\n",
      " (0.5413890739506996, 0.07459471463468798)\n",
      "------------oot------------\n",
      " (0.5619214773109049, 0.10348590692663262)\n",
      "隐藏层vs神经元数vs norm 1 46 0.3\n",
      "验证集最优结果： 3.508509635925293 3.489976167678833\n",
      "------------train------------\n",
      " (0.577218401680091, 0.11792663340866127)\n",
      "------------test------------\n",
      " (0.5593471019320453, 0.10695092160781705)\n",
      "------------oot------------\n",
      " (0.6000996304405751, 0.14639418899662876)\n",
      "隐藏层vs神经元数vs norm 1 46 0.4\n",
      "验证集最优结果： 4.41191291809082 4.380073070526123\n",
      "------------train------------\n",
      " (0.563691719812472, 0.10583260408016304)\n",
      "------------test------------\n",
      " (0.5641427936930935, 0.10084388185654009)\n",
      "------------oot------------\n",
      " (0.5832342821395058, 0.14036075487436134)\n",
      "隐藏层vs神经元数vs norm 1 46 0.5\n",
      "验证集最优结果： 5.311683654785156 5.281221866607666\n",
      "------------train------------\n",
      " (0.5245295724850578, 0.04336359310989424)\n",
      "------------test------------\n",
      " (0.5135365312014213, 0.04882300688429936)\n",
      "------------oot------------\n",
      " (0.5037361415215654, 0.03426128662287564)\n",
      "隐藏层vs神经元数vs norm 1 46 0.8\n",
      "验证集最优结果： 8.094347953796387 8.032730102539062\n",
      "------------train------------\n",
      " (0.509781535377408, 0.033487305580428006)\n",
      "------------test------------\n",
      " (0.49525760604041746, 0.026859871196979856)\n",
      "------------oot------------\n",
      " (0.5171897264796859, 0.05909011920898066)\n",
      "隐藏层vs神经元数vs norm 1 48 0.01\n",
      "验证集最优结果： 0.6847968101501465 0.6801894307136536\n",
      "------------train------------\n",
      " (0.6801775113888703, 0.27119297697048944)\n",
      "------------test------------\n",
      " (0.6476215856095935, 0.20873861869864535)\n",
      "------------oot------------\n",
      " (0.6416258297709658, 0.2251207729468599)\n",
      "隐藏层vs神经元数vs norm 1 48 0.05\n",
      "验证集最优结果： 1.1018544435501099 1.0916413068771362\n",
      "------------train------------\n",
      " (0.6129800296303516, 0.16093409378703372)\n",
      "------------test------------\n",
      " (0.5858483233399956, 0.15013324450366422)\n",
      "------------oot------------\n",
      " (0.6094301370497806, 0.16425815869043903)\n",
      "隐藏层vs神经元数vs norm 1 48 0.1\n",
      "验证集最优结果： 1.6186045408248901 1.604627013206482\n",
      "------------train------------\n",
      " (0.5844276868495519, 0.12785205669698052)\n",
      "------------test------------\n",
      " (0.552981345769487, 0.09230512991339102)\n",
      "------------oot------------\n",
      " (0.5899002537100754, 0.1482083898098912)\n",
      "隐藏层vs神经元数vs norm 1 48 0.2\n",
      "验证集最优结果： 2.6328277587890625 2.6199846267700195\n",
      "------------train------------\n",
      " (0.58773819168225, 0.12567180967812014)\n",
      "------------test------------\n",
      " (0.5725394181656673, 0.12752609371530094)\n",
      "------------oot------------\n",
      " (0.6055804631656994, 0.18093351405831853)\n",
      "隐藏层vs神经元数vs norm 1 48 0.3\n",
      "验证集最优结果： 3.609222173690796 3.5880982875823975\n",
      "------------train------------\n",
      " (0.588060890440117, 0.12745396229811867)\n",
      "------------test------------\n",
      " (0.5908727514990006, 0.1358871863202309)\n",
      "------------oot------------\n",
      " (0.6131616445973656, 0.1822889514475376)\n",
      "隐藏层vs神经元数vs norm 1 48 0.4\n",
      "验证集最优结果： 4.53162956237793 4.517889976501465\n",
      "------------train------------\n",
      " (0.5152807472425431, 0.04118781297820229)\n",
      "------------test------------\n",
      " (0.5031256939817899, 0.036786586719964466)\n",
      "------------oot------------\n",
      " (0.4864595280297501, 0.02255586834879919)\n",
      "隐藏层vs神经元数vs norm 1 48 0.5\n",
      "验证集最优结果： 5.497931480407715 5.473864555358887\n",
      "------------train------------\n",
      " (0.5352113886672365, 0.064798831029164)\n",
      "------------test------------\n",
      " (0.48425049966688877, 0.005574061736620034)\n",
      "------------oot------------\n",
      " (0.5074664905756554, 0.045014423244013446)\n",
      "隐藏层vs神经元数vs norm 1 48 0.8\n",
      "验证集最优结果： 8.41672134399414 8.355527877807617\n",
      "------------train------------\n",
      " (0.5412787073640696, 0.0841608918613993)\n",
      "------------test------------\n",
      " (0.5304585831667777, 0.07197423939595832)\n",
      "------------oot------------\n",
      " (0.5520302598500909, 0.10938032182949295)\n",
      "隐藏层vs神经元数vs norm 1 50 0.01\n",
      "验证集最优结果： 0.6905126571655273 0.6867944002151489\n",
      "------------train------------\n",
      " (0.6793902563654834, 0.2658834724497966)\n",
      "------------test------------\n",
      " (0.6464268265600711, 0.21303575394181656)\n",
      "------------oot------------\n",
      " (0.6469398394328015, 0.23453932506168973)\n",
      "隐藏层vs神经元数vs norm 1 50 0.05\n",
      "验证集最优结果： 1.1243172883987427 1.115144968032837\n",
      "------------train------------\n",
      " (0.6170386027035496, 0.1765286736932155)\n",
      "------------test------------\n",
      " (0.5848267821452365, 0.15024428159005104)\n",
      "------------oot------------\n",
      " (0.6147279278026854, 0.16049768880547732)\n",
      "隐藏层vs神经元数vs norm 1 50 0.1\n",
      "验证集最优结果： 1.644904613494873 1.6308584213256836\n",
      "------------train------------\n",
      " (0.6009122601839951, 0.14718393220077436)\n",
      "------------test------------\n",
      " (0.566892071952032, 0.10685098823006889)\n",
      "------------oot------------\n",
      " (0.5994670929922729, 0.14935529836999964)\n",
      "隐藏层vs神经元数vs norm 1 50 0.2\n",
      "验证集最优结果： 2.7210803031921387 2.7072393894195557\n",
      "------------train------------\n",
      " (0.5711242139801385, 0.10173497958429523)\n",
      "------------test------------\n",
      " (0.5526571174772374, 0.0990894958916278)\n",
      "------------oot------------\n",
      " (0.5608162745166185, 0.09629861328328637)\n",
      "隐藏层vs神经元数vs norm 1 50 0.3\n",
      "验证集最优结果： 3.7596497535705566 3.747715473175049\n",
      "------------train------------\n",
      " (0.5167658518658391, 0.033149311118014446)\n",
      "------------test------------\n",
      " (0.4982034199422607, 0.037908061292471706)\n",
      "------------oot------------\n",
      " (0.5635259908015616, 0.11355784937267577)\n",
      "隐藏层vs神经元数vs norm 1 50 0.4\n",
      "验证集最优结果： 4.7706499099731445 4.7514729499816895\n",
      "------------train------------\n",
      " (0.5437576943823479, 0.07922768874459485)\n",
      "------------test------------\n",
      " (0.54454363757495, 0.07730401954252719)\n",
      "------------oot------------\n",
      " (0.5328965812856961, 0.07910888680360062)\n",
      "隐藏层vs神经元数vs norm 1 50 0.5\n",
      "验证集最优结果： 5.816970348358154 5.785086154937744\n",
      "------------train------------\n",
      " (0.56822899429389, 0.10954106795150587)\n",
      "------------test------------\n",
      " (0.5458427714856762, 0.08645347546080395)\n",
      "------------oot------------\n",
      " (0.5620743984522527, 0.10663469224620303)\n",
      "隐藏层vs神经元数vs norm 1 50 0.8\n",
      "验证集最优结果： 8.866453170776367 8.818931579589844\n",
      "------------train------------\n",
      " (0.5239636314168357, 0.0419006198821148)\n",
      "------------test------------\n",
      " (0.524206084832334, 0.07698201199200527)\n",
      "------------oot------------\n",
      " (0.5462308414138255, 0.08717895249018176)\n",
      "隐藏层vs神经元数vs norm 1 52 0.01\n",
      "验证集最优结果： 0.6996172666549683 0.695814847946167\n",
      "------------train------------\n",
      " (0.6686720959649796, 0.23567838141666653)\n",
      "------------test------------\n",
      " (0.6531512325116589, 0.23669775705085505)\n",
      "------------oot------------\n",
      " (0.6229254277737231, 0.17175129461648073)\n",
      "隐藏层vs神经元数vs norm 1 52 0.05\n",
      "验证集最优结果： 1.1485447883605957 1.1366018056869507\n",
      "------------train------------\n",
      " (0.6163538830447115, 0.17526657502779958)\n",
      "------------test------------\n",
      " (0.5961103708638686, 0.14892294026204755)\n",
      "------------oot------------\n",
      " (0.6290573338430705, 0.21060021547979002)\n",
      "隐藏层vs神经元数vs norm 1 52 0.1\n",
      "验证集最优结果： 1.706105351448059 1.6929545402526855\n",
      "------------train------------\n",
      " (0.6015720058827551, 0.156246163383843)\n",
      "------------test------------\n",
      " (0.5898079058405508, 0.14844548079058412)\n",
      "------------oot------------\n",
      " (0.6266268144904366, 0.2150835853056685)\n",
      "隐藏层vs神经元数vs norm 1 52 0.2\n",
      "验证集最优结果： 2.784855365753174 2.7619340419769287\n",
      "------------train------------\n",
      " (0.5824445243069727, 0.1257427384319466)\n",
      "------------test------------\n",
      " (0.5633988452143015, 0.1060293137908061)\n",
      "------------oot------------\n",
      " (0.5902199979147118, 0.14671393320126502)\n",
      "隐藏层vs神经元数vs norm 1 52 0.3\n",
      "验证集最优结果： 3.832962989807129 3.808814764022827\n",
      "------------train------------\n",
      " (0.591061149654933, 0.14703097515530894)\n",
      "------------test------------\n",
      " (0.5794858982900288, 0.12526093715300912)\n",
      "------------oot------------\n",
      " (0.5766563560745606, 0.12805060299586418)\n",
      "隐藏层vs神经元数vs norm 1 52 0.4\n",
      "验证集最优结果： 4.8801164627075195 4.843968391418457\n",
      "------------train------------\n",
      " (0.5703683625271482, 0.099926025641286)\n",
      "------------test------------\n",
      " (0.5708794137241839, 0.12234066178103487)\n",
      "------------oot------------\n",
      " (0.5769286020458995, 0.11658846835575015)\n",
      "隐藏层vs神经元数vs norm 1 52 0.5\n",
      "验证集最优结果： 5.966835021972656 5.932262897491455\n",
      "------------train------------\n",
      " (0.47424467306785134, 0.006152934034228452)\n",
      "------------test------------\n",
      " (0.46389407061958693, 0.010348656451254719)\n",
      "------------oot------------\n",
      " (0.4436601443482895, 0.0)\n",
      "隐藏层vs神经元数vs norm 1 52 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集最优结果： 9.162543296813965 9.123723983764648\n",
      "------------train------------\n",
      " (0.5056822865589334, 0.018425638849465242)\n",
      "------------test------------\n",
      " (0.5046169220519654, 0.03580946035976018)\n",
      "------------oot------------\n",
      " (0.48013299505323276, 0.012351857644319342)\n",
      "隐藏层vs神经元数vs norm 1 54 0.01\n",
      "验证集最优结果： 0.7009040713310242 0.6965077519416809\n",
      "------------train------------\n",
      " (0.6668502828013338, 0.22708503802606905)\n",
      "------------test------------\n",
      " (0.6529469242727071, 0.23040195425272048)\n",
      "------------oot------------\n",
      " (0.6213023783871454, 0.17668647690543215)\n",
      "隐藏层vs神经元数vs norm 1 54 0.05\n",
      "验证集最优结果： 1.1730318069458008 1.1627293825149536\n",
      "------------train------------\n",
      " (0.6054509559476942, 0.147740533414008)\n",
      "------------test------------\n",
      " (0.5812247390628471, 0.12910282034199427)\n",
      "------------oot------------\n",
      " (0.5928914839143178, 0.1459423765335558)\n",
      "隐藏层vs神经元数vs norm 1 54 0.1\n",
      "验证集最优结果： 1.7488681077957153 1.7423279285430908\n",
      "------------train------------\n",
      " (0.5884712349386378, 0.1405776767990557)\n",
      "------------test------------\n",
      " (0.5497768154563625, 0.10809460359760165)\n",
      "------------oot------------\n",
      " (0.6001598721023181, 0.1485211830535571)\n",
      "隐藏层vs神经元数vs norm 1 54 0.2\n",
      "验证集最优结果： 2.85583758354187 2.8443894386291504\n",
      "------------train------------\n",
      " (0.6045508105031407, 0.1628483579790449)\n",
      "------------test------------\n",
      " (0.5937008660892739, 0.15657339551410165)\n",
      "------------oot------------\n",
      " (0.6340631842352205, 0.2310916484203941)\n",
      "隐藏层vs神经元数vs norm 1 54 0.3\n",
      "验证集最优结果： 4.016089916229248 4.0092902183532715\n",
      "------------train------------\n",
      " (0.5785644913602958, 0.12908072138874171)\n",
      "------------test------------\n",
      " (0.5662036420164336, 0.11616699977792577)\n",
      "------------oot------------\n",
      " (0.5888645605254927, 0.14468425259792161)\n",
      "隐藏层vs神经元数vs norm 1 54 0.4\n",
      "验证集最优结果： 5.04401159286499 5.014410972595215\n",
      "------------train------------\n",
      " (0.5442774099363875, 0.06978008702308369)\n",
      "------------test------------\n",
      " (0.5424083944037308, 0.08714190539640237)\n",
      "------------oot------------\n",
      " (0.5185138845445383, 0.05765127028811734)\n",
      "隐藏层vs神经元数vs norm 1 54 0.5\n",
      "验证集最优结果： 6.085422039031982 6.059995174407959\n",
      "------------train------------\n",
      " (0.5266457264410618, 0.05432059661369343)\n",
      "------------test------------\n",
      " (0.494105041083722, 0.03572063069065068)\n",
      "------------oot------------\n",
      " (0.5161748861780141, 0.07021165676154723)\n",
      "隐藏层vs神经元数vs norm 1 54 0.8\n",
      "验证集最优结果： 9.307507514953613 9.271963119506836\n",
      "------------train------------\n",
      " (0.5494552766458279, 0.08329377430984897)\n",
      "------------test------------\n",
      " (0.5486031534532534, 0.08599822340661789)\n",
      "------------oot------------\n",
      " (0.5617395938321806, 0.11050637750669035)\n",
      "隐藏层vs神经元数vs norm 1 56 0.01\n",
      "验证集最优结果： 0.7091653943061829 0.7050999999046326\n",
      "------------train------------\n",
      " (0.667785283501823, 0.2287777175424811)\n",
      "------------test------------\n",
      " (0.652719298245614, 0.22641572285143235)\n",
      "------------oot------------\n",
      " (0.6231837718231212, 0.17468460014597015)\n",
      "隐藏层vs神经元数vs norm 1 56 0.05\n",
      "验证集最优结果： 1.197234034538269 1.1850073337554932\n",
      "------------train------------\n",
      " (0.6100509022096878, 0.16111723616094065)\n",
      "------------test------------\n",
      " (0.5875605152120809, 0.1425494115034422)\n",
      "------------oot------------\n",
      " (0.612777024757006, 0.17660306537378795)\n",
      "隐藏层vs神经元数vs norm 1 56 0.1\n",
      "验证集最优结果： 1.792000651359558 1.7793340682983398\n",
      "------------train------------\n",
      " (0.5903057042825942, 0.1357863311899043)\n",
      "------------test------------\n",
      " (0.5533599822340662, 0.12481678880746172)\n",
      "------------oot------------\n",
      " (0.5958618612356491, 0.15577103534563652)\n",
      "隐藏层vs神经元数vs norm 1 56 0.2\n",
      "验证集最优结果： 2.936791181564331 2.916036605834961\n",
      "------------train------------\n",
      " (0.5838211377161617, 0.12750228589566848)\n",
      "------------test------------\n",
      " (0.5552753719742394, 0.11616699977792577)\n",
      "------------oot------------\n",
      " (0.5627555926273473, 0.10959580161957383)\n",
      "隐藏层vs神经元数vs norm 1 56 0.3\n",
      "验证集最优结果： 4.088204860687256 4.074869632720947\n",
      "------------train------------\n",
      " (0.5488003362347796, 0.0748757224005594)\n",
      "------------test------------\n",
      " (0.5408250055518543, 0.08025760604041754)\n",
      "------------oot------------\n",
      " (0.5847820294489047, 0.15143363570013552)\n",
      "隐藏层vs神经元数vs norm 1 56 0.4\n",
      "验证集最优结果： 5.182810306549072 5.153984546661377\n",
      "------------train------------\n",
      " (0.559970667440927, 0.1030000561744902)\n",
      "------------test------------\n",
      " (0.5446990894958916, 0.09814568065733953)\n",
      "------------oot------------\n",
      " (0.5371389844646023, 0.08562888819379277)\n",
      "隐藏层vs神经元数vs norm 1 56 0.5\n",
      "验证集最优结果： 6.401577472686768 6.36639404296875\n",
      "------------train------------\n",
      " (0.497798163026492, 0.025370700874900787)\n",
      "------------test------------\n",
      " (0.469974461470131, 0.005263157894736842)\n",
      "------------oot------------\n",
      " (0.476742084593195, 0.005352239947172696)\n",
      "隐藏层vs神经元数vs norm 1 56 0.8\n",
      "验证集最优结果： 9.645233154296875 9.569991111755371\n",
      "------------train------------\n",
      " (0.48938383352317605, 0.007503829002144746)\n",
      "------------test------------\n",
      " (0.47909948922940254, 0.01025982678214521)\n",
      "------------oot------------\n",
      " (0.45524392080538467, 0.00046571438501374907)\n",
      "隐藏层vs神经元数vs norm 1 58 0.01\n",
      "验证集最优结果： 0.7177862524986267 0.7725063562393188\n",
      "------------train------------\n",
      " (0.6701840019112864, 0.2522889751133473)\n",
      "------------test------------\n",
      " (0.6395069953364423, 0.22290695092160778)\n",
      "------------oot------------\n",
      " (0.6304788053615078, 0.19773398672366457)\n",
      "隐藏层vs神经元数vs norm 1 58 0.05\n",
      "验证集最优结果： 1.2158194780349731 1.2050809860229492\n",
      "------------train------------\n",
      " (0.6070481388308532, 0.1498992581583295)\n",
      "------------test------------\n",
      " (0.5763701976460138, 0.13017988007994674)\n",
      "------------oot------------\n",
      " (0.6090906984557283, 0.17614430194974456)\n",
      "隐藏层vs神经元数vs norm 1 58 0.1\n",
      "验证集最优结果： 1.8220019340515137 1.8103175163269043\n",
      "------------train------------\n",
      " (0.5967162964903125, 0.1400741367909747)\n",
      "------------test------------\n",
      " (0.5615023317788141, 0.11184765711747724)\n",
      "------------oot------------\n",
      " (0.5922508370115501, 0.1379487714176485)\n",
      "隐藏层vs神经元数vs norm 1 58 0.2\n",
      "验证集最优结果： 3.0222623348236084 3.003967046737671\n",
      "------------train------------\n",
      " (0.578597857653842, 0.11615693392864757)\n",
      "------------test------------\n",
      " (0.5548745280923828, 0.1189207195203198)\n",
      "------------oot------------\n",
      " (0.5791448001019475, 0.13787926180794502)\n",
      "隐藏层vs神经元数vs norm 1 58 0.3\n",
      "验证集最优结果： 4.202881336212158 4.193219184875488\n",
      "------------train------------\n",
      " (0.5459406486055529, 0.07421069765332755)\n",
      "------------test------------\n",
      " (0.5297990228736398, 0.05358649789029535)\n",
      "------------oot------------\n",
      " (0.5624092030723248, 0.10331213290237379)\n",
      "隐藏层vs神经元数vs norm 1 58 0.4\n",
      "验证集最优结果： 5.38337516784668 5.352809429168701\n",
      "------------train------------\n",
      " (0.5533997410559044, 0.08202098218727227)\n",
      "------------test------------\n",
      " (0.5413091272485011, 0.08464357095269814)\n",
      "------------oot------------\n",
      " (0.5430646786918292, 0.07699579466861295)\n",
      "隐藏层vs神经元数vs norm 1 58 0.5\n",
      "验证集最优结果： 6.561245441436768 6.5078043937683105\n",
      "------------train------------\n",
      " (0.5057890180902163, 0.026085132101419994)\n",
      "------------test------------\n",
      " (0.5080701754385964, 0.035964912280701755)\n",
      "------------oot------------\n",
      " (0.5098692060844079, 0.06378896882494006)\n",
      "隐藏层vs神经元数vs norm 1 58 0.8\n",
      "验证集最优结果： 10.148168563842773 10.071213722229004\n",
      "------------train------------\n",
      " (0.5143731569860424, 0.029238889802570278)\n",
      "------------test------------\n",
      " (0.5182933599822341, 0.045058849655784994)\n",
      "------------oot------------\n",
      " (0.4901250014481168, 0.01671706113370164)\n",
      "隐藏层vs神经元数vs norm 1 60 0.01\n",
      "验证集最优结果： 0.7198982238769531 0.7160325050354004\n",
      "------------train------------\n",
      " (0.6641254816285729, 0.22319126601734368)\n",
      "------------test------------\n",
      " (0.6474206084832335, 0.22108594270486337)\n",
      "------------oot------------\n",
      " (0.619096606772553, 0.16431376637820183)\n",
      "隐藏层vs神经元数vs norm 1 60 0.05\n",
      "验证集最优结果： 1.2368475198745728 1.2270113229751587\n",
      "------------train------------\n",
      " (0.6098907710727094, 0.16914125447788514)\n",
      "------------test------------\n",
      " (0.5836320230957139, 0.13726404619142796)\n",
      "------------oot------------\n",
      " (0.6087848561730327, 0.16093559934660973)\n",
      "隐藏层vs神经元数vs norm 1 60 0.1\n",
      "验证集最优结果： 1.862726092338562 1.8532168865203857\n",
      "------------train------------\n",
      " (0.5990732562727616, 0.14726663729349954)\n",
      "------------test------------\n",
      " (0.5972851432378414, 0.16236953142349547)\n",
      "------------oot------------\n",
      " (0.6204277157983757, 0.18931637298856568)\n",
      "隐藏层vs神经元数vs norm 1 60 0.2\n",
      "验证集最优结果： 3.11808443069458 3.0962541103363037\n",
      "------------train------------\n",
      " (0.5824621211352119, 0.13326308138059306)\n",
      "------------test------------\n",
      " (0.5832200755052187, 0.14735731734399288)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.59342554941554, 0.16783790359017137)\n",
      "隐藏层vs神经元数vs norm 1 60 0.3\n",
      "验证集最优结果： 4.373645782470703 4.350134372711182\n",
      "------------train------------\n",
      " (0.578394614287677, 0.12107849606677046)\n",
      "------------test------------\n",
      " (0.5696324672440595, 0.12385076615589607)\n",
      "------------oot------------\n",
      " (0.5880756264553575, 0.16113022625377965)\n",
      "隐藏层vs神经元数vs norm 1 60 0.4\n",
      "验证集最优结果： 5.545334815979004 5.5138702392578125\n",
      "------------train------------\n",
      " (0.568404082734872, 0.10354691145208345)\n",
      "------------test------------\n",
      " (0.5790350877192982, 0.15741727737064176)\n",
      "------------oot------------\n",
      " (0.5909278374401927, 0.1382059569735516)\n",
      "隐藏层vs神经元数vs norm 1 60 0.5\n",
      "验证集最优结果： 6.752451419830322 6.714202404022217\n",
      "------------train------------\n",
      " (0.523384289687108, 0.044361333271067616)\n",
      "------------test------------\n",
      " (0.5359515878303354, 0.07401732178547638)\n",
      "------------oot------------\n",
      " (0.5425920133458451, 0.0974524728043652)\n",
      "隐藏层vs神经元数vs norm 1 60 0.8\n",
      "验证集最优结果： 10.344383239746094 10.290135383605957\n",
      "------------train------------\n",
      " (0.5132656396886985, 0.03794255177020711)\n",
      "------------test------------\n",
      " (0.5101043748612036, 0.0370197646013769)\n",
      "------------oot------------\n",
      " (0.5066752395185301, 0.04548013762902725)\n",
      "隐藏层vs神经元数vs norm 1 62 0.01\n",
      "验证集最优结果： 0.7220762968063354 0.7179784774780273\n",
      "------------train------------\n",
      " (0.6630477435790189, 0.2214739509413965)\n",
      "------------test------------\n",
      " (0.6483855207639351, 0.21983122362869195)\n",
      "------------oot------------\n",
      " (0.6197129253119242, 0.1705279254856984)\n",
      "隐藏层vs神经元数vs norm 1 62 0.05\n",
      "验证集最优结果： 1.264807939529419 1.254170536994934\n",
      "------------train------------\n",
      " (0.6035512429790347, 0.14980951433430856)\n",
      "------------test------------\n",
      " (0.5861969797912503, 0.1521541194759049)\n",
      "------------oot------------\n",
      " (0.6076958722876771, 0.1616515483265562)\n",
      "隐藏层vs神经元数vs norm 1 62 0.1\n",
      "验证集最优结果： 1.913271188735962 1.9000887870788574\n",
      "------------train------------\n",
      " (0.6170147116252093, 0.177080401938629)\n",
      "------------test------------\n",
      " (0.5902609371530092, 0.16166999777925822)\n",
      "------------oot------------\n",
      " (0.6127944021594318, 0.16076877628332115)\n",
      "隐藏层vs神经元数vs norm 1 62 0.2\n",
      "验证集最优结果： 3.189218282699585 3.168508291244507\n",
      "------------train------------\n",
      " (0.5911244305564862, 0.13127775307453815)\n",
      "------------test------------\n",
      " (0.5815434155007773, 0.13224516988674218)\n",
      "------------oot------------\n",
      " (0.6080376278687195, 0.16741389497097975)\n",
      "隐藏层vs神经元数vs norm 1 62 0.3\n",
      "验证集最优结果： 4.462361812591553 4.437591075897217\n",
      "------------train------------\n",
      " (0.528911724157535, 0.05575974644324111)\n",
      "------------test------------\n",
      " (0.5344870086608927, 0.09150566289140571)\n",
      "------------oot------------\n",
      " (0.544337863042899, 0.09670871998053732)\n",
      "隐藏层vs神经元数vs norm 1 62 0.4\n",
      "验证集最优结果： 5.799417495727539 5.780737400054932\n",
      "------------train------------\n",
      " (0.490857906288768, 0.004295656493669538)\n",
      "------------test------------\n",
      " (0.46730068842993555, 0.012380635132134133)\n",
      "------------oot------------\n",
      " (0.4540738423753751, 0.022896465436346578)\n",
      "隐藏层vs神经元数vs norm 1 62 0.5\n",
      "验证集最优结果： 6.923733711242676 6.902164459228516\n",
      "------------train------------\n",
      " (0.4860534307385456, 0.00966147086472846)\n",
      "------------test------------\n",
      " (0.4755085498556518, 0.003053519875638462)\n",
      "------------oot------------\n",
      " (0.4812393563410141, 0.01383241233100474)\n",
      "隐藏层vs神经元数vs norm 1 62 0.8\n",
      "验证集最优结果： 10.697607040405273 10.619501113891602\n",
      "------------train------------\n",
      " (0.5373533287446219, 0.06711389682438162)\n",
      "------------test------------\n",
      " (0.5348889629136131, 0.07896957583832998)\n",
      "------------oot------------\n",
      " (0.5712786292704967, 0.13976297223091094)\n",
      "隐藏层vs神经元数vs norm 1 64 0.01\n",
      "验证集最优结果： 0.7181791067123413 0.7129772901535034\n",
      "------------train------------\n",
      " (0.6764144296698766, 0.26049410540094037)\n",
      "------------test------------\n",
      " (0.6438552076393516, 0.20910504108372202)\n",
      "------------oot------------\n",
      " (0.6414821765775784, 0.22996559274319678)\n",
      "隐藏层vs神经元数vs norm 1 64 0.05\n",
      "验证集最优结果： 1.285223364830017 1.2739161252975464\n",
      "------------train------------\n",
      " (0.6111183528827328, 0.1696939302448192)\n",
      "------------test------------\n",
      " (0.5921674439262714, 0.1695536309127249)\n",
      "------------oot------------\n",
      " (0.6234409573790243, 0.18404754457303718)\n",
      "隐藏层vs神经元数vs norm 1 64 0.1\n",
      "验证集最优结果： 1.9513905048370361 1.937016487121582\n",
      "------------train------------\n",
      " (0.5915311880092504, 0.13447306636237694)\n",
      "------------test------------\n",
      " (0.5594570286475682, 0.11880968243393297)\n",
      "------------oot------------\n",
      " (0.5949397004135821, 0.16971466305216698)\n",
      "隐藏层vs神经元数vs norm 1 64 0.2\n",
      "验证集最优结果： 3.2713351249694824 3.2644972801208496\n",
      "------------train------------\n",
      " (0.5633238107420515, 0.10609966978875007)\n",
      "------------test------------\n",
      " (0.5759427048634245, 0.1254163890739507)\n",
      "------------oot------------\n",
      " (0.5960588051298092, 0.17074340527577936)\n",
      "隐藏层vs神经元数vs norm 1 64 0.3\n",
      "验证集最优结果： 4.593835353851318 4.563864231109619\n",
      "------------train------------\n",
      " (0.528893518208318, 0.051590651752677935)\n",
      "------------test------------\n",
      " (0.5226915389740173, 0.05314234954474795)\n",
      "------------oot------------\n",
      " (0.5002583440493982, 0.043540819518298385)\n",
      "隐藏层vs神经元数vs norm 1 64 0.4\n",
      "验证集最优结果： 5.9055938720703125 5.90006160736084\n",
      "------------train------------\n",
      " (0.5332684281091734, 0.06309640557711171)\n",
      "------------test------------\n",
      " (0.500634021763269, 0.04382633799689101)\n",
      "------------oot------------\n",
      " (0.5105052190131951, 0.04066312167657177)\n",
      "隐藏层vs神经元数vs norm 1 64 0.5\n",
      "验证集最优结果： 7.222257137298584 7.191451549530029\n",
      "------------train------------\n",
      " (0.5432780454526074, 0.07619819172285808)\n",
      "------------test------------\n",
      " (0.5338074616922052, 0.0746946480124362)\n",
      "------------oot------------\n",
      " (0.5528933375039099, 0.10782330657213357)\n",
      "隐藏层vs神经元数vs norm 1 64 0.8\n",
      "验证集最优结果： 11.01063060760498 10.98953628540039\n",
      "------------train------------\n",
      " (0.553917358526577, 0.09037203078903505)\n",
      "------------test------------\n",
      " (0.5527803686431269, 0.11337996890961577)\n",
      "------------oot------------\n",
      " (0.574758743729654, 0.11537900114690852)\n",
      "隐藏层vs神经元数vs norm 1 66 0.01\n",
      "验证集最优结果： 0.7250023484230042 0.7203441262245178\n",
      "------------train------------\n",
      " (0.6792541516670626, 0.26535340183913925)\n",
      "------------test------------\n",
      " (0.646426826560071, 0.20974905618476572)\n",
      "------------oot------------\n",
      " (0.6437157520360522, 0.2301880234942481)\n",
      "隐藏层vs神经元数vs norm 1 66 0.05\n",
      "验证集最优结果： 1.3030074834823608 1.2938718795776367\n",
      "------------train------------\n",
      " (0.6028766753364885, 0.1586738488797927)\n",
      "------------test------------\n",
      " (0.5835998223406618, 0.1319564734621363)\n",
      "------------oot------------\n",
      " (0.6158064852465853, 0.18544468772807837)\n",
      "隐藏层vs神经元数vs norm 1 66 0.1\n",
      "验证集最优结果： 1.9989218711853027 1.9871258735656738\n",
      "------------train------------\n",
      " (0.5889412056128468, 0.13246418537852467)\n",
      "------------test------------\n",
      " (0.5666522318454363, 0.12238507661558962)\n",
      "------------oot------------\n",
      " (0.5846430102294975, 0.13313870642616343)\n",
      "隐藏层vs神经元数vs norm 1 66 0.2\n",
      "验证集最优结果： 3.3575243949890137 3.3376212120056152\n",
      "------------train------------\n",
      " (0.5654799636422456, 0.09361851023898521)\n",
      "------------test------------\n",
      " (0.5502465023317789, 0.0846324672440596)\n",
      "------------oot------------\n",
      " (0.5617894090524682, 0.10185243109859937)\n",
      "隐藏层vs神经元数vs norm 1 66 0.3\n",
      "验证集最优结果： 4.6782732009887695 4.66696310043335\n",
      "------------train------------\n",
      " (0.5740325636074581, 0.10860220948482574)\n",
      "------------test------------\n",
      " (0.5591572285143238, 0.09862314012880302)\n",
      "------------oot------------\n",
      " (0.6063960425862208, 0.17919577381573004)\n",
      "隐藏层vs神经元数vs norm 1 66 0.4\n",
      "验证集最优结果： 6.057092666625977 6.011263847351074\n",
      "------------train------------\n",
      " (0.49158682105853047, 0.01397201698229289)\n",
      "------------test------------\n",
      " (0.4998456584499223, 0.029213857428381118)\n",
      "------------oot------------\n",
      " (0.46394073147279274, 0.0089806415736976)\n",
      "隐藏层vs神经元数vs norm 1 66 0.5\n",
      "验证集最优结果： 7.38386344909668 7.3479156494140625\n",
      "------------train------------\n",
      " (0.5165236924372216, 0.043920058962910624)\n",
      "------------test------------\n",
      " (0.5283333333333333, 0.06987563846324674)\n",
      "------------oot------------\n",
      " (0.5294315272419745, 0.07675251103465064)\n",
      "隐藏层vs神经元数vs norm 1 66 0.8\n",
      "验证集最优结果： 11.582127571105957 11.530409812927246\n",
      "------------train------------\n",
      " (0.5082664484659964, 0.030591409093093214)\n",
      "------------test------------\n",
      " (0.5060348656451255, 0.056506773262269605)\n",
      "------------oot------------\n",
      " (0.5244720165896268, 0.061154554617175894)\n",
      "隐藏层vs神经元数vs norm 1 68 0.01\n",
      "验证集最优结果： 0.7342514991760254 0.7306250929832458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " (0.6634940938953218, 0.22311045596765972)\n",
      "------------test------------\n",
      " (0.6498667554963358, 0.22679324894514769)\n",
      "------------oot------------\n",
      " (0.6182358461057242, 0.16885274389184304)\n",
      "隐藏层vs神经元数vs norm 1 68 0.05\n",
      "验证集最优结果： 1.3133299350738525 1.3027199506759644\n",
      "------------train------------\n",
      " (0.6163367599772325, 0.18178308660549736)\n",
      "------------test------------\n",
      " (0.5961447923606484, 0.15765045525205412)\n",
      "------------oot------------\n",
      " (0.6312665809381479, 0.21093386160636707)\n",
      "隐藏层vs神经元数vs norm 1 68 0.1\n",
      "验证集最优结果： 2.0439541339874268 2.0324361324310303\n",
      "------------train------------\n",
      " (0.6024980051287987, 0.1523525267353349)\n",
      "------------test------------\n",
      " (0.5777825893848545, 0.13136797690428603)\n",
      "------------oot------------\n",
      " (0.6224747738041452, 0.19637854933444548)\n",
      "隐藏层vs神经元数vs norm 1 68 0.2\n",
      "验证集最优结果： 3.4275870323181152 3.408886432647705\n",
      "------------train------------\n",
      " (0.5764802824155573, 0.11831295146862453)\n",
      "------------test------------\n",
      " (0.571512325116589, 0.14220519653564295)\n",
      "------------oot------------\n",
      " (0.5774800449495476, 0.11288360615855142)\n",
      "隐藏层vs神经元数vs norm 1 68 0.3\n",
      "验证集最优结果： 4.811759948730469 4.785387992858887\n",
      "------------train------------\n",
      " (0.5307724533836331, 0.05919667771882842)\n",
      "------------test------------\n",
      " (0.5276982011992005, 0.06661114812347324)\n",
      "------------oot------------\n",
      " (0.5373845850855548, 0.06510270044833699)\n",
      "隐藏层vs神经元数vs norm 1 68 0.4\n",
      "验证集最优结果： 6.140038013458252 6.102267265319824\n",
      "------------train------------\n",
      " (0.5326470570319972, 0.0676618349837127)\n",
      "------------test------------\n",
      " (0.5139662447257385, 0.04219409282700415)\n",
      "------------oot------------\n",
      " (0.5240931892167424, 0.05463455322698363)\n",
      "隐藏层vs神经元数vs norm 1 68 0.5\n",
      "验证集最优结果： 7.554921627044678 7.513072490692139\n",
      "------------train------------\n",
      " (0.5306161800128457, 0.05686252613298198)\n",
      "------------test------------\n",
      " (0.5384787919165002, 0.08914057295136579)\n",
      "------------oot------------\n",
      " (0.5333090049699372, 0.08596948528134013)\n",
      "隐藏层vs神经元数vs norm 1 68 0.8\n",
      "验证集最优结果： 11.69832706451416 11.617327690124512\n",
      "------------train------------\n",
      " (0.523463881494837, 0.05066329890446203)\n",
      "------------test------------\n",
      " (0.5337830335332, 0.06852098600932713)\n",
      "------------oot------------\n",
      " (0.5474148217657758, 0.09583289889827268)\n",
      "隐藏层vs神经元数vs norm 1 70 0.01\n",
      "验证集最优结果： 0.7410396933555603 0.7369805574417114\n",
      "------------train------------\n",
      " (0.6636174747333234, 0.2253371315410287)\n",
      "------------test------------\n",
      " (0.645920497446147, 0.2084721296913169)\n",
      "------------oot------------\n",
      " (0.6221318597296076, 0.17558127411114588)\n",
      "隐藏层vs神经元数vs norm 1 70 0.05\n",
      "验证集最优结果： 1.3483914136886597 1.3385765552520752\n",
      "------------train------------\n",
      " (0.6064389501732272, 0.16167884570221158)\n",
      "------------test------------\n",
      " (0.5830113257828116, 0.14579169442593826)\n",
      "------------oot------------\n",
      " (0.6249724857794924, 0.19699718486080697)\n",
      "隐藏层vs神经元数vs norm 1 70 0.1\n",
      "验证集最优结果： 2.0968194007873535 2.0834953784942627\n",
      "------------train------------\n",
      " (0.5928471600411224, 0.13389670255742825)\n",
      "------------test------------\n",
      " (0.5633921829891183, 0.11653342216300244)\n",
      "------------oot------------\n",
      " (0.6049386577694367, 0.17199457825044312)\n",
      "隐藏层vs神经元数vs norm 1 70 0.2\n",
      "验证集最优结果： 3.534973621368408 3.5211172103881836\n",
      "------------train------------\n",
      " (0.5895895810533597, 0.13247393131416496)\n",
      "------------test------------\n",
      " (0.5819875638463248, 0.15409726848767485)\n",
      "------------oot------------\n",
      " (0.5700761130226253, 0.11210509852987172)\n",
      "隐藏层vs神经元数vs norm 1 70 0.3\n",
      "验证集最优结果： 4.9990057945251465 4.974679470062256\n",
      "------------train------------\n",
      " (0.573346964107208, 0.1041656430050239)\n",
      "------------test------------\n",
      " (0.5520763935154341, 0.09156118143459918)\n",
      "------------oot------------\n",
      " (0.5677139447862001, 0.10919264588329336)\n",
      "隐藏层vs神经元数vs norm 1 70 0.4\n",
      "验证集最优结果： 6.294327735900879 6.244677543640137\n",
      "------------train------------\n",
      " (0.5289362243568528, 0.05499455513526208)\n",
      "------------test------------\n",
      " (0.5012136353542083, 0.022207417277370634)\n",
      "------------oot------------\n",
      " (0.5037905907158331, 0.028679664963681184)\n",
      "隐藏层vs神经元数vs norm 1 70 0.5\n",
      "验证集最优结果： 7.806258201599121 7.766093730926514\n",
      "------------train------------\n",
      " (0.5339634351445207, 0.06628941774125757)\n",
      "------------test------------\n",
      " (0.5093371085942705, 0.035176548967355115)\n",
      "------------oot------------\n",
      " (0.5567719737253676, 0.09874535154485109)\n",
      "隐藏层vs神经元数vs norm 1 70 0.8\n",
      "验证集最优结果： 12.221014976501465 12.155397415161133\n",
      "------------train------------\n",
      " (0.47740086725291175, 0.02048365559217047)\n",
      "------------test------------\n",
      " (0.4911492338441039, 0.03202309571396844)\n",
      "------------oot------------\n",
      " (0.4831856254127133, 0.025419664268585218)\n",
      "隐藏层vs神经元数vs norm 1 72 0.01\n",
      "验证集最优结果： 0.7473089098930359 0.743498682975769\n",
      "------------train------------\n",
      " (0.6638240344248104, 0.2262701695183681)\n",
      "------------test------------\n",
      " (0.650515212080835, 0.22631578947368414)\n",
      "------------oot------------\n",
      " (0.6232509644458346, 0.169832829388663)\n",
      "隐藏层vs神经元数vs norm 1 72 0.05\n",
      "验证集最优结果： 1.3639328479766846 1.3519384860992432\n",
      "------------train------------\n",
      " (0.6077893037002746, 0.16852347044646532)\n",
      "------------test------------\n",
      " (0.5818787475016656, 0.1461470131023762)\n",
      "------------oot------------\n",
      " (0.6311820109130087, 0.2179056754596323)\n",
      "隐藏层vs神经元数vs norm 1 72 0.1\n",
      "验证集最优结果： 2.1384899616241455 2.1266636848449707\n",
      "------------train------------\n",
      " (0.6073507365964621, 0.15764429906757121)\n",
      "------------test------------\n",
      " (0.5826737730401954, 0.12349544747945812)\n",
      "------------oot------------\n",
      " (0.6132056673501778, 0.18109338616063675)\n",
      "隐藏层vs神经元数vs norm 1 72 0.2\n",
      "验证集最优结果： 3.616797924041748 3.592360496520996\n",
      "------------train------------\n",
      " (0.5878670546090492, 0.1335273045246183)\n",
      "------------test------------\n",
      " (0.5841772151898734, 0.14355984898956253)\n",
      "------------oot------------\n",
      " (0.6192089806415737, 0.2139575296284711)\n",
      "隐藏层vs神经元数vs norm 1 72 0.3\n",
      "验证集最优结果： 5.080305099487305 5.0652875900268555\n",
      "------------train------------\n",
      " (0.5943088473468383, 0.14681047336144765)\n",
      "------------test------------\n",
      " (0.5782245169886742, 0.1368198978458805)\n",
      "------------oot------------\n",
      " (0.6034036538884834, 0.1482292426928023)\n",
      "隐藏层vs神经元数vs norm 1 72 0.4\n",
      "验证集最优结果： 6.484154224395752 6.448739051818848\n",
      "------------train------------\n",
      " (0.5534543589035552, 0.08327631284182685)\n",
      "------------test------------\n",
      " (0.5435498556517877, 0.0790361980901621)\n",
      "------------oot------------\n",
      " (0.5817965917121375, 0.15755743231501762)\n",
      "隐藏层vs神经元数vs norm 1 72 0.5\n",
      "验证集最优结果： 7.999316215515137 7.938077449798584\n",
      "------------train------------\n",
      " (0.5265498914072657, 0.0548080287559245)\n",
      "------------test------------\n",
      " (0.5074727959138352, 0.03796357983566512)\n",
      "------------oot------------\n",
      " (0.5157230737149411, 0.03733361137177216)\n",
      "隐藏层vs神经元数vs norm 1 72 0.8\n",
      "验证集最优结果： 12.353239059448242 12.30189323425293\n",
      "------------train------------\n",
      " (0.46844854856623075, 0.0031912524813220156)\n",
      "------------test------------\n",
      " (0.47010770597379525, 0.008394403730846102)\n",
      "------------oot------------\n",
      " (0.47008306398359573, 0.00103569318458277)\n",
      "隐藏层vs神经元数vs norm 1 74 0.01\n",
      "验证集最优结果： 0.7521610856056213 0.7751221656799316\n",
      "------------train------------\n",
      " (0.6687350384659897, 0.25125536449460895)\n",
      "------------test------------\n",
      " (0.6464667999111704, 0.21252498334443704)\n",
      "------------oot------------\n",
      " (0.6367149758454107, 0.21177492788377988)\n",
      "隐藏层vs神经元数vs norm 1 74 0.05\n",
      "验证集最优结果： 1.3934270143508911 1.3847252130508423\n",
      "------------train------------\n",
      " (0.6051050429125728, 0.1612601765503313)\n",
      "------------test------------\n",
      " (0.5868865200977127, 0.1433932933599822)\n",
      "------------oot------------\n",
      " (0.6254289322165456, 0.18709901643902266)\n",
      "隐藏层vs神经元数vs norm 1 74 0.1\n",
      "验证集最优结果： 2.168846845626831 2.152963161468506\n",
      "------------train------------\n",
      " (0.5992340642108263, 0.15151207514657816)\n",
      "------------test------------\n",
      " (0.5784043970686209, 0.1343437708194537)\n",
      "------------oot------------\n",
      " (0.6082867039701572, 0.16596809508914612)\n",
      "隐藏层vs神经元数vs norm 1 74 0.2\n",
      "验证集最优结果： 3.6984243392944336 3.6853795051574707\n",
      "------------train------------\n",
      " (0.5630056465514615, 0.09564011508325676)\n",
      "------------test------------\n",
      " (0.5631734399289363, 0.10671774372640452)\n",
      "------------oot------------\n",
      " (0.5590901192089807, 0.10619678170507069)\n",
      "隐藏层vs神经元数vs norm 1 74 0.3\n",
      "验证集最优结果： 5.182314395904541 5.145675182342529\n",
      "------------train------------\n",
      " (0.6051189850149472, 0.1543132194818546)\n",
      "------------test------------\n",
      " (0.5963046857650456, 0.1517432822562736)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.5961758129728101, 0.14767316581517398)\n",
      "隐藏层vs神经元数vs norm 1 74 0.4\n",
      "验证集最优结果： 6.747620582580566 6.700944900512695\n",
      "------------train------------\n",
      " (0.534795900480461, 0.07193380343936784)\n",
      "------------test------------\n",
      " (0.5459904508105707, 0.08949589162780369)\n",
      "------------oot------------\n",
      " (0.5588665299644342, 0.12554825704653672)\n",
      "隐藏层vs神经元数vs norm 1 74 0.5\n",
      "验证集最优结果： 8.204301834106445 8.175688743591309\n",
      "------------train------------\n",
      " (0.5225749032682048, 0.04098396049105979)\n",
      "------------test------------\n",
      " (0.5043892960248723, 0.027948034643570957)\n",
      "------------oot------------\n",
      " (0.5164807284607097, 0.05222256977027073)\n",
      "隐藏层vs神经元数vs norm 1 74 0.8\n",
      "验证集最优结果： 12.65319538116455 12.563420295715332\n",
      "------------train------------\n",
      " (0.5525760064539751, 0.08835502819214924)\n",
      "------------test------------\n",
      " (0.5733144570286476, 0.12841439040639568)\n",
      "------------oot------------\n",
      " (0.57870573106732, 0.12700795885031102)\n",
      "隐藏层vs神经元数vs norm 1 76 0.01\n",
      "验证集最优结果： 0.750947117805481 0.7466071844100952\n",
      "------------train------------\n",
      " (0.659907724939917, 0.21779797352218794)\n",
      "------------test------------\n",
      " (0.6457894736842105, 0.21923162336220303)\n",
      "------------oot------------\n",
      " (0.6172221642975475, 0.16826191220936293)\n",
      "隐藏层vs神经元数vs norm 1 76 0.05\n",
      "验证集最优结果： 1.405308723449707 1.3954931497573853\n",
      "------------train------------\n",
      " (0.6179811835762034, 0.18071211656680464)\n",
      "------------test------------\n",
      " (0.5805163224516988, 0.1337774816788807)\n",
      "------------oot------------\n",
      " (0.6163625621242137, 0.16957564383275991)\n",
      "隐藏层vs神经元数vs norm 1 76 0.1\n",
      "验证集最优结果： 2.1940083503723145 2.1794047355651855\n",
      "------------train------------\n",
      " (0.5978252350699372, 0.14950414168424653)\n",
      "------------test------------\n",
      " (0.5961025982678214, 0.14906728847435044)\n",
      "------------oot------------\n",
      " (0.5988890047382385, 0.1743231501755118)\n",
      "隐藏层vs神经元数vs norm 1 76 0.2\n",
      "验证集最优结果： 3.800696849822998 3.776808500289917\n",
      "------------train------------\n",
      " (0.6005046228898188, 0.14914448958707688)\n",
      "------------test------------\n",
      " (0.5695047745947146, 0.1119475904952254)\n",
      "------------oot------------\n",
      " (0.6024444212745745, 0.1527195634796511)\n",
      "隐藏层vs神经元数vs norm 1 76 0.3\n",
      "验证集最优结果： 5.262180328369141 5.238960266113281\n",
      "------------train------------\n",
      " (0.5672466851974804, 0.10359306928615764)\n",
      "------------test------------\n",
      " (0.5263768598711969, 0.06778814123917387)\n",
      "------------oot------------\n",
      " (0.5193804376788425, 0.0614742988218121)\n",
      "隐藏层vs神经元数vs norm 1 76 0.4\n",
      "验证集最优结果： 6.855003833770752 6.824788570404053\n",
      "------------train------------\n",
      " (0.5524170258788431, 0.0919187919912774)\n",
      "------------test------------\n",
      " (0.547685987119698, 0.08157894736842103)\n",
      "------------oot------------\n",
      " (0.5587842769262851, 0.10049004274841)\n",
      "隐藏层vs神经元数vs norm 1 76 0.5\n",
      "验证集最优结果： 8.451358795166016 8.41431999206543\n",
      "------------train------------\n",
      " (0.5162103335343433, 0.03747285181643256)\n",
      "------------test------------\n",
      " (0.49558405507439485, 0.028147901399067254)\n",
      "------------oot------------\n",
      " (0.5195043964828138, 0.05049873144962291)\n",
      "隐藏层vs神经元数vs norm 1 76 0.8\n",
      "验证集最优结果： 13.067047119140625 12.955965042114258\n",
      "------------train------------\n",
      " (0.499409355692134, 0.011270497766894816)\n",
      "------------test------------\n",
      " (0.49619142793693094, 0.035021097046413485)\n",
      "------------oot------------\n",
      " (0.4609321238661245, 0.0028637959197859164)\n",
      "隐藏层vs神经元数vs norm 1 78 0.01\n",
      "验证集最优结果： 0.7609596848487854 0.7824723124504089\n",
      "------------train------------\n",
      " (0.6688363555885835, 0.25109970024479894)\n",
      "------------test------------\n",
      " (0.6411903175660671, 0.21516766600044415)\n",
      "------------oot------------\n",
      " (0.6355576408438466, 0.20357279393876204)\n",
      "隐藏层vs神经元数vs norm 1 78 0.05\n",
      "验证集最优结果： 1.4334872961044312 1.4237215518951416\n",
      "------------train------------\n",
      " (0.6119507505385644, 0.16340414703097517)\n",
      "------------test------------\n",
      " (0.5799011769931157, 0.1269264934488119)\n",
      "------------oot------------\n",
      " (0.6117355391049479, 0.16358391547631462)\n",
      "隐藏层vs神经元数vs norm 1 78 0.1\n",
      "验证集最优结果： 2.2379655838012695 2.22550892829895\n",
      "------------train------------\n",
      " (0.5873111301969018, 0.12243318112076906)\n",
      "------------test------------\n",
      " (0.5585931601154785, 0.09891183655340885)\n",
      "------------oot------------\n",
      " (0.5902756056024745, 0.1495499252771696)\n",
      "隐藏层vs神经元数vs norm 1 78 0.2\n",
      "验证集最优结果： 3.841326951980591 3.817328691482544\n",
      "------------train------------\n",
      " (0.5857195647627575, 0.11628796261892249)\n",
      "------------test------------\n",
      " (0.5888107928047968, 0.13981789917832554)\n",
      "------------oot------------\n",
      " (0.5995991612507096, 0.14772877350293673)\n",
      "隐藏层vs神经元数vs norm 1 78 0.3\n",
      "验证集最优结果： 5.439607620239258 5.420601844787598\n",
      "------------train------------\n",
      " (0.5317073864040137, 0.052898772891950774)\n",
      "------------test------------\n",
      " (0.5307317343992893, 0.06492338441039314)\n",
      "------------oot------------\n",
      " (0.5794367404627023, 0.1445521843394849)\n",
      "隐藏层vs神经元数vs norm 1 78 0.4\n",
      "验证集最优结果： 6.985670566558838 6.94287633895874\n",
      "------------train------------\n",
      " (0.5563645358938072, 0.08086933745911279)\n",
      "------------test------------\n",
      " (0.5457439484787919, 0.09301576726626692)\n",
      "------------oot------------\n",
      " (0.5667130064064689, 0.11282104750981825)\n",
      "隐藏层vs神经元数vs norm 1 78 0.5\n",
      "验证集最优结果： 8.549338340759277 8.50739860534668\n",
      "------------train------------\n",
      " (0.5272255419315497, 0.062195583331472126)\n",
      "------------test------------\n",
      " (0.55172218520986, 0.10927159671330222)\n",
      "------------oot------------\n",
      " (0.5271110647713713, 0.060737496958954584)\n",
      "隐藏层vs神经元数vs norm 1 78 0.8\n",
      "验证集最优结果： 13.246580123901367 13.128201484680176\n",
      "------------train------------\n",
      " (0.49365729094122046, 0.009441781232170432)\n",
      "------------test------------\n",
      " (0.49062069731290253, 0.018010215411947583)\n",
      "------------oot------------\n",
      " (0.492384063763482, 0.028846488026969763)\n",
      "隐藏层vs神经元数vs norm 1 80 0.01\n",
      "验证集最优结果： 0.766204297542572 0.7764365077018738\n",
      "------------train------------\n",
      " (0.6633567032748373, 0.24044319642324163)\n",
      "------------test------------\n",
      " (0.642576060404175, 0.2184987785920497)\n",
      "------------oot------------\n",
      " (0.6282533393574995, 0.18420741667535537)\n",
      "隐藏层vs神经元数vs norm 1 80 0.05\n",
      "验证集最优结果： 1.461883544921875 1.449851155281067\n",
      "------------train------------\n",
      " (0.6042157939655062, 0.15438793832176345)\n",
      "------------test------------\n",
      " (0.5939273817455031, 0.15819453697534974)\n",
      "------------oot------------\n",
      " (0.6220357047695177, 0.18382511382198585)\n",
      "隐藏层vs神经元数vs norm 1 80 0.1\n",
      "验证集最优结果： 2.2917962074279785 2.2807130813598633\n",
      "------------train------------\n",
      " (0.573189201774031, 0.11279539829405516)\n",
      "------------test------------\n",
      " (0.5492827004219409, 0.10204308238951809)\n",
      "------------oot------------\n",
      " (0.5767953752939677, 0.11610885204879573)\n",
      "隐藏层vs神经元数vs norm 1 80 0.2\n",
      "验证集最优结果： 3.971811056137085 3.970010280609131\n",
      "------------train------------\n",
      " (0.5698365322336669, 0.10913322761700361)\n",
      "------------test------------\n",
      " (0.5415256495669554, 0.08870752831445705)\n",
      "------------oot------------\n",
      " (0.5374958004610805, 0.08874291870851148)\n",
      "隐藏层vs神经元数vs norm 1 80 0.3\n",
      "验证集最优结果： 5.521165370941162 5.487940311431885\n",
      "------------train------------\n",
      " (0.5109742619314955, 0.038853119951486936)\n",
      "------------test------------\n",
      " (0.5298656451254719, 0.0696646679991117)\n",
      "------------oot------------\n",
      " (0.5054692477901737, 0.04377715219129047)\n",
      "隐藏层vs神经元数vs norm 1 80 0.4\n",
      "验证集最优结果： 7.194151401519775 7.1588006019592285\n",
      "------------train------------\n",
      " (0.5280117817533073, 0.05805856901239159)\n",
      "------------test------------\n",
      " (0.5285232067510548, 0.06593382189651348)\n",
      "------------oot------------\n",
      " (0.533112061075777, 0.0616063670802488)\n",
      "隐藏层vs神经元数vs norm 1 80 0.5\n",
      "验证集最优结果： 8.771675109863281 8.710766792297363\n",
      "------------train------------\n",
      " (0.4833266668426349, 0.0077589830116159275)\n",
      "------------test------------\n",
      " (0.48722074172773705, 0.02707084166111484)\n",
      "------------oot------------\n",
      " (0.4639963391605556, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 1 80 0.8\n",
      "验证集最优结果： 13.700023651123047 13.639958381652832\n",
      "------------train------------\n",
      " (0.519900794496795, 0.04218392881676891)\n",
      "------------test------------\n",
      " (0.5168620919387075, 0.05746169220519648)\n",
      "------------oot------------\n",
      " (0.5522955548604594, 0.11044381885795712)\n",
      "隐藏层vs神经元数vs norm 1 82 0.01\n",
      "验证集最优结果： 0.7693542838096619 0.8255191445350647\n",
      "------------train------------\n",
      " (0.6657611068134243, 0.24656959985489385)\n",
      "------------test------------\n",
      " (0.6362025316455696, 0.21248056850988234)\n",
      "------------oot------------\n",
      " (0.6232324285499138, 0.19469641677961977)\n",
      "隐藏层vs神经元数vs norm 1 82 0.05\n",
      "验证集最优结果： 1.480281114578247 1.4696029424667358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " (0.6053962704199347, 0.15759611083023867)\n",
      "------------test------------\n",
      " (0.58320897179658, 0.1404286031534533)\n",
      "------------oot------------\n",
      " (0.6021559563943049, 0.15114864630035107)\n",
      "隐藏层vs神经元数vs norm 1 82 0.1\n",
      "验证集最优结果： 2.3198933601379395 2.305149793624878\n",
      "------------train------------\n",
      " (0.6088701550348248, 0.16045911478478742)\n",
      "------------test------------\n",
      " (0.602483899622474, 0.15256495669553638)\n",
      "------------oot------------\n",
      " (0.6214379221260673, 0.20528273033746913)\n",
      "隐藏层vs神经元数vs norm 1 82 0.2\n",
      "验证集最优结果： 4.006129741668701 3.9959449768066406\n",
      "------------train------------\n",
      " (0.5846104231428071, 0.11722600892429902)\n",
      "------------test------------\n",
      " (0.5824950033311126, 0.13896291361314683)\n",
      "------------oot------------\n",
      " (0.5734589140281978, 0.10833072672296945)\n",
      "隐藏层vs神经元数vs norm 1 82 0.3\n",
      "验证集最优结果： 5.665934085845947 5.622910022735596\n",
      "------------train------------\n",
      " (0.5000393898232127, 0.024105488924488716)\n",
      "------------test------------\n",
      " (0.5014168332222964, 0.03353320008882965)\n",
      "------------oot------------\n",
      " (0.4967921315121815, 0.04272060612379658)\n",
      "隐藏层vs神经元数vs norm 1 82 0.4\n",
      "验证集最优结果： 7.362627983093262 7.3148016929626465\n",
      "------------train------------\n",
      " (0.5363998513744815, 0.06750887793824722)\n",
      "------------test------------\n",
      " (0.5402564956695537, 0.09182767044192763)\n",
      "------------oot------------\n",
      " (0.542748409967678, 0.08594863239842898)\n",
      "隐藏层vs神经元数vs norm 1 82 0.5\n",
      "验证集最优结果： 9.068233489990234 9.035688400268555\n",
      "------------train------------\n",
      " (0.4907744567148481, 0.002552893696883829)\n",
      "------------test------------\n",
      " (0.5037952476127027, 0.05298689762380637)\n",
      "------------oot------------\n",
      " (0.5258158690438954, 0.06430333993674625)\n",
      "隐藏层vs神经元数vs norm 1 82 0.8\n",
      "验证集最优结果： 13.869608879089355 13.76990032196045\n",
      "------------train------------\n",
      " (0.5132855376406309, 0.036956587947932384)\n",
      "------------test------------\n",
      " (0.5200877192982456, 0.04842327337330665)\n",
      "------------oot------------\n",
      " (0.5044625169429673, 0.046536683696521086)\n",
      "隐藏层vs神经元数vs norm 1 84 0.01\n",
      "验证集最优结果： 0.7733615636825562 0.7697592973709106\n",
      "------------train------------\n",
      " (0.6594240152036597, 0.21828175093855384)\n",
      "------------test------------\n",
      " (0.6439840106595602, 0.21534532533866307)\n",
      "------------oot------------\n",
      " (0.619902918245114, 0.16635734890348586)\n",
      "隐藏层vs神经元数vs norm 1 84 0.05\n",
      "验证集最优结果： 1.4946558475494385 1.4855444431304932\n",
      "------------train------------\n",
      " (0.614795074783136, 0.17061031891543976)\n",
      "------------test------------\n",
      " (0.5925827226293582, 0.15084388185654013)\n",
      "------------oot------------\n",
      " (0.6241186760736338, 0.184318632050881)\n",
      "隐藏层vs神经元数vs norm 1 84 0.1\n",
      "验证集最优结果： 2.4012176990509033 2.38545560836792\n",
      "------------train------------\n",
      " (0.6051547201122949, 0.15719206058181878)\n",
      "------------test------------\n",
      " (0.5771274705751721, 0.1286475682878081)\n",
      "------------oot------------\n",
      " (0.6089470452623409, 0.15975393598164944)\n",
      "隐藏层vs神经元数vs norm 1 84 0.2\n",
      "验证集最优结果： 4.133676528930664 4.119964599609375\n",
      "------------train------------\n",
      " (0.5995824137298575, 0.14826072272880786)\n",
      "------------test------------\n",
      " (0.5807428381079281, 0.1279369309349322)\n",
      "------------oot------------\n",
      " (0.6270357626941925, 0.20061168456539114)\n",
      "隐藏层vs神经元数vs norm 1 84 0.3\n",
      "验证集最优结果： 5.838930130004883 5.81464958190918\n",
      "------------train------------\n",
      " (0.5718395250480698, 0.10982667800985291)\n",
      "------------test------------\n",
      " (0.5349655785032201, 0.08231179213857431)\n",
      "------------oot------------\n",
      " (0.5561475457315308, 0.08632398429082822)\n",
      "隐藏层vs神经元数vs norm 1 84 0.4\n",
      "验证集最优结果： 7.486390113830566 7.4535746574401855\n",
      "------------train------------\n",
      " (0.5598551374955246, 0.08602006444499943)\n",
      "------------test------------\n",
      " (0.5373584277148568, 0.08202309571396849)\n",
      "------------oot------------\n",
      " (0.5776596114412818, 0.12838424912244117)\n",
      "隐藏层vs神经元数vs norm 1 84 0.5\n",
      "验证集最优结果： 9.138176918029785 9.095540046691895\n",
      "------------train------------\n",
      " (0.514437588449442, 0.04455936526886939)\n",
      "------------test------------\n",
      " (0.4883755274261603, 0.015967133022429497)\n",
      "------------oot------------\n",
      " (0.5146143954401696, 0.05840892503388595)\n",
      "隐藏层vs神经元数vs norm 1 84 0.8\n",
      "验证集最优结果： 14.343890190124512 14.273764610290527\n",
      "------------train------------\n",
      " (0.4408354026526542, 0.0003852351782254182)\n",
      "------------test------------\n",
      " (0.4400566289140573, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.4375931139146654, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 1 86 0.01\n",
      "验证集最优结果： 0.7822248339653015 0.7792750597000122\n",
      "------------train------------\n",
      " (0.6566776240762511, 0.2137012965478407)\n",
      "------------test------------\n",
      " (0.6385187652675994, 0.20208749722407288)\n",
      "------------oot------------\n",
      " (0.6204404592268213, 0.1724811455183679)\n",
      "隐藏层vs神经元数vs norm 1 86 0.05\n",
      "验证集最优结果： 1.5095348358154297 1.499534010887146\n",
      "------------train------------\n",
      " (0.605621509821399, 0.15514460193605717)\n",
      "------------test------------\n",
      " (0.5803808572063069, 0.12568287808127915)\n",
      "------------oot------------\n",
      " (0.6137559517603308, 0.16453619712925313)\n",
      "隐藏层vs神经元数vs norm 1 86 0.1\n",
      "验证集最优结果： 2.413353204727173 2.4000396728515625\n",
      "------------train------------\n",
      " (0.6133505105448993, 0.1713068825932852)\n",
      "------------test------------\n",
      " (0.5873117921385743, 0.15803908505440817)\n",
      "------------oot------------\n",
      " (0.6085079762277135, 0.16507142112397033)\n",
      "隐藏层vs神经元数vs norm 1 86 0.2\n",
      "验证集最优结果： 4.207949161529541 4.188577175140381\n",
      "------------train------------\n",
      " (0.548943682704822, 0.08500310313297998)\n",
      "------------test------------\n",
      " (0.5489784588052409, 0.08185654008438814)\n",
      "------------oot------------\n",
      " (0.5489903729190561, 0.07580022938171205)\n",
      "隐藏层vs神经元数vs norm 1 86 0.3\n",
      "验证集最优结果： 5.99198055267334 5.961736679077148\n",
      "------------train------------\n",
      " (0.5473570579186066, 0.0769499823693317)\n",
      "------------test------------\n",
      " (0.5179491450144349, 0.05370863868532094)\n",
      "------------oot------------\n",
      " (0.5621068362701144, 0.10549473464706499)\n",
      "隐藏层vs神经元数vs norm 1 86 0.4\n",
      "验证集最优结果： 7.683928489685059 7.667855739593506\n",
      "------------train------------\n",
      " (0.5511610184232023, 0.0806791563539101)\n",
      "------------test------------\n",
      " (0.5681823228958472, 0.10689540306462358)\n",
      "------------oot------------\n",
      " (0.581608915765938, 0.14233482778994194)\n",
      "隐藏层vs神经元数vs norm 1 86 0.5\n",
      "验证集最优结果： 9.35315990447998 9.308481216430664\n",
      "------------train------------\n",
      " (0.467873944444106, 0.0029124104338362645)\n",
      "------------test------------\n",
      " (0.5018776371308017, 0.036153675327559365)\n",
      "------------oot------------\n",
      " (0.45337527079785445, 0.0)\n",
      "隐藏层vs神经元数vs norm 1 86 0.8\n",
      "验证集最优结果： 14.38683032989502 14.358680725097656\n",
      "------------train------------\n",
      " (0.5316837660461078, 0.07912021273211733)\n",
      "------------test------------\n",
      " (0.5452409504774594, 0.08920719520319786)\n",
      "------------oot------------\n",
      " (0.5319987488270252, 0.07627984568866641)\n",
      "隐藏层vs神经元数vs norm 1 88 0.01\n",
      "验证集最优结果： 0.7790703773498535 0.7888494729995728\n",
      "------------train------------\n",
      " (0.6584725682367776, 0.23508645118673685)\n",
      "------------test------------\n",
      " (0.6362869198312235, 0.20165445258716413)\n",
      "------------oot------------\n",
      " (0.6301741215723073, 0.19035206617314843)\n",
      "隐藏层vs神经元数vs norm 1 88 0.05\n",
      "验证集最优结果： 1.5211800336837769 1.510276198387146\n",
      "------------train------------\n",
      " (0.613937703167226, 0.17168616192195263)\n",
      "------------test------------\n",
      " (0.5871163668665333, 0.15260937153009113)\n",
      "------------oot------------\n",
      " (0.6177006221110068, 0.1752337260626281)\n",
      "隐藏层vs神经元数vs norm 1 88 0.1\n",
      "验证集最优结果： 2.458063840866089 2.4462032318115234\n",
      "------------train------------\n",
      " (0.5891533827533486, 0.12610929390019487)\n",
      "------------test------------\n",
      " (0.5706173662003109, 0.12673773040195424)\n",
      "------------oot------------\n",
      " (0.5977791679699718, 0.15319917978660552)\n",
      "隐藏层vs神经元数vs norm 1 88 0.2\n",
      "验证集最优结果： 4.23128604888916 4.209268093109131\n",
      "------------train------------\n",
      " (0.5470480305426795, 0.08111136152751297)\n",
      "------------test------------\n",
      " (0.5368132356206974, 0.07449478125693987)\n",
      "------------oot------------\n",
      " (0.550912313627359, 0.1007472283043131)\n",
      "隐藏层vs神经元数vs norm 1 88 0.3\n",
      "验证集最优结果： 6.0121331214904785 5.975875377655029\n",
      "------------train------------\n",
      " (0.5745538358039957, 0.12148051591193199)\n",
      "------------test------------\n",
      " (0.5666400177659339, 0.1119475904952254)\n",
      "------------oot------------\n",
      " (0.5514000393887788, 0.09132172522851284)\n",
      "隐藏层vs神经元数vs norm 1 88 0.4\n",
      "验证集最优结果： 7.851800441741943 7.800502777099609\n",
      "------------train------------\n",
      " (0.5485208173862077, 0.07947607474320478)\n",
      "------------test------------\n",
      " (0.5268254497001998, 0.0618032422829225)\n",
      "------------oot------------\n",
      " (0.5286773479766911, 0.07077468460014597)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 1 88 0.5\n",
      "验证集最优结果： 9.552407264709473 9.511798858642578\n",
      "------------train------------\n",
      " (0.4664295155660866, 0.0013360053440213762)\n",
      "------------test------------\n",
      " (0.4717177437264046, 0.011669997779258257)\n",
      "------------oot------------\n",
      " (0.4304776468680128, 0.005192367844854551)\n",
      "隐藏层vs神经元数vs norm 1 88 0.8\n",
      "验证集最优结果： 14.975366592407227 14.867401123046875\n",
      "------------train------------\n",
      " (0.5018292579755932, 0.021743994574762504)\n",
      "------------test------------\n",
      " (0.49859093937375076, 0.03498778592049745)\n",
      "------------oot------------\n",
      " (0.5073077769668323, 0.030236680221040563)\n",
      "隐藏层vs神经元数vs norm 1 90 0.01\n",
      "验证集最优结果： 0.7856626510620117 0.7814663052558899\n",
      "------------train------------\n",
      " (0.6603131964706177, 0.21701071849880105)\n",
      "------------test------------\n",
      " (0.6436442371752165, 0.20451920941594492)\n",
      "------------oot------------\n",
      " (0.61972335175338, 0.16864421506273242)\n",
      "隐藏层vs神经元数vs norm 1 90 0.05\n",
      "验证集最优结果： 1.5590448379516602 1.5486067533493042\n",
      "------------train------------\n",
      " (0.6112704300867862, 0.16420615631803964)\n",
      "------------test------------\n",
      " (0.588327781479014, 0.14747945813901842)\n",
      "------------oot------------\n",
      " (0.6120043095958017, 0.16600284989399794)\n",
      "隐藏层vs神经元数vs norm 1 90 0.1\n",
      "验证集最优结果： 2.5022754669189453 2.489922046661377\n",
      "------------train------------\n",
      " (0.6050535383499184, 0.1644435781390542)\n",
      "------------test------------\n",
      " (0.5824372640461914, 0.12968021319120582)\n",
      "------------oot------------\n",
      " (0.6076194117170032, 0.16959649671567095)\n",
      "隐藏层vs神经元数vs norm 1 90 0.2\n",
      "验证集最优结果： 4.3728742599487305 4.353192329406738\n",
      "------------train------------\n",
      " (0.5874695016510563, 0.1307892380505692)\n",
      "------------test------------\n",
      " (0.5645725072174106, 0.10485232067510553)\n",
      "------------oot------------\n",
      " (0.6015940870492011, 0.1682897160532444)\n",
      "隐藏层vs神经元数vs norm 1 90 0.3\n",
      "验证集最优结果： 6.249479293823242 6.205906391143799\n",
      "------------train------------\n",
      " (0.5700206898092031, 0.11512562443360214)\n",
      "------------test------------\n",
      " (0.5632356206973129, 0.11463468798578735)\n",
      "------------oot------------\n",
      " (0.5851261020169372, 0.15287248462099887)\n",
      "隐藏层vs神经元数vs norm 1 90 0.4\n",
      "验证集最优结果： 7.968481540679932 7.93591833114624\n",
      "------------train------------\n",
      " (0.5579374216179742, 0.08850270618914291)\n",
      "------------test------------\n",
      " (0.5746602265156562, 0.12848101265822787)\n",
      "------------oot------------\n",
      " (0.5565877732596531, 0.10556424425676847)\n",
      "隐藏层vs神经元数vs norm 1 90 0.5\n",
      "验证集最优结果： 9.729583740234375 9.674079895019531\n",
      "------------train------------\n",
      " (0.5155660189003471, 0.03226567961996263)\n",
      "------------test------------\n",
      " (0.49059404841216964, 0.024172773706418016)\n",
      "------------oot------------\n",
      " (0.5247998702487285, 0.06294095158655688)\n",
      "隐藏层vs神经元数vs norm 1 90 0.8\n",
      "验证集最优结果： 15.231809616088867 15.122503280639648\n",
      "------------train------------\n",
      " (0.43332879876605623, 0.0011557055346762546)\n",
      "------------test------------\n",
      " (0.4316178103486565, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4149457245797565, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 1 92 0.01\n",
      "验证集最优结果： 0.7893213033676147 0.7857885360717773\n",
      "------------train------------\n",
      " (0.6563528949151258, 0.21085088109349392)\n",
      "------------test------------\n",
      " (0.641621141461248, 0.20737286253608705)\n",
      "------------oot------------\n",
      " (0.6141915453144731, 0.15999721961561184)\n",
      "隐藏层vs神经元数vs norm 1 92 0.05\n",
      "验证集最优结果： 1.5792007446289062 1.5685144662857056\n",
      "------------train------------\n",
      " (0.6077911310632071, 0.1643489613472131)\n",
      "------------test------------\n",
      " (0.5718498778592049, 0.12881412391738833)\n",
      "------------oot------------\n",
      " (0.6046339739802362, 0.17093108122197886)\n",
      "隐藏层vs神经元数vs norm 1 92 0.1\n",
      "验证集最优结果： 2.56551456451416 2.5515167713165283\n",
      "------------train------------\n",
      " (0.5970607882431529, 0.14631870969226535)\n",
      "------------test------------\n",
      " (0.5828603153453253, 0.1438707528314458)\n",
      "------------oot------------\n",
      " (0.6163069544364508, 0.17705487783686097)\n",
      "隐藏层vs神经元数vs norm 1 92 0.2\n",
      "验证集最优结果： 4.407721519470215 4.38229513168335\n",
      "------------train------------\n",
      " (0.5698041134616412, 0.10793217640955677)\n",
      "------------test------------\n",
      " (0.5819864534754609, 0.14032866977570513)\n",
      "------------oot------------\n",
      " (0.6070413234629688, 0.16924199770618292)\n",
      "隐藏层vs神经元数vs norm 1 92 0.3\n",
      "验证集最优结果： 6.262575149536133 6.228368759155273\n",
      "------------train------------\n",
      " (0.5680382717478185, 0.09677727626817295)\n",
      "------------test------------\n",
      " (0.5607828114590273, 0.09883411059293812)\n",
      "------------oot------------\n",
      " (0.5661024803345729, 0.10049699370938026)\n",
      "隐藏层vs神经元数vs norm 1 92 0.4\n",
      "验证集最优结果： 8.211962699890137 8.186652183532715\n",
      "------------train------------\n",
      " (0.5325572455278677, 0.059481340255654824)\n",
      "------------test------------\n",
      " (0.5007528314457028, 0.04598045747279589)\n",
      "------------oot------------\n",
      " (0.52757562066289, 0.05654606749383101)\n",
      "隐藏层vs神经元数vs norm 1 92 0.5\n",
      "验证集最优结果： 9.86733341217041 9.819019317626953\n",
      "------------train------------\n",
      " (0.5236812023235935, 0.05157968757508263)\n",
      "------------test------------\n",
      " (0.5239795691761049, 0.062014212747057484)\n",
      "------------oot------------\n",
      " (0.5262028058712451, 0.06363604768359232)\n",
      "隐藏层vs神经元数vs norm 1 92 0.8\n",
      "验证集最优结果： 15.675935745239258 15.580458641052246\n",
      "------------train------------\n",
      " (0.48370026104217895, 0.011565989121099407)\n",
      "------------test------------\n",
      " (0.46895403064623586, 0.019165001110370866)\n",
      "------------oot------------\n",
      " (0.4877663086921767, 0.02414763841101042)\n",
      "隐藏层vs神经元数vs norm 1 94 0.01\n",
      "验证集最优结果： 0.7949918508529663 0.7911285758018494\n",
      "------------train------------\n",
      " (0.6574829496886376, 0.21282538058217076)\n",
      "------------test------------\n",
      " (0.6423184543637575, 0.21173662003109045)\n",
      "------------oot------------\n",
      " (0.6151669968373128, 0.165829075869739)\n",
      "隐藏层vs神经元数vs norm 1 94 0.05\n",
      "验证集最优结果： 1.6043726205825806 1.5922443866729736\n",
      "------------train------------\n",
      " (0.6067380285731883, 0.16167397273439144)\n",
      "------------test------------\n",
      " (0.5814856762158561, 0.1249722407284033)\n",
      "------------oot------------\n",
      " (0.6056210104380264, 0.1623813992284434)\n",
      "隐藏层vs神经元数vs norm 1 94 0.1\n",
      "验证集最优结果： 2.571634531021118 2.559039354324341\n",
      "------------train------------\n",
      " (0.5694899423974595, 0.10663637305005147)\n",
      "------------test------------\n",
      " (0.5427714856762158, 0.0759937819231623)\n",
      "------------oot------------\n",
      " (0.5676282162675657, 0.12217009001494461)\n",
      "隐藏层vs神经元数vs norm 1 94 0.2\n",
      "验证集最优结果： 4.528130054473877 4.5156779289245605\n",
      "------------train------------\n",
      " (0.5887931892153101, 0.1319753996341213)\n",
      "------------test------------\n",
      " (0.5752764823451033, 0.12576060404174988)\n",
      "------------oot------------\n",
      " (0.5983271353931348, 0.15285858269905817)\n",
      "隐藏层vs神经元数vs norm 1 94 0.3\n",
      "验证集最优结果： 6.396073341369629 6.355523586273193\n",
      "------------train------------\n",
      " (0.5399003342720564, 0.06149983181493013)\n",
      "------------test------------\n",
      " (0.5274383744170552, 0.06140350877192979)\n",
      "------------oot------------\n",
      " (0.5582791737624393, 0.10043443506064709)\n",
      "隐藏层vs神经元数vs norm 1 94 0.4\n",
      "验证集最优结果： 8.337177276611328 8.29476547241211\n",
      "------------train------------\n",
      " (0.5652440307836206, 0.10646324733221935)\n",
      "------------test------------\n",
      " (0.5541694425938264, 0.09719076171441265)\n",
      "------------oot------------\n",
      " (0.5640009731345359, 0.10021200430959576)\n",
      "隐藏层vs神经元数vs norm 1 94 0.5\n",
      "验证集最优结果： 10.37583065032959 10.34002685546875\n",
      "------------train------------\n",
      " (0.5219405376101748, 0.04264807900163714)\n",
      "------------test------------\n",
      " (0.5179924494781257, 0.0455474128358872)\n",
      "------------oot------------\n",
      " (0.5525898122082045, 0.10519584332533971)\n",
      "隐藏层vs神经元数vs norm 1 94 0.8\n",
      "验证集最优结果： 15.798604965209961 15.724783897399902\n",
      "------------train------------\n",
      " (0.47132942006945333, 0.0036996654572231114)\n",
      "------------test------------\n",
      " (0.4701043748612037, 0.014146124805685112)\n",
      "------------oot------------\n",
      " (0.45738713377124396, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 1 96 0.01\n",
      "验证集最优结果： 0.8019263744354248 0.8486066460609436\n",
      "------------train------------\n",
      " (0.6622724679348566, 0.24247387040206725)\n",
      "------------test------------\n",
      " (0.6337641572285144, 0.21225849433710853)\n",
      "------------oot------------\n",
      " (0.6254405171514962, 0.19821360303061897)\n",
      "隐藏层vs神经元数vs norm 1 96 0.05\n",
      "验证集最优结果： 1.6304200887680054 1.621048927307129\n",
      "------------train------------\n",
      " (0.6038171581257753, 0.1618818860280507)\n",
      "------------test------------\n",
      " (0.5843448811903176, 0.1479013990672885)\n",
      "------------oot------------\n",
      " (0.6189564290596508, 0.17791679699718493)\n",
      "隐藏层vs神经元数vs norm 1 96 0.1\n",
      "验证集最优结果： 2.6216981410980225 2.604860305786133\n",
      "------------train------------\n",
      " (0.6003637129036865, 0.14447050128626043)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.5688718632023095, 0.11480124361536753)\n",
      "------------oot------------\n",
      " (0.6055063195820156, 0.17731206339276406)\n",
      "隐藏层vs神经元数vs norm 1 96 0.2\n",
      "验证集最优结果： 4.584980487823486 4.568702697753906\n",
      "------------train------------\n",
      " (0.5869974328934804, 0.1335103844974651)\n",
      "------------test------------\n",
      " (0.5924483677548301, 0.14115034421496775)\n",
      "------------oot------------\n",
      " (0.6013948261680511, 0.15669551315469366)\n",
      "隐藏层vs神经元数vs norm 1 96 0.3\n",
      "验证集最优结果： 6.520782947540283 6.492185115814209\n",
      "------------train------------\n",
      " (0.5404660046198442, 0.07015043257741427)\n",
      "------------test------------\n",
      " (0.5509327115256495, 0.08684210526315789)\n",
      "------------oot------------\n",
      " (0.5757805349922961, 0.12568727626594378)\n",
      "隐藏层vs神经元数vs norm 1 96 0.4\n",
      "验证集最优结果： 8.4330415725708 8.391386985778809\n",
      "------------train------------\n",
      " (0.49803084723990365, 0.009675006886451037)\n",
      "------------test------------\n",
      " (0.494290473017988, 0.025049966688874048)\n",
      "------------oot------------\n",
      " (0.5073182034082879, 0.04353386855732805)\n",
      "隐藏层vs神经元数vs norm 1 96 0.5\n",
      "验证集最优结果： 10.45627498626709 10.405213356018066\n",
      "------------train------------\n",
      " (0.46012964801605916, 0.004265200444793726)\n",
      "------------test------------\n",
      " (0.4890972684876749, 0.023084610259826777)\n",
      "------------oot------------\n",
      " (0.4734415366257719, 0.005122858235150907)\n",
      "隐藏层vs神经元数vs norm 1 96 0.8\n",
      "验证集最优结果： 16.256120681762695 16.1332950592041\n",
      "------------train------------\n",
      " (0.44761343017003274, 0.0012581732191163653)\n",
      "------------test------------\n",
      " (0.4356284699089496, 0.0009771263602043083)\n",
      "------------oot------------\n",
      " (0.4266105955815058, 0.0033295103047995545)\n",
      "隐藏层vs神经元数vs norm 1 98 0.01\n",
      "验证集最优结果： 0.8055264949798584 0.8028963804244995\n",
      "------------train------------\n",
      " (0.6579274049618995, 0.21949457848489956)\n",
      "------------test------------\n",
      " (0.6413835220963802, 0.20519653564290474)\n",
      "------------oot------------\n",
      " (0.6216116961503261, 0.17072255239286838)\n",
      "隐藏层vs神经元数vs norm 1 98 0.05\n",
      "验证集最优结果： 1.648748755455017 1.6385337114334106\n",
      "------------train------------\n",
      " (0.6093207015178618, 0.16316469480670226)\n",
      "------------test------------\n",
      " (0.5877814790139907, 0.15477459471463473)\n",
      "------------oot------------\n",
      " (0.6186563792444306, 0.17843811906996143)\n",
      "隐藏层vs神经元数vs norm 1 98 0.1\n",
      "验证集最优结果： 2.6825902462005615 2.666694402694702\n",
      "------------train------------\n",
      " (0.6051401012088344, 0.15844725587615627)\n",
      "------------test------------\n",
      " (0.5869642460581834, 0.16625582944703532)\n",
      "------------oot------------\n",
      " (0.6194140339901991, 0.195898933027491)\n",
      "隐藏层vs神经元数vs norm 1 98 0.2\n",
      "验证集最优结果： 4.6607208251953125 4.621449947357178\n",
      "------------train------------\n",
      " (0.5733874368121586, 0.11805955714197736)\n",
      "------------test------------\n",
      " (0.5581923162336221, 0.10284254941150339)\n",
      "------------oot------------\n",
      " (0.5455392207972752, 0.09637507385396038)\n",
      "隐藏层vs神经元数vs norm 1 98 0.3\n",
      "验证集最优结果： 6.641238689422607 6.603504657745361\n",
      "------------train------------\n",
      " (0.5208548133078044, 0.04269058210984622)\n",
      "------------test------------\n",
      " (0.5155718409948923, 0.046591161447923635)\n",
      "------------oot------------\n",
      " (0.5342068374286079, 0.08303617975185074)\n",
      "隐藏层vs神经元数vs norm 1 98 0.4\n",
      "验证集最优结果： 8.667791366577148 8.617926597595215\n",
      "------------train------------\n",
      " (0.5158048620036425, 0.04947984452525456)\n",
      "------------test------------\n",
      " (0.5032400621807684, 0.03909615811681105)\n",
      "------------oot------------\n",
      " (0.48684414787010966, 0.01881625134674869)\n",
      "隐藏层vs神经元数vs norm 1 98 0.5\n",
      "验证集最优结果： 10.529556274414062 10.469175338745117\n",
      "------------train------------\n",
      " (0.4961964455760559, 0.01848370838265523)\n",
      "------------test------------\n",
      " (0.49415611814345994, 0.0174439262713747)\n",
      "------------oot------------\n",
      " (0.4664674057855165, 0.01005804052410253)\n",
      "隐藏层vs神经元数vs norm 1 98 0.8\n",
      "验证集最优结果： 16.486289978027344 16.345935821533203\n",
      "------------train------------\n",
      " (0.5283359017934552, 0.065795759029034)\n",
      "------------test------------\n",
      " (0.518588718632023, 0.062047523872973576)\n",
      "------------oot------------\n",
      " (0.5223253281432825, 0.04791297396865113)\n",
      "隐藏层vs神经元数vs norm 1 100 0.01\n",
      "验证集最优结果： 0.8068373203277588 0.8035018444061279\n",
      "------------train------------\n",
      " (0.6573165919816668, 0.2128953618144766)\n",
      "------------test------------\n",
      " (0.6427048634243837, 0.21173662003109045)\n",
      "------------oot------------\n",
      " (0.6162791505925694, 0.16686476905432174)\n",
      "隐藏层vs神经元数vs norm 1 100 0.05\n",
      "验证集最优结果： 1.6776494979858398 1.6662678718566895\n",
      "------------train------------\n",
      " (0.6057168710944347, 0.15374362368776734)\n",
      "------------test------------\n",
      " (0.5875316455696202, 0.16366866533422164)\n",
      "------------oot------------\n",
      " (0.6190375236043049, 0.18508323775761998)\n",
      "隐藏层vs神经元数vs norm 1 100 0.1\n",
      "验证集最优结果： 2.7151153087615967 2.7023942470550537\n",
      "------------train------------\n",
      " (0.58557012708294, 0.12678799002936636)\n",
      "------------test------------\n",
      " (0.57942593826338, 0.14576948700866088)\n",
      "------------oot------------\n",
      " (0.5969149318226579, 0.15484655753657944)\n",
      "隐藏层vs神经元数vs norm 1 100 0.2\n",
      "验证集最优结果： 4.801122665405273 4.772777557373047\n",
      "------------train------------\n",
      " (0.5925289281704238, 0.13296934970921237)\n",
      "------------test------------\n",
      " (0.5849167221852098, 0.13763046857650452)\n",
      "------------oot------------\n",
      " (0.6233888251717467, 0.18651513571751294)\n",
      "隐藏层vs神经元数vs norm 1 100 0.3\n",
      "验证集最优结果： 6.790426731109619 6.742465496063232\n",
      "------------train------------\n",
      " (0.5670040520081027, 0.10394879593702777)\n",
      "------------test------------\n",
      " (0.5819820119920054, 0.15259826782145242)\n",
      "------------oot------------\n",
      " (0.6079217785192136, 0.17469155110694057)\n",
      "隐藏层vs神经元数vs norm 1 100 0.4\n",
      "验证集最优结果： 8.84568977355957 8.814427375793457\n",
      "------------train------------\n",
      " (0.5469151068093634, 0.07686890159921322)\n",
      "------------test------------\n",
      " (0.5372163002442816, 0.06646679991117033)\n",
      "------------oot------------\n",
      " (0.5145483613109513, 0.05192367844854551)\n",
      "隐藏层vs神经元数vs norm 1 100 0.5\n",
      "验证集最优结果： 10.803221702575684 10.720341682434082\n",
      "------------train------------\n",
      " (0.5412682846273431, 0.06507455979165355)\n",
      "------------test------------\n",
      " (0.5407639351543416, 0.06815456362425043)\n",
      "------------oot------------\n",
      " (0.5295103047996386, 0.07814270322872136)\n",
      "隐藏层vs神经元数vs norm 1 100 0.8\n",
      "验证集最优结果： 16.69843292236328 16.606412887573242\n",
      "------------train------------\n",
      " (0.47909374980964975, 0.0017438456785235437)\n",
      "------------test------------\n",
      " (0.4881090384188318, 0.024827892516100347)\n",
      "------------oot------------\n",
      " (0.4864942828346019, 0.018642477322489803)\n",
      "隐藏层vs神经元数vs norm 1 130 0.01\n",
      "验证集最优结果： 0.8753402829170227 0.8722352981567383\n",
      "------------train------------\n",
      " (0.6493417771036839, 0.20249604240564884)\n",
      "------------test------------\n",
      " (0.6333510992671552, 0.1949589162780369)\n",
      "------------oot------------\n",
      " (0.6141475225616608, 0.16457790289507523)\n",
      "隐藏层vs神经元数vs norm 1 130 0.05\n",
      "验证集最优结果： 1.9868555068969727 1.9767775535583496\n",
      "------------train------------\n",
      " (0.6106408697164677, 0.17402911192191878)\n",
      "------------test------------\n",
      " (0.5927059737952476, 0.14583610926049295)\n",
      "------------oot------------\n",
      " (0.6239912417891773, 0.1958919820665207)\n",
      "隐藏层vs神经元数vs norm 1 130 0.1\n",
      "验证集最优结果： 3.3310372829437256 3.3085803985595703\n",
      "------------train------------\n",
      " (0.576849883488693, 0.11340912151895821)\n",
      "------------test------------\n",
      " (0.5442360648456585, 0.08726404619142794)\n",
      "------------oot------------\n",
      " (0.5670640299354719, 0.10094880617245339)\n",
      "隐藏层vs神经元数vs norm 1 130 0.2\n",
      "验证集最优结果： 6.032454490661621 6.008637428283691\n",
      "------------train------------\n",
      " (0.568003010411231, 0.10194397575969227)\n",
      "------------test------------\n",
      " (0.5386508994003998, 0.07609371530091047)\n",
      "------------oot------------\n",
      " (0.5758303502125836, 0.11154902165224345)\n",
      "隐藏层vs神经元数vs norm 1 130 0.3\n",
      "验证集最优结果： 8.62228012084961 8.562057495117188\n",
      "------------train------------\n",
      " (0.5526487625707341, 0.09141917742949601)\n",
      "------------test------------\n",
      " (0.5617888074616921, 0.11880968243393297)\n",
      "------------oot------------\n",
      " (0.5655243920805385, 0.11259166579779656)\n",
      "隐藏层vs神经元数vs norm 1 130 0.4\n",
      "验证集最优结果： 11.344340324401855 11.322094917297363\n",
      "------------train------------\n",
      " (0.5195883831154372, 0.041181315687775444)\n",
      "------------test------------\n",
      " (0.5316644459249389, 0.06632245169886741)\n",
      "------------oot------------\n",
      " (0.5507964642778531, 0.11731831925763736)\n",
      "隐藏层vs神经元数vs norm 1 130 0.5\n",
      "验证集最优结果： 13.878669738769531 13.784680366516113\n",
      "------------train------------\n",
      " (0.48616408771612796, 0.00016838811022923394)\n",
      "------------test------------\n",
      " (0.48523206751054854, 0.019353764157228448)\n",
      "------------oot------------\n",
      " (0.4823920573685978, 0.017919577381573015)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 1 130 0.8\n",
      "验证集最优结果： 21.766048431396484 21.739280700683594\n",
      "------------train------------\n",
      " (0.46074465716302576, 0.0029015816164581487)\n",
      "------------test------------\n",
      " (0.47607705973795245, 0.005029980013324449)\n",
      "------------oot------------\n",
      " (0.45928474611615056, 0.008751259861675909)\n",
      "隐藏层vs神经元数vs norm 1 160 0.01\n",
      "验证集最优结果： 0.9444729089736938 0.9422115087509155\n",
      "------------train------------\n",
      " (0.6486775645177556, 0.2051788819110697)\n",
      "------------test------------\n",
      " (0.6309360426382411, 0.19713524317121917)\n",
      "------------oot------------\n",
      " (0.6152967481087593, 0.1750182462725472)\n",
      "隐藏层vs神经元数vs norm 1 160 0.05\n",
      "验证集最优结果： 2.316082715988159 2.306077480316162\n",
      "------------train------------\n",
      " (0.6099025474116082, 0.16623764245816858)\n",
      "------------test------------\n",
      " (0.5985198756384633, 0.15107705973795243)\n",
      "------------oot------------\n",
      " (0.6151507779283819, 0.1702707399297953)\n",
      "隐藏层vs神经元数vs norm 1 160 0.1\n",
      "验证集最优结果： 4.000120162963867 3.9866297245025635\n",
      "------------train------------\n",
      " (0.5786775171416795, 0.11843991935238252)\n",
      "------------test------------\n",
      " (0.5523362202975794, 0.0968465467466133)\n",
      "------------oot------------\n",
      " (0.5402089922265088, 0.08724846209988524)\n",
      "隐藏层vs神经元数vs norm 1 160 0.2\n",
      "验证集最优结果： 7.201496601104736 7.166929244995117\n",
      "------------train------------\n",
      " (0.5523514438535971, 0.09733184707814813)\n",
      "------------test------------\n",
      " (0.5529447035309794, 0.11049300466355766)\n",
      "------------oot------------\n",
      " (0.5355877616747182, 0.07703054947346466)\n",
      "隐藏层vs神经元数vs norm 1 160 0.3\n",
      "验证集最优结果： 10.376799583435059 10.315290451049805\n",
      "------------train------------\n",
      " (0.5566893327350412, 0.09314055331195992)\n",
      "------------test------------\n",
      " (0.5571319120586276, 0.10166555629580276)\n",
      "------------oot------------\n",
      " (0.5508810343029924, 0.09041114934139649)\n",
      "隐藏层vs神经元数vs norm 1 160 0.4\n",
      "验证集最优结果： 13.733294486999512 13.658069610595703\n",
      "------------train------------\n",
      " (0.5206613835573883, 0.04866308097451244)\n",
      "------------test------------\n",
      " (0.5579102820341995, 0.09352653786364651)\n",
      "------------oot------------\n",
      " (0.5257081291488548, 0.05552427623118894)\n",
      "隐藏层vs神经元数vs norm 1 160 0.5\n",
      "验证集最优结果： 16.9044189453125 16.808000564575195\n",
      "------------train------------\n",
      " (0.4693623653927239, 0.0017320693396248761)\n",
      "------------test------------\n",
      " (0.4921230290917167, 0.026149233844103947)\n",
      "------------oot------------\n",
      " (0.43633035600505105, 0.005261877454558084)\n",
      "隐藏层vs神经元数vs norm 1 160 0.8\n",
      "验证集最优结果： 26.639066696166992 26.497760772705078\n",
      "------------train------------\n",
      " (0.47770867638688386, 0.007717562785144794)\n",
      "------------test------------\n",
      " (0.4933266711081501, 0.013035753941816552)\n",
      "------------oot------------\n",
      " (0.48840463860795424, 0.039217321794738136)\n",
      "隐藏层vs神经元数vs norm 1 190 0.01\n",
      "验证集最优结果： 1.0043492317199707 1.0009984970092773\n",
      "------------train------------\n",
      " (0.645587155398267, 0.1986981054307196)\n",
      "------------test------------\n",
      " (0.6268110148789696, 0.19167221852098604)\n",
      "------------oot------------\n",
      " (0.6104449773514522, 0.16099120703437247)\n",
      "隐藏层vs神经元数vs norm 1 190 0.05\n",
      "验证集最优结果： 2.6450552940368652 2.635211706161499\n",
      "------------train------------\n",
      " (0.5985450807051454, 0.14358172609995407)\n",
      "------------test------------\n",
      " (0.5788552076393515, 0.14664667999111702)\n",
      "------------oot------------\n",
      " (0.6001679815567835, 0.1491120147360372)\n",
      "隐藏层vs神经元数vs norm 1 190 0.1\n",
      "验证集最优结果： 4.580892562866211 4.562412738800049\n",
      "------------train------------\n",
      " (0.6001201321927881, 0.14417392705031817)\n",
      "------------test------------\n",
      " (0.584602487230735, 0.13486564512547194)\n",
      "------------oot------------\n",
      " (0.6229740845005155, 0.18399888784624474)\n",
      "隐藏层vs神经元数vs norm 1 190 0.2\n",
      "验证集最优结果： 8.391393661499023 8.36030387878418\n",
      "------------train------------\n",
      " (0.5927233731224693, 0.1353646841132451)\n",
      "------------test------------\n",
      " (0.5923273373306684, 0.1618698645347546)\n",
      "------------oot------------\n",
      " (0.5926250304104542, 0.13826156466131434)\n",
      "隐藏层vs神经元数vs norm 1 190 0.3\n",
      "验证集最优结果： 12.22756576538086 12.171656608581543\n",
      "------------train------------\n",
      " (0.5218746171843857, 0.05209270279836942)\n",
      "------------test------------\n",
      " (0.5281889851210304, 0.05819453697534971)\n",
      "------------oot------------\n",
      " (0.5216267565657619, 0.060925172905154146)\n",
      "隐藏层vs神经元数vs norm 1 190 0.4\n",
      "验证集最优结果： 15.993050575256348 15.895707130432129\n",
      "------------train------------\n",
      " (0.48491525435200017, 0.0068074006845165735)\n",
      "------------test------------\n",
      " (0.47418387741505663, 0.0152453919609149)\n",
      "------------oot------------\n",
      " (0.4497978428851122, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 1 190 0.5\n",
      "验证集最优结果： 20.0616397857666 19.913042068481445\n",
      "------------train------------\n",
      " (0.5133080751167989, 0.030168814494913487)\n",
      "------------test------------\n",
      " (0.5367710415278704, 0.07962469464801247)\n",
      "------------oot------------\n",
      " (0.5254185057750901, 0.06958607027421543)\n",
      "隐藏层vs神经元数vs norm 1 190 0.8\n",
      "验证集最优结果： 31.195676803588867 31.027372360229492\n",
      "------------train------------\n",
      " (0.4432753382482628, 0.003148884733330193)\n",
      "------------test------------\n",
      " (0.4750532978014657, 0.0023761936486786372)\n",
      "------------oot------------\n",
      " (0.4280923087616863, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 1 220 0.01\n",
      "验证集最优结果： 1.0673062801361084 1.0642837285995483\n",
      "------------train------------\n",
      " (0.641651895482962, 0.19356984824089246)\n",
      "------------test------------\n",
      " (0.624011769931157, 0.18656451254719078)\n",
      "------------oot------------\n",
      " (0.6100395046281815, 0.15659819970110866)\n",
      "隐藏层vs神经元数vs norm 1 220 0.05\n",
      "验证集最优结果： 2.969866991043091 2.9581241607666016\n",
      "------------train------------\n",
      " (0.6043268570237401, 0.1581368748980569)\n",
      "------------test------------\n",
      " (0.5838396624472574, 0.14602487230735062)\n",
      "------------oot------------\n",
      " (0.6197928613630834, 0.18372084940743055)\n",
      "隐藏层vs神经元数vs norm 1 220 0.1\n",
      "验证集最优结果： 5.231926441192627 5.213221073150635\n",
      "------------train------------\n",
      " (0.599471959792601, 0.14552360377627932)\n",
      "------------test------------\n",
      " (0.5861125916055963, 0.12640461914279372)\n",
      "------------oot------------\n",
      " (0.6153025405762346, 0.17861189309422032)\n",
      "隐藏层vs神经元数vs norm 1 220 0.2\n",
      "验证集最优结果： 9.618912696838379 9.5827054977417\n",
      "------------train------------\n",
      " (0.5846268694092001, 0.131292642698433)\n",
      "------------test------------\n",
      " (0.5672262935820565, 0.13228958472129682)\n",
      "------------oot------------\n",
      " (0.6007854585896499, 0.13739269454002012)\n",
      "隐藏层vs神经元数vs norm 1 220 0.3\n",
      "验证集最优结果： 14.283978462219238 14.263541221618652\n",
      "------------train------------\n",
      " (0.5287663472842341, 0.06024490724102716)\n",
      "------------test------------\n",
      " (0.5209427048634244, 0.05366422385076619)\n",
      "------------oot------------\n",
      " (0.5434446645582085, 0.09608313349320541)\n",
      "隐藏层vs神经元数vs norm 1 220 0.4\n",
      "验证集最优结果： 18.534950256347656 18.437971115112305\n",
      "------------train------------\n",
      " (0.5561078252418379, 0.09315923302193707)\n",
      "------------test------------\n",
      " (0.5349566955363091, 0.0753164556962026)\n",
      "------------oot------------\n",
      " (0.5990141220357048, 0.17834080561637655)\n",
      "隐藏层vs神经元数vs norm 1 220 0.5\n",
      "验证集最优结果： 23.35577392578125 23.31109046936035\n",
      "------------train------------\n",
      " (0.4852177167573918, 0.002353778817344332)\n",
      "------------test------------\n",
      " (0.49780923828558743, 0.048845214301576706)\n",
      "------------oot------------\n",
      " (0.49279880443471313, 0.02110311750599525)\n",
      "隐藏层vs神经元数vs norm 1 220 0.8\n",
      "验证集最优结果： 36.284271240234375 36.018287658691406\n",
      "------------train------------\n",
      " (0.4398106581281441, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.47154563624250495, 0.008072396180324182)\n",
      "------------oot------------\n",
      " (0.41856369976482577, 0.00909185694922332)\n",
      "隐藏层vs神经元数vs norm 1 250 0.01\n",
      "验证集最优结果： 1.1273339986801147 1.1238274574279785\n",
      "------------train------------\n",
      " (0.6660844823723773, 0.2485331351659753)\n",
      "------------test------------\n",
      " (0.632618254497002, 0.21479013990672885)\n",
      "------------oot------------\n",
      " (0.6348057785655533, 0.21086435199666353)\n",
      "隐藏层vs神经元数vs norm 1 250 0.05\n",
      "验证集最优结果： 3.265467643737793 3.254601240158081\n",
      "------------train------------\n",
      " (0.6188545953778546, 0.17391676294162117)\n",
      "------------test------------\n",
      " (0.6008594270486343, 0.16757717077503886)\n",
      "------------oot------------\n",
      " (0.6290492243886051, 0.1952663955791888)\n",
      "隐藏层vs神经元数vs norm 1 250 0.1\n",
      "验证集最优结果： 5.883742809295654 5.854253768920898\n",
      "------------train------------\n",
      " (0.6080149491823905, 0.151379016053045)\n",
      "------------test------------\n",
      " (0.5905607372862536, 0.14521430157672655)\n",
      "------------oot------------\n",
      " (0.6163741470591643, 0.17373926945400198)\n",
      "隐藏层vs神经元数vs norm 1 250 0.2\n",
      "验证集最优结果： 10.837296485900879 10.779749870300293\n",
      "------------train------------\n",
      " (0.5704581063511691, 0.11028785026994203)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.5634754608039085, 0.09951143681989794)\n",
      "------------oot------------\n",
      " (0.5958595442486591, 0.1582247245681715)\n",
      "隐藏层vs神经元数vs norm 1 250 0.3\n",
      "验证集最优结果： 15.851775169372559 15.778907775878906\n",
      "------------train------------\n",
      " (0.5221606333233844, 0.05876406646457383)\n",
      "------------test------------\n",
      " (0.5198578725294248, 0.05156562291805461)\n",
      "------------oot------------\n",
      " (0.5377784728738748, 0.07802453689222538)\n",
      "隐藏层vs神经元数vs norm 1 250 0.4\n",
      "验证集最优结果： 20.897586822509766 20.769439697265625\n",
      "------------train------------\n",
      " (0.46308665964147133, 0.0022089433849122875)\n",
      "------------test------------\n",
      " (0.4682656007106374, 0.009193870752831457)\n",
      "------------oot------------\n",
      " (0.40053059002073704, 0.0)\n",
      "隐藏层vs神经元数vs norm 1 250 0.5\n",
      "验证集最优结果： 25.891611099243164 25.72259521484375\n",
      "------------train------------\n",
      " (0.4949908598013318, 0.012512021679292329)\n",
      "------------test------------\n",
      " (0.47331556739951136, 0.011492338441039252)\n",
      "------------oot------------\n",
      " (0.46155655185996136, 0.007590449379626718)\n",
      "隐藏层vs神经元数vs norm 1 250 0.8\n",
      "验证集最优结果： 41.144012451171875 40.890018463134766\n",
      "------------train------------\n",
      " (0.4533807229453842, 0.0010355056617794567)\n",
      "------------test------------\n",
      " (0.44019764601376854, 0.002631578947368421)\n",
      "------------oot------------\n",
      " (0.43236946674544424, 0.0)\n",
      "隐藏层vs神经元数vs norm 1 280 0.01\n",
      "验证集最优结果： 1.1907705068588257 1.187225341796875\n",
      "------------train------------\n",
      " (0.6377284119065554, 0.18924752578442938)\n",
      "------------test------------\n",
      " (0.6183744170552965, 0.177137463912947)\n",
      "------------oot------------\n",
      " (0.606634692246203, 0.1594202898550725)\n",
      "隐藏层vs神经元数vs norm 1 280 0.05\n",
      "验证集最优结果： 3.57442045211792 3.5600833892822266\n",
      "------------train------------\n",
      " (0.6119636097592009, 0.1700565602667679)\n",
      "------------test------------\n",
      " (0.605092160781701, 0.16102598267821455)\n",
      "------------oot------------\n",
      " (0.6238835018941369, 0.20090362492614605)\n",
      "隐藏层vs神经元数vs norm 1 280 0.1\n",
      "验证集最优结果： 6.490158557891846 6.469316005706787\n",
      "------------train------------\n",
      " (0.6018459749624205, 0.1522905317558454)\n",
      "------------test------------\n",
      " (0.5677148567621586, 0.12436153675327566)\n",
      "------------oot------------\n",
      " (0.5934626212073819, 0.1363361484725264)\n",
      "隐藏层vs神经元数vs norm 1 280 0.2\n",
      "验证集最优结果： 12.079553604125977 12.013755798339844\n",
      "------------train------------\n",
      " (0.5697595799501739, 0.11409986470746292)\n",
      "------------test------------\n",
      " (0.5600288696424606, 0.11744392627137468)\n",
      "------------oot------------\n",
      " (0.5826168051066394, 0.12554825704653672)\n",
      "隐藏层vs神经元数vs norm 1 280 0.3\n",
      "验证集最优结果： 17.781585693359375 17.64979362487793\n",
      "------------train------------\n",
      " (0.5457775395437954, 0.08062176362180618)\n",
      "------------test------------\n",
      " (0.5503553186764378, 0.10093271152564964)\n",
      "------------oot------------\n",
      " (0.5194615322234966, 0.05258401974072913)\n",
      "隐藏层vs神经元数vs norm 1 280 0.4\n",
      "验证集最优结果： 23.241519927978516 23.16064453125\n",
      "------------train------------\n",
      " (0.488103731948869, 0.004138097200818369)\n",
      "------------test------------\n",
      " (0.4761503442149678, 0.007872529424827968)\n",
      "------------oot------------\n",
      " (0.46255633174619726, 0.0)\n",
      "隐藏层vs神经元数vs norm 1 280 0.5\n",
      "验证集最优结果： 28.985750198364258 28.885229110717773\n",
      "------------train------------\n",
      " (0.4815261729132023, 0.00524547913794492)\n",
      "------------test------------\n",
      " (0.46559293804130575, 0.015889407061958693)\n",
      "------------oot------------\n",
      " (0.4679085716933699, 0.012115524971327285)\n",
      "隐藏层vs神经元数vs norm 1 280 0.8\n",
      "验证集最优结果： 45.614540100097656 45.333229064941406\n",
      "------------train------------\n",
      " (0.48710545034682673, 0.01202905642422969)\n",
      "------------test------------\n",
      " (0.47176771041527865, 0.011081501221408052)\n",
      "------------oot------------\n",
      " (0.5125488015384794, 0.06110589789038334)\n",
      "隐藏层vs神经元数vs norm 1 310 0.01\n",
      "验证集最优结果： 1.2719308137893677 1.264432430267334\n",
      "------------train------------\n",
      " (0.6464111607206307, 0.21525414895985823)\n",
      "------------test------------\n",
      " (0.632305129913391, 0.18989562513879643)\n",
      "------------oot------------\n",
      " (0.6322883722007901, 0.2055538178153129)\n",
      "隐藏层vs神经元数vs norm 1 310 0.05\n",
      "验证集最优结果： 3.8821611404418945 3.8682382106781006\n",
      "------------train------------\n",
      " (0.6169184705107614, 0.17462821624336144)\n",
      "------------test------------\n",
      " (0.604147235176549, 0.1800688429935598)\n",
      "------------oot------------\n",
      " (0.6431561996779388, 0.21683522747019773)\n",
      "隐藏层vs神经元数vs norm 1 310 0.1\n",
      "验证集最优结果： 7.03883695602417 7.002511501312256\n",
      "------------train------------\n",
      " (0.5789494558180868, 0.11402203258255783)\n",
      "------------test------------\n",
      " (0.5857839218298913, 0.15134354874528094)\n",
      "------------oot------------\n",
      " (0.5889757759010184, 0.1609773051124318)\n",
      "隐藏层vs神经元数vs norm 1 310 0.2\n",
      "验证集最优结果： 13.287154197692871 13.228553771972656\n",
      "------------train------------\n",
      " (0.528744148208609, 0.06660832641304226)\n",
      "------------test------------\n",
      " (0.5252731512325116, 0.058027981345769475)\n",
      "------------oot------------\n",
      " (0.5468205146028104, 0.10616897786118928)\n",
      "隐藏层vs神经元数vs norm 1 310 0.3\n",
      "验证集最优结果： 19.44647216796875 19.344615936279297\n",
      "------------train------------\n",
      " (0.5100073838998498, 0.043031148416387)\n",
      "------------test------------\n",
      " (0.5169986675549634, 0.05127692649344884)\n",
      "------------oot------------\n",
      " (0.5167587668995239, 0.05614986271852085)\n",
      "隐藏层vs神经元数vs norm 1 310 0.4\n",
      "验证集最优结果： 25.678024291992188 25.537553787231445\n",
      "------------train------------\n",
      " (0.4779262679360748, 0.004265200444793726)\n",
      "------------test------------\n",
      " (0.452145236508994, 0.008361092604930051)\n",
      "------------oot------------\n",
      " (0.49029761697888063, 0.02997254370416713)\n",
      "隐藏层vs神经元数vs norm 1 310 0.5\n",
      "验证集最优结果： 32.03292465209961 31.854808807373047\n",
      "------------train------------\n",
      " (0.46539658174843435, 0.0027252072534126003)\n",
      "------------test------------\n",
      " (0.5001654452587164, 0.024794581390184367)\n",
      "------------oot------------\n",
      " (0.48772460292635456, 0.016856080353108815)\n",
      "隐藏层vs神经元数vs norm 1 310 0.8\n",
      "验证集最优结果： 51.57276153564453 51.124847412109375\n",
      "------------train------------\n",
      " (0.49529041196205315, 0.022186216404440073)\n",
      "------------test------------\n",
      " (0.5118965134354875, 0.0447923606484566)\n",
      "------------oot------------\n",
      " (0.4738458508555474, 0.001842004657143903)\n",
      "隐藏层vs神经元数vs norm 1 340 0.01\n",
      "验证集最优结果： 1.331424593925476 1.3247178792953491\n",
      "------------train------------\n",
      " (0.6505979875996505, 0.22198642472381436)\n",
      "------------test------------\n",
      " (0.6329136131467911, 0.19322673773040194)\n",
      "------------oot------------\n",
      " (0.6336183227331178, 0.20479616306954435)\n",
      "隐藏层vs神经元数vs norm 1 340 0.05\n",
      "验证集最优结果： 4.20066499710083 4.180056571960449\n",
      "------------train------------\n",
      " (0.6096981534835967, 0.17108123711116935)\n",
      "------------test------------\n",
      " (0.5881379080612925, 0.15403064623584273)\n",
      "------------oot------------\n",
      " (0.5872368771649348, 0.14897299551663018)\n",
      "隐藏层vs神经元数vs norm 1 340 0.1\n",
      "验证集最优结果： 7.747607707977295 7.720254421234131\n",
      "------------train------------\n",
      " (0.6012511344878206, 0.15731523837949452)\n",
      "------------test------------\n",
      " (0.5692105263157894, 0.12809238285587393)\n",
      "------------oot------------\n",
      " (0.590303409446356, 0.14059708754735345)\n",
      "隐藏层vs神经元数vs norm 1 340 0.2\n",
      "验证集最优结果： 14.473158836364746 14.404311180114746\n",
      "------------train------------\n",
      " (0.5147930443798776, 0.030243939415473986)\n",
      "------------test------------\n",
      " (0.5116733288918499, 0.050210970464134974)\n",
      "------------oot------------\n",
      " (0.4997822032229289, 0.028853438987940072)\n",
      "隐藏层vs神经元数vs norm 1 340 0.3\n",
      "验证集最优结果： 21.343904495239258 21.238264083862305\n",
      "------------train------------\n",
      " (0.5241577379683379, 0.045138165557728094)\n",
      "------------test------------\n",
      " (0.5165378636464579, 0.04293804130579615)\n",
      "------------oot------------\n",
      " (0.5087813806925474, 0.042393910958190006)\n",
      "隐藏层vs神经元数vs norm 1 340 0.4\n",
      "验证集最优结果： 28.202302932739258 28.043846130371094\n",
      "------------train------------\n",
      " (0.4865103391517922, 0.019832437587095852)\n",
      "------------test------------\n",
      " (0.4819831223628692, 0.02324006218076835)\n",
      "------------oot------------\n",
      " (0.4655267090675286, 0.018468703298230915)\n",
      "隐藏层vs神经元数vs norm 1 340 0.5\n",
      "验证集最优结果： 35.25162124633789 35.00783920288086\n",
      "------------train------------\n",
      " (0.5465775861077101, 0.07823563371254494)\n",
      "------------test------------\n",
      " (0.5151932045303131, 0.046480124361536757)\n",
      "------------oot------------\n",
      " (0.5463026680105191, 0.0953254787474368)\n",
      "隐藏层vs神经元数vs norm 1 340 0.8\n",
      "验证集最优结果： 55.264495849609375 54.99523162841797\n",
      "------------train------------\n",
      " (0.5468201516169793, 0.06751997747605987)\n",
      "------------test------------\n",
      " (0.5263335554075061, 0.07209638019098374)\n",
      "------------oot------------\n",
      " (0.5444954181582271, 0.08108295971918122)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 1 370 0.01\n",
      "验证集最优结果： 1.3971515893936157 1.3902980089187622\n",
      "------------train------------\n",
      " (0.6456260714607194, 0.2166078864923362)\n",
      "------------test------------\n",
      " (0.6306018210082167, 0.1906284699089496)\n",
      "------------oot------------\n",
      " (0.6322061191626409, 0.19580161957390607)\n",
      "隐藏层vs神经元数vs norm 1 370 0.05\n",
      "验证集最优结果： 4.551682949066162 4.536683082580566\n",
      "------------train------------\n",
      " (0.6120087523916458, 0.16890681058164964)\n",
      "------------test------------\n",
      " (0.5945558516544527, 0.1548412169664668)\n",
      "------------oot------------\n",
      " (0.6268631471634287, 0.18950404893476525)\n",
      "隐藏层vs神经元数vs norm 1 370 0.1\n",
      "验证集最优结果： 8.272765159606934 8.238869667053223\n",
      "------------train------------\n",
      " (0.5869009210585981, 0.1320483587912062)\n",
      "------------test------------\n",
      " (0.5751709971130358, 0.12373972906950925)\n",
      "------------oot------------\n",
      " (0.5614464949779308, 0.11017968234108366)\n",
      "隐藏层vs神经元数vs norm 1 370 0.2\n",
      "验证集最优结果： 15.830379486083984 15.730233192443848\n",
      "------------train------------\n",
      " (0.5394140526916718, 0.07776160223181927)\n",
      "------------test------------\n",
      " (0.5295192094159449, 0.08717521652231847)\n",
      "------------oot------------\n",
      " (0.5138277783570245, 0.051986237097278676)\n",
      "隐藏层vs神经元数vs norm 1 370 0.3\n",
      "验证集最优结果： 23.579769134521484 23.506160736083984\n",
      "------------train------------\n",
      " (0.5013870361459156, 0.013612364885123185)\n",
      "------------test------------\n",
      " (0.5139118365534088, 0.044747945813901846)\n",
      "------------oot------------\n",
      " (0.518527786466479, 0.06393493900531755)\n",
      "隐藏层vs神经元数vs norm 1 370 0.4\n",
      "验证集最优结果： 30.65768051147461 30.426254272460938\n",
      "------------train------------\n",
      " (0.5457988587780086, 0.06806195978583307)\n",
      "------------test------------\n",
      " (0.5514290473017988, 0.08602043082389518)\n",
      "------------oot------------\n",
      " (0.5686291546472967, 0.11884057971014494)\n",
      "隐藏层vs神经元数vs norm 1 370 0.5\n",
      "验证集最优结果： 38.141754150390625 37.90792465209961\n",
      "------------train------------\n",
      " (0.4800447230157715, 0.007277100638291123)\n",
      "------------test------------\n",
      " (0.5053786364645791, 0.03331112591605595)\n",
      "------------oot------------\n",
      " (0.48901400618635527, 0.030167170611337002)\n",
      "隐藏层vs神经元数vs norm 1 370 0.8\n",
      "验证集最优结果： 60.17618179321289 59.8474006652832\n",
      "------------train------------\n",
      " (0.46331771953227635, 0.006195301782220275)\n",
      "------------test------------\n",
      " (0.45760159893404395, 0.002431712191872104)\n",
      "------------oot------------\n",
      " (0.4563120518078291, 0.011920898064157304)\n",
      "隐藏层vs神经元数vs norm 1 400 0.01\n",
      "验证集最优结果： 1.4670871496200562 1.4583733081817627\n",
      "------------train------------\n",
      " (0.6448859894730359, 0.21541969450552578)\n",
      "------------test------------\n",
      " (0.6299855651787698, 0.18656451254719075)\n",
      "------------oot------------\n",
      " (0.6319790544376094, 0.1982553087964411)\n",
      "隐藏层vs神经元数vs norm 1 400 0.05\n",
      "验证集最优结果： 4.818006992340088 4.798125267028809\n",
      "------------train------------\n",
      " (0.601821068682451, 0.16434097509439688)\n",
      "------------test------------\n",
      " (0.5849333777481679, 0.13505440817232955)\n",
      "------------oot------------\n",
      " (0.5785759797958734, 0.14665832551350227)\n",
      "隐藏层vs神经元数vs norm 1 400 0.1\n",
      "验证集最优结果： 9.000391960144043 8.9716215133667\n",
      "------------train------------\n",
      " (0.6100377045885084, 0.16141584080014132)\n",
      "------------test------------\n",
      " (0.5676471241394625, 0.11476793248945139)\n",
      "------------oot------------\n",
      " (0.5979251381503493, 0.15299760191846523)\n",
      "隐藏层vs神经元数vs norm 1 400 0.2\n",
      "验证集最优结果： 16.929784774780273 16.841632843017578\n",
      "------------train------------\n",
      " (0.5145416804564888, 0.03619099055930164)\n",
      "------------test------------\n",
      " (0.5381523428825228, 0.08314457028647565)\n",
      "------------oot------------\n",
      " (0.5428283460188371, 0.07885865220866783)\n",
      "隐藏层vs神经元数vs norm 1 400 0.3\n",
      "验证集最优结果： 24.951507568359375 24.80274772644043\n",
      "------------train------------\n",
      " (0.4844105637820728, 0.015200681674053973)\n",
      "------------test------------\n",
      " (0.4881479013990673, 0.025316455696202556)\n",
      "------------oot------------\n",
      " (0.46122174723988923, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 1 400 0.4\n",
      "验证集最优结果： 33.293174743652344 33.06314468383789\n",
      "------------train------------\n",
      " (0.4721656078113674, 0.003625758778617705)\n",
      "------------test------------\n",
      " (0.4766899844548079, 0.0029868976238063283)\n",
      "------------oot------------\n",
      " (0.4692894959394803, 0.009279532895422826)\n",
      "隐藏层vs神经元数vs norm 1 400 0.5\n",
      "验证集最优结果： 41.64243698120117 41.61384963989258\n",
      "------------train------------\n",
      " (0.5168228385172913, 0.03838098351380226)\n",
      "------------test------------\n",
      " (0.49905951587830333, 0.04976682211858763)\n",
      "------------oot------------\n",
      " (0.5011040443007913, 0.03152955896152643)\n",
      "隐藏层vs神经元数vs norm 1 400 0.8\n",
      "验证集最优结果： 65.96826934814453 65.51200866699219\n",
      "------------train------------\n",
      " (0.5678685300354172, 0.10217638925266948)\n",
      "------------test------------\n",
      " (0.5354519209415946, 0.06900954918942925)\n",
      "------------oot------------\n",
      " (0.5474611615055782, 0.08722065825600389)\n",
      "隐藏层vs神经元数vs norm 1 430 0.01\n",
      "验证集最优结果： 1.527282476425171 1.5193101167678833\n",
      "------------train------------\n",
      " (0.6308195587392279, 0.190286686172074)\n",
      "------------test------------\n",
      " (0.6173595380857206, 0.16893182322895844)\n",
      "------------oot------------\n",
      " (0.6322640438373939, 0.2077086157161227)\n",
      "隐藏层vs神经元数vs norm 1 430 0.05\n",
      "验证集最优结果： 5.137249946594238 5.115198135375977\n",
      "------------train------------\n",
      " (0.5797210767363838, 0.11832459244730598)\n",
      "------------test------------\n",
      " (0.5532811459027316, 0.10698423273373309)\n",
      "------------oot------------\n",
      " (0.568498244882355, 0.13000382302853364)\n",
      "隐藏层vs神经元数vs norm 1 430 0.1\n",
      "验证集最优结果： 9.528379440307617 9.482117652893066\n",
      "------------train------------\n",
      " (0.5750509462017585, 0.12174744626030182)\n",
      "------------test------------\n",
      " (0.5587441705529648, 0.10891627803686427)\n",
      "------------oot------------\n",
      " (0.5460281050521901, 0.0996628783929378)\n",
      "隐藏层vs神经元数vs norm 1 430 0.2\n",
      "验证集最优结果： 18.177873611450195 18.086225509643555\n",
      "------------train------------\n",
      " (0.5551182743738068, 0.09560573358808122)\n",
      "------------test------------\n",
      " (0.5405129913391074, 0.0929047301798801)\n",
      "------------oot------------\n",
      " (0.5203906440065339, 0.0629270496646161)\n",
      "隐藏层vs神经元数vs norm 1 430 0.3\n",
      "验证集最优结果： 26.997941970825195 26.829391479492188\n",
      "------------train------------\n",
      " (0.5212217071765957, 0.052646461447041326)\n",
      "------------test------------\n",
      " (0.522238507661559, 0.06601154785698427)\n",
      "------------oot------------\n",
      " (0.49530462586452584, 0.0218190664859417)\n",
      "隐藏层vs神经元数vs norm 1 430 0.4\n",
      "验证集最优结果： 35.39039611816406 35.14543533325195\n",
      "------------train------------\n",
      " (0.4834981682378604, 0.00316661692178688)\n",
      "------------test------------\n",
      " (0.47129580279813454, 0.01253608705307574)\n",
      "------------oot------------\n",
      " (0.45199087107125896, 0.0018976123449067073)\n",
      "隐藏层vs神经元数vs norm 1 430 0.5\n",
      "验证集最优结果： 44.086769104003906 43.79792404174805\n",
      "------------train------------\n",
      " (0.48971066076766845, 0.007095988667642716)\n",
      "------------test------------\n",
      " (0.48239395958250053, 0.02026426826560071)\n",
      "------------oot------------\n",
      " (0.46977142923342485, 0.007159489799464791)\n",
      "隐藏层vs神经元数vs norm 1 430 0.8\n",
      "验证集最优结果： 70.29290008544922 69.8392105102539\n",
      "------------train------------\n",
      " (0.49803132100066394, 0.01174940221544074)\n",
      "------------test------------\n",
      " (0.4907306240284255, 0.01407950255385304)\n",
      "------------oot------------\n",
      " (0.49656390829365493, 0.0391478121850346)\n",
      "隐藏层vs神经元数vs norm 1 460 0.01\n",
      "验证集最优结果： 1.590075135231018 1.5814062356948853\n",
      "------------train------------\n",
      " (0.6319251133134218, 0.18892618062873467)\n",
      "------------test------------\n",
      " (0.6198856318010215, 0.17184099489229404)\n",
      "------------oot------------\n",
      " (0.631265422444653, 0.2052062697667953)\n",
      "隐藏层vs神经元数vs norm 1 460 0.05\n",
      "验证集最优结果： 5.47418212890625 5.454650402069092\n",
      "------------train------------\n",
      " (0.6022653885954956, 0.15037992228969932)\n",
      "------------test------------\n",
      " (0.5874816788807462, 0.14450366422385075)\n",
      "------------oot------------\n",
      " (0.5865162942110079, 0.13853265213915822)\n",
      "隐藏层vs神经元数vs norm 1 460 0.1\n",
      "验证集最优结果： 10.26317310333252 10.236212730407715\n",
      "------------train------------\n",
      " (0.5912220929532148, 0.13115647031990352)\n",
      "------------test------------\n",
      " (0.5903320008882966, 0.15036642238507658)\n",
      "------------oot------------\n",
      " (0.6027004483369826, 0.16206165502380704)\n",
      "隐藏层vs神经元数vs norm 1 460 0.2\n",
      "验证集最优结果： 19.387168884277344 19.292579650878906\n",
      "------------train------------\n",
      " (0.5720014835479807, 0.10762693911971188)\n",
      "------------test------------\n",
      " (0.5407650455252054, 0.08491005996002665)\n",
      "------------oot------------\n",
      " (0.5881509285325363, 0.14597713133840762)\n",
      "隐藏层vs神经元数vs norm 1 460 0.3\n",
      "验证集最优结果： 28.83184242248535 28.625083923339844\n",
      "------------train------------\n",
      " (0.5132926440520352, 0.030285224281727974)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.5242727070841662, 0.051565622918054554)\n",
      "------------oot------------\n",
      " (0.5388408114088439, 0.06953046258645257)\n",
      "隐藏层vs神经元数vs norm 1 460 0.4\n",
      "验证集最优结果： 37.77125930786133 37.606712341308594\n",
      "------------train------------\n",
      " (0.5047943235339305, 0.024911694378287164)\n",
      "------------test------------\n",
      " (0.49804352653786366, 0.02965800577392852)\n",
      "------------oot------------\n",
      " (0.48729827732017283, 0.008104820491433018)\n",
      "隐藏层vs神经元数vs norm 1 460 0.5\n",
      "验证集最优结果： 47.58600997924805 47.24610137939453\n",
      "------------train------------\n",
      " (0.5421153688667439, 0.07674612988218926)\n",
      "------------test------------\n",
      " (0.5507550521874307, 0.09925605152120809)\n",
      "------------oot------------\n",
      " (0.5288395370659994, 0.0612657699927015)\n",
      "隐藏层vs神经元数vs norm 1 460 0.8\n",
      "验证集最优结果： 74.57430267333984 74.11957550048828\n",
      "------------train------------\n",
      " (0.49388740331050485, 0.00989686228248459)\n",
      "------------test------------\n",
      " (0.46557850322007543, 0.004086164779036228)\n",
      "------------oot------------\n",
      " (0.48340226369628936, 0.007451430160219652)\n",
      "隐藏层vs神经元数vs norm 1 490 0.01\n",
      "验证集最优结果： 1.6624246835708618 1.653371810913086\n",
      "------------train------------\n",
      " (0.6240754389562644, 0.1780183128837885)\n",
      "------------test------------\n",
      " (0.612618254497002, 0.16502331778814122)\n",
      "------------oot------------\n",
      " (0.6274458693914433, 0.19413338894102106)\n",
      "隐藏层vs神经元数vs norm 1 490 0.05\n",
      "验证集最优结果： 5.760506629943848 5.734140872955322\n",
      "------------train------------\n",
      " (0.6021867443092872, 0.15746887222604616)\n",
      "------------test------------\n",
      " (0.5914223850766156, 0.15755052187430596)\n",
      "------------oot------------\n",
      " (0.575544202319304, 0.12814791644944912)\n",
      "隐藏层vs神经元数vs norm 1 490 0.1\n",
      "验证集最优结果： 10.748632431030273 10.688901901245117\n",
      "------------train------------\n",
      " (0.5834181026693712, 0.12398305560800765)\n",
      "------------test------------\n",
      " (0.5778980679546968, 0.1451698867421719)\n",
      "------------oot------------\n",
      " (0.5707596241847102, 0.12216313905397425)\n",
      "隐藏层vs神经元数vs norm 1 490 0.2\n",
      "验证集最优结果： 20.639257431030273 20.53986358642578\n",
      "------------train------------\n",
      " (0.5407000424354281, 0.07824226636318898)\n",
      "------------test------------\n",
      " (0.5538307794803464, 0.08794137241838773)\n",
      "------------oot------------\n",
      " (0.5556748803855467, 0.08640044486150211)\n",
      "隐藏层vs神经元数vs norm 1 490 0.3\n",
      "验证集最优结果： 30.8109130859375 30.761262893676758\n",
      "------------train------------\n",
      " (0.5527821600648104, 0.08384956336177929)\n",
      "------------test------------\n",
      " (0.5383388851876527, 0.0720963801909838)\n",
      "------------oot------------\n",
      " (0.5409654884787821, 0.06772321273416049)\n",
      "隐藏层vs神经元数vs norm 1 490 0.4\n",
      "验证集最优结果： 40.7584342956543 40.73239517211914\n",
      "------------train------------\n",
      " (0.5306980729442674, 0.058441773787358486)\n",
      "------------test------------\n",
      " (0.49873306684432606, 0.022596047079724624)\n",
      "------------oot------------\n",
      " (0.5397340098935344, 0.09995481875369272)\n",
      "隐藏层vs神经元数vs norm 1 490 0.5\n",
      "验证集最优结果： 50.270362854003906 49.948177337646484\n",
      "------------train------------\n",
      " (0.4887129882866036, 0.01797407716479904)\n",
      "------------test------------\n",
      " (0.4472684876748834, 0.015678436597823753)\n",
      "------------oot------------\n",
      " (0.4364288279521311, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 1 490 0.8\n",
      "验证集最优结果： 80.10385131835938 79.50959777832031\n",
      "------------train------------\n",
      " (0.5471883990879429, 0.07742387848984017)\n",
      "------------test------------\n",
      " (0.518159005107706, 0.058039085054408246)\n",
      "------------oot------------\n",
      " (0.5402993547191233, 0.09013311090258225)\n",
      "隐藏层vs神经元数vs norm 1 520 0.01\n",
      "验证集最优结果： 1.6976475715637207 1.6932175159454346\n",
      "------------train------------\n",
      " (0.65597645815102, 0.23021131760312247)\n",
      "------------test------------\n",
      " (0.6224428159005109, 0.19110592938041304)\n",
      "------------oot------------\n",
      " (0.6331919971269362, 0.20284294303687483)\n",
      "隐藏层vs神经元数vs norm 1 520 0.05\n",
      "验证集最优结果： 6.074187755584717 6.052119255065918\n",
      "------------train------------\n",
      " (0.6050256541451697, 0.15450624315161904)\n",
      "------------test------------\n",
      " (0.6045813901843216, 0.18730846102598264)\n",
      "------------oot------------\n",
      " (0.6082959719181177, 0.16144301949744555)\n",
      "隐藏层vs神经元数vs norm 1 520 0.1\n",
      "验证集最优结果： 11.362525939941406 11.317468643188477\n",
      "------------train------------\n",
      " (0.5795075459937098, 0.11633939950146838)\n",
      "------------test------------\n",
      " (0.5752886964246058, 0.12787030868310023)\n",
      "------------oot------------\n",
      " (0.5795537483057033, 0.12375490911618531)\n",
      "隐藏层vs神经元数vs norm 1 520 0.2\n",
      "验证集最优结果： 21.886587142944336 21.7330265045166\n",
      "------------train------------\n",
      " (0.4951845602721824, 0.025147762597129364)\n",
      "------------test------------\n",
      " (0.4904019542527205, 0.04187208527648234)\n",
      "------------oot------------\n",
      " (0.46509111551338644, 0.004295693879678875)\n",
      "隐藏层vs神经元数vs norm 1 520 0.3\n",
      "验证集最优结果： 32.38996887207031 32.17208480834961\n",
      "------------train------------\n",
      " (0.4752232597582872, 0.0028730206106234446)\n",
      "------------test------------\n",
      " (0.4701676660004442, 0.007617144126138132)\n",
      "------------oot------------\n",
      " (0.4659565101541955, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 1 520 0.4\n",
      "验证集最优结果： 43.15199661254883 42.84825897216797\n",
      "------------train------------\n",
      " (0.5302096256004072, 0.05581294300861095)\n",
      "------------test------------\n",
      " (0.5207861425716189, 0.0584499222740395)\n",
      "------------oot------------\n",
      " (0.5565785053116925, 0.09650019115142666)\n",
      "隐藏层vs神经元数vs norm 1 520 0.5\n",
      "验证集最优结果： 53.6984748840332 53.31800079345703\n",
      "------------train------------\n",
      " (0.5337679749908463, 0.06075602742127284)\n",
      "------------test------------\n",
      " (0.5363113479902287, 0.07372862536087055)\n",
      "------------oot------------\n",
      " (0.5469398394328016, 0.08409272581934452)\n",
      "隐藏层vs神经元数vs norm 1 520 0.8\n",
      "验证集最优结果： 85.55328369140625 84.91048431396484\n",
      "------------train------------\n",
      " (0.5751562564507604, 0.1186233324467239)\n",
      "------------test------------\n",
      " (0.5169731290250944, 0.05751721074838989)\n",
      "------------oot------------\n",
      " (0.5463617511787672, 0.0936920029194036)\n",
      "隐藏层vs神经元数vs norm 1 550 0.01\n",
      "验证集最优结果： 1.7832752466201782 1.7744073867797852\n",
      "------------train------------\n",
      " (0.6137513121481057, 0.16728587198036737)\n",
      "------------test------------\n",
      " (0.6034621363535422, 0.1624805685098823)\n",
      "------------oot------------\n",
      " (0.6248786478063926, 0.19201334584506308)\n",
      "隐藏层vs神经元数vs norm 1 550 0.05\n",
      "验证集最优结果： 6.382741928100586 6.355319976806641\n",
      "------------train------------\n",
      " (0.6060142574916804, 0.14930502680470698)\n",
      "------------test------------\n",
      " (0.5993482123029092, 0.19112813679769047)\n",
      "------------oot------------\n",
      " (0.5981116556030538, 0.1473186668056859)\n",
      "隐藏层vs神经元数vs norm 1 550 0.1\n",
      "验证集最优结果： 11.956807136535645 11.891739845275879\n",
      "------------train------------\n",
      " (0.5573273531189363, 0.0882013943455977)\n",
      "------------test------------\n",
      " (0.5622629358205641, 0.11966466799911168)\n",
      "------------oot------------\n",
      " (0.5721208540414046, 0.11614360685364752)\n",
      "隐藏层vs神经元数vs norm 1 550 0.2\n",
      "验证集最优结果： 23.07048988342285 22.952844619750977\n",
      "------------train------------\n",
      " (0.5149805859608443, 0.044968288485109364)\n",
      "------------test------------\n",
      " (0.5182433932933599, 0.04736842105263156)\n",
      "------------oot------------\n",
      " (0.499764825820503, 0.03159906857122996)\n",
      "隐藏层vs神经元数vs norm 1 550 0.3\n",
      "验证集最优结果： 34.24516296386719 34.036102294921875\n",
      "------------train------------\n",
      " (0.5405839710491567, 0.07150633587336785)\n",
      "------------test------------\n",
      " (0.549290473017988, 0.10929380413057965)\n",
      "------------oot------------\n",
      " (0.5389798306282509, 0.09246168282765088)\n",
      "隐藏层vs神经元数vs norm 1 550 0.4\n",
      "验证集最优结果： 45.08992004394531 44.845455169677734\n",
      "------------train------------\n",
      " (0.49211073277930395, 0.016409583774100067)\n",
      "------------test------------\n",
      " (0.4752642682656007, 0.025705085498556546)\n",
      "------------oot------------\n",
      " (0.49615611858339415, 0.036687172001529156)\n",
      "隐藏层vs神经元数vs norm 1 550 0.5\n",
      "验证集最优结果： 56.9376220703125 56.59333419799805\n",
      "------------train------------\n",
      " (0.5200742586151702, 0.036857774989357384)\n",
      "------------test------------\n",
      " (0.5100710637352875, 0.04411503442149678)\n",
      "------------oot------------\n",
      " (0.5333692466316802, 0.0706356653807389)\n",
      "隐藏层vs神经元数vs norm 1 550 0.8\n",
      "验证集最优结果： 89.18677520751953 88.79531860351562\n",
      "------------train------------\n",
      " (0.5756833491366387, 0.11313623532103045)\n",
      "------------test------------\n",
      " (0.5458838552076394, 0.09292693759715745)\n",
      "------------oot------------\n",
      " (0.5771417648489904, 0.12641017620686068)\n",
      "隐藏层vs神经元数vs norm 1 580 0.01\n",
      "验证集最优结果： 1.8613715171813965 1.8534507751464844\n",
      "------------train------------\n",
      " (0.6247628658194471, 0.17746753215989564)\n",
      "------------test------------\n",
      " (0.6134599156118143, 0.169231623362203)\n",
      "------------oot------------\n",
      " (0.6292739721266465, 0.19980537309283009)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 1 580 0.05\n",
      "验证集最优结果： 6.696259021759033 6.673657417297363\n",
      "------------train------------\n",
      " (0.5968869180441261, 0.14836806338106812)\n",
      "------------test------------\n",
      " (0.5845103264490339, 0.1571729957805908)\n",
      "------------oot------------\n",
      " (0.5791946153222349, 0.14990442428665757)\n",
      "隐藏层vs神经元数vs norm 1 580 0.1\n",
      "验证集最优结果： 12.670464515686035 12.63931655883789\n",
      "------------train------------\n",
      " (0.5893278620733531, 0.13801002883849423)\n",
      "------------test------------\n",
      " (0.5786364645791695, 0.1380524095047746)\n",
      "------------oot------------\n",
      " (0.6041369802708558, 0.15867653703124457)\n",
      "隐藏层vs神经元数vs norm 1 580 0.2\n",
      "验证集最优结果： 24.383312225341797 24.26953125\n",
      "------------train------------\n",
      " (0.5554982305035603, 0.10138114797646625)\n",
      "------------test------------\n",
      " (0.5578147901399068, 0.09957805907172995)\n",
      "------------oot------------\n",
      " (0.579216626698641, 0.15055781461787088)\n",
      "隐藏层vs神经元数vs norm 1 580 0.3\n",
      "验证集最优结果： 36.385826110839844 36.304744720458984\n",
      "------------train------------\n",
      " (0.5360385072745965, 0.05715706996566583)\n",
      "------------test------------\n",
      " (0.5271474572507218, 0.07801465689540305)\n",
      "------------oot------------\n",
      " (0.5488594631541144, 0.10059430716296525)\n",
      "隐藏层vs神经元数vs norm 1 580 0.4\n",
      "验证集最优结果： 47.70289993286133 47.474308013916016\n",
      "------------train------------\n",
      " (0.5149784201973687, 0.03603397270731934)\n",
      "------------test------------\n",
      " (0.5069165001110371, 0.048956251387963584)\n",
      "------------oot------------\n",
      " (0.5070610178523848, 0.040809091856949226)\n",
      "隐藏层vs神经元数vs norm 1 580 0.5\n",
      "验证集最优结果： 59.11503982543945 58.83409118652344\n",
      "------------train------------\n",
      " (0.4870643685208986, 0.009156035813606245)\n",
      "------------test------------\n",
      " (0.48288030202087495, 0.023373306684432604)\n",
      "------------oot------------\n",
      " (0.4644133968187768, 0.0013276335453376031)\n",
      "隐藏层vs神经元数vs norm 1 580 0.8\n",
      "验证集最优结果： 95.50299835205078 94.7826919555664\n",
      "------------train------------\n",
      " (0.543573672167029, 0.07038311679082576)\n",
      "------------test------------\n",
      " (0.534433710859427, 0.08475460803908508)\n",
      "------------oot------------\n",
      " (0.5583440493981626, 0.10224168491293917)\n",
      "隐藏层vs神经元数vs norm 1 610 0.01\n",
      "验证集最优结果： 1.9180811643600464 1.9144583940505981\n",
      "------------train------------\n",
      " (0.6409983086740858, 0.19964075398348202)\n",
      "------------test------------\n",
      " (0.6164645791694426, 0.1890406395736176)\n",
      "------------oot------------\n",
      " (0.6192240410570095, 0.18474959163104293)\n",
      "隐藏层vs神经元数vs norm 1 610 0.05\n",
      "验证集最优结果： 6.980588436126709 6.956543445587158\n",
      "------------train------------\n",
      " (0.6021453240828161, 0.1573477248316288)\n",
      "------------test------------\n",
      " (0.5882222962469466, 0.15548523206751058)\n",
      "------------oot------------\n",
      " (0.5689477403584379, 0.12433878983769509)\n",
      "隐藏层vs神经元数vs norm 1 610 0.1\n",
      "验证集最优结果： 13.351402282714844 13.309065818786621\n",
      "------------train------------\n",
      " (0.5932312446575014, 0.13478737278677588)\n",
      "------------test------------\n",
      " (0.583353320008883, 0.13126804352653787)\n",
      "------------oot------------\n",
      " (0.6282730337469155, 0.2003127932436659)\n",
      "隐藏层vs神经元数vs norm 1 610 0.2\n",
      "验证集最优结果： 25.744779586791992 25.719375610351562\n",
      "------------train------------\n",
      " (0.5410752609575787, 0.06755435897123518)\n",
      "------------test------------\n",
      " (0.536714412613813, 0.0739062846990895)\n",
      "------------oot------------\n",
      " (0.5366894889885193, 0.08125673374344)\n",
      "隐藏层vs神经元数vs norm 1 610 0.3\n",
      "验证集最优结果： 37.69318771362305 37.54328536987305\n",
      "------------train------------\n",
      " (0.5424095742988848, 0.07083549063679534)\n",
      "------------test------------\n",
      " (0.5051776593382189, 0.04500333111259153)\n",
      "------------oot------------\n",
      " (0.5447966264669424, 0.09178048865255617)\n",
      "隐藏层vs神经元数vs norm 1 610 0.4\n",
      "验证集最优结果： 50.425296783447266 50.13446807861328\n",
      "------------train------------\n",
      " (0.512607924393197, 0.03588818975336683)\n",
      "------------test------------\n",
      " (0.5134365978236731, 0.03872973573173438)\n",
      "------------oot------------\n",
      " (0.542669632410014, 0.08146526257255071)\n",
      "隐藏层vs神经元数vs norm 1 610 0.5\n",
      "验证集最优结果： 62.889156341552734 62.45281982421875\n",
      "------------train------------\n",
      " (0.5356519184941988, 0.060050665329307695)\n",
      "------------test------------\n",
      " (0.5418310015545191, 0.09631356873195651)\n",
      "------------oot------------\n",
      " (0.5185312619469642, 0.05010947763528306)\n",
      "隐藏层vs神经元数vs norm 1 610 0.8\n",
      "验证集最优结果： 99.1720962524414 98.61137390136719\n",
      "------------train------------\n",
      " (0.5626088380746633, 0.09532472577711992)\n",
      "------------test------------\n",
      " (0.5172818121252498, 0.06049300466355767)\n",
      "------------oot------------\n",
      " (0.567849488525122, 0.12456817154971678)\n",
      "隐藏层vs神经元数vs norm 1 640 0.01\n",
      "验证集最优结果： 1.9542675018310547 1.9486849308013916\n",
      "------------train------------\n",
      " (0.644695334607073, 0.21602854476260863)\n",
      "------------test------------\n",
      " (0.6085232067510549, 0.1747279591383522)\n",
      "------------oot------------\n",
      " (0.6294071988785783, 0.19079692767525108)\n",
      "隐藏层vs神经元数vs norm 1 640 0.05\n",
      "验证集最优结果： 7.3397417068481445 7.312418460845947\n",
      "------------train------------\n",
      " (0.5981712157851671, 0.1480330468434336)\n",
      "------------test------------\n",
      " (0.5911025982678214, 0.15288696424605824)\n",
      "------------oot------------\n",
      " (0.5805407847634936, 0.13831022138810684)\n",
      "隐藏层vs神经元数vs norm 1 640 0.1\n",
      "验证集最优结果： 13.97829818725586 13.931146621704102\n",
      "------------train------------\n",
      " (0.5968972054206353, 0.14567453041848644)\n",
      "------------test------------\n",
      " (0.5839307128580946, 0.1447257383966245)\n",
      "------------oot------------\n",
      " (0.6069891912556911, 0.17472630591179228)\n",
      "隐藏层vs神经元数vs norm 1 640 0.2\n",
      "验证集最优结果： 26.63821029663086 26.531591415405273\n",
      "------------train------------\n",
      " (0.5447454855675552, 0.08156996194347493)\n",
      "------------test------------\n",
      " (0.5327814790139906, 0.06656673328891849)\n",
      "------------oot------------\n",
      " (0.5226010495951066, 0.05212525631668574)\n",
      "隐藏层vs神经元数vs norm 1 640 0.3\n",
      "验证集最优结果： 40.020599365234375 39.97540283203125\n",
      "------------train------------\n",
      " (0.5731532636363574, 0.11699170038828072)\n",
      "------------test------------\n",
      " (0.5449067288474351, 0.09199422607150787)\n",
      "------------oot------------\n",
      " (0.5619319037523605, 0.11757550481354051)\n",
      "隐藏层vs神经元数vs norm 1 640 0.4\n",
      "验证集最优结果： 52.50224685668945 52.15907287597656\n",
      "------------train------------\n",
      " (0.4837983971996678, 0.012112844398692646)\n",
      "------------test------------\n",
      " (0.4699544747945814, 0.014867865867199681)\n",
      "------------oot------------\n",
      " (0.4897056268029055, 0.022145761651548357)\n",
      "隐藏层vs神经元数vs norm 1 640 0.5\n",
      "验证集最优结果： 66.1335220336914 65.71417999267578\n",
      "------------train------------\n",
      " (0.49048830521563214, 0.015348495031264786)\n",
      "------------test------------\n",
      " (0.5015811681101487, 0.03037974683544306)\n",
      "------------oot------------\n",
      " (0.4794008271643555, 0.018399193688527438)\n",
      "隐藏层vs神经元数vs norm 1 640 0.8\n",
      "验证集最优结果： 105.35110473632812 104.65816497802734\n",
      "------------train------------\n",
      " (0.5111878603542782, 0.04020753428505097)\n",
      "------------test------------\n",
      " (0.49400621807683764, 0.02770375305351991)\n",
      "------------oot------------\n",
      " (0.47683244708580963, 0.0018628575400549963)\n",
      "隐藏层vs神经元数vs norm 1 670 0.01\n",
      "验证集最优结果： 2.0327818393707275 2.0276715755462646\n",
      "------------train------------\n",
      " (0.633964788746693, 0.20625973324561986)\n",
      "------------test------------\n",
      " (0.6197068620919387, 0.18596491228070178)\n",
      "------------oot------------\n",
      " (0.6191742258367219, 0.19222187467417373)\n",
      "隐藏层vs神经元数vs norm 1 670 0.05\n",
      "验证集最优结果： 7.627264022827148 7.603226184844971\n",
      "------------train------------\n",
      " (0.5984916810994498, 0.1541919367272201)\n",
      "------------test------------\n",
      " (0.585946035976016, 0.12964690206528984)\n",
      "------------oot------------\n",
      " (0.5810539973818047, 0.14362770653042778)\n",
      "隐藏层vs神经元数vs norm 1 670 0.1\n",
      "验证集最优结果： 14.404555320739746 14.342350006103516\n",
      "------------train------------\n",
      " (0.5734806323217188, 0.11210451974533331)\n",
      "------------test------------\n",
      " (0.5646224739062846, 0.12199644681323557)\n",
      "------------oot------------\n",
      " (0.5677197372536753, 0.10414624821881624)\n",
      "隐藏层vs神经元数vs norm 1 670 0.2\n",
      "验证集最优结果： 28.012304306030273 27.827102661132812\n",
      "------------train------------\n",
      " (0.47962591850367403, 0.02066977589085628)\n",
      "------------test------------\n",
      " (0.49417610481900953, 0.024628025760604036)\n",
      "------------oot------------\n",
      " (0.46813100244442124, 0.0032600006950961324)\n",
      "隐藏层vs神经元数vs norm 1 670 0.3\n",
      "验证集最优结果： 41.61225891113281 41.3443717956543\n",
      "------------train------------\n",
      " (0.5494770019606928, 0.07903155178983434)\n",
      "------------test------------\n",
      " (0.5559848989562515, 0.10561847657117479)\n",
      "------------oot------------\n",
      " (0.566083944438652, 0.1107983178674452)\n",
      "隐藏层vs神经元数vs norm 1 670 0.4\n",
      "验证集最优结果： 55.38264846801758 54.99295425415039\n",
      "------------train------------\n",
      " (0.5094511210871591, 0.021610935481229276)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.513664223850766, 0.058338885187652734)\n",
      "------------oot------------\n",
      " (0.513916982356144, 0.04949779306989194)\n",
      "隐藏层vs神经元数vs norm 1 670 0.5\n",
      "验证集最优结果： 69.34452819824219 68.83586883544922\n",
      "------------train------------\n",
      " (0.5337593796170524, 0.0537105281146556)\n",
      "------------test------------\n",
      " (0.5377836997557184, 0.06590051077059744)\n",
      "------------oot------------\n",
      " (0.5494166985252378, 0.08227157404511173)\n",
      "隐藏层vs神经元数vs norm 1 670 0.8\n",
      "验证集最优结果： 109.93346405029297 109.04301452636719\n",
      "------------train------------\n",
      " (0.5336323440531857, 0.06858296126193619)\n",
      "------------test------------\n",
      " (0.5168110148789695, 0.06337996890961584)\n",
      "------------oot------------\n",
      " (0.5581760678413791, 0.10913008723456019)\n",
      "隐藏层vs神经元数vs norm 1 700 0.01\n",
      "验证集最优结果： 2.113158941268921 2.107915163040161\n",
      "------------train------------\n",
      " (0.6148364273294986, 0.17065742427103447)\n",
      "------------test------------\n",
      " (0.6059427048634245, 0.16351321341328)\n",
      "------------oot------------\n",
      " (0.6243677521750715, 0.1829423417787509)\n",
      "隐藏层vs神经元数vs norm 1 700 0.05\n",
      "验证集最优结果： 8.00577449798584 7.980121612548828\n",
      "------------train------------\n",
      " (0.609477380969301, 0.15385692018958558)\n",
      "------------test------------\n",
      " (0.5881045969353764, 0.15330890517432827)\n",
      "------------oot------------\n",
      " (0.6136632722807261, 0.17741632780731936)\n",
      "隐藏层vs神经元数vs norm 1 700 0.1\n",
      "验证集最优结果： 14.993877410888672 14.925186157226562\n",
      "------------train------------\n",
      " (0.5821578990469964, 0.12198879352761594)\n",
      "------------test------------\n",
      " (0.5783733066844325, 0.1448034643570953)\n",
      "------------oot------------\n",
      " (0.5734484875867422, 0.11971640079240958)\n",
      "隐藏层vs神经元数vs norm 1 700 0.2\n",
      "验证集最优结果： 29.178211212158203 29.021055221557617\n",
      "------------train------------\n",
      " (0.5115751259357622, 0.04144824603614522)\n",
      "------------test------------\n",
      " (0.5190706195869421, 0.04287141905396408)\n",
      "------------oot------------\n",
      " (0.47916565298485847, 0.01860772251763798)\n",
      "隐藏层vs神经元数vs norm 1 700 0.3\n",
      "验证集最优结果： 43.153541564941406 42.93148422241211\n",
      "------------train------------\n",
      " (0.483507846493392, 0.006119500060573713)\n",
      "------------test------------\n",
      " (0.4878425494115034, 0.020708416611148084)\n",
      "------------oot------------\n",
      " (0.4896673965175686, 0.020289855072463836)\n",
      "隐藏层vs神经元数vs norm 1 700 0.4\n",
      "验证集最优结果： 58.138710021972656 58.08620071411133\n",
      "------------train------------\n",
      " (0.4966178219322806, 0.0107650627157726)\n",
      "------------test------------\n",
      " (0.47098156784365974, 0.012780368643126804)\n",
      "------------oot------------\n",
      " (0.4972485779492348, 0.03420567893511278)\n",
      "隐藏层vs神经元数vs norm 1 700 0.5\n",
      "验证集最优结果： 72.26597595214844 71.81839752197266\n",
      "------------train------------\n",
      " (0.4961145526446341, 0.009690167230780422)\n",
      "------------test------------\n",
      " (0.511013768598712, 0.03931823228958464)\n",
      "------------oot------------\n",
      " (0.4989897936723085, 0.02958328988982728)\n",
      "隐藏层vs神经元数vs norm 1 700 0.8\n",
      "验证集最优结果： 115.4096908569336 114.56771087646484\n",
      "------------train------------\n",
      " (0.5543115951592479, 0.09312282112350334)\n",
      "------------test------------\n",
      " (0.5255496335776149, 0.08215634021763271)\n",
      "------------oot------------\n",
      " (0.5543437713597238, 0.09710492475584748)\n",
      "隐藏层vs神经元数vs norm 1 730 0.01\n",
      "验证集最优结果： 2.1586883068084717 2.153660535812378\n",
      "------------train------------\n",
      " (0.6424449033155808, 0.20725097611636645)\n",
      "------------test------------\n",
      " (0.6051165889407062, 0.1671774372640462)\n",
      "------------oot------------\n",
      " (0.6284097359793324, 0.18130886595071768)\n",
      "隐藏层vs神经元数vs norm 1 730 0.05\n",
      "验证集最优结果： 8.241775512695312 8.217780113220215\n",
      "------------train------------\n",
      " (0.6033653257206747, 0.14310200949010488)\n",
      "------------test------------\n",
      " (0.5802220741727737, 0.1411170330890517)\n",
      "------------oot------------\n",
      " (0.597488386102712, 0.15730719772008483)\n",
      "隐藏层vs神经元数vs norm 1 730 0.1\n",
      "验证集最优结果： 15.849562644958496 15.797046661376953\n",
      "------------train------------\n",
      " (0.5732108594087871, 0.11585277952054057)\n",
      "------------test------------\n",
      " (0.5675471907617144, 0.12111925383077948)\n",
      "------------oot------------\n",
      " (0.5857980282440713, 0.1546171758245578)\n",
      "隐藏层vs神经元数vs norm 1 730 0.2\n",
      "验证集最优结果： 30.32061004638672 30.16685676574707\n",
      "------------train------------\n",
      " (0.46099155419924615, 0.003148884733330193)\n",
      "------------test------------\n",
      " (0.47020319786808795, 0.008116811014878971)\n",
      "------------oot------------\n",
      " (0.45293851875021723, 0.006603412921836416)\n",
      "隐藏层vs神经元数vs norm 1 730 0.3\n",
      "验证集最优结果： 45.08806228637695 44.83527755737305\n",
      "------------train------------\n",
      " (0.4664816969298272, 0.0054356602431474554)\n",
      "------------test------------\n",
      " (0.4609993337774817, 0.016311347990228736)\n",
      "------------oot------------\n",
      " (0.4253385697239309, 0.017043756299308432)\n",
      "隐藏层vs神经元数vs norm 1 730 0.4\n",
      "验证集最优结果： 60.45952606201172 60.000244140625\n",
      "------------train------------\n",
      " (0.5118092991115633, 0.024815859344491042)\n",
      "------------test------------\n",
      " (0.5123584277148567, 0.05664001776593386)\n",
      "------------oot------------\n",
      " (0.5133724904134663, 0.04264414555312271)\n",
      "隐藏层vs神经元数vs norm 1 730 0.5\n",
      "验证集最优结果： 74.46192169189453 74.08618927001953\n",
      "------------train------------\n",
      " (0.4729732345474468, 0.013878347711972383)\n",
      "------------test------------\n",
      " (0.4624539196091495, 0.008971796580057739)\n",
      "------------oot------------\n",
      " (0.4850473244592731, 0.017182775518715443)\n",
      "隐藏层vs神经元数vs norm 1 730 0.8\n",
      "验证集最优结果： 119.6828384399414 118.64151763916016\n",
      "------------train------------\n",
      " (0.5530771776582547, 0.08843786864509151)\n",
      "------------test------------\n",
      " (0.5095403064623584, 0.047279591383522)\n",
      "------------oot------------\n",
      " (0.545319107033214, 0.08900010426441451)\n",
      "隐藏层vs神经元数vs norm 1 760 0.01\n",
      "验证集最优结果： 2.2210443019866943 2.2158448696136475\n",
      "------------train------------\n",
      " (0.6407725278317526, 0.2078006739585216)\n",
      "------------test------------\n",
      " (0.6056850988230069, 0.1636242504996669)\n",
      "------------oot------------\n",
      " (0.6281629768648849, 0.19051888923643692)\n",
      "隐藏层vs神经元数vs norm 1 760 0.05\n",
      "验证集最优结果： 8.56320571899414 8.536408424377441\n",
      "------------train------------\n",
      " (0.5981006254318837, 0.15559007241094824)\n",
      "------------test------------\n",
      " (0.5811669997779259, 0.12238507661558962)\n",
      "------------oot------------\n",
      " (0.57222975242994, 0.1400549125916657)\n",
      "隐藏层vs神经元数vs norm 1 760 0.1\n",
      "验证集最优结果： 16.277999877929688 16.2098445892334\n",
      "------------train------------\n",
      " (0.5486282257185766, 0.0908368577749894)\n",
      "------------test------------\n",
      " (0.557735953808572, 0.09472573839662451)\n",
      "------------oot------------\n",
      " (0.5416895469131939, 0.09507524415250412)\n",
      "隐藏层vs神经元数vs norm 1 760 0.2\n",
      "验证集最优结果： 31.56413459777832 31.381261825561523\n",
      "------------train------------\n",
      " (0.48516932547973357, 0.009894967239443386)\n",
      "------------test------------\n",
      " (0.5022529424827893, 0.039806795469686906)\n",
      "------------oot------------\n",
      " (0.48894102109616655, 0.025593438292843995)\n",
      "隐藏层vs神经元数vs norm 1 760 0.3\n",
      "验证集最优结果： 46.95069122314453 46.63997268676758\n",
      "------------train------------\n",
      " (0.5070026577978652, 0.028309912631747813)\n",
      "------------test------------\n",
      " (0.4749789029535865, 0.012502775927159648)\n",
      "------------oot------------\n",
      " (0.4769123831369687, 0.008521878149654105)\n",
      "隐藏层vs神经元数vs norm 1 760 0.4\n",
      "验证集最优结果： 62.41276931762695 62.04131317138672\n",
      "------------train------------\n",
      " (0.5024712038057879, 0.013211834002351208)\n",
      "------------test------------\n",
      " (0.4822340661781035, 0.009182767044192741)\n",
      "------------oot------------\n",
      " (0.48142123981973833, 0.014603968998714079)\n",
      "隐藏层vs神经元数vs norm 1 760 0.5\n",
      "验证集最优结果： 77.83195495605469 77.43103790283203\n",
      "------------train------------\n",
      " (0.5060055944377779, 0.032109067848632045)\n",
      "------------test------------\n",
      " (0.493217854763491, 0.02287363979569179)\n",
      "------------oot------------\n",
      " (0.4982807956533324, 0.03127932436659375)\n",
      "隐藏层vs神经元数vs norm 1 760 0.8\n",
      "验证集最优结果： 123.79435729980469 123.14787292480469\n",
      "------------train------------\n",
      " (0.5651050158405294, 0.10587212926359307)\n",
      "------------test------------\n",
      " (0.5351210304241616, 0.07121918720852766)\n",
      "------------oot------------\n",
      " (0.5733755024965534, 0.1274875751572655)\n",
      "隐藏层vs神经元数vs norm 1 790 0.01\n",
      "验证集最优结果： 2.273510217666626 2.2676644325256348\n",
      "------------train------------\n",
      " (0.632400295355994, 0.19579435805078582)\n",
      "------------test------------\n",
      " (0.5956406839884522, 0.14400399733510988)\n",
      "------------oot------------\n",
      " (0.6258112350699151, 0.18335939943697216)\n",
      "隐藏层vs神经元数vs norm 1 790 0.05\n",
      "验证集最优结果： 8.867762565612793 8.829039573669434\n",
      "------------train------------\n",
      " (0.5757210469571361, 0.11293847404366314)\n",
      "------------test------------\n",
      " (0.5737008660892737, 0.15226515656229178)\n",
      "------------oot------------\n",
      " (0.5589800623269501, 0.10906752858582702)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 1 790 0.1\n",
      "验证集最优结果： 16.840370178222656 16.77278709411621\n",
      "------------train------------\n",
      " (0.5978355224464464, 0.13978757921110707)\n",
      "------------test------------\n",
      " (0.5829868976238064, 0.16088163446591158)\n",
      "------------oot------------\n",
      " (0.5969890754063416, 0.15226080005560766)\n",
      "隐藏层vs神经元数vs norm 1 790 0.2\n",
      "验证集最优结果： 32.75845718383789 32.62289047241211\n",
      "------------train------------\n",
      " (0.46434652486330313, 0.004654361069318602)\n",
      "------------test------------\n",
      " (0.4579991117033089, 0.008971796580057739)\n",
      "------------oot------------\n",
      " (0.43188637495800464, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 1 790 0.3\n",
      "验证集最优结果： 48.86310958862305 48.58615493774414\n",
      "------------train------------\n",
      " (0.5150528683168432, 0.03447083291879266)\n",
      "------------test------------\n",
      " (0.4933422163002442, 0.031045969353764136)\n",
      "------------oot------------\n",
      " (0.4982321389265399, 0.04064226879366073)\n",
      "隐藏层vs神经元数vs norm 1 790 0.4\n",
      "验证集最优结果： 64.9920883178711 64.52021789550781\n",
      "------------train------------\n",
      " (0.5209589729949599, 0.03950515011786493)\n",
      "------------test------------\n",
      " (0.4871141461248057, 0.03185654008438821)\n",
      "------------oot------------\n",
      " (0.4817247651154438, 0.010669725089493626)\n",
      "隐藏层vs神经元数vs norm 1 790 0.5\n",
      "验证集最优结果： 80.86314392089844 80.38146209716797\n",
      "------------train------------\n",
      " (0.4841710438776912, 0.02087863670603618)\n",
      "------------test------------\n",
      " (0.46292804796802134, 0.0032089717965800846)\n",
      "------------oot------------\n",
      " (0.4765671520754411, 0.015910749661140658)\n",
      "隐藏层vs神经元数vs norm 1 790 0.8\n",
      "验证集最优结果： 130.5668487548828 129.72898864746094\n",
      "------------train------------\n",
      " (0.5417993704396298, 0.07648068849620893)\n",
      "------------test------------\n",
      " (0.512702642682656, 0.047723739729069514)\n",
      "------------oot------------\n",
      " (0.5239298416339392, 0.07184513258958047)\n",
      "隐藏层vs神经元数vs norm 1 820 0.01\n",
      "验证集最优结果： 2.364158868789673 2.360187530517578\n",
      "------------train------------\n",
      " (0.6415480065162409, 0.20445578763064798)\n",
      "------------test------------\n",
      " (0.60545636242505, 0.17584943371085937)\n",
      "------------oot------------\n",
      " (0.6289229485976436, 0.18397803496333365)\n",
      "隐藏层vs神经元数vs norm 1 820 0.05\n",
      "验证集最优结果： 9.181931495666504 9.14997386932373\n",
      "------------train------------\n",
      " (0.5939624605509567, 0.14246134958197376)\n",
      "------------test------------\n",
      " (0.5796135909393737, 0.1278481012658228)\n",
      "------------oot------------\n",
      " (0.5792560154774731, 0.14686685434261293)\n",
      "隐藏层vs神经元数vs norm 1 820 0.1\n",
      "验证集最优结果： 17.68393898010254 17.625743865966797\n",
      "------------train------------\n",
      " (0.5785079107894953, 0.12357900535958788)\n",
      "------------test------------\n",
      " (0.5878092382855874, 0.15011103708638684)\n",
      "------------oot------------\n",
      " (0.6030572643334607, 0.1738991415563202)\n",
      "隐藏层vs神经元数vs norm 1 820 0.2\n",
      "验证集最优结果： 33.79866409301758 33.65523147583008\n",
      "------------train------------\n",
      " (0.5012028785703795, 0.022595004260462792)\n",
      "------------test------------\n",
      " (0.4922906950921608, 0.015756162558294484)\n",
      "------------oot------------\n",
      " (0.46481886954204754, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 1 820 0.3\n",
      "验证集最优结果： 50.59196090698242 50.32416534423828\n",
      "------------train------------\n",
      " (0.46435972248448265, 0.002647375128507606)\n",
      "------------test------------\n",
      " (0.4692771485676216, 0.0054630246502331775)\n",
      "------------oot------------\n",
      " (0.455819692072429, 0.00959232613908878)\n",
      "隐藏层vs神经元数vs norm 1 820 0.4\n",
      "验证集最优结果： 67.10331726074219 66.77651977539062\n",
      "------------train------------\n",
      " (0.49458687723302064, 0.022218296775922686)\n",
      "------------test------------\n",
      " (0.48547523872973575, 0.021863202309571395)\n",
      "------------oot------------\n",
      " (0.48612124792919287, 0.012296249956556426)\n",
      "隐藏层vs神经元数vs norm 1 820 0.5\n",
      "验证集最优结果： 84.73190307617188 84.1480484008789\n",
      "------------train------------\n",
      " (0.4904005241147611, 0.021989131928158878)\n",
      "------------test------------\n",
      " (0.5069620253164557, 0.03353320008882976)\n",
      "------------oot------------\n",
      " (0.4874083342022035, 0.017085462065130508)\n",
      "隐藏层vs神经元数vs norm 1 820 0.8\n",
      "验证集最优结果： 135.2980499267578 134.36355590820312\n",
      "------------train------------\n",
      " (0.5902955522663023, 0.13531636051569534)\n",
      "------------test------------\n",
      " (0.5657195203197868, 0.11451254719076165)\n",
      "------------oot------------\n",
      " (0.569638202481493, 0.12273311785354324)\n",
      "隐藏层vs神经元数vs norm 1 850 0.01\n",
      "验证集最优结果： 2.424269676208496 2.419238567352295\n",
      "------------train------------\n",
      " (0.6557508126689042, 0.23019074285010413)\n",
      "------------test------------\n",
      " (0.6223673106817676, 0.18864090606262493)\n",
      "------------oot------------\n",
      " (0.6328780453897751, 0.20148055468668546)\n",
      "隐藏层vs神经元数vs norm 1 850 0.05\n",
      "验证集最优结果： 9.536011695861816 9.503057479858398\n",
      "------------train------------\n",
      " (0.5946650477584686, 0.1427382965864184)\n",
      "------------test------------\n",
      " (0.595625138796358, 0.1590828336664446)\n",
      "------------oot------------\n",
      " (0.6074166753553678, 0.18146873805303582)\n",
      "隐藏层vs神经元数vs norm 1 850 0.1\n",
      "验证集最优结果： 18.33151626586914 18.265268325805664\n",
      "------------train------------\n",
      " (0.5704564143484537, 0.11577792532041459)\n",
      "------------test------------\n",
      " (0.5710359760159893, 0.13256717743726404)\n",
      "------------oot------------\n",
      " (0.587342300072985, 0.16541201821151774)\n",
      "隐藏层vs神经元数vs norm 1 850 0.2\n",
      "验证集最优结果： 35.206871032714844 35.00872802734375\n",
      "------------train------------\n",
      " (0.4828719241928639, 0.010064438231410455)\n",
      "------------test------------\n",
      " (0.49620031090384187, 0.022074172773706414)\n",
      "------------oot------------\n",
      " (0.4909382638816483, 0.045952802975011364)\n",
      "隐藏层vs神经元数vs norm 1 850 0.3\n",
      "验证集最优结果： 52.5963134765625 52.28872299194336\n",
      "------------train------------\n",
      " (0.5271933938799586, 0.04704227773344738)\n",
      "------------test------------\n",
      " (0.5276238063513213, 0.0690872751499001)\n",
      "------------oot------------\n",
      " (0.5054344929853218, 0.03836235359538459)\n",
      "隐藏层vs神经元数vs norm 1 850 0.4\n",
      "验证集最优结果： 69.5733642578125 69.18865966796875\n",
      "------------train------------\n",
      " (0.4705904886436162, 0.003972551655150869)\n",
      "------------test------------\n",
      " (0.4848723073506551, 0.008971796580057756)\n",
      "------------oot------------\n",
      " (0.446987337666099, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 1 850 0.5\n",
      "验证集最优结果： 86.60172271728516 86.17047119140625\n",
      "------------train------------\n",
      " (0.5277300294611513, 0.048125024111038694)\n",
      "------------test------------\n",
      " (0.5035243171219188, 0.04156118143459919)\n",
      "------------oot------------\n",
      " (0.5191475804863356, 0.04673826156466132)\n",
      "隐藏层vs神经元数vs norm 1 850 0.8\n",
      "验证集最优结果： 139.62342834472656 138.66455078125\n",
      "------------train------------\n",
      " (0.5473873109271565, 0.07795083581550133)\n",
      "------------test------------\n",
      " (0.5213146791028204, 0.06543415500777261)\n",
      "------------oot------------\n",
      " (0.5447236413767536, 0.0976331977895944)\n",
      "隐藏层vs神经元数vs norm 1 880 0.01\n",
      "验证集最优结果： 2.465801954269409 2.4600396156311035\n",
      "------------train------------\n",
      " (0.6221197545377821, 0.17772674697588353)\n",
      "------------test------------\n",
      " (0.5863735287586054, 0.13573173439928943)\n",
      "------------oot------------\n",
      " (0.6177944600841067, 0.17448997323880025)\n",
      "隐藏层vs神经元数vs norm 1 880 0.05\n",
      "验证集最优结果： 9.811251640319824 9.778759002685547\n",
      "------------train------------\n",
      " (0.5894229526259543, 0.1411441593081469)\n",
      "------------test------------\n",
      " (0.5794925605152121, 0.13881856540084386)\n",
      "------------oot------------\n",
      " (0.5603505601316049, 0.11692906544329756)\n",
      "隐藏层vs神经元数vs norm 1 880 0.1\n",
      "验证集最优结果： 18.70528221130371 18.622676849365234\n",
      "------------train------------\n",
      " (0.5718228080612424, 0.10687514847323831)\n",
      "------------test------------\n",
      " (0.5662513879635799, 0.12460581834332668)\n",
      "------------oot------------\n",
      " (0.5895828264924292, 0.14909811281409657)\n",
      "隐藏层vs神经元数vs norm 1 880 0.2\n",
      "验证集最优结果： 36.41390609741211 36.21220779418945\n",
      "------------train------------\n",
      " (0.4976746468282732, 0.01787458740513792)\n",
      "------------test------------\n",
      " (0.5063535420830557, 0.04008438818565396)\n",
      "------------oot------------\n",
      " (0.5001228003104763, 0.03308657421888572)\n",
      "隐藏层vs神经元数vs norm 1 880 0.3\n",
      "验证集最优结果： 54.60197067260742 54.218502044677734\n",
      "------------train------------\n",
      " (0.5370392930406575, 0.07207769135027908)\n",
      "------------test------------\n",
      " (0.5245125471907617, 0.05722851432378406)\n",
      "------------oot------------\n",
      " (0.5458427460929807, 0.10040663121676574)\n",
      "隐藏层vs神经元数vs norm 1 880 0.4\n",
      "验证集最优结果： 72.87187194824219 72.84342193603516\n",
      "------------train------------\n",
      " (0.5366493879349378, 0.05781126589551955)\n",
      "------------test------------\n",
      " (0.5285309793471019, 0.0780590717299578)\n",
      "------------oot------------\n",
      " (0.5598408229937788, 0.11778403364265111)\n",
      "隐藏层vs神经元数vs norm 1 880 0.5\n",
      "验证集最优结果： 90.91968536376953 90.21577453613281\n",
      "------------train------------\n",
      " (0.536804307703553, 0.05841118237826548)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.5285964912280701, 0.0705973795247612)\n",
      "------------oot------------\n",
      " (0.5278756704781102, 0.07629374761060714)\n",
      "隐藏层vs神经元数vs norm 1 880 0.8\n",
      "验证集最优结果： 145.0255889892578 144.01722717285156\n",
      "------------train------------\n",
      " (0.5603596927052349, 0.09394648804532402)\n",
      "------------test------------\n",
      " (0.521646679991117, 0.05928270042194095)\n",
      "------------oot------------\n",
      " (0.548145831161158, 0.11376637820178637)\n",
      "隐藏层vs神经元数vs norm 1 910 0.01\n",
      "验证集最优结果： 2.533703327178955 2.528846025466919\n",
      "------------train------------\n",
      " (0.6261438107555874, 0.18852321326205262)\n",
      "------------test------------\n",
      " (0.5894936708860758, 0.13758605374194988)\n",
      "------------oot------------\n",
      " (0.6211297628563816, 0.16961039863761168)\n",
      "隐藏层vs神经元数vs norm 1 910 0.05\n",
      "验证集最优结果： 10.113536834716797 10.073140144348145\n",
      "------------train------------\n",
      " (0.592311878062102, 0.14925480816411607)\n",
      "------------test------------\n",
      " (0.5896313568731957, 0.14753497668221188)\n",
      "------------oot------------\n",
      " (0.5730777696683234, 0.13625273694088208)\n",
      "隐藏层vs神经元数vs norm 1 910 0.1\n",
      "验证集最优结果： 19.37594223022461 19.287874221801758\n",
      "------------train------------\n",
      " (0.5772800582590375, 0.1293328974734339)\n",
      "------------test------------\n",
      " (0.583850766155896, 0.13989562513879628)\n",
      "------------oot------------\n",
      " (0.5859972891252215, 0.15111389149549925)\n",
      "隐藏层vs神经元数vs norm 1 910 0.2\n",
      "验证集最优结果： 37.6708869934082 37.480098724365234\n",
      "------------train------------\n",
      " (0.4457849843557429, 0.002739013995569639)\n",
      "------------test------------\n",
      " (0.4588363313346657, 0.010859427048634185)\n",
      "------------oot------------\n",
      " (0.45088103430299237, 0.007194244604316502)\n",
      "隐藏层vs神经元数vs norm 1 910 0.3\n",
      "验证集最优结果： 55.76789093017578 55.48876190185547\n",
      "------------train------------\n",
      " (0.48814285105164734, 0.014747360306563873)\n",
      "------------test------------\n",
      " (0.48598156784365976, 0.0166999777925827)\n",
      "------------oot------------\n",
      " (0.4688735967747541, 0.021339450178987196)\n",
      "隐藏层vs神经元数vs norm 1 910 0.4\n",
      "验证集最优结果： 75.16616821289062 74.59911346435547\n",
      "------------train------------\n",
      " (0.5471081304791279, 0.07749954485126953)\n",
      "------------test------------\n",
      " (0.5206173662003108, 0.057172995780590735)\n",
      "------------oot------------\n",
      " (0.5384318632050882, 0.07659958989330273)\n",
      "隐藏层vs神经元数vs norm 1 910 0.5\n",
      "验证集最优结果： 94.25023651123047 94.21479797363281\n",
      "------------train------------\n",
      " (0.500856153373955, 0.012160761915590734)\n",
      "------------test------------\n",
      " (0.48700644015101047, 0.015112147457250723)\n",
      "------------oot------------\n",
      " (0.4896233737647563, 0.019010878253918617)\n",
      "隐藏层vs神经元数vs norm 1 910 0.8\n",
      "验证集最优结果： 150.44393920898438 149.33297729492188\n",
      "------------train------------\n",
      " (0.5133120682432072, 0.04153176329017372)\n",
      "------------test------------\n",
      " (0.48939373750832776, 0.035531867643793014)\n",
      "------------oot------------\n",
      " (0.5037442509760307, 0.05394640809091866)\n",
      "隐藏层vs神经元数vs norm 1 940 0.01\n",
      "验证集最优结果： 2.6120846271514893 2.606821060180664\n",
      "------------train------------\n",
      " (0.628109782550579, 0.18383433533734128)\n",
      "------------test------------\n",
      " (0.5913968465467466, 0.15800577392849213)\n",
      "------------oot------------\n",
      " (0.6219488177573883, 0.1810308275119035)\n",
      "隐藏层vs神经元数vs norm 1 940 0.05\n",
      "验证集最优结果： 10.432809829711914 10.38760757446289\n",
      "------------train------------\n",
      " (0.5837687533120953, 0.1272659469563917)\n",
      "------------test------------\n",
      " (0.5816222518321119, 0.1499777925827227)\n",
      "------------oot------------\n",
      " (0.5561185833941542, 0.10910228339067884)\n",
      "隐藏层vs神经元数vs norm 1 940 0.1\n",
      "验证集最优结果： 20.184856414794922 20.109371185302734\n",
      "------------train------------\n",
      " (0.591640762105095, 0.13974223353833642)\n",
      "------------test------------\n",
      " (0.5833477681545636, 0.12670441927603815)\n",
      "------------oot------------\n",
      " (0.6118791922983352, 0.18547249157195983)\n",
      "隐藏层vs神经元数vs norm 1 940 0.2\n",
      "验证集最优结果： 39.00198745727539 38.74784851074219\n",
      "------------train------------\n",
      " (0.505548212263771, 0.03418062061305993)\n",
      "------------test------------\n",
      " (0.509814568065734, 0.03836331334665779)\n",
      "------------oot------------\n",
      " (0.4904968778600308, 0.02090849059882527)\n",
      "隐藏层vs神经元数vs norm 1 940 0.3\n",
      "验证集最优结果： 58.247867584228516 57.89263153076172\n",
      "------------train------------\n",
      " (0.5180219270015884, 0.03606050330989574)\n",
      "------------test------------\n",
      " (0.5483555407506107, 0.09430379746835449)\n",
      "------------oot------------\n",
      " (0.5298578528481562, 0.06392798804434713)\n",
      "隐藏层vs神经元数vs norm 1 940 0.4\n",
      "验证集最优结果： 77.68462371826172 77.11929321289062\n",
      "------------train------------\n",
      " (0.5047470151380099, 0.022236299684813665)\n",
      "------------test------------\n",
      " (0.5024505884965579, 0.047046413502109724)\n",
      "------------oot------------\n",
      " (0.47764802650633115, 0.024286657630417374)\n",
      "隐藏层vs神经元数vs norm 1 940 0.5\n",
      "验证集最优结果： 96.79562377929688 96.10331726074219\n",
      "------------train------------\n",
      " (0.5186760552513334, 0.03743251447169921)\n",
      "------------test------------\n",
      " (0.49659560293137905, 0.04208305574061735)\n",
      "------------oot------------\n",
      " (0.49562784554964723, 0.026865464150418787)\n",
      "隐藏层vs神经元数vs norm 1 940 0.8\n",
      "验证集最优结果： 155.6934051513672 154.55755615234375\n",
      "------------train------------\n",
      " (0.590526815197433, 0.13666427755883265)\n",
      "------------test------------\n",
      " (0.561157006440151, 0.11296913168998446)\n",
      "------------oot------------\n",
      " (0.5703356155655186, 0.12153060160567197)\n",
      "隐藏层vs神经元数vs norm 1 970 0.01\n",
      "验证集最优结果： 2.646965742111206 2.6403486728668213\n",
      "------------train------------\n",
      " (0.6197204946874499, 0.17391486789858002)\n",
      "------------test------------\n",
      " (0.5848978458805242, 0.13964023984010654)\n",
      "------------oot------------\n",
      " (0.6179242113555532, 0.1632085635839155)\n",
      "隐藏层vs神经元数vs norm 1 970 0.05\n",
      "验证集最优结果： 10.72443962097168 10.686049461364746\n",
      "------------train------------\n",
      " (0.5819695453047263, 0.1199307767849106)\n",
      "------------test------------\n",
      " (0.5791772151898735, 0.14007328447701528)\n",
      "------------oot------------\n",
      " (0.5539093362990767, 0.10332603482431446)\n",
      "隐藏层vs神经元数vs norm 1 970 0.1\n",
      "验证集最优结果： 20.579593658447266 20.50223159790039\n",
      "------------train------------\n",
      " (0.5397910985767549, 0.0670026307258218)\n",
      "------------test------------\n",
      " (0.5534110592938041, 0.09861203642016436)\n",
      "------------oot------------\n",
      " (0.5332337028927583, 0.07266534598408236)\n",
      "隐藏层vs神经元数vs norm 1 970 0.2\n",
      "验证集最优结果： 40.10324478149414 39.91763687133789\n",
      "------------train------------\n",
      " (0.48544126415614075, 0.002311411069352509)\n",
      "------------test------------\n",
      " (0.507449478125694, 0.05690650677326231)\n",
      "------------oot------------\n",
      " (0.4934614627138868, 0.019414033990199142)\n",
      "隐藏层vs神经元数vs norm 1 970 0.3\n",
      "验证集最优结果： 59.56358337402344 59.23006820678711\n",
      "------------train------------\n",
      " (0.4997805134077679, 0.013854118233088908)\n",
      "------------test------------\n",
      " (0.4861536753275594, 0.01027093049078387)\n",
      "------------oot------------\n",
      " (0.5246064018350538, 0.05879122788725544)\n",
      "隐藏层vs神经元数vs norm 1 970 0.4\n",
      "验证集最优结果： 80.06273651123047 79.48605346679688\n",
      "------------train------------\n",
      " (0.5357258251728043, 0.06174036692094076)\n",
      "------------test------------\n",
      " (0.5164323784143905, 0.06422385076615583)\n",
      "------------oot------------\n",
      " (0.519037523604305, 0.05500990511938281)\n",
      "隐藏层vs神经元数vs norm 1 970 0.5\n",
      "验证集最优结果： 99.1339340209961 98.58187103271484\n",
      "------------train------------\n",
      " (0.5100981429254997, 0.030569616098119923)\n",
      "------------test------------\n",
      " (0.4611980901621141, 0.005363091272485011)\n",
      "------------oot------------\n",
      " (0.4738412168815672, 0.01005804052410253)\n",
      "隐藏层vs神经元数vs norm 1 970 0.8\n",
      "验证集最优结果： 160.67385864257812 159.26795959472656\n",
      "------------train------------\n",
      " (0.523185783928546, 0.04430800134548063)\n",
      "------------test------------\n",
      " (0.5027104152787031, 0.04294914501443492)\n",
      "------------oot------------\n",
      " (0.4975961259977525, 0.05010947763528306)\n",
      "隐藏层vs神经元数vs norm 2 1 0.01\n",
      "验证集最优结果： 0.5732214450836182 0.5683709979057312\n",
      "------------train------------\n",
      " (0.6965539995898585, 0.2943277977772499)\n",
      "------------test------------\n",
      " (0.6661092604930046, 0.24640239840106593)\n",
      "------------oot------------\n",
      " (0.6421239819738412, 0.20820213394501785)\n",
      "隐藏层vs神经元数vs norm 2 1 0.05\n",
      "验证集最优结果： 0.5923334360122681 0.5817270874977112\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 1 0.1\n",
      "验证集最优结果： 0.606045126914978 0.5936563014984131\n",
      "------------train------------\n",
      " (0.46583981877974123, 0.004198197137266768)\n",
      "------------test------------\n",
      " (0.48050632911392405, 0.00952698201199198)\n",
      "------------oot------------\n",
      " (0.43427634703831136, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 2 1 0.2\n",
      "验证集最优结果： 0.6263803839683533 0.612471878528595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " (0.5078253095180567, 0.022733071682033423)\n",
      "------------test------------\n",
      " (0.518335554075061, 0.07355096602265154)\n",
      "------------oot------------\n",
      " (0.5179670756148703, 0.0579432106488722)\n",
      "隐藏层vs神经元数vs norm 2 1 0.3\n",
      "验证集最优结果： 0.6524369120597839 0.6360489130020142\n",
      "------------train------------\n",
      " (0.512963177283307, 0.029927331867382168)\n",
      "------------test------------\n",
      " (0.5038729735731734, 0.045103264490339745)\n",
      "------------oot------------\n",
      " (0.5244279938368146, 0.060091057588711694)\n",
      "隐藏层vs神经元数vs norm 2 1 0.4\n",
      "验证集最优结果： 0.6714451909065247 0.663343608379364\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 1 0.5\n",
      "验证集最优结果： 0.6990454196929932 0.6903670430183411\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 1 0.8\n",
      "验证集最优结果： 0.7569366097450256 0.7490699887275696\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 2 0.01\n",
      "验证集最优结果： 0.5765834450721741 0.5726089477539062\n",
      "------------train------------\n",
      " (0.6953355545944979, 0.29197009351360603)\n",
      "------------test------------\n",
      " (0.6657061958694204, 0.24106151454585834)\n",
      "------------oot------------\n",
      " (0.6418030792757099, 0.20613074757585237)\n",
      "隐藏层vs神经元数vs norm 2 2 0.05\n",
      "验证集最优结果： 0.6032251715660095 0.5913145542144775\n",
      "------------train------------\n",
      " (0.44299812052338383, 0.0015586729013582722)\n",
      "------------test------------\n",
      " (0.4274272707084166, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.3882945817259236, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 2 2 0.1\n",
      "验证集最优结果： 0.6259564161300659 0.6140086054801941\n",
      "------------train------------\n",
      " (0.5255023386861531, 0.03936613517477372)\n",
      "------------test------------\n",
      " (0.5339540306462358, 0.05435265378636467)\n",
      "------------oot------------\n",
      " (0.5238128337909382, 0.07014214715184375)\n",
      "隐藏层vs神经元数vs norm 2 2 0.2\n",
      "验证集最优结果： 0.67392897605896 0.664969801902771\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 2 0.3\n",
      "验证集最优结果： 0.7210932374000549 0.7040953040122986\n",
      "------------train------------\n",
      " (0.531796182706514, 0.05330580106514954)\n",
      "------------test------------\n",
      " (0.5289429269375971, 0.0620253164556962)\n",
      "------------oot------------\n",
      " (0.5276277528701676, 0.0703993327077469)\n",
      "隐藏层vs神经元数vs norm 2 2 0.4\n",
      "验证集最优结果： 0.7690757513046265 0.7495437860488892\n",
      "------------train------------\n",
      " (0.46272815810614815, 0.00016256762088850962)\n",
      "------------test------------\n",
      " (0.46314901176993123, 0.004119475904952208)\n",
      "------------oot------------\n",
      " (0.44595743694899154, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 2 0.5\n",
      "验证集最优结果： 0.79865562915802 0.7817960381507874\n",
      "------------train------------\n",
      " (0.48218849045608947, 6.700330752684724e-05)\n",
      "------------test------------\n",
      " (0.4957383966244726, 0.02780368643126796)\n",
      "------------oot------------\n",
      " (0.4515726549195426, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 2 2 0.8\n",
      "验证集最优结果： 0.9403192400932312 0.9315792322158813\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 3 0.01\n",
      "验证集最优结果： 0.5871847867965698 0.5767555236816406\n",
      "------------train------------\n",
      " (0.504266892447509, 0.009952089251112795)\n",
      "------------test------------\n",
      " (0.4840495225405286, 0.016055962691538972)\n",
      "------------oot------------\n",
      " (0.5260846395347489, 0.040079240955062045)\n",
      "隐藏层vs神经元数vs norm 2 3 0.05\n",
      "验证集最优结果： 0.6125865578651428 0.6017680168151855\n",
      "------------train------------\n",
      " (0.4460994938204676, 0.00044533511467379205)\n",
      "------------test------------\n",
      " (0.44095491894292693, 0.0037086386853208966)\n",
      "------------oot------------\n",
      " (0.4599983781091069, 0.0027942863100823834)\n",
      "隐藏层vs神经元数vs norm 2 3 0.1\n",
      "验证集最优结果： 0.6462653279304504 0.6356173753738403\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 3 0.2\n",
      "验证集最优结果： 0.7096814513206482 0.6949517726898193\n",
      "------------train------------\n",
      " (0.522527459512067, 0.03744280184820847)\n",
      "------------test------------\n",
      " (0.5065434155007773, 0.022640461914279375)\n",
      "------------oot------------\n",
      " (0.49452495974235106, 0.03132798109338608)\n",
      "隐藏层vs神经元数vs norm 2 3 0.3\n",
      "验证集最优结果： 0.7806509733200073 0.7629746198654175\n",
      "------------train------------\n",
      " (0.48769352281056544, 0.008262523019696877)\n",
      "------------test------------\n",
      " (0.4931112591605596, 0.015245391960915011)\n",
      "------------oot------------\n",
      " (0.48419583174040487, 0.002085288291106324)\n",
      "隐藏层vs神经元数vs norm 2 3 0.4\n",
      "验证集最优结果： 0.853162944316864 0.8356544971466064\n",
      "------------train------------\n",
      " (0.516395980072269, 0.03169527166457198)\n",
      "------------test------------\n",
      " (0.5065300910504108, 0.03157894736842104)\n",
      "------------oot------------\n",
      " (0.5208517244175673, 0.0648177110485525)\n",
      "隐藏层vs神经元数vs norm 2 3 0.5\n",
      "验证集最优结果： 0.9178018569946289 0.8977777361869812\n",
      "------------train------------\n",
      " (0.4935640277515517, 0.0028440535241371356)\n",
      "------------test------------\n",
      " (0.48359204974461467, 0.028036864312680487)\n",
      "------------oot------------\n",
      " (0.46290735527520016, 0.010989469294129917)\n",
      "隐藏层vs神经元数vs norm 2 3 0.8\n",
      "验证集最优结果： 1.136847734451294 1.1232054233551025\n",
      "------------train------------\n",
      " (0.544492091240908, 0.07218733312623216)\n",
      "------------test------------\n",
      " (0.5405707306240285, 0.06382411725516324)\n",
      "------------oot------------\n",
      " (0.5331166950497572, 0.050484829527682185)\n",
      "隐藏层vs神经元数vs norm 2 4 0.01\n",
      "验证集最优结果： 0.5898768901824951 0.5824309587478638\n",
      "------------train------------\n",
      " (0.6796075095141312, 0.26087446761134564)\n",
      "------------test------------\n",
      " (0.6609116144792361, 0.23757495003331108)\n",
      "------------oot------------\n",
      " (0.6366338813007564, 0.2113161644597366)\n",
      "隐藏层vs神经元数vs norm 2 4 0.05\n",
      "验证集最优结果： 0.6237756013870239 0.6122782230377197\n",
      "------------train------------\n",
      " (0.5338445888737962, 0.05831588878533828)\n",
      "------------test------------\n",
      " (0.5270208749722407, 0.061059293804130554)\n",
      "------------oot------------\n",
      " (0.5777337550249656, 0.12662565599694153)\n",
      "隐藏层vs神经元数vs norm 2 4 0.1\n",
      "验证集最优结果： 0.6678259968757629 0.654787003993988\n",
      "------------train------------\n",
      " (0.5037508316193345, 0.01828675926659129)\n",
      "------------test------------\n",
      " (0.5315733955141018, 0.06835443037974687)\n",
      "------------oot------------\n",
      " (0.5227412273080086, 0.04777395474924406)\n",
      "隐藏层vs神经元数vs norm 2 4 0.2\n",
      "验证集最优结果： 0.7580490112304688 0.7487961053848267\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 4 0.3\n",
      "验证集最优结果： 0.8528158068656921 0.8347179889678955\n",
      "------------train------------\n",
      " (0.5036824747096355, 0.03174224165994943)\n",
      "------------test------------\n",
      " (0.49850210970464137, 0.02008660892738179)\n",
      "------------oot------------\n",
      " (0.4591990175975162, 0.0022312584714837547)\n",
      "隐藏层vs神经元数vs norm 2 4 0.4\n",
      "验证集最优结果： 0.9359845519065857 0.9170562624931335\n",
      "------------train------------\n",
      " (0.523918624144608, 0.04080068275693571)\n",
      "------------test------------\n",
      " (0.5285343104596936, 0.055773928492116376)\n",
      "------------oot------------\n",
      " (0.5441189077723328, 0.0889931533034442)\n",
      "隐藏层vs神经元数vs norm 2 4 0.5\n",
      "验证集最优结果： 1.027793288230896 1.0015358924865723\n",
      "------------train------------\n",
      " (0.49894161846150925, 0.0034493844155720765)\n",
      "------------test------------\n",
      " (0.50557406173662, 0.02668221185876085)\n",
      "------------oot------------\n",
      " (0.4793452194765927, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 2 4 0.8\n",
      "验证集最优结果： 1.2870850563049316 1.2636747360229492\n",
      "------------train------------\n",
      " (0.47660210661106067, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.4588041305796136, 0.0061403508771929825)\n",
      "------------oot------------\n",
      " (0.4245299412643798, 0.0045528794355819135)\n",
      "隐藏层vs神经元数vs norm 2 5 0.01\n",
      "验证集最优结果： 0.5830618143081665 0.5788706541061401\n",
      "------------train------------\n",
      " (0.6947348936305573, 0.28877978855380465)\n",
      "------------test------------\n",
      " (0.6683510992671552, 0.24835665112147465)\n",
      "------------oot------------\n",
      " (0.653364844356399, 0.23259305598999064)\n",
      "隐藏层vs神经元数vs norm 2 5 0.05\n",
      "验证集最优结果： 0.6352957487106323 0.6235231757164001\n",
      "------------train------------\n",
      " (0.5063347228059631, 0.02403456017066219)\n",
      "------------test------------\n",
      " (0.49128580946035977, 0.020475238729735723)\n",
      "------------oot------------\n",
      " (0.5101541954841924, 0.03327425016508534)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 2 5 0.1\n",
      "验证集最优结果： 0.6912214756011963 0.6782083511352539\n",
      "------------train------------\n",
      " (0.5235503766736446, 0.043097610283044985)\n",
      "------------test------------\n",
      " (0.5029702420608484, 0.023484343770819427)\n",
      "------------oot------------\n",
      " (0.4916692732770306, 0.017412157230737135)\n",
      "隐藏层vs神经元数vs norm 2 5 0.2\n",
      "验证集最优结果： 0.7958901524543762 0.7805889844894409\n",
      "------------train------------\n",
      " (0.48714971313785965, 0.006760836769790779)\n",
      "------------test------------\n",
      " (0.5116411281367977, 0.03990672884743507)\n",
      "------------oot------------\n",
      " (0.4816459875577798, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 2 5 0.3\n",
      "验证集最优结果： 0.9065665006637573 0.8882678747177124\n",
      "------------train------------\n",
      " (0.5344781423705229, 0.06153543155206054)\n",
      "------------test------------\n",
      " (0.5279491450144348, 0.08105707306240284)\n",
      "------------oot------------\n",
      " (0.5528736431144939, 0.10331213290237373)\n",
      "隐藏层vs神经元数vs norm 2 5 0.4\n",
      "验证集最优结果： 1.0302189588546753 1.0063692331314087\n",
      "------------train------------\n",
      " (0.4893170332559749, 0.0060810577588814585)\n",
      "------------test------------\n",
      " (0.5204230512991339, 0.03197868087941369)\n",
      "------------oot------------\n",
      " (0.49470336774059015, 0.014471900740277377)\n",
      "隐藏层vs神经元数vs norm 2 5 0.5\n",
      "验证集最优结果： 1.1451976299285889 1.123266577720642\n",
      "------------train------------\n",
      " (0.48838399527863563, 0.001805976018230293)\n",
      "------------test------------\n",
      " (0.5072640461914281, 0.013602043082389513)\n",
      "------------oot------------\n",
      " (0.4870202388813587, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 2 5 0.8\n",
      "验证集最优结果： 1.5052294731140137 1.4736461639404297\n",
      "------------train------------\n",
      " (0.5130772182663199, 0.0323750506754813)\n",
      "------------test------------\n",
      " (0.5032911392405064, 0.039684654674661354)\n",
      "------------oot------------\n",
      " (0.49263893233239503, 0.03542904806589511)\n",
      "隐藏层vs神经元数vs norm 2 6 0.01\n",
      "验证集最优结果： 0.5931476950645447 0.5827046632766724\n",
      "------------train------------\n",
      " (0.5336336299752494, 0.0631482485403092)\n",
      "------------test------------\n",
      " (0.5098079058405508, 0.037685987119698006)\n",
      "------------oot------------\n",
      " (0.5332869935935309, 0.06680568588607383)\n",
      "隐藏层vs神经元数vs norm 2 6 0.05\n",
      "验证集最优结果： 0.6448737382888794 0.6327952146530151\n",
      "------------train------------\n",
      " (0.46676243402035406, 0.002449343130705856)\n",
      "------------test------------\n",
      " (0.4710226515656229, 0.01395736175882745)\n",
      "------------oot------------\n",
      " (0.4599172835644528, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 6 0.1\n",
      "验证集最优结果： 0.7128673791885376 0.6988429427146912\n",
      "------------train------------\n",
      " (0.4828474239935461, 0.018384895424080172)\n",
      "------------test------------\n",
      " (0.46467799244947816, 0.01681101487896957)\n",
      "------------oot------------\n",
      " (0.48681171005224805, 0.0029124526465784117)\n",
      "隐藏层vs神经元数vs norm 2 6 0.2\n",
      "验证集最优结果： 0.843430757522583 0.825743556022644\n",
      "------------train------------\n",
      " (0.4869497184169081, 0.0034523623403510673)\n",
      "------------test------------\n",
      " (0.46178103486564515, 0.0035087719298245615)\n",
      "------------oot------------\n",
      " (0.48774198032878047, 0.011781878844750238)\n",
      "隐藏层vs神经元数vs norm 2 6 0.3\n",
      "验证集最优结果： 0.9810078144073486 0.9578139185905457\n",
      "------------train------------\n",
      " (0.5286865524361795, 0.047394078938017836)\n",
      "------------test------------\n",
      " (0.5139962247390629, 0.032178547634910126)\n",
      "------------oot------------\n",
      " (0.5317936954783998, 0.07974142425190278)\n",
      "隐藏层vs神经元数vs norm 2 6 0.4\n",
      "验证集最优结果： 1.108752965927124 1.08131742477417\n",
      "------------train------------\n",
      " (0.4866204546885057, 0.009654567493649902)\n",
      "------------test------------\n",
      " (0.4805041083721963, 0.02288474350433045)\n",
      "------------oot------------\n",
      " (0.4661963183076727, 0.01569526987105968)\n",
      "隐藏层vs神经元数vs norm 2 6 0.5\n",
      "验证集最优结果： 1.250118374824524 1.225914716720581\n",
      "------------train------------\n",
      " (0.49646263144323094, 0.009059794699158519)\n",
      "------------test------------\n",
      " (0.5003142349544748, 0.019675771707750395)\n",
      "------------oot------------\n",
      " (0.47999860980780595, 0.001772495047440259)\n",
      "隐藏层vs神经元数vs norm 2 6 0.8\n",
      "验证集最优结果： 1.6762220859527588 1.6432337760925293\n",
      "------------train------------\n",
      " (0.5161487446355055, 0.029240784845611545)\n",
      "------------test------------\n",
      " (0.5105762824783479, 0.02550521874306022)\n",
      "------------oot------------\n",
      " (0.5157833153766841, 0.029618044694679074)\n",
      "隐藏层vs神经元数vs norm 2 7 0.01\n",
      "验证集最优结果： 0.5943750739097595 0.5837097764015198\n",
      "------------train------------\n",
      " (0.5271526504545734, 0.04381989240216333)\n",
      "------------test------------\n",
      " (0.5330901621141461, 0.0695314234954475)\n",
      "------------oot------------\n",
      " (0.5339751387295961, 0.05017898724498665)\n",
      "隐藏层vs神经元数vs norm 2 7 0.05\n",
      "验证集最优结果： 0.6569573283195496 0.645114541053772\n",
      "------------train------------\n",
      " (0.5249860071375442, 0.056802155476099014)\n",
      "------------test------------\n",
      " (0.5272995780590718, 0.06351321341327998)\n",
      "------------oot------------\n",
      " (0.5223994717269662, 0.04302644840649217)\n",
      "隐藏层vs神经元数vs norm 2 7 0.1\n",
      "验证集最优结果： 0.731974184513092 0.7190441489219666\n",
      "------------train------------\n",
      " (0.5140317108380897, 0.04551825704769885)\n",
      "------------test------------\n",
      " (0.5357617144126138, 0.06850988230068844)\n",
      "------------oot------------\n",
      " (0.5056105839965709, 0.04511173669759844)\n",
      "隐藏层vs神经元数vs norm 2 7 0.2\n",
      "验证集最优结果： 0.8849420547485352 0.868287980556488\n",
      "------------train------------\n",
      " (0.46431654257518756, 0.001240441030659789)\n",
      "------------test------------\n",
      " (0.46112258494337105, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4878080144579988, 0.0164598755777986)\n",
      "隐藏层vs神经元数vs norm 2 7 0.3\n",
      "验证集最优结果： 1.0342262983322144 1.0105524063110352\n",
      "------------train------------\n",
      " (0.46641313697980225, 0.00381296195904135)\n",
      "------------test------------\n",
      " (0.4846946480124362, 0.006340217632689319)\n",
      "------------oot------------\n",
      " (0.455053927872195, 0.010315226080005568)\n",
      "隐藏层vs神经元数vs norm 2 7 0.4\n",
      "验证集最优结果： 1.2010389566421509 1.1783334016799927\n",
      "------------train------------\n",
      " (0.46480180895394296, 0.008121477673347366)\n",
      "------------test------------\n",
      " (0.4732000888296692, 0.006617810348656494)\n",
      "------------oot------------\n",
      " (0.45758755314588906, 0.00615855141973376)\n",
      "隐藏层vs神经元数vs norm 2 7 0.5\n",
      "验证集最优结果： 1.350919485092163 1.3278194665908813\n",
      "------------train------------\n",
      " (0.4747560639685315, 0.0011734377231328581)\n",
      "------------test------------\n",
      " (0.4735809460359759, 0.010526315789473684)\n",
      "------------oot------------\n",
      " (0.45861281988901637, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 7 0.8\n",
      "验证集最优结果： 1.8408241271972656 1.805016040802002\n",
      "------------train------------\n",
      " (0.5298163364892569, 0.042590009468447154)\n",
      "------------test------------\n",
      " (0.5182445036642239, 0.051576726626693326)\n",
      "------------oot------------\n",
      " (0.5215584054495535, 0.05503075800229382)\n",
      "隐藏层vs神经元数vs norm 2 8 0.01\n",
      "验证集最优结果： 0.589952826499939 0.5850182175636292\n",
      "------------train------------\n",
      " (0.6890494937866277, 0.2790268141822314)\n",
      "------------test------------\n",
      " (0.6660659560293137, 0.24123917388407734)\n",
      "------------oot------------\n",
      " (0.6441270172267982, 0.21602891599763668)\n",
      "隐藏层vs神经元数vs norm 2 8 0.05\n",
      "验证集最优结果： 0.6673584580421448 0.6555967926979065\n",
      "------------train------------\n",
      " (0.5141302530762302, 0.036512877155865264)\n",
      "------------test------------\n",
      " (0.5183244503664224, 0.03849655785032202)\n",
      "------------oot------------\n",
      " (0.5415354672783512, 0.07265839502311194)\n",
      "隐藏层vs神经元数vs norm 2 8 0.1\n",
      "验证集最优结果： 0.7547151446342468 0.7400708794593811\n",
      "------------train------------\n",
      " (0.4513590504210041, 0.003901622901324342)\n",
      "------------test------------\n",
      " (0.4402709304907839, 0.0043859649122807015)\n",
      "------------oot------------\n",
      " (0.420646671068942, 0.004295693879678875)\n",
      "隐藏层vs神经元数vs norm 2 8 0.2\n",
      "验证集最优结果： 0.9333847165107727 0.917604386806488\n",
      "------------train------------\n",
      " (0.5159390716590222, 0.033783744456153175)\n",
      "------------test------------\n",
      " (0.529147235176549, 0.07006440151010435)\n",
      "------------oot------------\n",
      " (0.5076912383136969, 0.05237549091161853)\n",
      "隐藏层vs神经元数vs norm 2 8 0.3\n",
      "验证集最优结果： 1.1082696914672852 1.0842376947402954\n",
      "------------train------------\n",
      " (0.466762095619811, 0.0020601825061808965)\n",
      "------------test------------\n",
      " (0.4536497890295359, 0.0043859649122807015)\n",
      "------------oot------------\n",
      " (0.461550759392486, 0.005157613040002729)\n",
      "隐藏层vs神经元数vs norm 2 8 0.4\n",
      "验证集最优结果： 1.2859405279159546 1.2604329586029053\n",
      "------------train------------\n",
      " (0.514469601140816, 0.0344034235306141)\n",
      "------------test------------\n",
      " (0.5138330002220741, 0.04830113257828106)\n",
      "------------oot------------\n",
      " (0.4924767432430867, 0.009425503075800201)\n",
      "隐藏层vs神经元数vs norm 2 8 0.5\n",
      "验证集最优结果： 1.4509832859039307 1.4210608005523682\n",
      "------------train------------\n",
      " (0.5351286835745114, 0.05687105382666724)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.5118809682433934, 0.062258494337108505)\n",
      "------------oot------------\n",
      " (0.5222604525075591, 0.06125186807076077)\n",
      "隐藏层vs神经元数vs norm 2 8 0.8\n",
      "验证集最优结果： 2.0011327266693115 1.9772677421569824\n",
      "------------train------------\n",
      " (0.49312715265045454, 0.003679902865508119)\n",
      "------------test------------\n",
      " (0.4917876970908284, 0.01745502998001333)\n",
      "------------oot------------\n",
      " (0.48473337272211214, 0.03004205331387065)\n",
      "隐藏层vs神经元数vs norm 2 9 0.01\n",
      "验证集最优结果： 0.5989565849304199 0.5882320404052734\n",
      "------------train------------\n",
      " (0.5123861366772722, 0.032533692850070295)\n",
      "------------test------------\n",
      " (0.5066677770375306, 0.03339995558516545)\n",
      "------------oot------------\n",
      " (0.52767409260997, 0.0628992458207347)\n",
      "隐藏层vs神经元数vs norm 2 9 0.05\n",
      "验证集最优结果： 0.6785396337509155 0.6654368042945862\n",
      "------------train------------\n",
      " (0.5468098642404702, 0.06940189057615404)\n",
      "------------test------------\n",
      " (0.5315467466133688, 0.07244059515878304)\n",
      "------------oot------------\n",
      " (0.5177933015906115, 0.045438431863205064)\n",
      "隐藏层vs神经元数vs norm 2 9 0.1\n",
      "验证集最优结果： 0.7767573595046997 0.7632380127906799\n",
      "------------train------------\n",
      " (0.5064349570468191, 0.027317857599697848)\n",
      "------------test------------\n",
      " (0.520548523206751, 0.05960470797246287)\n",
      "------------oot------------\n",
      " (0.5188498476581053, 0.03779237479581543)\n",
      "隐藏层vs神经元数vs norm 2 9 0.2\n",
      "验证集最优结果： 0.97221839427948 0.9560489058494568\n",
      "------------train------------\n",
      " (0.4802570355164906, 0.002781381743561462)\n",
      "------------test------------\n",
      " (0.49760381967577166, 0.0011547856984231997)\n",
      "------------oot------------\n",
      " (0.485279023158285, 0.012421367254022875)\n",
      "隐藏层vs神经元数vs norm 2 9 0.3\n",
      "验证集最优结果： 1.1690064668655396 1.1511752605438232\n",
      "------------train------------\n",
      " (0.5234981276297952, 0.038651839308471714)\n",
      "------------test------------\n",
      " (0.4944037308461026, 0.030735065511880988)\n",
      "------------oot------------\n",
      " (0.4849476940186981, 0.011489938483995488)\n",
      "隐藏层vs神经元数vs norm 2 9 0.4\n",
      "验证集最优结果： 1.3662713766098022 1.339637279510498\n",
      "------------train------------\n",
      " (0.5116499124557795, 0.02397770887942724)\n",
      "------------test------------\n",
      " (0.4715978236731069, 0.007017543859649123)\n",
      "------------oot------------\n",
      " (0.4745444224330681, 0.00815347721822543)\n",
      "隐藏层vs神经元数vs norm 2 9 0.5\n",
      "验证集最优结果： 1.5671950578689575 1.5360172986984253\n",
      "------------train------------\n",
      " (0.5408510367577437, 0.054951239865749735)\n",
      "------------test------------\n",
      " (0.5356873195647347, 0.06283588718632016)\n",
      "------------oot------------\n",
      " (0.5523036643149248, 0.08856219372328222)\n",
      "隐藏层vs神经元数vs norm 2 9 0.8\n",
      "验证集最优结果： 2.190445899963379 2.167917013168335\n",
      "------------train------------\n",
      " (0.49342541888911223, 0.014248828626520216)\n",
      "------------test------------\n",
      " (0.5190928270042193, 0.04629136131467915)\n",
      "------------oot------------\n",
      " (0.5001320682584367, 0.019566955131546937)\n",
      "隐藏层vs神经元数vs norm 2 10 0.01\n",
      "验证集最优结果： 0.5899778604507446 0.5855677127838135\n",
      "------------train------------\n",
      " (0.6903092913283507, 0.28739654249397134)\n",
      "------------test------------\n",
      " (0.6683988452143017, 0.24796802131912055)\n",
      "------------oot------------\n",
      " (0.6422560502322779, 0.2057275918395718)\n",
      "隐藏层vs神经元数vs norm 2 10 0.05\n",
      "验证集最优结果： 0.6895278692245483 0.6781097054481506\n",
      "------------train------------\n",
      " (0.45914158611041744, 0.0013783730920131632)\n",
      "------------test------------\n",
      " (0.46581834332667116, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.4617604467150917, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 2 10 0.1\n",
      "验证集最优结果： 0.7987495064735413 0.7871415019035339\n",
      "------------train------------\n",
      " (0.5202559797067963, 0.0352714886036849)\n",
      "------------test------------\n",
      " (0.5083766377970242, 0.027192982456140352)\n",
      "------------oot------------\n",
      " (0.5169487598327135, 0.06257255065512801)\n",
      "隐藏层vs神经元数vs norm 2 10 0.2\n",
      "验证集最优结果： 1.014999270439148 0.999631941318512\n",
      "------------train------------\n",
      " (0.513447631500759, 0.03659666513032822)\n",
      "------------test------------\n",
      " (0.4852187430601821, 0.022640461914279375)\n",
      "------------oot------------\n",
      " (0.5260116544445603, 0.05460674938310217)\n",
      "隐藏层vs神经元数vs norm 2 10 0.3\n",
      "验证集最优结果： 1.2431180477142334 1.2257683277130127\n",
      "------------train------------\n",
      " (0.4693919416001879, 0.0025872751920592288)\n",
      "------------test------------\n",
      " (0.4777348434377082, 0.007450588496557775)\n",
      "------------oot------------\n",
      " (0.4638642709021189, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 10 0.4\n",
      "验证集最优结果： 1.4614933729171753 1.4425580501556396\n",
      "------------train------------\n",
      " (0.44897061938805, 0.004371593575533295)\n",
      "------------test------------\n",
      " (0.47063957361758824, 0.024550299800133235)\n",
      "------------oot------------\n",
      " (0.4539290306884927, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 2 10 0.5\n",
      "验证集最优结果： 1.7007060050964355 1.678501844406128\n",
      "------------train------------\n",
      " (0.4940908497169957, 0.009040979628964108)\n",
      "------------test------------\n",
      " (0.48746280257606045, 0.020219853431046042)\n",
      "------------oot------------\n",
      " (0.4771776781473372, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 10 0.8\n",
      "验证集最优结果： 2.3395609855651855 2.2952828407287598\n",
      "------------train------------\n",
      " (0.49851848242246055, 0.01634677663330708)\n",
      "------------test------------\n",
      " (0.5266067066400179, 0.05721741061514546)\n",
      "------------oot------------\n",
      " (0.534326162258599, 0.06072359503701388)\n",
      "隐藏层vs神经元数vs norm 2 11 0.01\n",
      "验证集最优结果： 0.5974893569946289 0.5915620923042297\n",
      "------------train------------\n",
      " (0.6748447249108145, 0.26761161634312186)\n",
      "------------test------------\n",
      " (0.6613379968909616, 0.2338330002220742)\n",
      "------------oot------------\n",
      " (0.6413674857215677, 0.21511138914954997)\n",
      "隐藏层vs神经元数vs norm 2 11 0.05\n",
      "验证集最优结果： 0.7008424997329712 0.6892194747924805\n",
      "------------train------------\n",
      " (0.5174365617421943, 0.03378469197767364)\n",
      "------------test------------\n",
      " (0.5220164334887852, 0.06045969353764158)\n",
      "------------oot------------\n",
      " (0.5146306143491004, 0.04167796197824347)\n",
      "隐藏层vs神经元数vs norm 2 11 0.1\n",
      "验证集最优结果： 0.8204742670059204 0.8078640103340149\n",
      "------------train------------\n",
      " (0.5203841658325093, 0.045839602203393615)\n",
      "------------test------------\n",
      " (0.5198767488341106, 0.06019320453031318)\n",
      "------------oot------------\n",
      " (0.5189425271377102, 0.045035276126924484)\n",
      "隐藏层vs神经元数vs norm 2 11 0.2\n",
      "验证集最优结果： 1.0621304512023926 1.0436807870864868\n",
      "------------train------------\n",
      " (0.49426864536232207, 0.011018186321985368)\n",
      "------------test------------\n",
      " (0.5082234066178103, 0.030324228292249567)\n",
      "------------oot------------\n",
      " (0.4766957448533926, 0.0067632850241546305)\n",
      "隐藏层vs神经元数vs norm 2 11 0.3\n",
      "验证集最优结果： 1.3072642087936401 1.2869817018508911\n",
      "------------train------------\n",
      " (0.4497128671392092, 0.0007704703564508364)\n",
      "------------test------------\n",
      " (0.4757972462802576, 0.0035087719298245615)\n",
      "------------oot------------\n",
      " (0.43963090397247423, 0.004295693879678875)\n",
      "隐藏层vs神经元数vs norm 2 11 0.4\n",
      "验证集最优结果： 1.5420947074890137 1.5163792371749878\n",
      "------------train------------\n",
      " (0.5509922919124299, 0.08080923752266439)\n",
      "------------test------------\n",
      " (0.5563979569176105, 0.09133910726182543)\n",
      "------------oot------------\n",
      " (0.5396702927513062, 0.08336982587842778)\n",
      "隐藏层vs神经元数vs norm 2 11 0.5\n",
      "验证集最优结果： 1.800746202468872 1.775490403175354\n",
      "------------train------------\n",
      " (0.5242650109404896, 0.04214372683225276)\n",
      "------------test------------\n",
      " (0.523758605374195, 0.05363091272485007)\n",
      "------------oot------------\n",
      " (0.5485489868974385, 0.0740763910610642)\n",
      "隐藏层vs神经元数vs norm 2 11 0.8\n",
      "验证集最优结果： 2.5481910705566406 2.51138973236084\n",
      "------------train------------\n",
      " (0.47697231680517393, 0.00020493536888022135)\n",
      "------------test------------\n",
      " (0.49942593826338005, 0.027259604707972507)\n",
      "------------oot------------\n",
      " (0.4734438536127619, 0.00046571438501374907)\n",
      "隐藏层vs神经元数vs norm 2 12 0.01\n",
      "验证集最优结果： 0.603969156742096 0.5933113694190979\n",
      "------------train------------\n",
      " (0.4480823856426125, 0.0017458760817820052)\n",
      "------------test------------\n",
      " (0.4585143237841439, 0.003986231401288065)\n",
      "------------oot------------\n",
      " (0.441902709716285, 0.01036388280679812)\n",
      "隐藏层vs神经元数vs norm 2 12 0.05\n",
      "验证集最优结果： 0.7107963562011719 0.6985893845558167\n",
      "------------train------------\n",
      " (0.48212906732072724, 0.0049193963746473335)\n",
      "------------test------------\n",
      " (0.44593604263824116, 0.00912724850099933)\n",
      "------------oot------------\n",
      " (0.484907146746371, 0.019740729155805714)\n",
      "隐藏层vs神经元数vs norm 2 12 0.1\n",
      "验证集最优结果： 0.8427100777626038 0.8286296129226685\n",
      "------------train------------\n",
      " (0.5526823319046065, 0.0753963177960108)\n",
      "------------test------------\n",
      " (0.5466766600044415, 0.109171663335554)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.5375548836293284, 0.07119869321933758)\n",
      "隐藏层vs神经元数vs norm 2 12 0.2\n",
      "验证集最优结果： 1.1166062355041504 1.1053763628005981\n",
      "------------train------------\n",
      " (0.5017557573776394, 0.01464110253604134)\n",
      "------------test------------\n",
      " (0.51293915167666, 0.034465911614479317)\n",
      "------------oot------------\n",
      " (0.49438130654896373, 0.012282348034615809)\n",
      "隐藏层vs神经元数vs norm 2 12 0.3\n",
      "验证集最优结果： 1.381953239440918 1.3589918613433838\n",
      "------------train------------\n",
      " (0.5165663985857565, 0.03551811491947082)\n",
      "------------test------------\n",
      " (0.5104319342660447, 0.03427714856762154)\n",
      "------------oot------------\n",
      " (0.5106650911155134, 0.026733395891982092)\n",
      "隐藏层vs神经元数vs norm 2 12 0.4\n",
      "验证集最优结果： 1.6295584440231323 1.599900484085083\n",
      "------------train------------\n",
      " (0.45951680463256805, 0.0008552058524343709)\n",
      "------------test------------\n",
      " (0.4623051299133911, 0.008971796580057739)\n",
      "------------oot------------\n",
      " (0.46389555022648554, 0.005261877454558084)\n",
      "隐藏层vs神经元数vs norm 2 12 0.5\n",
      "验证集最优结果： 1.892435073852539 1.8669838905334473\n",
      "------------train------------\n",
      " (0.49287633016793464, 0.010558232303851223)\n",
      "------------test------------\n",
      " (0.501301354652454, 0.03155673995114369)\n",
      "------------oot------------\n",
      " (0.46164228037859567, 0.011038126020922356)\n",
      "隐藏层vs神经元数vs norm 2 12 0.8\n",
      "验证集最优结果： 2.682290554046631 2.612264394760132\n",
      "------------train------------\n",
      " (0.4259526821288643, 0.0022197722022904293)\n",
      "------------test------------\n",
      " (0.439737952476127, 0.005363091272485011)\n",
      "------------oot------------\n",
      " (0.4316129704931707, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 2 13 0.01\n",
      "验证集最优结果： 0.6057073473930359 0.594927191734314\n",
      "------------train------------\n",
      " (0.4734320380037346, 0.003077955979503777)\n",
      "------------test------------\n",
      " (0.4729524761270265, 0.0035087719298245615)\n",
      "------------oot------------\n",
      " (0.5065327448186377, 0.03411531644249821)\n",
      "隐藏层vs神经元数vs norm 2 13 0.05\n",
      "验证集最优结果： 0.7202250361442566 0.7070276141166687\n",
      "------------train------------\n",
      " (0.4746058818075191, 0.008527422964808351)\n",
      "------------test------------\n",
      " (0.48323784143904064, 0.007994670219853431)\n",
      "------------oot------------\n",
      " (0.5206374031209815, 0.0600702047058006)\n",
      "隐藏层vs神经元数vs norm 2 13 0.1\n",
      "验证集最优结果： 0.8618748188018799 0.8474305868148804\n",
      "------------train------------\n",
      " (0.5328167987443987, 0.05041315322302825)\n",
      "------------test------------\n",
      " (0.5369942260715079, 0.05860537419498113)\n",
      "------------oot------------\n",
      " (0.5376695744853391, 0.08463490077503211)\n",
      "隐藏层vs神经元数vs norm 2 13 0.2\n",
      "验证集最优结果： 1.1474652290344238 1.125238299369812\n",
      "------------train------------\n",
      " (0.5135325023569597, 0.03082490546780836)\n",
      "------------test------------\n",
      " (0.5317799244947813, 0.056173662003109026)\n",
      "------------oot------------\n",
      " (0.5561510212120159, 0.09156500886247532)\n",
      "隐藏层vs神经元数vs norm 2 13 0.3\n",
      "验证集最优结果： 1.4418256282806396 1.4141502380371094\n",
      "------------train------------\n",
      " (0.5126528639853163, 0.029151176381807864)\n",
      "------------test------------\n",
      " (0.5174139462580503, 0.04875638463246723)\n",
      "------------oot------------\n",
      " (0.49264472479987015, 0.05870781635561115)\n",
      "隐藏层vs神经元数vs norm 2 13 0.4\n",
      "验证集最优结果： 1.7358105182647705 1.716523289680481\n",
      "------------train------------\n",
      " (0.531401066232431, 0.060166939755904925)\n",
      "------------test------------\n",
      " (0.5563424383744171, 0.10282034199422602)\n",
      "------------oot------------\n",
      " (0.5651814780060009, 0.1053696173495986)\n",
      "隐藏层vs神经元数vs norm 2 13 0.5\n",
      "验证集最优结果： 2.0079305171966553 1.9836872816085815\n",
      "------------train------------\n",
      " (0.5051281218296099, 0.03156085896886651)\n",
      "------------test------------\n",
      " (0.5065312014212746, 0.04113924050632911)\n",
      "------------oot------------\n",
      " (0.49745594828485035, 0.020206443540819574)\n",
      "隐藏层vs神经元数vs norm 2 13 0.8\n",
      "验证集最优结果： 2.930830955505371 2.903203248977661\n",
      "------------train------------\n",
      " (0.48306555698360587, 0.004672093257775289)\n",
      "------------test------------\n",
      " (0.4977648234510327, 0.03317788141239175)\n",
      "------------oot------------\n",
      " (0.48197731669736676, 0.010739234699197187)\n",
      "隐藏层vs神经元数vs norm 2 14 0.01\n",
      "验证集最优结果： 0.6088795065879822 0.59786057472229\n",
      "------------train------------\n",
      " (0.48803625488058183, 0.014689020052939372)\n",
      "------------test------------\n",
      " (0.5128036864312681, 0.04173884077281809)\n",
      "------------oot------------\n",
      " (0.46370324030630566, 0.00809091856949229)\n",
      "隐藏层vs神经元数vs norm 2 14 0.05\n",
      "验证集最优结果： 0.7331804037094116 0.7199914455413818\n",
      "------------train------------\n",
      " (0.48380672185302714, 0.0037351298341363748)\n",
      "------------test------------\n",
      " (0.493217854763491, 0.028281145902731453)\n",
      "------------oot------------\n",
      " (0.49376962198357255, 0.01668230632885004)\n",
      "隐藏层vs神经元数vs norm 2 14 0.1\n",
      "验证集最优结果： 0.8851966857910156 0.8687713146209717\n",
      "------------train------------\n",
      " (0.46218671723724386, 0.005357828118242591)\n",
      "------------test------------\n",
      " (0.46907284032866975, 0.011769931157006433)\n",
      "------------oot------------\n",
      " (0.4792085172441757, 0.007659958989330362)\n",
      "隐藏层vs神经元数vs norm 2 14 0.2\n",
      "验证集最优结果： 1.1950128078460693 1.1751364469528198\n",
      "------------train------------\n",
      " (0.4998916441461106, 0.015044746703809508)\n",
      "------------test------------\n",
      " (0.5035665112147457, 0.03354430379746831)\n",
      "------------oot------------\n",
      " (0.5069891912556911, 0.02934000625586486)\n",
      "隐藏层vs神经元数vs norm 2 14 0.3\n",
      "验证集最优结果： 1.4943017959594727 1.4692487716674805\n",
      "------------train------------\n",
      " (0.5090252778437659, 0.024214183178921156)\n",
      "------------test------------\n",
      " (0.4854041749944481, 0.004630246502331778)\n",
      "------------oot------------\n",
      " (0.48054310175048365, 0.02013693393111593)\n",
      "隐藏层vs神经元数vs norm 2 14 0.4\n",
      "验证集最优结果： 1.7984496355056763 1.7730519771575928\n",
      "------------train------------\n",
      " (0.5290578455120305, 0.04479001907902258)\n",
      "------------test------------\n",
      " (0.5293626471241395, 0.06289140572951357)\n",
      "------------oot------------\n",
      " (0.5517047231779794, 0.08548291801341534)\n",
      "隐藏层vs神经元数vs norm 2 14 0.5\n",
      "验证集最优结果： 2.1374073028564453 2.1117775440216064\n",
      "------------train------------\n",
      " (0.45910158716622707, 0.0)\n",
      "------------test------------\n",
      " (0.4492971352431713, 0.0035087719298245615)\n",
      "------------oot------------\n",
      " (0.45943419177701317, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 2 14 0.8\n",
      "验证集最优结果： 3.0724329948425293 3.0286061763763428\n",
      "------------train------------\n",
      " (0.5329267112407862, 0.05915417461061945)\n",
      "------------test------------\n",
      " (0.5308760826115922, 0.06039307128580951)\n",
      "------------oot------------\n",
      " (0.5182381630927142, 0.04117054182740763)\n",
      "隐藏层vs神经元数vs norm 2 15 0.01\n",
      "验证集最优结果： 0.6101382374763489 0.5995579361915588\n",
      "------------train------------\n",
      " (0.5230716075853158, 0.049138059976758686)\n",
      "------------test------------\n",
      " (0.4948600932711526, 0.02660448589829001)\n",
      "------------oot------------\n",
      " (0.5411056661916843, 0.09447746150905362)\n",
      "隐藏层vs神经元数vs norm 2 15 0.05\n",
      "验证集最优结果： 0.7441933155059814 0.732276201248169\n",
      "------------train------------\n",
      " (0.4695474028096721, 0.0023360466288876447)\n",
      "------------test------------\n",
      " (0.46196091494559177, 0.014057295136575613)\n",
      "------------oot------------\n",
      " (0.44066428017006687, 0.006693775414451153)\n",
      "隐藏层vs神经元数vs norm 2 15 0.1\n",
      "验证集最优结果： 0.9079440236091614 0.8943853378295898\n",
      "------------train------------\n",
      " (0.504212139239641, 0.023834362409384746)\n",
      "------------test------------\n",
      " (0.48396402398401067, 0.012358427714856762)\n",
      "------------oot------------\n",
      " (0.5282695582664303, 0.0566850867132381)\n",
      "隐藏层vs神经元数vs norm 2 15 0.2\n",
      "验证集最优结果： 1.2281553745269775 1.207553744316101\n",
      "------------train------------\n",
      " (0.47940548438992137, 0.00316661692178688)\n",
      "------------test------------\n",
      " (0.47778703086831, 0.012735953808572065)\n",
      "------------oot------------\n",
      " (0.49518877651501986, 0.017439961074618537)\n",
      "隐藏层vs神经元数vs norm 2 15 0.3\n",
      "验证集最优结果： 1.5832418203353882 1.5626606941223145\n",
      "------------train------------\n",
      " (0.4932007209285169, 0.008866364948742378)\n",
      "------------test------------\n",
      " (0.48700199866755506, 0.009715745058849645)\n",
      "------------oot------------\n",
      " (0.4802685387921547, 0.03157821568831891)\n",
      "隐藏层vs神经元数vs norm 2 15 0.4\n",
      "验证集最优结果： 1.90719473361969 1.8827086687088013\n",
      "------------train------------\n",
      " (0.5370321866292531, 0.0694963720077778)\n",
      "------------test------------\n",
      " (0.5231523428825228, 0.04210526315789473)\n",
      "------------oot------------\n",
      " (0.5514718659854724, 0.08431515657039584)\n",
      "隐藏层vs神经元数vs norm 2 15 0.5\n",
      "验证集最优结果： 2.246105670928955 2.2312965393066406\n",
      "------------train------------\n",
      " (0.5007243125223767, 0.0181032108120327)\n",
      "------------test------------\n",
      " (0.4610870530757273, 0.0035087719298245615)\n",
      "------------oot------------\n",
      " (0.4852732306908097, 0.027928961178882883)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 2 15 0.8\n",
      "验证集最优结果： 3.246650218963623 3.2142279148101807\n",
      "------------train------------\n",
      " (0.4857088036254881, 0.01203595979530836)\n",
      "------------test------------\n",
      " (0.49305463024650237, 0.028758605374195056)\n",
      "------------oot------------\n",
      " (0.5039944855709635, 0.02954158412400515)\n",
      "隐藏层vs神经元数vs norm 2 16 0.01\n",
      "验证集最优结果： 0.6066508293151855 0.6007049679756165\n",
      "------------train------------\n",
      " (0.6818039997590588, 0.27491037461616913)\n",
      "------------test------------\n",
      " (0.6645003331112591, 0.24556962025316453)\n",
      "------------oot------------\n",
      " (0.6400850334225374, 0.21568136794911902)\n",
      "隐藏层vs神经元数vs norm 2 16 0.05\n",
      "验证集最优结果： 0.7563672065734863 0.7439347505569458\n",
      "------------train------------\n",
      " (0.4968272241883293, 0.019991891922988225)\n",
      "------------test------------\n",
      " (0.49442926937597154, 0.018565400843881856)\n",
      "------------oot------------\n",
      " (0.4834729317994879, 0.03262781079484239)\n",
      "隐藏层vs神经元数vs norm 2 16 0.1\n",
      "验证集最优结果： 0.9335818886756897 0.9213960766792297\n",
      "------------train------------\n",
      " (0.5089480548398384, 0.027616056158246916)\n",
      "------------test------------\n",
      " (0.5462458361092605, 0.08105707306240284)\n",
      "------------oot------------\n",
      " (0.5057044219696706, 0.0346296875543044)\n",
      "隐藏层vs神经元数vs norm 2 16 0.2\n",
      "验证集最优结果： 1.285407304763794 1.2669540643692017\n",
      "------------train------------\n",
      " (0.5412579295707254, 0.05591378637044436)\n",
      "------------test------------\n",
      " (0.5239029535864979, 0.06128136797690431)\n",
      "------------oot------------\n",
      " (0.5371262410361565, 0.06543634657491398)\n",
      "隐藏层vs神经元数vs norm 2 16 0.3\n",
      "验证集最优结果： 1.6364784240722656 1.6053065061569214\n",
      "------------train------------\n",
      " (0.458771037515761, 0.007021946628819942)\n",
      "------------test------------\n",
      " (0.4774206084832334, 0.007650455252054211)\n",
      "------------oot------------\n",
      " (0.4486509343250038, 0.010621068362701158)\n",
      "隐藏层vs神经元数vs norm 2 16 0.4\n",
      "验证集最优结果： 1.9853681325912476 1.9467549324035645\n",
      "------------train------------\n",
      " (0.4935835873029409, 0.0037686991680084825)\n",
      "------------test------------\n",
      " (0.5022618254497002, 0.038529868976238)\n",
      "------------oot------------\n",
      " (0.4716331282799847, 0.01010669725089497)\n",
      "隐藏层vs神经元数vs norm 2 16 0.5\n",
      "验证集最优结果： 2.337200164794922 2.3034508228302\n",
      "------------train------------\n",
      " (0.4816113144898375, 0.0006079027355623268)\n",
      "------------test------------\n",
      " (0.4963746391294693, 0.03356651121474563)\n",
      "------------oot------------\n",
      " (0.5180006719262271, 0.035206617314843786)\n",
      "隐藏层vs神经元数vs norm 2 16 0.8\n",
      "验证集最优结果： 3.4359042644500732 3.406057834625244\n",
      "------------train------------\n",
      " (0.511135814350755, 0.030083266837626632)\n",
      "------------test------------\n",
      " (0.528681989784588, 0.04915611814345988)\n",
      "------------oot------------\n",
      " (0.5092065478052341, 0.02407117784033641)\n",
      "隐藏层vs神经元数vs norm 2 17 0.01\n",
      "验证集最优结果： 0.6136330366134644 0.6025232076644897\n",
      "------------train------------\n",
      " (0.5252731061582807, 0.04658855028530551)\n",
      "------------test------------\n",
      " (0.49939484787919164, 0.025027759271596728)\n",
      "------------oot------------\n",
      " (0.4837162154334504, 0.013644736384805234)\n",
      "隐藏层vs神经元数vs norm 2 17 0.05\n",
      "验证集最优结果： 0.7641409635543823 0.752567708492279\n",
      "------------train------------\n",
      " (0.48228831861629373, 0.005142063931984242)\n",
      "------------test------------\n",
      " (0.46275705085498553, 0.002831445702864757)\n",
      "------------oot------------\n",
      " (0.47177330599288686, 0.010419490494560923)\n",
      "隐藏层vs神经元数vs norm 2 17 0.1\n",
      "验证集最优结果： 0.9543226361274719 0.9415947198867798\n",
      "------------train------------\n",
      " (0.5265501621277001, 0.04522276569349437)\n",
      "------------test------------\n",
      " (0.5741094825671774, 0.12248500999333778)\n",
      "------------oot------------\n",
      " (0.5392462841321145, 0.07919229833524488)\n",
      "隐藏层vs神经元数vs norm 2 17 0.2\n",
      "验证集最优结果： 1.3302110433578491 1.313177227973938\n",
      "------------train------------\n",
      " (0.5326476661529745, 0.045078877782583016)\n",
      "------------test------------\n",
      " (0.5145347546080391, 0.050055518543193456)\n",
      "------------oot------------\n",
      " (0.5191823352911873, 0.05560073680186284)\n",
      "隐藏层vs神经元数vs norm 2 17 0.3\n",
      "验证集最优结果： 1.6994743347167969 1.6770216226577759\n",
      "------------train------------\n",
      " (0.49808201340201513, 0.008492229308329602)\n",
      "------------test------------\n",
      " (0.520641794359316, 0.04193870752831441)\n",
      "------------oot------------\n",
      " (0.4917434168607144, 0.018628575400549074)\n",
      "隐藏层vs神经元数vs norm 2 17 0.4\n",
      "验证集最优结果： 2.085681915283203 2.0671465396881104\n",
      "------------train------------\n",
      " (0.48779849465902425, 0.005894802099978391)\n",
      "------------test------------\n",
      " (0.4853086831001555, 0.012358427714856735)\n",
      "------------oot------------\n",
      " (0.4997474484180771, 0.025774163278073137)\n",
      "隐藏层vs神经元数vs norm 2 17 0.5\n",
      "验证集最优结果： 2.456892728805542 2.445469617843628\n",
      "------------train------------\n",
      " (0.46065477797878773, 0.0018197827603874117)\n",
      "------------test------------\n",
      " (0.4733033533200089, 0.0054630246502331775)\n",
      "------------oot------------\n",
      " (0.4904771834706148, 0.007555694574774896)\n",
      "隐藏层vs神经元数vs norm 2 17 0.8\n",
      "验证集最优结果： 3.6231160163879395 3.591557264328003\n",
      "------------train------------\n",
      " (0.5464148831266045, 0.07545330444746295)\n",
      "------------test------------\n",
      " (0.5361658894070619, 0.06526759937819238)\n",
      "------------oot------------\n",
      " (0.5551361809103441, 0.09341396448058936)\n",
      "隐藏层vs神经元数vs norm 2 18 0.01\n",
      "验证集最优结果： 0.6171332001686096 0.606261670589447\n",
      "------------train------------\n",
      " (0.5182820216589883, 0.04564224700667796)\n",
      "------------test------------\n",
      " (0.5304663557628249, 0.05355318676437931)\n",
      "------------oot------------\n",
      " (0.5455033074989284, 0.08589997567163654)\n",
      "隐藏层vs神经元数vs norm 2 18 0.05\n",
      "验证集最优结果： 0.779951810836792 0.7680215835571289\n",
      "------------train------------\n",
      " (0.5572723291906339, 0.08850378907088063)\n",
      "------------test------------\n",
      " (0.546393515434155, 0.08427714856762158)\n",
      "------------oot------------\n",
      " (0.5481307707457221, 0.07108052688284155)\n",
      "隐藏层vs神经元数vs norm 2 18 0.1\n",
      "验证集最优结果： 0.9755460023880005 0.9615708589553833\n",
      "------------train------------\n",
      " (0.4737462767480249, 0.008651548284004718)\n",
      "------------test------------\n",
      " (0.46500888296691095, 0.013824117255163193)\n",
      "------------oot------------\n",
      " (0.47187061944647185, 0.007326312862753287)\n",
      "隐藏层vs神经元数vs norm 2 18 0.2\n",
      "验证集最优结果： 1.3768315315246582 1.3633670806884766\n",
      "------------train------------\n",
      " (0.5084315879310123, 0.02685154165135395)\n",
      "------------test------------\n",
      " (0.525396402398401, 0.045114368198978405)\n",
      "------------oot------------\n",
      " (0.5074966114065269, 0.0579432106488722)\n",
      "隐藏层vs神经元数vs norm 2 18 0.3\n",
      "验证集最优结果： 1.758478045463562 1.728585124015808\n",
      "------------train------------\n",
      " (0.5241752671164687, 0.042821610800121035)\n",
      "------------test------------\n",
      " (0.4985465245391961, 0.019398178991783255)\n",
      "------------oot------------\n",
      " (0.507771174364856, 0.0401904563305876)\n",
      "隐藏层vs神经元数vs norm 2 18 0.4\n",
      "验证集最优结果： 2.175783395767212 2.1595404148101807\n",
      "------------train------------\n",
      " (0.4803315513160735, 0.0032828913483839983)\n",
      "------------test------------\n",
      " (0.5015567399511436, 0.022529424827892497)\n",
      "------------oot------------\n",
      " (0.475251103465054, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 2 18 0.5\n",
      "验证集最优结果： 2.579693555831909 2.554344415664673\n",
      "------------train------------\n",
      " (0.5126489385390165, 0.029499864301382295)\n",
      "------------test------------\n",
      " (0.5055463024650233, 0.029047301798800884)\n",
      "------------oot------------\n",
      " (0.4846661800993987, 0.0040176554408647425)\n",
      "隐藏层vs神经元数vs norm 2 18 0.8\n",
      "验证集最优结果： 3.74088978767395 3.673091173171997\n",
      "------------train------------\n",
      " (0.535807718104226, 0.05423369535423439)\n",
      "------------test------------\n",
      " (0.5423628691983123, 0.07287363979569178)\n",
      "------------oot------------\n",
      " (0.5618172128963496, 0.10477878566711846)\n",
      "隐藏层vs神经元数vs norm 2 19 0.01\n",
      "验证集最优结果： 0.6171753406524658 0.6062595248222351\n",
      "------------train------------\n",
      " (0.5706902491237118, 0.11642995548679258)\n",
      "------------test------------\n",
      " (0.5370164334887852, 0.0686098156784366)\n",
      "------------oot------------\n",
      " (0.5708314507814038, 0.1029854377367671)\n",
      "隐藏层vs神经元数vs norm 2 19 0.05\n",
      "验证集最优结果： 0.7885903716087341 0.7767527103424072\n",
      "------------train------------\n",
      " (0.4610003526133659, 0.0015054763359884094)\n",
      "------------test------------\n",
      " (0.4793892960248723, 0.004308238951809904)\n",
      "------------oot------------\n",
      " (0.4397930930617825, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 19 0.1\n",
      "验证集最优结果： 0.9924528002738953 0.9742574095726013\n",
      "------------train------------\n",
      " (0.5362597535496525, 0.06411201328695887)\n",
      "------------test------------\n",
      " (0.520861647790362, 0.0442260715078836)\n",
      "------------oot------------\n",
      " (0.5060589209791587, 0.02716435547214402)\n",
      "隐藏层vs神经元数vs norm 2 19 0.2\n",
      "验证集最优结果： 1.4159761667251587 1.3990451097488403\n",
      "------------train------------\n",
      " (0.5040473381751683, 0.018776492532515177)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.48666555629580277, 0.02904730179880083)\n",
      "------------oot------------\n",
      " (0.5005016276833606, 0.028366871720015292)\n",
      "隐藏层vs神经元数vs norm 2 19 0.3\n",
      "验证集最优结果： 1.8458664417266846 1.8270790576934814\n",
      "------------train------------\n",
      " (0.5142696064198644, 0.029062380079307615)\n",
      "------------test------------\n",
      " (0.5077159671330225, 0.0223961803242283)\n",
      "------------oot------------\n",
      " (0.5032368308251949, 0.03009071004066316)\n",
      "隐藏层vs神经元数vs norm 2 19 0.4\n",
      "验证集最优结果： 2.2628486156463623 2.2408950328826904\n",
      "------------train------------\n",
      " (0.48599813608980874, 0.002162650190621007)\n",
      "------------test------------\n",
      " (0.49770153231179215, 0.05608483233399958)\n",
      "------------oot------------\n",
      " (0.4880721509748723, 0.01700900149445661)\n",
      "隐藏层vs神经元数vs norm 2 19 0.5\n",
      "验证集最优结果： 2.690120220184326 2.684339761734009\n",
      "------------train------------\n",
      " (0.5313610672882407, 0.05317950998247756)\n",
      "------------test------------\n",
      " (0.5242982456140352, 0.05614035087719299)\n",
      "------------oot------------\n",
      " (0.5211900045181247, 0.047669690334688763)\n",
      "隐藏层vs神经元数vs norm 2 19 0.8\n",
      "验证集最优结果： 3.9624834060668945 3.9158830642700195\n",
      "------------train------------\n",
      " (0.5568133903741289, 0.09084484402780568)\n",
      "------------test------------\n",
      " (0.5495103264490341, 0.0664890073284477)\n",
      "------------oot------------\n",
      " (0.5896384341801921, 0.1409863413616933)\n",
      "隐藏层vs神经元数vs norm 2 20 0.01\n",
      "验证集最优结果： 0.6208896636962891 0.6100396513938904\n",
      "------------train------------\n",
      " (0.5348214835615169, 0.0649524648757156)\n",
      "------------test------------\n",
      " (0.5319375971574507, 0.06934266044858983)\n",
      "------------oot------------\n",
      " (0.548891900971976, 0.10600215479790087)\n",
      "隐藏层vs神经元数vs norm 2 20 0.05\n",
      "验证集最优结果： 0.7955533862113953 0.7821534872055054\n",
      "------------train------------\n",
      " (0.45130450025346197, 0.0009044769715046419)\n",
      "------------test------------\n",
      " (0.4637186320230957, 0.0035087719298245615)\n",
      "------------oot------------\n",
      " (0.4741435836837776, 0.019205505161088543)\n",
      "隐藏层vs神经元数vs norm 2 20 0.1\n",
      "验证集最优结果： 1.0234315395355225 1.01223623752594\n",
      "------------train------------\n",
      " (0.5290505360603002, 0.04599607861450694)\n",
      "------------test------------\n",
      " (0.5115467466133689, 0.04383744170552964)\n",
      "------------oot------------\n",
      " (0.5058272222801469, 0.02529454697111877)\n",
      "隐藏层vs神经元数vs norm 2 20 0.2\n",
      "验证集最优结果： 1.4541155099868774 1.4365068674087524\n",
      "------------train------------\n",
      " (0.5055825937589465, 0.0236988668319415)\n",
      "------------test------------\n",
      " (0.4909671330224296, 0.019520319786808793)\n",
      "------------oot------------\n",
      " (0.47460698108180127, 0.005213220727765616)\n",
      "隐藏层vs神经元数vs norm 2 20 0.3\n",
      "验证集最优结果： 1.9188098907470703 1.8961756229400635\n",
      "------------train------------\n",
      " (0.4896760762321672, 0.008426038162106075)\n",
      "------------test------------\n",
      " (0.48664445924938926, 0.015001110370863935)\n",
      "------------oot------------\n",
      " (0.47506226902535936, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 2 20 0.4\n",
      "验证集最优结果： 2.325420618057251 2.288336992263794\n",
      "------------train------------\n",
      " (0.42605447301221827, 0.000565534987570548)\n",
      "------------test------------\n",
      " (0.40793248945147675, 0.005263157894736842)\n",
      "------------oot------------\n",
      " (0.385633522167773, 0.00046571438501374907)\n",
      "隐藏层vs神经元数vs norm 2 20 0.5\n",
      "验证集最优结果： 2.7541439533233643 2.709665536880493\n",
      "------------train------------\n",
      " (0.5032043824223928, 0.01769361079470655)\n",
      "------------test------------\n",
      " (0.4992582722629359, 0.03842993559848995)\n",
      "------------oot------------\n",
      " (0.5268144904366362, 0.04292218399193681)\n",
      "隐藏层vs神经元数vs norm 2 20 0.8\n",
      "验证集最优结果： 4.14483642578125 4.099494457244873\n",
      "------------train------------\n",
      " (0.5000506247212426, 0.020819213570673928)\n",
      "------------test------------\n",
      " (0.49277592715967133, 0.022096380190983783)\n",
      "------------oot------------\n",
      " (0.4957529628471136, 0.013783755604212189)\n",
      "隐藏层vs神经元数vs norm 2 22 0.01\n",
      "验证集最优结果： 0.6245076656341553 0.6136934757232666\n",
      "------------train------------\n",
      " (0.5056219159020506, 0.01734275711165656)\n",
      "------------test------------\n",
      " (0.4787408394403731, 0.015156562291805453)\n",
      "------------oot------------\n",
      " (0.5362886502392289, 0.06914815973308308)\n",
      "隐藏层vs神经元数vs norm 2 22 0.05\n",
      "验证集最优结果： 0.8179620504379272 0.8044781684875488\n",
      "------------train------------\n",
      " (0.4987234854714495, 0.02089068376536929)\n",
      "------------test------------\n",
      " (0.4810170997113036, 0.010193204530313131)\n",
      "------------oot------------\n",
      " (0.47074108828878924, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 22 0.1\n",
      "验证集最优结果： 1.069000244140625 1.0540534257888794\n",
      "------------train------------\n",
      " (0.5071586604482183, 0.02082462797936291)\n",
      "------------test------------\n",
      " (0.49563957361758837, 0.014679102820341995)\n",
      "------------oot------------\n",
      " (0.5260394582884418, 0.048128453758732204)\n",
      "隐藏层vs神经元数vs norm 2 22 0.2\n",
      "验证集最优结果： 1.5509920120239258 1.5372196435928345\n",
      "------------train------------\n",
      " (0.5392975075446401, 0.0748493271582002)\n",
      "------------test------------\n",
      " (0.5269209415944925, 0.05015545192094162)\n",
      "------------oot------------\n",
      " (0.5531354626443773, 0.09524901817676301)\n",
      "隐藏层vs神经元数vs norm 2 22 0.3\n",
      "验证集最优结果： 2.050032377243042 2.031862258911133\n",
      "------------train------------\n",
      " (0.5054160330116498, 0.013055492951455097)\n",
      "------------test------------\n",
      " (0.48879302687097487, 0.018454363757494985)\n",
      "------------oot------------\n",
      " (0.5173426476210337, 0.04183783408056163)\n",
      "隐藏层vs神经元数vs norm 2 22 0.4\n",
      "验证集最优结果： 2.5217790603637695 2.5013723373413086\n",
      "------------train------------\n",
      " (0.5050888673666143, 0.028267274163321532)\n",
      "------------test------------\n",
      " (0.4883200088829669, 0.01752165223184543)\n",
      "------------oot------------\n",
      " (0.4831462366338813, 0.01328328641434684)\n",
      "隐藏层vs神经元数vs norm 2 22 0.5\n",
      "验证集最优结果： 2.959301471710205 2.908719778060913\n",
      "------------train------------\n",
      " (0.5261773800894596, 0.05026127905930067)\n",
      "------------test------------\n",
      " (0.5267110815012214, 0.05944925605152124)\n",
      "------------oot------------\n",
      " (0.5277389682456933, 0.06453272164876794)\n",
      "隐藏层vs神经元数vs norm 2 22 0.8\n",
      "验证集最优结果： 4.489656925201416 4.427158832550049\n",
      "------------train------------\n",
      " (0.49713198771741385, 0.006257567482144344)\n",
      "------------test------------\n",
      " (0.4858072396180324, 0.014956695536309128)\n",
      "------------oot------------\n",
      " (0.45949559193225126, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 24 0.01\n",
      "验证集最优结果： 0.6287190914154053 0.6179930567741394\n",
      "------------train------------\n",
      " (0.4914398875427315, 0.004969885735672586)\n",
      "------------test------------\n",
      " (0.5051865423051299, 0.03617588274483674)\n",
      "------------oot------------\n",
      " (0.47438339183725475, 0.0023285719250686343)\n",
      "隐藏层vs神经元数vs norm 2 24 0.05\n",
      "验证集最优结果： 0.8463374376296997 0.8344774842262268\n",
      "------------train------------\n",
      " (0.4650873513321814, 0.00031823187069850677)\n",
      "------------test------------\n",
      " (0.4553097934710193, 0.006540084388185654)\n",
      "------------oot------------\n",
      " (0.43851527473673235, 0.006123796614881938)\n",
      "隐藏层vs神经元数vs norm 2 24 0.1\n",
      "验证集最优结果： 1.115239143371582 1.1030871868133545\n",
      "------------train------------\n",
      " (0.4789513508611279, 0.005880995357821273)\n",
      "------------test------------\n",
      " (0.4804519209415945, 0.016688874083944035)\n",
      "------------oot------------\n",
      " (0.47460118861432593, 0.002933305529489452)\n",
      "隐藏层vs神经元数vs norm 2 24 0.2\n",
      "验证集最优结果： 1.6316337585449219 1.6126396656036377\n",
      "------------train------------\n",
      " (0.5078339048918505, 0.031695000944137575)\n",
      "------------test------------\n",
      " (0.4956262491672219, 0.025949367088607567)\n",
      "------------oot------------\n",
      " (0.514857679074132, 0.03743092482535715)\n",
      "隐藏层vs神经元数vs norm 2 24 0.3\n",
      "验证集最优结果： 2.165987730026245 2.144138813018799\n",
      "------------train------------\n",
      " (0.5378451600939129, 0.06156331575680918)\n",
      "------------test------------\n",
      " (0.5442715967133023, 0.07456140350877194)\n",
      "------------oot------------\n",
      " (0.5513548581424714, 0.07976227713481387)\n",
      "隐藏层vs神经元数vs norm 2 24 0.4\n",
      "验证集最优结果： 2.7038443088531494 2.6871466636657715\n",
      "------------train------------\n",
      " (0.46022528000952934, 0.005665231171563034)\n",
      "------------test------------\n",
      " (0.49204197201865424, 0.017943593160115456)\n",
      "------------oot------------\n",
      " (0.479057913089818, 0.007124734994612969)\n",
      "隐藏层vs神经元数vs norm 2 24 0.5\n",
      "验证集最优结果： 3.243605136871338 3.2316298484802246\n",
      "------------train------------\n",
      " (0.5439721726465426, 0.0713556799515952)\n",
      "------------test------------\n",
      " (0.5352442815900511, 0.07260715078836333)\n",
      "------------oot------------\n",
      " (0.5472144023911306, 0.08039481458311612)\n",
      "隐藏层vs神经元数vs norm 2 24 0.8\n",
      "验证集最优结果： 4.8420729637146 4.7826056480407715\n",
      "------------train------------\n",
      " (0.5075269079191818, 0.024058248208676747)\n",
      "------------test------------\n",
      " (0.4677359538085721, 0.006617810348656494)\n",
      "------------oot------------\n",
      " (0.47487459307915986, 0.002481493066416429)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 2 26 0.01\n",
      "验证集最优结果： 0.6342704892158508 0.6234913468360901\n",
      "------------train------------\n",
      " (0.5178831150988231, 0.033873623640391204)\n",
      "------------test------------\n",
      " (0.5073328891849879, 0.03474350433044637)\n",
      "------------oot------------\n",
      " (0.5254324076970308, 0.05459979842213189)\n",
      "隐藏层vs神经元数vs norm 2 26 0.05\n",
      "验证集最优结果： 0.8619185090065002 0.8486661911010742\n",
      "------------train------------\n",
      " (0.4913136641401682, 0.004498696819508652)\n",
      "------------test------------\n",
      " (0.4857994670219854, 0.01567843659782367)\n",
      "------------oot------------\n",
      " (0.4747158794703368, 0.010489000104264457)\n",
      "隐藏层vs神经元数vs norm 2 26 0.1\n",
      "验证集最优结果： 1.1481820344924927 1.1287521123886108\n",
      "------------train------------\n",
      " (0.520053480821826, 0.03692599653883927)\n",
      "------------test------------\n",
      " (0.5545813901843215, 0.09063957361758834)\n",
      "------------oot------------\n",
      " (0.557545847380067, 0.10532791158377647)\n",
      "隐藏层vs神经元数vs norm 2 26 0.2\n",
      "验证集最优结果： 1.723750114440918 1.7047396898269653\n",
      "------------train------------\n",
      " (0.571795059216711, 0.10368673855647809)\n",
      "------------test------------\n",
      " (0.565531867643793, 0.10716189207195204)\n",
      "------------oot------------\n",
      " (0.597015720756728, 0.167928266082786)\n",
      "隐藏层vs神经元数vs norm 2 26 0.3\n",
      "验证集最优结果： 2.3130595684051514 2.2916038036346436\n",
      "------------train------------\n",
      " (0.49906682666244345, 0.014109949043646264)\n",
      "------------test------------\n",
      " (0.5135887186320232, 0.04820119920053298)\n",
      "------------oot------------\n",
      " (0.4986480380912661, 0.035435999026865506)\n",
      "隐藏层vs神经元数vs norm 2 26 0.4\n",
      "验证集最优结果： 2.8777859210968018 2.837183713912964\n",
      "------------train------------\n",
      " (0.48725048881958444, 0.010431941221179297)\n",
      "------------test------------\n",
      " (0.46655340883855206, 0.00488563180102154)\n",
      "------------oot------------\n",
      " (0.4960889259606807, 0.023563757689500586)\n",
      "隐藏层vs神经元数vs norm 2 26 0.5\n",
      "验证集最优结果： 3.469512939453125 3.4447453022003174\n",
      "------------train------------\n",
      " (0.4711656342066098, 0.005215970610589649)\n",
      "------------test------------\n",
      " (0.45657117477237397, 0.002631578947368421)\n",
      "------------oot------------\n",
      " (0.478528481562576, 0.010614117401730794)\n",
      "隐藏层vs神经元数vs norm 2 26 0.8\n",
      "验证集最优结果： 5.222447395324707 5.1947760581970215\n",
      "------------train------------\n",
      " (0.5176517168074751, 0.0363527460188868)\n",
      "------------test------------\n",
      " (0.525438596491228, 0.057272929158338926)\n",
      "------------oot------------\n",
      " (0.528165293851875, 0.07691238313696869)\n",
      "隐藏层vs神经元数vs norm 2 28 0.01\n",
      "验证集最优结果： 0.6387637257575989 0.6276180148124695\n",
      "------------train------------\n",
      " (0.48506814371735707, 0.0007281026084590661)\n",
      "------------test------------\n",
      " (0.4749933377748167, 0.013768598711969782)\n",
      "------------oot------------\n",
      " (0.4625910865510491, 0.0033295103047995545)\n",
      "隐藏层vs神经元数vs norm 2 28 0.05\n",
      "验证集最优结果： 0.8904628157615662 0.879777193069458\n",
      "------------train------------\n",
      " (0.4809560356782461, 0.0035518521000122982)\n",
      "------------test------------\n",
      " (0.4809493670886075, 0.006884299355984891)\n",
      "------------oot------------\n",
      " (0.47549207011202627, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 28 0.1\n",
      "验证集最优结果： 1.1954820156097412 1.178053855895996\n",
      "------------train------------\n",
      " (0.5364466860096417, 0.06296605368792296)\n",
      "------------test------------\n",
      " (0.5314479236064846, 0.04908949589162781)\n",
      "------------oot------------\n",
      " (0.5073853960310012, 0.04133041392972581)\n",
      "隐藏层vs神经元数vs norm 2 28 0.2\n",
      "验证集最优结果： 1.7961550951004028 1.7728968858718872\n",
      "------------train------------\n",
      " (0.45693230432496196, 0.0010355056617794567)\n",
      "------------test------------\n",
      " (0.47709082833666444, 0.01672218520986013)\n",
      "------------oot------------\n",
      " (0.45609425503075796, 0.0018976123449067073)\n",
      "隐藏层vs神经元数vs norm 2 28 0.3\n",
      "验证集最优结果： 2.4340341091156006 2.4009344577789307\n",
      "------------train------------\n",
      " (0.5406417021818036, 0.06866282379009958)\n",
      "------------test------------\n",
      " (0.5367832556073729, 0.06633355540750618)\n",
      "------------oot------------\n",
      " (0.5425595755279835, 0.08544121224759321)\n",
      "隐藏层vs神经元数vs norm 2 28 0.4\n",
      "验证集最优结果： 3.0228734016418457 2.981194019317627\n",
      "------------train------------\n",
      " (0.5282635517573478, 0.04903965309883529)\n",
      "------------test------------\n",
      " (0.521266933155674, 0.047212969131689986)\n",
      "------------oot------------\n",
      " (0.5405044080677488, 0.09542974316199215)\n",
      "隐藏层vs神经元数vs norm 2 28 0.5\n",
      "验证集最优结果： 3.6909737586975098 3.672934055328369\n",
      "------------train------------\n",
      " (0.4377363304792632, 0.0032552778640699163)\n",
      "------------test------------\n",
      " (0.4493715300910504, 0.005562958027981345)\n",
      "------------oot------------\n",
      " (0.4452252690601142, 0.010885204879574673)\n",
      "隐藏层vs神经元数vs norm 2 28 0.8\n",
      "验证集最优结果： 5.57952356338501 5.545966625213623\n",
      "------------train------------\n",
      " (0.46114241316134463, 0.0008483024813558224)\n",
      "------------test------------\n",
      " (0.5048534310459694, 0.03472129691316905)\n",
      "------------oot------------\n",
      " (0.4864433091208193, 0.025252841205296583)\n",
      "隐藏层vs神经元数vs norm 2 30 0.01\n",
      "验证集最优结果： 0.6448394656181335 0.6338230967521667\n",
      "------------train------------\n",
      " (0.47774874301118286, 0.0034986555346424586)\n",
      "------------test------------\n",
      " (0.48408505440817234, 0.02588274483677549)\n",
      "------------oot------------\n",
      " (0.4539429326104334, 0.007020470580057725)\n",
      "隐藏层vs神经元数vs norm 2 30 0.05\n",
      "验证集最优结果： 0.9084072113037109 0.8925557136535645\n",
      "------------train------------\n",
      " (0.5518899331929649, 0.07969874230054158)\n",
      "------------test------------\n",
      " (0.5589951143681989, 0.1063735287586054)\n",
      "------------oot------------\n",
      " (0.5713307614777744, 0.13571751294616485)\n",
      "隐藏层vs神经元数vs norm 2 30 0.1\n",
      "验证集最优结果： 1.2359915971755981 1.2143545150756836\n",
      "------------train------------\n",
      " (0.4905255292753693, 0.011071382887355319)\n",
      "------------test------------\n",
      " (0.5112202975793916, 0.03265600710637362)\n",
      "------------oot------------\n",
      " (0.5058712450329592, 0.024370069162061636)\n",
      "隐藏层vs神经元数vs norm 2 30 0.2\n",
      "验证集最优结果： 1.879455804824829 1.8560175895690918\n",
      "------------train------------\n",
      " (0.49446742184131864, 0.015428357559428174)\n",
      "------------test------------\n",
      " (0.4918465467466133, 0.02093049078392184)\n",
      "------------oot------------\n",
      " (0.5145970180377438, 0.03333680881381851)\n",
      "隐藏层vs神经元数vs norm 2 30 0.3\n",
      "验证集最优结果： 2.5935733318328857 2.569676399230957\n",
      "------------train------------\n",
      " (0.5002743074802086, 0.021336966401563684)\n",
      "------------test------------\n",
      " (0.5089473684210526, 0.035332000888296695)\n",
      "------------oot------------\n",
      " (0.46959649671567094, 0.012351857644319342)\n",
      "隐藏层vs神经元数vs norm 2 30 0.4\n",
      "验证集最优结果： 3.260653495788574 3.2414357662200928\n",
      "------------train------------\n",
      " (0.4968145003279101, 0.03139138797689944)\n",
      "------------test------------\n",
      " (0.5092105263157894, 0.03607594936708858)\n",
      "------------oot------------\n",
      " (0.5081928659970574, 0.037396170020505326)\n",
      "隐藏层vs神经元数vs norm 2 30 0.5\n",
      "验证集最优结果： 3.9274723529815674 3.908245086669922\n",
      "------------train------------\n",
      " (0.5270955284429041, 0.054097929056356575)\n",
      "------------test------------\n",
      " (0.5298134576948701, 0.0741283588718632)\n",
      "------------oot------------\n",
      " (0.5505972033967029, 0.0896117888298057)\n",
      "隐藏层vs神经元数vs norm 2 30 0.8\n",
      "验证集最优结果： 5.933500289916992 5.892496109008789\n",
      "------------train------------\n",
      " (0.4873449025710997, 0.019132760624254286)\n",
      "------------test------------\n",
      " (0.4952487230735066, 0.01600044414834545)\n",
      "------------oot------------\n",
      " (0.48420973366234554, 0.027720432349772395)\n",
      "隐藏层vs神经元数vs norm 2 32 0.01\n",
      "验证集最优结果： 0.6483913064002991 0.6371493935585022\n",
      "------------train------------\n",
      " (0.5133966683789734, 0.022719264939876305)\n",
      "------------test------------\n",
      " (0.492288474350433, 0.029935598489895687)\n",
      "------------oot------------\n",
      " (0.542726398591272, 0.07523025058214297)\n",
      "隐藏层vs神经元数vs norm 2 32 0.05\n",
      "验证集最优结果： 0.9337337017059326 0.9195154905319214\n",
      "------------train------------\n",
      " (0.5253782810470654, 0.039778036315792686)\n",
      "------------test------------\n",
      " (0.5080246502331778, 0.03281145902731514)\n",
      "------------oot------------\n",
      " (0.5332174839838275, 0.06206513050429224)\n",
      "隐藏层vs神经元数vs norm 2 32 0.1\n",
      "验证集最优结果： 1.2890626192092896 1.272678017616272\n",
      "------------train------------\n",
      " (0.498316051217599, 0.00978288897958024)\n",
      "------------test------------\n",
      " (0.48082056406839885, 0.001554519209415961)\n",
      "------------oot------------\n",
      " (0.4786686592754782, 0.006937059048413442)\n",
      "隐藏层vs神经元数vs norm 2 32 0.2\n",
      "验证集最优结果： 1.9906588792800903 1.9727765321731567\n",
      "------------train------------\n",
      " (0.5443523994967306, 0.0790051565474752)\n",
      "------------test------------\n",
      " (0.525581834332667, 0.05812791472351764)\n",
      "------------oot------------\n",
      " (0.5155678355866031, 0.027011434330796225)\n",
      "隐藏层vs神经元数vs norm 2 32 0.3\n",
      "验证集最优结果： 2.7146213054656982 2.7061495780944824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " (0.4716025093077069, 0.01014227035631543)\n",
      "------------test------------\n",
      " (0.4900322007550522, 0.014779036198090068)\n",
      "------------oot------------\n",
      " (0.4484296620674475, 0.004260939074827164)\n",
      "隐藏层vs神经元数vs norm 2 32 0.4\n",
      "验证集最优结果： 3.4418728351593018 3.4155540466308594\n",
      "------------train------------\n",
      " (0.48599461672416094, 0.00267891405912124)\n",
      "------------test------------\n",
      " (0.4836364645791695, 0.00510770597379525)\n",
      "------------oot------------\n",
      " (0.5244013484864283, 0.07192854412122474)\n",
      "隐藏层vs神经元数vs norm 2 32 0.5\n",
      "验证集最优结果： 4.174686908721924 4.148560523986816\n",
      "------------train------------\n",
      " (0.5220201294179038, 0.032408620009353406)\n",
      "------------test------------\n",
      " (0.4906628914057295, 0.010726182544970021)\n",
      "------------oot------------\n",
      " (0.522591781647146, 0.06811246654850023)\n",
      "隐藏层vs神经元数vs norm 2 32 0.8\n",
      "验证集最优结果： 6.301677703857422 6.238352298736572\n",
      "------------train------------\n",
      " (0.46090465293978705, 0.0021981145675342706)\n",
      "------------test------------\n",
      " (0.4721141461248057, 0.016711081501221407)\n",
      "------------oot------------\n",
      " (0.4618230053638249, 0.0043443506064713144)\n",
      "隐藏层vs神经元数vs norm 2 34 0.01\n",
      "验证集最优结果： 0.6517060995101929 0.640911877155304\n",
      "------------train------------\n",
      " (0.504424654780686, 0.01972834558004899)\n",
      "------------test------------\n",
      " (0.515455252054186, 0.042971352431712184)\n",
      "------------oot------------\n",
      " (0.5244604316546762, 0.046731310603690956)\n",
      "隐藏层vs神经元数vs norm 2 34 0.05\n",
      "验证集最优结果： 0.9582707285881042 0.9468249082565308\n",
      "------------train------------\n",
      " (0.5047871494424174, 0.016142924146164694)\n",
      "------------test------------\n",
      " (0.5197568287808128, 0.05053297801465695)\n",
      "------------oot------------\n",
      " (0.505180782909904, 0.03682619122093633)\n",
      "隐藏层vs神经元数vs norm 2 34 0.1\n",
      "验证集最优结果： 1.3335057497024536 1.321879267692566\n",
      "------------train------------\n",
      " (0.5042913926468269, 0.025001032121656386)\n",
      "------------test------------\n",
      " (0.5012447257383966, 0.026515656229180617)\n",
      "------------oot------------\n",
      " (0.5076425815869045, 0.03282243770201221)\n",
      "隐藏层vs神经元数vs norm 2 34 0.2\n",
      "验证集最优结果： 2.091001510620117 2.076878309249878\n",
      "------------train------------\n",
      " (0.4887778258306549, 0.004272645256741148)\n",
      "------------test------------\n",
      " (0.5067033089051743, 0.028347768154563635)\n",
      "------------oot------------\n",
      " (0.4671300640646903, 0.008945886768845779)\n",
      "隐藏层vs神经元数vs norm 2 34 0.3\n",
      "验证集最优结果： 2.8523480892181396 2.8362927436828613\n",
      "------------train------------\n",
      " (0.5067184690217993, 0.021986289363597256)\n",
      "------------test------------\n",
      " (0.5214656895403065, 0.053053519875638444)\n",
      "------------oot------------\n",
      " (0.5270485061226381, 0.06509574948736663)\n",
      "隐藏层vs神经元数vs norm 2 34 0.4\n",
      "验证集最优结果： 3.6079137325286865 3.594064712524414\n",
      "------------train------------\n",
      " (0.5061022416328773, 0.01843051181728539)\n",
      "------------test------------\n",
      " (0.5117121918720853, 0.04222740395292024)\n",
      "------------oot------------\n",
      " (0.5520777580833884, 0.09211413477913322)\n",
      "隐藏层vs神经元数vs norm 2 34 0.5\n",
      "验证集最优结果： 4.368978023529053 4.355292320251465\n",
      "------------train------------\n",
      " (0.5007324341354102, 0.008305973649426424)\n",
      "------------test------------\n",
      " (0.5154930046635576, 0.03936264712413946)\n",
      "------------oot------------\n",
      " (0.49552473962858695, 0.01995620894588679)\n",
      "隐藏层vs神经元数vs norm 2 34 0.8\n",
      "验证集最优结果： 6.685111999511719 6.6347222328186035\n",
      "------------train------------\n",
      " (0.4974935348576247, 0.02369954363302762)\n",
      "------------test------------\n",
      " (0.48490117699311563, 0.029535864978902926)\n",
      "------------oot------------\n",
      " (0.4666979459910332, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 36 0.01\n",
      "验证集最优结果： 0.6577115058898926 0.6467458009719849\n",
      "------------train------------\n",
      " (0.46719159358906936, 0.0014276442110834342)\n",
      "------------test------------\n",
      " (0.5054585831667777, 0.04087275149900066)\n",
      "------------oot------------\n",
      " (0.4576199909637508, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 36 0.05\n",
      "验证集最优结果： 0.9797533750534058 0.96489018201828\n",
      "------------train------------\n",
      " (0.48893491136274575, 0.015983875890924093)\n",
      "------------test------------\n",
      " (0.5022163002442815, 0.029857872529424845)\n",
      "------------oot------------\n",
      " (0.4834474449425966, 0.011893094220275957)\n",
      "隐藏层vs神经元数vs norm 2 36 0.1\n",
      "验证集最优结果： 1.3867818117141724 1.3708709478378296\n",
      "------------train------------\n",
      " (0.4929682397554312, 0.012660647197806685)\n",
      "------------test------------\n",
      " (0.49203975127692645, 0.007961359093937373)\n",
      "------------oot------------\n",
      " (0.48810574728622896, 0.03811211900045175)\n",
      "隐藏层vs神经元数vs norm 2 36 0.2\n",
      "验证集最优结果： 2.1861679553985596 2.1645383834838867\n",
      "------------train------------\n",
      " (0.4727586209230349, 0.0030641492373466583)\n",
      "------------test------------\n",
      " (0.5125227626027092, 0.038540972684876745)\n",
      "------------oot------------\n",
      " (0.48673872496205933, 0.012435269175963493)\n",
      "隐藏层vs神经元数vs norm 2 36 0.3\n",
      "验证集最优结果： 2.96338152885437 2.9435105323791504\n",
      "------------train------------\n",
      " (0.5429867502651368, 0.06267557066175583)\n",
      "------------test------------\n",
      " (0.5314734621363536, 0.05932711525649559)\n",
      "------------oot------------\n",
      " (0.5480427252400978, 0.07999860980780593)\n",
      "隐藏层vs神经元数vs norm 2 36 0.4\n",
      "验证集最优结果： 3.8073883056640625 3.766918420791626\n",
      "------------train------------\n",
      " (0.5260618501440572, 0.047235436763428895)\n",
      "------------test------------\n",
      " (0.5164579169442595, 0.049122807017543846)\n",
      "------------oot------------\n",
      " (0.5461393204277157, 0.09048065895109997)\n",
      "隐藏层vs神经元数vs norm 2 36 0.5\n",
      "验证集最优结果： 4.591256618499756 4.571941375732422\n",
      "------------train------------\n",
      " (0.5081511215609199, 0.026884840264791654)\n",
      "------------test------------\n",
      " (0.49053186764379303, 0.026959804574727957)\n",
      "------------oot------------\n",
      " (0.5020076692269373, 0.0498175372745282)\n",
      "隐藏层vs神经元数vs norm 2 36 0.8\n",
      "验证集最优结果： 7.045653820037842 6.990630626678467\n",
      "------------train------------\n",
      " (0.5197084476281169, 0.05239834616886596)\n",
      "------------test------------\n",
      " (0.5296913168998446, 0.07450588496557853)\n",
      "------------oot------------\n",
      " (0.5160555613480231, 0.037542140200882756)\n",
      "隐藏层vs神经元数vs norm 2 38 0.01\n",
      "验证集最优结果： 0.6606870889663696 0.6497179269790649\n",
      "------------train------------\n",
      " (0.47068185679024377, 0.0008906702293475841)\n",
      "------------test------------\n",
      " (0.49468132356206973, 0.033177881412391697)\n",
      "------------oot------------\n",
      " (0.4341535467278351, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 38 0.05\n",
      "验证集最优结果： 0.997049868106842 0.9799672961235046\n",
      "------------train------------\n",
      " (0.5081300730471412, 0.0322310274043528)\n",
      "------------test------------\n",
      " (0.4888241172551632, 0.03237841439040634)\n",
      "------------oot------------\n",
      " (0.5047092760574149, 0.048100649914850746)\n",
      "隐藏层vs神经元数vs norm 2 38 0.1\n",
      "验证集最优结果： 1.4206833839416504 1.4001388549804688\n",
      "------------train------------\n",
      " (0.4984206169854061, 0.02204517105809045)\n",
      "------------test------------\n",
      " (0.4862702642682656, 0.014268265600710595)\n",
      "------------oot------------\n",
      " (0.5216255980722668, 0.05661557710353449)\n",
      "隐藏层vs神经元数vs norm 2 38 0.2\n",
      "验证集最优结果： 2.2773008346557617 2.26128888130188\n",
      "------------train------------\n",
      " (0.5026400656767773, 0.012758647995078254)\n",
      "------------test------------\n",
      " (0.5008971796580058, 0.026771041527870243)\n",
      "------------oot------------\n",
      " (0.5340145275084279, 0.07698189274667228)\n",
      "隐藏层vs神经元数vs norm 2 38 0.3\n",
      "验证集最优结果： 3.1382250785827637 3.105569839477539\n",
      "------------train------------\n",
      " (0.5137819035571989, 0.02795689318522221)\n",
      "------------test------------\n",
      " (0.5062713746391294, 0.02849211636686652)\n",
      "------------oot------------\n",
      " (0.5103117505995204, 0.05073506412261497)\n",
      "隐藏层vs神经元数vs norm 2 38 0.4\n",
      "验证集最优结果： 3.9879508018493652 3.9589970111846924\n",
      "------------train------------\n",
      " (0.48010813927754187, 0.0014562052169181322)\n",
      "------------test------------\n",
      " (0.48117810348656453, 0.03537641572285144)\n",
      "------------oot------------\n",
      " (0.4782550770977421, 0.02190942897855619)\n",
      "隐藏层vs神经元数vs norm 2 38 0.5\n",
      "验证集最优结果： 4.809578895568848 4.786800384521484\n",
      "------------train------------\n",
      " (0.5223145378903704, 0.032764482020440744)\n",
      "------------test------------\n",
      " (0.5092638241172552, 0.04264934488119032)\n",
      "------------oot------------\n",
      " (0.5440911039284514, 0.07032287213707294)\n",
      "隐藏层vs神经元数vs norm 2 38 0.8\n",
      "验证集最优结果： 7.396326065063477 7.345348358154297\n",
      "------------train------------\n",
      " (0.5102987467674288, 0.03333461925539699)\n",
      "------------test------------\n",
      " (0.5093559848989563, 0.0604263824117256)\n",
      "------------oot------------\n",
      " (0.49640519468483185, 0.03264866367775343)\n",
      "隐藏层vs神经元数vs norm 2 40 0.01\n",
      "验证集最优结果： 0.6668773293495178 0.655757486820221\n",
      "------------train------------\n",
      " (0.5219112998032539, 0.044013592873013874)\n",
      "------------test------------\n",
      " (0.5269398178991783, 0.048478791916500175)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.5570836084755384, 0.09661835748792275)\n",
      "隐藏层vs神经元数vs norm 2 40 0.05\n",
      "验证集最优结果： 1.0169895887374878 0.9994750022888184\n",
      "------------train------------\n",
      " (0.5000732298775192, 0.020585717195958947)\n",
      "------------test------------\n",
      " (0.5044692427270708, 0.02703753053519875)\n",
      "------------oot------------\n",
      " (0.48953185277864664, 0.007986654154936823)\n",
      "隐藏层vs神经元数vs norm 2 40 0.1\n",
      "验证集最优结果： 1.4774994850158691 1.459977149963379\n",
      "------------train------------\n",
      " (0.49448738747335946, 0.008969780154703288)\n",
      "------------test------------\n",
      " (0.49158560959360426, 0.024095047745947173)\n",
      "------------oot------------\n",
      " (0.5071085160856821, 0.035498557675598646)\n",
      "隐藏层vs神经元数vs norm 2 40 0.2\n",
      "验证集最优结果： 2.3660590648651123 2.3508365154266357\n",
      "------------train------------\n",
      " (0.4613932356438646, 0.0003852351782254182)\n",
      "------------test------------\n",
      " (0.46115256495669554, 0.015833888518765264)\n",
      "------------oot------------\n",
      " (0.4554883629328422, 0.010078893407013512)\n",
      "隐藏层vs神经元数vs norm 2 40 0.3\n",
      "验证集最优结果： 3.2566335201263428 3.2387444972991943\n",
      "------------train------------\n",
      " (0.49976291657952854, 0.019347577288992057)\n",
      "------------test------------\n",
      " (0.48051743282256276, 0.014068398845214297)\n",
      "------------oot------------\n",
      " (0.5020389485513039, 0.036555103743092454)\n",
      "隐藏层vs神经元数vs norm 2 40 0.4\n",
      "验证集最优结果： 4.105886936187744 4.036646366119385\n",
      "------------train------------\n",
      " (0.4912019919609567, 0.010275329449848769)\n",
      "------------test------------\n",
      " (0.49710082167443925, 0.02322895847212969)\n",
      "------------oot------------\n",
      " (0.4971373625737091, 0.03494248079797031)\n",
      "隐藏层vs神经元数vs norm 2 40 0.5\n",
      "验证集最优结果： 4.978363037109375 4.904472351074219\n",
      "------------train------------\n",
      " (0.48833282911652415, 0.0031134203564169294)\n",
      "------------test------------\n",
      " (0.5111703308905174, 0.040006662225183176)\n",
      "------------oot------------\n",
      " (0.4776306491039053, 0.010885204879574673)\n",
      "隐藏层vs神经元数vs norm 2 40 0.8\n",
      "验证集最优结果： 7.718850612640381 7.654969215393066\n",
      "------------train------------\n",
      " (0.4705839236730808, 0.003396187850202237)\n",
      "------------test------------\n",
      " (0.46925605152120803, 0.007439484787919164)\n",
      "------------oot------------\n",
      " (0.456996721463409, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 2 42 0.01\n",
      "验证集最优结果： 0.6728579998016357 0.6620339751243591\n",
      "------------train------------\n",
      " (0.5038263626205467, 0.01748854006560907)\n",
      "------------test------------\n",
      " (0.5115900510770597, 0.03152342882522763)\n",
      "------------oot------------\n",
      " (0.5474298821812116, 0.08624752372015432)\n",
      "隐藏层vs神经元数vs norm 2 42 0.05\n",
      "验证集最优结果： 1.0415337085723877 1.0261777639389038\n",
      "------------train------------\n",
      " (0.49251356478576874, 0.010395529322745456)\n",
      "------------test------------\n",
      " (0.5177437264046192, 0.048512103042416155)\n",
      "------------oot------------\n",
      " (0.5061481249782783, 0.04905988252875962)\n",
      "隐藏层vs神经元数vs norm 2 42 0.1\n",
      "验证集最优结果： 1.5079374313354492 1.4882192611694336\n",
      "------------train------------\n",
      " (0.5289303361874034, 0.04577530610021119)\n",
      "------------test------------\n",
      " (0.5098067954696869, 0.04915611814345994)\n",
      "------------oot------------\n",
      " (0.5594573616469143, 0.09987835818301882)\n",
      "隐藏层vs神经元数vs norm 2 42 0.2\n",
      "验证集最优结果： 2.432236909866333 2.4041659832000732\n",
      "------------train------------\n",
      " (0.5465472654190516, 0.07252221430364947)\n",
      "------------test------------\n",
      " (0.5376970908283367, 0.07428381079280488)\n",
      "------------oot------------\n",
      " (0.5596195507362227, 0.10641921245612207)\n",
      "隐藏层vs神经元数vs norm 2 42 0.3\n",
      "验证集最优结果： 3.397561550140381 3.369300603866577\n",
      "------------train------------\n",
      " (0.5117685556861782, 0.0339739255613557)\n",
      "------------test------------\n",
      " (0.4962547190761714, 0.018176771041527817)\n",
      "------------oot------------\n",
      " (0.486809393065258, 0.017919577381573015)\n",
      "隐藏层vs神经元数vs norm 2 42 0.4\n",
      "验证集最优结果： 4.3449931144714355 4.325504302978516\n",
      "------------train------------\n",
      " (0.48310433768584116, 0.008766875189081258)\n",
      "------------test------------\n",
      " (0.49114590273151226, 0.00990450810570731)\n",
      "------------oot------------\n",
      " (0.48083735909822867, 0.029319153372953766)\n",
      "隐藏层vs神经元数vs norm 2 42 0.5\n",
      "验证集最优结果： 5.278383255004883 5.252824306488037\n",
      "------------train------------\n",
      " (0.4753242384803379, 0.0015232085244450966)\n",
      "------------test------------\n",
      " (0.4742771485676216, 0.011403508771929804)\n",
      "------------oot------------\n",
      " (0.4773630371065466, 0.006693775414451153)\n",
      "隐藏层vs神经元数vs norm 2 42 0.8\n",
      "验证集最优结果： 8.101578712463379 8.081957817077637\n",
      "------------train------------\n",
      " (0.52572256975958, 0.04097110127042336)\n",
      "------------test------------\n",
      " (0.5185009993337775, 0.0516433488785254)\n",
      "------------oot------------\n",
      " (0.5195206153917447, 0.062364021826017524)\n",
      "隐藏层vs神经元数vs norm 2 44 0.01\n",
      "验证集最优结果： 0.6735562086105347 0.6626981496810913\n",
      "------------train------------\n",
      " (0.4979412387761, 0.022057082757206414)\n",
      "------------test------------\n",
      " (0.4657916944259382, 0.01406839884521427)\n",
      "------------oot------------\n",
      " (0.5314287700274563, 0.08174330101136484)\n",
      "隐藏层vs神经元数vs norm 2 44 0.05\n",
      "验证集最优结果： 1.065585732460022 1.0495033264160156\n",
      "------------train------------\n",
      " (0.5398050406791293, 0.06372596594743013)\n",
      "------------test------------\n",
      " (0.5369575838330002, 0.06746613368865206)\n",
      "------------oot------------\n",
      " (0.5494780986804759, 0.10262398776630866)\n",
      "隐藏层vs神经元数vs norm 2 44 0.1\n",
      "验证集最优结果： 1.5615543127059937 1.5494967699050903\n",
      "------------train------------\n",
      " (0.5188432251196077, 0.044588196995138496)\n",
      "------------test------------\n",
      " (0.5063102376193649, 0.04007328447701536)\n",
      "------------oot------------\n",
      " (0.5458717084303571, 0.09280923087616866)\n",
      "隐藏层vs神经元数vs norm 2 44 0.2\n",
      "验证集最优结果： 2.5578227043151855 2.5351107120513916\n",
      "------------train------------\n",
      " (0.5361892985565864, 0.06370891056005967)\n",
      "------------test------------\n",
      " (0.558032422829225, 0.11987563846324678)\n",
      "------------oot------------\n",
      " (0.5443343875624137, 0.0999756716366037)\n",
      "隐藏层vs神经元数vs norm 2 44 0.3\n",
      "验证集最优结果： 3.512636184692383 3.4745187759399414\n",
      "------------train------------\n",
      " (0.4842123287439451, 0.00764176106349812)\n",
      "------------test------------\n",
      " (0.4741594492560515, 0.014878969575838327)\n",
      "------------oot------------\n",
      " (0.48250790671810373, 0.0074166753553678855)\n",
      "隐藏层vs神经元数vs norm 2 44 0.4\n",
      "验证集最优结果： 4.539283275604248 4.506247520446777\n",
      "------------train------------\n",
      " (0.52831566544098, 0.044244517403601524)\n",
      "------------test------------\n",
      " (0.503978458805241, 0.034787919165001124)\n",
      "------------oot------------\n",
      " (0.5258552578227272, 0.047634935529837)\n",
      "隐藏层vs神经元数vs norm 2 44 0.5\n",
      "验证集最优结果： 5.4663214683532715 5.420950412750244\n",
      "------------train------------\n",
      " (0.5492803235650634, 0.08386255794263298)\n",
      "------------test------------\n",
      " (0.5370974905618477, 0.0761714412613812)\n",
      "------------oot------------\n",
      " (0.5624219465007704, 0.11432245507941474)\n",
      "隐藏层vs神经元数vs norm 2 44 0.8\n",
      "验证集最优结果： 8.497122764587402 8.428552627563477\n",
      "------------train------------\n",
      " (0.4466303765924284, 0.00032513524177701925)\n",
      "------------test------------\n",
      " (0.475126582278481, 0.010626249167221852)\n",
      "------------oot------------\n",
      " (0.4426615229555486, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 2 46 0.01\n",
      "验证集最优结果： 0.6792181730270386 0.6680222153663635\n",
      "------------train------------\n",
      " (0.4980805244396256, 0.01327125713771346)\n",
      "------------test------------\n",
      " (0.4870253164556962, 0.01884299355984899)\n",
      "------------oot------------\n",
      " (0.47708384017423744, 0.009335140583185624)\n",
      "隐藏层vs神经元数vs norm 2 46 0.05\n",
      "验证集最优结果： 1.0945706367492676 1.081984043121338\n",
      "------------train------------\n",
      " (0.4581983961167861, 0.0015163051533665104)\n",
      "------------test------------\n",
      " (0.47554852320675106, 0.010170997113035755)\n",
      "------------oot------------\n",
      " (0.4754631077746498, 0.008897230042053339)\n",
      "隐藏层vs神经元数vs norm 2 46 0.1\n",
      "验证集最优结果： 1.6043729782104492 1.5869370698928833\n",
      "------------train------------\n",
      " (0.5126819664320198, 0.02614306627439278)\n",
      "------------test------------\n",
      " (0.538083499888963, 0.07373972906950921)\n",
      "------------oot------------\n",
      " (0.5570627555926273, 0.08527438918430474)\n",
      "隐藏层vs神经元数vs norm 2 46 0.2\n",
      "验证集最优结果： 2.6514058113098145 2.63350248336792\n",
      "------------train------------\n",
      " (0.47024098856273844, 0.006353943956809327)\n",
      "------------test------------\n",
      " (0.4635787252942483, 0.0043859649122807015)\n",
      "------------oot------------\n",
      " (0.4788343238452716, 0.011712369235046816)\n",
      "隐藏层vs神经元数vs norm 2 46 0.3\n",
      "验证集最优结果： 3.678715467453003 3.655855655670166\n",
      "------------train------------\n",
      " (0.478562867037689, 0.0028474375295677312)\n",
      "------------test------------\n",
      " (0.486959804574728, 0.029013990672884793)\n",
      "------------oot------------\n",
      " (0.48703529929679445, 0.028978556285406437)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 2 46 0.4\n",
      "验证集最优结果： 4.657676696777344 4.577500820159912\n",
      "------------train------------\n",
      " (0.5350998518482423, 0.06466184648933121)\n",
      "------------test------------\n",
      " (0.5438307794803464, 0.08136797690428604)\n",
      "------------oot------------\n",
      " (0.5536648941716191, 0.08519097765266048)\n",
      "隐藏层vs神经元数vs norm 2 46 0.5\n",
      "验证集最优结果： 5.764523506164551 5.725671768188477\n",
      "------------train------------\n",
      " (0.5294103911977959, 0.05114423375626631)\n",
      "------------test------------\n",
      " (0.5136420164334887, 0.039351543415500845)\n",
      "------------oot------------\n",
      " (0.5199423070239461, 0.0602926354568519)\n",
      "隐藏层vs神经元数vs norm 2 46 0.8\n",
      "验证集最优结果： 8.829113960266113 8.784261703491211\n",
      "------------train------------\n",
      " (0.521625689744907, 0.038817384854139214)\n",
      "------------test------------\n",
      " (0.512407284032867, 0.028858538751943108)\n",
      "------------oot------------\n",
      " (0.5093536764791066, 0.040899454349563824)\n",
      "隐藏层vs神经元数vs norm 2 48 0.01\n",
      "验证集最优结果： 0.6844276189804077 0.673397958278656\n",
      "------------train------------\n",
      " (0.5461250769015233, 0.08023084331445735)\n",
      "------------test------------\n",
      " (0.5603175660670664, 0.10910504108372199)\n",
      "------------oot------------\n",
      " (0.5639442069532781, 0.11808292496437628)\n",
      "隐藏层vs神经元数vs norm 2 48 0.05\n",
      "验证集最优结果： 1.117247223854065 1.1044870615005493\n",
      "------------train------------\n",
      " (0.48809100808844974, 0.010612241030524383)\n",
      "------------test------------\n",
      " (0.4719775705085499, 0.003086831001554491)\n",
      "------------oot------------\n",
      " (0.4610491317091254, 0.006624265804747509)\n",
      "隐藏层vs神经元数vs norm 2 48 0.1\n",
      "验证集最优结果： 1.6584913730621338 1.6433249711990356\n",
      "------------train------------\n",
      " (0.5270229753664708, 0.04525795934997312)\n",
      "------------test------------\n",
      " (0.527797024206085, 0.04986675549633579)\n",
      "------------oot------------\n",
      " (0.5452067331641932, 0.09219754631077742)\n",
      "隐藏层vs神经元数vs norm 2 48 0.2\n",
      "验证集最优结果： 2.743286371231079 2.7260758876800537\n",
      "------------train------------\n",
      " (0.4958773338639454, 0.010862522072175418)\n",
      "------------test------------\n",
      " (0.4617343992893627, 0.008794137241838775)\n",
      "------------oot------------\n",
      " (0.4719273856277297, 0.0187397907760748)\n",
      "隐藏层vs神经元数vs norm 2 48 0.3\n",
      "验证集最优结果： 3.8050601482391357 3.772226095199585\n",
      "------------train------------\n",
      " (0.5037707972513754, 0.020375232058172377)\n",
      "------------test------------\n",
      " (0.5186953142349544, 0.058971796580057745)\n",
      "------------oot------------\n",
      " (0.47584772761500943, 0.007889340701351943)\n",
      "隐藏层vs神经元数vs norm 2 48 0.4\n",
      "验证集最优结果： 4.901785373687744 4.865628719329834\n",
      "------------train------------\n",
      " (0.5542499385803015, 0.08294116094397508)\n",
      "------------test------------\n",
      " (0.5354041749944481, 0.06889851210304243)\n",
      "------------oot------------\n",
      " (0.5791088868036006, 0.13038612588190313)\n",
      "隐藏层vs神经元数vs norm 2 48 0.5\n",
      "验证集最优结果： 5.990699291229248 5.963345527648926\n",
      "------------train------------\n",
      " (0.4747324436106255, 0.0028661172395448853)\n",
      "------------test------------\n",
      " (0.48192427270708416, 0.010071063735287586)\n",
      "------------oot------------\n",
      " (0.47474947578169346, 0.009522816529385136)\n",
      "隐藏层vs神经元数vs norm 2 48 0.8\n",
      "验证集最优结果： 9.245254516601562 9.200542449951172\n",
      "------------train------------\n",
      " (0.45257350228995646, 0.009998382445404075)\n",
      "------------test------------\n",
      " (0.4648867421718854, 0.012103042416166998)\n",
      "------------oot------------\n",
      " (0.4355309954934603, 0.00046571438501374907)\n",
      "隐藏层vs神经元数vs norm 2 50 0.01\n",
      "验证集最优结果： 0.6874108910560608 0.6759123802185059\n",
      "------------train------------\n",
      " (0.5572017388373505, 0.09725888792106341)\n",
      "------------test------------\n",
      " (0.5485332000888298, 0.09381523428825234)\n",
      "------------oot------------\n",
      " (0.5889456550701468, 0.16099120703437247)\n",
      "隐藏层vs神经元数vs norm 2 50 0.05\n",
      "验证集最优结果： 1.1424131393432617 1.1292271614074707\n",
      "------------train------------\n",
      " (0.5013293726933774, 0.01612952348465929)\n",
      "------------test------------\n",
      " (0.5064012880302021, 0.047423939595825)\n",
      "------------oot------------\n",
      " (0.5357812300883931, 0.07408334202203448)\n",
      "隐藏层vs神经元数vs norm 2 50 0.1\n",
      "验证集最优结果： 1.7040406465530396 1.6936191320419312\n",
      "------------train------------\n",
      " (0.49195046628210837, 0.01963223982581841)\n",
      "------------test------------\n",
      " (0.4961725516322452, 0.014234954474794583)\n",
      "------------oot------------\n",
      " (0.4724718775704075, 0.004608487123344801)\n",
      "隐藏层vs神经元数vs norm 2 50 0.2\n",
      "验证集最优结果： 2.8260748386383057 2.8124940395355225\n",
      "------------train------------\n",
      " (0.46256674104710604, 0.0012335376595812358)\n",
      "------------test------------\n",
      " (0.4667521652231845, 0.005263157894736842)\n",
      "------------oot------------\n",
      " (0.4359318342427507, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 50 0.3\n",
      "验证集最优结果： 3.9595203399658203 3.932426929473877\n",
      "------------train------------\n",
      " (0.4798812078733624, 0.008156942050260518)\n",
      "------------test------------\n",
      " (0.45834110592938043, 0.005785032200755054)\n",
      "------------oot------------\n",
      " (0.45811003371216075, 0.005053348625447485)\n",
      "隐藏层vs神经元数vs norm 2 50 0.4\n",
      "验证集最优结果： 5.0431108474731445 5.014646530151367\n",
      "------------train------------\n",
      " (0.4885239577432474, 0.00654358362114299)\n",
      "------------test------------\n",
      " (0.4655118809682434, 0.0061403508771929825)\n",
      "------------oot------------\n",
      " (0.4672667662971072, 0.014249469989226049)\n",
      "隐藏层vs神经元数vs norm 2 50 0.5\n",
      "验证集最优结果： 6.201677322387695 6.166882038116455\n",
      "------------train------------\n",
      " (0.47401997510725613, 0.0007704703564508364)\n",
      "------------test------------\n",
      " (0.48986453475460806, 0.02221852098600932)\n",
      "------------oot------------\n",
      " (0.46611522376301856, 0.03590866437284955)\n",
      "隐藏层vs神经元数vs norm 2 50 0.8\n",
      "验证集最优结果： 9.590218544006348 9.555227279663086\n",
      "------------train------------\n",
      " (0.49238422809820925, 0.005010087720188738)\n",
      "------------test------------\n",
      " (0.4892793693093493, 0.02325116588940706)\n",
      "------------oot------------\n",
      " (0.5146514672320115, 0.037667257498349094)\n",
      "隐藏层vs神经元数vs norm 2 52 0.01\n",
      "验证集最优结果： 0.6937846541404724 0.6822210550308228\n",
      "------------train------------\n",
      " (0.5218240601432518, 0.05554601266024106)\n",
      "------------test------------\n",
      " (0.5372762602709305, 0.08765267599378196)\n",
      "------------oot------------\n",
      " (0.5349818695768023, 0.08585826990581447)\n",
      "隐藏层vs神经元数vs norm 2 52 0.05\n",
      "验证集最优结果： 1.1631150245666504 1.1528372764587402\n",
      "------------train------------\n",
      " (0.49449293724226573, 0.009973882246086196)\n",
      "------------test------------\n",
      " (0.5056784365978237, 0.02741505662891408)\n",
      "------------oot------------\n",
      " (0.4822843174735574, 0.00888332812011261)\n",
      "隐藏层vs神经元数vs norm 2 52 0.1\n",
      "验证集最优结果： 1.7451612949371338 1.7305333614349365\n",
      "------------train------------\n",
      " (0.47462077143141396, 0.0009754057253310577)\n",
      "------------test------------\n",
      " (0.46639573617588276, 0.009182767044192852)\n",
      "------------oot------------\n",
      " (0.43378630428990145, 0.015716122753970718)\n",
      "隐藏层vs神经元数vs norm 2 52 0.2\n",
      "验证集最优结果： 2.914501428604126 2.8961739540100098\n",
      "------------train------------\n",
      " (0.5328616029763006, 0.06174523988876102)\n",
      "------------test------------\n",
      " (0.5354752387297357, 0.06594492560515208)\n",
      "------------oot------------\n",
      " (0.5464428457234213, 0.09751503145309837)\n",
      "隐藏层vs神经元数vs norm 2 52 0.3\n",
      "验证集最优结果： 4.082450866699219 4.070210933685303\n",
      "------------train------------\n",
      " (0.4823925459835578, 0.003953871945173715)\n",
      "------------test------------\n",
      " (0.49029424827892515, 0.020230957139684702)\n",
      "------------oot------------\n",
      " (0.45117413315724236, 0.004295693879678875)\n",
      "隐藏层vs神经元数vs norm 2 52 0.4\n",
      "验证集最优结果： 5.201063632965088 5.119837760925293\n",
      "------------train------------\n",
      " (0.4685419471161167, 0.004361712279675866)\n",
      "------------test------------\n",
      " (0.43405174328225626, 0.006595602931379063)\n",
      "------------oot------------\n",
      " (0.43657595662600357, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 52 0.5\n",
      "验证集最优结果： 6.401836395263672 6.359009265899658\n",
      "------------train------------\n",
      " (0.4890300695954557, 0.012270674411978266)\n",
      "------------test------------\n",
      " (0.5279213857428381, 0.06646679991117033)\n",
      "------------oot------------\n",
      " (0.500764605706739, 0.03669412296249952)\n",
      "隐藏层vs神经元数vs norm 2 52 0.8\n",
      "验证集最优结果： 9.826196670532227 9.709715843200684\n",
      "------------train------------\n",
      " (0.4997095169738328, 0.011871091050726923)\n",
      "------------test------------\n",
      " (0.49437597157450586, 0.020919387075283125)\n",
      "------------oot------------\n",
      " (0.4757898029402565, 0.010676676050463962)\n",
      "隐藏层vs神经元数vs norm 2 54 0.01\n",
      "验证集最优结果： 0.698979914188385 0.6880912780761719\n",
      "------------train------------\n",
      " (0.5061996333091715, 0.019286800551457484)\n",
      "------------test------------\n",
      " (0.49898734177215187, 0.03040195425272041)\n",
      "------------oot------------\n",
      " (0.5119266905316326, 0.043971779098460395)\n",
      "隐藏层vs神经元数vs norm 2 54 0.05\n",
      "验证集最优结果： 1.1873654127120972 1.1716160774230957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " (0.481855910402365, 0.009156983335126823)\n",
      "------------test------------\n",
      " (0.4814512547190762, 0.008238951809904527)\n",
      "------------oot------------\n",
      " (0.4351544851075661, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 54 0.1\n",
      "验证集最优结果： 1.7994074821472168 1.7787182331085205\n",
      "------------train------------\n",
      " (0.5503171151489064, 0.08109782550579037)\n",
      "------------test------------\n",
      " (0.5449211636686654, 0.08525427492782589)\n",
      "------------oot------------\n",
      " (0.5592766366616851, 0.10260313488339767)\n",
      "隐藏层vs神经元数vs norm 2 54 0.2\n",
      "验证集最优结果： 3.009901285171509 2.9932284355163574\n",
      "------------train------------\n",
      " (0.4672821495743936, 0.0008798414119695064)\n",
      "------------test------------\n",
      " (0.46511658894070623, 0.008949589162780325)\n",
      "------------oot------------\n",
      " (0.46090316152874805, 0.005261877454558084)\n",
      "隐藏层vs神经元数vs norm 2 54 0.3\n",
      "验证集最优结果： 4.223016738891602 4.207387924194336\n",
      "------------train------------\n",
      " (0.49321669343414953, 0.013397548220385413)\n",
      "------------test------------\n",
      " (0.5030701754385964, 0.023872973573173417)\n",
      "------------oot------------\n",
      " (0.4845781345937743, 0.030820560942550368)\n",
      "隐藏层vs神经元数vs norm 2 54 0.4\n",
      "验证集最优结果： 5.445043087005615 5.422181606292725\n",
      "------------train------------\n",
      " (0.4762752116864597, 0.0037173976456796876)\n",
      "------------test------------\n",
      " (0.48829335998223405, 0.019276038196757717)\n",
      "------------oot------------\n",
      " (0.47131570106233855, 0.0056580822298683)\n",
      "隐藏层vs神经元数vs norm 2 54 0.5\n",
      "验证集最优结果： 6.607423305511475 6.5689377784729\n",
      "------------train------------\n",
      " (0.47938856436276817, 0.0069234043906794)\n",
      "------------test------------\n",
      " (0.49221074838996226, 0.013768598711969782)\n",
      "------------oot------------\n",
      " (0.5071722332279104, 0.03980815347721822)\n",
      "隐藏层vs神经元数vs norm 2 54 0.8\n",
      "验证集最优结果： 10.32996940612793 10.28984260559082\n",
      "------------train------------\n",
      " (0.5235995124324975, 0.03995644108209673)\n",
      "------------test------------\n",
      " (0.4985942704863425, 0.013835220963801853)\n",
      "------------oot------------\n",
      " (0.5381607757272443, 0.07695408890279082)\n",
      "隐藏层vs神经元数vs norm 2 56 0.01\n",
      "验证集最优结果： 0.7050465941429138 0.6937833428382874\n",
      "------------train------------\n",
      " (0.5350527464926476, 0.05171937931925996)\n",
      "------------test------------\n",
      " (0.5371419053964024, 0.07958027981345761)\n",
      "------------oot------------\n",
      " (0.5331444988936387, 0.05932645188197269)\n",
      "隐藏层vs神经元数vs norm 2 56 0.05\n",
      "验证集最优结果： 1.2114038467407227 1.195661187171936\n",
      "------------train------------\n",
      " (0.5042596506758873, 0.0228524593936269)\n",
      "------------test------------\n",
      " (0.49328447701532313, 0.014135021097046414)\n",
      "------------oot------------\n",
      " (0.5435836837776156, 0.08362006047336046)\n",
      "隐藏层vs神经元数vs norm 2 56 0.1\n",
      "验证集最优结果： 1.8345353603363037 1.8194011449813843\n",
      "------------train------------\n",
      " (0.5116261567376563, 0.0290771343429852)\n",
      "------------test------------\n",
      " (0.5038885187652676, 0.028569842327337336)\n",
      "------------oot------------\n",
      " (0.5017446912035589, 0.028526743822333445)\n",
      "隐藏层vs神经元数vs norm 2 56 0.2\n",
      "验证集最优结果： 3.0977723598480225 3.0838565826416016\n",
      "------------train------------\n",
      " (0.5291787221860134, 0.050064059222802215)\n",
      "------------test------------\n",
      " (0.506622251832112, 0.036775483011325716)\n",
      "------------oot------------\n",
      " (0.5425804284108945, 0.06766760504639768)\n",
      "隐藏层vs神经元数vs norm 2 56 0.3\n",
      "验证集最优结果： 4.384984493255615 4.35990571975708\n",
      "------------train------------\n",
      " (0.46511482945627836, 0.0024562465017843316)\n",
      "------------test------------\n",
      " (0.44865534088385517, 0.002631578947368421)\n",
      "------------oot------------\n",
      " (0.41928312422525743, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 56 0.4\n",
      "验证集最优结果： 5.638160705566406 5.601797103881836\n",
      "------------train------------\n",
      " (0.5031323707868286, 0.013508137517859176)\n",
      "------------test------------\n",
      " (0.4915933821896514, 0.02276260270930497)\n",
      "------------oot------------\n",
      " (0.5005363824882123, 0.04539672609738299)\n",
      "隐藏层vs神经元数vs norm 2 56 0.5\n",
      "验证集最优结果： 6.8408966064453125 6.781614303588867\n",
      "------------train------------\n",
      " (0.5295230108985278, 0.0537125585179139)\n",
      "------------test------------\n",
      " (0.5363957361758828, 0.06042638241172554)\n",
      "------------oot------------\n",
      " (0.5679259490957959, 0.10726722969450525)\n",
      "隐藏层vs神经元数vs norm 2 56 0.8\n",
      "验证集最优结果： 10.697344779968262 10.674139976501465\n",
      "------------train------------\n",
      " (0.5634262107463829, 0.09473956355805158)\n",
      "------------test------------\n",
      " (0.5246269153897403, 0.051043748612036366)\n",
      "------------oot------------\n",
      " (0.5328178037280321, 0.08747089285093668)\n",
      "隐藏层vs神经元数vs norm 2 58 0.01\n",
      "验证集最优结果： 0.7070840001106262 0.6958476901054382\n",
      "------------train------------\n",
      " (0.49461110671190406, 0.01003980267187543)\n",
      "------------test------------\n",
      " (0.5088218965134355, 0.045869420386409065)\n",
      "------------oot------------\n",
      " (0.5044289206316107, 0.03791749209328188)\n",
      "隐藏层vs神经元数vs norm 2 58 0.05\n",
      "验证集最优结果： 1.232979416847229 1.2161214351654053\n",
      "------------train------------\n",
      " (0.47569275667173594, 0.004085848156969123)\n",
      "------------test------------\n",
      " (0.4865889407061959, 0.03280035531867644)\n",
      "------------oot------------\n",
      " (0.47033329857852846, 0.009300385778333854)\n",
      "隐藏层vs神经元数vs norm 2 58 0.1\n",
      "验证集最优结果： 1.891024112701416 1.8711780309677124\n",
      "------------train------------\n",
      " (0.5049365194421264, 0.019988913998209124)\n",
      "------------test------------\n",
      " (0.487120808349989, 0.007395069953364475)\n",
      "------------oot------------\n",
      " (0.5196897554420232, 0.05660167518159384)\n",
      "隐藏层vs神经元数vs norm 2 58 0.2\n",
      "验证集最优结果： 3.2076988220214844 3.1782519817352295\n",
      "------------train------------\n",
      " (0.520712143638848, 0.03441344018668879)\n",
      "------------test------------\n",
      " (0.5083977348434376, 0.04936708860759492)\n",
      "------------oot------------\n",
      " (0.5092992272848388, 0.037993952663955784)\n",
      "隐藏层vs神经元数vs norm 2 58 0.3\n",
      "验证集最优结果： 4.522150039672852 4.4888834953308105\n",
      "------------train------------\n",
      " (0.5234373508922607, 0.045762582239792016)\n",
      "------------test------------\n",
      " (0.5103431045969354, 0.04028425494115029)\n",
      "------------oot------------\n",
      " (0.5084431005919902, 0.03523442115872519)\n",
      "隐藏层vs神经元数vs norm 2 58 0.4\n",
      "验证集最优结果： 5.836709022521973 5.793859481811523\n",
      "------------train------------\n",
      " (0.5590049399711277, 0.1012610834637867)\n",
      "------------test------------\n",
      " (0.5370419720186542, 0.06384632467244056)\n",
      "------------oot------------\n",
      " (0.5556169557107937, 0.10548778368609463)\n",
      "隐藏层vs神经元数vs norm 2 58 0.5\n",
      "验证集最优结果： 7.0327277183532715 6.921931743621826\n",
      "------------train------------\n",
      " (0.5376126112407185, 0.060681443941581203)\n",
      "------------test------------\n",
      " (0.5248978458805242, 0.0501443482123029)\n",
      "------------oot------------\n",
      " (0.5341952524936573, 0.09198901748166688)\n",
      "隐藏层vs神经元数vs norm 2 58 0.8\n",
      "验证集最优结果： 11.143555641174316 11.074447631835938\n",
      "------------train------------\n",
      " (0.5101497828483715, 0.02514343107017819)\n",
      "------------test------------\n",
      " (0.49365756162558294, 0.013790806129247213)\n",
      "------------oot------------\n",
      " (0.4628042493541399, 0.0028637959197859164)\n",
      "隐藏层vs神经元数vs norm 2 60 0.01\n",
      "验证集最优结果： 0.7155272960662842 0.704335629940033\n",
      "------------train------------\n",
      " (0.5575224748720676, 0.08676914788712853)\n",
      "------------test------------\n",
      " (0.5363990672884744, 0.0670552964690207)\n",
      "------------oot------------\n",
      " (0.5456620211077514, 0.08430820560942548)\n",
      "隐藏层vs神经元数vs norm 2 60 0.05\n",
      "验证集最优结果： 1.2592475414276123 1.2421376705169678\n",
      "------------train------------\n",
      " (0.5197003260150832, 0.047359426722408005)\n",
      "------------test------------\n",
      " (0.529975571840995, 0.07007550521874306)\n",
      "------------oot------------\n",
      " (0.5291384283877246, 0.05723421262989603)\n",
      "隐藏层vs神经元数vs norm 2 60 0.1\n",
      "验证集最优结果： 1.9368478059768677 1.9161580801010132\n",
      "------------train------------\n",
      " (0.5492280068411054, 0.07972527290311804)\n",
      "------------test------------\n",
      " (0.5652331778814124, 0.11305796135909396)\n",
      "------------oot------------\n",
      " (0.5636765949559193, 0.10350675980954371)\n",
      "隐藏层vs神经元数vs norm 2 60 0.2\n",
      "验证集最优结果： 3.2467503547668457 3.200972080230713\n",
      "------------train------------\n",
      " (0.46804179111346633, 0.0011379733462196784)\n",
      "------------test------------\n",
      " (0.5076959804574728, 0.03346657783699755)\n",
      "------------oot------------\n",
      " (0.4795352124097823, 0.03379557223786189)\n",
      "隐藏层vs神经元数vs norm 2 60 0.3\n",
      "验证集最优结果： 4.650190830230713 4.630722522735596\n",
      "------------train------------\n",
      " (0.49743126915770075, 0.018876659093262527)\n",
      "------------test------------\n",
      " (0.4849233844103931, 0.024572507217410666)\n",
      "------------oot------------\n",
      " (0.48975428352969796, 0.012247593229763987)\n",
      "隐藏层vs神经元数vs norm 2 60 0.4\n",
      "验证集最优结果： 6.0202531814575195 6.008716106414795\n",
      "------------train------------\n",
      " (0.4964880791640694, 0.014343039337709529)\n",
      "------------test------------\n",
      " (0.5135021097046414, 0.052487230735065504)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.5186123564916183, 0.05581621659194386)\n",
      "隐藏层vs神经元数vs norm 2 60 0.5\n",
      "验证集最优结果： 7.274902820587158 7.153940677642822\n",
      "------------train------------\n",
      " (0.5029437463241241, 0.014435084285423283)\n",
      "------------test------------\n",
      " (0.5217199644681324, 0.056073728625360864)\n",
      "------------oot------------\n",
      " (0.5488953764524612, 0.10256838007854585)\n",
      "隐藏层vs神经元数vs norm 2 60 0.8\n",
      "验证集最优结果： 11.441972732543945 11.365143775939941\n",
      "------------train------------\n",
      " (0.5013458189597703, 0.01965416818100918)\n",
      "------------test------------\n",
      " (0.4706850988230069, 0.012536087053075712)\n",
      "------------oot------------\n",
      " (0.4916889676664466, 0.01676571786049419)\n",
      "隐藏层vs神经元数vs norm 2 62 0.01\n",
      "验证集最优结果： 0.7200490236282349 0.7086277604103088\n",
      "------------train------------\n",
      " (0.5171934547920563, 0.032251060716502244)\n",
      "------------test------------\n",
      " (0.5206950921607816, 0.045591827670441926)\n",
      "------------oot------------\n",
      " (0.5434075927663666, 0.08272338650818478)\n",
      "隐藏层vs神经元数vs norm 2 62 0.05\n",
      "验证集最优结果： 1.2818045616149902 1.265535831451416\n",
      "------------train------------\n",
      " (0.5627483944586235, 0.08934924898767471)\n",
      "------------test------------\n",
      " (0.5647990228736399, 0.12611592271818794)\n",
      "------------oot------------\n",
      " (0.5944948389114795, 0.1478469398394328)\n",
      "隐藏层vs神经元数vs norm 2 62 0.1\n",
      "验证集最优结果： 1.9889153242111206 1.9714739322662354\n",
      "------------train------------\n",
      " (0.5088266367249866, 0.03230385120122037)\n",
      "------------test------------\n",
      " (0.512964690206529, 0.06456806573395513)\n",
      "------------oot------------\n",
      " (0.5542163370752673, 0.09478330379174915)\n",
      "隐藏层vs神经元数vs norm 2 62 0.2\n",
      "验证集最优结果： 3.3773622512817383 3.359043598175049\n",
      "------------train------------\n",
      " (0.5064442969018078, 0.028973719137024512)\n",
      "------------test------------\n",
      " (0.47081168110148786, 0.020386409060626262)\n",
      "------------oot------------\n",
      " (0.485377495105365, 0.022764397177909845)\n",
      "隐藏层vs神经元数vs norm 2 62 0.3\n",
      "验证集最优结果： 4.795701503753662 4.765573501586914\n",
      "------------train------------\n",
      " (0.47045594058769347, 0.004618896692405339)\n",
      "------------test------------\n",
      " (0.4679580279813458, 0.013379968909615816)\n",
      "------------oot------------\n",
      " (0.47025220403387435, 0.010245716470302035)\n",
      "隐藏层vs神经元数vs norm 2 62 0.4\n",
      "验证集最优结果： 6.186162948608398 6.1636457443237305\n",
      "------------train------------\n",
      " (0.5382831180767478, 0.06303210947392934)\n",
      "------------test------------\n",
      " (0.49498778592049747, 0.03331112591605595)\n",
      "------------oot------------\n",
      " (0.4776665624022521, 0.013568275814131336)\n",
      "隐藏层vs神经元数vs norm 2 62 0.5\n",
      "验证集最优结果： 7.498109340667725 7.3952131271362305\n",
      "------------train------------\n",
      " (0.5098993664465034, 0.031070448901856396)\n",
      "------------test------------\n",
      " (0.5155673995114368, 0.04177215189873418)\n",
      "------------oot------------\n",
      " (0.544512795560653, 0.07810794842386964)\n",
      "隐藏层vs神经元数vs norm 2 62 0.8\n",
      "验证集最优结果： 11.869919776916504 11.798287391662598\n",
      "------------train------------\n",
      " (0.4894626131696016, 0.006082005280402036)\n",
      "------------test------------\n",
      " (0.4739873417721519, 0.007817010881634466)\n",
      "------------oot------------\n",
      " (0.4793301590611569, 0.013116463351058205)\n",
      "隐藏层vs神经元数vs norm 2 64 0.01\n",
      "验证集最优结果： 0.724372386932373 0.7130768895149231\n",
      "------------train------------\n",
      " (0.5157802264441073, 0.03971712421804091)\n",
      "------------test------------\n",
      " (0.5099533644237175, 0.056051521208083516)\n",
      "------------oot------------\n",
      " (0.4994995308101345, 0.03565842977791678)\n",
      "隐藏层vs神经元数vs norm 2 64 0.05\n",
      "验证集最优结果： 1.3073573112487793 1.29124116897583\n",
      "------------train------------\n",
      " (0.529046745974218, 0.04973202060994664)\n",
      "------------test------------\n",
      " (0.5291661114812348, 0.059038418831889816)\n",
      "------------oot------------\n",
      " (0.5417683244708581, 0.07316581517394771)\n",
      "隐藏层vs神经元数vs norm 2 64 0.1\n",
      "验证集最优结果： 2.0310275554656982 2.0133609771728516\n",
      "------------train------------\n",
      " (0.48524891728746244, 0.006441792737788998)\n",
      "------------test------------\n",
      " (0.5031578947368421, 0.033755274261603296)\n",
      "------------oot------------\n",
      " (0.4541560954135243, 0.005261877454558084)\n",
      "隐藏层vs神经元数vs norm 2 64 0.2\n",
      "验证集最优结果： 3.4730892181396484 3.4633140563964844\n",
      "------------train------------\n",
      " (0.5170760298036127, 0.03764976762034711)\n",
      "------------test------------\n",
      " (0.5247668221185876, 0.058783033533200135)\n",
      "------------oot------------\n",
      " (0.535093084952328, 0.0777743022972926)\n",
      "隐藏层vs神经元数vs norm 2 64 0.3\n",
      "验证集最优结果： 4.955236434936523 4.927640914916992\n",
      "------------train------------\n",
      " (0.523428890878684, 0.048326169393836604)\n",
      "------------test------------\n",
      " (0.517466133688652, 0.0540084388185654)\n",
      "------------oot------------\n",
      " (0.5100927953289542, 0.050776769888437046)\n",
      "隐藏层vs神经元数vs norm 2 64 0.4\n",
      "验证集最优结果： 6.388072967529297 6.3608012199401855\n",
      "------------train------------\n",
      " (0.5060309744785079, 0.029011213917196077)\n",
      "------------test------------\n",
      " (0.493412169664668, 0.02551632245169877)\n",
      "------------oot------------\n",
      " (0.5128048286008874, 0.036847044103847315)\n",
      "隐藏层vs神经元数vs norm 2 64 0.5\n",
      "验证集最优结果： 7.759735584259033 7.7031569480896\n",
      "------------train------------\n",
      " (0.4454896283617556, 0.0017636082702384703)\n",
      "------------test------------\n",
      " (0.44649677992449477, 0.011081501221408052)\n",
      "------------oot------------\n",
      " (0.4383461346864538, 0.008125673374344)\n",
      "隐藏层vs神经元数vs norm 2 64 0.8\n",
      "验证集最优结果： 12.179316520690918 12.1600341796875\n",
      "------------train------------\n",
      " (0.5111360850711892, 0.027181279140516823)\n",
      "------------test------------\n",
      " (0.5120430823895181, 0.039773484343770815)\n",
      "------------oot------------\n",
      " (0.515994161192785, 0.0396413304139297)\n",
      "隐藏层vs神经元数vs norm 2 66 0.01\n",
      "验证集最优结果： 0.7284369468688965 0.7168499827384949\n",
      "------------train------------\n",
      " (0.4829396719815856, 0.0014739374053747483)\n",
      "------------test------------\n",
      " (0.48876082611592275, 0.032744836775483024)\n",
      "------------oot------------\n",
      " (0.47845086249840707, 0.02538490946373337)\n",
      "隐藏层vs神经元数vs norm 2 66 0.05\n",
      "验证集最优结果： 1.3264087438583374 1.3105578422546387\n",
      "------------train------------\n",
      " (0.5402750113533382, 0.06560666080556926)\n",
      "------------test------------\n",
      " (0.5184332667110816, 0.04864534754608035)\n",
      "------------oot------------\n",
      " (0.5636036098657307, 0.10745490564070481)\n",
      "隐藏层vs神经元数vs norm 2 66 0.1\n",
      "验证集最优结果： 2.071904420852661 2.0557663440704346\n",
      "------------train------------\n",
      " (0.46315447511030167, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.4958472129691317, 0.023373306684432604)\n",
      "------------oot------------\n",
      " (0.4646010727649764, 0.008626142564209571)\n",
      "隐藏层vs神经元数vs norm 2 66 0.2\n",
      "验证集最优结果： 3.5789988040924072 3.562936782836914\n",
      "------------train------------\n",
      " (0.5086699572735475, 0.02948808796248359)\n",
      "------------test------------\n",
      " (0.5203275594048412, 0.06128136797690431)\n",
      "------------oot------------\n",
      " (0.49610862035009673, 0.05972265665728288)\n",
      "隐藏层vs神经元数vs norm 2 66 0.3\n",
      "验证集最优结果： 5.007913589477539 4.923577308654785\n",
      "------------train------------\n",
      " (0.4980566333612852, 0.0182322090990491)\n",
      "------------test------------\n",
      " (0.4911159227181878, 0.022584943371085936)\n",
      "------------oot------------\n",
      " (0.5522190942897856, 0.0966531122927744)\n",
      "隐藏层vs神经元数vs norm 2 66 0.4\n",
      "验证集最优结果： 6.584740161895752 6.545844554901123\n",
      "------------train------------\n",
      " (0.511995081009706, 0.030668293696477722)\n",
      "------------test------------\n",
      " (0.5273439928936264, 0.05748389962247391)\n",
      "------------oot------------\n",
      " (0.5250697992330773, 0.06307997080596395)\n",
      "隐藏层vs神经元数vs norm 2 66 0.5\n",
      "验证集最优结果： 8.086116790771484 8.04588508605957\n",
      "------------train------------\n",
      " (0.4990868599745929, 0.011367009601776945)\n",
      "------------test------------\n",
      " (0.46262158560959366, 0.009848989562513878)\n",
      "------------oot------------\n",
      " (0.4882378155446657, 0.012143328815208632)\n",
      "隐藏层vs神经元数vs norm 2 66 0.8\n",
      "验证集最优结果： 12.572847366333008 12.54810905456543\n",
      "------------train------------\n",
      " (0.5352876641496435, 0.061635056671938915)\n",
      "------------test------------\n",
      " (0.5383810792804797, 0.07808127914723517)\n",
      "------------oot------------\n",
      " (0.5184362654803693, 0.04454870885899975)\n",
      "隐藏层vs神经元数vs norm 2 68 0.01\n",
      "验证集最优结果： 0.7344412207603455 0.7232439517974854\n",
      "------------train------------\n",
      " (0.5669733252387923, 0.09915555528483505)\n",
      "------------test------------\n",
      " (0.5503986231401288, 0.08393293359982232)\n",
      "------------oot------------\n",
      " (0.5774186447943095, 0.11327285997289127)\n",
      "隐藏层vs神经元数vs norm 2 68 0.05\n",
      "验证集最优结果： 1.3521772623062134 1.336227297782898\n",
      "------------train------------\n",
      " (0.4802711806591907, 0.0021912111964557113)\n",
      "------------test------------\n",
      " (0.4943648678658672, 0.032100821674439284)\n",
      "------------oot------------\n",
      " (0.4560073680186286, 0.01818371389844642)\n",
      "隐藏层vs神经元数vs norm 2 68 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集最优结果： 2.116293430328369 2.107830286026001\n",
      "------------train------------\n",
      " (0.46661096593727813, 0.0005724383586490633)\n",
      "------------test------------\n",
      " (0.45992449478125697, 0.010748389962247393)\n",
      "------------oot------------\n",
      " (0.447380066960924, 0.004295693879678875)\n",
      "隐藏层vs神经元数vs norm 2 68 0.2\n",
      "验证集最优结果： 3.6779634952545166 3.6484577655792236\n",
      "------------train------------\n",
      " (0.516991294307629, 0.04321253110746992)\n",
      "------------test------------\n",
      " (0.4985343104596935, 0.03194536975349771)\n",
      "------------oot------------\n",
      " (0.516271041138104, 0.04413860216174892)\n",
      "隐藏层vs神经元数vs norm 2 68 0.3\n",
      "验证集最优结果： 5.219150543212891 5.182362079620361\n",
      "------------train------------\n",
      " (0.48405328048870444, 0.0011764156479119325)\n",
      "------------test------------\n",
      " (0.48940262047523875, 0.011270264268265606)\n",
      "------------oot------------\n",
      " (0.48348335824094346, 0.022993778889931538)\n",
      "隐藏层vs神经元数vs norm 2 68 0.4\n",
      "验证集最优结果： 6.653946876525879 6.56801700592041\n",
      "------------train------------\n",
      " (0.49905965257093043, 0.01326259408381103)\n",
      "------------test------------\n",
      " (0.5303397734843439, 0.06337996890961584)\n",
      "------------oot------------\n",
      " (0.5234177875091232, 0.06540159177006222)\n",
      "隐藏层vs神经元数vs norm 2 68 0.5\n",
      "验证集最优结果： 8.30203628540039 8.27994441986084\n",
      "------------train------------\n",
      " (0.5143617190476868, 0.034147592720056796)\n",
      "------------test------------\n",
      " (0.49269487008660895, 0.02093049078392184)\n",
      "------------oot------------\n",
      " (0.4846766065408542, 0.011399575991380861)\n",
      "隐藏层vs神经元数vs norm 2 68 0.8\n",
      "验证集最优结果： 12.943875312805176 12.898489952087402\n",
      "------------train------------\n",
      " (0.5034072873880148, 0.023209133566017615)\n",
      "------------test------------\n",
      " (0.49694425938263376, 0.02377304019542531)\n",
      "------------oot------------\n",
      " (0.5008005190050857, 0.029736211031175075)\n",
      "隐藏层vs神经元数vs norm 2 70 0.01\n",
      "验证集最优结果： 0.7337420582771301 0.7223984599113464\n",
      "------------train------------\n",
      " (0.5436668676765893, 0.07060402466533877)\n",
      "------------test------------\n",
      " (0.5519953364423718, 0.10034421496779933)\n",
      "------------oot------------\n",
      " (0.5549473464706496, 0.10600910575887112)\n",
      "隐藏层vs神经元数vs norm 2 70 0.05\n",
      "验证集最优结果： 1.3741981983184814 1.35767662525177\n",
      "------------train------------\n",
      " (0.4942921303600108, 0.007550257556653395)\n",
      "------------test------------\n",
      " (0.49243393293359977, 0.024628025760604036)\n",
      "------------oot------------\n",
      " (0.5186054055306479, 0.04828832586105025)\n",
      "隐藏层vs神经元数vs norm 2 70 0.1\n",
      "验证集最优结果： 2.1761231422424316 2.1549453735351562\n",
      "------------train------------\n",
      " (0.498483085725656, 0.016099473516435037)\n",
      "------------test------------\n",
      " (0.5055207639351543, 0.028958472129691326)\n",
      "------------oot------------\n",
      " (0.51040327158563, 0.05157613040002784)\n",
      "隐藏层vs神经元数vs norm 2 70 0.2\n",
      "验证集最优结果： 3.7711715698242188 3.7461280822753906\n",
      "------------train------------\n",
      " (0.5368152042010397, 0.054417920609879045)\n",
      "------------test------------\n",
      " (0.5261447923606485, 0.052398401065956)\n",
      "------------oot------------\n",
      " (0.5363419409400016, 0.08043652034893822)\n",
      "隐藏层vs神经元数vs norm 2 70 0.3\n",
      "验证集最优结果： 5.346527576446533 5.321018218994141\n",
      "------------train------------\n",
      " (0.5628426728499214, 0.09342629873052422)\n",
      "------------test------------\n",
      " (0.5435176548967356, 0.08841883188985122)\n",
      "------------oot------------\n",
      " (0.5832817803728032, 0.14532374100719425)\n",
      "隐藏层vs神经元数vs norm 2 70 0.4\n",
      "验证集最优结果： 6.9644694328308105 6.925685405731201\n",
      "------------train------------\n",
      " (0.5358031835369489, 0.06011577359379339)\n",
      "------------test------------\n",
      " (0.5365134354874529, 0.07537197423939601)\n",
      "------------oot------------\n",
      " (0.5285811930166011, 0.0719841518089876)\n",
      "隐藏层vs神经元数vs norm 2 70 0.5\n",
      "验证集最优结果： 8.46172046661377 8.39511489868164\n",
      "------------train------------\n",
      " (0.4931219412820914, 0.013948328944278221)\n",
      "------------test------------\n",
      " (0.47320341994226073, 0.009704641350210985)\n",
      "------------oot------------\n",
      " (0.44391964689118274, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 70 0.8\n",
      "验证集最优结果： 13.313806533813477 13.304239273071289\n",
      "------------train------------\n",
      " (0.48754124256618603, 0.010119665200038708)\n",
      "------------test------------\n",
      " (0.4848023539862314, 0.028558738618698634)\n",
      "------------oot------------\n",
      " (0.49040999084790143, 0.023695825947937288)\n",
      "隐藏层vs神经元数vs norm 2 72 0.01\n",
      "验证集最优结果： 0.7398595809936523 0.7283130884170532\n",
      "------------train------------\n",
      " (0.560928273297693, 0.10472319173977807)\n",
      "------------test------------\n",
      " (0.5403664223850766, 0.07673773040195431)\n",
      "------------oot------------\n",
      " (0.5462041960634391, 0.08364786431724186)\n",
      "隐藏层vs神经元数vs norm 2 72 0.05\n",
      "验证集最优结果： 1.3964378833770752 1.3824180364608765\n",
      "------------train------------\n",
      " (0.5109781873777951, 0.03632161316892479)\n",
      "------------test------------\n",
      " (0.47096713302242954, 0.016266933155673985)\n",
      "------------oot------------\n",
      " (0.47450271666724586, 0.013387550828902084)\n",
      "隐藏层vs神经元数vs norm 2 72 0.1\n",
      "验证集最优结果： 2.219978094100952 2.198805809020996\n",
      "------------train------------\n",
      " (0.499446782792197, 0.012372465295332313)\n",
      "------------test------------\n",
      " (0.4833155673995114, 0.005263157894736842)\n",
      "------------oot------------\n",
      " (0.49295172557606093, 0.019288916692732805)\n",
      "隐藏层vs神经元数vs norm 2 72 0.2\n",
      "验证集最优结果： 3.841047525405884 3.8266067504882812\n",
      "------------train------------\n",
      " (0.49282049407832895, 0.01367950355286729)\n",
      "------------test------------\n",
      " (0.5054319342660449, 0.03164556962025317)\n",
      "------------oot------------\n",
      " (0.49782550770977424, 0.018871859034511496)\n",
      "隐藏层vs神经元数vs norm 2 72 0.3\n",
      "验证集最优结果： 5.389218807220459 5.298774719238281\n",
      "------------train------------\n",
      " (0.5216212228577384, 0.041965457426166086)\n",
      "------------test------------\n",
      " (0.49998778592049736, 0.04082833666444591)\n",
      "------------oot------------\n",
      " (0.5241511138914954, 0.07115003649254509)\n",
      "隐藏层vs神经元数vs norm 2 72 0.4\n",
      "验证集最优结果： 7.067398548126221 7.013848781585693\n",
      "------------train------------\n",
      " (0.5330035958441707, 0.056949292032223875)\n",
      "------------test------------\n",
      " (0.5411747723739729, 0.0873861869864535)\n",
      "------------oot------------\n",
      " (0.5339566028336751, 0.06474820143884885)\n",
      "隐藏层vs神经元数vs norm 2 72 0.5\n",
      "验证集最优结果： 8.777913093566895 8.750639915466309\n",
      "------------train------------\n",
      " (0.5278475898098121, 0.04317909713381507)\n",
      "------------test------------\n",
      " (0.5330512991339108, 0.0788141239173884)\n",
      "------------oot------------\n",
      " (0.5170877790521207, 0.057790289507524406)\n",
      "隐藏层vs神经元数vs norm 2 72 0.8\n",
      "验证集最优结果： 13.693568229675293 13.675801277160645\n",
      "------------train------------\n",
      " (0.5347841241415624, 0.06169502124817006)\n",
      "------------test------------\n",
      " (0.5276293582056406, 0.0529757939151676)\n",
      "------------oot------------\n",
      " (0.5805790150488306, 0.12038369304556351)\n",
      "隐藏层vs神经元数vs norm 2 74 0.01\n",
      "验证集最优结果： 0.7471120357513428 0.7361212968826294\n",
      "------------train------------\n",
      " (0.5184766019712508, 0.03623146326425225)\n",
      "------------test------------\n",
      " (0.5140417499444815, 0.041605596269153944)\n",
      "------------oot------------\n",
      " (0.5349471147719506, 0.07104577207798979)\n",
      "隐藏层vs神经元数vs norm 2 74 0.05\n",
      "验证集最优结果： 1.4228429794311523 1.4053106307983398\n",
      "------------train------------\n",
      " (0.48626926260491266, 0.004470135813673948)\n",
      "------------test------------\n",
      " (0.49254385964912273, 0.027781479013990668)\n",
      "------------oot------------\n",
      " (0.49315330344420116, 0.023953011503840396)\n",
      "隐藏层vs神经元数vs norm 2 74 0.1\n",
      "验证集最优结果： 2.2463185787200928 2.218576192855835\n",
      "------------train------------\n",
      " (0.5083628249406615, 0.017426545086119516)\n",
      "------------test------------\n",
      " (0.5093015767266267, 0.05111037086386855)\n",
      "------------oot------------\n",
      " (0.5177469618508093, 0.04848295276822012)\n",
      "隐藏层vs神经元数vs norm 2 74 0.2\n",
      "验证集最优结果： 3.9584133625030518 3.9268741607666016\n",
      "------------train------------\n",
      " (0.5284733600940483, 0.046393090131631065)\n",
      "------------test------------\n",
      " (0.5074938929602488, 0.03683100155451924)\n",
      "------------oot------------\n",
      " (0.507102723618207, 0.025975741146213482)\n",
      "隐藏层vs神经元数vs norm 2 74 0.3\n",
      "验证集最优结果： 5.625443935394287 5.602110862731934\n",
      "------------train------------\n",
      " (0.5155368487735349, 0.034634212700984546)\n",
      "------------test------------\n",
      " (0.5185298689762381, 0.07146346879857873)\n",
      "------------oot------------\n",
      " (0.5053603494016381, 0.04010704479894345)\n",
      "隐藏层vs神经元数vs norm 2 74 0.4\n",
      "验证集最优结果： 7.337893009185791 7.310451507568359\n",
      "------------train------------\n",
      " (0.5128181388105492, 0.025104041246965414)\n",
      "------------test------------\n",
      " (0.500827226293582, 0.03493226737730404)\n",
      "------------oot------------\n",
      " (0.5194395208470904, 0.060869565217391286)\n",
      "隐藏层vs神经元数vs norm 2 74 0.5\n",
      "验证集最优结果： 9.032690048217773 9.009222030639648\n",
      "------------train------------\n",
      " (0.5094552495737845, 0.024269545507766638)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.5237041972018655, 0.05123251165889409)\n",
      "------------oot------------\n",
      " (0.5220055839386462, 0.047919924929621494)\n",
      "隐藏层vs神经元数vs norm 2 74 0.8\n",
      "验证集最优结果： 13.785175323486328 13.601162910461426\n",
      "------------train------------\n",
      " (0.4879877282427063, 0.011414250317588914)\n",
      "------------test------------\n",
      " (0.4739029535864979, 0.007517210748389963)\n",
      "------------oot------------\n",
      " (0.5216128546438212, 0.050484829527682185)\n",
      "隐藏层vs神经元数vs norm 2 76 0.01\n",
      "验证集最优结果： 0.7522872686386108 0.7411430478096008\n",
      "------------train------------\n",
      " (0.5104391829928008, 0.03718981360221285)\n",
      "------------test------------\n",
      " (0.4912391738840773, 0.026160337552742614)\n",
      "------------oot------------\n",
      " (0.46585572122012536, 0.010266569353213083)\n",
      "隐藏层vs神经元数vs norm 2 76 0.05\n",
      "验证集最优结果： 1.4448617696762085 1.429220199584961\n",
      "------------train------------\n",
      " (0.48397788484770954, 0.0158489217543496)\n",
      "------------test------------\n",
      " (0.4752298467688208, 0.006362425049966692)\n",
      "------------oot------------\n",
      " (0.47155203373533056, 0.01659889479720571)\n",
      "隐藏层vs神经元数vs norm 2 76 0.1\n",
      "验证集最优结果： 2.319836378097534 2.2992348670959473\n",
      "------------train------------\n",
      " (0.5362244922130651, 0.06007909097492525)\n",
      "------------test------------\n",
      " (0.5174594714634687, 0.07764823451032646)\n",
      "------------oot------------\n",
      " (0.5293214703599439, 0.05040836895700829)\n",
      "隐藏层vs神经元数vs norm 2 76 0.2\n",
      "验证集最优结果： 4.042718410491943 4.024227142333984\n",
      "------------train------------\n",
      " (0.4599263369697856, 0.0013744476457135946)\n",
      "------------test------------\n",
      " (0.46244836775483006, 0.0037086386853208966)\n",
      "------------oot------------\n",
      " (0.4653228142123982, 0.01085045007472285)\n",
      "隐藏层vs神经元数vs norm 2 76 0.3\n",
      "验证集最优结果： 5.769052028656006 5.752823352813721\n",
      "------------train------------\n",
      " (0.5195825626260965, 0.03861041908200058)\n",
      "------------test------------\n",
      " (0.5172051965356429, 0.04483677548301135)\n",
      "------------oot------------\n",
      " (0.5449182682839235, 0.10360407326312865)\n",
      "隐藏层vs神经元数vs norm 2 76 0.4\n",
      "验证集最优结果： 7.461883068084717 7.4128618240356445\n",
      "------------train------------\n",
      " (0.4519143657121741, 0.0008729380408909471)\n",
      "------------test------------\n",
      " (0.4824006218076838, 0.005263157894736842)\n",
      "------------oot------------\n",
      " (0.4416791204717385, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 76 0.5\n",
      "验证集最优结果： 9.26607894897461 9.230694770812988\n",
      "------------train------------\n",
      " (0.5243368872158366, 0.04691734025294764)\n",
      "------------test------------\n",
      " (0.5379280479680213, 0.07181878747501663)\n",
      "------------oot------------\n",
      " (0.5421529443112176, 0.06995447120564413)\n",
      "隐藏层vs神经元数vs norm 2 76 0.8\n",
      "验证集最优结果： 14.474781036376953 14.426078796386719\n",
      "------------train------------\n",
      " (0.5232969146668887, 0.04215090092376578)\n",
      "------------test------------\n",
      " (0.47518765267599383, 0.013446591161447918)\n",
      "------------oot------------\n",
      " (0.5099815799534285, 0.042101970597435104)\n",
      "隐藏层vs神经元数vs norm 2 78 0.01\n",
      "验证集最优结果： 0.7571128606796265 0.7462306022644043\n",
      "------------train------------\n",
      " (0.5246803637670479, 0.04050221347795213)\n",
      "------------test------------\n",
      " (0.5026837663779702, 0.032889184987785924)\n",
      "------------oot------------\n",
      " (0.5139216163301243, 0.03871685260487262)\n",
      "隐藏层vs神经元数vs norm 2 78 0.05\n",
      "验证集最优结果： 1.4682283401489258 1.4518556594848633\n",
      "------------train------------\n",
      " (0.5626240660991012, 0.10964854396398338)\n",
      "------------test------------\n",
      " (0.5558716411281368, 0.10031090384188324)\n",
      "------------oot------------\n",
      " (0.5979459910332604, 0.14700587356201994)\n",
      "隐藏层vs神经元数vs norm 2 78 0.1\n",
      "验证集最优结果： 2.360046148300171 2.34513783454895\n",
      "------------train------------\n",
      " (0.5343618002638171, 0.05732640559741575)\n",
      "------------test------------\n",
      " (0.5224272707084167, 0.05103264490339776)\n",
      "------------oot------------\n",
      " (0.5422757446216939, 0.08118722413373647)\n",
      "隐藏层vs神经元数vs norm 2 78 0.2\n",
      "验证集最优结果： 4.096315860748291 4.042911052703857\n",
      "------------train------------\n",
      " (0.5050247743037577, 0.015659823530884798)\n",
      "------------test------------\n",
      " (0.5176449033977348, 0.0559737952476127)\n",
      "------------oot------------\n",
      " (0.5073436902651791, 0.0632050881034303)\n",
      "隐藏层vs神经元数vs norm 2 78 0.3\n",
      "验证集最优结果： 5.944931983947754 5.909237384796143\n",
      "------------train------------\n",
      " (0.5038904556834032, 0.02485024083966647)\n",
      "------------test------------\n",
      " (0.5209427048634244, 0.07080834998889629)\n",
      "------------oot------------\n",
      " (0.49408820769471384, 0.018753692698015523)\n",
      "隐藏层vs神经元数vs norm 2 78 0.4\n",
      "验证集最优结果： 7.711088180541992 7.692028522491455\n",
      "------------train------------\n",
      " (0.5148720947467377, 0.0277745629726186)\n",
      "------------test------------\n",
      " (0.5348267821452366, 0.07056406839884521)\n",
      "------------oot------------\n",
      " (0.4963681228929899, 0.013728147916449496)\n",
      "隐藏层vs神经元数vs norm 2 78 0.5\n",
      "验证集最优结果： 9.525131225585938 9.489617347717285\n",
      "------------train------------\n",
      " (0.49687297594175184, 0.02114759745766437)\n",
      "------------test------------\n",
      " (0.49558516544525866, 0.022607150788363395)\n",
      "------------oot------------\n",
      " (0.5111910471622702, 0.03515796058805132)\n",
      "隐藏层vs神经元数vs norm 2 78 0.8\n",
      "验证集最优结果： 14.89583969116211 14.819121360778809\n",
      "------------train------------\n",
      " (0.5224242473464321, 0.049805927288552154)\n",
      "------------test------------\n",
      " (0.5026115922718187, 0.03964023984010662)\n",
      "------------oot------------\n",
      " (0.528145599462459, 0.06842525979216629)\n",
      "隐藏层vs神经元数vs norm 2 80 0.01\n",
      "验证集最优结果： 0.7623293995857239 0.7509915828704834\n",
      "------------train------------\n",
      " (0.48028722084493203, 0.01053048345931984)\n",
      "------------test------------\n",
      " (0.46540417499444814, 0.011292471685542968)\n",
      "------------oot------------\n",
      " (0.46620211077514806, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 80 0.05\n",
      "验证集最优结果： 1.493483304977417 1.4772303104400635\n",
      "------------train------------\n",
      " (0.47073512103572224, 0.008626912724469471)\n",
      "------------test------------\n",
      " (0.5057106373528758, 0.037574950033311016)\n",
      "------------oot------------\n",
      " (0.47869182914537933, 0.01212247593229765)\n",
      "隐藏层vs神经元数vs norm 2 80 0.1\n",
      "验证集最优结果： 2.4039230346679688 2.384507894515991\n",
      "------------train------------\n",
      " (0.4868174714846782, 0.0008906702293475841)\n",
      "------------test------------\n",
      " (0.476266933155674, 0.009227181878747492)\n",
      "------------oot------------\n",
      " (0.45339033121329025, 0.005400896673965176)\n",
      "隐藏层vs神经元数vs norm 2 80 0.2\n",
      "验证集最优结果： 4.201582908630371 4.16705846786499\n",
      "------------train------------\n",
      " (0.5214102639591917, 0.04040691988502504)\n",
      "------------test------------\n",
      " (0.5163468798578725, 0.053131245836109287)\n",
      "------------oot------------\n",
      " (0.4571948238510641, 0.004761408264692624)\n",
      "隐藏层vs神经元数vs norm 2 80 0.3\n",
      "验证集最优结果： 6.023740291595459 5.9665398597717285\n",
      "------------train------------\n",
      " (0.49119278746618533, 0.00883198345356706)\n",
      "------------test------------\n",
      " (0.4893670886075949, 0.022607150788363395)\n",
      "------------oot------------\n",
      " (0.49523279926783215, 0.017606784137907172)\n",
      "隐藏层vs神经元数vs norm 2 80 0.4\n",
      "验证集最优结果： 7.920241355895996 7.897212982177734\n",
      "------------train------------\n",
      " (0.48411392186602176, 0.0036464688918532717)\n",
      "------------test------------\n",
      " (0.48653564290473017, 0.00989340439706865)\n",
      "------------oot------------\n",
      " (0.4940511359028719, 0.023695825947937288)\n",
      "隐藏层vs神经元数vs norm 2 80 0.5\n",
      "验证集最优结果： 9.72916316986084 9.709037780761719\n",
      "------------train------------\n",
      " (0.4817221068276371, 0.0019084437026705148)\n",
      "------------test------------\n",
      " (0.4770941594492561, 0.007317343992893626)\n",
      "------------oot------------\n",
      " (0.44475492070112027, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 80 0.8\n",
      "验证集最优结果： 15.248066902160645 15.159059524536133\n",
      "------------train------------\n",
      " (0.48284661183224264, 0.013630097073579761)\n",
      "------------test------------\n",
      " (0.4838474350433045, 0.018065733955141022)\n",
      "------------oot------------\n",
      " (0.48956660758349846, 0.016362562124213664)\n",
      "隐藏层vs神经元数vs norm 2 82 0.01\n",
      "验证集最优结果： 0.7628563046455383 0.7515760064125061\n",
      "------------train------------\n",
      " (0.4926489926831034, 0.005897780024757382)\n",
      "------------test------------\n",
      " (0.49439928936264715, 0.020064401510104357)\n",
      "------------oot------------\n",
      " (0.5233424854319444, 0.060737496958954584)\n",
      "隐藏层vs神经元数vs norm 2 82 0.05\n",
      "验证集最优结果： 1.516634464263916 1.498325228691101\n",
      "------------train------------\n",
      " (0.4281964807697124, 0.0018907115142138275)\n",
      "------------test------------\n",
      " (0.4208794137241839, 0.0035087719298245615)\n",
      "------------oot------------\n",
      " (0.42175766633070355, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 2 82 0.1\n",
      "验证集最优结果： 2.4603288173675537 2.4408962726593018\n",
      "------------train------------\n",
      " (0.4881040703494121, 0.002311411069352509)\n",
      "------------test------------\n",
      " (0.46890628469908957, 0.018909615811681046)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.4791505925694227, 0.014124352691759656)\n",
      "隐藏层vs神经元数vs norm 2 82 0.2\n",
      "验证集最优结果： 4.336811065673828 4.310375690460205\n",
      "------------train------------\n",
      " (0.49285054404655304, 0.015790716860942466)\n",
      "------------test------------\n",
      " (0.4976315789473685, 0.02969131689984461)\n",
      "------------oot------------\n",
      " (0.5232891947311716, 0.044228964654363434)\n",
      "隐藏层vs神经元数vs norm 2 82 0.3\n",
      "验证集最优结果： 6.209153652191162 6.1971869468688965\n",
      "------------train------------\n",
      " (0.47495010283992506, 0.001547844083980232)\n",
      "------------test------------\n",
      " (0.46383411059293805, 0.005740617366200351)\n",
      "------------oot------------\n",
      " (0.46097614661893677, 0.005261877454558084)\n",
      "隐藏层vs神经元数vs norm 2 82 0.4\n",
      "验证集最优结果： 8.09310531616211 8.04996395111084\n",
      "------------train------------\n",
      " (0.4928411365114559, 0.011821143130570588)\n",
      "------------test------------\n",
      " (0.5150977126360203, 0.0478014656895403)\n",
      "------------oot------------\n",
      " (0.4922137652197083, 0.019970110867827462)\n",
      "隐藏层vs神经元数vs norm 2 82 0.5\n",
      "验证集最优结果： 9.89193344116211 9.814939498901367\n",
      "------------train------------\n",
      " (0.5032099998714077, 0.015358782407774052)\n",
      "------------test------------\n",
      " (0.5196269153897402, 0.04143904063957361)\n",
      "------------oot------------\n",
      " (0.5163741470591643, 0.06529037639453655)\n",
      "隐藏层vs神经元数vs norm 2 82 0.8\n",
      "验证集最优结果： 15.66201114654541 15.583952903747559\n",
      "------------train------------\n",
      " (0.5196731862915294, 0.0357398349552871)\n",
      "------------test------------\n",
      " (0.5080735065511881, 0.055729513657561625)\n",
      "------------oot------------\n",
      " (0.5008931984846905, 0.025245890244326274)\n",
      "隐藏层vs神经元数vs norm 2 84 0.01\n",
      "验证集最优结果： 0.7716596126556396 0.7605980634689331\n",
      "------------train------------\n",
      " (0.5095803224145014, 0.028509975032807944)\n",
      "------------test------------\n",
      " (0.5108205640683988, 0.04306018210082163)\n",
      "------------oot------------\n",
      " (0.4996037952246898, 0.026462308414138325)\n",
      "隐藏层vs神经元数vs norm 2 84 0.05\n",
      "验证集最优结果： 1.5401692390441895 1.522050142288208\n",
      "------------train------------\n",
      " (0.5068282461579694, 0.01794280895461975)\n",
      "------------test------------\n",
      " (0.5139196091494559, 0.04996668887408395)\n",
      "------------oot------------\n",
      " (0.4968106674081024, 0.01598721023181454)\n",
      "隐藏层vs神经元数vs norm 2 84 0.1\n",
      "验证集最优结果： 2.4637997150421143 2.428295373916626\n",
      "------------train------------\n",
      " (0.5106885841930399, 0.025850958925618867)\n",
      "------------test------------\n",
      " (0.5054608039085053, 0.029769042860315342)\n",
      "------------oot------------\n",
      " (0.4778426534135011, 0.012344906683348977)\n",
      "隐藏层vs神经元数vs norm 2 84 0.2\n",
      "验证集最优结果： 4.419588088989258 4.403878688812256\n",
      "------------train------------\n",
      " (0.5345314066160014, 0.05640135387289269)\n",
      "------------test------------\n",
      " (0.5262258494337109, 0.055751721074839056)\n",
      "------------oot------------\n",
      " (0.545885610352298, 0.08077711743648563)\n",
      "隐藏层vs神经元数vs norm 2 84 0.3\n",
      "验证集最优结果： 6.375380039215088 6.339740753173828\n",
      "------------train------------\n",
      " (0.534812008346311, 0.058784641217592304)\n",
      "------------test------------\n",
      " (0.5069076171441261, 0.027304019542527147)\n",
      "------------oot------------\n",
      " (0.5341350108319142, 0.06237792374795814)\n",
      "隐藏层vs神经元数vs norm 2 84 0.4\n",
      "验证集最优结果： 8.301016807556152 8.271933555603027\n",
      "------------train------------\n",
      " (0.4933660634338586, 0.01680361736644509)\n",
      "------------test------------\n",
      " (0.4813513213413281, 0.01643348878525419)\n",
      "------------oot------------\n",
      " (0.4461346864537355, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 84 0.5\n",
      "验证集最优结果： 10.185397148132324 10.182276725769043\n",
      "------------train------------\n",
      " (0.5048443391341955, 0.024063121176496893)\n",
      "------------test------------\n",
      " (0.4853197868087942, 0.01370197646013771)\n",
      "------------oot------------\n",
      " (0.5043014863471542, 0.037618600771556654)\n",
      "隐藏层vs神经元数vs norm 2 84 0.8\n",
      "验证集最优结果： 15.995412826538086 15.891345024108887\n",
      "------------train------------\n",
      " (0.5348055110558841, 0.06581051329271181)\n",
      "------------test------------\n",
      " (0.514477015323118, 0.03871863202309578)\n",
      "------------oot------------\n",
      " (0.5458844518588029, 0.1018941368644215)\n",
      "隐藏层vs神经元数vs norm 2 86 0.01\n",
      "验证集最优结果： 0.7771583199501038 0.76546311378479\n",
      "------------train------------\n",
      " (0.5046609937199628, 0.025777458327665204)\n",
      "------------test------------\n",
      " (0.4839851210304242, 0.011236953142349515)\n",
      "------------oot------------\n",
      " (0.49516213116463353, 0.041295659124873985)\n",
      "隐藏层vs神经元数vs norm 2 86 0.05\n",
      "验证集最优结果： 1.5651077032089233 1.5472291707992554\n",
      "------------train------------\n",
      " (0.5587690747926112, 0.09542353873569498)\n",
      "------------test------------\n",
      " (0.5246335776149234, 0.05841661114812349)\n",
      "------------oot------------\n",
      " (0.5569318458276856, 0.08096479338268514)\n",
      "隐藏层vs神经元数vs norm 2 86 0.1\n",
      "验证集最优结果： 2.553711175918579 2.5343692302703857\n",
      "------------train------------\n",
      " (0.5193716037275496, 0.03714433256922489)\n",
      "------------test------------\n",
      " (0.4944636908727515, 0.02199644681323565)\n",
      "------------oot------------\n",
      " (0.46148472526326767, 0.016286101553539822)\n",
      "隐藏层vs神经元数vs norm 2 86 0.2\n",
      "验证集最优结果： 4.539397239685059 4.511701583862305\n",
      "------------train------------\n",
      " (0.5316795698793737, 0.0469293873122808)\n",
      "------------test------------\n",
      " (0.5195891627803686, 0.05560737286253603)\n",
      "------------oot------------\n",
      " (0.5394536544677302, 0.07552914190386828)\n",
      "隐藏层vs神经元数vs norm 2 86 0.3\n",
      "验证集最优结果： 6.480749607086182 6.472408771514893\n",
      "------------train------------\n",
      " (0.47775483422095794, 0.0025656175573030016)\n",
      "------------test------------\n",
      " (0.4557050854985565, 0.005174328225627356)\n",
      "------------oot------------\n",
      " (0.4695872287677104, 0.009522816529385136)\n",
      "隐藏层vs神经元数vs norm 2 86 0.4\n",
      "验证集最优结果： 8.397607803344727 8.341384887695312\n",
      "------------train------------\n",
      " (0.48911385756991865, 0.01697132867558826)\n",
      "------------test------------\n",
      " (0.48623251165889414, 0.01679991117033086)\n",
      "------------oot------------\n",
      " (0.4569306873341906, 0.010523754909116168)\n",
      "隐藏层vs神经元数vs norm 2 86 0.5\n",
      "验证集最优结果： 10.371970176696777 10.299490928649902\n",
      "------------train------------\n",
      " (0.5175502643246642, 0.03615417258021625)\n",
      "------------test------------\n",
      " (0.5043060182100821, 0.05338663113479902)\n",
      "------------oot------------\n",
      " (0.5285035739524323, 0.05505856184617519)\n",
      "隐藏层vs神经元数vs norm 2 86 0.8\n",
      "验证集最优结果： 16.33988380432129 16.324623107910156\n",
      "------------train------------\n",
      " (0.47491612742540135, 0.0036681265266094165)\n",
      "------------test------------\n",
      " (0.49337885853875196, 0.024727959138352212)\n",
      "------------oot------------\n",
      " (0.48678622319535675, 0.03585305668508676)\n",
      "隐藏层vs神经元数vs norm 2 88 0.01\n",
      "验证集最优结果： 0.7807705402374268 0.768978476524353\n",
      "------------train------------\n",
      " (0.5055481445836625, 0.018518902039133978)\n",
      "------------test------------\n",
      " (0.5066788807461693, 0.029480346435709515)\n",
      "------------oot------------\n",
      " (0.48821001170078426, 0.03040350328432906)\n",
      "隐藏层vs神经元数vs norm 2 88 0.05\n",
      "验证集最优结果： 1.5892248153686523 1.571278691291809\n",
      "------------train------------\n",
      " (0.49590982031607966, 0.01644599567253391)\n",
      "------------test------------\n",
      " (0.5045092160781701, 0.02971352431712193)\n",
      "------------oot------------\n",
      " (0.5144614742988218, 0.04570951934104894)\n",
      "隐藏层vs神经元数vs norm 2 88 0.1\n",
      "验证集最优结果： 2.60565447807312 2.582298517227173\n",
      "------------train------------\n",
      " (0.5196495659336234, 0.03638969935818959)\n",
      "------------test------------\n",
      " (0.5131367976904286, 0.031701088163446633)\n",
      "------------oot------------\n",
      " (0.5259931185486393, 0.0580474750634275)\n",
      "隐藏层vs神经元数vs norm 2 88 0.2\n",
      "验证集最优结果： 4.585958480834961 4.549375057220459\n",
      "------------train------------\n",
      " (0.47482658664170624, 0.013005409671081436)\n",
      "------------test------------\n",
      " (0.4689007328447702, 0.019509216078170133)\n",
      "------------oot------------\n",
      " (0.4648246620095228, 0.004295693879678875)\n",
      "隐藏层vs神经元数vs norm 2 88 0.3\n",
      "验证集最优结果： 6.654109477996826 6.616310119628906\n",
      "------------train------------\n",
      " (0.433194521430568, 0.00043450629729568924)\n",
      "------------test------------\n",
      " (0.4511514545858316, 0.005518543193426595)\n",
      "------------oot------------\n",
      " (0.42787798746510036, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 88 0.4\n",
      "验证集最优结果： 8.66758918762207 8.640824317932129\n",
      "------------train------------\n",
      " (0.47937144129528897, 0.001728143893325318)\n",
      "------------test------------\n",
      " (0.49026204752387303, 0.03256717743726406)\n",
      "------------oot------------\n",
      " (0.4913136157740474, 0.02181211552497131)\n",
      "隐藏层vs神经元数vs norm 2 88 0.5\n",
      "验证集最优结果： 10.664551734924316 10.63875961303711\n",
      "------------train------------\n",
      " (0.48674160208292305, 0.007566906863372136)\n",
      "------------test------------\n",
      " (0.5054152787030868, 0.054985565178769735)\n",
      "------------oot------------\n",
      " (0.46418169811976506, 0.010245716470302035)\n",
      "隐藏层vs神经元数vs norm 2 88 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集最优结果： 16.809043884277344 16.726037979125977\n",
      "------------train------------\n",
      " (0.5051924179327923, 0.016125462678142494)\n",
      "------------test------------\n",
      " (0.4982611592271819, 0.022573839662447248)\n",
      "------------oot------------\n",
      " (0.5055572932957981, 0.04360337816703158)\n",
      "隐藏层vs神经元数vs norm 2 90 0.01\n",
      "验证集最优结果： 0.7863993048667908 0.7747431993484497\n",
      "------------train------------\n",
      " (0.48626296835481164, 0.0037282264630578155)\n",
      "------------test------------\n",
      " (0.5404263824117255, 0.08022429491450145)\n",
      "------------oot------------\n",
      " (0.4865962302621671, 0.006513050429221845)\n",
      "隐藏层vs神经元数vs norm 2 90 0.05\n",
      "验证集最优结果： 1.6113876104354858 1.5918736457824707\n",
      "------------train------------\n",
      " (0.5162700950702486, 0.03957201806517452)\n",
      "------------test------------\n",
      " (0.5014823451032645, 0.02602709304907838)\n",
      "------------oot------------\n",
      " (0.5208551998980526, 0.05259097070169949)\n",
      "隐藏层vs神经元数vs norm 2 90 0.1\n",
      "验证集最优结果： 2.6502630710601807 2.6278250217437744\n",
      "------------train------------\n",
      " (0.5009928671933532, 0.014657887202977338)\n",
      "------------test------------\n",
      " (0.5321163668665334, 0.07583833000222073)\n",
      "------------oot------------\n",
      " (0.49901875600968504, 0.03486602022729646)\n",
      "隐藏层vs神经元数vs norm 2 90 0.2\n",
      "验证集最优结果： 4.715907573699951 4.694030284881592\n",
      "------------train------------\n",
      " (0.5062399706539049, 0.03947834879485412)\n",
      "------------test------------\n",
      " (0.5219598045747279, 0.06469020652898072)\n",
      "------------oot------------\n",
      " (0.5267287619180019, 0.07472978139227748)\n",
      "隐藏层vs神经元数vs norm 2 90 0.3\n",
      "验证集最优结果： 6.727340221405029 6.671521186828613\n",
      "------------train------------\n",
      " (0.44748747748790385, 0.00032513524177701925)\n",
      "------------test------------\n",
      " (0.4540106595602932, 0.007117477237397292)\n",
      "------------oot------------\n",
      " (0.40709808964422667, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 2 90 0.4\n",
      "验证集最优结果： 8.877415657043457 8.836884498596191\n",
      "------------train------------\n",
      " (0.4606811055410382, 0.0018237082066869803)\n",
      "------------test------------\n",
      " (0.48936042638241173, 0.016078170108816348)\n",
      "------------oot------------\n",
      " (0.45435303930768434, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 90 0.5\n",
      "验证集最优结果： 10.835195541381836 10.772821426391602\n",
      "------------train------------\n",
      " (0.49934424742764827, 0.023781301204232164)\n",
      "------------test------------\n",
      " (0.4736531201421275, 0.005751721074839011)\n",
      "------------oot------------\n",
      " (0.5027236182068837, 0.04208806867549439)\n",
      "隐藏层vs神经元数vs norm 2 90 0.8\n",
      "验证集最优结果： 17.163028717041016 17.10325050354004\n",
      "------------train------------\n",
      " (0.5432823092994501, 0.07669658804268453)\n",
      "------------test------------\n",
      " (0.5093282256273596, 0.05421940928270047)\n",
      "------------oot------------\n",
      " (0.5137246724359643, 0.044055190630104546)\n",
      "隐藏层vs神经元数vs norm 2 92 0.01\n",
      "验证集最优结果： 0.7915735244750977 0.7798433899879456\n",
      "------------train------------\n",
      " (0.5411036866031962, 0.07127283949865282)\n",
      "------------test------------\n",
      " (0.5503653120142127, 0.10047745947146347)\n",
      "------------oot------------\n",
      " (0.5373869020725449, 0.08983421958085713)\n",
      "隐藏层vs神经元数vs norm 2 92 0.05\n",
      "验证集最优结果： 1.634077548980713 1.6173049211502075\n",
      "------------train------------\n",
      " (0.46664494135180185, 0.00359421984800401)\n",
      "------------test------------\n",
      " (0.4822829224961137, 0.024206084832333996)\n",
      "------------oot------------\n",
      " (0.4472144023911306, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 2 92 0.1\n",
      "验证集最优结果： 2.6923389434814453 2.676669120788574\n",
      "------------train------------\n",
      " (0.4593075377367366, 0.003346916731131966)\n",
      "------------test------------\n",
      " (0.45211192538307793, 0.010615145458583164)\n",
      "------------oot------------\n",
      " (0.4669620825079067, 0.005192367844854551)\n",
      "隐藏层vs神经元数vs norm 2 92 0.2\n",
      "验证集最优结果： 4.813250541687012 4.8033318519592285\n",
      "------------train------------\n",
      " (0.5174518574467408, 0.03400343408871098)\n",
      "------------test------------\n",
      " (0.4971996446813236, 0.019264934488119057)\n",
      "------------oot------------\n",
      " (0.5135497399182103, 0.04292913495290723)\n",
      "隐藏层vs神经元数vs norm 2 92 0.3\n",
      "验证集最优结果： 6.924432754516602 6.918753623962402\n",
      "------------train------------\n",
      " (0.4879168671689884, 0.007666396623033256)\n",
      "------------test------------\n",
      " (0.49806018210082165, 0.022429491450144348)\n",
      "------------oot------------\n",
      " (0.47675135254115547, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 2 92 0.4\n",
      "验证集最优结果： 9.069123268127441 9.028182029724121\n",
      "------------train------------\n",
      " (0.5132236780213585, 0.032338368056613054)\n",
      "------------test------------\n",
      " (0.509552520541861, 0.05532978014656892)\n",
      "------------oot------------\n",
      " (0.5256224006302205, 0.048774893128975094)\n",
      "隐藏层vs神经元数vs norm 2 92 0.5\n",
      "验证集最优结果： 11.136260032653809 11.12397289276123\n",
      "------------train------------\n",
      " (0.5202894136804511, 0.03497193644296359)\n",
      "------------test------------\n",
      " (0.5001665556295802, 0.041172551632245175)\n",
      "------------oot------------\n",
      " (0.48455728171086315, 0.01686303131407918)\n",
      "隐藏层vs神经元数vs norm 2 92 0.8\n",
      "验证集最优结果： 17.273029327392578 17.051223754882812\n",
      "------------train------------\n",
      " (0.4699297954233357, 0.00623672200869152)\n",
      "------------test------------\n",
      " (0.4777526093715301, 0.013968465467466218)\n",
      "------------oot------------\n",
      " (0.4680823457176288, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 2 94 0.01\n",
      "验证集最优结果： 0.7959061861038208 0.7836577892303467\n",
      "------------train------------\n",
      " (0.5140646710509842, 0.026762880709070958)\n",
      "------------test------------\n",
      " (0.5073628691983123, 0.027337330668443238)\n",
      "------------oot------------\n",
      " (0.47640496298613283, 0.020560942550307493)\n",
      "隐藏层vs神经元数vs norm 2 94 0.05\n",
      "验证集最优结果： 1.6606605052947998 1.6436975002288818\n",
      "------------train------------\n",
      " (0.4873646651628147, 0.007971769273095286)\n",
      "------------test------------\n",
      " (0.5051387963579835, 0.045547412835887174)\n",
      "------------oot------------\n",
      " (0.4787543877941125, 0.011114586591596295)\n",
      "隐藏层vs神经元数vs norm 2 94 0.1\n",
      "验证集最优结果： 2.7428412437438965 2.7267651557922363\n",
      "------------train------------\n",
      " (0.544344819324566, 0.07400698052640231)\n",
      "------------test------------\n",
      " (0.523302242949145, 0.0491228070175439)\n",
      "------------oot------------\n",
      " (0.5365690056650332, 0.09597886907865011)\n",
      "隐藏层vs神经元数vs norm 2 94 0.2\n",
      "验证集最优结果： 4.909942626953125 4.893978595733643\n",
      "------------train------------\n",
      " (0.4739795700824141, 0.0007527381679941492)\n",
      "------------test------------\n",
      " (0.4772351765489674, 0.01159227181878747)\n",
      "------------oot------------\n",
      " (0.49446703506759804, 0.018413095610468222)\n",
      "隐藏层vs神经元数vs norm 2 94 0.3\n",
      "验证集最优结果： 7.076269149780273 7.052166938781738\n",
      "------------train------------\n",
      " (0.5263615376649956, 0.046619953855701945)\n",
      "------------test------------\n",
      " (0.5483821896513436, 0.08356651121474579)\n",
      "------------oot------------\n",
      " (0.552757793764988, 0.08880547735724459)\n",
      "隐藏层vs神经元数vs norm 2 94 0.4\n",
      "验证集最优结果： 9.146515846252441 9.037022590637207\n",
      "------------train------------\n",
      " (0.4850433051174961, 0.005965730853804918)\n",
      "------------test------------\n",
      " (0.4619142793693094, 0.0038862980235397915)\n",
      "------------oot------------\n",
      " (0.4683569086759578, 0.014353734403781293)\n",
      "隐藏层vs神经元数vs norm 2 94 0.5\n",
      "验证集最优结果： 11.397756576538086 11.349898338317871\n",
      "------------train------------\n",
      " (0.45109245847317736, 0.001519283078145528)\n",
      "------------test------------\n",
      " (0.47584277148567616, 0.00923828558738618)\n",
      "------------oot------------\n",
      " (0.46976563676594957, 0.020352413721197005)\n",
      "隐藏层vs神经元数vs norm 2 94 0.8\n",
      "验证集最优结果： 17.942569732666016 17.901979446411133\n",
      "------------train------------\n",
      " (0.5399523802755799, 0.06263387971485013)\n",
      "------------test------------\n",
      " (0.547743726404619, 0.10562958027981345)\n",
      "------------oot------------\n",
      " (0.5359086643728496, 0.07144892781427031)\n",
      "隐藏层vs神经元数vs norm 2 96 0.01\n",
      "验证集最优结果： 0.7961416840553284 0.7848244905471802\n",
      "------------train------------\n",
      " (0.4696807326236397, 0.0013360053440213762)\n",
      "------------test------------\n",
      " (0.4881678880746169, 0.015045525205418575)\n",
      "------------oot------------\n",
      " (0.45527635862324634, 0.005261877454558084)\n",
      "隐藏层vs神经元数vs norm 2 96 0.05\n",
      "验证集最优结果： 1.68500816822052 1.6677361726760864\n",
      "------------train------------\n",
      " (0.5490524446393632, 0.07818365538913019)\n",
      "------------test------------\n",
      " (0.5673162336220299, 0.10866089273817453)\n",
      "------------oot------------\n",
      " (0.5550145390933631, 0.09297605393945713)\n",
      "隐藏层vs神经元数vs norm 2 96 0.1\n",
      "验证集最优结果： 2.7642569541931152 2.7380597591400146\n",
      "------------train------------\n",
      " (0.5400675718204392, 0.06714272855065079)\n",
      "------------test------------\n",
      " (0.5105196535642904, 0.05361980901621144)\n",
      "------------oot------------\n",
      " (0.5014550678297942, 0.02832516595419321)\n",
      "隐藏层vs神经元数vs norm 2 96 0.2\n",
      "验证集最优结果： 5.016275882720947 4.988325595855713\n",
      "------------train------------\n",
      " (0.5071238728723912, 0.030818272817164205)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.5028358871863202, 0.02705973795247607)\n",
      "------------oot------------\n",
      " (0.4866611058978903, 0.011197998123240538)\n",
      "隐藏层vs神经元数vs norm 2 96 0.3\n",
      "验证集最优结果： 7.256013870239258 7.219299793243408\n",
      "------------train------------\n",
      " (0.5143286911546836, 0.027049709009373035)\n",
      "------------test------------\n",
      " (0.5150088829669108, 0.04954474794581387)\n",
      "------------oot------------\n",
      " (0.5332325443992632, 0.0749730650262399)\n",
      "隐藏层vs神经元数vs norm 2 96 0.4\n",
      "验证集最优结果： 9.370698928833008 9.286466598510742\n",
      "------------train------------\n",
      " (0.48171648937862216, 0.004516429007965339)\n",
      "------------test------------\n",
      " (0.4581012658227849, 0.00624028425494115)\n",
      "------------oot------------\n",
      " (0.4580996072707052, 0.004260939074827164)\n",
      "隐藏层vs神经元数vs norm 2 96 0.5\n",
      "验证集最优结果： 11.651822090148926 11.640456199645996\n",
      "------------train------------\n",
      " (0.5566858133693933, 0.09146560598400444)\n",
      "------------test------------\n",
      " (0.5417810348656451, 0.07264046191427942)\n",
      "------------oot------------\n",
      " (0.5753820132299957, 0.13763597817398254)\n",
      "隐藏层vs神经元数vs norm 2 96 0.8\n",
      "验证集最优结果： 18.369407653808594 18.308975219726562\n",
      "------------train------------\n",
      " (0.47213413656086234, 0.004292813929107742)\n",
      "------------test------------\n",
      " (0.4788962913613146, 0.0069953364423717135)\n",
      "------------oot------------\n",
      " (0.48392011028858073, 0.01747471587947036)\n",
      "隐藏层vs神经元数vs norm 2 98 0.01\n",
      "验证集最优结果： 0.7988197803497314 0.7875927090644836\n",
      "------------train------------\n",
      " (0.5471122589657532, 0.07156819549264004)\n",
      "------------test------------\n",
      " (0.5412458361092605, 0.09229402620475241)\n",
      "------------oot------------\n",
      " (0.5468992921604745, 0.08532304591109724)\n",
      "隐藏层vs神经元数vs norm 2 98 0.05\n",
      "验证集最优结果： 1.7083625793457031 1.6879897117614746\n",
      "------------train------------\n",
      " (0.4575132026971877, 0.0036858587150661037)\n",
      "------------test------------\n",
      " (0.4783155673995115, 0.012891405729513639)\n",
      "------------oot------------\n",
      " (0.45216232810852763, 0.004295693879678875)\n",
      "隐藏层vs神经元数vs norm 2 98 0.1\n",
      "验证集最优结果： 2.8362205028533936 2.8093698024749756\n",
      "------------train------------\n",
      " (0.5310268629119096, 0.0556123391666819)\n",
      "------------test------------\n",
      " (0.5211259160559627, 0.04675771707750381)\n",
      "------------oot------------\n",
      " (0.5098031719551894, 0.047906023007680876)\n",
      "隐藏层vs神经元数vs norm 2 98 0.2\n",
      "验证集最优结果： 5.089050769805908 5.082304954528809\n",
      "------------train------------\n",
      " (0.506320577663263, 0.02149845114071436)\n",
      "------------test------------\n",
      " (0.5108727514990007, 0.03462136353542089)\n",
      "------------oot------------\n",
      " (0.49926899060461777, 0.031355784937267595)\n",
      "隐藏层vs神经元数vs norm 2 98 0.3\n",
      "验证集最优结果： 7.3937859535217285 7.370213031768799\n",
      "------------train------------\n",
      " (0.4589635874247652, 0.001647333843641352)\n",
      "------------test------------\n",
      " (0.4894781256939818, 0.03395514101709973)\n",
      "------------oot------------\n",
      " (0.44090640531053416, 0.015285163173808791)\n",
      "隐藏层vs神经元数vs norm 2 98 0.4\n",
      "验证集最优结果： 9.632635116577148 9.617232322692871\n",
      "------------train------------\n",
      " (0.45215043393101634, 0.0012158054711246535)\n",
      "------------test------------\n",
      " (0.4701421274705752, 0.024605818343326757)\n",
      "------------oot------------\n",
      " (0.45786906706518843, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 2 98 0.5\n",
      "验证集最优结果： 11.873047828674316 11.849946975708008\n",
      "------------train------------\n",
      " (0.5143368804478258, 0.041526754962136314)\n",
      "------------test------------\n",
      " (0.5271108150122141, 0.054286031534532486)\n",
      "------------oot------------\n",
      " (0.5158644099213383, 0.046696555798839134)\n",
      "隐藏层vs神经元数vs norm 2 98 0.8\n",
      "验证集最优结果： 18.694185256958008 18.68240737915039\n",
      "------------train------------\n",
      " (0.49060099259647294, 0.007106682124803476)\n",
      "------------test------------\n",
      " (0.4976671108150122, 0.03146791028203422)\n",
      "------------oot------------\n",
      " (0.4923076031928081, 0.017349598582004022)\n",
      "隐藏层vs神经元数vs norm 2 100 0.01\n",
      "验证集最优结果： 0.8104939460754395 0.7987331748008728\n",
      "------------train------------\n",
      " (0.5400230383089719, 0.06144704133021195)\n",
      "------------test------------\n",
      " (0.5393126804352655, 0.08664223850766156)\n",
      "------------oot------------\n",
      " (0.5377170727186367, 0.06841830883119593)\n",
      "隐藏层vs神经元数vs norm 2 100 0.05\n",
      "验证集最优结果： 1.7338827848434448 1.717719316482544\n",
      "------------train------------\n",
      " (0.5075743516753195, 0.016866018426586415)\n",
      "------------test------------\n",
      " (0.5271374639129469, 0.06239173884077276)\n",
      "------------oot------------\n",
      " (0.5310244557976805, 0.06873805303583225)\n",
      "隐藏层vs神经元数vs norm 2 100 0.1\n",
      "验证集最优结果： 2.88948917388916 2.8621981143951416\n",
      "------------train------------\n",
      " (0.4645224254655884, 0.0017527794528604534)\n",
      "------------test------------\n",
      " (0.4782145236508994, 0.01719964468132351)\n",
      "------------oot------------\n",
      " (0.48686731774001085, 0.006485246585340443)\n",
      "隐藏层vs神经元数vs norm 2 100 0.2\n",
      "验证集最优结果： 5.203884124755859 5.1705098152160645\n",
      "------------train------------\n",
      " (0.46654842951691977, 0.0)\n",
      "------------test------------\n",
      " (0.5038285587386186, 0.03931823228958464)\n",
      "------------oot------------\n",
      " (0.4687067737114656, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 100 0.3\n",
      "验证集最优结果： 7.492743492126465 7.489415645599365\n",
      "------------train------------\n",
      " (0.45286811380274905, 0.0005478027991139278)\n",
      "------------test------------\n",
      " (0.4663979569176105, 0.0061403508771929825)\n",
      "------------oot------------\n",
      " (0.4632803901806091, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 2 100 0.4\n",
      "验证集最优结果： 9.833154678344727 9.833658218383789\n",
      "------------train------------\n",
      " (0.528705502866591, 0.05690773644553537)\n",
      "------------test------------\n",
      " (0.5319309349322674, 0.06642238507661558)\n",
      "------------oot------------\n",
      " (0.5148159733083099, 0.0359781739825531)\n",
      "隐藏层vs神经元数vs norm 2 100 0.5\n",
      "验证集最优结果： 12.180335998535156 12.121867179870605\n",
      "------------train------------\n",
      " (0.5064567500417925, 0.023491765699585665)\n",
      "------------test------------\n",
      " (0.48423717521652226, 0.011747723739729099)\n",
      "------------oot------------\n",
      " (0.5060786153685747, 0.03680533833802524)\n",
      "隐藏层vs神经元数vs norm 2 100 0.8\n",
      "验证集最优结果： 19.09453582763672 19.06337547302246\n",
      "------------train------------\n",
      " (0.49741198032674605, 0.009886710266192644)\n",
      "------------test------------\n",
      " (0.5310537419498111, 0.057672662669331576)\n",
      "------------oot------------\n",
      " (0.505121699741656, 0.04440968963959269)\n",
      "隐藏层vs神经元数vs norm 2 130 0.01\n",
      "验证集最优结果： 0.8838192820549011 0.8715430498123169\n",
      "------------train------------\n",
      " (0.5191511019336883, 0.045066018561946586)\n",
      "------------test------------\n",
      " (0.4858994003997335, 0.014623584277148494)\n",
      "------------oot------------\n",
      " (0.4795537483057032, 0.01697424668960479)\n",
      "隐藏层vs神经元数vs norm 2 130 0.05\n",
      "验证集最优结果： 2.0983965396881104 2.0801289081573486\n",
      "------------train------------\n",
      " (0.4967912860506558, 0.00936042974161766)\n",
      "------------test------------\n",
      " (0.4912025316455696, 0.03845214301576727)\n",
      "------------oot------------\n",
      " (0.4689384724104774, 0.01231710283946752)\n",
      "隐藏层vs神经元数vs norm 2 130 0.1\n",
      "验证集最优结果： 3.62681245803833 3.6094822883605957\n",
      "------------train------------\n",
      " (0.5077205407099237, 0.040539437537689405)\n",
      "------------test------------\n",
      " (0.4971674439262714, 0.045425272040861664)\n",
      "------------oot------------\n",
      " (0.5435060647134466, 0.08348799221492365)\n",
      "隐藏层vs神经元数vs norm 2 130 0.2\n",
      "验证集最优结果： 6.6959123611450195 6.65676212310791\n",
      "------------train------------\n",
      " (0.44641440936584414, 0.004689825446231866)\n",
      "------------test------------\n",
      " (0.44521763268931824, 0.0043859649122807015)\n",
      "------------oot------------\n",
      " (0.4217692512656541, 0.005261877454558084)\n",
      "隐藏层vs神经元数vs norm 2 130 0.3\n",
      "验证集最优结果： 9.737749099731445 9.71688461303711\n",
      "------------train------------\n",
      " (0.4852368025480207, 0.0031626914754873114)\n",
      "------------test------------\n",
      " (0.46806684432600487, 0.003308905174328247)\n",
      "------------oot------------\n",
      " (0.4726757724255379, 0.005234073610676682)\n",
      "隐藏层vs神经元数vs norm 2 130 0.4\n",
      "验证集最优结果： 12.792631149291992 12.77411937713623\n",
      "------------train------------\n",
      " (0.5007107088205455, 0.012067769446356458)\n",
      "------------test------------\n",
      " (0.5066977570508551, 0.03234510326449036)\n",
      "------------oot------------\n",
      " (0.5181257892236936, 0.05377263406665975)\n",
      "隐藏层vs神经元数vs norm 2 130 0.5\n",
      "验证集最优结果： 15.861087799072266 15.795509338378906\n",
      "------------train------------\n",
      " (0.5380131421234905, 0.05717561431542584)\n",
      "------------test------------\n",
      " (0.5558349988896292, 0.11908727514990003)\n",
      "------------oot------------\n",
      " (0.5429105990569864, 0.07721822541966428)\n",
      "隐藏层vs神经元数vs norm 2 130 0.8\n",
      "验证集最优结果： 25.035566329956055 25.01030158996582\n",
      "------------train------------\n",
      " (0.48357694788428596, 0.007724736876657645)\n",
      "------------test------------\n",
      " (0.47933488785254275, 0.01717743726404619)\n",
      "------------oot------------\n",
      " (0.4548257046536684, 0.007020470580057725)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 2 160 0.01\n",
      "验证集最优结果： 0.9604288339614868 0.9467761516571045\n",
      "------------train------------\n",
      " (0.579690823727834, 0.11349507525689678)\n",
      "------------test------------\n",
      " (0.5253930712858095, 0.05369753497668217)\n",
      "------------oot------------\n",
      " (0.5346899292160474, 0.05629583289889828)\n",
      "隐藏层vs神经元数vs norm 2 160 0.05\n",
      "验证集最优结果： 2.4844439029693604 2.464092493057251\n",
      "------------train------------\n",
      " (0.5469967967004594, 0.07296538365484773)\n",
      "------------test------------\n",
      " (0.5179913391072618, 0.04565844992227408)\n",
      "------------oot------------\n",
      " (0.5589175036782168, 0.09058492336565532)\n",
      "隐藏层vs神经元数vs norm 2 160 0.1\n",
      "验证集最优结果： 4.395481586456299 4.361231327056885\n",
      "------------train------------\n",
      " (0.5089463628371231, 0.01902839789677291)\n",
      "------------test------------\n",
      " (0.5216933155673995, 0.05012214079502553)\n",
      "------------oot------------\n",
      " (0.5393621334816205, 0.06481076008758219)\n",
      "隐藏层vs神经元数vs norm 2 160 0.2\n",
      "验证集最优结果： 8.219779014587402 8.171850204467773\n",
      "------------train------------\n",
      " (0.5305805125956066, 0.06009817676555407)\n",
      "------------test------------\n",
      " (0.503217854763491, 0.04872307350655125)\n",
      "------------oot------------\n",
      " (0.4975046050116429, 0.02968755430438258)\n",
      "隐藏层vs神经元数vs norm 2 160 0.3\n",
      "验证集最优结果： 12.022915840148926 11.985512733459473\n",
      "------------train------------\n",
      " (0.46674172390711854, 0.00111333778668448)\n",
      "------------test------------\n",
      " (0.49781256939817903, 0.032889184987785924)\n",
      "------------oot------------\n",
      " (0.4552369698444143, 0.0037604698849615925)\n",
      "隐藏层vs神经元数vs norm 2 160 0.4\n",
      "验证集最优结果： 15.698158264160156 15.606367111206055\n",
      "------------train------------\n",
      " (0.503854652905947, 0.020743005768375622)\n",
      "------------test------------\n",
      " (0.5181212524983344, 0.044703530979347095)\n",
      "------------oot------------\n",
      " (0.49231107867329327, 0.018420046571438475)\n",
      "隐藏层vs神经元数vs norm 2 160 0.5\n",
      "验证集最优结果： 19.628101348876953 19.599803924560547\n",
      "------------train------------\n",
      " (0.5384513031466513, 0.056158788363623535)\n",
      "------------test------------\n",
      " (0.5375727292915833, 0.07133022429491448)\n",
      "------------oot------------\n",
      " (0.5559691377332916, 0.09513780280123729)\n",
      "隐藏层vs神经元数vs norm 2 160 0.8\n",
      "验证集最优结果： 31.153545379638672 31.110103607177734\n",
      "------------train------------\n",
      " (0.47254908330676887, 0.008774726081680395)\n",
      "------------test------------\n",
      " (0.4700199866755496, 0.004141683322229639)\n",
      "------------oot------------\n",
      " (0.5191325200708998, 0.0462864491015883)\n",
      "隐藏层vs神经元数vs norm 2 190 0.01\n",
      "验证集最优结果： 1.03807532787323 1.0241655111312866\n",
      "------------train------------\n",
      " (0.5330980772757945, 0.05216579731567156)\n",
      "------------test------------\n",
      " (0.5153764157228514, 0.03965134354874533)\n",
      "------------oot------------\n",
      " (0.5575145680557003, 0.11069405345288985)\n",
      "隐藏层vs神经元数vs norm 2 190 0.05\n",
      "验证集最优结果： 2.876683473587036 2.8491408824920654\n",
      "------------train------------\n",
      " (0.4774894605150862, 0.0031311525448736166)\n",
      "------------test------------\n",
      " (0.47852986897623806, 0.019398178991783255)\n",
      "------------oot------------\n",
      " (0.4929980653158632, 0.027915059256942265)\n",
      "隐藏层vs神经元数vs norm 2 190 0.1\n",
      "验证集最优结果： 5.179431438446045 5.140678405761719\n",
      "------------train------------\n",
      " (0.5002972510370285, 0.009786949786097066)\n",
      "------------test------------\n",
      " (0.5007483899622474, 0.03306684432600493)\n",
      "------------oot------------\n",
      " (0.48591387759357735, 0.014610919959684443)\n",
      "隐藏层vs神经元数vs norm 2 190 0.2\n",
      "验证集最优结果： 9.78491497039795 9.758578300476074\n",
      "------------train------------\n",
      " (0.4949779329005867, 0.01098380482680994)\n",
      "------------test------------\n",
      " (0.5154918942926938, 0.042382855873861924)\n",
      "------------oot------------\n",
      " (0.5190039272929483, 0.04571647030201925)\n",
      "隐藏层vs神经元数vs norm 2 190 0.3\n",
      "验证集最优结果： 14.358824729919434 14.346195220947266\n",
      "------------train------------\n",
      " (0.4960163488070365, 0.007651100918486753)\n",
      "------------test------------\n",
      " (0.4936420164334888, 0.022851432378414395)\n",
      "------------oot------------\n",
      " (0.49389358078754386, 0.03303791749209328)\n",
      "隐藏层vs神经元数vs norm 2 190 0.4\n",
      "验证集最优结果： 18.799413681030273 18.675451278686523\n",
      "------------train------------\n",
      " (0.49027585735469587, 0.013389697327786276)\n",
      "------------test------------\n",
      " (0.49060848323339995, 0.02047523872973578)\n",
      "------------oot------------\n",
      " (0.4966368933838437, 0.027532756403572778)\n",
      "隐藏层vs神经元数vs norm 2 190 0.5\n",
      "验证集最优结果： 23.544944763183594 23.53851318359375\n",
      "------------train------------\n",
      " (0.501785062864669, 0.012503358625389871)\n",
      "------------test------------\n",
      " (0.4916600044414834, 0.017077503886298015)\n",
      "------------oot------------\n",
      " (0.45828844171039973, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 190 0.8\n",
      "验证集最优结果： 37.535526275634766 37.378536224365234\n",
      "------------train------------\n",
      " (0.5250271566435809, 0.04841889114263653)\n",
      "------------test------------\n",
      " (0.5257528314457028, 0.04935598489895632)\n",
      "------------oot------------\n",
      " (0.5475839618160544, 0.08555937858408924)\n",
      "隐藏层vs神经元数vs norm 2 220 0.01\n",
      "验证集最优结果： 1.118001103401184 1.1048030853271484\n",
      "------------train------------\n",
      " (0.5112918846812164, 0.037460669396882196)\n",
      "------------test------------\n",
      " (0.5198190095491895, 0.049300466355762795)\n",
      "------------oot------------\n",
      " (0.5209733662345486, 0.0675285858269905)\n",
      "隐藏层vs神经元数vs norm 2 220 0.05\n",
      "验证集最优结果： 3.2810654640197754 3.2575621604919434\n",
      "------------train------------\n",
      " (0.4968759538665307, 0.010026808091021633)\n",
      "------------test------------\n",
      " (0.5103308905174329, 0.038962913613146744)\n",
      "------------oot------------\n",
      " (0.46198519445313313, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 2 220 0.1\n",
      "验证集最优结果： 5.929842948913574 5.891476154327393\n",
      "------------train------------\n",
      " (0.49099705659207643, 0.017951472008522318)\n",
      "------------test------------\n",
      " (0.5048534310459694, 0.04338218965134355)\n",
      "------------oot------------\n",
      " (0.46963588549450297, 0.0020366315643137664)\n",
      "隐藏层vs神经元数vs norm 2 220 0.2\n",
      "验证集最优结果： 11.393693923950195 11.39096450805664\n",
      "------------train------------\n",
      " (0.5050718796593525, 0.03207603995562891)\n",
      "------------test------------\n",
      " (0.49837441705529656, 0.024095047745947173)\n",
      "------------oot------------\n",
      " (0.5233019381596171, 0.06267681506968337)\n",
      "隐藏层vs神经元数vs norm 2 220 0.3\n",
      "验证集最优结果： 16.77850341796875 16.7521915435791\n",
      "------------train------------\n",
      " (0.4389471276223504, 0.0007103704200025485)\n",
      "------------test------------\n",
      " (0.45151676660004436, 0.005662891405729514)\n",
      "------------oot------------\n",
      " (0.42264738933490886, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 220 0.4\n",
      "验证集最优结果： 22.2590274810791 22.141338348388672\n",
      "------------train------------\n",
      " (0.5348984358450097, 0.05516592117027025)\n",
      "------------test------------\n",
      " (0.5309704641350211, 0.0626471241394626)\n",
      "------------oot------------\n",
      " (0.5463883965291535, 0.08854829180134155)\n",
      "隐藏层vs神经元数vs norm 2 220 0.5\n",
      "验证集最优结果： 27.730682373046875 27.622114181518555\n",
      "------------train------------\n",
      " (0.46520145999530305, 0.0005300706106573516)\n",
      "------------test------------\n",
      " (0.4806218076837664, 0.015656229180546294)\n",
      "------------oot------------\n",
      " (0.4756577346818197, 0.0031765891634518498)\n",
      "隐藏层vs神经元数vs norm 2 220 0.8\n",
      "验证集最优结果： 43.870697021484375 43.74667739868164\n",
      "------------train------------\n",
      " (0.5122898955628243, 0.03215725608596459)\n",
      "------------test------------\n",
      " (0.49781145902731516, 0.03184543637574949)\n",
      "------------oot------------\n",
      " (0.47977617905675457, 0.013825461370034417)\n",
      "隐藏层vs神经元数vs norm 2 250 0.01\n",
      "验证集最优结果： 1.2010504007339478 1.187657117843628\n",
      "------------train------------\n",
      " (0.5293068406316178, 0.04985722881088084)\n",
      "------------test------------\n",
      " (0.5465067732622696, 0.09257161892071952)\n",
      "------------oot------------\n",
      " (0.5633649602057484, 0.11488548291801337)\n",
      "隐藏层vs神经元数vs norm 2 250 0.05\n",
      "验证集最优结果： 3.696420431137085 3.6672651767730713\n",
      "------------train------------\n",
      " (0.5293737085789275, 0.05194285903790019)\n",
      "------------test------------\n",
      " (0.5175705085498556, 0.04377081945369754)\n",
      "------------oot------------\n",
      " (0.5518912406306838, 0.08980641573697562)\n",
      "隐藏层vs神经元数vs norm 2 250 0.1\n",
      "验证集最优结果： 6.799136161804199 6.787075519561768\n",
      "------------train------------\n",
      " (0.5293810180306577, 0.05099642039905544)\n",
      "------------test------------\n",
      " (0.5121618920719521, 0.03625360870530753)\n",
      "------------oot------------\n",
      " (0.5598396645002838, 0.1043061203211344)\n",
      "隐藏层vs神经元数vs norm 2 250 0.2\n",
      "验证集最优结果： 12.925759315490723 12.854105949401855\n",
      "------------train------------\n",
      " (0.5232651726959492, 0.0363143037171946)\n",
      "------------test------------\n",
      " (0.5095836109260493, 0.05073284477015316)\n",
      "------------oot------------\n",
      " (0.5470568472758026, 0.10253362527369408)\n",
      "隐藏层vs神经元数vs norm 2 250 0.3\n",
      "验证集最优结果： 19.288755416870117 19.262147903442383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " (0.5270656815150058, 0.05756193237538909)\n",
      "------------test------------\n",
      " (0.5233044636908728, 0.058760826115922704)\n",
      "------------oot------------\n",
      " (0.48856219372328225, 0.025496124839259116)\n",
      "隐藏层vs神经元数vs norm 2 250 0.4\n",
      "验证集最优结果： 25.491472244262695 25.44393539428711\n",
      "------------train------------\n",
      " (0.5027103176295177, 0.01588898837864855)\n",
      "------------test------------\n",
      " (0.5169864534754608, 0.050444148345547446)\n",
      "------------oot------------\n",
      " (0.5023054020551675, 0.018559065790845652)\n",
      "隐藏层vs神经元数vs norm 2 250 0.5\n",
      "验证集最优结果： 31.504514694213867 31.297042846679688\n",
      "------------train------------\n",
      " (0.46669962687956124, 0.002739013995569639)\n",
      "------------test------------\n",
      " (0.48084388185654003, 0.005474128358871844)\n",
      "------------oot------------\n",
      " (0.5122823480346157, 0.047259583637437874)\n",
      "隐藏层vs神经元数vs norm 2 250 0.8\n",
      "验证集最优结果： 50.44898986816406 50.367794036865234\n",
      "------------train------------\n",
      " (0.5447287685807278, 0.07158701056283456)\n",
      "------------test------------\n",
      " (0.5432134132800357, 0.07496113701976459)\n",
      "------------oot------------\n",
      " (0.5626640716412377, 0.10780940465019295)\n",
      "隐藏层vs神经元数vs norm 2 280 0.01\n",
      "验证集最优结果： 1.2848477363586426 1.2705010175704956\n",
      "------------train------------\n",
      " (0.5282508278969287, 0.04772720043261125)\n",
      "------------test------------\n",
      " (0.5322929158338886, 0.06625582944703534)\n",
      "------------oot------------\n",
      " (0.5540043327656715, 0.10926910645396726)\n",
      "隐藏层vs神经元数vs norm 2 280 0.05\n",
      "验证集最优结果： 4.119767189025879 4.092861652374268\n",
      "------------train------------\n",
      " (0.4797810413126151, 0.002503622577813447)\n",
      "------------test------------\n",
      " (0.4820986009327115, 0.03263379968909619)\n",
      "------------oot------------\n",
      " (0.4871488316593103, 0.012226740346852893)\n",
      "隐藏层vs神经元数vs norm 2 280 0.1\n",
      "验证集最优结果： 7.663331031799316 7.615692615509033\n",
      "------------train------------\n",
      " (0.5032847863914252, 0.017154877130146795)\n",
      "------------test------------\n",
      " (0.5111747723739729, 0.034832333999555876)\n",
      "------------oot------------\n",
      " (0.5095286089968605, 0.0462099885309144)\n",
      "隐藏层vs神经元数vs norm 2 280 0.2\n",
      "验证集最优结果： 14.801981925964355 14.715848922729492\n",
      "------------train------------\n",
      " (0.46325430327050593, 0.0)\n",
      "------------test------------\n",
      " (0.5005274261603376, 0.032378414390406396)\n",
      "------------oot------------\n",
      " (0.45874372965395804, 0.0028637959197859164)\n",
      "隐藏层vs神经元数vs norm 2 280 0.3\n",
      "验证集最优结果： 21.852203369140625 21.799339294433594\n",
      "------------train------------\n",
      " (0.5506837382972631, 0.08857986151296171)\n",
      "------------test------------\n",
      " (0.532694870086609, 0.058461025982678216)\n",
      "------------oot------------\n",
      " (0.5962858698548408, 0.14540715253883846)\n",
      "隐藏层vs神经元数vs norm 2 280 0.4\n",
      "验证集最优结果： 29.002107620239258 28.847597122192383\n",
      "------------train------------\n",
      " (0.5371515743408465, 0.06926761324066566)\n",
      "------------test------------\n",
      " (0.5081467910282035, 0.05052187430601818)\n",
      "------------oot------------\n",
      " (0.5249157195982345, 0.05958363743787576)\n",
      "隐藏层vs神经元数vs norm 2 280 0.5\n",
      "验证集最优结果： 36.06686782836914 36.05210494995117\n",
      "------------train------------\n",
      " (0.5231538389172807, 0.054506716912379294)\n",
      "------------test------------\n",
      " (0.5193282256273596, 0.06288030202087491)\n",
      "------------oot------------\n",
      " (0.5589383565611279, 0.11343273207520943)\n",
      "隐藏层vs神经元数vs norm 2 280 0.8\n",
      "验证集最优结果： 57.51860809326172 57.27687454223633\n",
      "------------train------------\n",
      " (0.46355250182905494, 0.0008128381044425481)\n",
      "------------test------------\n",
      " (0.4688407728181213, 0.006051521208083499)\n",
      "------------oot------------\n",
      " (0.4530995493460305, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 310 0.01\n",
      "验证集最优结果： 1.3715840578079224 1.356207013130188\n",
      "------------train------------\n",
      " (0.5588016289248541, 0.09762747379256992)\n",
      "------------test------------\n",
      " (0.5224727959138352, 0.049911170330890514)\n",
      "------------oot------------\n",
      " (0.5505439126959302, 0.08931984846905083)\n",
      "隐藏层vs神经元数vs norm 2 310 0.05\n",
      "验证集最优结果： 4.556822776794434 4.518443584442139\n",
      "------------train------------\n",
      " (0.49861783682190447, 0.01586475889976513)\n",
      "------------test------------\n",
      " (0.5286442371752165, 0.09521430157672661)\n",
      "------------oot------------\n",
      " (0.5101715728866183, 0.04697459423765338)\n",
      "隐藏层vs神经元数vs norm 2 310 0.1\n",
      "验证集最优结果： 8.542139053344727 8.489856719970703\n",
      "------------train------------\n",
      " (0.517556084814005, 0.04168566785715977)\n",
      "------------test------------\n",
      " (0.5087230735065512, 0.04059515878303349)\n",
      "------------oot------------\n",
      " (0.5287850878717316, 0.08456539116532863)\n",
      "隐藏层vs神经元数vs norm 2 310 0.2\n",
      "验证集最优结果： 16.541889190673828 16.466049194335938\n",
      "------------train------------\n",
      " (0.5258765420066747, 0.04280969910100518)\n",
      "------------test------------\n",
      " (0.49252498334443695, 0.0165667332889185)\n",
      "------------oot------------\n",
      " (0.506849013542789, 0.03301706460918219)\n",
      "隐藏层vs神经元数vs norm 2 310 0.3\n",
      "验证集最优结果： 24.45342254638672 24.41606330871582\n",
      "------------train------------\n",
      " (0.5323545436025715, 0.052732279824762696)\n",
      "------------test------------\n",
      " (0.5168954030646236, 0.04651343548745279)\n",
      "------------oot------------\n",
      " (0.5530636360476836, 0.08947276961039863)\n",
      "隐藏层vs神经元数vs norm 2 310 0.4\n",
      "验证集最优结果： 32.548736572265625 32.38236618041992\n",
      "------------train------------\n",
      " (0.481724746351873, 4.927111907027104e-05)\n",
      "------------test------------\n",
      " (0.5277004219409283, 0.05849433710859425)\n",
      "------------oot------------\n",
      " (0.47203049154878995, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 2 310 0.5\n",
      "验证集最优结果： 40.39480972290039 40.323150634765625\n",
      "------------train------------\n",
      " (0.4708051022680281, 0.01553366780843013)\n",
      "------------test------------\n",
      " (0.4694525871641128, 0.007128580946035981)\n",
      "------------oot------------\n",
      " (0.464515344246342, 0.003913391026309387)\n",
      "隐藏层vs神经元数vs norm 2 310 0.8\n",
      "验证集最优结果： 63.797691345214844 63.39318084716797\n",
      "------------train------------\n",
      " (0.495031738586934, 0.018220432760150507)\n",
      "------------test------------\n",
      " (0.47865978236731077, 0.008605374194981141)\n",
      "------------oot------------\n",
      " (0.5067273717258078, 0.031077746498453407)\n",
      "隐藏层vs神经元数vs norm 2 340 0.01\n",
      "验证集最优结果： 1.4607642889022827 1.4449816942214966\n",
      "------------train------------\n",
      " (0.57111487412515, 0.09939473678867361)\n",
      "------------test------------\n",
      " (0.5603530979347102, 0.12238507661558962)\n",
      "------------oot------------\n",
      " (0.5655799997683013, 0.1201890661383937)\n",
      "隐藏层vs神经元数vs norm 2 340 0.05\n",
      "验证集最优结果： 5.005648612976074 4.975684642791748\n",
      "------------train------------\n",
      " (0.5156464228693795, 0.032435692052798615)\n",
      "------------test------------\n",
      " (0.4957861425716189, 0.0334332667110816)\n",
      "------------oot------------\n",
      " (0.560059778264345, 0.11002676119973587)\n",
      "隐藏层vs神经元数vs norm 2 340 0.1\n",
      "验证集最优结果： 9.436493873596191 9.391108512878418\n",
      "------------train------------\n",
      " (0.5436715376040835, 0.07009953713573719)\n",
      "------------test------------\n",
      " (0.5577881412391739, 0.11321341328003554)\n",
      "------------oot------------\n",
      " (0.5825472954969357, 0.15034928578876028)\n",
      "隐藏层vs神经元数vs norm 2 340 0.2\n",
      "验证集最优结果： 18.357803344726562 18.282119750976562\n",
      "------------train------------\n",
      " (0.4274634375133245, 0.0026966462475779274)\n",
      "------------test------------\n",
      " (0.45644015101043756, 0.008139018432156364)\n",
      "------------oot------------\n",
      " (0.39182103592488327, 0.0)\n",
      "隐藏层vs神经元数vs norm 2 340 0.3\n",
      "验证集最优结果： 27.26149559020996 27.150259017944336\n",
      "------------train------------\n",
      " (0.46786907147628587, 0.005244531616424353)\n",
      "------------test------------\n",
      " (0.463479902287364, 0.0038862980235397915)\n",
      "------------oot------------\n",
      " (0.4649532547874744, 0.00762520418447854)\n",
      "隐藏层vs神经元数vs norm 2 340 0.4\n",
      "验证集最优结果： 36.106693267822266 35.916351318359375\n",
      "------------train------------\n",
      " (0.5178103589820642, 0.0422168213495549)\n",
      "------------test------------\n",
      " (0.5038885187652676, 0.0301354652453919)\n",
      "------------oot------------\n",
      " (0.47848330031626873, 0.01034998088485728)\n",
      "隐藏层vs神经元数vs norm 2 340 0.5\n",
      "验证集最优结果： 44.88864517211914 44.8671760559082\n",
      "------------train------------\n",
      " (0.5598584538208468, 0.09363231698114227)\n",
      "------------test------------\n",
      " (0.5559504774594715, 0.10566289140572954)\n",
      "------------oot------------\n",
      " (0.5312735318991184, 0.09143989156500887)\n",
      "隐藏层vs神经元数vs norm 2 340 0.8\n",
      "验证集最优结果： 71.50633239746094 71.42870330810547\n",
      "------------train------------\n",
      " (0.492923841604181, 0.005504693953932827)\n",
      "------------test------------\n",
      " (0.47902842549411506, 0.007561625582944702)\n",
      "------------oot------------\n",
      " (0.47234444328595093, 0.015292114134779142)\n",
      "隐藏层vs神经元数vs norm 2 370 0.01\n",
      "验证集最优结果： 1.5529367923736572 1.5362523794174194\n",
      "------------train------------\n",
      " (0.5808474767840308, 0.11811789739560175)\n",
      "------------test------------\n",
      " (0.595388629802354, 0.16635576282478348)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.6280737728657654, 0.1945226427553609)\n",
      "隐藏层vs神经元数vs norm 2 370 0.05\n",
      "验证集最优结果： 5.464423656463623 5.422749042510986\n",
      "------------train------------\n",
      " (0.5069359252107728, 0.030357100557074967)\n",
      "------------test------------\n",
      " (0.4945169886742171, 0.023717521652231843)\n",
      "------------oot------------\n",
      " (0.5152909556412841, 0.035303930768428735)\n",
      "隐藏层vs神经元数vs norm 2 370 0.1\n",
      "验证集最优结果： 10.368494033813477 10.30611801147461\n",
      "------------train------------\n",
      " (0.49743939077073435, 0.01079402980225902)\n",
      "------------test------------\n",
      " (0.502559404841217, 0.032511658894070594)\n",
      "------------oot------------\n",
      " (0.4856404731287434, 0.017870920654780575)\n",
      "隐藏层vs神经元数vs norm 2 370 0.2\n",
      "验证集最优结果： 20.17475700378418 20.08026695251465\n",
      "------------train------------\n",
      " (0.4671136937840558, 0.007856442368018746)\n",
      "------------test------------\n",
      " (0.455793915167666, 0.0)\n",
      "------------oot------------\n",
      " (0.4374100719424461, 0.007159489799464791)\n",
      "隐藏层vs神经元数vs norm 2 370 0.3\n",
      "验证集最优结果： 29.936321258544922 29.892789840698242\n",
      "------------train------------\n",
      " (0.44979611367280325, 0.0008906702293475841)\n",
      "------------test------------\n",
      " (0.4940572951365756, 0.016600044414834647)\n",
      "------------oot------------\n",
      " (0.47029970226717177, 0.014047892121085745)\n",
      "隐藏层vs神经元数vs norm 2 370 0.4\n",
      "验证集最优结果： 39.831886291503906 39.6645393371582\n",
      "------------train------------\n",
      " (0.5014463916011692, 0.010832201383516815)\n",
      "------------test------------\n",
      " (0.4992438374417055, 0.043515434155007804)\n",
      "------------oot------------\n",
      " (0.4833211691516352, 0.010572411635908663)\n",
      "隐藏层vs神经元数vs norm 2 370 0.5\n",
      "验证集最优结果： 49.511070251464844 49.5136604309082\n",
      "------------train------------\n",
      " (0.5423124533430251, 0.07849579605005352)\n",
      "------------test------------\n",
      " (0.5506784365978238, 0.08580946035976011)\n",
      "------------oot------------\n",
      " (0.49829469757527306, 0.03920341987279742)\n",
      "隐藏层vs神经元数vs norm 2 370 0.8\n",
      "验证集最优结果： 78.97389221191406 78.91240692138672\n",
      "------------train------------\n",
      " (0.4989269995580489, 0.014074620026950146)\n",
      "------------test------------\n",
      " (0.4865989340439707, 0.008238951809904506)\n",
      "------------oot------------\n",
      " (0.45702104982680525, 0.009453306919681714)\n",
      "隐藏层vs神经元数vs norm 2 400 0.01\n",
      "验证集最优结果： 1.645865797996521 1.6299058198928833\n",
      "------------train------------\n",
      " (0.561173816731741, 0.0888014461885609)\n",
      "------------test------------\n",
      " (0.545650677326227, 0.10685098823006878)\n",
      "------------oot------------\n",
      " (0.5894982564672899, 0.17227956765022762)\n",
      "隐藏层vs神经元数vs norm 2 400 0.05\n",
      "验证集最优结果： 5.934141635894775 5.891160488128662\n",
      "------------train------------\n",
      " (0.510574340169701, 0.02453593441526747)\n",
      "------------test------------\n",
      " (0.48577503886298024, 0.014468132356206975)\n",
      "------------oot------------\n",
      " (0.5157844738701792, 0.041149688944496554)\n",
      "隐藏层vs神经元数vs norm 2 400 0.1\n",
      "验证集最优结果： 11.318483352661133 11.25563907623291\n",
      "------------train------------\n",
      " (0.47904454637068805, 0.018535686706069976)\n",
      "------------test------------\n",
      " (0.49882189651343545, 0.020186542305129895)\n",
      "------------oot------------\n",
      " (0.49061736118351695, 0.03784103152260801)\n",
      "隐藏层vs神经元数vs norm 2 400 0.2\n",
      "验证集最优结果： 21.97467803955078 21.9531192779541\n",
      "------------train------------\n",
      " (0.48319719479485823, 0.0010453869576370067)\n",
      "------------test------------\n",
      " (0.4972829224961137, 0.03334443704197203)\n",
      "------------oot------------\n",
      " (0.47857945527635865, 0.012456122058874697)\n",
      "隐藏层vs神经元数vs norm 2 400 0.3\n",
      "验证集最优结果： 32.45432662963867 32.204322814941406\n",
      "------------train------------\n",
      " (0.4675537498502577, 0.00514896730306269)\n",
      "------------test------------\n",
      " (0.47766155896069296, 0.005518543193426706)\n",
      "------------oot------------\n",
      " (0.4901609147464637, 0.03393459145726896)\n",
      "隐藏层vs神经元数vs norm 2 400 0.4\n",
      "验证集最优结果： 43.65350341796875 43.47878646850586\n",
      "------------train------------\n",
      " (0.45503854720586057, 0.0008128381044425481)\n",
      "------------test------------\n",
      " (0.4654374861203642, 0.004485898290028869)\n",
      "------------oot------------\n",
      " (0.46579547955838224, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 2 400 0.5\n",
      "验证集最优结果： 54.204856872558594 54.121253967285156\n",
      "------------train------------\n",
      " (0.5352093582639781, 0.07654105915309173)\n",
      "------------test------------\n",
      " (0.5283044636908728, 0.06413502109704644)\n",
      "------------oot------------\n",
      " (0.5553041624671278, 0.11257776387585583)\n",
      "隐藏层vs神经元数vs norm 2 400 0.8\n",
      "验证集最优结果： 86.46990203857422 86.40196228027344\n",
      "------------train------------\n",
      " (0.4469471195007374, 0.0008906702293475841)\n",
      "------------test------------\n",
      " (0.4544803464357095, 0.010626249167221852)\n",
      "------------oot------------\n",
      " (0.42411635908664375, 0.000966183574879227)\n",
      "隐藏层vs神经元数vs norm 2 430 0.01\n",
      "验证集最优结果： 1.742494821548462 1.7261576652526855\n",
      "------------train------------\n",
      " (0.5780283972199718, 0.11263391355490449)\n",
      "------------test------------\n",
      " (0.5436897623806352, 0.09777925827226297)\n",
      "------------oot------------\n",
      " (0.5982576257834312, 0.1774441316512008)\n",
      "隐藏层vs神经元数vs norm 2 430 0.05\n",
      "验证集最优结果： 6.413735389709473 6.372310161590576\n",
      "------------train------------\n",
      " (0.4841878285446273, 0.002502539696075704)\n",
      "------------test------------\n",
      " (0.4971463468798578, 0.027037530535198757)\n",
      "------------oot------------\n",
      " (0.5131361577404743, 0.038556980502554516)\n",
      "隐藏层vs神经元数vs norm 2 430 0.1\n",
      "验证集最优结果： 12.281292915344238 12.204894065856934\n",
      "------------train------------\n",
      " (0.49600991919671833, 0.011287011713396397)\n",
      "------------test------------\n",
      " (0.4913035753941817, 0.007150788363313398)\n",
      "------------oot------------\n",
      " (0.4893071050406052, 0.01406179404302645)\n",
      "隐藏层vs神经元数vs norm 2 430 0.2\n",
      "验证集最优结果： 23.94009780883789 23.904043197631836\n",
      "------------train------------\n",
      " (0.5140454499001379, 0.030875665549268044)\n",
      "------------test------------\n",
      " (0.5114068398845214, 0.04309349322673772)\n",
      "------------oot------------\n",
      " (0.5140015523812833, 0.05510026761199738)\n",
      "隐藏层vs神经元数vs norm 2 430 0.3\n",
      "验证集最优结果： 35.376243591308594 35.19137954711914\n",
      "------------train------------\n",
      " (0.5280125939146108, 0.04761958905991659)\n",
      "------------test------------\n",
      " (0.5328436597823673, 0.06457916944259379)\n",
      "------------oot------------\n",
      " (0.5394246921303536, 0.07347165745664341)\n",
      "隐藏层vs神经元数vs norm 2 430 0.4\n",
      "验证集最优结果： 47.50734329223633 47.30211639404297\n",
      "------------train------------\n",
      " (0.4840617405022811, 0.01375923072081342)\n",
      "------------test------------\n",
      " (0.4721430157672663, 0.00834998889629135)\n",
      "------------oot------------\n",
      " (0.4945492881057473, 0.035394293261043264)\n",
      "隐藏层vs神经元数vs norm 2 430 0.5\n",
      "验证集最优结果： 59.0433235168457 59.035423278808594\n",
      "------------train------------\n",
      " (0.4922162460686318, 0.007786190415278393)\n",
      "------------test------------\n",
      " (0.48146679991117025, 0.01256939817899183)\n",
      "------------oot------------\n",
      " (0.47985495661441857, 0.020164737774997388)\n",
      "隐藏层vs神经元数vs norm 2 430 0.8\n",
      "验证集最优结果： 94.58251190185547 94.25830841064453\n",
      "------------train------------\n",
      " (0.4714105685196804, 0.00858454497647776)\n",
      "------------test------------\n",
      " (0.4908116811014879, 0.01785476349100601)\n",
      "------------oot------------\n",
      " (0.4827627752870168, 0.016619747680116773)\n",
      "隐藏层vs神经元数vs norm 2 460 0.01\n",
      "验证集最优结果： 1.839539647102356 1.8224412202835083\n",
      "------------train------------\n",
      " (0.574436952256421, 0.10829778435628434)\n",
      "------------test------------\n",
      " (0.582389518099045, 0.15364201643348885)\n",
      "------------oot------------\n",
      " (0.5934950590252436, 0.14635248323080663)\n",
      "隐藏层vs神经元数vs norm 2 460 0.05\n",
      "验证集最优结果： 6.907957553863525 6.862139701843262\n",
      "------------train------------\n",
      " (0.538094899694695, 0.07441076005438774)\n",
      "------------test------------\n",
      " (0.5398778592049744, 0.07621585609593606)\n",
      "------------oot------------\n",
      " (0.5580625354788633, 0.1249991311298787)\n",
      "隐藏层vs神经元数vs norm 2 460 0.1\n",
      "验证集最优结果： 13.246307373046875 13.166848182678223\n",
      "------------train------------\n",
      " (0.522868702619694, 0.049240663021416)\n",
      "------------test------------\n",
      " (0.5039717965800578, 0.03668665334221627)\n",
      "------------oot------------\n",
      " (0.5039307684287353, 0.027275570847669683)\n",
      "隐藏层vs神经元数vs norm 2 460 0.2\n",
      "验证集最优结果： 26.028942108154297 25.909465789794922\n",
      "------------train------------\n",
      " (0.5437849017860104, 0.06855751354109774)\n",
      "------------test------------\n",
      " (0.5268343326671108, 0.0798245614035088)\n",
      "------------oot------------\n",
      " (0.5339033121329024, 0.07203280853578009)\n",
      "隐藏层vs神经元数vs norm 2 460 0.3\n",
      "验证集最优结果： 38.754539489746094 38.55824279785156\n",
      "------------train------------\n",
      " (0.499958376733203, 0.016057105768443325)\n",
      "------------test------------\n",
      " (0.50217854763491, 0.027526093715300903)\n",
      "------------oot------------\n",
      " (0.494778669817769, 0.02187467417370459)\n",
      "隐藏层vs神经元数vs norm 2 460 0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集最优结果： 51.52360916137695 51.367305755615234\n",
      "------------train------------\n",
      " (0.45728281960746886, 0.0018128793893088524)\n",
      "------------test------------\n",
      " (0.47799689096158116, 0.014123917388407792)\n",
      "------------oot------------\n",
      " (0.46998111655603053, 0.01135091926458831)\n",
      "隐藏层vs神经元数vs norm 2 460 0.5\n",
      "验证集最优结果： 64.26425170898438 64.02303314208984\n",
      "------------train------------\n",
      " (0.44926320049758417, 0.001360640903556476)\n",
      "------------test------------\n",
      " (0.4735454141683322, 0.011159227181878784)\n",
      "------------oot------------\n",
      " (0.4538062303780165, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 460 0.8\n",
      "验证集最优结果： 102.02040100097656 102.0076675415039\n",
      "------------train------------\n",
      " (0.4952195508883353, 0.01190980407285358)\n",
      "------------test------------\n",
      " (0.4846735509660227, 0.02432822562735948)\n",
      "------------oot------------\n",
      " (0.47188915534239273, 0.017043756299308432)\n",
      "隐藏层vs神经元数vs norm 2 490 0.01\n",
      "验证集最优结果： 1.9407826662063599 1.9226027727127075\n",
      "------------train------------\n",
      " (0.5174932099931034, 0.03184091925830723)\n",
      "------------test------------\n",
      " (0.49724294914501443, 0.018687541638907387)\n",
      "------------oot------------\n",
      " (0.5107600875821082, 0.0405727591839572)\n",
      "隐藏层vs神经元数vs norm 2 490 0.05\n",
      "验证集最优结果： 7.410492897033691 7.3639421463012695\n",
      "------------train------------\n",
      " (0.47327441103077483, 0.004126320861919663)\n",
      "------------test------------\n",
      " (0.4676149233844104, 0.004585831667777038)\n",
      "------------oot------------\n",
      " (0.47294685990338164, 0.0048100649914850635)\n",
      "隐藏层vs神经元数vs norm 2 490 0.1\n",
      "验证集最优结果： 14.270340919494629 14.191319465637207\n",
      "------------train------------\n",
      " (0.5154326214062708, 0.045110145992762196)\n",
      "------------test------------\n",
      " (0.5127859204974461, 0.046035976015989355)\n",
      "------------oot------------\n",
      " (0.5208227620801908, 0.042748409967678036)\n",
      "隐藏层vs神经元数vs norm 2 490 0.2\n",
      "验证集最优结果： 27.914609909057617 27.8831787109375\n",
      "------------train------------\n",
      " (0.5439639833534005, 0.0707721420551336)\n",
      "------------test------------\n",
      " (0.5199600266489007, 0.05591827670441929)\n",
      "------------oot------------\n",
      " (0.5437412388929437, 0.09239912417891771)\n",
      "隐藏层vs神经元数vs norm 2 490 0.3\n",
      "验证集最优结果： 41.790523529052734 41.601661682128906\n",
      "------------train------------\n",
      " (0.5364516943376791, 0.07217609822820237)\n",
      "------------test------------\n",
      " (0.530379746835443, 0.06425716189207198)\n",
      "------------oot------------\n",
      " (0.5402402715508753, 0.06057067389566606)\n",
      "隐藏层vs神经元数vs norm 2 490 0.4\n",
      "验证集最优结果： 55.27372360229492 55.230472564697266\n",
      "------------train------------\n",
      " (0.4753969269169883, 0.016086343575364093)\n",
      "------------test------------\n",
      " (0.4459915611814347, 0.0018543193426604483)\n",
      "------------oot------------\n",
      " (0.5082299377888992, 0.044590414624821884)\n",
      "隐藏层vs神经元数vs norm 2 490 0.5\n",
      "验证集最优结果： 69.10013580322266 68.96426391601562\n",
      "------------train------------\n",
      " (0.5031002227352375, 0.01553664573320912)\n",
      "------------test------------\n",
      " (0.5096846546746614, 0.04294914501443482)\n",
      "------------oot------------\n",
      " (0.47259236089389367, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 2 490 0.8\n",
      "验证集最优结果： 110.08892059326172 109.98821258544922\n",
      "------------train------------\n",
      " (0.5033431266450497, 0.01785333585103338)\n",
      "------------test------------\n",
      " (0.497407284032867, 0.029791250277592718)\n",
      "------------oot------------\n",
      " (0.5057843580208297, 0.037521287317971774)\n",
      "隐藏层vs神经元数vs norm 2 520 0.01\n",
      "验证集最优结果： 2.0437228679656982 2.025134325027466\n",
      "------------train------------\n",
      " (0.566439735262487, 0.10099902608323708)\n",
      "------------test------------\n",
      " (0.5254819009549189, 0.06695536309127248)\n",
      "------------oot------------\n",
      " (0.5513247373116, 0.07878219163799405)\n",
      "隐藏层vs神经元数vs norm 2 520 0.05\n",
      "验证集最优结果： 7.92340612411499 7.8733038902282715\n",
      "------------train------------\n",
      " (0.4651099564884582, 0.0016187728378066499)\n",
      "------------test------------\n",
      " (0.4676993115700644, 0.010648456584499227)\n",
      "------------oot------------\n",
      " (0.43179137849140975, 0.007659958989330362)\n",
      "隐藏层vs神经元数vs norm 2 520 0.1\n",
      "验证集最优结果： 15.306169509887695 15.238333702087402\n",
      "------------train------------\n",
      " (0.4940936922815573, 0.024310424293368937)\n",
      "------------test------------\n",
      " (0.5105829447035309, 0.046602265156562295)\n",
      "------------oot------------\n",
      " (0.5083446286449101, 0.060563722934695696)\n",
      "隐藏层vs神经元数vs norm 2 520 0.2\n",
      "验证集最优结果： 30.004701614379883 29.94560432434082\n",
      "------------train------------\n",
      " (0.5400138338142005, 0.07379094561970945)\n",
      "------------test------------\n",
      " (0.5302809238285587, 0.053653120142127475)\n",
      "------------oot------------\n",
      " (0.5580092447780906, 0.09286483856393146)\n",
      "隐藏层vs神经元数vs norm 2 520 0.3\n",
      "验证集最优结果： 44.89178466796875 44.669212341308594\n",
      "------------train------------\n",
      " (0.5587747599217348, 0.09124889427622546)\n",
      "------------test------------\n",
      " (0.5408094603597602, 0.0713413280035532)\n",
      "------------oot------------\n",
      " (0.5541039632062466, 0.09495012685503768)\n",
      "隐藏层vs神经元数vs norm 2 520 0.4\n",
      "验证集最优结果： 59.497276306152344 59.45014190673828\n",
      "------------train------------\n",
      " (0.49956948682911245, 0.011849027335319118)\n",
      "------------test------------\n",
      " (0.48702309571396846, 0.016422385076615642)\n",
      "------------oot------------\n",
      " (0.5126843452774013, 0.04716922114482325)\n",
      "隐藏层vs神经元数vs norm 2 520 0.5\n",
      "验证集最优结果： 74.21424865722656 74.199462890625\n",
      "------------train------------\n",
      " (0.5280006145353862, 0.04283081529489238)\n",
      "------------test------------\n",
      " (0.5535676215856096, 0.10981567843659784)\n",
      "------------oot------------\n",
      " (0.5369443575574323, 0.07155319222882561)\n",
      "隐藏层vs神经元数vs norm 2 520 0.8\n",
      "验证集最优结果： 118.79529571533203 118.41181945800781\n",
      "------------train------------\n",
      " (0.46504078741745564, 0.0015163051533665104)\n",
      "------------test------------\n",
      " (0.47522429491450147, 0.013557628247834796)\n",
      "------------oot------------\n",
      " (0.47738273149596266, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 2 550 0.01\n",
      "验证集最优结果： 2.1486763954162598 2.1298959255218506\n",
      "------------train------------\n",
      " (0.5851124065083899, 0.13344446407167593)\n",
      "------------test------------\n",
      " (0.5577892516100378, 0.1077059737952476)\n",
      "------------oot------------\n",
      " (0.5691041369802708, 0.1390400722899941)\n",
      "隐藏层vs神经元数vs norm 2 550 0.05\n",
      "验证集最优结果： 8.450772285461426 8.382453918457031\n",
      "------------train------------\n",
      " (0.5052757998266035, 0.02219501481855979)\n",
      "------------test------------\n",
      " (0.49545636242505, 0.03155673995114372)\n",
      "------------oot------------\n",
      " (0.461825322350815, 0.00859138775935775)\n",
      "隐藏层vs神经元数vs norm 2 550 0.1\n",
      "验证集最优结果： 16.363283157348633 16.273103713989258\n",
      "------------train------------\n",
      " (0.46789032303039035, 0.0016247286873646294)\n",
      "------------test------------\n",
      " (0.5122196313568731, 0.03276704419276044)\n",
      "------------oot------------\n",
      " (0.4494143815382477, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 2 550 0.2\n",
      "验证集最优结果： 32.20296096801758 32.06510925292969\n",
      "------------train------------\n",
      " (0.4921878881031228, 0.011487209474673743)\n",
      "------------test------------\n",
      " (0.501360204308239, 0.029091716633355545)\n",
      "------------oot------------\n",
      " (0.4918407303142993, 0.02190942897855619)\n",
      "隐藏层vs神经元数vs norm 2 550 0.3\n",
      "验证集最优结果： 47.85002899169922 47.81038284301758\n",
      "------------train------------\n",
      " (0.5245774223218473, 0.04012685959558426)\n",
      "------------test------------\n",
      " (0.5174883411059293, 0.04485898290028867)\n",
      "------------oot------------\n",
      " (0.5134199886467637, 0.034942480797970354)\n",
      "隐藏层vs神经元数vs norm 2 550 0.4\n",
      "验证集最优结果： 63.69364547729492 63.647735595703125\n",
      "------------train------------\n",
      " (0.5260117668636836, 0.05431261036087709)\n",
      "------------test------------\n",
      " (0.5200599600266489, 0.050277592715967157)\n",
      "------------oot------------\n",
      " (0.5174805083469456, 0.05696312515205226)\n",
      "隐藏层vs神经元数vs norm 2 550 0.5\n",
      "验证集最优结果： 78.8177490234375 78.37755584716797\n",
      "------------train------------\n",
      " (0.5028326155857815, 0.01659380902974472)\n",
      "------------test------------\n",
      " (0.48266600044414837, 0.031445702864756786)\n",
      "------------oot------------\n",
      " (0.49117575504813543, 0.012852326834184802)\n",
      "隐藏层vs神经元数vs norm 2 550 0.8\n",
      "验证集最优结果： 126.74693298339844 126.7343978881836\n",
      "------------train------------\n",
      " (0.4764353428234382, 0.004897738739891189)\n",
      "------------test------------\n",
      " (0.5052742616033755, 0.024894514767932474)\n",
      "------------oot------------\n",
      " (0.45176959881370266, 0.009071004066312227)\n",
      "隐藏层vs神经元数vs norm 2 580 0.01\n",
      "验证集最优结果： 2.2554640769958496 2.2363264560699463\n",
      "------------train------------\n",
      " (0.5445922578016553, 0.06785688905673559)\n",
      "------------test------------\n",
      " (0.5391550077725961, 0.0796024872307351)\n",
      "------------oot------------\n",
      " (0.5309120819286599, 0.06654850033017062)\n",
      "隐藏层vs神经元数vs norm 2 580 0.05\n",
      "验证集最优结果： 8.99038314819336 8.920475006103516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " (0.5379455296949861, 0.06532781875808352)\n",
      "------------test------------\n",
      " (0.5089129469242727, 0.04701310237619363)\n",
      "------------oot------------\n",
      " (0.5153732086794333, 0.050088624752372024)\n",
      "隐藏层vs神经元数vs norm 2 580 0.1\n",
      "验证集最优结果： 17.423095703125 17.338224411010742\n",
      "------------train------------\n",
      " (0.4924356649807552, 0.01191169911589474)\n",
      "------------test------------\n",
      " (0.5067710415278702, 0.028736397956917625)\n",
      "------------oot------------\n",
      " (0.4720745143016022, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 2 580 0.2\n",
      "验证集最优结果： 34.339473724365234 34.17087173461914\n",
      "------------train------------\n",
      " (0.5185932147983912, 0.04283717722510205)\n",
      "------------test------------\n",
      " (0.509442593826338, 0.05022207417277369)\n",
      "------------oot------------\n",
      " (0.5405797101449276, 0.07170611337017341)\n",
      "隐藏层vs神经元数vs norm 2 580 0.3\n",
      "验证集最优结果： 51.136531829833984 51.04372787475586\n",
      "------------train------------\n",
      " (0.5119278746618533, 0.026774657047969663)\n",
      "------------test------------\n",
      " (0.5274095047745947, 0.05884965578503215)\n",
      "------------oot------------\n",
      " (0.5129253119243735, 0.04902512772390777)\n",
      "隐藏层vs神经元数vs norm 2 580 0.4\n",
      "验证集最优结果： 68.00724792480469 68.01912689208984\n",
      "------------train------------\n",
      " (0.5149730734687883, 0.03266147289513166)\n",
      "------------test------------\n",
      " (0.5079380413057961, 0.0613590939373751)\n",
      "------------oot------------\n",
      " (0.5151588873828473, 0.05667118479129743)\n",
      "隐藏层vs神经元数vs norm 2 580 0.5\n",
      "验证集最优结果： 84.86802673339844 84.74256896972656\n",
      "------------train------------\n",
      " (0.4853768326927411, 0.004696728817310425)\n",
      "------------test------------\n",
      " (0.4658705307572729, 0.02963579835665113)\n",
      "------------oot------------\n",
      " (0.4655406109894693, 0.005227122649706373)\n",
      "隐藏层vs神经元数vs norm 2 580 0.8\n",
      "验证集最优结果： 135.447265625 135.45181274414062\n",
      "------------train------------\n",
      " (0.5114524218988467, 0.02594909508310783)\n",
      "------------test------------\n",
      " (0.5025838330002221, 0.03778592049744611)\n",
      "------------oot------------\n",
      " (0.5028186146734787, 0.03221075313662114)\n",
      "隐藏层vs神经元数vs norm 2 610 0.01\n",
      "验证集最优结果： 2.364821434020996 2.346261739730835\n",
      "------------train------------\n",
      " (0.5563733343079269, 0.08144055757580682)\n",
      "------------test------------\n",
      " (0.5645036642238508, 0.1096935376415723)\n",
      "------------oot------------\n",
      " (0.5803125615449669, 0.12850936641990762)\n",
      "隐藏层vs神经元数vs norm 2 610 0.05\n",
      "验证集最优结果： 9.528180122375488 9.463061332702637\n",
      "------------train------------\n",
      " (0.5447745203341502, 0.07829465076725561)\n",
      "------------test------------\n",
      " (0.5137630468576504, 0.06567843659782369)\n",
      "------------oot------------\n",
      " (0.5857899187896061, 0.14305077676988842)\n",
      "隐藏层vs神经元数vs norm 2 610 0.1\n",
      "验证集最优结果： 18.535001754760742 18.44456672668457\n",
      "------------train------------\n",
      " (0.45131898379670515, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.43447035309793475, 0.0043859649122807015)\n",
      "------------oot------------\n",
      " (0.4181443251196145, 0.004761408264692624)\n",
      "隐藏层vs神经元数vs norm 2 610 0.2\n",
      "验证集最优结果： 36.55472946166992 36.383628845214844\n",
      "------------train------------\n",
      " (0.5377818791923598, 0.06325477703126614)\n",
      "------------test------------\n",
      " (0.536580057739285, 0.09240506329113918)\n",
      "------------oot------------\n",
      " (0.5631981371424599, 0.11891008931984848)\n",
      "隐藏层vs神经元数vs norm 2 610 0.3\n",
      "验证集最优结果： 54.384246826171875 54.362545013427734\n",
      "------------train------------\n",
      " (0.495038574277904, 0.014390686134173158)\n",
      "------------test------------\n",
      " (0.4966144792360649, 0.03878525427492785)\n",
      "------------oot------------\n",
      " (0.5157068548060102, 0.037257150801098315)\n",
      "隐藏层vs神经元数vs norm 2 610 0.4\n",
      "验证集最优结果： 72.29971313476562 72.2811279296875\n",
      "------------train------------\n",
      " (0.51744116398958, 0.04018330480616755)\n",
      "------------test------------\n",
      " (0.5062558294470354, 0.04950033311125912)\n",
      "------------oot------------\n",
      " (0.5222048448197962, 0.04489625690751747)\n",
      "隐藏层vs神经元数vs norm 2 610 0.5\n",
      "验证集最优结果： 90.4028091430664 90.4241943359375\n",
      "------------train------------\n",
      " (0.5200147677996994, 0.03625664026465625)\n",
      "------------test------------\n",
      " (0.5523773040195425, 0.08935154341550078)\n",
      "------------oot------------\n",
      " (0.5514150998042147, 0.09136343099433503)\n",
      "隐藏层vs神经元数vs norm 2 610 0.8\n",
      "验证集最优结果： 144.31163024902344 144.23387145996094\n",
      "------------train------------\n",
      " (0.5232029069960251, 0.04167673408282291)\n",
      "------------test------------\n",
      " (0.5152365089940041, 0.04721296913168993)\n",
      "------------oot------------\n",
      " (0.5255864873318736, 0.06812636847044107)\n",
      "隐藏层vs神经元数vs norm 2 640 0.01\n",
      "验证集最优结果： 2.4759299755096436 2.4553768634796143\n",
      "------------train------------\n",
      " (0.5590849378595083, 0.09742226770325524)\n",
      "------------test------------\n",
      " (0.5518010215411948, 0.08375527426160337)\n",
      "------------oot------------\n",
      " (0.5552033735330576, 0.09581899697633195)\n",
      "隐藏层vs神经元数vs norm 2 640 0.05\n",
      "验证集最优结果： 10.095489501953125 10.019654273986816\n",
      "------------train------------\n",
      " (0.4865489168137017, 0.002046511124241035)\n",
      "------------test------------\n",
      " (0.485118809682434, 0.011925383077948049)\n",
      "------------oot------------\n",
      " (0.48204335082658517, 0.0160428179195774)\n",
      "隐藏层vs神经元数vs norm 2 640 0.1\n",
      "验证集最优结果： 19.64173126220703 19.508914947509766\n",
      "------------train------------\n",
      " (0.5157404305402429, 0.028452717660921334)\n",
      "------------test------------\n",
      " (0.5285021097046413, 0.06439040639573618)\n",
      "------------oot------------\n",
      " (0.5539765289217901, 0.10370833767768395)\n",
      "隐藏层vs神经元数vs norm 2 640 0.2\n",
      "验证集最优结果： 38.839176177978516 38.658851623535156\n",
      "------------train------------\n",
      " (0.5233798904800482, 0.0369304634260077)\n",
      "------------test------------\n",
      " (0.5295647346213636, 0.05635132134132803)\n",
      "------------oot------------\n",
      " (0.5234722367033908, 0.040023633267299186)\n",
      "隐藏层vs神经元数vs norm 2 640 0.3\n",
      "验证集最优结果： 57.89500045776367 57.66569519042969\n",
      "------------train------------\n",
      " (0.5163027845627086, 0.03820068370445717)\n",
      "------------test------------\n",
      " (0.5173684210526316, 0.047001998667554945)\n",
      "------------oot------------\n",
      " (0.5482338766667826, 0.08024189344176835)\n",
      "隐藏层vs神经元数vs norm 2 640 0.4\n",
      "验证集最优结果： 76.83899688720703 76.77781677246094\n",
      "------------train------------\n",
      " (0.5078986747557932, 0.02455867493176145)\n",
      "------------test------------\n",
      " (0.5015345325338663, 0.031068176771041456)\n",
      "------------oot------------\n",
      " (0.5007727151612044, 0.024488235498557692)\n",
      "隐藏层vs神经元数vs norm 2 640 0.5\n",
      "验证集最优结果： 95.92607879638672 95.77813720703125\n",
      "------------train------------\n",
      " (0.5027426010413262, 0.025395201074218665)\n",
      "------------test------------\n",
      " (0.48799800133244503, 0.03119031756606705)\n",
      "------------oot------------\n",
      " (0.5512714466108273, 0.08054078476349358)\n",
      "隐藏层vs神经元数vs norm 2 640 0.8\n",
      "验证集最优结果： 153.1996612548828 153.1030731201172\n",
      "------------train------------\n",
      " (0.5252760840830597, 0.042563343505653606)\n",
      "------------test------------\n",
      " (0.5455185431934266, 0.09480346435709525)\n",
      "------------oot------------\n",
      " (0.5269847889804099, 0.057484447224828816)\n",
      "隐藏层vs神经元数vs norm 2 670 0.01\n",
      "验证集最优结果： 2.5899503231048584 2.5664966106414795\n",
      "------------train------------\n",
      " (0.5614802045834323, 0.09465401590076467)\n",
      "------------test------------\n",
      " (0.5371718854097268, 0.08010215411947585)\n",
      "------------oot------------\n",
      " (0.5479604722019487, 0.09247558474959161)\n",
      "隐藏层vs神经元数vs norm 2 670 0.05\n",
      "验证集最优结果： 10.66820240020752 10.596212387084961\n",
      "------------train------------\n",
      " (0.4959932698899995, 0.006327007273581264)\n",
      "------------test------------\n",
      " (0.4735476349100599, 0.014290473017988026)\n",
      "------------oot------------\n",
      " (0.4703854307858062, 0.010419490494560923)\n",
      "隐藏层vs神经元数vs norm 2 670 0.1\n",
      "验证集最优结果： 20.769052505493164 20.63880157470703\n",
      "------------train------------\n",
      " (0.4954633346395594, 0.025946793959415015)\n",
      "------------test------------\n",
      " (0.5218798578725294, 0.051376859871197)\n",
      "------------oot------------\n",
      " (0.4952768220206444, 0.021819066485941674)\n",
      "隐藏层vs神经元数vs norm 2 670 0.2\n",
      "验证集最优结果： 41.08957290649414 40.89223861694336\n",
      "------------train------------\n",
      " (0.517247192798295, 0.0460265346633828)\n",
      "------------test------------\n",
      " (0.5132422829224962, 0.045081057073062314)\n",
      "------------oot------------\n",
      " (0.5054993686210453, 0.02801932367149762)\n",
      "隐藏层vs神经元数vs norm 2 670 0.3\n",
      "验证集最优结果： 61.399757385253906 61.12348937988281\n",
      "------------train------------\n",
      " (0.4900142737349065, 0.0098969976427018)\n",
      "------------test------------\n",
      " (0.4787452809238285, 0.004463690872751447)\n",
      "------------oot------------\n",
      " (0.5000463397398024, 0.04819101240746532)\n",
      "隐藏层vs神经元数vs norm 2 670 0.4\n",
      "验证集最优结果： 81.46247100830078 81.34346771240234\n",
      "------------train------------\n",
      " (0.5177732702825442, 0.050364694265261356)\n",
      "------------test------------\n",
      " (0.4954530313124584, 0.019920053297801443)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.5546276022660133, 0.09559656622528068)\n",
      "隐藏层vs神经元数vs norm 2 670 0.5\n",
      "验证集最优结果： 101.76231384277344 101.6220474243164\n",
      "------------train------------\n",
      " (0.5369995648169016, 0.06883933351336241)\n",
      "------------test------------\n",
      " (0.5052254052853653, 0.03236731068176768)\n",
      "------------oot------------\n",
      " (0.5319686279961537, 0.08802001876759458)\n",
      "隐藏层vs神经元数vs norm 2 670 0.8\n",
      "验证集最优结果： 162.42054748535156 162.3579559326172\n",
      "------------train------------\n",
      " (0.544329591300128, 0.06601950946810886)\n",
      "------------test------------\n",
      " (0.5478147901399066, 0.0958916278036864)\n",
      "------------oot------------\n",
      " (0.5637414705916426, 0.1239078302575331)\n",
      "隐藏层vs神经元数vs norm 2 700 0.01\n",
      "验证集最优结果： 2.7065019607543945 2.684418201446533\n",
      "------------train------------\n",
      " (0.5443384573943564, 0.07421570598136495)\n",
      "------------test------------\n",
      " (0.5046069287141906, 0.03003553186764374)\n",
      "------------oot------------\n",
      " (0.5485281340145275, 0.08526743822333438)\n",
      "隐藏层vs神经元数vs norm 2 700 0.05\n",
      "验证集最优结果： 11.248069763183594 11.164306640625\n",
      "------------train------------\n",
      " (0.4703313415077368, 0.005545031298666125)\n",
      "------------test------------\n",
      " (0.46852320675105485, 0.0039751276926493495)\n",
      "------------oot------------\n",
      " (0.4694308321458775, 0.021068362701143428)\n",
      "隐藏层vs神经元数vs norm 2 700 0.1\n",
      "验证集最优结果： 21.989152908325195 21.88181495666504\n",
      "------------train------------\n",
      " (0.4814572068825256, 0.004224727739843073)\n",
      "------------test------------\n",
      " (0.4990561847657118, 0.021374639129469245)\n",
      "------------oot------------\n",
      " (0.4789501731947775, 0.013318041219198551)\n",
      "隐藏层vs神经元数vs norm 2 700 0.2\n",
      "验证集最优结果： 43.45562744140625 43.28031539916992\n",
      "------------train------------\n",
      " (0.5281143171178562, 0.05035386544788334)\n",
      "------------test------------\n",
      " (0.5366544525871642, 0.07682656007106375)\n",
      "------------oot------------\n",
      " (0.5518159385535051, 0.09877315538873249)\n",
      "隐藏层vs神经元数vs norm 2 700 0.3\n",
      "验证集最优结果： 64.72007751464844 64.69506072998047\n",
      "------------train------------\n",
      " (0.5239538854811954, 0.04359600660287144)\n",
      "------------test------------\n",
      " (0.5128281145902731, 0.03393293359982241)\n",
      "------------oot------------\n",
      " (0.5201126055677198, 0.052611823584610584)\n",
      "隐藏层vs神经元数vs norm 2 700 0.4\n",
      "验证集最优结果： 86.19293212890625 86.15459442138672\n",
      "------------train------------\n",
      " (0.4451048669442905, 0.002073989248337904)\n",
      "------------test------------\n",
      " (0.47556517876970905, 0.005640683988452078)\n",
      "------------oot------------\n",
      " (0.46861409423186084, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 700 0.5\n",
      "验证集最优结果： 107.41797637939453 107.38375091552734\n",
      "------------train------------\n",
      " (0.48297635460045385, 0.006276111831904241)\n",
      "------------test------------\n",
      " (0.48048856318010214, 0.006773262269598068)\n",
      "------------oot------------\n",
      " (0.4674428573083562, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 700 0.8\n",
      "验证集最优结果： 171.60305786132812 171.5865478515625\n",
      "------------train------------\n",
      " (0.5120748081776523, 0.02382502255439617)\n",
      "------------test------------\n",
      " (0.5137519431490117, 0.043948478791916434)\n",
      "------------oot------------\n",
      " (0.5002676119973586, 0.023563757689500586)\n",
      "隐藏层vs神经元数vs norm 2 730 0.01\n",
      "验证集最优结果： 2.8230910301208496 2.799595355987549\n",
      "------------train------------\n",
      " (0.590883963130584, 0.12814484084684058)\n",
      "------------test------------\n",
      " (0.5694492560515212, 0.12516100377526096)\n",
      "------------oot------------\n",
      " (0.5990523523210417, 0.15039099155458246)\n",
      "隐藏层vs神经元数vs norm 2 730 0.05\n",
      "验证集最优结果： 11.825221061706543 11.733993530273438\n",
      "------------train------------\n",
      " (0.541131029367076, 0.06318966876678034)\n",
      "------------test------------\n",
      " (0.5230934932267377, 0.06426826560071064)\n",
      "------------oot------------\n",
      " (0.5537031244569561, 0.09137038195530534)\n",
      "隐藏层vs神经元数vs norm 2 730 0.1\n",
      "验证集最优结果： 23.139705657958984 22.988981246948242\n",
      "------------train------------\n",
      " (0.4852335539028073, 0.002710452989735046)\n",
      "------------test------------\n",
      " (0.4975805018876305, 0.02420608483233397)\n",
      "------------oot------------\n",
      " (0.4597724718775704, 0.031168108991068005)\n",
      "隐藏层vs神经元数vs norm 2 730 0.2\n",
      "验证集最优结果： 45.82125473022461 45.60487747192383\n",
      "------------train------------\n",
      " (0.496811387042914, 0.013998412224651938)\n",
      "------------test------------\n",
      " (0.5155451920941594, 0.05665112147457252)\n",
      "------------oot------------\n",
      " (0.5192599543553563, 0.05063775066902998)\n",
      "隐藏层vs神经元数vs norm 2 730 0.3\n",
      "验证集最优结果： 68.27814483642578 68.20708465576172\n",
      "------------train------------\n",
      " (0.46787624556779883, 0.002243460240304973)\n",
      "------------test------------\n",
      " (0.5075860537419499, 0.03828558738618698)\n",
      "------------oot------------\n",
      " (0.4868198195067135, 0.02782469676432764)\n",
      "隐藏层vs神经元数vs norm 2 730 0.4\n",
      "验证集最优结果： 91.15884399414062 90.7892837524414\n",
      "------------train------------\n",
      " (0.5148640408138127, 0.030921823383342206)\n",
      "------------test------------\n",
      " (0.5094636908727516, 0.060659560293137904)\n",
      "------------oot------------\n",
      " (0.5429604142772738, 0.07424321412435264)\n",
      "隐藏层vs神经元数vs norm 2 730 0.5\n",
      "验证集最优结果： 113.4725570678711 113.3912124633789\n",
      "------------train------------\n",
      " (0.4869518841803837, 0.003248645213425827)\n",
      "------------test------------\n",
      " (0.5041650011103708, 0.03041305796135907)\n",
      "------------oot------------\n",
      " (0.46163764640461546, 0.011955652869009126)\n",
      "隐藏层vs神经元数vs norm 2 730 0.8\n",
      "验证集最优结果： 181.86477661132812 181.1960906982422\n",
      "------------train------------\n",
      " (0.5578469333127586, 0.09027660183589065)\n",
      "------------test------------\n",
      " (0.5377970242060849, 0.06409060626249163)\n",
      "------------oot------------\n",
      " (0.5620257417254602, 0.10785806137698534)\n",
      "隐藏层vs神经元数vs norm 2 760 0.01\n",
      "验证集最优结果： 2.9417245388031006 2.917842149734497\n",
      "------------train------------\n",
      " (0.5684585652223055, 0.09979621519296614)\n",
      "------------test------------\n",
      " (0.5611703308905174, 0.11734399289362651)\n",
      "------------oot------------\n",
      " (0.5694991832620859, 0.11975810655823171)\n",
      "隐藏层vs神经元数vs norm 2 760 0.05\n",
      "验证集最优结果： 12.435371398925781 12.345852851867676\n",
      "------------train------------\n",
      " (0.5385652764495557, 0.0688509744920438)\n",
      "------------test------------\n",
      " (0.5105041083721963, 0.042915833888518745)\n",
      "------------oot------------\n",
      " (0.538643867514684, 0.07906023007680807)\n",
      "隐藏层vs神经元数vs norm 2 760 0.1\n",
      "验证集最优结果： 24.32489776611328 24.174541473388672\n",
      "------------train------------\n",
      " (0.5144312265192323, 0.02898874412113661)\n",
      "------------test------------\n",
      " (0.49408949589162776, 0.013069065067732644)\n",
      "------------oot------------\n",
      " (0.5243665936815765, 0.05465540610989472)\n",
      "隐藏层vs神经元数vs norm 2 760 0.2\n",
      "验证集最优结果： 48.200008392333984 47.944705963134766\n",
      "------------train------------\n",
      " (0.48319753319540126, 0.010071341602489015)\n",
      "------------test------------\n",
      " (0.46057406173662, 0.0043859649122807015)\n",
      "------------oot------------\n",
      " (0.4877338708743151, 0.01926806380982171)\n",
      "隐藏层vs神经元数vs norm 2 760 0.3\n",
      "验证集最优结果： 72.23017120361328 71.94218444824219\n",
      "------------train------------\n",
      " (0.47381138501251063, 0.007400278435966801)\n",
      "------------test------------\n",
      " (0.4772418387741505, 0.02647124139462581)\n",
      "------------oot------------\n",
      " (0.488223913622725, 0.02513467486880061)\n",
      "隐藏层vs神经元数vs norm 2 760 0.4\n",
      "验证集最优结果： 94.94284057617188 94.36537170410156\n",
      "------------train------------\n",
      " (0.5579749840782544, 0.08212845819974973)\n",
      "------------test------------\n",
      " (0.536596713302243, 0.06114812347324006)\n",
      "------------oot------------\n",
      " (0.5638109802013462, 0.09427588364091333)\n",
      "隐藏层vs神经元数vs norm 2 760 0.5\n",
      "验证集最优结果： 119.47254943847656 119.40594482421875\n",
      "------------train------------\n",
      " (0.5053435476153252, 0.028868138167588153)\n",
      "------------test------------\n",
      " (0.49737064179435925, 0.031123695314234957)\n",
      "------------oot------------\n",
      " (0.488086052896813, 0.048615021026656935)\n",
      "隐藏层vs神经元数vs norm 2 760 0.8\n",
      "验证集最优结果： 190.88970947265625 190.8629913330078\n",
      "------------train------------\n",
      " (0.5184579222612737, 0.042755555014114655)\n",
      "------------test------------\n",
      " (0.4866699977792583, 0.029558072396180246)\n",
      "------------oot------------\n",
      " (0.5232845607571913, 0.05392555520800757)\n",
      "隐藏层vs神经元数vs norm 2 790 0.01\n",
      "验证集最优结果： 3.066422462463379 3.0435049533843994\n",
      "------------train------------\n",
      " (0.5472935062966189, 0.06975044313551115)\n",
      "------------test------------\n",
      " (0.5261303575394182, 0.05330890517432829)\n",
      "------------oot------------\n",
      " (0.5344651814780059, 0.08872206582560038)\n",
      "隐藏层vs神经元数vs norm 2 790 0.05\n",
      "验证集最优结果： 13.05398178100586 12.960418701171875\n",
      "------------train------------\n",
      " (0.5156433095843832, 0.04409237251943943)\n",
      "------------test------------\n",
      " (0.5288862980235398, 0.07225183211192537)\n",
      "------------oot------------\n",
      " (0.4804006070505914, 0.016758766899523825)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 2 790 0.1\n",
      "验证集最优结果： 25.59402847290039 25.46230125427246\n",
      "------------train------------\n",
      " (0.47087636942239763, 0.001353737532477992)\n",
      "------------test------------\n",
      " (0.48764490339773486, 0.02019764601376861)\n",
      "------------oot------------\n",
      " (0.5126889792513815, 0.0466270461891356)\n",
      "隐藏层vs神经元数vs norm 2 790 0.2\n",
      "验证集最优结果： 50.46372985839844 50.39793395996094\n",
      "------------train------------\n",
      " (0.48405294208816146, 0.001926175891127091)\n",
      "------------test------------\n",
      " (0.47333000222074173, 0.0035864978902953037)\n",
      "------------oot------------\n",
      " (0.46883073251543694, 0.013888020018767655)\n",
      "隐藏层vs神经元数vs norm 2 790 0.3\n",
      "验证集最优结果： 75.54784393310547 75.43434143066406\n",
      "------------train------------\n",
      " (0.4902101399692327, 0.0076998305966882175)\n",
      "------------test------------\n",
      " (0.4830990450810571, 0.01370197646013771)\n",
      "------------oot------------\n",
      " (0.4836779851481134, 0.009995481875369278)\n",
      "隐藏层vs神经元数vs norm 2 790 0.4\n",
      "验证集最优结果： 100.69023132324219 100.6042251586914\n",
      "------------train------------\n",
      " (0.5058809953578214, 0.021586570642128544)\n",
      "------------test------------\n",
      " (0.47960026648900733, 0.021041527870308774)\n",
      "------------oot------------\n",
      " (0.49427935912139853, 0.03745872866923852)\n",
      "隐藏层vs神经元数vs norm 2 790 0.5\n",
      "验证集最优结果： 125.70711517333984 125.66443634033203\n",
      "------------train------------\n",
      " (0.47615751597758166, 0.015061666730962764)\n",
      "------------test------------\n",
      " (0.5091716633355541, 0.04715745058849663)\n",
      "------------oot------------\n",
      " (0.45381433983248176, 0.007659958989330362)\n",
      "隐藏层vs神经元数vs norm 2 790 0.8\n",
      "验证集最优结果： 200.89190673828125 200.9461669921875\n",
      "------------train------------\n",
      " (0.5382871788832647, 0.062232130590123225)\n",
      "------------test------------\n",
      " (0.5413801909837885, 0.08164556962025316)\n",
      "------------oot------------\n",
      " (0.5510038346134687, 0.09025822820004864)\n",
      "隐藏层vs神经元数vs norm 2 820 0.01\n",
      "验证集最优结果： 3.1921088695526123 3.16903018951416\n",
      "------------train------------\n",
      " (0.5769130290300291, 0.1135057687140576)\n",
      "------------test------------\n",
      " (0.555861647790362, 0.10393071285809463)\n",
      "------------oot------------\n",
      " (0.5927304533185046, 0.13005943071629655)\n",
      "隐藏层vs神经元数vs norm 2 820 0.05\n",
      "验证集最优结果： 13.687318801879883 13.591233253479004\n",
      "------------train------------\n",
      " (0.495346924852745, 0.007689949300830667)\n",
      "------------test------------\n",
      " (0.5039673550966023, 0.03231179213857427)\n",
      "------------oot------------\n",
      " (0.5008306398359573, 0.048058944149028615)\n",
      "隐藏层vs神经元数vs norm 2 820 0.1\n",
      "验证集最优结果： 26.887714385986328 26.735519409179688\n",
      "------------train------------\n",
      " (0.49090717740783824, 0.018259822583363228)\n",
      "------------test------------\n",
      " (0.4930801687763713, 0.02820341994226072)\n",
      "------------oot------------\n",
      " (0.4620384851539059, 0.005449553400757701)\n",
      "隐藏层vs神经元数vs norm 2 820 0.2\n",
      "验证集最优结果： 53.057769775390625 53.020843505859375\n",
      "------------train------------\n",
      " (0.471776176466408, 0.0017813404586951682)\n",
      "------------test------------\n",
      " (0.48618476571174774, 0.011558960692871323)\n",
      "------------oot------------\n",
      " (0.4834034221897844, 0.017613735098877426)\n",
      "隐藏层vs神经元数vs norm 2 820 0.3\n",
      "验证集最优结果： 79.64810943603516 79.3189926147461\n",
      "------------train------------\n",
      " (0.5444051223013402, 0.07403824873658149)\n",
      "------------test------------\n",
      " (0.5485343104596936, 0.08635354208305573)\n",
      "------------oot------------\n",
      " (0.5422409898168422, 0.10101831578215686)\n",
      "隐藏层vs神经元数vs norm 2 820 0.4\n",
      "验证集最优结果： 105.68944549560547 105.69821166992188\n",
      "------------train------------\n",
      " (0.497048199742951, 0.01620870921173645)\n",
      "------------test------------\n",
      " (0.4911214745725072, 0.020719520319786806)\n",
      "------------oot------------\n",
      " (0.4785423834845167, 0.013665589267716265)\n",
      "隐藏层vs神经元数vs norm 2 820 0.5\n",
      "验证集最优结果： 131.93447875976562 131.8731231689453\n",
      "------------train------------\n",
      " (0.5338112902603586, 0.06482806883608483)\n",
      "------------test------------\n",
      " (0.519729069509216, 0.06058183433266712)\n",
      "------------oot------------\n",
      " (0.5456249493159097, 0.09255204532026556)\n",
      "隐藏层vs神经元数vs norm 2 820 0.8\n",
      "验证集最优结果： 210.82749938964844 210.80323791503906\n",
      "------------train------------\n",
      " (0.49875333239934777, 0.021125939822908224)\n",
      "------------test------------\n",
      " (0.4761103708638685, 0.018365534088385517)\n",
      "------------oot------------\n",
      " (0.4922647389334909, 0.03772286518611198)\n",
      "隐藏层vs神经元数vs norm 2 850 0.01\n",
      "验证集最优结果： 3.3178296089172363 3.2966580390930176\n",
      "------------train------------\n",
      " (0.5621153824027657, 0.10199717232506217)\n",
      "------------test------------\n",
      " (0.5205463024650233, 0.050810570730624116)\n",
      "------------oot------------\n",
      " (0.5331919971269361, 0.06049421332499218)\n",
      "隐藏层vs神经元数vs norm 2 850 0.05\n",
      "验证集最优结果： 14.333403587341309 14.235932350158691\n",
      "------------train------------\n",
      " (0.5343377061451509, 0.05843487041628004)\n",
      "------------test------------\n",
      " (0.519687985787253, 0.05602931379080611)\n",
      "------------oot------------\n",
      " (0.5252111354394745, 0.06910645396726095)\n",
      "隐藏层vs神经元数vs norm 2 850 0.1\n",
      "验证集最优结果： 28.161775588989258 28.007444381713867\n",
      "------------train------------\n",
      " (0.5511317129361729, 0.09119068938281838)\n",
      "------------test------------\n",
      " (0.5266899844548079, 0.056351321341327976)\n",
      "------------oot------------\n",
      " (0.5444050556656125, 0.1031383588781149)\n",
      "隐藏层vs神经元数vs norm 2 850 0.2\n",
      "验证集最优结果： 55.595149993896484 55.54063415527344\n",
      "------------train------------\n",
      " (0.4843407179099841, 0.006603277476939784)\n",
      "------------test------------\n",
      " (0.4528791916500111, 0.0061403508771929825)\n",
      "------------oot------------\n",
      " (0.4668334897299552, 0.008125673374344)\n",
      "隐藏层vs神经元数vs norm 2 850 0.3\n",
      "验证集最优结果： 83.19366455078125 83.15938568115234\n",
      "------------train------------\n",
      " (0.4913382996997034, 0.007088949936346789)\n",
      "------------test------------\n",
      " (0.5117410615145458, 0.04227181878747499)\n",
      "------------oot------------\n",
      " (0.4860413118780338, 0.025843672887776725)\n",
      "隐藏层vs神经元数vs norm 2 850 0.4\n",
      "验证集最优结果： 110.7963638305664 110.67839813232422\n",
      "------------train------------\n",
      " (0.48568294982399784, 0.010337324429338213)\n",
      "------------test------------\n",
      " (0.50163890739507, 0.028336664445924864)\n",
      "------------oot------------\n",
      " (0.4859057681391119, 0.01781531296701766)\n",
      "隐藏层vs神经元数vs norm 2 850 0.5\n",
      "验证集最优结果： 138.37489318847656 138.31809997558594\n",
      "------------train------------\n",
      " (0.519493969363922, 0.045162530396828826)\n",
      "------------test------------\n",
      " (0.5240239840106596, 0.056862091938707504)\n",
      "------------oot------------\n",
      " (0.5096595187618022, 0.030528620581795424)\n",
      "隐藏层vs神经元数vs norm 2 850 0.8\n",
      "验证集最优结果： 220.876220703125 220.67417907714844\n",
      "------------train------------\n",
      " (0.49783220612112444, 0.011253713099958707)\n",
      "------------test------------\n",
      " (0.484213857428381, 0.02031978680879415)\n",
      "------------oot------------\n",
      " (0.4791088868036006, 0.009988530914398885)\n",
      "隐藏层vs神经元数vs norm 2 880 0.01\n",
      "验证集最优结果： 3.448580026626587 3.423490524291992\n",
      "------------train------------\n",
      " (0.5676300930127732, 0.10823863194135652)\n",
      "------------test------------\n",
      " (0.5515189873417721, 0.10416389073950694)\n",
      "------------oot------------\n",
      " (0.5602856844958816, 0.09202377228651859)\n",
      "隐藏层vs神经元数vs norm 2 880 0.05\n",
      "验证集最优结果： 14.968332290649414 14.86243724822998\n",
      "------------train------------\n",
      " (0.5249939933903606, 0.0412154264625163)\n",
      "------------test------------\n",
      " (0.5087863646457917, 0.03449922274039524)\n",
      "------------oot------------\n",
      " (0.5169024200929111, 0.04086469954471206)\n",
      "隐藏层vs神经元数vs norm 2 880 0.1\n",
      "验证集最优结果： 29.4199275970459 29.235389709472656\n",
      "------------train------------\n",
      " (0.5126596319961774, 0.0315826519638398)\n",
      "------------test------------\n",
      " (0.5367221852098601, 0.08323339995558521)\n",
      "------------oot------------\n",
      " (0.5224492869472539, 0.06070274215410276)\n",
      "隐藏层vs神经元数vs norm 2 880 0.2\n",
      "验证集最优结果： 58.4194450378418 58.1318244934082\n",
      "------------train------------\n",
      " (0.5050460258578622, 0.014061760806313717)\n",
      "------------test------------\n",
      " (0.5029469242727072, 0.025438596491228038)\n",
      "------------oot------------\n",
      " (0.4858837567627057, 0.0439231223716679)\n",
      "隐藏层vs神经元数vs norm 2 880 0.3\n",
      "验证集最优结果： 87.13890075683594 87.11430358886719\n",
      "------------train------------\n",
      " (0.4551500840248549, 0.0)\n",
      "------------test------------\n",
      " (0.4827748167888075, 0.013113479902287367)\n",
      "------------oot------------\n",
      " (0.4776155886884695, 0.016362562124213664)\n",
      "隐藏层vs神经元数vs norm 2 880 0.4\n",
      "验证集最优结果： 115.92668151855469 115.84134674072266\n",
      "------------train------------\n",
      " (0.48537473460937414, 0.003784400953206757)\n",
      "------------test------------\n",
      " (0.49495780590717303, 0.01757717077503884)\n",
      "------------oot------------\n",
      " (0.47985727360140873, 0.018044694679039353)\n",
      "隐藏层vs神经元数vs norm 2 880 0.5\n",
      "验证集最优结果： 144.80157470703125 144.74765014648438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " (0.5023359112686704, 0.033204267366208295)\n",
      "------------test------------\n",
      " (0.4814279369309349, 0.007894736842105263)\n",
      "------------oot------------\n",
      " (0.47520360523175664, 0.030966531122927687)\n",
      "隐藏层vs神经元数vs norm 2 880 0.8\n",
      "验证集最优结果： 232.28187561035156 231.42645263671875\n",
      "------------train------------\n",
      " (0.5107723721675028, 0.02635192708957257)\n",
      "------------test------------\n",
      " (0.48855651787697085, 0.01946480124361538)\n",
      "------------oot------------\n",
      " (0.5176287955143132, 0.05019984012789769)\n",
      "隐藏层vs神经元数vs norm 2 910 0.01\n",
      "验证集最优结果： 3.5797321796417236 3.5568392276763916\n",
      "------------train------------\n",
      " (0.5493025226406884, 0.07904657677394639)\n",
      "------------test------------\n",
      " (0.5125538529868976, 0.04499222740395292)\n",
      "------------oot------------\n",
      " (0.5512575446888865, 0.08616411218851006)\n",
      "隐藏层vs神经元数vs norm 2 910 0.05\n",
      "验证集最优结果： 15.625767707824707 15.514500617980957\n",
      "------------train------------\n",
      " (0.47386708574189923, 0.008460419657281504)\n",
      "------------test------------\n",
      " (0.46611814345991565, 0.004263824117255122)\n",
      "------------oot------------\n",
      " (0.42374679966171985, 0.005727591839571833)\n",
      "隐藏层vs神经元数vs norm 2 910 0.1\n",
      "验证集最优结果： 30.7460880279541 30.56028175354004\n",
      "------------train------------\n",
      " (0.4736791380802807, 0.006796301146704042)\n",
      "------------test------------\n",
      " (0.49120586275816125, 0.014634687985787253)\n",
      "------------oot------------\n",
      " (0.48630313140791714, 0.025190282556563415)\n",
      "隐藏层vs神经元数vs norm 2 910 0.2\n",
      "验证集最优结果： 61.063621520996094 60.80617904663086\n",
      "------------train------------\n",
      " (0.4666825714921907, 0.0016010406493500717)\n",
      "------------test------------\n",
      " (0.4946602265156562, 0.02051965356429053)\n",
      "------------oot------------\n",
      " (0.49897820873735793, 0.029757063914086168)\n",
      "隐藏层vs神经元数vs norm 2 910 0.3\n",
      "验证集最优结果： 91.10772705078125 91.09019470214844\n",
      "------------train------------\n",
      " (0.5559901295329599, 0.09449713340899968)\n",
      "------------test------------\n",
      " (0.5341316899844548, 0.07581612258494336)\n",
      "------------oot------------\n",
      " (0.545395567603888, 0.08578876029611093)\n",
      "隐藏层vs神经元数vs norm 2 910 0.4\n",
      "验证集最优结果： 121.29440307617188 121.2417984008789\n",
      "------------train------------\n",
      " (0.47766982800453994, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.45509438152342885, 0.032778147901399074)\n",
      "------------oot------------\n",
      " (0.5018756009685006, 0.02411288360615854)\n",
      "隐藏层vs神经元数vs norm 2 910 0.5\n",
      "验证集最优结果： 151.5336456298828 151.4543914794922\n",
      "------------train------------\n",
      " (0.4638349309222971, 0.001728143893325318)\n",
      "------------test------------\n",
      " (0.4881401288030202, 0.009071729957805908)\n",
      "------------oot------------\n",
      " (0.4685399506481771, 0.015097487227609216)\n",
      "隐藏层vs神经元数vs norm 2 910 0.8\n",
      "验证集最优结果： 242.00108337402344 241.92013549804688\n",
      "------------train------------\n",
      " (0.5155057836036815, 0.029816471849474002)\n",
      "------------test------------\n",
      " (0.5002398401065956, 0.02289584721296911)\n",
      "------------oot------------\n",
      " (0.5228037859567418, 0.05523233587043408)\n",
      "隐藏层vs神经元数vs norm 2 940 0.01\n",
      "验证集最优结果： 3.711895227432251 3.685133695602417\n",
      "------------train------------\n",
      " (0.5967622512840609, 0.14741336776897263)\n",
      "------------test------------\n",
      " (0.5691516766600044, 0.114290473017988)\n",
      "------------oot------------\n",
      " (0.5946361751178767, 0.13856045598303968)\n",
      "隐藏层vs神经元数vs norm 2 940 0.05\n",
      "验证集最优结果： 16.28908348083496 16.179418563842773\n",
      "------------train------------\n",
      " (0.5306351981233659, 0.045767861288263795)\n",
      "------------test------------\n",
      " (0.5297712636020431, 0.06514545858316667)\n",
      "------------oot------------\n",
      " (0.5179612831473951, 0.050484829527682185)\n",
      "隐藏层vs神经元数vs norm 2 940 0.1\n",
      "验证集最优结果： 32.08503341674805 31.899349212646484\n",
      "------------train------------\n",
      " (0.5245342424125522, 0.03906807197644188)\n",
      "------------test------------\n",
      " (0.5462136353542083, 0.09204974461470133)\n",
      "------------oot------------\n",
      " (0.5241638573199412, 0.0750773294407952)\n",
      "隐藏层vs神经元数vs norm 2 940 0.2\n",
      "验证集最优结果： 63.69636535644531 63.415382385253906\n",
      "------------train------------\n",
      " (0.5112121575132704, 0.03636925996538837)\n",
      "------------test------------\n",
      " (0.5199400399733511, 0.07060848323339997)\n",
      "------------oot------------\n",
      " (0.5100974293029344, 0.03942585062384874)\n",
      "隐藏层vs神经元数vs norm 2 940 0.3\n",
      "验证集最优结果： 95.07526397705078 95.01887512207031\n",
      "------------train------------\n",
      " (0.5040093019541277, 0.030316492491907154)\n",
      "------------test------------\n",
      " (0.4837641572285143, 0.006495669553630901)\n",
      "------------oot------------\n",
      " (0.4898515969832829, 0.02782469676432764)\n",
      "隐藏层vs神经元数vs norm 2 940 0.4\n",
      "验证集最优结果： 126.59600067138672 126.53990936279297\n",
      "------------train------------\n",
      " (0.5003621562611884, 0.009727662010951987)\n",
      "------------test------------\n",
      " (0.522423939595825, 0.05591827670441926)\n",
      "------------oot------------\n",
      " (0.5113381758361427, 0.04263719459215237)\n",
      "隐藏层vs神经元数vs norm 2 940 0.5\n",
      "验证集最优结果： 158.2184600830078 158.15663146972656\n",
      "------------train------------\n",
      " (0.5182158305127648, 0.03470811937959001)\n",
      "------------test------------\n",
      " (0.5183999555851654, 0.03632023095713971)\n",
      "------------oot------------\n",
      " (0.5280077387365469, 0.05402286866159256)\n",
      "隐藏层vs神经元数vs norm 2 940 0.8\n",
      "验证集最优结果： 252.63641357421875 252.6337127685547\n",
      "------------train------------\n",
      " (0.5129355637989929, 0.03476578283212828)\n",
      "------------test------------\n",
      " (0.48469908949589163, 0.040539640239840136)\n",
      "------------oot------------\n",
      " (0.4892804596902188, 0.03379557223786189)\n",
      "隐藏层vs神经元数vs norm 2 970 0.01\n",
      "验证集最优结果： 3.8462605476379395 3.8181729316711426\n",
      "------------train------------\n",
      " (0.5891717917428914, 0.12428044200525334)\n",
      "------------test------------\n",
      " (0.5749455918276705, 0.12291805463024652)\n",
      "------------oot------------\n",
      " (0.5973702197662161, 0.15327564035727942)\n",
      "隐藏层vs神经元数vs norm 2 970 0.05\n",
      "验证集最优结果： 16.983461380004883 16.866836547851562\n",
      "------------train------------\n",
      " (0.526659668543436, 0.05089097478983634)\n",
      "------------test------------\n",
      " (0.54515212080835, 0.078936264712414)\n",
      "------------oot------------\n",
      " (0.5316500422850126, 0.06519306294095151)\n",
      "隐藏层vs神经元数vs norm 2 970 0.1\n",
      "验证集最优结果： 33.50614547729492 33.33055877685547\n",
      "------------train------------\n",
      " (0.5240390270578306, 0.04113678217630801)\n",
      "------------test------------\n",
      " (0.49054630246502334, 0.02754830113257828)\n",
      "------------oot------------\n",
      " (0.5401105202794286, 0.07130990859486319)\n",
      "隐藏层vs神经元数vs norm 2 970 0.2\n",
      "验证集最优结果： 66.43018341064453 66.11872863769531\n",
      "------------train------------\n",
      " (0.47644292299560287, 0.0032089846697785918)\n",
      "------------test------------\n",
      " (0.4757328447701532, 0.013557628247834777)\n",
      "------------oot------------\n",
      " (0.46542939561394364, 0.004587634240433736)\n",
      "隐藏层vs神经元数vs norm 2 970 0.3\n",
      "验证集最优结果： 99.1737289428711 99.18035125732422\n",
      "------------train------------\n",
      " (0.5157174193033145, 0.05229168231769177)\n",
      "------------test------------\n",
      " (0.5179980013324451, 0.04499222740395292)\n",
      "------------oot------------\n",
      " (0.5160196480496763, 0.044034337747193564)\n",
      "隐藏层vs神经元数vs norm 2 970 0.4\n",
      "验证集最优结果： 132.21043395996094 132.18881225585938\n",
      "------------train------------\n",
      " (0.48140380727682985, 0.011443758844944196)\n",
      "------------test------------\n",
      " (0.4656528980679547, 0.0061403508771929825)\n",
      "------------oot------------\n",
      " (0.4321273416049769, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 2 970 0.5\n",
      "验证集最优结果： 165.0467987060547 165.02818298339844\n",
      "------------train------------\n",
      " (0.5213268820653804, 0.038266062689377406)\n",
      "------------test------------\n",
      " (0.5122118587608261, 0.054063957361758785)\n",
      "------------oot------------\n",
      " (0.5076854458462216, 0.037542140200882756)\n",
      "隐藏层vs神经元数vs norm 2 970 0.8\n",
      "验证集最优结果： 263.8937072753906 263.8196716308594\n",
      "------------train------------\n",
      " (0.5814107106479084, 0.12116620948753304)\n",
      "------------test------------\n",
      " (0.5660248723073507, 0.11330224294914498)\n",
      "------------oot------------\n",
      " (0.5605173831948933, 0.09668091613665597)\n",
      "隐藏层vs神经元数vs norm 3 1 0.01\n",
      "验证集最优结果： 0.5835162997245789 0.5727494359016418\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 1 0.05\n",
      "验证集最优结果： 0.5922632813453674 0.5818273425102234\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 1 0.1\n",
      "验证集最优结果： 0.6035086512565613 0.5937145352363586\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 1 0.2\n",
      "验证集最优结果： 0.6255797147750854 0.6136845946311951\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 1 0.3\n",
      "验证集最优结果： 0.6514132022857666 0.6359977722167969\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 1 0.4\n",
      "验证集最优结果： 0.6699650287628174 0.6595215797424316\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 1 0.5\n",
      "验证集最优结果： 0.6922516822814941 0.6818181872367859\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 1 0.8\n",
      "验证集最优结果： 0.7625880241394043 0.7503935694694519\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 2 0.01\n",
      "验证集最优结果： 0.5850410461425781 0.5749129056930542\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 2 0.05\n",
      "验证集最优结果： 0.6036461591720581 0.5920706987380981\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4988009592326139, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 2 0.1\n",
      "验证集最优结果： 0.6266809701919556 0.6136806607246399\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 2 0.2\n",
      "验证集最优结果： 0.6711525917053223 0.6559355854988098\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 2 0.3\n",
      "验证集最优结果： 0.7218807935714722 0.7042307257652283\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 2 0.4\n",
      "验证集最优结果： 0.7635972499847412 0.7449091672897339\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 2 0.5\n",
      "验证集最优结果： 0.8123352527618408 0.7908071279525757\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 2 0.8\n",
      "验证集最优结果： 0.9344823956489563 0.9257662892341614\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 3 0.01\n",
      "验证集最优结果： 0.5874224901199341 0.5769038796424866\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 3 0.05\n",
      "验证集最优结果： 0.6139276623725891 0.6022999286651611\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 3 0.1\n",
      "验证集最优结果： 0.6469123363494873 0.6335834860801697\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 3 0.2\n",
      "验证集最优结果： 0.713765561580658 0.6992135047912598\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 3 0.3\n",
      "验证集最优结果： 0.7798704504966736 0.7629214525222778\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 3 0.4\n",
      "验证集最优结果： 0.846921443939209 0.8271133899688721\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4992840510200536, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 3 0.5\n",
      "验证集最优结果： 0.8990696668624878 0.8877367973327637\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 3 0.8\n",
      "验证集最优结果： 1.1534786224365234 1.134403109550476\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4992828925265585, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 4 0.01\n",
      "验证集最优结果： 0.5897528529167175 0.5791822671890259\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4992840510200536, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 4 0.05\n",
      "验证集最优结果： 0.6241714954376221 0.6126859188079834\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 4 0.1\n",
      "验证集最优结果： 0.6683179140090942 0.6564134359359741\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5007171074734416, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 4 0.2\n",
      "验证集最优结果： 0.7579379677772522 0.7410992980003357\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4988009592326139, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 4 0.3\n",
      "验证集最优结果： 0.8493279814720154 0.8329377770423889\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 4 0.4\n",
      "验证集最优结果： 0.940222442150116 0.9199265837669373\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5011990407673861, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 4 0.5\n",
      "验证集最优结果： 1.029858946800232 1.003255844116211\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 4 0.8\n",
      "验证集最优结果： 1.293329119682312 1.278838038444519\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 5 0.01\n",
      "验证集最优结果： 0.5921109914779663 0.581178605556488\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5011990407673861, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 5 0.05\n",
      "验证集最优结果： 0.6364234685897827 0.6250454187393188\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5007171074734416, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 5 0.1\n",
      "验证集最优结果： 0.6929242610931396 0.6803625226020813\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 5 0.2\n",
      "验证集最优结果： 0.8922784924507141 0.8748279809951782\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5011990407673861, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 7 0.3\n",
      "验证集最优结果： 1.04436194896698 1.021099328994751\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 7 0.4\n",
      "验证集最优结果： 1.2013672590255737 1.1788409948349\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 7 0.5\n",
      "验证集最优结果： 1.3589569330215454 1.334064245223999\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 7 0.8\n",
      "验证集最优结果： 1.8120293617248535 1.7798821926116943\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 8 0.01\n",
      "验证集最优结果： 0.5984823107719421 0.5875744819641113\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 8 0.05\n",
      "验证集最优结果： 0.66838538646698 0.6562231779098511\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019161482408276, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 8 0.1\n",
      "验证集最优结果： 0.7549960613250732 0.7412320971488953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 8 0.2\n",
      "验证集最优结果： 0.9341036677360535 0.9164601564407349\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 8 0.3\n",
      "验证集最优结果： 1.1038670539855957 1.0863033533096313\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4992840510200536, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 8 0.4\n",
      "验证集最优结果： 1.2856196165084839 1.2670565843582153\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 8 0.5\n",
      "验证集最优结果： 1.4649044275283813 1.4404869079589844\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019173067343227, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 8 0.8\n",
      "验证集最优结果： 2.0218043327331543 1.9910054206848145\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4992840510200536, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 9 0.01\n",
      "验证集最优结果： 0.6006163954734802 0.5896369814872742\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 9 0.05\n",
      "验证集最优结果： 0.6792851686477661 0.6668184995651245\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 9 0.1\n",
      "验证集最优结果： 0.7780718207359314 0.7642405033111572\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 9 0.2\n",
      "验证集最优结果： 0.9760165810585022 0.9583964347839355\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 9 0.3\n",
      "验证集最优结果： 1.1794168949127197 1.157636284828186\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5011990407673861, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 9 0.4\n",
      "验证集最优结果： 1.3663781881332397 1.341058611869812\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019161482408276, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 9 0.5\n",
      "验证集最优结果： 1.5806865692138672 1.5517890453338623\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5007171074734416, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 9 0.8\n",
      "验证集最优结果： 2.170806407928467 2.1368656158447266\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 10 0.01\n",
      "验证集最优结果： 0.6027456521987915 0.5917505621910095\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 10 0.05\n",
      "验证集最优结果： 0.6895595788955688 0.677054762840271\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 10 0.1\n",
      "验证集最优结果： 0.8002164363861084 0.7853585481643677\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4992828925265585, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 10 0.2\n",
      "验证集最优结果： 1.0232733488082886 1.0063087940216064\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 10 0.3\n",
      "验证集最优结果： 1.2432591915130615 1.2208340167999268\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 10 0.4\n",
      "验证集最优结果： 1.4551939964294434 1.4348766803741455\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4992828925265585, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 10 0.5\n",
      "验证集最优结果： 1.6887677907943726 1.6716926097869873\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4992828925265585, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 10 0.8\n",
      "验证集最优结果： 2.34784197807312 2.319544553756714\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 11 0.01\n",
      "验证集最优结果： 0.6051535606384277 0.5941942930221558\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019161482408276, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 11 0.05\n",
      "验证集最优结果： 0.7023507952690125 0.6902905106544495\n",
      "------------train------------\n",
      " (0.4997773324426631, 0.0)\n",
      "------------test------------\n",
      " (0.4986842105263158, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 11 0.1\n",
      "验证集最优结果： 0.8217052221298218 0.8091447949409485\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 11 0.2\n",
      "验证集最优结果： 1.0684727430343628 1.050999641418457\n",
      "------------train------------\n",
      " (0.5016079440204285, 0.003215888040857151)\n",
      "------------test------------\n",
      " (0.5010659560293138, 0.0021319120586275053)\n",
      "------------oot------------\n",
      " (0.49519341048900006, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 11 0.3\n",
      "验证集最优结果： 1.317343831062317 1.2991600036621094\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 11 0.4\n",
      "验证集最优结果： 1.5584465265274048 1.5305174589157104\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 11 0.5\n",
      "验证集最优结果： 1.7905794382095337 1.7616440057754517\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 11 0.8\n",
      "验证集最优结果： 2.556716203689575 2.521420478820801\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.49808385175917247, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 12 0.01\n",
      "验证集最优结果： 0.6073889136314392 0.5962449908256531\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 12 0.05\n",
      "验证集最优结果： 0.7134107947349548 0.6996128559112549\n",
      "------------train------------\n",
      " (0.5001113337786685, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 12 0.1\n",
      "验证集最优结果： 0.8464395999908447 0.8322709202766418\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 12 0.2\n",
      "验证集最优结果： 1.1108665466308594 1.093809723854065\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 12 0.3\n",
      "验证集最优结果： 1.3801274299621582 1.3608769178390503\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019138312538375, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 12 0.4\n",
      "验证集最优结果： 1.6495248079299927 1.6225076913833618\n",
      "------------train------------\n",
      " (0.5, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 12 0.5\n",
      "验证集最优结果： 1.8936415910720825 1.855184555053711\n",
      "------------train------------\n",
      " (0.4990191798659799, 0.0)\n",
      "------------test------------\n",
      " (0.49912280701754386, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5021513224203247, 0.006693775414451153)\n",
      "隐藏层vs神经元数vs norm 3 12 0.8\n",
      "验证集最优结果： 2.7402896881103516 2.698748826980591\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 13 0.01\n",
      "验证集最优结果： 0.609581708908081 0.5985584855079651\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019173067343227, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 13 0.05\n",
      "验证集最优结果： 0.7251975536346436 0.7120552062988281\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 13 0.1\n",
      "验证集最优结果： 0.866850733757019 0.8503812551498413\n",
      "------------train------------\n",
      " (0.489300586989582, 0.0)\n",
      "------------test------------\n",
      " (0.4947701532311792, 0.0)\n",
      "------------oot------------\n",
      " (0.4900415899164726, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 13 0.2\n",
      "验证集最优结果： 1.150921106338501 1.1288511753082275\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4995180667060554, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 3 13 0.3\n",
      "验证集最优结果： 1.4554334878921509 1.4362627267837524\n",
      "------------train------------\n",
      " (0.4997773324426631, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.49903613341211095, 0.00046571438501374907)\n",
      "隐藏层vs神经元数vs norm 3 13 0.4\n",
      "验证集最优结果： 1.738052248954773 1.7279679775238037\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 13 0.5\n",
      "验证集最优结果： 2.008375644683838 1.9822914600372314\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 13 0.8\n",
      "验证集最优结果： 2.904917001724243 2.850748062133789\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 14 0.01\n",
      "验证集最优结果： 0.611638605594635 0.6006227731704712\n",
      "------------train------------\n",
      " (0.4914340670533908, 0.0)\n",
      "------------test------------\n",
      " (0.5100644015101045, 0.0199200532978015)\n",
      "------------oot------------\n",
      " (0.4800414740671231, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 14 0.05\n",
      "验证集最优结果： 0.7362000942230225 0.7243003249168396\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 14 0.1\n",
      "验证集最优结果： 0.8924049735069275 0.8790886998176575\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 14 0.2\n",
      "验证集最优结果： 1.1984983682632446 1.1790106296539307\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 14 0.3\n",
      "验证集最优结果： 1.523964762687683 1.508792519569397\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 14 0.4\n",
      "验证集最优结果： 1.812423586845398 1.7839783430099487\n",
      "------------train------------\n",
      " (0.49994876615777994, 0.0)\n",
      "------------test------------\n",
      " (0.5021929824561403, 0.0043859649122807015)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 14 0.5\n",
      "验证集最优结果： 2.14794659614563 2.132209300994873\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5011990407673861, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 14 0.8\n",
      "验证集最优结果： 3.1129097938537598 3.084660053253174\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 15 0.01\n",
      "验证集最优结果： 0.6141992211341858 0.6031709313392639\n",
      "------------train------------\n",
      " (0.49966599866399464, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5038299794946651, 0.007659958989330362)\n",
      "隐藏层vs神经元数vs norm 3 15 0.05\n",
      "验证集最优结果： 0.7480483055114746 0.7354587912559509\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 15 0.1\n",
      "验证集最优结果： 0.9118490219116211 0.8938330411911011\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 15 0.2\n",
      "验证集最优结果： 1.2410926818847656 1.215968132019043\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 15 0.3\n",
      "验证集最优结果： 1.577012538909912 1.5511471033096313\n",
      "------------train------------\n",
      " (0.49920144239847475, 0.0)\n",
      "------------test------------\n",
      " (0.5024428159005108, 0.00488563180102154)\n",
      "------------oot------------\n",
      " (0.4883096421413593, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 15 0.4\n",
      "验证集最优结果： 1.9221090078353882 1.8947750329971313\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 15 0.5\n",
      "验证集最优结果： 2.2320480346679688 2.184998035430908\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 15 0.8\n",
      "验证集最优结果： 3.2831761837005615 3.2451674938201904\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4992828925265585, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 16 0.01\n",
      "验证集最优结果： 0.6164007782936096 0.6054428815841675\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 16 0.05\n",
      "验证集最优结果： 0.7560127973556519 0.7425137758255005\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 16 0.1\n",
      "验证集最优结果： 0.9307966232299805 0.9141722321510315\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 16 0.2\n",
      "验证集最优结果： 1.283360242843628 1.2677655220031738\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4992828925265585, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 16 0.3\n",
      "验证集最优结果： 1.6450825929641724 1.6282904148101807\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4992828925265585, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 16 0.4\n",
      "验证集最优结果： 2.0188188552856445 2.0001399517059326\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5011990407673861, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 16 0.5\n",
      "验证集最优结果： 2.3690848350524902 2.35187029838562\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019173067343227, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 16 0.8\n",
      "验证集最优结果： 3.4671292304992676 3.43863582611084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " (0.5003039513677812, 0.0006079027355623268)\n",
      "------------test------------\n",
      " (0.5017033089051743, 0.0025316455696202667)\n",
      "------------oot------------\n",
      " (0.5019161482408276, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 17 0.01\n",
      "验证集最优结果： 0.6184722185134888 0.6076685786247253\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 17 0.05\n",
      "验证集最优结果： 0.7681159973144531 0.7554075717926025\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 17 0.1\n",
      "验证集最优结果： 0.9552199840545654 0.9385843873023987\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019161482408276, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 17 0.2\n",
      "验证集最优结果： 1.333790898323059 1.3176308870315552\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 17 0.3\n",
      "验证集最优结果： 1.7088285684585571 1.6768124103546143\n",
      "------------train------------\n",
      " (0.4990068620862123, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.4971234606517685, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 17 0.4\n",
      "验证集最优结果： 2.092456340789795 2.064544916152954\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 17 0.5\n",
      "验证集最优结果： 2.5006420612335205 2.4849777221679688\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 17 0.8\n",
      "验证集最优结果： 3.644765615463257 3.6093809604644775\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 18 0.01\n",
      "验证集最优结果： 0.6207147836685181 0.6092312335968018\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 18 0.05\n",
      "验证集最优结果： 0.7798135876655579 0.7680778503417969\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.49808385175917247, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 18 0.1\n",
      "验证集最优结果： 0.9806257486343384 0.9670179486274719\n",
      "------------train------------\n",
      " (0.5005620833020313, 0.0011241666040625667)\n",
      "------------test------------\n",
      " (0.4993781923162336, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4985820039620477, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 18 0.2\n",
      "验证集最优结果： 1.3788470029830933 1.3597553968429565\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5011990407673861, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 18 0.3\n",
      "验证集最优结果： 1.7885982990264893 1.7652432918548584\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 18 0.4\n",
      "验证集最优结果： 2.194596290588379 2.173827886581421\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 18 0.5\n",
      "验证集最优结果： 2.5763089656829834 2.5388927459716797\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4992828925265585, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 18 0.8\n",
      "验证集最优结果： 3.804762363433838 3.7849371433258057\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019126727603425, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 19 0.01\n",
      "验证集最优结果： 0.623534619808197 0.6122630834579468\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5011990407673861, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 19 0.05\n",
      "验证集最优结果： 0.7905915379524231 0.7766561508178711\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 19 0.1\n",
      "验证集最优结果： 1.008108139038086 0.9974676370620728\n",
      "------------train------------\n",
      " (0.5012882231873406, 0.0025764463746811295)\n",
      "------------test------------\n",
      " (0.4994115034421497, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473326, 0.007659958989330362)\n",
      "隐藏层vs神经元数vs norm 3 19 0.2\n",
      "验证集最优结果： 1.4203449487686157 1.390716314315796\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 19 0.3\n",
      "验证集最优结果： 1.8402349948883057 1.808126449584961\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 19 0.4\n",
      "验证集最优结果： 2.2611331939697266 2.210970878601074\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 19 0.5\n",
      "验证集最优结果： 2.7065200805664062 2.676767349243164\n",
      "------------train------------\n",
      " (0.49952461491710204, 0.0)\n",
      "------------test------------\n",
      " (0.49736842105263157, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 19 0.8\n",
      "验证集最优结果： 3.968925714492798 3.92590594291687\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5028788563352218, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 20 0.01\n",
      "验证集最优结果： 0.6254135966300964 0.6144009828567505\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 20 0.05\n",
      "验证集最优结果： 0.8062651753425598 0.7959408760070801\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 20 0.1\n",
      "验证集最优结果： 1.0274080038070679 1.0120962858200073\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 20 0.2\n",
      "验证集最优结果： 1.4601240158081055 1.4304126501083374\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 20 0.3\n",
      "验证集最优结果： 1.9289313554763794 1.9101835489273071\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995180667060554, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 3 20 0.4\n",
      "验证集最优结果： 2.3713133335113525 2.3539741039276123\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 20 0.5\n",
      "验证集最优结果： 2.8363096714019775 2.8066225051879883\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 20 0.8\n",
      "验证集最优结果： 4.211452007293701 4.180347442626953\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.49808385175917247, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 22 0.01\n",
      "验证集最优结果： 0.6294171810150146 0.6180133819580078\n",
      "------------train------------\n",
      " (0.4997761818808167, 0.0)\n",
      "------------test------------\n",
      " (0.5054075061070398, 0.010815012214079489)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.49243503747726464, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 22 0.05\n",
      "验证集最优结果： 0.8250673413276672 0.8123409748077393\n",
      "------------train------------\n",
      " (0.4998374323791115, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4968871279787765, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 22 0.1\n",
      "验证集最优结果： 1.0748372077941895 1.0573601722717285\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 22 0.2\n",
      "验证集最优结果： 1.5681723356246948 1.5574473142623901\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 22 0.3\n",
      "验证集最优结果： 2.0552215576171875 2.041412353515625\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 22 0.4\n",
      "验证集最优结果： 2.5665597915649414 2.5401434898376465\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.49808385175917247, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 22 0.5\n",
      "验证集最优结果： 3.044896125793457 3.0281014442443848\n",
      "------------train------------\n",
      " (0.5034401799208008, 0.006880359841601513)\n",
      "------------test------------\n",
      " (0.5114445924938928, 0.022296246946480025)\n",
      "------------oot------------\n",
      " (0.49035322466664355, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 22 0.8\n",
      "验证集最优结果： 4.532927989959717 4.506685256958008\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 24 0.01\n",
      "验证集最优结果： 0.6347663998603821 0.6232922673225403\n",
      "------------train------------\n",
      " (0.5001113337786685, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 24 0.05\n",
      "验证集最优结果： 0.8475042581558228 0.8351120948791504\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 24 0.1\n",
      "验证集最优结果： 1.121446967124939 1.1095538139343262\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 24 0.2\n",
      "验证集最优结果： 1.6502500772476196 1.631717562675476\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.49808385175917247, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 24 0.3\n",
      "验证集最优结果： 2.2014291286468506 2.184608221054077\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019138312538375, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 24 0.4\n",
      "验证集最优结果： 2.733057737350464 2.691495418548584\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 24 0.5\n",
      "验证集最优结果： 3.2951042652130127 3.281825065612793\n",
      "------------train------------\n",
      " (0.5141816222786675, 0.028363244557334855)\n",
      "------------test------------\n",
      " (0.49077836997557184, 0.0)\n",
      "------------oot------------\n",
      " (0.49285788760296106, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 24 0.8\n",
      "验证集最优结果： 4.918695449829102 4.8783674240112305\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.49808616874616257, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 26 0.01\n",
      "验证集最优结果： 0.6391475796699524 0.6280425190925598\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 26 0.05\n",
      "验证集最优结果： 0.8712671399116516 0.8573684096336365\n",
      "------------train------------\n",
      " (0.49115651092796875, 0.0)\n",
      "------------test------------\n",
      " (0.4993681989784588, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.47599717327587204, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 26 0.1\n",
      "验证集最优结果： 1.1563185453414917 1.141104817390442\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 26 0.2\n",
      "验证集最优结果： 1.7408690452575684 1.7187460660934448\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019161482408276, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 26 0.3\n",
      "验证集最优结果： 2.3475353717803955 2.3326683044433594\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 26 0.4\n",
      "验证集最优结果： 2.89973521232605 2.8578169345855713\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 26 0.5\n",
      "验证集最优结果： 3.4973061084747314 3.452249526977539\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5007171074734416, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 26 0.8\n",
      "验证集最优结果： 5.282839775085449 5.222827911376953\n",
      "------------train------------\n",
      " (0.501694642239562, 0.0033892844791237886)\n",
      "------------test------------\n",
      " (0.4994115034421497, 0.0)\n",
      "------------oot------------\n",
      " (0.5002363326729921, 0.004295693879678875)\n",
      "隐藏层vs神经元数vs norm 3 28 0.01\n",
      "验证集最优结果： 0.6439288854598999 0.6325829029083252\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.49688481099178633, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 28 0.05\n",
      "验证集最优结果： 0.8974258303642273 0.8867577314376831\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 28 0.1\n",
      "验证集最优结果： 1.215313196182251 1.2032570838928223\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 28 0.2\n",
      "验证集最优结果： 1.8530443906784058 1.8316099643707275\n",
      "------------train------------\n",
      " (0.5005566688933423, 0.00111333778668448)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4961700205053348, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 28 0.3\n",
      "验证集最优结果： 2.4851326942443848 2.4650049209594727\n",
      "------------train------------\n",
      " (0.4997773324426631, 0.0)\n",
      "------------test------------\n",
      " (0.49912280701754386, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 28 0.4\n",
      "验证集最优结果： 3.0960330963134766 3.0666439533233643\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4992828925265585, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 28 0.5\n",
      "验证集最优结果： 3.7080705165863037 3.6522912979125977\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.49808732723965765, 0.000966183574879227)\n",
      "隐藏层vs神经元数vs norm 3 28 0.8\n",
      "验证集最优结果： 5.672471046447754 5.636411666870117\n",
      "------------train------------\n",
      " (0.5005279048471817, 0.0010558096943634188)\n",
      "------------test------------\n",
      " (0.4937597157450589, 0.0)\n",
      "------------oot------------\n",
      " (0.5120819286599706, 0.025516977722170098)\n",
      "隐藏层vs神经元数vs norm 3 30 0.01\n",
      "验证集最优结果： 0.648992121219635 0.6382520794868469\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 30 0.05\n",
      "验证集最优结果： 0.9219849109649658 0.9107095003128052\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 3 30 0.1\n",
      "验证集最优结果： 1.2565330266952515 1.2446223497390747\n",
      "------------train------------\n",
      " (0.5002226675573369, 0.00044533511467379205)\n",
      "------------test------------\n",
      " (0.49917388407728175, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.49951922519955055, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 30 0.2\n",
      "验证集最优结果： 1.9425990581512451 1.9283069372177124\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 30 0.3\n",
      "验证集最优结果： 2.614433765411377 2.5884273052215576\n",
      "------------train------------\n",
      " (0.5250237726381504, 0.050047545276300676)\n",
      "------------test------------\n",
      " (0.53206084832334, 0.06375749500333111)\n",
      "------------oot------------\n",
      " (0.5259398278478666, 0.05268133319431406)\n",
      "隐藏层vs神经元数vs norm 3 30 0.4\n",
      "验证集最优结果： 3.303792953491211 3.293020248413086\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5008771929824561, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 30 0.5\n",
      "验证集最优结果： 3.9917218685150146 3.952728033065796\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.49808616874616257, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 30 0.8\n",
      "验证集最优结果： 6.035702228546143 6.002366065979004\n",
      "------------train------------\n",
      " (0.5003852351782254, 0.0007704703564508364)\n",
      "------------test------------\n",
      " (0.5016544525871641, 0.003308905174328247)\n",
      "------------oot------------\n",
      " (0.5031151890082137, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 3 32 0.01\n",
      "验证集最优结果： 0.6534461379051208 0.642146646976471\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 32 0.05\n",
      "验证集最优结果： 0.9435839653015137 0.9335707426071167\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 32 0.1\n",
      "验证集最优结果： 1.3095946311950684 1.2950526475906372\n",
      "------------train------------\n",
      " (0.5002527175255611, 0.0005054350511221699)\n",
      "------------test------------\n",
      " (0.5013157894736842, 0.002631578947368421)\n",
      "------------oot------------\n",
      " (0.49856810204010704, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 32 0.2\n",
      "验证集最优结果： 2.0197019577026367 1.9977469444274902\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 32 0.3\n",
      "验证集最优结果： 2.751589298248291 2.729149341583252\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019173067343227, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 32 0.4\n",
      "验证集最优结果： 3.493149518966675 3.473370313644409\n",
      "------------train------------\n",
      " (0.4987664623404187, 0.0)\n",
      "------------test------------\n",
      " (0.49945924938929603, 0.0)\n",
      "------------oot------------\n",
      " (0.5019091972798573, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 32 0.5\n",
      "验证集最优结果： 4.159745693206787 4.091193675994873\n",
      "------------train------------\n",
      " (0.48022685018804917, 0.0)\n",
      "------------test------------\n",
      " (0.4981123695314235, 0.0)\n",
      "------------oot------------\n",
      " (0.47355622748178267, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 32 0.8\n",
      "验证集最优结果： 6.3593010902404785 6.299751281738281\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 34 0.01\n",
      "验证集最优结果： 0.6586180925369263 0.6473323702812195\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995180667060554, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 3 34 0.05\n",
      "验证集最优结果： 0.9668051600456238 0.9562285542488098\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 34 0.1\n",
      "验证集最优结果： 1.355211615562439 1.3423024415969849\n",
      "------------train------------\n",
      " (0.49962166819285314, 0.0)\n",
      "------------test------------\n",
      " (0.5073839662447257, 0.013912946924272696)\n",
      "------------oot------------\n",
      " (0.5021432129658592, 0.00809091856949229)\n",
      "隐藏层vs神经元数vs norm 3 34 0.2\n",
      "验证集最优结果： 2.1303560733795166 2.116447925567627\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 34 0.3\n",
      "验证集最优结果： 2.9005026817321777 2.8749189376831055\n",
      "------------train------------\n",
      " (0.48776973061286377, 0.0)\n",
      "------------test------------\n",
      " (0.49608150122140793, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.47893858825982694, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 34 0.4\n",
      "验证集最优结果： 3.6815454959869385 3.6606132984161377\n",
      "------------train------------\n",
      " (0.5001113337786685, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.5008771929824561, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 34 0.5\n",
      "验证集最优结果： 4.473234176635742 4.4497575759887695\n",
      "------------train------------\n",
      " (0.5001113337786685, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 34 0.8\n",
      "验证集最优结果： 6.781206130981445 6.748602867126465\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 36 0.01\n",
      "验证集最优结果： 0.6627224087715149 0.6510613560676575\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 36 0.05\n",
      "验证集最优结果： 0.9849506616592407 0.9695488810539246\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 36 0.1\n",
      "验证集最优结果： 1.400984764099121 1.385820746421814\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 36 0.2\n",
      "验证集最优结果： 2.220170021057129 2.196561336517334\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 36 0.3\n",
      "验证集最优结果： 3.036870241165161 3.0019664764404297\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 36 0.4\n",
      "验证集最优结果： 3.86128830909729 3.836193799972534\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 36 0.5\n",
      "验证集最优结果： 4.6904520988464355 4.652892112731934\n",
      "------------train------------\n",
      " (0.5002226675573369, 0.00044533511467379205)\n",
      "------------test------------\n",
      " (0.5013157894736842, 0.002631578947368421)\n",
      "------------oot------------\n",
      " (0.4985657850531169, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 36 0.8\n",
      "验证集最优结果： 7.170016765594482 7.133227825164795\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019173067343227, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 38 0.01\n",
      "验证集最优结果： 0.667571485042572 0.656480610370636\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 38 0.05\n",
      "验证集最优结果： 1.0174142122268677 1.0041258335113525\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019161482408276, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 38 0.1\n",
      "验证集最优结果： 1.4549970626831055 1.439970850944519\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 38 0.2\n",
      "验证集最优结果： 2.3006186485290527 2.2789134979248047\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 38 0.3\n",
      "验证集最优结果： 3.1815478801727295 3.166421413421631\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 38 0.4\n",
      "验证集最优结果： 4.064458847045898 4.0400071144104\n",
      "------------train------------\n",
      " (0.5012103910624356, 0.002420782124871179)\n",
      "------------test------------\n",
      " (0.49546080390850544, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4975764316083365, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 38 0.5\n",
      "验证集最优结果： 4.920172214508057 4.895131587982178\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 38 0.8\n",
      "验证集最优结果： 7.5318145751953125 7.498195648193359\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 40 0.01\n",
      "验证集最优结果： 0.6722617149353027 0.6615687012672424\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 40 0.05\n",
      "验证集最优结果： 1.0308306217193604 1.0141992568969727\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 40 0.1\n",
      "验证集最优结果： 1.488490343093872 1.4702266454696655\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019126727603425, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 40 0.2\n",
      "验证集最优结果： 2.4120826721191406 2.3900959491729736\n",
      "------------train------------\n",
      " (0.5060124301287479, 0.012024860257495745)\n",
      "------------test------------\n",
      " (0.4972185209860093, 0.0)\n",
      "------------oot------------\n",
      " (0.5055688782307487, 0.009981579953428549)\n",
      "隐藏层vs神经元数vs norm 3 40 0.3\n",
      "验证集最优结果： 3.3257369995117188 3.294156789779663\n",
      "------------train------------\n",
      " (0.4958545256673428, 0.0)\n",
      "------------test------------\n",
      " (0.49705307572729285, 0.0)\n",
      "------------oot------------\n",
      " (0.5053209606228061, 0.006937059048413442)\n",
      "隐藏层vs神经元数vs norm 3 40 0.4\n",
      "验证集最优结果： 4.251489162445068 4.233031749725342\n",
      "------------train------------\n",
      " (0.5062158765352387, 0.012431753070477336)\n",
      "------------test------------\n",
      " (0.4852265156562292, 0.0)\n",
      "------------oot------------\n",
      " (0.47996037952246895, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 40 0.5\n",
      "验证集最优结果： 5.134697437286377 5.1136393547058105\n",
      "------------train------------\n",
      " (0.5000211838739959, 4.2367747991822746e-05)\n",
      "------------test------------\n",
      " (0.4990717299578059, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 40 0.8\n",
      "验证集最优结果： 7.944030284881592 7.911065578460693\n",
      "------------train------------\n",
      " (0.5005054350511221, 0.0010108701022443398)\n",
      "------------test------------\n",
      " (0.5013657561625583, 0.0027315123251165888)\n",
      "------------oot------------\n",
      " (0.49976366732700794, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 42 0.01\n",
      "验证集最优结果： 0.677305281162262 0.6663869619369507\n",
      "------------train------------\n",
      " (0.49988866622133155, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 42 0.05\n",
      "验证集最优结果： 1.0596482753753662 1.0443178415298462\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 42 0.1\n",
      "验证集最优结果： 1.5291167497634888 1.502834677696228\n",
      "------------train------------\n",
      " (0.5014487604049707, 0.0028975208099413924)\n",
      "------------test------------\n",
      " (0.4968520986009327, 0.0)\n",
      "------------oot------------\n",
      " (0.4879794714952676, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 42 0.2\n",
      "验证集最优结果： 2.5063750743865967 2.48652720451355\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 42 0.3\n",
      "验证集最优结果： 3.4746949672698975 3.461435079574585\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 42 0.4\n",
      "验证集最优结果： 4.433811187744141 4.418097019195557\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.49808385175917247, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 42 0.5\n",
      "验证集最优结果： 5.405844688415527 5.3766560554504395\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 42 0.8\n",
      "验证集最优结果： 8.318052291870117 8.244698524475098\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 44 0.01\n",
      "验证集最优结果： 0.6819043159484863 0.670649528503418\n",
      "------------train------------\n",
      " (0.4997773324426631, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5011990407673861, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 44 0.05\n",
      "验证集最优结果： 1.0879496335983276 1.0758053064346313\n",
      "------------train------------\n",
      " (0.4983332419651867, 0.0)\n",
      "------------test------------\n",
      " (0.505102154119476, 0.010726182544970042)\n",
      "------------oot------------\n",
      " (0.47735956162606147, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 44 0.1\n",
      "验证集最优结果： 1.5911927223205566 1.5782815217971802\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 44 0.2\n",
      "验证集最优结果： 2.5676047801971436 2.5341246128082275\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 44 0.3\n",
      "验证集最优结果： 3.587354898452759 3.564805507659912\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 44 0.4\n",
      "验证集最优结果： 4.643502712249756 4.618061542510986\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 44 0.5\n",
      "验证集最优结果： 5.629842281341553 5.621621608734131\n",
      "------------train------------\n",
      " (0.5001113337786685, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 44 0.8\n",
      "验证集最优结果： 8.697275161743164 8.642792701721191\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 46 0.01\n",
      "验证集最优结果： 0.686823308467865 0.6761812567710876\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 46 0.05\n",
      "验证集最优结果： 1.1098030805587769 1.0994902849197388\n",
      "------------train------------\n",
      " (0.5014596569024574, 0.002919313804914836)\n",
      "------------test------------\n",
      " (0.4986842105263158, 0.0)\n",
      "------------oot------------\n",
      " (0.4985507246376812, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 46 0.1\n",
      "验证集最优结果： 1.6390599012374878 1.627748727798462\n",
      "------------train------------\n",
      " (0.5001113337786685, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 46 0.2\n",
      "验证集最优结果： 2.7046821117401123 2.681272029876709\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.49808385175917247, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 46 0.3\n",
      "验证集最优结果： 3.702125310897827 3.6476807594299316\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019173067343227, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 46 0.4\n",
      "验证集最优结果： 4.780871391296387 4.749337196350098\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 46 0.5\n",
      "验证集最优结果： 5.874570369720459 5.838680744171143\n",
      "------------train------------\n",
      " (0.5006133171442514, 0.0012266342885027051)\n",
      "------------test------------\n",
      " (0.4950866089273817, 0.0)\n",
      "------------oot------------\n",
      " (0.5045795247859682, 0.006832794633858132)\n",
      "隐藏层vs神经元数vs norm 3 46 0.8\n",
      "验证集最优结果： 9.02650260925293 8.931740760803223\n",
      "------------train------------\n",
      " (0.48953767041005347, 0.0)\n",
      "------------test------------\n",
      " (0.4754230512991339, 0.0)\n",
      "------------oot------------\n",
      " (0.5075800229381712, 0.014430194974455302)\n",
      "隐藏层vs神经元数vs norm 3 48 0.01\n",
      "验证集最优结果： 0.6907403469085693 0.6793644428253174\n",
      "------------train------------\n",
      " (0.5015621245868975, 0.0031242491737950573)\n",
      "------------test------------\n",
      " (0.5023761936486786, 0.0047634910059959346)\n",
      "------------oot------------\n",
      " (0.5019068802928672, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 48 0.05\n",
      "验证集最优结果： 1.1354092359542847 1.1213661432266235\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 48 0.1\n",
      "验证集最优结果： 1.6803919076919556 1.6582978963851929\n",
      "------------train------------\n",
      " (0.4992561279262341, 0.0)\n",
      "------------test------------\n",
      " (0.506578947368421, 0.014035087719298246)\n",
      "------------oot------------\n",
      " (0.49498024768590926, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 48 0.2\n",
      "验证集最优结果： 2.800755739212036 2.7799134254455566\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 48 0.3\n",
      "验证集最优结果： 3.8602819442749023 3.790264368057251\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 48 0.4\n",
      "验证集最优结果： 5.003963947296143 4.97930383682251\n",
      "------------train------------\n",
      " (0.5038164136445806, 0.007632827289161259)\n",
      "------------test------------\n",
      " (0.4878303353320009, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.491264959047255, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 48 0.5\n",
      "验证集最优结果： 6.169572830200195 6.13970422744751\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019161482408276, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 48 0.8\n",
      "验证集最优结果： 9.464621543884277 9.403136253356934\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 50 0.01\n",
      "验证集最优结果： 0.6965075135231018 0.6851989030838013\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 50 0.05\n",
      "验证集最优结果： 1.156826138496399 1.1441634893417358\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 50 0.1\n",
      "验证集最优结果： 1.7352944612503052 1.724695086479187\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 50 0.2\n",
      "验证集最优结果： 2.89929461479187 2.8744401931762695\n",
      "------------train------------\n",
      " (0.5042330523932025, 0.008466104786404971)\n",
      "------------test------------\n",
      " (0.508318898512103, 0.01646679991117031)\n",
      "------------oot------------\n",
      " (0.5044080677486997, 0.009585375178118388)\n",
      "隐藏层vs神经元数vs norm 3 50 0.3\n",
      "验证集最优结果： 4.048299789428711 4.044300079345703\n",
      "------------train------------\n",
      " (0.5007536180094062, 0.003752862022592951)\n",
      "------------test------------\n",
      " (0.5002165223184545, 0.006895403064623662)\n",
      "------------oot------------\n",
      " (0.49476476789582824, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 50 0.4\n",
      "验证集最优结果： 5.211673259735107 5.180415630340576\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 50 0.5\n",
      "验证集最优结果： 6.373258113861084 6.338223457336426\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 50 0.8\n",
      "验证集最优结果： 9.83296012878418 9.76961612701416\n",
      "------------train------------\n",
      " (0.4880774043866185, 0.0)\n",
      "------------test------------\n",
      " (0.500634021763269, 0.001221407950255389)\n",
      "------------oot------------\n",
      " (0.492402599659403, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 52 0.01\n",
      "验证集最优结果： 0.7016206979751587 0.6904163956642151\n",
      "------------train------------\n",
      " (0.48819821338049274, 0.0)\n",
      "------------test------------\n",
      " (0.4704874528092382, 0.0)\n",
      "------------oot------------\n",
      " (0.47975996014782385, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 52 0.05\n",
      "验证集最优结果： 1.176975965499878 1.1623297929763794\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.49808385175917247, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 52 0.1\n",
      "验证集最优结果： 1.7688015699386597 1.739706039428711\n",
      "------------train------------\n",
      " (0.5023518160941944, 0.004703632188388873)\n",
      "------------test------------\n",
      " (0.49789584721296914, 0.0)\n",
      "------------oot------------\n",
      " (0.507634472132439, 0.015215653564105258)\n",
      "隐藏层vs神经元数vs norm 3 52 0.2\n",
      "验证集最优结果： 2.9950973987579346 2.9764931201934814\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 52 0.3\n",
      "验证集最优结果： 4.208480358123779 4.193514823913574\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 52 0.4\n",
      "验证集最优结果： 5.363202095031738 5.3330864906311035\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5008771929824561, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.49808732723965765, 0.000966183574879227)\n",
      "隐藏层vs神经元数vs norm 3 52 0.5\n",
      "验证集最优结果： 6.637847900390625 6.592209339141846\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 52 0.8\n",
      "验证集最优结果： 10.303614616394043 10.228565216064453\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 54 0.01\n",
      "验证集最优结果： 0.7053188681602478 0.6938776969909668\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 54 0.05\n",
      "验证集最优结果： 1.202463984489441 1.1883628368377686\n",
      "------------train------------\n",
      " (0.5003640513042296, 0.0007281026084590661)\n",
      "------------test------------\n",
      " (0.5013157894736842, 0.002631578947368421)\n",
      "------------oot------------\n",
      " (0.5023957645477821, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 54 0.1\n",
      "验证集最优结果： 1.8225231170654297 1.8051034212112427\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5004830917874397, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 54 0.2\n",
      "验证集最优结果： 3.069103240966797 3.042177438735962\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 54 0.3\n",
      "验证集最优结果： 4.3642964363098145 4.346658706665039\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 54 0.4\n",
      "验证集最优结果： 5.599676132202148 5.578058242797852\n",
      "------------train------------\n",
      " (0.48685110849865887, 0.0)\n",
      "------------test------------\n",
      " (0.4939418165667333, 0.0)\n",
      "------------oot------------\n",
      " (0.4880756264553574, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 54 0.5\n",
      "验证集最优结果： 6.888045310974121 6.847425937652588\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49912280701754386, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 54 0.8\n",
      "验证集最优结果： 10.62837028503418 10.616272926330566\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5023980815347722, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 56 0.01\n",
      "验证集最优结果： 0.7110902667045593 0.69975745677948\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 56 0.05\n",
      "验证集最优结果： 1.2324482202529907 1.220608115196228\n",
      "------------train------------\n",
      " (0.49649498253514796, 0.0)\n",
      "------------test------------\n",
      " (0.49678547634910064, 0.0)\n",
      "------------oot------------\n",
      " (0.49772703576269417, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 56 0.1\n",
      "验证集最优结果： 1.890458345413208 1.873294472694397\n",
      "------------train------------\n",
      " (0.5000812838104443, 0.00016256762088850962)\n",
      "------------test------------\n",
      " (0.49912280701754386, 0.0)\n",
      "------------oot------------\n",
      " (0.5014342149468831, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 56 0.2\n",
      "验证集最优结果： 3.1885108947753906 3.1726186275482178\n",
      "------------train------------\n",
      " (0.4982097934470765, 0.0)\n",
      "------------test------------\n",
      " (0.5011625582944704, 0.0014545858316677984)\n",
      "------------oot------------\n",
      " (0.4995111157450851, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 56 0.3\n",
      "验证集最优结果： 4.5002617835998535 4.481825351715088\n",
      "------------train------------\n",
      " (0.5013463604006392, 0.0026927208012783588)\n",
      "------------test------------\n",
      " (0.5090361980901621, 0.017221852098600943)\n",
      "------------oot------------\n",
      " (0.5054843082056093, 0.010919959684426273)\n",
      "隐藏层vs神经元数vs norm 3 56 0.4\n",
      "验证集最优结果： 5.799346446990967 5.756258964538574\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4992828925265585, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 56 0.5\n",
      "验证集最优结果： 7.096370220184326 7.095791339874268\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 56 0.8\n",
      "验证集最优结果： 11.049663543701172 10.984027862548828\n",
      "------------train------------\n",
      " (0.5002014836833409, 0.00040296736668202996)\n",
      "------------test------------\n",
      " (0.5008771929824561, 0.002631578947368421)\n",
      "------------oot------------\n",
      " (0.49784636059268533, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 58 0.01\n",
      "验证集最优结果： 0.7163902521133423 0.7052804231643677\n",
      "------------train------------\n",
      " (0.5038060585879629, 0.007612117175925692)\n",
      "------------test------------\n",
      " (0.4974794581390184, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5078638538444606, 0.019476592638932422)\n",
      "隐藏层vs神经元数vs norm 3 58 0.05\n",
      "验证集最优结果： 1.2565677165985107 1.2458077669143677\n",
      "------------train------------\n",
      " (0.5001113337786685, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.5008771929824561, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.5004830917874397, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 58 0.1\n",
      "验证集最优结果： 1.9330440759658813 1.921136498451233\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 58 0.2\n",
      "验证集最优结果： 3.291372776031494 3.2686729431152344\n",
      "------------train------------\n",
      " (0.4705056177874154, 0.0)\n",
      "------------test------------\n",
      " (0.4762513879635799, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.44549635653795805, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 58 0.3\n",
      "验证集最优结果： 4.638870716094971 4.623669624328613\n",
      "------------train------------\n",
      " (0.499551213199787, 0.0)\n",
      "------------test------------\n",
      " (0.5022951365756163, 0.0054630246502331775)\n",
      "------------oot------------\n",
      " (0.4992910019810239, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 58 0.4\n",
      "验证集最优结果： 5.996654510498047 5.9847588539123535\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4992828925265585, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 58 0.5\n",
      "验证集最优结果： 7.349969863891602 7.3398051261901855\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 58 0.8\n",
      "验证集最优结果： 11.442375183105469 11.344045639038086\n",
      "------------train------------\n",
      " (0.49988866622133155, 0.0)\n",
      "------------test------------\n",
      " (0.49912280701754386, 0.0)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 60 0.01\n",
      "验证集最优结果： 0.7194389700889587 0.707984447479248\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 60 0.05\n",
      "验证集最优结果： 1.2812726497650146 1.270336389541626\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019173067343227, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 60 0.1\n",
      "验证集最优结果： 1.9879564046859741 1.9696909189224243\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 60 0.2\n",
      "验证集最优结果： 3.3888564109802246 3.364586353302002\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 60 0.3\n",
      "验证集最优结果： 4.795754432678223 4.776630878448486\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 60 0.4\n",
      "验证集最优结果： 6.181089401245117 6.1488261222839355\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 60 0.5\n",
      "验证集最优结果： 7.637990474700928 7.596272945404053\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 60 0.8\n",
      "验证集最优结果： 11.695514678955078 11.611677169799805\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5007147904864514, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 3 62 0.01\n",
      "验证集最优结果： 0.7256073355674744 0.7143516540527344\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019173067343227, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 62 0.05\n",
      "验证集最优结果： 1.305509328842163 1.2930649518966675\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 62 0.1\n",
      "验证集最优结果： 2.0307319164276123 2.0190072059631348\n",
      "------------train------------\n",
      " (0.49988866622133155, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019126727603425, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 62 0.2\n",
      "验证集最优结果： 3.498053550720215 3.4815173149108887\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 62 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集最优结果： 4.948806285858154 4.919157981872559\n",
      "------------train------------\n",
      " (0.49988866622133155, 0.0)\n",
      "------------test------------\n",
      " (0.49912280701754386, 0.0)\n",
      "------------oot------------\n",
      " (0.5031128720212236, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 3 62 0.4\n",
      "验证集最优结果： 6.394952774047852 6.378284454345703\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 62 0.5\n",
      "验证集最优结果： 7.856071472167969 7.855896472930908\n",
      "------------train------------\n",
      " (0.49685652967535887, 0.0)\n",
      "------------test------------\n",
      " (0.4925349766822119, 0.0)\n",
      "------------oot------------\n",
      " (0.5067470661152238, 0.011197998123240538)\n",
      "隐藏层vs神经元数vs norm 3 62 0.8\n",
      "验证集最优结果： 12.208755493164062 12.15941333770752\n",
      "------------train------------\n",
      " (0.4987758021954074, 0.0)\n",
      "------------test------------\n",
      " (0.509721296913169, 0.019420386409060627)\n",
      "------------oot------------\n",
      " (0.4959881370266106, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 64 0.01\n",
      "验证集最优结果： 0.7308250665664673 0.7190734148025513\n",
      "------------train------------\n",
      " (0.4998374323791115, 0.0)\n",
      "------------test------------\n",
      " (0.49785920497446146, 0.0)\n",
      "------------oot------------\n",
      " (0.4985657850531169, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 64 0.05\n",
      "验证集最优结果： 1.3320916891098022 1.3185570240020752\n",
      "------------train------------\n",
      " (0.501152253849137, 0.0023045076982739546)\n",
      "------------test------------\n",
      " (0.5035587386186986, 0.007117477237397292)\n",
      "------------oot------------\n",
      " (0.5016786570743406, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 64 0.1\n",
      "验证集最优结果： 2.0794286727905273 2.0647921562194824\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019173067343227, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 64 0.2\n",
      "验证集最优结果： 3.591942310333252 3.570736885070801\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 64 0.3\n",
      "验证集最优结果： 5.079610347747803 5.065047740936279\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 64 0.4\n",
      "验证集最优结果： 6.616999626159668 6.57631254196167\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 64 0.5\n",
      "验证集最优结果： 8.029407501220703 7.974073886871338\n",
      "------------train------------\n",
      " (0.5003340013360054, 0.0006680026720106881)\n",
      "------------test------------\n",
      " (0.5018043526537863, 0.0036087053075727293)\n",
      "------------oot------------\n",
      " (0.5002421251404674, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 3 64 0.8\n",
      "验证集最优结果： 12.60331916809082 12.557440757751465\n",
      "------------train------------\n",
      " (0.46589010510044065, 0.0)\n",
      "------------test------------\n",
      " (0.46996446813235615, 0.0)\n",
      "------------oot------------\n",
      " (0.45782388581888117, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 66 0.01\n",
      "验证集最优结果： 0.7364601492881775 0.7249085307121277\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 66 0.05\n",
      "验证集最优结果： 1.3501756191253662 1.3338440656661987\n",
      "------------train------------\n",
      " (0.5043780231858517, 0.008756046371703241)\n",
      "------------test------------\n",
      " (0.49495891627803684, 0.0)\n",
      "------------oot------------\n",
      " (0.5056337538664721, 0.014833350710735771)\n",
      "隐藏层vs神经元数vs norm 3 66 0.1\n",
      "验证集最优结果： 2.132634162902832 2.1173455715179443\n",
      "------------train------------\n",
      " (0.4995457987910979, 0.0)\n",
      "------------test------------\n",
      " (0.5002853653120142, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5002363326729921, 0.004295693879678875)\n",
      "隐藏层vs神经元数vs norm 3 66 0.2\n",
      "验证集最优结果： 3.6810014247894287 3.6646203994750977\n",
      "------------train------------\n",
      " (0.500118237149747, 0.0002364742994940272)\n",
      "------------test------------\n",
      " (0.5027637130801688, 0.004663557628247772)\n",
      "------------oot------------\n",
      " (0.4980687913437366, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 66 0.3\n",
      "验证集最优结果： 5.205717086791992 5.169947147369385\n",
      "------------train------------\n",
      " (0.5001113337786685, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.49873417721518987, 0.0)\n",
      "------------oot------------\n",
      " (0.4992828925265585, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 66 0.4\n",
      "验证集最优结果： 6.740155220031738 6.683355331420898\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.49808732723965765, 0.000966183574879227)\n",
      "隐藏层vs神经元数vs norm 3 66 0.5\n",
      "验证集最优结果： 8.338788032531738 8.303532600402832\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 66 0.8\n",
      "验证集最优结果： 12.89481258392334 12.763120651245117\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.49808732723965765, 0.000966183574879227)\n",
      "隐藏层vs神经元数vs norm 3 68 0.01\n",
      "验证集最优结果： 0.7410448789596558 0.7296632528305054\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5004819332939446, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 68 0.05\n",
      "验证集最优结果： 1.3799331188201904 1.3676106929779053\n",
      "------------train------------\n",
      " (0.5004064190522213, 0.0008128381044425481)\n",
      "------------test------------\n",
      " (0.5042327337330668, 0.0075949367088608)\n",
      "------------oot------------\n",
      " (0.4978382511382199, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 68 0.1\n",
      "验证集最优结果： 2.1715219020843506 2.152371644973755\n",
      "------------train------------\n",
      " (0.503422109331801, 0.006844218663602131)\n",
      "------------test------------\n",
      " (0.5219908949589163, 0.044570286475682896)\n",
      "------------oot------------\n",
      " (0.49752198241406875, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 68 0.2\n",
      "验证集最优结果： 3.7939915657043457 3.778367042541504\n",
      "------------train------------\n",
      " (0.49575774311202614, 0.0)\n",
      "------------test------------\n",
      " (0.5025638463246725, 0.006029313790806123)\n",
      "------------oot------------\n",
      " (0.4667651386137467, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 68 0.3\n",
      "验证集最优结果： 5.375604152679443 5.363645553588867\n",
      "------------train------------\n",
      " (0.5133119328829899, 0.02662386576597975)\n",
      "------------test------------\n",
      " (0.5259993337774818, 0.05142127470575175)\n",
      "------------oot------------\n",
      " (0.5074746000301208, 0.017808362006047296)\n",
      "隐藏层vs神经元数vs norm 3 68 0.4\n",
      "验证集最优结果： 7.001518726348877 6.974078178405762\n",
      "------------train------------\n",
      " (0.5074142205383411, 0.014828441076682242)\n",
      "------------test------------\n",
      " (0.48773928492116364, 0.0)\n",
      "------------oot------------\n",
      " (0.492913495290724, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 68 0.5\n",
      "验证集最优结果： 8.60698413848877 8.589370727539062\n",
      "------------train------------\n",
      " (0.5013611146643168, 0.002722229328633627)\n",
      "------------test------------\n",
      " (0.5052331778814124, 0.010448589829002885)\n",
      "------------oot------------\n",
      " (0.4955015697586858, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 68 0.8\n",
      "验证集最优结果： 13.417088508605957 13.383119583129883\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 70 0.01\n",
      "验证集最优结果： 0.7468299865722656 0.7348949909210205\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 70 0.05\n",
      "验证集最优结果： 1.4076037406921387 1.3938333988189697\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 70 0.1\n",
      "验证集最优结果： 2.2303719520568848 2.2193899154663086\n",
      "------------train------------\n",
      " (0.510911048710051, 0.021822097420101938)\n",
      "------------test------------\n",
      " (0.5019387075283145, 0.0035642904730179836)\n",
      "------------oot------------\n",
      " (0.51000938379731, 0.021568831891008944)\n",
      "隐藏层vs神经元数vs norm 3 70 0.2\n",
      "验证集最优结果： 3.9001617431640625 3.8730862140655518\n",
      "------------train------------\n",
      " (0.5004330173349062, 0.0008660346698124381)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.5027337330668443, 0.0054630246502331775)\n",
      "------------oot------------\n",
      " (0.4973679027792259, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 70 0.3\n",
      "验证集最优结果： 5.5408148765563965 5.527397632598877\n",
      "------------train------------\n",
      " (0.4978129172901697, 0.0)\n",
      "------------test------------\n",
      " (0.5003864090606263, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4785307985495661, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 70 0.4\n",
      "验证集最优结果： 7.167417526245117 7.126997470855713\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5016809740613306, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 70 0.5\n",
      "验证集最优结果： 8.850004196166992 8.819908142089844\n",
      "------------train------------\n",
      " (0.49969604863221884, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 70 0.8\n",
      "验证集最优结果： 13.837809562683105 13.82414722442627\n",
      "------------train------------\n",
      " (0.49959358094777867, 0.0)\n",
      "------------test------------\n",
      " (0.5000510770597378, 0.0009771263602043083)\n",
      "------------oot------------\n",
      " (0.4999988415065049, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 3 72 0.01\n",
      "验证集最优结果： 0.7511275410652161 0.7394814491271973\n",
      "------------train------------\n",
      " (0.5000064972904268, 1.2994580853686877e-05)\n",
      "------------test------------\n",
      " (0.5005551854319342, 0.0012769264934487934)\n",
      "------------oot------------\n",
      " (0.4843881416605846, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 72 0.05\n",
      "验证集最优结果： 1.4357649087905884 1.4193960428237915\n",
      "------------train------------\n",
      " (0.5003039513677812, 0.0006079027355623268)\n",
      "------------test------------\n",
      " (0.5, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 72 0.1\n",
      "验证集最优结果： 2.286973714828491 2.2736456394195557\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 72 0.2\n",
      "验证集最优结果： 4.001511573791504 3.9769182205200195\n",
      "------------train------------\n",
      " (0.5007882025449075, 0.0015764050898148876)\n",
      "------------test------------\n",
      " (0.5022951365756163, 0.004585831667777038)\n",
      "------------oot------------\n",
      " (0.5009696590553645, 0.0019671219546102256)\n",
      "隐藏层vs神经元数vs norm 3 72 0.3\n",
      "验证集最优结果： 5.712157249450684 5.68355131149292\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 72 0.4\n",
      "验证集最优结果： 7.332736492156982 7.279885292053223\n",
      "------------train------------\n",
      " (0.48903521328371025, 0.0)\n",
      "------------test------------\n",
      " (0.5055718409948923, 0.010481900954918966)\n",
      "------------oot------------\n",
      " (0.5017782875149156, 0.004128870816390351)\n",
      "隐藏层vs神经元数vs norm 3 72 0.5\n",
      "验证集最优结果： 9.091114044189453 9.057263374328613\n",
      "------------train------------\n",
      " (0.5031668876422213, 0.005407099237312862)\n",
      "------------test------------\n",
      " (0.5000810570730624, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5073877130179913, 0.01671706113370164)\n",
      "隐藏层vs神经元数vs norm 3 72 0.8\n",
      "验证集最优结果： 14.239052772521973 14.201338768005371\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 74 0.01\n",
      "验证集最优结果： 0.75604647397995 0.7440687417984009\n",
      "------------train------------\n",
      " (0.49991871618955575, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 74 0.05\n",
      "验证集最优结果： 1.4579107761383057 1.445198893547058\n",
      "------------train------------\n",
      " (0.49572742242336754, 0.0)\n",
      "------------test------------\n",
      " (0.49130024428159, 0.0)\n",
      "------------oot------------\n",
      " (0.4952652370856937, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 74 0.1\n",
      "验证集最优结果： 2.3322510719299316 2.314239025115967\n",
      "------------train------------\n",
      " (0.4995546648853262, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.49808385175917247, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 74 0.2\n",
      "验证集最优结果： 4.0885233879089355 4.0701141357421875\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4985657850531169, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 74 0.3\n",
      "验证集最优结果： 5.845839500427246 5.818585395812988\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 74 0.4\n",
      "验证集最优结果： 7.529623985290527 7.483026027679443\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 74 0.5\n",
      "验证集最优结果： 9.372471809387207 9.338834762573242\n",
      "------------train------------\n",
      " (0.5212605555589396, 0.04252111111787904)\n",
      "------------test------------\n",
      " (0.5389296024872308, 0.07785920497446142)\n",
      "------------oot------------\n",
      " (0.5430565692373637, 0.08699822750495251)\n",
      "隐藏层vs神经元数vs norm 3 74 0.8\n",
      "验证集最优结果： 14.648767471313477 14.62364387512207\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.49808616874616257, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 76 0.01\n",
      "验证集最优结果： 0.7613696455955505 0.7497608065605164\n",
      "------------train------------\n",
      " (0.5016468600828811, 0.0032937201657621262)\n",
      "------------test------------\n",
      " (0.5010604041749944, 0.0012547190761713622)\n",
      "------------oot------------\n",
      " (0.5043026448406492, 0.012421367254022875)\n",
      "隐藏层vs神经元数vs norm 3 76 0.05\n",
      "验证集最优结果： 1.483243465423584 1.470015525817871\n",
      "------------train------------\n",
      " (0.5028143419564559, 0.005628683912911936)\n",
      "------------test------------\n",
      " (0.4817343992893627, 0.0)\n",
      "------------oot------------\n",
      " (0.5114076854458462, 0.023174503875160735)\n",
      "隐藏层vs神经元数vs norm 3 76 0.1\n",
      "验证集最优结果： 2.371718645095825 2.34810471534729\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 76 0.2\n",
      "验证集最优结果： 4.202335834503174 4.177832126617432\n",
      "------------train------------\n",
      " (0.49988866622133155, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5031128720212236, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 3 76 0.3\n",
      "验证集最优结果： 5.999667644500732 5.982190132141113\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.49808616874616257, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 76 0.4\n",
      "验证集最优结果： 7.807078838348389 7.787549018859863\n",
      "------------train------------\n",
      " (0.49542408017656386, 0.0)\n",
      "------------test------------\n",
      " (0.4964756828780813, 0.0)\n",
      "------------oot------------\n",
      " (0.5152399819275014, 0.029750112953115804)\n",
      "隐藏层vs神经元数vs norm 3 76 0.5\n",
      "验证集最优结果： 9.61950969696045 9.603081703186035\n",
      "------------train------------\n",
      " (0.5094479401220543, 0.018895880244108654)\n",
      "------------test------------\n",
      " (0.5131467910282034, 0.026904286031534497)\n",
      "------------oot------------\n",
      " (0.49578424217148015, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 76 0.8\n",
      "验证集最优结果： 14.953243255615234 14.841995239257812\n",
      "------------train------------\n",
      " (0.49422106624596707, 0.0)\n",
      "------------test------------\n",
      " (0.4729358205640684, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4886641411508474, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 78 0.01\n",
      "验证集最优结果： 0.7671613693237305 0.7553612589836121\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 78 0.05\n",
      "验证集最优结果： 1.510654330253601 1.4957771301269531\n",
      "------------train------------\n",
      " (0.4994132811384336, 0.0)\n",
      "------------test------------\n",
      " (0.4982456140350877, 0.0)\n",
      "------------oot------------\n",
      " (0.5004691898654989, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 78 0.1\n",
      "验证集最优结果： 2.434474468231201 2.4188032150268555\n",
      "------------train------------\n",
      " (0.4990970119908848, 0.0)\n",
      "------------test------------\n",
      " (0.4996124805685099, 9.993337774816778e-05)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.5038380889491305, 0.003864734299516908)\n",
      "隐藏层vs神经元数vs norm 3 78 0.2\n",
      "验证集最优结果： 4.319129467010498 4.290152072906494\n",
      "------------train------------\n",
      " (0.5022636289126717, 0.004527257825343356)\n",
      "------------test------------\n",
      " (0.49940817232955803, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4971072417428376, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 78 0.3\n",
      "验证集最优结果： 6.152756214141846 6.126825332641602\n",
      "------------train------------\n",
      " (0.5142909256540775, 0.028581851308154993)\n",
      "------------test------------\n",
      " (0.49638241172551634, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.5125047787856671, 0.026782052618774532)\n",
      "隐藏层vs神经元数vs norm 3 78 0.4\n",
      "验证集最优结果： 8.013418197631836 7.973225116729736\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 78 0.5\n",
      "验证集最优结果： 9.888482093811035 9.84739875793457\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5007171074734416, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 78 0.8\n",
      "验证集最优结果： 15.30978775024414 15.188728332519531\n",
      "------------train------------\n",
      " (0.4893961513029436, 0.0)\n",
      "------------test------------\n",
      " (0.49541305796135915, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.47785076286796646, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 80 0.01\n",
      "验证集最优结果： 0.7713554501533508 0.7591781616210938\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019173067343227, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 80 0.05\n",
      "验证集最优结果： 1.5367802381515503 1.5221388339996338\n",
      "------------train------------\n",
      " (0.5033054965046607, 0.006610993009321581)\n",
      "------------test------------\n",
      " (0.49795247612702637, 0.0)\n",
      "------------oot------------\n",
      " (0.5068281606598778, 0.010113648211865292)\n",
      "隐藏层vs神经元数vs norm 3 80 0.1\n",
      "验证集最优结果： 2.4903833866119385 2.4740514755249023\n",
      "------------train------------\n",
      " (0.5001113337786685, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 80 0.2\n",
      "验证集最优结果： 4.4062275886535645 4.375786304473877\n",
      "------------train------------\n",
      " (0.48894621394088417, 0.0)\n",
      "------------test------------\n",
      " (0.49586164779036196, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5085531574740209, 0.018600771556667728)\n",
      "隐藏层vs神经元数vs norm 3 80 0.3\n",
      "验证集最优结果： 6.335906505584717 6.299737453460693\n",
      "------------train------------\n",
      " (0.4933934738778468, 0.0)\n",
      "------------test------------\n",
      " (0.5119586942038641, 0.024083944037308513)\n",
      "------------oot------------\n",
      " (0.4891310140293562, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 80 0.4\n",
      "验证集最优结果： 8.225768089294434 8.199358940124512\n",
      "------------train------------\n",
      " (0.5075766527990124, 0.015153305598024858)\n",
      "------------test------------\n",
      " (0.5033733066844326, 0.0059515878303353364)\n",
      "------------oot------------\n",
      " (0.5034882239136227, 0.010572411635908607)\n",
      "隐藏层vs神经元数vs norm 3 80 0.5\n",
      "验证集最优结果： 10.106184005737305 10.085392951965332\n",
      "------------train------------\n",
      " (0.4996413631044595, 0.0)\n",
      "------------test------------\n",
      " (0.501469020652898, 0.0029313790806129248)\n",
      "------------oot------------\n",
      " (0.501925416188788, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 80 0.8\n",
      "验证集最优结果： 15.813044548034668 15.70665168762207\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 82 0.01\n",
      "验证集最优结果： 0.7759841680526733 0.7649958729743958\n",
      "------------train------------\n",
      " (0.49988866622133155, 0.0)\n",
      "------------test------------\n",
      " (0.49912280701754386, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 82 0.05\n",
      "验证集最优结果： 1.5537939071655273 1.5347907543182373\n",
      "------------train------------\n",
      " (0.48880983852202886, 0.0)\n",
      "------------test------------\n",
      " (0.48815567399511434, 0.0)\n",
      "------------oot------------\n",
      " (0.4927617326428712, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 82 0.1\n",
      "验证集最优结果： 2.5410728454589844 2.527226209640503\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 82 0.2\n",
      "验证集最优结果： 4.51133918762207 4.488141059875488\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 82 0.3\n",
      "验证集最优结果： 6.488507270812988 6.462447166442871\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 82 0.4\n",
      "验证集最优结果： 8.3685941696167 8.295877456665039\n",
      "------------train------------\n",
      " (0.5043296995883019, 0.0086593991766038)\n",
      "------------test------------\n",
      " (0.5022951365756163, 0.0054630246502331775)\n",
      "------------oot------------\n",
      " (0.5043269732040454, 0.004865672679247906)\n",
      "隐藏层vs神经元数vs norm 3 82 0.5\n",
      "验证集最优结果： 10.259698867797852 10.100885391235352\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 82 0.8\n",
      "验证集最优结果： 16.293903350830078 16.262548446655273\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 84 0.01\n",
      "验证集最优结果： 0.7819738388061523 0.7707013487815857\n",
      "------------train------------\n",
      " (0.49975513336703803, 0.0)\n",
      "------------test------------\n",
      " (0.5043981789917832, 0.00873861869864534)\n",
      "------------oot------------\n",
      " (0.5036909602752581, 0.005213220727765616)\n",
      "隐藏层vs神经元数vs norm 3 84 0.05\n",
      "验证集最优结果： 1.5888638496398926 1.5732835531234741\n",
      "------------train------------\n",
      " (0.5000070387312958, 1.4077462591521872e-05)\n",
      "------------test------------\n",
      " (0.4799800133244504, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4849048297593809, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 84 0.1\n",
      "验证集最优结果： 2.5899486541748047 2.580721616744995\n",
      "------------train------------\n",
      " (0.498963005375831, 0.0)\n",
      "------------test------------\n",
      " (0.5072218520986009, 0.014434821230290917)\n",
      "------------oot------------\n",
      " (0.500765764200234, 0.0016404267890035816)\n",
      "隐藏层vs神经元数vs norm 3 84 0.2\n",
      "验证集最优结果： 4.6124372482299805 4.595137596130371\n",
      "------------train------------\n",
      " (0.5109460393262039, 0.02189207865240783)\n",
      "------------test------------\n",
      " (0.5064956695536309, 0.01274705751721078)\n",
      "------------oot------------\n",
      " (0.5276242773896824, 0.05272303896013625)\n",
      "隐藏层vs神经元数vs norm 3 84 0.3\n",
      "验证集最优结果： 6.620643138885498 6.597201824188232\n",
      "------------train------------\n",
      " (0.4991906135810967, 0.0)\n",
      "------------test------------\n",
      " (0.4986842105263158, 0.0)\n",
      "------------oot------------\n",
      " (0.49784056812521, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 84 0.4\n",
      "验证集最优结果： 8.62392520904541 8.586747169494629\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 84 0.5\n",
      "验证集最优结果： 10.70809555053711 10.65097427368164\n",
      "------------train------------\n",
      " (0.5014236510846753, 0.0028473021693505296)\n",
      "------------test------------\n",
      " (0.5057650455252054, 0.011470131023761931)\n",
      "------------oot------------\n",
      " (0.5015882945817259, 0.0035241372119695497)\n",
      "隐藏层vs神经元数vs norm 3 84 0.8\n",
      "验证集最优结果： 16.565757751464844 16.416322708129883\n",
      "------------train------------\n",
      " (0.49994876615777994, 0.0)\n",
      "------------test------------\n",
      " (0.4982978014656895, 0.0)\n",
      "------------oot------------\n",
      " (0.5, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 86 0.01\n",
      "验证集最优结果： 0.7876142263412476 0.7755883932113647\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 86 0.05\n",
      "验证集最优结果： 1.6105139255523682 1.5963941812515259\n",
      "------------train------------\n",
      " (0.5029365722326111, 0.005873144465222246)\n",
      "------------test------------\n",
      " (0.500566289140573, 0.0011325782811458796)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.4989816842178431, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 86 0.1\n",
      "验证集最优结果： 2.6405582427978516 2.6240410804748535\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019138312538375, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 86 0.2\n",
      "验证集最优结果： 4.66929292678833 4.630545616149902\n",
      "------------train------------\n",
      " (0.5023140505935884, 0.004628101187176714)\n",
      "------------test------------\n",
      " (0.4990195425272041, 0.0)\n",
      "------------oot------------\n",
      " (0.4967515842398545, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 86 0.3\n",
      "验证集最优结果： 6.6396260261535645 6.55553674697876\n",
      "------------train------------\n",
      " (0.4990088248093621, 0.0)\n",
      "------------test------------\n",
      " (0.4978791916500111, 0.0)\n",
      "------------oot------------\n",
      " (0.4997937881578795, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 86 0.4\n",
      "验证集最优结果： 8.843441009521484 8.784064292907715\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 86 0.5\n",
      "验证集最优结果： 10.91458797454834 10.896203994750977\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 86 0.8\n",
      "验证集最优结果： 17.18783950805664 17.13846778869629\n",
      "------------train------------\n",
      " (0.5032168355623777, 0.006433671124755423)\n",
      "------------test------------\n",
      " (0.49294359316011543, 0.0)\n",
      "------------oot------------\n",
      " (0.5036747413663272, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 88 0.01\n",
      "验证集最优结果： 0.7924352884292603 0.7798808217048645\n",
      "------------train------------\n",
      " (0.5115716742502229, 0.023143348500445693)\n",
      "------------test------------\n",
      " (0.5155840550743949, 0.03116811014878973)\n",
      "------------oot------------\n",
      " (0.5112999455508057, 0.023807041323462952)\n",
      "隐藏层vs神经元数vs norm 3 88 0.05\n",
      "验证集最优结果： 1.639484167098999 1.6285783052444458\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 88 0.1\n",
      "验证集最优结果： 2.7029547691345215 2.6797752380371094\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 88 0.2\n",
      "验证集最优结果： 4.787498950958252 4.757875442504883\n",
      "------------train------------\n",
      " (0.49733137331738786, 0.0)\n",
      "------------test------------\n",
      " (0.4906817677104153, 0.0)\n",
      "------------oot------------\n",
      " (0.48078406839745597, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 88 0.3\n",
      "验证集最优结果： 6.950738430023193 6.912356376647949\n",
      "------------train------------\n",
      " (0.5004453351146738, 0.0008906702293475841)\n",
      "------------test------------\n",
      " (0.49912280701754386, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 88 0.4\n",
      "验证集最优结果： 9.050422668457031 9.023512840270996\n",
      "------------train------------\n",
      " (0.5107873294715064, 0.021574658943012692)\n",
      "------------test------------\n",
      " (0.494864534754608, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4729989921106593, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 88 0.5\n",
      "验证集最优结果： 11.184799194335938 11.153633117675781\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 88 0.8\n",
      "验证集最优结果： 17.537302017211914 17.50633430480957\n",
      "------------train------------\n",
      " (0.5035464376913232, 0.0070928753826463575)\n",
      "------------test------------\n",
      " (0.4927781479013991, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.50284410153037, 0.009453306919681714)\n",
      "隐藏层vs神经元数vs norm 3 90 0.01\n",
      "验证集最优结果： 0.79848313331604 0.7854531407356262\n",
      "------------train------------\n",
      " (0.49840782544487827, 0.0)\n",
      "------------test------------\n",
      " (0.4988374417055296, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4973679027792259, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 90 0.05\n",
      "验证集最优结果： 1.6663252115249634 1.6501802206039429\n",
      "------------train------------\n",
      " (0.5007788626899189, 0.0015577253798377821)\n",
      "------------test------------\n",
      " (0.5058427714856761, 0.011736620031090328)\n",
      "------------oot------------\n",
      " (0.500882772043235, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 90 0.1\n",
      "验证集最优结果： 2.747413158416748 2.737555742263794\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 90 0.2\n",
      "验证集最优结果： 4.916966438293457 4.903257369995117\n",
      "------------train------------\n",
      " (0.4994425189453544, 0.0)\n",
      "------------test------------\n",
      " (0.5167466133688652, 0.03383300022207414)\n",
      "------------oot------------\n",
      " (0.5202122360082948, 0.039022694887568155)\n",
      "隐藏层vs神经元数vs norm 3 90 0.3\n",
      "验证集最优结果： 7.0860514640808105 7.077842712402344\n",
      "------------train------------\n",
      " (0.500273901399557, 0.0005478027991139278)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4992828925265585, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 90 0.4\n",
      "验证集最优结果： 9.275615692138672 9.23661994934082\n",
      "------------train------------\n",
      " (0.5001113337786685, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.5, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4968871279787765, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 90 0.5\n",
      "验证集最优结果： 11.4405517578125 11.401277542114258\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 90 0.8\n",
      "验证集最优结果： 17.988201141357422 17.895069122314453\n",
      "------------train------------\n",
      " (0.5047549337107176, 0.009509867421435225)\n",
      "------------test------------\n",
      " (0.5053497668221185, 0.010848323339995525)\n",
      "------------oot------------\n",
      " (0.4836223774603505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 92 0.01\n",
      "验证集最优结果： 0.8032458424568176 0.7912676930427551\n",
      "------------train------------\n",
      " (0.5035645759604315, 0.007129151920862997)\n",
      "------------test------------\n",
      " (0.5041761048190095, 0.009105041083721954)\n",
      "------------oot------------\n",
      " (0.5019520615391745, 0.004545928474611605)\n",
      "隐藏层vs神经元数vs norm 3 92 0.05\n",
      "验证集最优结果： 1.6824814081192017 1.66423761844635\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 92 0.1\n",
      "验证集最优结果： 2.8065402507781982 2.7950046062469482\n",
      "------------train------------\n",
      " (0.5142488286265202, 0.028428758902472318)\n",
      "------------test------------\n",
      " (0.502195203197868, 0.004763491005996046)\n",
      "------------oot------------\n",
      " (0.5045355020331561, 0.011288360615855142)\n",
      "隐藏层vs神经元数vs norm 3 92 0.2\n",
      "验证集最优结果： 5.023474216461182 5.0155720710754395\n",
      "------------train------------\n",
      " (0.49704968870534044, 0.0)\n",
      "------------test------------\n",
      " (0.4986209193870753, 0.0)\n",
      "------------oot------------\n",
      " (0.5039666817270821, 0.011538595210787927)\n",
      "隐藏层vs神经元数vs norm 3 92 0.3\n",
      "验证集最优结果： 7.249409198760986 7.225559234619141\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 92 0.4\n",
      "验证集最优结果： 9.471334457397461 9.444440841674805\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 92 0.5\n",
      "验证集最优结果： 11.596323013305664 11.514080047607422\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 92 0.8\n",
      "验证集最优结果： 18.413259506225586 18.373233795166016\n",
      "------------train------------\n",
      " (0.5173998114432174, 0.03479962288643479)\n",
      "------------test------------\n",
      " (0.5211203642016433, 0.04263824117255155)\n",
      "------------oot------------\n",
      " (0.5300154079634842, 0.062433531435720946)\n",
      "隐藏层vs神经元数vs norm 3 94 0.01\n",
      "验证集最优结果： 0.8077602386474609 0.7957675457000732\n",
      "------------train------------\n",
      " (0.4831282287641816, 0.0)\n",
      "------------test------------\n",
      " (0.5196302465023318, 0.041128136797690396)\n",
      "------------oot------------\n",
      " (0.47839988878462447, 0.0023980815347721673)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 3 94 0.05\n",
      "验证集最优结果： 1.7178106307983398 1.705693006515503\n",
      "------------train------------\n",
      " (0.4954683429675968, 0.0)\n",
      "------------test------------\n",
      " (0.5024361536753276, 0.0049189429269375085)\n",
      "------------oot------------\n",
      " (0.4932042771579837, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 94 0.1\n",
      "验证集最优结果： 2.8576292991638184 2.8487496376037598\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 94 0.2\n",
      "验证集最优结果： 5.1356611251831055 5.1225714683532715\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019173067343227, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 94 0.3\n",
      "验证集最优结果： 7.426336288452148 7.394654750823975\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 94 0.4\n",
      "验证集最优结果： 9.713722229003906 9.703583717346191\n",
      "------------train------------\n",
      " (0.49988866622133155, 0.0)\n",
      "------------test------------\n",
      " (0.5017033089051743, 0.0025316455696202667)\n",
      "------------oot------------\n",
      " (0.49760423545221794, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 94 0.5\n",
      "验证集最优结果： 11.986505508422852 11.963136672973633\n",
      "------------train------------\n",
      " (0.5001113337786685, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 94 0.8\n",
      "验证集最优结果： 18.77125358581543 18.61246109008789\n",
      "------------train------------\n",
      " (0.47659121011357397, 0.0)\n",
      "------------test------------\n",
      " (0.4649822340661781, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5032275628772344, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 96 0.01\n",
      "验证集最优结果： 0.8138160109519958 0.8013122081756592\n",
      "------------train------------\n",
      " (0.499242321184077, 0.0)\n",
      "------------test------------\n",
      " (0.509451476793249, 0.018154563624250497)\n",
      "------------oot------------\n",
      " (0.5088404638607954, 0.017405206269766826)\n",
      "隐藏层vs神经元数vs norm 3 96 0.05\n",
      "验证集最优结果： 1.736966848373413 1.7186706066131592\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 96 0.1\n",
      "验证集最优结果： 2.910505533218384 2.8918120861053467\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5007171074734416, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 96 0.2\n",
      "验证集最优结果： 5.234249114990234 5.22480583190918\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 96 0.3\n",
      "验证集最优结果： 7.5543317794799805 7.535562992095947\n",
      "------------train------------\n",
      " (0.48791497212594737, 0.0)\n",
      "------------test------------\n",
      " (0.4801754385964912, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4787497538201323, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 96 0.4\n",
      "验证集最优结果： 9.813340187072754 9.755782127380371\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 96 0.5\n",
      "验证集最优结果： 12.244421005249023 12.222187042236328\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 96 0.8\n",
      "验证集最优结果： 19.212303161621094 19.18580436706543\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 98 0.01\n",
      "验证集最优结果： 0.8184565305709839 0.806304931640625\n",
      "------------train------------\n",
      " (0.49411832784109255, 0.0)\n",
      "------------test------------\n",
      " (0.49323673106817684, 0.0)\n",
      "------------oot------------\n",
      " (0.4942990535108145, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 98 0.05\n",
      "验证集最优结果： 1.7597901821136475 1.744065284729004\n",
      "------------train------------\n",
      " (0.49350961294422685, 0.0)\n",
      "------------test------------\n",
      " (0.49811792138574285, 0.0)\n",
      "------------oot------------\n",
      " (0.4890394930432465, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 98 0.1\n",
      "验证集最优结果： 2.9642040729522705 2.9459471702575684\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 98 0.2\n",
      "验证集最优结果： 5.353649139404297 5.326343536376953\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 98 0.3\n",
      "验证集最优结果： 7.731087684631348 7.699921131134033\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 98 0.4\n",
      "验证集最优结果： 10.1408109664917 10.084600448608398\n",
      "------------train------------\n",
      " (0.5094888865877651, 0.0189777731755304)\n",
      "------------test------------\n",
      " (0.5102775927159672, 0.02037530535198756)\n",
      "------------oot------------\n",
      " (0.49437551408148844, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 98 0.5\n",
      "验证集最优结果： 12.529130935668945 12.486902236938477\n",
      "------------train------------\n",
      " (0.49988866622133155, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 98 0.8\n",
      "验证集最优结果： 19.634843826293945 19.58574104309082\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.4996124805685099, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 100 0.01\n",
      "验证集最优结果： 0.8241993188858032 0.8126082420349121\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 100 0.05\n",
      "验证集最优结果： 1.800850749015808 1.783434510231018\n",
      "------------train------------\n",
      " (0.500443372391524, 0.0008867447830480657)\n",
      "------------test------------\n",
      " (0.498428825227626, 0.0)\n",
      "------------oot------------\n",
      " (0.5016543287109443, 0.0056580822298683)\n",
      "隐藏层vs神经元数vs norm 3 100 0.1\n",
      "验证集最优结果： 3.016052722930908 3.002488136291504\n",
      "------------train------------\n",
      " (0.4999699500317758, 0.0)\n",
      "------------test------------\n",
      " (0.49912280701754386, 0.0)\n",
      "------------oot------------\n",
      " (0.5031151890082137, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 3 100 0.2\n",
      "验证集最优结果： 5.4114298820495605 5.368878364562988\n",
      "------------train------------\n",
      " (0.5201315836671654, 0.04026316733433094)\n",
      "------------test------------\n",
      " (0.5190317566067066, 0.03806351321341328)\n",
      "------------oot------------\n",
      " (0.5347200500469189, 0.070559204810065)\n",
      "隐藏层vs神经元数vs norm 3 100 0.3\n",
      "验证集最优结果： 7.938259601593018 7.900066375732422\n",
      "------------train------------\n",
      " (0.5002527175255611, 0.0005054350511221699)\n",
      "------------test------------\n",
      " (0.5000510770597378, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4983213429256595, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 100 0.4\n",
      "验证集最优结果： 10.35852336883545 10.312982559204102\n",
      "------------train------------\n",
      " (0.4992896295799975, 0.0)\n",
      "------------test------------\n",
      " (0.4996124805685099, 9.993337774816778e-05)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 100 0.5\n",
      "验证集最优结果： 12.591506958007812 12.408059120178223\n",
      "------------train------------\n",
      " (0.5009118541033435, 0.0018237082066869803)\n",
      "------------test------------\n",
      " (0.49912280701754386, 0.0)\n",
      "------------oot------------\n",
      " (0.4966403688643289, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 100 0.8\n",
      "验证集最优结果： 20.145076751708984 20.072446823120117\n",
      "------------train------------\n",
      " (0.5000460901539656, 0.0006079027355623268)\n",
      "------------test------------\n",
      " (0.5044370419720186, 0.008871863202309573)\n",
      "------------oot------------\n",
      " (0.5026402066752396, 0.002933305529489452)\n",
      "隐藏层vs神经元数vs norm 3 130 0.01\n",
      "验证集最优结果： 0.9069738984107971 0.893801748752594\n",
      "------------train------------\n",
      " (0.5021522951340033, 0.004304590268006447)\n",
      "------------test------------\n",
      " (0.49551188096824333, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.5043026448406492, 0.00859138775935775)\n",
      "隐藏层vs神经元数vs norm 3 130 0.05\n",
      "验证集最优结果： 2.2159881591796875 2.199915647506714\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019173067343227, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 130 0.1\n",
      "验证集最优结果： 3.85155987739563 3.8276402950286865\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 130 0.2\n",
      "验证集最优结果： 7.113237380981445 7.0809407234191895\n",
      "------------train------------\n",
      " (0.49695310919034963, 0.0)\n",
      "------------test------------\n",
      " (0.4962824783477682, 0.0)\n",
      "------------oot------------\n",
      " (0.4966021385789919, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 130 0.3\n",
      "验证集最优结果： 10.391087532043457 10.36337661743164\n",
      "------------train------------\n",
      " (0.4995034310431061, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 130 0.4\n",
      "验证集最优结果： 13.536312103271484 13.453274726867676\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 130 0.5\n",
      "验证集最优结果： 16.900426864624023 16.868671417236328\n",
      "------------train------------\n",
      " (0.4996448147899988, 0.0)\n",
      "------------test------------\n",
      " (0.4983477681545636, 0.0)\n",
      "------------oot------------\n",
      " (0.4980826932656774, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 130 0.8\n",
      "验证集最优结果： 26.710418701171875 26.710891723632812\n",
      "------------train------------\n",
      " (0.5087677550304933, 0.01829488087962483)\n",
      "------------test------------\n",
      " (0.5188074616922053, 0.039540306462358454)\n",
      "------------oot------------\n",
      " (0.49478446228524425, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 160 0.01\n",
      "验证集最优结果： 0.9933315515518188 0.9796982407569885\n",
      "------------train------------\n",
      " (0.5157992445546278, 0.031598489109255334)\n",
      "------------test------------\n",
      " (0.5139618032422829, 0.02739284921163665)\n",
      "------------oot------------\n",
      " (0.5242461103580903, 0.04844124700239805)\n",
      "隐藏层vs神经元数vs norm 3 160 0.05\n",
      "验证集最优结果： 2.6462759971618652 2.632131576538086\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4995192251995505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 160 0.1\n",
      "验证集最优结果： 4.727630615234375 4.700766563415527\n",
      "------------train------------\n",
      " (0.4914750135191017, 0.0)\n",
      "------------test------------\n",
      " (0.4963690872751499, 0.0)\n",
      "------------oot------------\n",
      " (0.492795328954228, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 160 0.2\n",
      "验证集最优结果： 8.870200157165527 8.837935447692871\n",
      "------------train------------\n",
      " (0.5295445331730668, 0.059089066346133645)\n",
      "------------test------------\n",
      " (0.5041505662891406, 0.007739284921163714)\n",
      "------------oot------------\n",
      " (0.533486254474681, 0.06581864942828342)\n",
      "隐藏层vs神经元数vs norm 3 160 0.3\n",
      "验证集最优结果： 13.005521774291992 12.998950004577637\n",
      "------------train------------\n",
      " (0.5021836987043996, 0.004148926018196386)\n",
      "------------test------------\n",
      " (0.49876526759937817, 0.0)\n",
      "------------oot------------\n",
      " (0.5018929783709264, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 160 0.4\n",
      "验证集最优结果： 17.168289184570312 17.0952091217041\n",
      "------------train------------\n",
      " (0.502294355681982, 0.004804069469570682)\n",
      "------------test------------\n",
      " (0.5037852542749278, 0.007539418165667333)\n",
      "------------oot------------\n",
      " (0.5019798653830558, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 160 0.5\n",
      "验证集最优结果： 21.26286506652832 21.241783142089844\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.49808616874616257, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 160 0.8\n",
      "验证集最优结果： 33.69279861450195 33.61400604248047\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5008771929824561, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.50000231698699, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 190 0.01\n",
      "验证集最优结果： 1.0851976871490479 1.0710936784744263\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 190 0.05\n",
      "验证集最优结果： 3.1018428802490234 3.0898616313934326\n",
      "------------train------------\n",
      " (0.5084726697569404, 0.016945339513880844)\n",
      "------------test------------\n",
      " (0.5018687541638907, 0.003675327559404834)\n",
      "------------oot------------\n",
      " (0.5041879539846383, 0.006248913912348386)\n",
      "隐藏层vs神经元数vs norm 3 190 0.1\n",
      "验证集最优结果： 5.623610496520996 5.612193584442139\n",
      "------------train------------\n",
      " (0.49909748575164514, 0.0)\n",
      "------------test------------\n",
      " (0.4975216522318454, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 3 190 0.2\n",
      "验证集最优结果： 10.691444396972656 10.65976333618164\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 190 0.3\n",
      "验证集最优结果： 15.791322708129883 15.714018821716309\n",
      "------------train------------\n",
      " (0.5017232032453965, 0.003453309861871666)\n",
      "------------test------------\n",
      " (0.4967088607594936, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019312086562633, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 190 0.4\n",
      "验证集最优结果： 20.631439208984375 20.50313949584961\n",
      "------------train------------\n",
      " (0.5009319550956015, 0.0015833084608933845)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.002631578947368421)\n",
      "------------oot------------\n",
      " (0.5028684298937661, 0.005727591839571833)\n",
      "隐藏层vs神经元数vs norm 3 190 0.5\n",
      "验证集最优结果： 25.979738235473633 25.8665714263916\n",
      "------------train------------\n",
      " (0.5001926175891127, 0.0003852351782254182)\n",
      "------------test------------\n",
      " (0.49912280701754386, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 190 0.8\n",
      "验证集最优结果： 40.73580551147461 40.42959213256836\n",
      "------------train------------\n",
      " (0.49988866622133155, 0.0)\n",
      "------------test------------\n",
      " (0.4986842105263158, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 220 0.01\n",
      "验证集最优结果： 1.1795251369476318 1.1659526824951172\n",
      "------------train------------\n",
      " (0.504034614314749, 0.007932514810099711)\n",
      "------------test------------\n",
      " (0.49576060404174993, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5070239460605429, 0.015549299690682195)\n",
      "隐藏层vs神经元数vs norm 3 220 0.05\n",
      "验证集最优结果： 3.580204486846924 3.562861919403076\n",
      "------------train------------\n",
      " (0.5008094540990119, 0.003460213232950196)\n",
      "------------test------------\n",
      " (0.5013701976460138, 0.005363091272485011)\n",
      "------------oot------------\n",
      " (0.4971338870932239, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 220 0.1\n",
      "验证集最优结果： 6.615160942077637 6.57729434967041\n",
      "------------train------------\n",
      " (0.5034635972383809, 0.006927194476761683)\n",
      "------------test------------\n",
      " (0.4952576060404175, 0.0)\n",
      "------------oot------------\n",
      " (0.5165977363037105, 0.031682480102874236)\n",
      "隐藏层vs神经元数vs norm 3 220 0.2\n",
      "验证集最优结果： 12.641663551330566 12.575973510742188\n",
      "------------train------------\n",
      " (0.5004064190522213, 0.0008128381044425481)\n",
      "------------test------------\n",
      " (0.4977559404841217, 0.0)\n",
      "------------oot------------\n",
      " (0.49784056812521, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 220 0.3\n",
      "验证集最优结果： 18.609668731689453 18.58529281616211\n",
      "------------train------------\n",
      " (0.4979339293243698, 0.0)\n",
      "------------test------------\n",
      " (0.4941960914945592, 0.0)\n",
      "------------oot------------\n",
      " (0.49397004135821776, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 220 0.4\n",
      "验证集最优结果： 24.58435821533203 24.564800262451172\n",
      "------------train------------\n",
      " (0.49950275424202, 0.0)\n",
      "------------test------------\n",
      " (0.5192782589384854, 0.03912946924272703)\n",
      "------------oot------------\n",
      " (0.5214367636325721, 0.04044069092552044)\n",
      "隐藏层vs神经元数vs norm 3 220 0.5\n",
      "验证集最优结果： 30.673519134521484 30.641813278198242\n",
      "------------train------------\n",
      " (0.4997773324426631, 0.0)\n",
      "------------test------------\n",
      " (0.4986842105263158, 0.0)\n",
      "------------oot------------\n",
      " (0.5016809740613306, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 220 0.8\n",
      "验证集最优结果： 48.68503952026367 48.64574432373047\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5008771929824561, 0.0017543859649122807)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 250 0.01\n",
      "验证集最优结果： 1.2805962562561035 1.2652474641799927\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.4983190259386694, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 3 250 0.05\n",
      "验证集最优结果： 4.0909810066223145 4.064965724945068\n",
      "------------train------------\n",
      " (0.4998251145993439, 0.0)\n",
      "------------test------------\n",
      " (0.49878858538751936, 0.0)\n",
      "------------oot------------\n",
      " (0.499763667327008, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 250 0.1\n",
      "验证集最优结果： 7.6120781898498535 7.57620096206665\n",
      "------------train------------\n",
      " (0.4948175987232824, 6.0099936448378024e-05)\n",
      "------------test------------\n",
      " (0.507677104152787, 0.013846324672440624)\n",
      "------------oot------------\n",
      " (0.5096247639569503, 0.01723143224550794)\n",
      "隐藏层vs神经元数vs norm 3 250 0.2\n",
      "验证集最优结果： 14.672524452209473 14.617083549499512\n",
      "------------train------------\n",
      " (0.4980119644896006, 0.0)\n",
      "------------test------------\n",
      " (0.4868709749056185, 0.010526315789473684)\n",
      "------------oot------------\n",
      " (0.5061608684067238, 0.012935738365829064)\n",
      "隐藏层vs神经元数vs norm 3 250 0.3\n",
      "验证集最优结果： 21.628862380981445 21.597734451293945\n",
      "------------train------------\n",
      " (0.4802916200519919, 0.0)\n",
      "------------test------------\n",
      " (0.4958894070619587, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5147603656205471, 0.029673652382441906)\n",
      "隐藏层vs神经元数vs norm 3 250 0.4\n",
      "验证集最优结果： 28.455379486083984 28.255451202392578\n",
      "------------train------------\n",
      " (0.5006803204517782, 0.001360640903556476)\n",
      "------------test------------\n",
      " (0.4982456140350877, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5026320972207742, 0.006693775414451153)\n",
      "隐藏层vs神经元数vs norm 3 250 0.5\n",
      "验证集最优结果： 35.4236946105957 35.21221160888672\n",
      "------------train------------\n",
      " (0.5039582711522336, 0.007939282820961124)\n",
      "------------test------------\n",
      " (0.5225605152120808, 0.04460359760159893)\n",
      "------------oot------------\n",
      " (0.49407662275976316, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 250 0.8\n",
      "验证集最优结果： 56.84318923950195 56.77377700805664\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 280 0.01\n",
      "验证集最优结果： 1.383252739906311 1.368088960647583\n",
      "------------train------------\n",
      " (0.5093686190347599, 0.018551523851485507)\n",
      "------------test------------\n",
      " (0.5084199422607151, 0.016988674217188526)\n",
      "------------oot------------\n",
      " (0.5128662287561255, 0.02888819379279184)\n",
      "隐藏层vs神经元数vs norm 3 280 0.05\n",
      "验证集最优结果： 4.616425514221191 4.586809158325195\n",
      "------------train------------\n",
      " (0.49632205985764166, 0.0)\n",
      "------------test------------\n",
      " (0.49240839440373085, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5078499519225199, 0.015577103534563652)\n",
      "隐藏层vs神经元数vs norm 3 280 0.1\n",
      "验证集最优结果： 8.637636184692383 8.628167152404785\n",
      "------------train------------\n",
      " (0.5059691148592355, 0.010438844592257746)\n",
      "------------test------------\n",
      " (0.4901410170997113, 0.0)\n",
      "------------oot------------\n",
      " (0.5100731009395383, 0.030688492684113666)\n",
      "隐藏层vs神经元数vs norm 3 280 0.2\n",
      "验证集最优结果： 16.71157455444336 16.682464599609375\n",
      "------------train------------\n",
      " (0.5133401554882815, 0.026562682947793514)\n",
      "------------test------------\n",
      " (0.5189340439706862, 0.03807461692205205)\n",
      "------------oot------------\n",
      " (0.5236657051170657, 0.04671045772077986)\n",
      "隐藏层vs神经元数vs norm 3 280 0.3\n",
      "验证集最优结果： 24.851266860961914 24.774892807006836\n",
      "------------train------------\n",
      " (0.5003852351782254, 0.0007704703564508364)\n",
      "------------test------------\n",
      " (0.4986842105263158, 0.0)\n",
      "------------oot------------\n",
      " (0.5004807748004496, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 280 0.4\n",
      "验证集最优结果： 32.611751556396484 32.43745040893555\n",
      "------------train------------\n",
      " (0.49976433786180935, 0.0007704703564508364)\n",
      "------------test------------\n",
      " (0.49685987119697983, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5142853832875728, 0.028394675563896743)\n",
      "隐藏层vs神经元数vs norm 3 280 0.5\n",
      "验证集最优结果： 40.60317611694336 40.29814910888672\n",
      "------------train------------\n",
      " (0.49602311681789785, 2.463555953513552e-05)\n",
      "------------test------------\n",
      " (0.49537197423939594, 0.0029313790806129248)\n",
      "------------oot------------\n",
      " (0.502177967770711, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 280 0.8\n",
      "验证集最优结果： 65.28616333007812 65.14949798583984\n",
      "------------train------------\n",
      " (0.5009350683805978, 0.0018701367611955177)\n",
      "------------test------------\n",
      " (0.49726515656229175, 0.0)\n",
      "------------oot------------\n",
      " (0.49813482547295496, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 310 0.01\n",
      "验证集最优结果： 1.4933393001556396 1.4775279760360718\n",
      "------------train------------\n",
      " (0.4996375730183772, 0.0008906702293475841)\n",
      "------------test------------\n",
      " (0.5016133688652009, 0.00571840994892292)\n",
      "------------oot------------\n",
      " (0.4922751653749464, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 310 0.05\n",
      "验证集最优结果： 5.165860652923584 5.130870342254639\n",
      "------------train------------\n",
      " (0.500510375699051, 0.0006472925587750963)\n",
      "------------test------------\n",
      " (0.49972129691316897, 0.0035087719298245615)\n",
      "------------oot------------\n",
      " (0.4942793591213985, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 310 0.1\n",
      "验证集最优结果： 9.72188949584961 9.6974458694458\n",
      "------------train------------\n",
      " (0.481402724395092, 0.0006009993644837805)\n",
      "------------test------------\n",
      " (0.4723872973573173, 0.0027315123251165888)\n",
      "------------oot------------\n",
      " (0.47529860169835153, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 310 0.2\n",
      "验证集最优结果： 18.893796920776367 18.89417839050293\n",
      "------------train------------\n",
      " (0.49658662140221005, 0.0)\n",
      "------------test------------\n",
      " (0.5014712413946257, 0.002631578947368421)\n",
      "------------oot------------\n",
      " (0.49507061017852383, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 310 0.3\n",
      "验证集最优结果： 27.87076759338379 27.692304611206055\n",
      "------------train------------\n",
      " (0.4994221472326619, 0.0)\n",
      "------------test------------\n",
      " (0.49961359093937374, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4968871279787765, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 310 0.4\n",
      "验证集最优结果： 37.25241470336914 37.21916961669922\n",
      "------------train------------\n",
      " (0.4999187838696644, 6.0099936448378024e-05)\n",
      "------------test------------\n",
      " (0.5008771929824561, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.4992828925265585, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 310 0.5\n",
      "验证集最优结果： 45.983497619628906 45.684852600097656\n",
      "------------train------------\n",
      " (0.510280879218755, 0.020561758437509958)\n",
      "------------test------------\n",
      " (0.5072473906284699, 0.01404619142793695)\n",
      "------------oot------------\n",
      " (0.5085763273439219, 0.015417231432245493)\n",
      "隐藏层vs神经元数vs norm 3 310 0.8\n",
      "验证集最优结果： 73.97918701171875 73.93612670898438\n",
      "------------train------------\n",
      " (0.5, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 340 0.01\n",
      "验证集最优结果： 1.6064879894256592 1.5890817642211914\n",
      "------------train------------\n",
      " (0.5009222768400698, 0.0016109219452075108)\n",
      "------------test------------\n",
      " (0.49488674217188544, 0.0)\n",
      "------------oot------------\n",
      " (0.4987036457790289, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 340 0.05\n",
      "验证集最优结果： 5.718273639678955 5.70201301574707\n",
      "------------train------------\n",
      " (0.5001113337786685, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.4996124805685099, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 340 0.1\n",
      "验证集最优结果： 10.896650314331055 10.850717544555664\n",
      "------------train------------\n",
      " (0.49946992938934265, 0.0)\n",
      "------------test------------\n",
      " (0.50141794359316, 0.0037086386853208966)\n",
      "------------oot------------\n",
      " (0.49857389450758227, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 340 0.2\n",
      "验证集最优结果： 21.03376579284668 20.884170532226562\n",
      "------------train------------\n",
      " (0.5004984639999349, 0.001301353128411481)\n",
      "------------test------------\n",
      " (0.4945081057073063, 0.0043859649122807015)\n",
      "------------oot------------\n",
      " (0.49674347478538905, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 3 340 0.3\n",
      "验证集最优结果： 31.208480834960938 31.015670776367188\n",
      "------------train------------\n",
      " (0.5049062664335765, 0.010169613120195126)\n",
      "------------test------------\n",
      " (0.5022651565622918, 0.007495003331112582)\n",
      "------------oot------------\n",
      " (0.5325212293932969, 0.06248218816251347)\n",
      "隐藏层vs神经元数vs norm 3 340 0.4\n",
      "验证集最优结果： 41.838321685791016 41.78738784790039\n",
      "------------train------------\n",
      " (0.4989314664452173, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.45819564734621365, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.48760064412238313, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 340 0.5\n",
      "验证集最优结果： 52.10426330566406 52.10869216918945\n",
      "------------train------------\n",
      " (0.5005986305606823, 0.0009754057253310577)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4985576755986515, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 340 0.8\n",
      "验证集最优结果： 83.13232421875 83.06993865966797\n",
      "------------train------------\n",
      " (0.5169633424227719, 0.03392668484554384)\n",
      "------------test------------\n",
      " (0.48235287586053743, 0.0)\n",
      "------------oot------------\n",
      " (0.5238000903624926, 0.046182184687032946)\n",
      "隐藏层vs神经元数vs norm 3 370 0.01\n",
      "验证集最优结果： 1.7239820957183838 1.7064768075942993\n",
      "------------train------------\n",
      " (0.49901396849761664, 0.0)\n",
      "------------test------------\n",
      " (0.5027370641794359, 0.002909171663335486)\n",
      "------------oot------------\n",
      " (0.4992782585525783, 0.004726653459840802)\n",
      "隐藏层vs神经元数vs norm 3 370 0.05\n",
      "验证集最优结果： 6.323825359344482 6.288815498352051\n",
      "------------train------------\n",
      " (0.4899828024844014, 8.473549598353447e-05)\n",
      "------------test------------\n",
      " (0.4899966688874084, 0.004863424383744208)\n",
      "------------oot------------\n",
      " (0.4713678332696162, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 370 0.1\n",
      "验证集最优结果： 12.046491622924805 12.021414756774902\n",
      "------------train------------\n",
      " (0.5045196099730701, 0.007624705676127691)\n",
      "------------test------------\n",
      " (0.4878092382855874, 0.0)\n",
      "------------oot------------\n",
      " (0.49028950752441525, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 370 0.2\n",
      "验证集最优结果： 23.551395416259766 23.520248413085938\n",
      "------------train------------\n",
      " (0.48944900946777037, 0.0)\n",
      "------------test------------\n",
      " (0.5016822118587608, 0.0044081723295580355)\n",
      "------------oot------------\n",
      " (0.4861710631494804, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 370 0.3\n",
      "验证集最优结果： 35.063636779785156 35.0378532409668\n",
      "------------train------------\n",
      " (0.5017667892353433, 0.0038592551533327413)\n",
      "------------test------------\n",
      " (0.5026004885631801, 0.005240950477459427)\n",
      "------------oot------------\n",
      " (0.5023795456388512, 0.004726653459840802)\n",
      "隐藏层vs神经元数vs norm 3 370 0.4\n",
      "验证集最优结果： 46.55982971191406 46.51275634765625\n",
      "------------train------------\n",
      " (0.4980574455225886, 0.0)\n",
      "------------test------------\n",
      " (0.49800133244503664, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.49160671462829736, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 370 0.5\n",
      "验证集最优结果： 58.0698127746582 58.02861404418945\n",
      "------------train------------\n",
      " (0.5030909505603576, 0.007517635744301865)\n",
      "------------test------------\n",
      " (0.4863413280035531, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.5009905119382754, 0.008584436798387385)\n",
      "隐藏层vs神经元数vs norm 3 370 0.8\n",
      "验证集最优结果： 91.81922149658203 91.2493896484375\n",
      "------------train------------\n",
      " (0.5001926175891127, 0.0003852351782254182)\n",
      "------------test------------\n",
      " (0.4986842105263158, 0.0)\n",
      "------------oot------------\n",
      " (0.4980850102526675, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 400 0.01\n",
      "验证集最优结果： 1.8458369970321655 1.8274016380310059\n",
      "------------train------------\n",
      " (0.49184305794973937, 0.0002650353053287313)\n",
      "------------test------------\n",
      " (0.5044048412169665, 0.009449256051521193)\n",
      "------------oot------------\n",
      " (0.4870920654780524, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 400 0.05\n",
      "验证集最优结果： 6.9384989738464355 6.898818016052246\n",
      "------------train------------\n",
      " (0.517449014882179, 0.03505220505177867)\n",
      "------------test------------\n",
      " (0.5183333333333333, 0.03684210526315787)\n",
      "------------oot------------\n",
      " (0.5164343887209073, 0.029944739860285674)\n",
      "隐藏层vs神经元数vs norm 3 400 0.1\n",
      "验证集最优结果： 13.327641487121582 13.261962890625\n",
      "------------train------------\n",
      " (0.49593770452082825, 0.0)\n",
      "------------test------------\n",
      " (0.4702465023317788, 0.0)\n",
      "------------oot------------\n",
      " (0.48360500005792467, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 400 0.2\n",
      "验证集最优结果： 26.01618003845215 25.975635528564453\n",
      "------------train------------\n",
      " (0.5147382911720096, 0.022353521632931472)\n",
      "------------test------------\n",
      " (0.5076982011992005, 0.021763268931823232)\n",
      "------------oot------------\n",
      " (0.5271238081998169, 0.03772286518611198)\n",
      "隐藏层vs神经元数vs norm 3 400 0.3\n",
      "验证集最优结果： 38.843509674072266 38.71311569213867\n",
      "------------train------------\n",
      " (0.5018911175948655, 0.003572562213247865)\n",
      "------------test------------\n",
      " (0.4938718632023095, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4977756924894867, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 400 0.4\n",
      "验证集最优结果： 51.07178497314453 50.7023811340332\n",
      "------------train------------\n",
      " (0.5050804750331463, 0.010160950066292584)\n",
      "------------test------------\n",
      " (0.5009582500555185, 0.0019320453031311802)\n",
      "------------oot------------\n",
      " (0.5074097243943975, 0.013818510409064011)\n",
      "隐藏层vs神经元数vs norm 3 400 0.5\n",
      "验证集最优结果： 64.20459747314453 64.12474060058594\n",
      "------------train------------\n",
      " (0.49866270873391494, 0.0)\n",
      "------------test------------\n",
      " (0.501587830335332, 0.00576282478347768)\n",
      "------------oot------------\n",
      " (0.4961885564012558, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 400 0.8\n",
      "验证集最优结果： 102.35397338867188 102.29029083251953\n",
      "------------train------------\n",
      " (0.49966599866399464, 0.0)\n",
      "------------test------------\n",
      " (0.5, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019149897473325, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 430 0.01\n",
      "验证集最优结果： 1.972277283668518 1.952841877937317\n",
      "------------train------------\n",
      " (0.49695987720121093, 0.0)\n",
      "------------test------------\n",
      " (0.48548190095491894, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.49821360303061896, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 430 0.05\n",
      "验证集最优结果： 7.578789710998535 7.533740520477295\n",
      "------------train------------\n",
      " (0.5116826019482396, 0.022490776893198672)\n",
      "------------test------------\n",
      " (0.48227848101265824, 0.0)\n",
      "------------oot------------\n",
      " (0.5137015025660632, 0.027358982379314)\n",
      "隐藏层vs神经元数vs norm 3 430 0.1\n",
      "验证集最优结果： 14.609203338623047 14.539812088012695\n",
      "------------train------------\n",
      " (0.4856757080523763, 4.927111907027104e-05)\n",
      "------------test------------\n",
      " (0.4930091050410837, 0.0)\n",
      "------------oot------------\n",
      " (0.5245809149781625, 0.05060299586417827)\n",
      "隐藏层vs神经元数vs norm 3 430 0.2\n",
      "验证集最优结果： 28.649736404418945 28.525625228881836\n",
      "------------train------------\n",
      " (0.5029529508188955, 0.006006203558755474)\n",
      "------------test------------\n",
      " (0.49436708860759493, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.49559656622528064, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 430 0.3\n",
      "验证集最优结果： 42.53940963745117 42.487422943115234\n",
      "------------train------------\n",
      " (0.5018747390085813, 0.0027498428129477466)\n",
      "------------test------------\n",
      " (0.5025693981789918, 0.00624028425494115)\n",
      "------------oot------------\n",
      " (0.5033318272917897, 0.010523754909116168)\n",
      "隐藏层vs神经元数vs norm 3 430 0.4\n",
      "验证集最优结果： 56.555267333984375 56.50914764404297\n",
      "------------train------------\n",
      " (0.4911802666460919, 0.0)\n",
      "------------test------------\n",
      " (0.4838474350433044, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.48538792154682053, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 430 0.5\n",
      "验证集最优结果： 70.56062316894531 70.47672271728516\n",
      "------------train------------\n",
      " (0.4955078681510269, 0.0014207408400048749)\n",
      "------------test------------\n",
      " (0.5014379302687098, 0.003664223850766174)\n",
      "------------oot------------\n",
      " (0.5027247767003789, 0.005727591839571833)\n",
      "隐藏层vs神经元数vs norm 3 430 0.8\n",
      "验证集最优结果： 112.62810516357422 112.54821014404297\n",
      "------------train------------\n",
      " (0.49850190079585044, 0.0)\n",
      "------------test------------\n",
      " (0.5093848545414168, 0.018743060182100823)\n",
      "------------oot------------\n",
      " (0.5060566039921685, 0.00843846661800994)\n",
      "隐藏层vs神经元数vs norm 3 460 0.01\n",
      "验证集最优结果： 2.102175712585449 2.0835554599761963\n",
      "------------train------------\n",
      " (0.4997392285415139, 0.0007281026084590661)\n",
      "------------test------------\n",
      " (0.4994503664223851, 0.0035087719298245615)\n",
      "------------oot------------\n",
      " (0.5038276625076751, 0.006693775414451153)\n",
      "隐藏层vs神经元数vs norm 3 460 0.05\n",
      "验证集最优结果： 8.210018157958984 8.194063186645508\n",
      "------------train------------\n",
      " (0.49509278604490303, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.49507994670219857, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.5122788725541306, 0.019156848434296034)\n",
      "隐藏层vs神经元数vs norm 3 460 0.1\n",
      "验证集最优结果： 15.91357707977295 15.851580619812012\n",
      "------------train------------\n",
      " (0.5023572305028836, 0.004714461005767112)\n",
      "------------test------------\n",
      " (0.5002298467688208, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.4968627996153802, 0.0023980815347721673)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 3 460 0.2\n",
      "验证集最优结果： 30.93290138244629 30.71453857421875\n",
      "------------train------------\n",
      " (0.4985200390649587, 0.0)\n",
      "------------test------------\n",
      " (0.4988507661558961, 0.0035087719298245615)\n",
      "------------oot------------\n",
      " (0.49244430542522505, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 460 0.3\n",
      "验证集最优结果： 46.47332763671875 46.439727783203125\n",
      "------------train------------\n",
      " (0.49676692121155513, 0.0)\n",
      "------------test------------\n",
      " (0.48703975127692645, 0.0)\n",
      "------------oot------------\n",
      " (0.5133157242322085, 0.023681924025996587)\n",
      "隐藏层vs神经元数vs norm 3 460 0.4\n",
      "验证集最优结果： 61.79026412963867 61.7495002746582\n",
      "------------train------------\n",
      " (0.4907215985500214, 0.0009044769715046419)\n",
      "------------test------------\n",
      " (0.4988552076393515, 0.0069953364423717135)\n",
      "------------oot------------\n",
      " (0.4809358310453087, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 460 0.5\n",
      "验证集最优结果： 76.54017639160156 76.04854583740234\n",
      "------------train------------\n",
      " (0.4940269596944649, 0.006732275763956075)\n",
      "------------test------------\n",
      " (0.47950921607817015, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.48980873272396586, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 460 0.8\n",
      "验证集最优结果： 123.16506958007812 123.00995635986328\n",
      "------------train------------\n",
      " (0.5003340013360054, 0.0006680026720106881)\n",
      "------------test------------\n",
      " (0.500438596491228, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5019126727603425, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 490 0.01\n",
      "验证集最优结果： 2.2410550117492676 2.2193174362182617\n",
      "------------train------------\n",
      " (0.4812067228005487, 0.0)\n",
      "------------test------------\n",
      " (0.46727181878747504, 0.002631578947368421)\n",
      "------------oot------------\n",
      " (0.4725054738817641, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 490 0.05\n",
      "验证集最优结果： 8.922442436218262 8.872004508972168\n",
      "------------train------------\n",
      " (0.5223324054390442, 0.04480111861683511)\n",
      "------------test------------\n",
      " (0.5250588496557851, 0.05035531867643794)\n",
      "------------oot------------\n",
      " (0.5401788713956371, 0.08191707503562368)\n",
      "隐藏层vs神经元数vs norm 3 490 0.1\n",
      "验证集最优结果： 17.276357650756836 17.178638458251953\n",
      "------------train------------\n",
      " (0.4974383755691051, 0.0008906702293475841)\n",
      "------------test------------\n",
      " (0.525887186320231, 0.05149900066622254)\n",
      "------------oot------------\n",
      " (0.5112906776028452, 0.024314461474298832)\n",
      "隐藏层vs神经元数vs norm 3 490 0.2\n",
      "验证集最优结果： 34.035282135009766 33.89161682128906\n",
      "------------train------------\n",
      " (0.48785236802548027, 0.0003852351782254182)\n",
      "------------test------------\n",
      " (0.48862425049966685, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.4768729943581367, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 490 0.3\n",
      "验证集最优结果： 50.6208381652832 50.576820373535156\n",
      "------------train------------\n",
      " (0.510725131451691, 0.01529218518089881)\n",
      "------------test------------\n",
      " (0.5189207195203197, 0.04580279813457694)\n",
      "------------oot------------\n",
      " (0.5270519816031233, 0.03611719320196018)\n",
      "隐藏层vs神经元数vs norm 3 490 0.4\n",
      "验证集最优结果： 66.79036712646484 66.29764556884766\n",
      "------------train------------\n",
      " (0.5038304911071722, 0.0071956137875209825)\n",
      "------------test------------\n",
      " (0.4974183877415057, 0.0035087719298245615)\n",
      "------------oot------------\n",
      " (0.4949362249330971, 0.000966183574879227)\n",
      "隐藏层vs神经元数vs norm 3 490 0.5\n",
      "验证集最优结果： 84.02747344970703 83.97144317626953\n",
      "------------train------------\n",
      " (0.485235178225414, 0.0)\n",
      "------------test------------\n",
      " (0.4719487008660893, 0.0)\n",
      "------------oot------------\n",
      " (0.4986515135717513, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 490 0.8\n",
      "验证集最优结果： 132.8787078857422 132.05636596679688\n",
      "------------train------------\n",
      " (0.5011665343520544, 0.0023330687041086574)\n",
      "------------test------------\n",
      " (0.49991894292693767, 0.0006995336442371727)\n",
      "------------oot------------\n",
      " (0.4959580161957391, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 520 0.01\n",
      "验证集最优结果： 2.380690097808838 2.3608193397521973\n",
      "------------train------------\n",
      " (0.49920184847912646, 0.0010256243659219795)\n",
      "------------test------------\n",
      " (0.49533755274261604, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5099746289924582, 0.012664650887985265)\n",
      "隐藏层vs神经元数vs norm 3 520 0.05\n",
      "验证集最优结果： 9.616963386535645 9.554666519165039\n",
      "------------train------------\n",
      " (0.4877410342468117, 0.0)\n",
      "------------test------------\n",
      " (0.48424938929602496, 0.0018543193426604483)\n",
      "------------oot------------\n",
      " (0.4803160370254521, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 520 0.1\n",
      "验证集最优结果： 18.689655303955078 18.604475021362305\n",
      "------------train------------\n",
      " (0.5019330792622057, 0.004236639438959022)\n",
      "------------test------------\n",
      " (0.4934987785920497, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4977780094764768, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 520 0.2\n",
      "验证集最优结果： 36.7508544921875 36.68383026123047\n",
      "------------train------------\n",
      " (0.5130117716012911, 0.02632092959982782)\n",
      "------------test------------\n",
      " (0.5187164112813679, 0.04018432156340218)\n",
      "------------oot------------\n",
      " (0.5379464544306582, 0.06800125117297466)\n",
      "隐藏层vs神经元数vs norm 3 520 0.3\n",
      "验证集最优结果： 54.76787185668945 54.779335021972656\n",
      "------------train------------\n",
      " (0.49059916523354036, 0.00016256762088850962)\n",
      "------------test------------\n",
      " (0.4829735731734399, 0.0)\n",
      "------------oot------------\n",
      " (0.48552578227273263, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 520 0.4\n",
      "验证集最优结果： 72.86467742919922 72.83601379394531\n",
      "------------train------------\n",
      " (0.48297967092577593, 0.0001024676844402217)\n",
      "------------test------------\n",
      " (0.4778580946035976, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4961839224272756, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 520 0.5\n",
      "验证集最优结果： 90.27960205078125 89.7419204711914\n",
      "------------train------------\n",
      " (0.4984072840040093, 0.0020887435120156006)\n",
      "------------test------------\n",
      " (0.5003797468354431, 0.005263157894736842)\n",
      "------------oot------------\n",
      " (0.5002444421274574, 0.005727591839571833)\n",
      "隐藏层vs神经元数vs norm 3 520 0.8\n",
      "验证集最优结果： 145.3731231689453 145.3339385986328\n",
      "------------train------------\n",
      " (0.49509792973315764, 0.0)\n",
      "------------test------------\n",
      " (0.5016788807461692, 0.002598267821452449)\n",
      "------------oot------------\n",
      " (0.4982564672899361, 0.0018211517742326988)\n",
      "隐藏层vs神经元数vs norm 3 550 0.01\n",
      "验证集最优结果： 2.5231244564056396 2.4996695518493652\n",
      "------------train------------\n",
      " (0.5157964019900659, 0.03345360088633875)\n",
      "------------test------------\n",
      " (0.5010437486120365, 0.005263157894736842)\n",
      "------------oot------------\n",
      " (0.5017145703726874, 0.003663156431376713)\n",
      "隐藏层vs神经元数vs norm 3 550 0.05\n",
      "验证集最优结果： 10.340551376342773 10.275283813476562\n",
      "------------train------------\n",
      " (0.5036982441749422, 0.006743104581334314)\n",
      "------------test------------\n",
      " (0.4975460803908506, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5093328235961955, 0.01768324470858096)\n",
      "隐藏层vs神经元数vs norm 3 550 0.1\n",
      "验证集最优结果： 20.064523696899414 20.045690536499023\n",
      "------------train------------\n",
      " (0.503486473115092, 0.00666797966077376)\n",
      "------------test------------\n",
      " (0.5057950255385298, 0.009193870752831457)\n",
      "------------oot------------\n",
      " (0.4986376116498106, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 550 0.2\n",
      "验证集最优结果： 39.66062545776367 39.64412307739258\n",
      "------------train------------\n",
      " (0.5059559849181646, 0.011616207761690256)\n",
      "------------test------------\n",
      " (0.49718187874750164, 0.0)\n",
      "------------oot------------\n",
      " (0.5173275872055979, 0.031397490703089725)\n",
      "隐藏层vs神经元数vs norm 3 550 0.3\n",
      "验证集最优结果： 59.406982421875 59.17919921875\n",
      "------------train------------\n",
      " (0.4963106895993947, 0.0)\n",
      "------------test------------\n",
      " (0.49146013768598706, 0.002631578947368421)\n",
      "------------oot------------\n",
      " (0.4975845410628019, 0.0032252458902443104)\n",
      "隐藏层vs神经元数vs norm 3 550 0.4\n",
      "验证集最优结果： 78.70883178710938 78.57453918457031\n",
      "------------train------------\n",
      " (0.49704522181817196, 0.0011557055346762546)\n",
      "------------test------------\n",
      " (0.4923006884299356, 0.002631578947368421)\n",
      "------------oot------------\n",
      " (0.4935634101414521, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 550 0.5\n",
      "验证集最优结果： 98.31116485595703 98.20458221435547\n",
      "------------train------------\n",
      " (0.4982772028352551, 0.0003852351782254182)\n",
      "------------test------------\n",
      " (0.499670219853431, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.5043130712821047, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 3 550 0.8\n",
      "验证集最优结果： 156.83714294433594 156.75767517089844\n",
      "------------train------------\n",
      " (0.4753768936048388, 0.0)\n",
      "------------test------------\n",
      " (0.4930624028425494, 0.004485898290028869)\n",
      "------------oot------------\n",
      " (0.49029414149839545, 0.0023980815347721673)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隐藏层vs神经元数vs norm 3 580 0.01\n",
      "验证集最优结果： 2.6727042198181152 2.647886276245117\n",
      "------------train------------\n",
      " (0.4935839257034841, 0.0)\n",
      "------------test------------\n",
      " (0.4865600710637353, 0.0)\n",
      "------------oot------------\n",
      " (0.48950057345428, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 580 0.05\n",
      "验证集最优结果： 11.095426559448242 11.029156684875488\n",
      "------------train------------\n",
      " (0.4900137999741462, 0.0)\n",
      "------------test------------\n",
      " (0.48853431045969353, 0.0025316455696202667)\n",
      "------------oot------------\n",
      " (0.47012361125592284, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 580 0.1\n",
      "验证集最优结果： 21.58965492248535 21.56623649597168\n",
      "------------train------------\n",
      " (0.5128163114476166, 0.02649946972634898)\n",
      "------------test------------\n",
      " (0.49503775260937144, 0.0013546524539196358)\n",
      "------------oot------------\n",
      " (0.5062801932367149, 0.014179960379522405)\n",
      "隐藏层vs神经元数vs norm 3 580 0.2\n",
      "验证集最优结果： 42.28580856323242 42.00511169433594\n",
      "------------train------------\n",
      " (0.4872370881580791, 0.00032513524177701925)\n",
      "------------test------------\n",
      " (0.4809105041083722, 0.0016544525871641236)\n",
      "------------oot------------\n",
      " (0.4890186401603355, 0.006228061029437293)\n",
      "隐藏层vs神经元数vs norm 3 580 0.3\n",
      "验证集最优结果： 63.706085205078125 63.69288635253906\n",
      "------------train------------\n",
      " (0.4587510042036115, 0.0)\n",
      "------------test------------\n",
      " (0.4583333333333333, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.46895584981290334, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 580 0.4\n",
      "验证集最优结果： 84.68557739257812 84.62470245361328\n",
      "------------train------------\n",
      " (0.49812424578978964, 0.0009084024178042001)\n",
      "------------test------------\n",
      " (0.5018121252498334, 0.0027093049078391607)\n",
      "------------oot------------\n",
      " (0.5102712033271933, 0.019580857053487666)\n",
      "隐藏层vs神经元数vs norm 3 580 0.5\n",
      "验证集最优结果： 104.93879699707031 104.28871154785156\n",
      "------------train------------\n",
      " (0.478035368271159, 0.00044533511467379205)\n",
      "------------test------------\n",
      " (0.4718842993559849, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.48521067204207646, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 580 0.8\n",
      "验证集最优结果： 168.8887481689453 168.91697692871094\n",
      "------------train------------\n",
      " (0.5009620727439343, 0.0012581732191163653)\n",
      "------------test------------\n",
      " (0.49912280701754386, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.49880211772610894, 0.0014318979598929582)\n",
      "隐藏层vs神经元数vs norm 3 610 0.01\n",
      "验证集最优结果： 2.8257198333740234 2.8028182983398438\n",
      "------------train------------\n",
      " (0.49766023096513873, 0.0007103704200025485)\n",
      "------------test------------\n",
      " (0.5009304907839217, 0.0036087053075727293)\n",
      "------------oot------------\n",
      " (0.5009569156269187, 0.004295693879678875)\n",
      "隐藏层vs神经元数vs norm 3 610 0.05\n",
      "验证集最优结果： 11.851497650146484 11.778631210327148\n",
      "------------train------------\n",
      " (0.5109548377403237, 0.022447326263469125)\n",
      "------------test------------\n",
      " (0.5176648900732845, 0.03725294248278932)\n",
      "------------oot------------\n",
      " (0.5352367381457152, 0.07023946060542863)\n",
      "隐藏层vs神经元数vs norm 3 610 0.1\n",
      "验证集最优结果： 23.121719360351562 23.083356857299805\n",
      "------------train------------\n",
      " (0.5015778263720958, 0.004364690204454846)\n",
      "------------test------------\n",
      " (0.504890073284477, 0.008072396180324182)\n",
      "------------oot------------\n",
      " (0.5019010878253918, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 610 0.2\n",
      "验证集最优结果： 45.69339370727539 45.66366195678711\n",
      "------------train------------\n",
      " (0.5038543821855126, 0.0066804328007585845)\n",
      "------------test------------\n",
      " (0.49163890739507005, 0.0035087719298245615)\n",
      "------------oot------------\n",
      " (0.5046548268631472, 0.011177145240329533)\n",
      "隐藏层vs神经元数vs norm 3 610 0.3\n",
      "验证集最优结果： 68.27648162841797 68.27029418945312\n",
      "------------train------------\n",
      " (0.5041420226471179, 0.005748206984722559)\n",
      "------------test------------\n",
      " (0.4924261603375527, 0.0036087053075727293)\n",
      "------------oot------------\n",
      " (0.48425259792166275, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 610 0.4\n",
      "验证集最优结果： 90.97442626953125 90.92229461669922\n",
      "------------train------------\n",
      " (0.5131262186649558, 0.026396595961257208)\n",
      "------------test------------\n",
      " (0.4736686653342216, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.4956533324065385, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 610 0.5\n",
      "验证集最优结果： 113.4243392944336 113.47132873535156\n",
      "------------train------------\n",
      " (0.5004173832298165, 0.0016966049627116448)\n",
      "------------test------------\n",
      " (0.5017521652231846, 0.0037086386853208966)\n",
      "------------oot------------\n",
      " (0.4973574763377703, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 610 0.8\n",
      "验证集最优结果： 181.18772888183594 181.20326232910156\n",
      "------------train------------\n",
      " (0.5048888726456628, 0.009517582953817105)\n",
      "------------test------------\n",
      " (0.500557406173662, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5126681263684704, 0.02584367288777678)\n",
      "隐藏层vs神经元数vs norm 3 640 0.01\n",
      "验证集最优结果： 2.9847400188446045 2.961904525756836\n",
      "------------train------------\n",
      " (0.4857222719671021, 0.0007704703564508364)\n",
      "------------test------------\n",
      " (0.49659560293137905, 0.0029313790806129248)\n",
      "------------oot------------\n",
      " (0.4737809752198241, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 640 0.05\n",
      "验证集最优结果： 12.650192260742188 12.571931838989258\n",
      "------------train------------\n",
      " (0.5201587233907193, 0.03931496901266229)\n",
      "------------test------------\n",
      " (0.5110526315789474, 0.02287363979569179)\n",
      "------------oot------------\n",
      " (0.5286530196132949, 0.05360581100337125)\n",
      "隐藏层vs神经元数vs norm 3 640 0.1\n",
      "验证集最优结果： 24.759357452392578 24.641294479370117\n",
      "------------train------------\n",
      " (0.5043280075855865, 0.008883149615678487)\n",
      "------------test------------\n",
      " (0.4949877859204974, 0.0014545858316677984)\n",
      "------------oot------------\n",
      " (0.5065802430519353, 0.01705765822124905)\n",
      "隐藏层vs神经元数vs norm 3 640 0.2\n",
      "验证集最优结果： 48.865116119384766 48.83873748779297\n",
      "------------train------------\n",
      " (0.5047247483822761, 0.00837175871499829)\n",
      "------------test------------\n",
      " (0.5002165223184544, 0.0043859649122807015)\n",
      "------------oot------------\n",
      " (0.49727522329962115, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 640 0.3\n",
      "验证集最优结果： 73.0369644165039 72.9924087524414\n",
      "------------train------------\n",
      " (0.4967858039618583, 0.00044533511467379205)\n",
      "------------test------------\n",
      " (0.49615922718187866, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.49671567094150765, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 640 0.4\n",
      "验证集最优结果： 97.22383117675781 97.15692138671875\n",
      "------------train------------\n",
      " (0.5069489197916265, 0.010764791995338197)\n",
      "------------test------------\n",
      " (0.49477126360204304, 0.0)\n",
      "------------oot------------\n",
      " (0.5049386577694367, 0.007659958989330362)\n",
      "隐藏层vs神经元数vs norm 3 640 0.5\n",
      "验证集最优结果： 121.40758514404297 121.3608169555664\n",
      "------------train------------\n",
      " (0.48517575509005173, 0.0)\n",
      "------------test------------\n",
      " (0.49198867421718845, 0.0)\n",
      "------------oot------------\n",
      " (0.4660688840232163, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 640 0.8\n",
      "验证集最优结果： 194.09091186523438 193.97705078125\n",
      "------------train------------\n",
      " (0.498836917333485, 0.0)\n",
      "------------test------------\n",
      " (0.49956140350877193, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4966450028383091, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 670 0.01\n",
      "验证集最优结果： 3.1483027935028076 3.123502492904663\n",
      "------------train------------\n",
      " (0.4962419942891524, 0.0008473549598352337)\n",
      "------------test------------\n",
      " (0.48679769042860316, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5024015570152573, 0.008278594515691795)\n",
      "隐藏层vs神经元数vs norm 3 670 0.05\n",
      "验证集最优结果： 13.474416732788086 13.391634941101074\n",
      "------------train------------\n",
      " (0.505915512213214, 0.008957868455587298)\n",
      "------------test------------\n",
      " (0.5081245836109259, 0.013124583610926041)\n",
      "------------oot------------\n",
      " (0.5088022335754585, 0.015048830500816748)\n",
      "隐藏层vs神经元数vs norm 3 670 0.1\n",
      "验证集最优结果： 26.306745529174805 26.294340133666992\n",
      "------------train------------\n",
      " (0.4971855226833268, 0.0001024676844402217)\n",
      "------------test------------\n",
      " (0.4603686431268043, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.48891553423927525, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 670 0.2\n",
      "验证集最优结果： 52.35063934326172 52.16293716430664\n",
      "------------train------------\n",
      " (0.5121832317116503, 0.02782478161320956)\n",
      "------------test------------\n",
      " (0.49805018876304685, 0.0035309793471019306)\n",
      "------------oot------------\n",
      " (0.483965291534888, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 670 0.3\n",
      "验证集最优结果： 78.01514434814453 77.94678497314453\n",
      "------------train------------\n",
      " (0.49935555000578663, 0.000625634924018926)\n",
      "------------test------------\n",
      " (0.4924150566289141, 0.0017543859649122807)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------oot------------\n",
      " (0.4973273555068988, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 670 0.4\n",
      "验证集最优结果： 103.78142547607422 103.77156066894531\n",
      "------------train------------\n",
      " (0.5057374458474531, 0.011028067617842918)\n",
      "------------test------------\n",
      " (0.5043526537863646, 0.00838330002220744)\n",
      "------------oot------------\n",
      " (0.5097915870202389, 0.021610537656830964)\n",
      "隐藏层vs神经元数vs norm 3 670 0.5\n",
      "验证集最优结果： 129.68629455566406 129.527587890625\n",
      "------------train------------\n",
      " (0.5104780313751448, 0.014101150629526549)\n",
      "------------test------------\n",
      " (0.49217632689318225, 0.014412613813013536)\n",
      "------------oot------------\n",
      " (0.5085126102016937, 0.025058214298126713)\n",
      "隐藏层vs神经元数vs norm 3 670 0.8\n",
      "验证集最优结果： 207.1493377685547 207.16880798339844\n",
      "------------train------------\n",
      " (0.4799616118423946, 0.0)\n",
      "------------test------------\n",
      " (0.46836886520097715, 0.0)\n",
      "------------oot------------\n",
      " (0.45583243550087466, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 700 0.01\n",
      "验证集最优结果： 3.3124022483825684 3.28438138961792\n",
      "------------train------------\n",
      " (0.5146676331386176, 0.02595207300788671)\n",
      "------------test------------\n",
      " (0.4956329113924051, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.5171121074155168, 0.030563375386647218)\n",
      "隐藏层vs神经元数vs norm 3 700 0.05\n",
      "验证集最优结果： 14.305980682373047 14.225042343139648\n",
      "------------train------------\n",
      " (0.49328823130895355, 0.0026148886763732726)\n",
      "------------test------------\n",
      " (0.49551743282256266, 0.009371530091050411)\n",
      "------------oot------------\n",
      " (0.5015431133354187, 0.0033225593438292733)\n",
      "隐藏层vs神经元数vs norm 3 700 0.1\n",
      "验证集最优结果： 28.09233856201172 27.95573616027832\n",
      "------------train------------\n",
      " (0.4906550013231461, 6.0099936448378024e-05)\n",
      "------------test------------\n",
      " (0.5099633577614923, 0.024572507217410625)\n",
      "------------oot------------\n",
      " (0.5065257938576675, 0.024238000903624934)\n",
      "隐藏层vs神经元数vs norm 3 700 0.2\n",
      "验证集最优结果： 55.5576057434082 55.525936126708984\n",
      "------------train------------\n",
      " (0.5166982394373346, 0.033926549485326585)\n",
      "------------test------------\n",
      " (0.501554519209416, 0.00762824783477678)\n",
      "------------oot------------\n",
      " (0.550971396795607, 0.08652556215896845)\n",
      "隐藏层vs神经元数vs norm 3 700 0.3\n",
      "验证集最优结果： 82.92456817626953 82.89688873291016\n",
      "------------train------------\n",
      " (0.5021857291076581, 0.0028237494915532846)\n",
      "------------test------------\n",
      " (0.5029502553852987, 0.007017543859649123)\n",
      "------------oot------------\n",
      " (0.5011920898064157, 0.004260939074827164)\n",
      "隐藏层vs神经元数vs norm 3 700 0.4\n",
      "验证集最优结果： 110.49480438232422 110.48857879638672\n",
      "------------train------------\n",
      " (0.4965681447325586, 0.0006079027355623268)\n",
      "------------test------------\n",
      " (0.5014257161892071, 0.004685765045525206)\n",
      "------------oot------------\n",
      " (0.5023992400282673, 0.005831856254127134)\n",
      "隐藏层vs神经元数vs norm 3 700 0.5\n",
      "验证集最优结果： 138.05892944335938 137.99478149414062\n",
      "------------train------------\n",
      " (0.4900858792898191, 0.002830652862631733)\n",
      "------------test------------\n",
      " (0.4993104596935376, 0.0036864312680434663)\n",
      "------------oot------------\n",
      " (0.5353317346123102, 0.07162965279949951)\n",
      "隐藏层vs神经元数vs norm 3 700 0.8\n",
      "验证集最优结果： 220.40211486816406 220.37286376953125\n",
      "------------train------------\n",
      " (0.49822190818651824, 0.0010709700386927184)\n",
      "------------test------------\n",
      " (0.493986231401288, 0.0)\n",
      "------------oot------------\n",
      " (0.495938321806323, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 730 0.01\n",
      "验证集最优结果： 3.4870975017547607 3.4607136249542236\n",
      "------------train------------\n",
      " (0.4995343608527423, 0.00022266755733689602)\n",
      "------------test------------\n",
      " (0.5047890295358649, 0.007417277370641793)\n",
      "------------oot------------\n",
      " (0.5009372212375027, 0.0028290411149342054)\n",
      "隐藏层vs神经元数vs norm 3 730 0.05\n",
      "验证集最优结果： 15.18181037902832 15.10266399383545\n",
      "------------train------------\n",
      " (0.48184758574900566, 0.0)\n",
      "------------test------------\n",
      " (0.47003886298023545, 0.0008771929824561404)\n",
      "------------oot------------\n",
      " (0.4789490147012825, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 730 0.1\n",
      "验证集最优结果： 29.825273513793945 29.69023895263672\n",
      "------------train------------\n",
      " (0.467709549460285, 0.0)\n",
      "------------test------------\n",
      " (0.48723850766155896, 0.011403508771929825)\n",
      "------------oot------------\n",
      " (0.45763852685967166, 0.0023980815347721673)\n",
      "隐藏层vs神经元数vs norm 3 730 0.2\n",
      "验证集最优结果： 58.87937927246094 58.85285186767578\n",
      "------------train------------\n",
      " (0.5024552313001551, 0.003074978054724782)\n",
      "------------test------------\n",
      " (0.4957905840550744, 0.0)\n",
      "------------oot------------\n",
      " (0.5014122035704769, 0.008056163764640467)\n",
      "隐藏层vs神经元数vs norm 3 730 0.3\n",
      "验证集最优结果： 88.14202880859375 88.12725067138672\n",
      "------------train------------\n",
      " (0.4909433862659463, 0.00111333778668448)\n",
      "------------test------------\n",
      " (0.479982234066178, 0.002631578947368421)\n",
      "------------oot------------\n",
      " (0.490913935518252, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 730 0.4\n",
      "验证集最优结果： 117.44416809082031 117.35967254638672\n",
      "------------train------------\n",
      " (0.48740838651297874, 0.00016256762088850962)\n",
      "------------test------------\n",
      " (0.48137463912946926, 0.0017543859649122807)\n",
      "------------oot------------\n",
      " (0.49596728414369945, 0.004796163069544335)\n",
      "隐藏层vs神经元数vs norm 3 730 0.5\n",
      "验证集最优结果： 146.68649291992188 146.5917510986328\n",
      "------------train------------\n",
      " (0.4938872679502876, 0.0)\n",
      "------------test------------\n",
      " (0.5064201643348879, 0.009404841216966497)\n",
      "------------oot------------\n",
      " (0.5044555659819969, 0.007242901331109053)\n",
      "隐藏层vs神经元数vs norm 3 730 0.8\n",
      "验证集最优结果： 234.2432098388672 233.99142456054688\n",
      "------------train------------\n",
      " (0.49386588103596585, 0.00044533511467379205)\n",
      "------------test------------\n",
      " (0.48647346213635356, 0.0)\n",
      "------------oot------------\n",
      " (0.48498476581053995, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 760 0.01\n",
      "验证集最优结果： 3.659092426300049 3.6299855709075928\n",
      "------------train------------\n",
      " (0.4988954606274352, 0.0023468754462657162)\n",
      "------------test------------\n",
      " (0.5092282922496114, 0.019886742171885408)\n",
      "------------oot------------\n",
      " (0.49694736964051944, 0.0009314287700273871)\n",
      "隐藏层vs神经元数vs norm 3 760 0.05\n",
      "验证集最优结果： 16.06171989440918 15.962825775146484\n",
      "------------train------------\n",
      " (0.4983157804971645, 0.0)\n",
      "------------test------------\n",
      " (0.500869420386409, 0.0063180102154118956)\n",
      "------------oot------------\n",
      " (0.49663921037083375, 0.0)\n",
      "隐藏层vs神经元数vs norm 3 760 0.1\n",
      "验证集最优结果： 31.499893188476562 31.46938133239746\n",
      "------------train------------\n",
      " (0.4642611125662335, 0.0004877028626656399)\n",
      "------------test------------\n",
      " (0.46091272485009993, 0.0007772596047079805)\n",
      "------------oot------------\n",
      " (0.47284954644979665, 0.0038299794946651256)\n",
      "隐藏层vs神经元数vs norm 3 760 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def model_metrics2(nnmodel, x, y):\n",
    "    yprob = nnmodel.predict(x.replace([np.inf, -np.inf], np.nan).fillna(0))[:,0]\n",
    "    fpr,tpr,_ = roc_curve(y, yprob,pos_label=1)\n",
    "    return auc(fpr, tpr),max(tpr-fpr)\n",
    "\n",
    "np.random.seed(1) # 固定随机种子，使每次运行结果固定\n",
    "random.set_seed(1)\n",
    "\n",
    "bestval = 0\n",
    "# 创建模型结构：输入层的特征维数为13；1层k个神经元的relu隐藏层；线性的输出层；\n",
    "for layer_nums in range(1,4):\n",
    "    for k in list(range(1,20,1)) + list(range(20,100,2)) + list(range(100,1000,30)):  # 网格搜索超参数：神经元数,5,10,100\n",
    "        for norm in [0.01,0.05,0.1,0.2,0.3,0.4,0.5,0.8]:\n",
    "            print(\"隐藏层vs神经元数vs norm\",layer_nums,k,norm)\n",
    "            model = Sequential()\n",
    "            model.add(BatchNormalization())  # 输入层 批标准化  input_dim=train_x.shape\n",
    "            for _ in range(layer_nums):\n",
    "                model.add(Dense(k,  \n",
    "                                kernel_initializer='random_uniform',   # 均匀初始化\n",
    "                                activation='relu',                     # relu激活函数\n",
    "                                kernel_regularizer=regularizers.l1_l2(l1=norm, l2=norm),  # L1及L2 正则项\n",
    "                                use_bias=True))   # 隐藏层1\n",
    "                model.add(Dropout(norm)) # dropout正则\n",
    "            model.add(Dense(1,use_bias=True,activation='sigmoid'))  # 输出层\n",
    "\n",
    "\n",
    "\n",
    "            # 编译模型：优化目标为回归预测损失mse，优化算法为adam\n",
    "            model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy) \n",
    "\n",
    "            # 训练模型\n",
    "            history = model.fit(train_x.replace([np.inf, -np.inf], np.nan).fillna(0), \n",
    "                                train_y, \n",
    "                                epochs=1000,              # 训练迭代次数\n",
    "                                batch_size=1000,           # 每epoch采样的batch大小\n",
    "                                validation_data=(test_x.replace([np.inf, -np.inf], np.nan).fillna(0),test_y),   # 从训练集再拆分验证集，作为早停的衡量指标\n",
    "                                callbacks=[EarlyStopping(monitor='val_loss', patience=10)],    #早停法\n",
    "                                verbose=False)  # 不输出过程  \n",
    "            print(\"验证集最优结果：\",min(history.history['loss']),min(history.history['val_loss']))\n",
    "            print('------------train------------\\n',model_metrics2(model, train_x,train_y))\n",
    "\n",
    "            print('------------test------------\\n',model_metrics2(model, test_x,test_y))\n",
    "\n",
    "            print('------------oot------------\\n',model_metrics2(model, oot_x,oot_y))\n",
    "            if model_metrics2(model, test_x,test_y)[0] > bestval: # 仅以test调参\n",
    "                bestval = model_metrics2(model, oot_x,oot_y)[0]\n",
    "                best_paras = ['bestval, layer_nums, k, norm',bestval, layer_nums, k, norm]\n",
    "\n",
    "# 模型评估：拟合效果\n",
    "plt.plot(history.history['loss'],c='blue')    # 蓝色线训练集损失\n",
    "plt.plot(history.history['val_loss'],c='red') # 红色线验证集损失\n",
    "plt.show()\n",
    "model.summary()   #模型概述信息\n",
    "print(best_paras)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b3c22fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bestval, layer_nums, k, norm', 0.6400850334225374, 2, 16, 0.01]\n"
     ]
    }
   ],
   "source": [
    "print(bestparas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75461bfe",
   "metadata": {},
   "source": [
    "####  autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb24599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./data/automodel\"\n",
      "Presets specified: ['best_quality']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (7671 samples, 108.19 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./data/automodel/\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    7671\n",
      "Train Data Columns: 1761\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1.0, 0.0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    115523.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 108.07 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 57): ['Amount_Past_Due35_sum_30', 'Amount_Past_Due35_min_30', 'Days_Past_Due58_max_30', 'Days_Past_Due58_min_30', 'Duecount53_std_30', 'feature_7', 'feature_10', 'feature_13', 'feature_14', 'feature_17', 'feature_264', 'feature_265', 'feature_266', 'feature_267', 'feature_268', 'feature_269', 'feature_270', 'feature_271', 'feature_306', 'feature_307', 'feature_308', 'feature_309', 'feature_327', 'feature_328', 'feature_338', 'feature_339', 'feature_341', 'feature_342', 'feature_361', 'feature_362', 'feature_363', 'feature_364', 'feature_365', 'feature_366', 'feature_367', 'feature_368', 'feature_507', 'feature_508', 'feature_509', 'feature_510', 'feature_511', 'feature_512', 'feature_513', 'feature_514', 'feature_531', 'feature_532', 'feature_533', 'feature_534', 'feature_547', 'feature_548', 'feature_549', 'feature_550', 'feature_551', 'feature_552', 'feature_553', 'feature_554', 'feature_589']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1051 | ['BureauScore', 'MissingRate', 'Tel_nuniq', 'Email_nuniq', 'City_nuniq', ...]\n",
      "\t\t('int', [])   :  653 | ['Len_Name', 'Len_of_addrs', 'Current_State', 'CreditAccountActive', 'CreditAccountTotal', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 1049 | ['BureauScore', 'MissingRate', 'Tel_nuniq', 'Email_nuniq', 'City_nuniq', ...]\n",
      "\t\t('int', [])       :  651 | ['Len_Name', 'Len_of_addrs', 'Current_State', 'CreditAccountActive', 'CreditAccountTotal', ...]\n",
      "\t\t('int', ['bool']) :    4 | ['Number_of_Major_Credit_Card_Held62_sum_7', 'feature_6', 'feature_593', 'feature_1300_sms']\n",
      "\t2.4s = Fit runtime\n",
      "\t1704 features in original data used to generate 1704 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 104.36 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.74s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t0.5138\t = Validation score   (roc_auc)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t5.39s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t0.515\t = Validation score   (roc_auc)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t5.41s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.7237\t = Validation score   (roc_auc)\n",
      "\t39.11s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.7236\t = Validation score   (roc_auc)\n",
      "\t40.06s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.6408\t = Validation score   (roc_auc)\n",
      "\t3.25s\t = Training   runtime\n",
      "\t4.28s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.6445\t = Validation score   (roc_auc)\n",
      "\t4.24s\t = Training   runtime\n",
      "\t4.35s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\t0.7292\t = Validation score   (roc_auc)\n",
      "\t106.96s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.6362\t = Validation score   (roc_auc)\n",
      "\t1.99s\t = Training   runtime\n",
      "\t4.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.6445\t = Validation score   (roc_auc)\n",
      "\t2.1s\t = Training   runtime\n",
      "\t4.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tfuture feature annotations is not defined (dispatch.py, line 4)\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 962, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 934, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 189, in _fit\n",
      "    n_repeats=n_repeats, n_repeat_start=n_repeat_start, save_folds=save_bag_folds, groups=groups, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 388, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 59, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(*job)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 64, in _fit_fold_model\n",
      "    fold_model = self._fit(model_base, time_start_fold, time_limit_fold, fold_ctx, kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 111, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 163, in _fit\n",
      "    try_import_fastai()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/utils/try_import.py\", line 107, in try_import_fastai\n",
      "    import autogluon.tabular.models.fastainn.imports_helper\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "    from fastai.tabular.all import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "    from ..basics import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "    from .data.all import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "    from ..torch_basics import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "    from .imports import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/imports.py\", line 30, in <module>\n",
      "    from fastcore.all import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastcore/all.py\", line 3, in <module>\n",
      "    from .dispatch import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastcore/dispatch.py\", line 4\n",
      "    from __future__ import annotations\n",
      "                                     ^\n",
      "SyntaxError: future feature annotations is not defined\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\t0.7227\t = Validation score   (roc_auc)\n",
      "\t154.98s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ...\n",
      "\tWarning: Exception caused NeuralNetMXNet_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tlibquadmath.so.0: cannot open shared object file: No such file or directory\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 962, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 934, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 189, in _fit\n",
      "    n_repeats=n_repeats, n_repeat_start=n_repeat_start, save_folds=save_bag_folds, groups=groups, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 388, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 59, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(*job)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 64, in _fit_fold_model\n",
      "    fold_model = self._fit(model_base, time_start_fold, time_limit_fold, fold_ctx, kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 111, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/models/tabular_nn/tabular_nn_model.py\", line 168, in _fit\n",
      "    try_import_mxnet()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/utils/try_import.py\", line 31, in try_import_mxnet\n",
      "    import mxnet as mx\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/__init__.py\", line 23, in <module>\n",
      "    from .context import Context, current_context, cpu, gpu, cpu_pinned\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/context.py\", line 23, in <module>\n",
      "    from .base import classproperty, with_metaclass, _MXClassPropertyMetaClass\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/base.py\", line 356, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/base.py\", line 347, in _load_lib\n",
      "    lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)\n",
      "  File \"/usr/lib64/python3.6/ctypes/__init__.py\", line 343, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: libquadmath.so.0: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.7163\t = Validation score   (roc_auc)\n",
      "\t121.76s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7335\t = Validation score   (roc_auc)\n",
      "\t2.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 11 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.7221\t = Validation score   (roc_auc)\n",
      "\t31.46s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.714\t = Validation score   (roc_auc)\n",
      "\t37.63s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ...\n",
      "\t0.7073\t = Validation score   (roc_auc)\n",
      "\t3.13s\t = Training   runtime\n",
      "\t4.38s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ...\n",
      "\t0.7088\t = Validation score   (roc_auc)\n",
      "\t4.19s\t = Training   runtime\n",
      "\t4.41s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\t0.7278\t = Validation score   (roc_auc)\n",
      "\t72.99s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ...\n",
      "\t0.6907\t = Validation score   (roc_auc)\n",
      "\t1.99s\t = Training   runtime\n",
      "\t4.4s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ...\n",
      "\t0.695\t = Validation score   (roc_auc)\n",
      "\t2.22s\t = Training   runtime\n",
      "\t4.27s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tfuture feature annotations is not defined (dispatch.py, line 4)\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 962, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 934, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 189, in _fit\n",
      "    n_repeats=n_repeats, n_repeat_start=n_repeat_start, save_folds=save_bag_folds, groups=groups, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 388, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 59, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(*job)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 64, in _fit_fold_model\n",
      "    fold_model = self._fit(model_base, time_start_fold, time_limit_fold, fold_ctx, kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 111, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 163, in _fit\n",
      "    try_import_fastai()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/utils/try_import.py\", line 107, in try_import_fastai\n",
      "    import autogluon.tabular.models.fastainn.imports_helper\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/models/fastainn/imports_helper.py\", line 1, in <module>\n",
      "    from fastai.tabular.all import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/tabular/all.py\", line 1, in <module>\n",
      "    from ..basics import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/basics.py\", line 1, in <module>\n",
      "    from .data.all import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/data/all.py\", line 1, in <module>\n",
      "    from ..torch_basics import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/torch_basics.py\", line 9, in <module>\n",
      "    from .imports import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastai/imports.py\", line 30, in <module>\n",
      "    from fastcore.all import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastcore/all.py\", line 3, in <module>\n",
      "    from .dispatch import *\n",
      "  File \"/usr/local/lib/python3.6/site-packages/fastcore/dispatch.py\", line 4\n",
      "    from __future__ import annotations\n",
      "                                     ^\n",
      "SyntaxError: future feature annotations is not defined\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\t0.7129\t = Validation score   (roc_auc)\n",
      "\t156.48s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L2 ...\n",
      "\tWarning: Exception caused NeuralNetMXNet_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tlibquadmath.so.0: cannot open shared object file: No such file or directory\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 962, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 934, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 189, in _fit\n",
      "    n_repeats=n_repeats, n_repeat_start=n_repeat_start, save_folds=save_bag_folds, groups=groups, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 388, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 59, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(*job)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 64, in _fit_fold_model\n",
      "    fold_model = self._fit(model_base, time_start_fold, time_limit_fold, fold_ctx, kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 111, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 522, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/tabular/models/tabular_nn/tabular_nn_model.py\", line 168, in _fit\n",
      "    try_import_mxnet()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/autogluon/core/utils/try_import.py\", line 31, in try_import_mxnet\n",
      "    import mxnet as mx\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/__init__.py\", line 23, in <module>\n",
      "    from .context import Context, current_context, cpu, gpu, cpu_pinned\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/context.py\", line 23, in <module>\n",
      "    from .base import classproperty, with_metaclass, _MXClassPropertyMetaClass\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/base.py\", line 356, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mxnet/base.py\", line 347, in _load_lib\n",
      "    lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)\n",
      "  File \"/usr/lib64/python3.6/ctypes/__init__.py\", line 343, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: libquadmath.so.0: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.7077\t = Validation score   (roc_auc)\n",
      "\t117.45s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7283\t = Validation score   (roc_auc)\n",
      "\t2.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 976.95s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./data/automodel/\")\n",
      "Evaluation: roc_auc on test data: 0.7300130909764941\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"roc_auc\": 0.7300130909764941,\n",
      "    \"accuracy\": 0.7210743801652892,\n",
      "    \"balanced_accuracy\": 0.5380148055468669,\n",
      "    \"mcc\": 0.15257391971809992,\n",
      "    \"f1\": 0.8318804483188045,\n",
      "    \"precision\": 0.7292576419213974,\n",
      "    \"recall\": 0.9681159420289855\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  \n",
      "              0         1\n",
      "0     0.314340  0.685660\n",
      "1789  0.086377  0.913623\n",
      "3921  0.225109  0.774891\n",
      "3922  0.075995  0.924005\n",
      "3923  0.105877  0.894123\n",
      "...        ...       ...\n",
      "8714  0.366803  0.633197\n",
      "8718  0.340966  0.659034\n",
      "8721  0.456564  0.543436\n",
      "8723  0.286990  0.713010\n",
      "8724  0.581488  0.418512\n",
      "\n",
      "[1452 rows x 2 columns]\n",
      "0.7300130909764941 0.3458033573141487\n",
      "{'roc_auc': 0.7300130909764941, 'accuracy': 0.7210743801652892, 'balanced_accuracy': 0.5380148055468669, 'mcc': 0.15257391971809992, 'f1': 0.8318804483188045, 'precision': 0.7292576419213974, 'recall': 0.9681159420289855}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n",
      "Computing feature importance via permutation shuffling for 1761 features using 1000 rows with 3 shuffle sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L2   0.733550      10.295661  347.655579                0.002392           2.456590            2       True         12\n",
      "1           CatBoost_BAG_L1   0.729190       0.800230  106.959460                0.800230         106.959460            1       True          7\n",
      "2       WeightedEnsemble_L3   0.728325      40.298569  743.484664                0.002392           2.033625            3       True         22\n",
      "3           CatBoost_BAG_L2   0.727775      30.894764  548.392217                0.932192          72.991360            2       True         17\n",
      "4         LightGBMXT_BAG_L1   0.723712       0.242499   39.105738                0.242499          39.105738            1       True          3\n",
      "5           LightGBM_BAG_L1   0.723562       0.254709   40.058334                0.254709          40.058334            1       True          4\n",
      "6            XGBoost_BAG_L1   0.722663       0.384475  154.984993                0.384475         154.984993            1       True         10\n",
      "7         LightGBMXT_BAG_L2   0.722149      30.197714  506.859643                0.235142          31.458786            2       True         13\n",
      "8      LightGBMLarge_BAG_L1   0.716333       0.236607  121.761869                0.236607         121.761869            1       True         11\n",
      "9           LightGBM_BAG_L2   0.714032      30.200924  513.031050                0.238351          37.630194            2       True         14\n",
      "10           XGBoost_BAG_L2   0.712854      30.347161  631.881180                0.384589         156.480323            2       True         20\n",
      "11  RandomForestEntr_BAG_L2   0.708833      34.371543  479.589384                4.408971           4.188527            2       True         16\n",
      "12     LightGBMLarge_BAG_L2   0.707741      30.201514  592.852427                0.238942         117.451570            2       True         21\n",
      "13  RandomForestGini_BAG_L2   0.707261      34.341073  478.528560                4.378501           3.127703            2       True         15\n",
      "14    ExtraTreesEntr_BAG_L2   0.694975      34.233581  477.616334                4.271009           2.215477            2       True         19\n",
      "15    ExtraTreesGini_BAG_L2   0.690716      34.365754  477.392866                4.403182           1.992009            2       True         18\n",
      "16    ExtraTreesEntr_BAG_L1   0.644539       4.352430    2.100752                4.352430           2.100752            1       True          9\n",
      "17  RandomForestEntr_BAG_L1   0.644479       4.345647    4.235652                4.345647           4.235652            1       True          6\n",
      "18  RandomForestGini_BAG_L1   0.640840       4.284757    3.249153                4.284757           3.249153            1       True          5\n",
      "19    ExtraTreesGini_BAG_L1   0.636168       4.258927    1.989712                4.258927           1.989712            1       True          8\n",
      "20    KNeighborsDist_BAG_L1   0.515038       5.409837    0.487729                5.409837           0.487729            1       True          2\n",
      "21    KNeighborsUnif_BAG_L1   0.513839       5.392455    0.467465                5.392455           0.467465            1       True          1\n",
      "Number of models trained: 22\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_LGB', 'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XT'}\n",
      "Bagging used: True  (with 10 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 1049 | ['BureauScore', 'MissingRate', 'Tel_nuniq', 'Email_nuniq', 'City_nuniq', ...]\n",
      "('int', [])       :  651 | ['Len_Name', 'Len_of_addrs', 'Current_State', 'CreditAccountActive', 'CreditAccountTotal', ...]\n",
      "('int', ['bool']) :    4 | ['Number_of_Major_Credit_Card_Held62_sum_7', 'feature_6', 'feature_593', 'feature_1300_sms']\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t10234.36s\t= Expected runtime (3411.45s per shuffle set)\n",
      "\t5970.57s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature_2</th>\n",
       "      <td>0.188764</td>\n",
       "      <td>0.028887</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>3</td>\n",
       "      <td>0.354291</td>\n",
       "      <td>0.023238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_Rating34_mean_9999</th>\n",
       "      <td>0.004409</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>-0.000388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_4</th>\n",
       "      <td>0.004160</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.017681</td>\n",
       "      <td>3</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>-0.003818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_1236_sms</th>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004452</td>\n",
       "      <td>0.001393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.078636</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015356</td>\n",
       "      <td>-0.009755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_256</th>\n",
       "      <td>-0.000378</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.991376</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>-0.000877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_32</th>\n",
       "      <td>-0.000397</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.968303</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>-0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_545</th>\n",
       "      <td>-0.000506</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.984164</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>-0.001423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_253</th>\n",
       "      <td>-0.000541</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.962814</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>-0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_254</th>\n",
       "      <td>-0.000902</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.966808</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>-0.003330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1761 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   importance    stddev  \\\n",
       "feature_2                                            0.188764  0.028887   \n",
       "Payment_Rating34_mean_9999                           0.004409  0.000837   \n",
       "feature_4                                            0.004160  0.001392   \n",
       "feature_1236_sms                                     0.002922  0.000267   \n",
       "Highest_Credit_or_Original_Loan_Amount58_sum_9999    0.002801  0.002191   \n",
       "...                                                       ...       ...   \n",
       "feature_256                                         -0.000378  0.000087   \n",
       "feature_32                                          -0.000397  0.000182   \n",
       "feature_545                                         -0.000506  0.000160   \n",
       "feature_253                                         -0.000541  0.000271   \n",
       "feature_254                                         -0.000902  0.000424   \n",
       "\n",
       "                                                    p_value  n  p99_high  \\\n",
       "feature_2                                          0.003858  3  0.354291   \n",
       "Payment_Rating34_mean_9999                         0.005901  3  0.009205   \n",
       "feature_4                                          0.017681  3  0.012138   \n",
       "feature_1236_sms                                   0.001385  3  0.004452   \n",
       "Highest_Credit_or_Original_Loan_Amount58_sum_9999  0.078636  3  0.015356   \n",
       "...                                                     ... ..       ...   \n",
       "feature_256                                        0.991376  3  0.000121   \n",
       "feature_32                                         0.968303  3  0.000645   \n",
       "feature_545                                        0.984164  3  0.000410   \n",
       "feature_253                                        0.962814  3  0.001011   \n",
       "feature_254                                        0.966808  3  0.001526   \n",
       "\n",
       "                                                    p99_low  \n",
       "feature_2                                          0.023238  \n",
       "Payment_Rating34_mean_9999                        -0.000388  \n",
       "feature_4                                         -0.003818  \n",
       "feature_1236_sms                                   0.001393  \n",
       "Highest_Credit_or_Original_Loan_Amount58_sum_9999 -0.009755  \n",
       "...                                                     ...  \n",
       "feature_256                                       -0.000877  \n",
       "feature_32                                        -0.001438  \n",
       "feature_545                                       -0.001423  \n",
       "feature_253                                       -0.002092  \n",
       "feature_254                                       -0.003330  \n",
       "\n",
       "[1761 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "# train = pd.concat([train_x,train_y],axis=1)\n",
    "# val = pd.concat([test_x,test_y],axis=1)\n",
    "# vpath='./data/automodel'\n",
    "# model = TabularPredictor(label='label',eval_metric='roc_auc',path=vpath)\n",
    "# predictor = model.fit( pd.concat([train,val]) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train = pd.concat([train_x,train_y],axis=1)\n",
    "val = pd.concat([test_x,test_y],axis=1)\n",
    "vpath='./data/automodel'\n",
    "model = TabularPredictor(label='label',eval_metric='roc_auc',path=vpath)\n",
    "predictor2 = model.fit( pd.concat([train,val]),auto_stack=True, presets='best_quality')\n",
    "\n",
    "\n",
    "y_pred = predictor2.predict_proba(oot_x)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "fpr,tpr,_ = roc_curve(oot_y, y_pred[1],pos_label=1)\n",
    "print(auc(fpr, tpr),max(tpr-fpr))   # val-》oot0.6085821264860178\n",
    "\n",
    "perf = predictor2.evaluate_predictions(y_true=oot_y, y_pred=y_pred, auxiliary_metrics=True)\n",
    "print(perf)\n",
    "\n",
    "predictor2.leaderboard(val, silent=True)\n",
    "\n",
    "predictor2.fit_summary(show_plot=True)\n",
    "\n",
    "predictor2.feature_importance(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b472f",
   "metadata": {},
   "source": [
    "#### pytorch  Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18a7c14c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment Tracking is turned off\n",
      "Global seed set to 42\n",
      "Preparing the DataLoaders...\n",
      "Preprocessing data: Stage: fit...\n",
      "Preprocessing data: Stage: inference...\n",
      "Preparing the Model: TabTransformerModel...\n",
      "/usr/local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning:\n",
      "\n",
      "Checkpoint directory saved_models exists and is not empty.\n",
      "\n",
      "Preparing the Trainer...\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name         | Type                   | Params\n",
      "--------------------------------------------------------\n",
      "0 | backbone     | TabTransformerBackbone | 507 K \n",
      "1 | dropout      | Dropout                | 0     \n",
      "2 | output_layer | Linear                 | 66    \n",
      "3 | loss         | CrossEntropyLoss       | 0     \n",
      "--------------------------------------------------------\n",
      "507 K     Trainable params\n",
      "0         Non-trainable params\n",
      "507 K     Total params\n",
      "2.029     Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning:\n",
      "\n",
      "The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "Global seed set to 42\n",
      "/usr/local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning:\n",
      "\n",
      "The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24868428bca142b18a198b8bd1d57745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restored states from the checkpoint file at /home/projects/Euler/lr_find_temp_model.ckpt\n",
      "Learning rate set to 0.006918309709189364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type                   | Params\n",
      "--------------------------------------------------------\n",
      "0 | backbone     | TabTransformerBackbone | 507 K \n",
      "1 | dropout      | Dropout                | 0     \n",
      "2 | output_layer | Linear                 | 66    \n",
      "3 | loss         | CrossEntropyLoss       | 0     \n",
      "--------------------------------------------------------\n",
      "507 K     Trainable params\n",
      "0         Non-trainable params\n",
      "507 K     Total params\n",
      "2.029     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75313b674b754aa4a0e9c2f24c9d2e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 3it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training the model completed...\n",
      "Loading the best model...\n",
      "Preprocessing data: Stage: inference...\n",
      "/usr/local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning:\n",
      "\n",
      "The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf03bbd79154697a4ae0cc147951f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data: Stage: inference...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': 0.1179153099656105}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b26611c26549489780fae94595892f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Predictions...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Directory is not empty. Overwriting the contents.\n",
      "Experiment Tracking is turned off\n",
      "Preparing the Trainer...\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Preprocessing data: Stage: inference...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655c0fa18a9e4c90a946d7712de2071a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Predictions...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'1_probability'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1_probability'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3ea10299e8b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m### oot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0myprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabular_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moot_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1_probability'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moot_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1_probability'"
     ]
    }
   ],
   "source": [
    "#### Pytorch FC transformer网络实现\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig,TabTransformerConfig\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=['label'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=list(train_x.columns),\n",
    "    categorical_cols=[],\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=100\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "# model_config = CategoryEmbeddingModelConfig(\n",
    "#     task=\"classification\",\n",
    "#     layers=\"1024-512-512\",  # Number of nodes in each layer\n",
    "#     activation=\"LeakyReLU\", # Activation between each layers\n",
    "#     learning_rate = 1e-3\n",
    "# )\n",
    "model_config = TabTransformerConfig(\n",
    "    task=\"classification\"\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "tabular_model.fit(train=pd.concat([train_x,train_y],axis=1), validation=pd.concat([test_x,test_y],axis=1))\n",
    "result = tabular_model.evaluate(test_x)\n",
    "pred_df = tabular_model.predict(test_x)\n",
    "tabular_model.save_model(\"examples/basic\")\n",
    "loaded_model = TabularModel.load_from_checkpoint(\"examples/basic\")\n",
    "\n",
    "\n",
    "### oot\n",
    "yprob = tabular_model.predict(oot_x)['1.0_probability']\n",
    "fpr,tpr,_ = roc_curve(oot_y, yprob,pos_label=1)\n",
    "auc(fpr, tpr),max(tpr-fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090cd3c9",
   "metadata": {},
   "source": [
    "#### tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f24d7099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 12\n",
      "\n",
      "Early stopping occured at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.53921\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.4809428380570665, 0.003109494910117361)\n",
      "------------test------------\n",
      " (0.5392049744614701, 0.09709082833666449)\n",
      "------------oot------------\n",
      " (0.4730754526813332, 0.0016404267890035816)\n",
      "8 8 14\n",
      "\n",
      "Early stopping occured at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.54293\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5108400522761158, 0.02644789748358589)\n",
      "------------test------------\n",
      " (0.5429202753719743, 0.09945591827670441)\n",
      "------------oot------------\n",
      " (0.5265665728286936, 0.05789455392207976)\n",
      "8 8 16\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.52775\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5155775245188113, 0.033688450863225916)\n",
      "------------test------------\n",
      " (0.527627137463913, 0.07195203197868089)\n",
      "------------oot------------\n",
      " (0.4750576350513792, 0.01135091926458831)\n",
      "8 8 18\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.52722\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.49610859679507613, 0.020119130527180618)\n",
      "------------test------------\n",
      " (0.5271474572507218, 0.07187430601821015)\n",
      "------------oot------------\n",
      " (0.5018211517742328, 0.03403190491085395)\n",
      "10 10 12\n",
      "\n",
      "Early stopping occured at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.53065\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5017384312698344, 0.01319180069020176)\n",
      "------------test------------\n",
      " (0.5306517876970909, 0.08079058405507439)\n",
      "------------oot------------\n",
      " (0.5040303988693104, 0.03865429395613945)\n",
      "10 10 14\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.50916\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5029842867091833, 0.026774657047969663)\n",
      "------------test------------\n",
      " (0.5091538974017322, 0.03984010659560289)\n",
      "------------oot------------\n",
      " (0.5224226415968675, 0.0649289264240781)\n",
      "10 10 16\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.52701\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5234412763385603, 0.04798465556577525)\n",
      "------------test------------\n",
      " (0.5269864534754609, 0.06496779924494789)\n",
      "------------oot------------\n",
      " (0.49992006394884086, 0.032405380043791066)\n",
      "10 10 18\n",
      "------------train------------\n",
      " (0.49929646527096744, 0.021474898462917058)\n",
      "------------test------------\n",
      " (0.5264512547190761, 0.0675438596491228)\n",
      "------------oot------------\n",
      " (0.4951169499183262, 0.02958328988982728)\n",
      "12 12 12\n",
      "\n",
      "Early stopping occured at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.53997\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5155176953027975, 0.034967334195577904)\n",
      "------------test------------\n",
      " (0.5399689096158117, 0.08592049744614705)\n",
      "------------oot------------\n",
      " (0.5085728518634368, 0.05655996941577174)\n",
      "12 12 14\n",
      "\n",
      "Early stopping occured at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.52643\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5020793359769185, 0.02212652254864339)\n",
      "------------test------------\n",
      " (0.5260826115922719, 0.08422163002442817)\n",
      "------------oot------------\n",
      " (0.5267994300212004, 0.05490564070482744)\n",
      "12 12 16\n",
      "\n",
      "Early stopping occured at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.53699\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.4797923438907535, 0.0005300706106573516)\n",
      "------------test------------\n",
      " (0.5363957361758828, 0.07408394403730845)\n",
      "------------oot------------\n",
      " (0.48923875392439675, 0.023139749070308968)\n",
      "12 12 18\n",
      "\n",
      "Early stopping occured at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.53241\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.4906947972270106, 0.012803452226980094)\n",
      "------------test------------\n",
      " (0.5323595380857206, 0.0844214967799245)\n",
      "------------oot------------\n",
      " (0.4844205794784463, 0.015326868939630922)\n",
      "14 14 12\n",
      "\n",
      "Early stopping occured at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.51885\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.4906038351610347, 0.012877223545368341)\n",
      "------------test------------\n",
      " (0.5188385520763935, 0.09166111481234734)\n",
      "------------oot------------\n",
      " (0.5080607977386207, 0.04560525492649359)\n",
      "14 14 14\n",
      "\n",
      "Early stopping occured at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.52743\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5014663572332101, 0.01541698730118124)\n",
      "------------test------------\n",
      " (0.527423939595825, 0.07662669331556743)\n",
      "------------oot------------\n",
      " (0.5307962325791541, 0.07302679595454073)\n",
      "14 14 16\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.51672\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.501943163598389, 0.022626678551293744)\n",
      "------------test------------\n",
      " (0.5164978902953586, 0.054541416833222334)\n",
      "------------oot------------\n",
      " (0.5031290909301543, 0.0406005630278386)\n",
      "14 14 18\n",
      "\n",
      "Early stopping occured at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.53311\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5070229618304491, 0.02625230196969419)\n",
      "------------test------------\n",
      " (0.5331379080612926, 0.08408838552076392)\n",
      "------------oot------------\n",
      " (0.5021814432511962, 0.029666701421471514)\n",
      "16 16 12\n",
      "\n",
      "Early stopping occured at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.54344\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5296030087869085, 0.05217134708457771)\n",
      "------------test------------\n",
      " (0.5434443704197202, 0.0884521430157672)\n",
      "------------oot------------\n",
      " (0.5375386647203976, 0.07204671045772082)\n",
      "16 16 14\n",
      "\n",
      "Early stopping occured at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.53678\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5101031512535371, 0.026372637202808136)\n",
      "------------test------------\n",
      " (0.53672218520986, 0.08807461692205198)\n",
      "------------oot------------\n",
      " (0.5033503631877108, 0.040649219754631094)\n",
      "16 16 16\n",
      "\n",
      "Early stopping occured at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.54427\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5146918626175011, 0.04058979153849751)\n",
      "------------test------------\n",
      " (0.5442682656007106, 0.08060182100821672)\n",
      "------------oot------------\n",
      " (0.4824615669783014, 0.0105932645188197)\n",
      "16 16 18\n",
      "\n",
      "Early stopping occured at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.56935\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5465721716990211, 0.08464480463798246)\n",
      "------------test------------\n",
      " (0.5693537641572284, 0.11140350877192984)\n",
      "------------oot------------\n",
      " (0.5074224678228432, 0.05409237827129601)\n",
      "18 18 12\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.50879\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5152532014383377, 0.035226142930914084)\n",
      "------------test------------\n",
      " (0.5087819231623363, 0.03355540750610703)\n",
      "------------oot------------\n",
      " (0.5203500967342068, 0.05824905293156779)\n",
      "18 18 14\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.53523\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5115346532308115, 0.035485222386684834)\n",
      "------------test------------\n",
      " (0.5351865423051299, 0.07974683544303796)\n",
      "------------oot------------\n",
      " (0.525300339438594, 0.09364334619261117)\n",
      "18 18 16\n",
      "\n",
      "Early stopping occured at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.52136\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5114762452970785, 0.024796367473210457)\n",
      "------------test------------\n",
      " (0.5213713080168777, 0.05292027537197419)\n",
      "------------oot------------\n",
      " (0.4969241997706183, 0.02874917457338476)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18 18\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.51868\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.4973288691533692, 0.016561187217393303)\n",
      "------------test------------\n",
      " (0.5186164779036199, 0.04870086608927382)\n",
      "------------oot------------\n",
      " (0.4861861235649162, 0.03508150001737742)\n",
      "20 20 12\n",
      "\n",
      "Early stopping occured at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.53022\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.517346547197739, 0.031172916586296506)\n",
      "------------test------------\n",
      " (0.5302409504774594, 0.07199644681323564)\n",
      "------------oot------------\n",
      " (0.5523303096653112, 0.10615507593924861)\n",
      "20 20 14\n",
      "\n",
      "Early stopping occured at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.53068\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.4937649699940239, 0.011843342206195595)\n",
      "------------test------------\n",
      " (0.530599600266489, 0.05853875194314895)\n",
      "------------oot------------\n",
      " (0.5186401603354998, 0.0491919507871964)\n",
      "20 20 16\n",
      "\n",
      "Early stopping occured at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.53041\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.514882517483464, 0.03481045170381292)\n",
      "------------test------------\n",
      " (0.5304108372196313, 0.05981567843659785)\n",
      "------------oot------------\n",
      " (0.5008074699660562, 0.03456017794460084)\n",
      "20 20 18\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.53212\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5064847696067583, 0.02149966938266945)\n",
      "------------test------------\n",
      " (0.5321174772373973, 0.08786364645791694)\n",
      "------------oot------------\n",
      " (0.4768382395532849, 0.012372710527230386)\n",
      "30 30 12\n",
      "\n",
      "Early stopping occured at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.5524\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5432974696437792, 0.0665210190729314)\n",
      "------------test------------\n",
      " (0.5524006218076838, 0.12426160337552739)\n",
      "------------oot------------\n",
      " (0.5201079715937396, 0.04700934904250509)\n",
      "30 30 14\n",
      "\n",
      "Early stopping occured at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.53387\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5228760797515328, 0.041076005438773544)\n",
      "------------test------------\n",
      " (0.5338729735731734, 0.06542305129913384)\n",
      "------------oot------------\n",
      " (0.4774429731577058, 0.0073749695895457545)\n",
      "30 30 16\n",
      "\n",
      "Early stopping occured at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.554\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5169070325724059, 0.0377128454815745)\n",
      "------------test------------\n",
      " (0.5540051077059738, 0.11456806573395512)\n",
      "------------oot------------\n",
      " (0.5245056129009835, 0.0824592499913113)\n",
      "30 30 18\n",
      "\n",
      "Early stopping occured at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.53383\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5338805270114697, 0.05086539170878063)\n",
      "------------test------------\n",
      " (0.5338574283810793, 0.05964912280701751)\n",
      "------------oot------------\n",
      " (0.5756762705777407, 0.12178778716157507)\n",
      "40 40 12\n",
      "\n",
      "Early stopping occured at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.51213\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5030200894866396, 0.022249158905450206)\n",
      "------------test------------\n",
      " (0.5119975571840994, 0.042182989118365544)\n",
      "------------oot------------\n",
      " (0.4684449541815822, 0.007513988808952848)\n",
      "40 40 14\n",
      "\n",
      "Early stopping occured at epoch 58 with best_epoch = 48 and best_val_0_auc = 0.55936\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5800043179909294, 0.1251100647766319)\n",
      "------------test------------\n",
      " (0.5593626471241394, 0.11241394625805018)\n",
      "------------oot------------\n",
      " (0.5560235869275594, 0.1066416432071734)\n",
      "40 40 16\n",
      "\n",
      "Early stopping occured at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.53644\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.4891743635870187, 0.008839834346166087)\n",
      "------------test------------\n",
      " (0.5337541638907395, 0.09479236064845659)\n",
      "------------oot------------\n",
      " (0.5094347710237607, 0.059618392242727525)\n",
      "40 40 18\n",
      "\n",
      "Early stopping occured at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.52495\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5098113823053063, 0.032389804939158995)\n",
      "------------test------------\n",
      " (0.5249111703308905, 0.06223628691983124)\n",
      "------------oot------------\n",
      " (0.4857447375432987, 0.038105168039481496)\n",
      "50 50 12\n",
      "\n",
      "Early stopping occured at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.53304\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5244693371883923, 0.05136175762534856)\n",
      "------------test------------\n",
      " (0.5330379746835443, 0.07613813013546522)\n",
      "------------oot------------\n",
      " (0.5391211668346483, 0.06833489729955167)\n",
      "50 50 14\n",
      "\n",
      "Early stopping occured at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.5289\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5013785084522304, 0.023088933693120706)\n",
      "------------test------------\n",
      " (0.528902953586498, 0.08011325782811457)\n",
      "------------oot------------\n",
      " (0.4894565507014678, 0.02190942897855619)\n",
      "50 50 16\n",
      "\n",
      "Early stopping occured at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.51057\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5056638775693907, 0.01948388502773868)\n",
      "------------test------------\n",
      " (0.5105729513657561, 0.03895180990450811)\n",
      "------------oot------------\n",
      " (0.5412446854110915, 0.08383554026344142)\n",
      "50 50 18\n",
      "\n",
      "Early stopping occured at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.54007\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5075469412313314, 0.037377964304157074)\n",
      "------------test------------\n",
      " (0.5400688429935598, 0.08925161003775259)\n",
      "------------oot------------\n",
      " (0.4884718312306676, 0.022590623153651013)\n",
      "60 60 12\n",
      "\n",
      "Early stopping occured at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.53764\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5241927962645995, 0.059491221551512374)\n",
      "------------test------------\n",
      " (0.5376393515434155, 0.0968798578725294)\n",
      "------------oot------------\n",
      " (0.5083515796058805, 0.045132589580509475)\n",
      "60 60 14\n",
      "\n",
      "Early stopping occured at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.53134\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.501951014490988, 0.01459819334718071)\n",
      "------------test------------\n",
      " (0.5313368865200977, 0.06865423051299124)\n",
      "------------oot------------\n",
      " (0.4990396088925961, 0.03889062662913145)\n",
      "60 60 16\n",
      "\n",
      "Early stopping occured at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.52716\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5116576279881614, 0.027205237898965784)\n",
      "------------test------------\n",
      " (0.527694870086609, 0.06897623806351316)\n",
      "------------oot------------\n",
      " (0.4847148368261912, 0.022847808709554163)\n",
      "60 60 18\n",
      "\n",
      "Early stopping occured at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.53978\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5101344194637163, 0.03228327644820206)\n",
      "------------test------------\n",
      " (0.5397690428603154, 0.08945147679324894)\n",
      "------------oot------------\n",
      " (0.5043721544503528, 0.03646474125047783)\n",
      "70 70 12\n",
      "\n",
      "Early stopping occured at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.54047\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5101677857572626, 0.027201583173100674)\n",
      "------------test------------\n",
      " (0.540414168332223, 0.06724405951587831)\n",
      "------------oot------------\n",
      " (0.4977536811130805, 0.02040802140895981)\n",
      "70 70 14\n",
      "\n",
      "Early stopping occured at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.52767\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5020821108613716, 0.022258092679787178)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test------------\n",
      " (0.5273073506551188, 0.07503886298023538)\n",
      "------------oot------------\n",
      " (0.5027039238174678, 0.03798700170298541)\n",
      "70 70 16\n",
      "\n",
      "Early stopping occured at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.53901\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5105784686563265, 0.030716888014461874)\n",
      "------------test------------\n",
      " (0.5404363757495003, 0.09397068620919391)\n",
      "------------oot------------\n",
      " (0.5311391466536914, 0.08139575296284707)\n",
      "70 70 18\n",
      "\n",
      "Early stopping occured at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.50745\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.49929274286499375, 0.010915041836459194)\n",
      "------------test------------\n",
      " (0.5032511658894071, 0.044481456806573394)\n",
      "------------oot------------\n",
      " (0.5100835273809937, 0.04283182149932219)\n",
      "80 80 12\n",
      "\n",
      "Early stopping occured at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.55117\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5026753270133648, 0.02888194490974516)\n",
      "------------test------------\n",
      " (0.5511703308905175, 0.09806795469686874)\n",
      "------------oot------------\n",
      " (0.525554049514012, 0.06596461960866096)\n",
      "80 80 14\n",
      "\n",
      "Early stopping occured at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.54523\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5138686017763321, 0.03795514027040914)\n",
      "------------test------------\n",
      " (0.5435332000888297, 0.09184987785920501)\n",
      "------------oot------------\n",
      " (0.5021872357186714, 0.027942863100823723)\n",
      "80 80 16\n",
      "\n",
      "Early stopping occured at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.52298\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5084962224347378, 0.019996494170373857)\n",
      "------------test------------\n",
      " (0.5230013324450367, 0.054197201865422984)\n",
      "------------oot------------\n",
      " (0.5131535351429002, 0.06424078128801305)\n",
      "80 80 18\n",
      "\n",
      "Early stopping occured at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.55335\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5117660515221595, 0.03460172624885027)\n",
      "------------test------------\n",
      " (0.5532467244059516, 0.09871196979791252)\n",
      "------------oot------------\n",
      " (0.48510409064053106, 0.00125812393563407)\n",
      "90 90 12\n",
      "\n",
      "Early stopping occured at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.57123\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5486189535436966, 0.07598012641290686)\n",
      "------------test------------\n",
      " (0.5712291805463025, 0.12482789251610032)\n",
      "------------oot------------\n",
      " (0.572778878346598, 0.12298335244847597)\n",
      "90 90 14\n",
      "\n",
      "Early stopping occured at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.53839\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5142395564516402, 0.03947455870877181)\n",
      "------------test------------\n",
      " (0.5381812125249834, 0.0939151676660005)\n",
      "------------oot------------\n",
      " (0.5450016798155679, 0.09081430507767696)\n",
      "90 90 16\n",
      "\n",
      "Early stopping occured at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.52034\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.501657012099173, 0.015716133381250774)\n",
      "------------test------------\n",
      " (0.5202043082389518, 0.06771041527870308)\n",
      "------------oot------------\n",
      " (0.49430716296527993, 0.024516039342439178)\n",
      "90 90 18\n",
      "\n",
      "Early stopping occured at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.52386\n",
      "Best weights from best epoch are automatically used!\n",
      "------------train------------\n",
      " (0.5061151685336225, 0.02490871645350823)\n",
      "------------test------------\n",
      " (0.523842993559849, 0.051532311792138574)\n",
      "------------oot------------\n",
      " (0.4868128685457431, 0.01894136864421514)\n",
      "['nd,na,ns', 30, 30, 18, 0.5756762705777407]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "n_steps: 决策的步数，通常为{3 ~ 10}\n",
    "n_d: 预测阶段的特征数，通常为{8 ~ 64}\n",
    "n_a: Attentive阶段的特征数，通常为{8 ~ 64}\n",
    "gamma: Attentive中注意力更新的比例，通常为{1.0 ~ 2.0}\n",
    "momentum: BN层的动量，通常为{0.0 ~ 1.0}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def model_metrics2(nnmodel, x, y):\n",
    "    yprob = nnmodel.predict_proba(x)[:,1]\n",
    "    fpr,tpr,_ = roc_curve(y, yprob,pos_label=1)\n",
    "    return auc(fpr, tpr),max(tpr-fpr)\n",
    "\n",
    "\n",
    "bestval=0\n",
    "\n",
    "for nd in list(range(1,20,3)) + list(range(20,100,10)):\n",
    "    for ns in range(1,20,3):\n",
    "        print(nd,nd,ns)\n",
    "        clf = TabNetClassifier(n_d=nd,\n",
    "                               n_a=nd,\n",
    "                               n_steps=ns,\n",
    "                               verbose=False)  \n",
    "\n",
    "        clf.fit(\n",
    "            train_x.values,\n",
    "            train_y.values,\n",
    "            num_workers=16,\n",
    "            max_epochs=200,\n",
    "            patience=3,\n",
    "            batch_size=2024,\n",
    "            eval_set=[(test_x.values,test_y.values)]\n",
    "        )\n",
    "\n",
    "        print('------------train------------\\n',model_metrics2(clf, train_x.values,train_y.values))\n",
    "\n",
    "        print('------------test------------\\n',model_metrics2(clf, test_x.values,test_y.values))\n",
    "\n",
    "        print('------------oot------------\\n',model_metrics2(clf, oot_x.values,oot_y.values))\n",
    "        if model_metrics2(clf, test_x.values,test_y.values)[0] > bestval:\n",
    "            bestval =model_metrics2(clf, oot_x.values,oot_y.values)[0]\n",
    "            bestparas = ['nd,na,ns',nd,nd,ns,bestval ]\n",
    "print(bestparas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fe598f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nd,na,ns', 30, 30, 18, 0.5756762705777407]\n"
     ]
    }
   ],
   "source": [
    "print(bestparas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d39a0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "274b3178",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### qcut-onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6199944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/filter_feas_df32n_old.pkl')\n",
    "df.head()\n",
    "\n",
    "# qcut-onehot\n",
    "df2 = df[final_feas].apply(lambda x: pd.qcut(x.replace([np.inf, -np.inf], np.nan).fillna(-9999),q=50,duplicates='drop'))\n",
    "df2 = df2.applymap(lambda x: str(x).replace(']','qcut').replace('(','').replace(',','_'))\n",
    "df2 = pd.get_dummies(df2,prefix_sep='_')\n",
    "df2.head()\n",
    "\n",
    "# 等频onehot 存储\n",
    "pd.concat([df,df2],axis=1).to_pickle('./data/filter_feas_df32n_old_qcut_oh.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7134dc0",
   "metadata": {},
   "source": [
    "#### lgb_onehot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b875c6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26ade2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6506, 1717)\n",
      "1    3480\n",
      "0    1896\n",
      "Name: label, dtype: int64\n",
      "1    727\n",
      "0    403\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y,oot_x, oot_y,df,final_feas =  read_train(file='./data/filter_feas_df32n_old.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf33aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad97904a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6321724090841454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6321724090841454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------train------------\n",
      " 0.8595395762520878\n",
      "------------test------------\n",
      " 0.6037486255603485\n",
      "------------oot------------\n",
      " 0.6176646267164082\n"
     ]
    }
   ],
   "source": [
    "paras = {'boosting_type': 'dart', 'class_weight': 'balanced', 'feature_fraction': 0.6321724090841454, 'learning_rate': 0.35706456691656796, 'max_depth': 12, 'min_child_samples': 2, 'min_child_weight': 0.002290570255954292, 'min_split_gain': 1.23684757609968, 'n_estimators': 1700, 'num_leaves': 1640, 'reg_alpha': 8.94729123569297, 'reg_lambda': 7.85980599994622, 'subsample': 0.7809264483077517, 'subsample_for_bin': 20000, 'n_jobs': -1, 'objective': 'binary', 'verbose': -1, 'random_state': 0}\n",
    "\n",
    "\n",
    "clf = LGBMClassifier(**paras)\n",
    "clf.fit(train_x, train_y,\n",
    "        eval_set=[(test_x,test_y)],\n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=50,verbose=-1)\n",
    "\n",
    "\n",
    "print('------------train------------\\n',model_metrics(clf, train_x,train_y))\n",
    "\n",
    "\n",
    "print('------------test------------\\n',model_metrics(clf, test_x,test_y))\n",
    "\n",
    "print('------------oot------------\\n',model_metrics(clf, oot_x,oot_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f1cfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6506, 1763000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred = clf.predict(df[final_feas],pred_leaf=True) \n",
    "train_matrix = np.zeros([len(y_pred), len(y_pred[0])*clf.get_params()['num_leaves']],dtype=np.int64)\n",
    "print(train_matrix.shape) \n",
    "\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0]))*clf.get_params()['num_leaves'] + np.array(y_pred[i])\n",
    "    train_matrix[i][temp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9af8ddc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1749994\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>1640</th>\n",
       "      <th>1641</th>\n",
       "      <th>1642</th>\n",
       "      <th>1643</th>\n",
       "      <th>1644</th>\n",
       "      <th>1645</th>\n",
       "      <th>1646</th>\n",
       "      <th>1647</th>\n",
       "      <th>1648</th>\n",
       "      <th>1649</th>\n",
       "      <th>1650</th>\n",
       "      <th>1651</th>\n",
       "      <th>1652</th>\n",
       "      <th>1653</th>\n",
       "      <th>1654</th>\n",
       "      <th>1655</th>\n",
       "      <th>1656</th>\n",
       "      <th>1657</th>\n",
       "      <th>1658</th>\n",
       "      <th>1659</th>\n",
       "      <th>1660</th>\n",
       "      <th>1661</th>\n",
       "      <th>1662</th>\n",
       "      <th>1663</th>\n",
       "      <th>1664</th>\n",
       "      <th>1665</th>\n",
       "      <th>1666</th>\n",
       "      <th>1667</th>\n",
       "      <th>1668</th>\n",
       "      <th>1669</th>\n",
       "      <th>1670</th>\n",
       "      <th>1671</th>\n",
       "      <th>1672</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "      <th>1683</th>\n",
       "      <th>1684</th>\n",
       "      <th>1685</th>\n",
       "      <th>1686</th>\n",
       "      <th>1687</th>\n",
       "      <th>1688</th>\n",
       "      <th>1689</th>\n",
       "      <th>1690</th>\n",
       "      <th>1691</th>\n",
       "      <th>3280</th>\n",
       "      <th>3281</th>\n",
       "      <th>3282</th>\n",
       "      <th>3283</th>\n",
       "      <th>3284</th>\n",
       "      <th>3285</th>\n",
       "      <th>3286</th>\n",
       "      <th>3287</th>\n",
       "      <th>3288</th>\n",
       "      <th>3289</th>\n",
       "      <th>3290</th>\n",
       "      <th>3291</th>\n",
       "      <th>3292</th>\n",
       "      <th>3293</th>\n",
       "      <th>3294</th>\n",
       "      <th>3295</th>\n",
       "      <th>3296</th>\n",
       "      <th>3297</th>\n",
       "      <th>3298</th>\n",
       "      <th>3299</th>\n",
       "      <th>3300</th>\n",
       "      <th>3301</th>\n",
       "      <th>3302</th>\n",
       "      <th>3303</th>\n",
       "      <th>3304</th>\n",
       "      <th>3305</th>\n",
       "      <th>3306</th>\n",
       "      <th>3307</th>\n",
       "      <th>3308</th>\n",
       "      <th>3309</th>\n",
       "      <th>3310</th>\n",
       "      <th>3311</th>\n",
       "      <th>3312</th>\n",
       "      <th>3313</th>\n",
       "      <th>3314</th>\n",
       "      <th>3315</th>\n",
       "      <th>3316</th>\n",
       "      <th>3317</th>\n",
       "      <th>3318</th>\n",
       "      <th>3319</th>\n",
       "      <th>3320</th>\n",
       "      <th>3321</th>\n",
       "      <th>3322</th>\n",
       "      <th>4920</th>\n",
       "      <th>4921</th>\n",
       "      <th>4922</th>\n",
       "      <th>4923</th>\n",
       "      <th>4924</th>\n",
       "      <th>4925</th>\n",
       "      <th>4926</th>\n",
       "      <th>4927</th>\n",
       "      <th>4928</th>\n",
       "      <th>4929</th>\n",
       "      <th>4930</th>\n",
       "      <th>4931</th>\n",
       "      <th>4932</th>\n",
       "      <th>4933</th>\n",
       "      <th>4934</th>\n",
       "      <th>4935</th>\n",
       "      <th>4936</th>\n",
       "      <th>4937</th>\n",
       "      <th>4938</th>\n",
       "      <th>4939</th>\n",
       "      <th>4940</th>\n",
       "      <th>4941</th>\n",
       "      <th>4942</th>\n",
       "      <th>4943</th>\n",
       "      <th>4944</th>\n",
       "      <th>4945</th>\n",
       "      <th>4946</th>\n",
       "      <th>4947</th>\n",
       "      <th>4948</th>\n",
       "      <th>4949</th>\n",
       "      <th>4950</th>\n",
       "      <th>4951</th>\n",
       "      <th>6560</th>\n",
       "      <th>6561</th>\n",
       "      <th>6562</th>\n",
       "      <th>6563</th>\n",
       "      <th>6564</th>\n",
       "      <th>6565</th>\n",
       "      <th>6566</th>\n",
       "      <th>6567</th>\n",
       "      <th>6568</th>\n",
       "      <th>6569</th>\n",
       "      <th>6570</th>\n",
       "      <th>6571</th>\n",
       "      <th>6572</th>\n",
       "      <th>6573</th>\n",
       "      <th>6574</th>\n",
       "      <th>6575</th>\n",
       "      <th>6576</th>\n",
       "      <th>6577</th>\n",
       "      <th>6578</th>\n",
       "      <th>6579</th>\n",
       "      <th>6580</th>\n",
       "      <th>6581</th>\n",
       "      <th>6582</th>\n",
       "      <th>6583</th>\n",
       "      <th>6584</th>\n",
       "      <th>6585</th>\n",
       "      <th>6586</th>\n",
       "      <th>6587</th>\n",
       "      <th>6588</th>\n",
       "      <th>6589</th>\n",
       "      <th>6590</th>\n",
       "      <th>6591</th>\n",
       "      <th>6592</th>\n",
       "      <th>6593</th>\n",
       "      <th>6594</th>\n",
       "      <th>6595</th>\n",
       "      <th>6596</th>\n",
       "      <th>6597</th>\n",
       "      <th>6598</th>\n",
       "      <th>8200</th>\n",
       "      <th>8201</th>\n",
       "      <th>8202</th>\n",
       "      <th>8203</th>\n",
       "      <th>8204</th>\n",
       "      <th>8205</th>\n",
       "      <th>8206</th>\n",
       "      <th>8207</th>\n",
       "      <th>8208</th>\n",
       "      <th>8209</th>\n",
       "      <th>8210</th>\n",
       "      <th>8211</th>\n",
       "      <th>8212</th>\n",
       "      <th>8213</th>\n",
       "      <th>8214</th>\n",
       "      <th>8215</th>\n",
       "      <th>8216</th>\n",
       "      <th>8217</th>\n",
       "      <th>8218</th>\n",
       "      <th>8219</th>\n",
       "      <th>8220</th>\n",
       "      <th>8221</th>\n",
       "      <th>8222</th>\n",
       "      <th>8223</th>\n",
       "      <th>8224</th>\n",
       "      <th>8225</th>\n",
       "      <th>8226</th>\n",
       "      <th>8227</th>\n",
       "      <th>8228</th>\n",
       "      <th>8229</th>\n",
       "      <th>8230</th>\n",
       "      <th>8231</th>\n",
       "      <th>8232</th>\n",
       "      <th>8233</th>\n",
       "      <th>8234</th>\n",
       "      <th>8235</th>\n",
       "      <th>8236</th>\n",
       "      <th>8237</th>\n",
       "      <th>8238</th>\n",
       "      <th>8239</th>\n",
       "      <th>8240</th>\n",
       "      <th>8241</th>\n",
       "      <th>8242</th>\n",
       "      <th>8243</th>\n",
       "      <th>9840</th>\n",
       "      <th>9841</th>\n",
       "      <th>9842</th>\n",
       "      <th>9843</th>\n",
       "      <th>9844</th>\n",
       "      <th>9845</th>\n",
       "      <th>9846</th>\n",
       "      <th>9847</th>\n",
       "      <th>9848</th>\n",
       "      <th>9849</th>\n",
       "      <th>9850</th>\n",
       "      <th>9851</th>\n",
       "      <th>9852</th>\n",
       "      <th>9853</th>\n",
       "      <th>9854</th>\n",
       "      <th>9855</th>\n",
       "      <th>9856</th>\n",
       "      <th>9857</th>\n",
       "      <th>9858</th>\n",
       "      <th>9859</th>\n",
       "      <th>9860</th>\n",
       "      <th>9861</th>\n",
       "      <th>9862</th>\n",
       "      <th>9863</th>\n",
       "      <th>9864</th>\n",
       "      <th>9865</th>\n",
       "      <th>9866</th>\n",
       "      <th>9867</th>\n",
       "      <th>11480</th>\n",
       "      <th>11481</th>\n",
       "      <th>11482</th>\n",
       "      <th>11483</th>\n",
       "      <th>11484</th>\n",
       "      <th>11485</th>\n",
       "      <th>11486</th>\n",
       "      <th>11487</th>\n",
       "      <th>11488</th>\n",
       "      <th>11489</th>\n",
       "      <th>...</th>\n",
       "      <th>1707250</th>\n",
       "      <th>1708880</th>\n",
       "      <th>1708881</th>\n",
       "      <th>1708882</th>\n",
       "      <th>1708883</th>\n",
       "      <th>1708884</th>\n",
       "      <th>1708885</th>\n",
       "      <th>1708886</th>\n",
       "      <th>1708887</th>\n",
       "      <th>1708888</th>\n",
       "      <th>1710520</th>\n",
       "      <th>1710521</th>\n",
       "      <th>1710522</th>\n",
       "      <th>1710523</th>\n",
       "      <th>1710524</th>\n",
       "      <th>1710525</th>\n",
       "      <th>1710526</th>\n",
       "      <th>1710527</th>\n",
       "      <th>1710528</th>\n",
       "      <th>1710529</th>\n",
       "      <th>1712160</th>\n",
       "      <th>1712161</th>\n",
       "      <th>1712162</th>\n",
       "      <th>1712163</th>\n",
       "      <th>1712164</th>\n",
       "      <th>1712165</th>\n",
       "      <th>1712166</th>\n",
       "      <th>1712167</th>\n",
       "      <th>1712168</th>\n",
       "      <th>1713800</th>\n",
       "      <th>1713801</th>\n",
       "      <th>1713802</th>\n",
       "      <th>1713803</th>\n",
       "      <th>1713804</th>\n",
       "      <th>1713805</th>\n",
       "      <th>1713806</th>\n",
       "      <th>1713807</th>\n",
       "      <th>1713808</th>\n",
       "      <th>1713809</th>\n",
       "      <th>1713810</th>\n",
       "      <th>1715440</th>\n",
       "      <th>1715441</th>\n",
       "      <th>1715442</th>\n",
       "      <th>1715443</th>\n",
       "      <th>1715444</th>\n",
       "      <th>1715445</th>\n",
       "      <th>1715446</th>\n",
       "      <th>1715447</th>\n",
       "      <th>1715448</th>\n",
       "      <th>1715449</th>\n",
       "      <th>1715450</th>\n",
       "      <th>1717080</th>\n",
       "      <th>1717081</th>\n",
       "      <th>1717082</th>\n",
       "      <th>1717083</th>\n",
       "      <th>1717084</th>\n",
       "      <th>1717085</th>\n",
       "      <th>1718720</th>\n",
       "      <th>1718721</th>\n",
       "      <th>1718722</th>\n",
       "      <th>1718723</th>\n",
       "      <th>1718724</th>\n",
       "      <th>1718725</th>\n",
       "      <th>1718726</th>\n",
       "      <th>1718727</th>\n",
       "      <th>1718728</th>\n",
       "      <th>1718729</th>\n",
       "      <th>1718730</th>\n",
       "      <th>1718731</th>\n",
       "      <th>1718732</th>\n",
       "      <th>1718733</th>\n",
       "      <th>1718734</th>\n",
       "      <th>1718735</th>\n",
       "      <th>1720360</th>\n",
       "      <th>1720361</th>\n",
       "      <th>1720362</th>\n",
       "      <th>1720363</th>\n",
       "      <th>1720364</th>\n",
       "      <th>1720365</th>\n",
       "      <th>1720366</th>\n",
       "      <th>1720367</th>\n",
       "      <th>1720368</th>\n",
       "      <th>1720369</th>\n",
       "      <th>1720370</th>\n",
       "      <th>1720371</th>\n",
       "      <th>1722000</th>\n",
       "      <th>1722001</th>\n",
       "      <th>1722002</th>\n",
       "      <th>1722003</th>\n",
       "      <th>1722004</th>\n",
       "      <th>1722005</th>\n",
       "      <th>1722006</th>\n",
       "      <th>1722007</th>\n",
       "      <th>1722008</th>\n",
       "      <th>1722009</th>\n",
       "      <th>1723640</th>\n",
       "      <th>1723641</th>\n",
       "      <th>1723642</th>\n",
       "      <th>1723643</th>\n",
       "      <th>1723644</th>\n",
       "      <th>1723645</th>\n",
       "      <th>1723646</th>\n",
       "      <th>1723647</th>\n",
       "      <th>1723648</th>\n",
       "      <th>1723649</th>\n",
       "      <th>1723650</th>\n",
       "      <th>1725280</th>\n",
       "      <th>1725281</th>\n",
       "      <th>1726920</th>\n",
       "      <th>1726921</th>\n",
       "      <th>1728560</th>\n",
       "      <th>1728561</th>\n",
       "      <th>1728562</th>\n",
       "      <th>1728563</th>\n",
       "      <th>1728564</th>\n",
       "      <th>1728565</th>\n",
       "      <th>1728566</th>\n",
       "      <th>1730200</th>\n",
       "      <th>1730201</th>\n",
       "      <th>1730202</th>\n",
       "      <th>1731840</th>\n",
       "      <th>1731841</th>\n",
       "      <th>1731842</th>\n",
       "      <th>1731843</th>\n",
       "      <th>1731844</th>\n",
       "      <th>1731845</th>\n",
       "      <th>1731846</th>\n",
       "      <th>1731847</th>\n",
       "      <th>1731848</th>\n",
       "      <th>1731849</th>\n",
       "      <th>1733480</th>\n",
       "      <th>1733481</th>\n",
       "      <th>1733482</th>\n",
       "      <th>1733483</th>\n",
       "      <th>1733484</th>\n",
       "      <th>1733485</th>\n",
       "      <th>1733486</th>\n",
       "      <th>1733487</th>\n",
       "      <th>1733488</th>\n",
       "      <th>1733489</th>\n",
       "      <th>1733490</th>\n",
       "      <th>1733491</th>\n",
       "      <th>1733492</th>\n",
       "      <th>1735120</th>\n",
       "      <th>1735121</th>\n",
       "      <th>1735122</th>\n",
       "      <th>1735123</th>\n",
       "      <th>1735124</th>\n",
       "      <th>1735125</th>\n",
       "      <th>1735126</th>\n",
       "      <th>1735127</th>\n",
       "      <th>1735128</th>\n",
       "      <th>1735129</th>\n",
       "      <th>1735130</th>\n",
       "      <th>1735131</th>\n",
       "      <th>1735132</th>\n",
       "      <th>1735133</th>\n",
       "      <th>1735134</th>\n",
       "      <th>1736760</th>\n",
       "      <th>1736761</th>\n",
       "      <th>1736762</th>\n",
       "      <th>1736763</th>\n",
       "      <th>1736764</th>\n",
       "      <th>1736765</th>\n",
       "      <th>1736766</th>\n",
       "      <th>1736767</th>\n",
       "      <th>1736768</th>\n",
       "      <th>1738400</th>\n",
       "      <th>1738401</th>\n",
       "      <th>1738402</th>\n",
       "      <th>1738403</th>\n",
       "      <th>1738404</th>\n",
       "      <th>1738405</th>\n",
       "      <th>1738406</th>\n",
       "      <th>1738407</th>\n",
       "      <th>1738408</th>\n",
       "      <th>1740040</th>\n",
       "      <th>1740041</th>\n",
       "      <th>1740042</th>\n",
       "      <th>1740043</th>\n",
       "      <th>1740044</th>\n",
       "      <th>1740045</th>\n",
       "      <th>1740046</th>\n",
       "      <th>1741680</th>\n",
       "      <th>1741681</th>\n",
       "      <th>1741682</th>\n",
       "      <th>1741683</th>\n",
       "      <th>1741684</th>\n",
       "      <th>1741685</th>\n",
       "      <th>1741686</th>\n",
       "      <th>1741687</th>\n",
       "      <th>1743320</th>\n",
       "      <th>1743321</th>\n",
       "      <th>1743322</th>\n",
       "      <th>1743323</th>\n",
       "      <th>1743324</th>\n",
       "      <th>1743325</th>\n",
       "      <th>1743326</th>\n",
       "      <th>1743327</th>\n",
       "      <th>1743328</th>\n",
       "      <th>1743329</th>\n",
       "      <th>1744960</th>\n",
       "      <th>1744961</th>\n",
       "      <th>1744962</th>\n",
       "      <th>1744963</th>\n",
       "      <th>1744964</th>\n",
       "      <th>1744965</th>\n",
       "      <th>1744966</th>\n",
       "      <th>1744967</th>\n",
       "      <th>1744968</th>\n",
       "      <th>1744969</th>\n",
       "      <th>1744970</th>\n",
       "      <th>1744971</th>\n",
       "      <th>1746600</th>\n",
       "      <th>1746601</th>\n",
       "      <th>1746602</th>\n",
       "      <th>1746603</th>\n",
       "      <th>1746604</th>\n",
       "      <th>1746605</th>\n",
       "      <th>1746606</th>\n",
       "      <th>1746607</th>\n",
       "      <th>1746608</th>\n",
       "      <th>1746609</th>\n",
       "      <th>1748240</th>\n",
       "      <th>1748241</th>\n",
       "      <th>1748242</th>\n",
       "      <th>1748243</th>\n",
       "      <th>1748244</th>\n",
       "      <th>1748245</th>\n",
       "      <th>1748246</th>\n",
       "      <th>1749880</th>\n",
       "      <th>1749881</th>\n",
       "      <th>1749882</th>\n",
       "      <th>1749883</th>\n",
       "      <th>1749884</th>\n",
       "      <th>1749885</th>\n",
       "      <th>1749886</th>\n",
       "      <th>1749887</th>\n",
       "      <th>1749888</th>\n",
       "      <th>1749889</th>\n",
       "      <th>1749890</th>\n",
       "      <th>1749891</th>\n",
       "      <th>1751520</th>\n",
       "      <th>1751521</th>\n",
       "      <th>1751522</th>\n",
       "      <th>1751523</th>\n",
       "      <th>1751524</th>\n",
       "      <th>1751525</th>\n",
       "      <th>1751526</th>\n",
       "      <th>1751527</th>\n",
       "      <th>1751528</th>\n",
       "      <th>1753160</th>\n",
       "      <th>1753161</th>\n",
       "      <th>1753162</th>\n",
       "      <th>1753163</th>\n",
       "      <th>1753164</th>\n",
       "      <th>1753165</th>\n",
       "      <th>1754800</th>\n",
       "      <th>1754801</th>\n",
       "      <th>1754802</th>\n",
       "      <th>1754803</th>\n",
       "      <th>1754804</th>\n",
       "      <th>1754805</th>\n",
       "      <th>1754806</th>\n",
       "      <th>1754807</th>\n",
       "      <th>1754808</th>\n",
       "      <th>1754809</th>\n",
       "      <th>1756440</th>\n",
       "      <th>1756441</th>\n",
       "      <th>1756442</th>\n",
       "      <th>1756443</th>\n",
       "      <th>1756444</th>\n",
       "      <th>1756445</th>\n",
       "      <th>1758080</th>\n",
       "      <th>1758081</th>\n",
       "      <th>1758082</th>\n",
       "      <th>1758083</th>\n",
       "      <th>1758084</th>\n",
       "      <th>1759720</th>\n",
       "      <th>1759721</th>\n",
       "      <th>1759722</th>\n",
       "      <th>1759723</th>\n",
       "      <th>1759724</th>\n",
       "      <th>1759725</th>\n",
       "      <th>1759726</th>\n",
       "      <th>1759727</th>\n",
       "      <th>1759728</th>\n",
       "      <th>1761360</th>\n",
       "      <th>1761361</th>\n",
       "      <th>1761362</th>\n",
       "      <th>1761363</th>\n",
       "      <th>1761364</th>\n",
       "      <th>1761365</th>\n",
       "      <th>1761366</th>\n",
       "      <th>1761367</th>\n",
       "      <th>1761368</th>\n",
       "      <th>1761369</th>\n",
       "      <th>1761370</th>\n",
       "      <th>1761371</th>\n",
       "      <th>1761372</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13006 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0        1        2        3        4        5        6        7        \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   8        9        10       11       12       13       14       15       \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   16       17       18       19       20       21       22       23       \\\n",
       "0        0        0        1        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        1        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   24       25       26       27       28       29       30       31       \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   32       33       34       35       36       37       38       39       \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        1        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        1        0        0        0        0        0        0        0   \n",
       "\n",
       "   40       41       42       43       44       45       46       47       \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        1        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   48       49       50       51       1640     1641     1642     1643     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   1644     1645     1646     1647     1648     1649     1650     1651     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   1652     1653     1654     1655     1656     1657     1658     1659     \\\n",
       "0        0        0        0        0        0        0        1        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        1   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   1660     1661     1662     1663     1664     1665     1666     1667     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   1668     1669     1670     1671     1672     1673     1674     1675     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        1        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   1676     1677     1678     1679     1680     1681     1682     1683     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        1        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   1684     1685     1686     1687     1688     1689     1690     1691     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        1        0        0        0        0        0   \n",
       "\n",
       "   3280     3281     3282     3283     3284     3285     3286     3287     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        1        0        0        0        0        0   \n",
       "\n",
       "   3288     3289     3290     3291     3292     3293     3294     3295     \\\n",
       "0        0        1        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        1        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   3296     3297     3298     3299     3300     3301     3302     3303     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        1        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   3304     3305     3306     3307     3308     3309     3310     3311     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   3312     3313     3314     3315     3316     3317     3318     3319     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        1        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   3320     3321     3322     4920     4921     4922     4923     4924     \\\n",
       "0        0        0        0        0        0        1        0        0   \n",
       "1        0        0        0        0        0        1        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        1        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   4925     4926     4927     4928     4929     4930     4931     4932     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        1        0        0        0        0        0   \n",
       "\n",
       "   4933     4934     4935     4936     4937     4938     4939     4940     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        1        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   4941     4942     4943     4944     4945     4946     4947     4948     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   4949     4950     4951     6560     6561     6562     6563     6564     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        1        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   6565     6566     6567     6568     6569     6570     6571     6572     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   6573     6574     6575     6576     6577     6578     6579     6580     \\\n",
       "0        0        0        0        0        0        1        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        1        0   \n",
       "4        0        1        0        0        0        0        0        0   \n",
       "\n",
       "   6581     6582     6583     6584     6585     6586     6587     6588     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        1        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   6589     6590     6591     6592     6593     6594     6595     6596     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   6597     6598     8200     8201     8202     8203     8204     8205     \\\n",
       "0        0        0        0        0        0        0        0        1   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        1        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   8206     8207     8208     8209     8210     8211     8212     8213     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        1        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   8214     8215     8216     8217     8218     8219     8220     8221     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        1        0        0        0        0        0        0   \n",
       "\n",
       "   8222     8223     8224     8225     8226     8227     8228     8229     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   8230     8231     8232     8233     8234     8235     8236     8237     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        1        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   8238     8239     8240     8241     8242     8243     9840     9841     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        1        0   \n",
       "2        0        0        0        0        0        0        1        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   9842     9843     9844     9845     9846     9847     9848     9849     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        1        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   9850     9851     9852     9853     9854     9855     9856     9857     \\\n",
       "0        0        0        0        0        1        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        1        0        0        0        0        0        0   \n",
       "\n",
       "   9858     9859     9860     9861     9862     9863     9864     9865     \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   9866     9867     11480    11481    11482    11483    11484    11485    \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        1        0        0   \n",
       "2        0        0        0        1        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   11486    11487    11488    11489    ...  1707250  1708880  1708881  \\\n",
       "0        0        1        0        0  ...        0        0        0   \n",
       "1        0        0        0        0  ...        0        1        0   \n",
       "2        0        0        0        0  ...        0        0        0   \n",
       "3        0        0        0        0  ...        1        0        0   \n",
       "4        0        0        0        0  ...        0        0        0   \n",
       "\n",
       "   1708882  1708883  1708884  1708885  1708886  1708887  1708888  1710520  \\\n",
       "0        0        0        0        0        1        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        1        0        0        0        0        1   \n",
       "3        0        0        0        0        1        0        0        0   \n",
       "4        1        0        0        0        0        0        0        0   \n",
       "\n",
       "   1710521  1710522  1710523  1710524  1710525  1710526  1710527  1710528  \\\n",
       "0        0        0        0        0        0        0        1        0   \n",
       "1        0        0        0        0        1        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        1        0        0        0   \n",
       "4        0        0        0        0        1        0        0        0   \n",
       "\n",
       "   1710529  1712160  1712161  1712162  1712163  1712164  1712165  1712166  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        1        0        0        0        0   \n",
       "2        0        1        0        0        0        0        0        0   \n",
       "3        0        0        0        1        0        0        0        0   \n",
       "4        0        0        1        0        0        0        0        0   \n",
       "\n",
       "   1712167  1712168  1713800  1713801  1713802  1713803  1713804  1713805  \\\n",
       "0        1        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   1713806  1713807  1713808  1713809  1713810  1715440  1715441  1715442  \\\n",
       "0        1        0        0        0        0        0        0        1   \n",
       "1        0        0        0        1        0        0        0        0   \n",
       "2        0        0        0        1        0        0        1        0   \n",
       "3        1        0        0        0        0        0        0        1   \n",
       "4        0        0        0        1        0        0        0        0   \n",
       "\n",
       "   1715443  1715444  1715445  1715446  1715447  1715448  1715449  1715450  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        1        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        1        0   \n",
       "\n",
       "   1717080  1717081  1717082  1717083  1717084  1717085  1718720  1718721  \\\n",
       "0        0        1        0        0        0        0        0        0   \n",
       "1        0        0        0        0        1        0        1        0   \n",
       "2        0        1        0        0        0        0        0        0   \n",
       "3        0        1        0        0        0        0        0        0   \n",
       "4        1        0        0        0        0        0        0        0   \n",
       "\n",
       "   1718722  1718723  1718724  1718725  1718726  1718727  1718728  1718729  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   1718730  1718731  1718732  1718733  1718734  1718735  1720360  1720361  \\\n",
       "0        0        0        0        0        0        1        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        1        0        0        0   \n",
       "3        0        0        0        0        1        0        0        0   \n",
       "4        0        1        0        0        0        0        0        0   \n",
       "\n",
       "   1720362  1720363  1720364  1720365  1720366  1720367  1720368  1720369  \\\n",
       "0        0        0        1        0        0        0        0        0   \n",
       "1        0        0        1        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        1        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        1        0        0        0        0        0   \n",
       "\n",
       "   1720370  1720371  1722000  1722001  1722002  1722003  1722004  1722005  \\\n",
       "0        0        0        0        0        0        0        0        1   \n",
       "1        0        0        0        0        1        0        0        0   \n",
       "2        0        0        1        0        0        0        0        0   \n",
       "3        0        1        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        1        0        0   \n",
       "\n",
       "   1722006  1722007  1722008  1722009  1723640  1723641  1723642  1723643  \\\n",
       "0        0        0        0        0        0        1        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        1        0   \n",
       "3        0        0        0        1        0        0        1        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   1723644  1723645  1723646  1723647  1723648  1723649  1723650  1725280  \\\n",
       "0        0        0        0        0        0        0        0        1   \n",
       "1        1        0        0        0        0        0        0        1   \n",
       "2        0        0        0        0        0        0        0        1   \n",
       "3        0        0        0        0        0        0        0        1   \n",
       "4        0        1        0        0        0        0        0        1   \n",
       "\n",
       "   1725281  1726920  1726921  1728560  1728561  1728562  1728563  1728564  \\\n",
       "0        0        0        1        0        0        0        0        0   \n",
       "1        0        0        1        1        0        0        0        0   \n",
       "2        0        0        1        1        0        0        0        0   \n",
       "3        0        1        0        0        1        0        0        0   \n",
       "4        0        1        0        0        0        0        0        0   \n",
       "\n",
       "   1728565  1728566  1730200  1730201  1730202  1731840  1731841  1731842  \\\n",
       "0        1        0        1        0        0        0        0        0   \n",
       "1        0        0        1        0        0        0        0        0   \n",
       "2        0        0        1        0        0        1        0        0   \n",
       "3        0        0        0        1        0        0        0        0   \n",
       "4        1        0        0        1        0        0        0        0   \n",
       "\n",
       "   1731843  1731844  1731845  1731846  1731847  1731848  1731849  1733480  \\\n",
       "0        0        0        0        0        0        1        0        0   \n",
       "1        0        0        0        1        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        1        0        0   \n",
       "4        0        0        0        1        0        0        0        0   \n",
       "\n",
       "   1733481  1733482  1733483  1733484  1733485  1733486  1733487  1733488  \\\n",
       "0        1        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        1        0   \n",
       "3        0        0        0        0        0        0        1        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   1733489  1733490  1733491  1733492  1735120  1735121  1735122  1735123  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        1        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        1        0        0        0        0   \n",
       "\n",
       "   1735124  1735125  1735126  1735127  1735128  1735129  1735130  1735131  \\\n",
       "0        0        0        0        1        0        0        0        0   \n",
       "1        0        0        0        1        0        0        0        0   \n",
       "2        0        0        0        0        1        0        0        0   \n",
       "3        0        0        0        1        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   1735132  1735133  1735134  1736760  1736761  1736762  1736763  1736764  \\\n",
       "0        0        0        0        0        1        0        0        0   \n",
       "1        0        0        0        0        0        1        0        0   \n",
       "2        0        0        0        0        1        0        0        0   \n",
       "3        0        0        0        0        1        0        0        0   \n",
       "4        0        1        0        0        0        0        0        0   \n",
       "\n",
       "   1736765  1736766  1736767  1736768  1738400  1738401  1738402  1738403  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        1        0        0        0        0        0   \n",
       "\n",
       "   1738404  1738405  1738406  1738407  1738408  1740040  1740041  1740042  \\\n",
       "0        0        1        0        0        0        1        0        0   \n",
       "1        1        0        0        0        0        1        0        0   \n",
       "2        0        0        0        0        1        0        0        0   \n",
       "3        0        0        0        0        1        0        0        0   \n",
       "4        0        1        0        0        0        0        0        0   \n",
       "\n",
       "   1740043  1740044  1740045  1740046  1741680  1741681  1741682  1741683  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        1        0        0        1        0   \n",
       "3        1        0        0        0        0        0        1        0   \n",
       "4        0        0        0        1        0        0        0        0   \n",
       "\n",
       "   1741684  1741685  1741686  1741687  1743320  1743321  1743322  1743323  \\\n",
       "0        1        0        0        0        0        0        0        0   \n",
       "1        0        0        1        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        1        0        0        0        0   \n",
       "\n",
       "   1743324  1743325  1743326  1743327  1743328  1743329  1744960  1744961  \\\n",
       "0        0        1        0        0        0        0        0        0   \n",
       "1        0        0        1        0        0        0        0        0   \n",
       "2        0        1        0        0        0        0        0        1   \n",
       "3        0        0        1        0        0        0        0        0   \n",
       "4        0        0        1        0        0        0        0        0   \n",
       "\n",
       "   1744962  1744963  1744964  1744965  1744966  1744967  1744968  1744969  \\\n",
       "0        0        0        0        1        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        1        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   1744970  1744971  1746600  1746601  1746602  1746603  1746604  1746605  \\\n",
       "0        0        0        0        1        0        0        0        0   \n",
       "1        1        0        1        0        0        0        0        0   \n",
       "2        0        0        0        0        1        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        1        0        0        0        0        0        0        0   \n",
       "\n",
       "   1746606  1746607  1746608  1746609  1748240  1748241  1748242  1748243  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        1        0   \n",
       "2        0        0        0        0        0        0        1        0   \n",
       "3        1        0        0        0        0        0        0        0   \n",
       "4        0        1        0        0        0        0        0        0   \n",
       "\n",
       "   1748244  1748245  1748246  1749880  1749881  1749882  1749883  1749884  \\\n",
       "0        0        0        1        0        0        0        0        0   \n",
       "1        0        0        0        0        1        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        1        0        0        0        0        0   \n",
       "4        0        0        1        0        1        0        0        0   \n",
       "\n",
       "   1749885  1749886  1749887  1749888  1749889  1749890  1749891  1751520  \\\n",
       "0        0        1        0        0        0        0        0        1   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        1        0   \n",
       "3        0        0        0        0        0        1        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   1751521  1751522  1751523  1751524  1751525  1751526  1751527  1751528  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        1        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        1   \n",
       "3        0        0        0        0        0        0        0        1   \n",
       "4        0        0        0        0        0        0        1        0   \n",
       "\n",
       "   1753160  1753161  1753162  1753163  1753164  1753165  1754800  1754801  \\\n",
       "0        0        0        0        0        0        1        0        0   \n",
       "1        0        0        1        0        0        0        0        0   \n",
       "2        0        1        0        0        0        0        1        0   \n",
       "3        0        1        0        0        0        0        0        0   \n",
       "4        0        0        1        0        0        0        0        0   \n",
       "\n",
       "   1754802  1754803  1754804  1754805  1754806  1754807  1754808  1754809  \\\n",
       "0        0        0        0        0        0        1        0        0   \n",
       "1        0        0        0        0        0        1        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        1        0        0   \n",
       "4        0        0        0        0        1        0        0        0   \n",
       "\n",
       "   1756440  1756441  1756442  1756443  1756444  1756445  1758080  1758081  \\\n",
       "0        0        0        0        0        1        0        0        0   \n",
       "1        0        0        0        0        1        0        0        0   \n",
       "2        0        0        0        1        0        0        0        0   \n",
       "3        0        0        0        0        1        0        0        0   \n",
       "4        0        0        0        0        1        0        0        0   \n",
       "\n",
       "   1758082  1758083  1758084  1759720  1759721  1759722  1759723  1759724  \\\n",
       "0        0        1        0        0        0        0        0        0   \n",
       "1        0        1        0        0        0        0        1        0   \n",
       "2        0        1        0        0        0        1        0        0   \n",
       "3        0        0        1        0        0        0        0        0   \n",
       "4        0        0        1        0        0        0        0        0   \n",
       "\n",
       "   1759725  1759726  1759727  1759728  1761360  1761361  1761362  1761363  \\\n",
       "0        0        0        1        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        1        0        0        0        0        0   \n",
       "4        0        0        0        1        0        0        0        0   \n",
       "\n",
       "   1761364  1761365  1761366  1761367  1761368  1761369  1761370  1761371  \\\n",
       "0        0        1        0        0        0        0        0        0   \n",
       "1        0        0        1        0        0        0        0        0   \n",
       "2        0        0        0        1        0        0        0        0   \n",
       "3        0        0        0        1        0        0        0        0   \n",
       "4        0        0        1        0        0        0        0        0   \n",
       "\n",
       "   1761372  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 13006 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop zero-features\n",
    "df2 = pd.DataFrame(train_matrix)\n",
    "droplist2 = []\n",
    "for k in df2.columns:\n",
    "    if not df2[k].any():\n",
    "        droplist2.append(k)\n",
    "print(len(droplist2))\n",
    "df2.drop(droplist2,axis=1, inplace=True).add_suffix('_lgb')\n",
    "\n",
    "#  存储lgb-onehot\n",
    "pd.concat([df,df2],axis=1).to_pickle('./data/filter_feas_df32n_old_lgb_oh.pkl')\n",
    "df2.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1efafc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd6ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59173cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd8ce7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d0e987e",
   "metadata": {},
   "source": [
    "### 训练集异常检测编码\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15477c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models import iforest\n",
    "\n",
    "\n",
    "it = iforest.IForest()\n",
    "\n",
    "it.fit(train_x)\n",
    "ift = it.predict_proba(df[final_feas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b10d9d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>report_timestamp</th>\n",
       "      <th>BureauScore</th>\n",
       "      <th>BureauScoreConfidLevel</th>\n",
       "      <th>MissingRate</th>\n",
       "      <th>Current_Enquiry_Reason</th>\n",
       "      <th>Current_Gender_Code</th>\n",
       "      <th>First_Name1</th>\n",
       "      <th>Len_Name</th>\n",
       "      <th>Tel_nuniq</th>\n",
       "      <th>Email_nuniq</th>\n",
       "      <th>IncomeTaxPAN_5</th>\n",
       "      <th>Len_of_addrs</th>\n",
       "      <th>City_nuniq</th>\n",
       "      <th>PinCode3</th>\n",
       "      <th>Current_State</th>\n",
       "      <th>Current_City</th>\n",
       "      <th>CreditAccountActive</th>\n",
       "      <th>CreditAccountTotal</th>\n",
       "      <th>CreditAccountActivePor</th>\n",
       "      <th>Outstanding_Balance_Secured</th>\n",
       "      <th>Outstanding_Balance_UnSecured_Percentage</th>\n",
       "      <th>Outstanding_Balance_All</th>\n",
       "      <th>Outstanding_Balance_Secured_Percentage</th>\n",
       "      <th>Outstanding_Balance_UnSecured</th>\n",
       "      <th>Diff_dateBirth</th>\n",
       "      <th>State_nuniq</th>\n",
       "      <th>Birth_nuniq</th>\n",
       "      <th>TotalCAPSLast90Days</th>\n",
       "      <th>TotalCAPSLast7Days</th>\n",
       "      <th>TotalCAPSLast30Days</th>\n",
       "      <th>TotalCAPSLast180Days</th>\n",
       "      <th>CAPSLast30Days</th>\n",
       "      <th>CAPSLast7Days</th>\n",
       "      <th>CAPSLast180Days</th>\n",
       "      <th>NonCreditCAPSLast180Days</th>\n",
       "      <th>Pin_nuniq</th>\n",
       "      <th>Pan_nuniq</th>\n",
       "      <th>Ident_nuniq</th>\n",
       "      <th>Name_nuniq2</th>\n",
       "      <th>Tel_nuniq2</th>\n",
       "      <th>Email_nuniq2</th>\n",
       "      <th>Pan_nuniq2</th>\n",
       "      <th>Account_nuniq2</th>\n",
       "      <th>Ident_nuniq2</th>\n",
       "      <th>Gender_nuniq</th>\n",
       "      <th>Amount_Past_Due35_sum_30</th>\n",
       "      <th>Amount_Past_Due35_min_30</th>\n",
       "      <th>Amount_Past_Due35_sum_90</th>\n",
       "      <th>Amount_Past_Due35_mean_90</th>\n",
       "      <th>Amount_Past_Due35_max_90</th>\n",
       "      <th>Amount_Past_Due35_min_90</th>\n",
       "      <th>Amount_Past_Due35_std_90</th>\n",
       "      <th>Amount_Past_Due35_sum_360</th>\n",
       "      <th>Amount_Past_Due35_mean_360</th>\n",
       "      <th>Amount_Past_Due35_max_360</th>\n",
       "      <th>Amount_Past_Due35_std_360</th>\n",
       "      <th>Amount_Past_Due35_sum_9999</th>\n",
       "      <th>Amount_Past_Due35_max_9999</th>\n",
       "      <th>Amount_Past_Due35_min_9999</th>\n",
       "      <th>Amount_Past_Due35_std_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_30</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_min_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_90</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_360</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_sum_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_mean_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_max_9999</th>\n",
       "      <th>Highest_Credit_or_Original_Loan_Amount58_std_9999</th>\n",
       "      <th>Terms_Duration34_sum_30</th>\n",
       "      <th>Terms_Duration34_std_30</th>\n",
       "      <th>Terms_Duration34_sum_90</th>\n",
       "      <th>Terms_Duration34_std_90</th>\n",
       "      <th>Terms_Duration34_mean_360</th>\n",
       "      <th>Terms_Duration34_max_360</th>\n",
       "      <th>Terms_Duration34_min_360</th>\n",
       "      <th>Terms_Duration34_std_360</th>\n",
       "      <th>Terms_Duration34_sum_9999</th>\n",
       "      <th>Terms_Duration34_mean_9999</th>\n",
       "      <th>Terms_Duration34_max_9999</th>\n",
       "      <th>Terms_Duration34_min_9999</th>\n",
       "      <th>Terms_Duration34_std_9999</th>\n",
       "      <th>Payment_Rating34_sum_90</th>\n",
       "      <th>Payment_Rating34_mean_90</th>\n",
       "      <th>Payment_Rating34_max_90</th>\n",
       "      <th>Payment_Rating34_min_90</th>\n",
       "      <th>Payment_Rating34_std_90</th>\n",
       "      <th>Payment_Rating34_sum_360</th>\n",
       "      <th>Payment_Rating34_mean_360</th>\n",
       "      <th>Payment_Rating34_max_360</th>\n",
       "      <th>Payment_Rating34_min_360</th>\n",
       "      <th>Payment_Rating34_std_360</th>\n",
       "      <th>Payment_Rating34_sum_9999</th>\n",
       "      <th>Payment_Rating34_mean_9999</th>\n",
       "      <th>Payment_Rating34_max_9999</th>\n",
       "      <th>Payment_Rating34_min_9999</th>\n",
       "      <th>Payment_Rating34_std_9999</th>\n",
       "      <th>Current_Balance35_mean_30</th>\n",
       "      <th>Current_Balance35_min_30</th>\n",
       "      <th>Current_Balance35_std_30</th>\n",
       "      <th>Current_Balance35_sum_90</th>\n",
       "      <th>Current_Balance35_mean_90</th>\n",
       "      <th>Current_Balance35_max_90</th>\n",
       "      <th>Current_Balance35_std_90</th>\n",
       "      <th>Current_Balance35_sum_360</th>\n",
       "      <th>Current_Balance35_max_360</th>\n",
       "      <th>Current_Balance35_std_360</th>\n",
       "      <th>Current_Balance35_max_9999</th>\n",
       "      <th>Current_Balance35_std_9999</th>\n",
       "      <th>Settlement_Amount37_max_360</th>\n",
       "      <th>Settlement_Amount37_min_360</th>\n",
       "      <th>Settlement_Amount37_std_360</th>\n",
       "      <th>Settlement_Amount37_sum_9999</th>\n",
       "      <th>Settlement_Amount37_mean_9999</th>\n",
       "      <th>Settlement_Amount37_max_9999</th>\n",
       "      <th>Settlement_Amount37_min_9999</th>\n",
       "      <th>Settlement_Amount37_std_9999</th>\n",
       "      <th>Value_of_Collateral39_std_90</th>\n",
       "      <th>Value_of_Collateral39_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_360</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_360</th>\n",
       "      <th>Written_Off_Amt_Total41_min_360</th>\n",
       "      <th>Written_Off_Amt_Total41_std_360</th>\n",
       "      <th>Written_Off_Amt_Total41_sum_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_mean_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_max_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_min_9999</th>\n",
       "      <th>Written_Off_Amt_Total41_std_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_sum_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_mean_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_std_360</th>\n",
       "      <th>Written_Off_Amt_Principal45_max_9999</th>\n",
       "      <th>Written_Off_Amt_Principal45_min_9999</th>\n",
       "      <th>Rate_of_Interest36_sum_30</th>\n",
       "      <th>Rate_of_Interest36_std_30</th>\n",
       "      <th>Rate_of_Interest36_sum_90</th>\n",
       "      <th>Rate_of_Interest36_mean_90</th>\n",
       "      <th>Rate_of_Interest36_max_90</th>\n",
       "      <th>Rate_of_Interest36_std_90</th>\n",
       "      <th>Rate_of_Interest36_sum_360</th>\n",
       "      <th>Rate_of_Interest36_mean_360</th>\n",
       "      <th>Rate_of_Interest36_max_360</th>\n",
       "      <th>Rate_of_Interest36_min_360</th>\n",
       "      <th>Rate_of_Interest36_std_360</th>\n",
       "      <th>Rate_of_Interest36_sum_9999</th>\n",
       "      <th>Rate_of_Interest36_mean_9999</th>\n",
       "      <th>Rate_of_Interest36_max_9999</th>\n",
       "      <th>Rate_of_Interest36_min_9999</th>\n",
       "      <th>Rate_of_Interest36_std_9999</th>\n",
       "      <th>Repayment_Tenure36_std_30</th>\n",
       "      <th>Repayment_Tenure36_mean_90</th>\n",
       "      <th>Repayment_Tenure36_max_90</th>\n",
       "      <th>Repayment_Tenure36_min_90</th>\n",
       "      <th>Repayment_Tenure36_std_90</th>\n",
       "      <th>Repayment_Tenure36_sum_360</th>\n",
       "      <th>Repayment_Tenure36_mean_360</th>\n",
       "      <th>Repayment_Tenure36_min_360</th>\n",
       "      <th>Repayment_Tenure36_std_360</th>\n",
       "      <th>Repayment_Tenure36_mean_9999</th>\n",
       "      <th>Repayment_Tenure36_min_9999</th>\n",
       "      <th>Repayment_Tenure36_std_9999</th>\n",
       "      <th>Income26_count_360</th>\n",
       "      <th>Income26_std_360</th>\n",
       "      <th>Open_Date29_max_30</th>\n",
       "      <th>Open_Date29_min_30</th>\n",
       "      <th>Open_Date29_mean_30</th>\n",
       "      <th>Open_Date29_nuniq_30</th>\n",
       "      <th>Open_Date29_maxcount_30</th>\n",
       "      <th>Open_Date29_max_90</th>\n",
       "      <th>Open_Date29_mean_90</th>\n",
       "      <th>Open_Date29_mode_90</th>\n",
       "      <th>Open_Date29_nuniq_90</th>\n",
       "      <th>Open_Date29_maxcount_90</th>\n",
       "      <th>Open_Date29_max_360</th>\n",
       "      <th>Open_Date29_mean_360</th>\n",
       "      <th>Open_Date29_mode_360</th>\n",
       "      <th>Open_Date29_nuniq_360</th>\n",
       "      <th>Open_Date29_maxcount_360</th>\n",
       "      <th>Open_Date29_max_9999</th>\n",
       "      <th>Open_Date29_mean_9999</th>\n",
       "      <th>Open_Date29_mode_9999</th>\n",
       "      <th>Open_Date29_maxcount_9999</th>\n",
       "      <th>Portfolio_Type34_mode_30</th>\n",
       "      <th>Portfolio_Type34_nuniq_30</th>\n",
       "      <th>Portfolio_Type34_nuniq_90</th>\n",
       "      <th>Portfolio_Type34_mode_360</th>\n",
       "      <th>Portfolio_Type34_nuniq_360</th>\n",
       "      <th>Portfolio_Type34_mode_9999</th>\n",
       "      <th>Portfolio_Type34_nuniq_9999</th>\n",
       "      <th>Account_Type32_nuniq_30</th>\n",
       "      <th>Account_Type32_mode_90</th>\n",
       "      <th>Account_Type32_nuniq_90</th>\n",
       "      <th>Account_Type32_mode_360</th>\n",
       "      <th>Account_Type32_nuniq_360</th>\n",
       "      <th>Account_Type32_mode_9999</th>\n",
       "      <th>Account_Type32_nuniq_9999</th>\n",
       "      <th>Occupation_Code35_nuniq_30</th>\n",
       "      <th>Occupation_Code35_nuniq_90</th>\n",
       "      <th>Occupation_Code35_nuniq_360</th>\n",
       "      <th>Occupation_Code35_nuniq_9999</th>\n",
       "      <th>CurrencyCode32_mode_360</th>\n",
       "      <th>CurrencyCode32_mode_9999</th>\n",
       "      <th>AccountHoldertypeCode41_mode_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_90</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_360</th>\n",
       "      <th>AccountHoldertypeCode41_mode_9999</th>\n",
       "      <th>AccountHoldertypeCode41_nuniq_9999</th>\n",
       "      <th>Payment_History_Profile43_mode_30</th>\n",
       "      <th>Payment_History_Profile43_mode_90</th>\n",
       "      <th>Payment_History_Profile43_nuniq_90</th>\n",
       "      <th>Payment_History_Profile43_mode_360</th>\n",
       "      <th>Payment_History_Profile43_nuniq_360</th>\n",
       "      <th>Payment_History_Profile43_mode_9999</th>\n",
       "      <th>Payment_History_Profile43_nuniq_9999</th>\n",
       "      <th>Date_Closed31_nuniq_30</th>\n",
       "      <th>Date_Closed31_maxcount_30</th>\n",
       "      <th>Date_Closed31_max_90</th>\n",
       "      <th>Date_Closed31_min_90</th>\n",
       "      <th>Date_Closed31_mean_90</th>\n",
       "      <th>Date_Closed31_mode_90</th>\n",
       "      <th>Date_Closed31_nuniq_90</th>\n",
       "      <th>Date_Closed31_maxcount_90</th>\n",
       "      <th>Date_Closed31_min_360</th>\n",
       "      <th>Date_Closed31_mode_360</th>\n",
       "      <th>Date_Closed31_nuniq_360</th>\n",
       "      <th>Date_Closed31_maxcount_360</th>\n",
       "      <th>Date_Closed31_max_9999</th>\n",
       "      <th>Date_Closed31_min_9999</th>\n",
       "      <th>Date_Closed31_mean_9999</th>\n",
       "      <th>Date_Closed31_mode_9999</th>\n",
       "      <th>Date_Closed31_nuniq_9999</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_30</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_30</th>\n",
       "      <th>Date_of_Last_Payment40_min_90</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_90</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_90</th>\n",
       "      <th>Date_of_Last_Payment40_max_360</th>\n",
       "      <th>Date_of_Last_Payment40_min_360</th>\n",
       "      <th>Date_of_Last_Payment40_mean_360</th>\n",
       "      <th>Date_of_Last_Payment40_mode_360</th>\n",
       "      <th>Date_of_Last_Payment40_nuniq_360</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_360</th>\n",
       "      <th>Date_of_Last_Payment40_max_9999</th>\n",
       "      <th>Date_of_Last_Payment40_min_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mean_9999</th>\n",
       "      <th>Date_of_Last_Payment40_mode_9999</th>\n",
       "      <th>Date_of_Last_Payment40_maxcount_9999</th>\n",
       "      <th>Date_Reported33_nuniq_30</th>\n",
       "      <th>Date_Reported33_max_90</th>\n",
       "      <th>Date_Reported33_mean_90</th>\n",
       "      <th>Date_Reported33_mode_90</th>\n",
       "      <th>Date_Reported33_nuniq_90</th>\n",
       "      <th>Date_Reported33_maxcount_90</th>\n",
       "      <th>Date_Reported33_max_360</th>\n",
       "      <th>Date_Reported33_mean_360</th>\n",
       "      <th>Date_Reported33_mode_360</th>\n",
       "      <th>Date_Reported33_nuniq_360</th>\n",
       "      <th>Date_Reported33_maxcount_360</th>\n",
       "      <th>Date_Reported33_max_9999</th>\n",
       "      <th>Date_Reported33_mean_9999</th>\n",
       "      <th>Date_Reported33_mode_9999</th>\n",
       "      <th>Date_Reported33_nuniq_9999</th>\n",
       "      <th>Date_Reported33_maxcount_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_30</th>\n",
       "      <th>DateOfAddition34_max_90</th>\n",
       "      <th>DateOfAddition34_mean_90</th>\n",
       "      <th>DateOfAddition34_mode_90</th>\n",
       "      <th>DateOfAddition34_nuniq_90</th>\n",
       "      <th>DateOfAddition34_maxcount_90</th>\n",
       "      <th>DateOfAddition34_max_360</th>\n",
       "      <th>DateOfAddition34_mean_360</th>\n",
       "      <th>DateOfAddition34_mode_360</th>\n",
       "      <th>DateOfAddition34_nuniq_360</th>\n",
       "      <th>DateOfAddition34_maxcount_360</th>\n",
       "      <th>DateOfAddition34_max_9999</th>\n",
       "      <th>DateOfAddition34_mean_9999</th>\n",
       "      <th>DateOfAddition34_mode_9999</th>\n",
       "      <th>DateOfAddition34_nuniq_9999</th>\n",
       "      <th>DateOfAddition34_maxcount_9999</th>\n",
       "      <th>Account_Status34_mode_30</th>\n",
       "      <th>Account_Status34_nuniq_30</th>\n",
       "      <th>Account_Status34_mode_90</th>\n",
       "      <th>Account_Status34_nuniq_90</th>\n",
       "      <th>Account_Status34_mode_360</th>\n",
       "      <th>Account_Status34_nuniq_360</th>\n",
       "      <th>Account_Status34_mode_9999</th>\n",
       "      <th>Account_Status34_nuniq_9999</th>\n",
       "      <th>Month50_sum_30</th>\n",
       "      <th>Month50_max_30</th>\n",
       "      <th>Month50_std_30</th>\n",
       "      <th>Month50_sum_90</th>\n",
       "      <th>Month50_mean_90</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_1036_sms</th>\n",
       "      <th>feature_1037_sms</th>\n",
       "      <th>feature_1038_sms</th>\n",
       "      <th>feature_1039_sms</th>\n",
       "      <th>feature_1040_sms</th>\n",
       "      <th>feature_1041_sms</th>\n",
       "      <th>feature_1042_sms</th>\n",
       "      <th>feature_1043_sms</th>\n",
       "      <th>feature_1044_sms</th>\n",
       "      <th>feature_1045_sms</th>\n",
       "      <th>feature_1046_sms</th>\n",
       "      <th>feature_1047_sms</th>\n",
       "      <th>feature_1048_sms</th>\n",
       "      <th>feature_1049_sms</th>\n",
       "      <th>feature_1050_sms</th>\n",
       "      <th>feature_1051_sms</th>\n",
       "      <th>feature_1052_sms</th>\n",
       "      <th>feature_1053_sms</th>\n",
       "      <th>feature_1054_sms</th>\n",
       "      <th>feature_1055_sms</th>\n",
       "      <th>feature_1056_sms</th>\n",
       "      <th>feature_1057_sms</th>\n",
       "      <th>feature_1058_sms</th>\n",
       "      <th>feature_1059_sms</th>\n",
       "      <th>feature_1060_sms</th>\n",
       "      <th>feature_1061_sms</th>\n",
       "      <th>feature_1062_sms</th>\n",
       "      <th>feature_1063_sms</th>\n",
       "      <th>feature_1064_sms</th>\n",
       "      <th>feature_1065_sms</th>\n",
       "      <th>feature_1066_sms</th>\n",
       "      <th>feature_1067_sms</th>\n",
       "      <th>feature_1068_sms</th>\n",
       "      <th>feature_1069_sms</th>\n",
       "      <th>feature_1070_sms</th>\n",
       "      <th>feature_1071_sms</th>\n",
       "      <th>feature_1072_sms</th>\n",
       "      <th>feature_1073_sms</th>\n",
       "      <th>feature_1074_sms</th>\n",
       "      <th>feature_1075_sms</th>\n",
       "      <th>feature_1076_sms</th>\n",
       "      <th>feature_1077_sms</th>\n",
       "      <th>feature_1078_sms</th>\n",
       "      <th>feature_1079_sms</th>\n",
       "      <th>feature_1080_sms</th>\n",
       "      <th>feature_1081_sms</th>\n",
       "      <th>feature_1082_sms</th>\n",
       "      <th>feature_1083_sms</th>\n",
       "      <th>feature_1084_sms</th>\n",
       "      <th>feature_1085_sms</th>\n",
       "      <th>feature_1086_sms</th>\n",
       "      <th>feature_1087_sms</th>\n",
       "      <th>feature_1088_sms</th>\n",
       "      <th>feature_1089_sms</th>\n",
       "      <th>feature_1090_sms</th>\n",
       "      <th>feature_1091_sms</th>\n",
       "      <th>feature_1092_sms</th>\n",
       "      <th>feature_1093_sms</th>\n",
       "      <th>feature_1094_sms</th>\n",
       "      <th>feature_1095_sms</th>\n",
       "      <th>feature_1096_sms</th>\n",
       "      <th>feature_1097_sms</th>\n",
       "      <th>feature_1098_sms</th>\n",
       "      <th>feature_1099_sms</th>\n",
       "      <th>feature_1100_sms</th>\n",
       "      <th>feature_1101_sms</th>\n",
       "      <th>feature_1102_sms</th>\n",
       "      <th>feature_1103_sms</th>\n",
       "      <th>feature_1104_sms</th>\n",
       "      <th>feature_1105_sms</th>\n",
       "      <th>feature_1106_sms</th>\n",
       "      <th>feature_1107_sms</th>\n",
       "      <th>feature_1108_sms</th>\n",
       "      <th>feature_1109_sms</th>\n",
       "      <th>feature_1110_sms</th>\n",
       "      <th>feature_1111_sms</th>\n",
       "      <th>feature_1112_sms</th>\n",
       "      <th>feature_1113_sms</th>\n",
       "      <th>feature_1114_sms</th>\n",
       "      <th>feature_1115_sms</th>\n",
       "      <th>feature_1116_sms</th>\n",
       "      <th>feature_1117_sms</th>\n",
       "      <th>feature_1118_sms</th>\n",
       "      <th>feature_1119_sms</th>\n",
       "      <th>feature_1120_sms</th>\n",
       "      <th>feature_1121_sms</th>\n",
       "      <th>feature_1122_sms</th>\n",
       "      <th>feature_1123_sms</th>\n",
       "      <th>feature_1124_sms</th>\n",
       "      <th>feature_1125_sms</th>\n",
       "      <th>feature_1126_sms</th>\n",
       "      <th>feature_1127_sms</th>\n",
       "      <th>feature_1128_sms</th>\n",
       "      <th>feature_1129_sms</th>\n",
       "      <th>feature_1130_sms</th>\n",
       "      <th>feature_1131_sms</th>\n",
       "      <th>feature_1132_sms</th>\n",
       "      <th>feature_1133_sms</th>\n",
       "      <th>feature_1134_sms</th>\n",
       "      <th>feature_1135_sms</th>\n",
       "      <th>feature_1136_sms</th>\n",
       "      <th>feature_1137_sms</th>\n",
       "      <th>feature_1138_sms</th>\n",
       "      <th>feature_1139_sms</th>\n",
       "      <th>feature_1140_sms</th>\n",
       "      <th>feature_1141_sms</th>\n",
       "      <th>feature_1142_sms</th>\n",
       "      <th>feature_1143_sms</th>\n",
       "      <th>feature_1144_sms</th>\n",
       "      <th>feature_1145_sms</th>\n",
       "      <th>feature_1146_sms</th>\n",
       "      <th>feature_1147_sms</th>\n",
       "      <th>feature_1148_sms</th>\n",
       "      <th>feature_1149_sms</th>\n",
       "      <th>feature_1150_sms</th>\n",
       "      <th>feature_1151_sms</th>\n",
       "      <th>feature_1152_sms</th>\n",
       "      <th>feature_1153_sms</th>\n",
       "      <th>feature_1154_sms</th>\n",
       "      <th>feature_1155_sms</th>\n",
       "      <th>feature_1156_sms</th>\n",
       "      <th>feature_1157_sms</th>\n",
       "      <th>feature_1158_sms</th>\n",
       "      <th>feature_1159_sms</th>\n",
       "      <th>feature_1160_sms</th>\n",
       "      <th>feature_1161_sms</th>\n",
       "      <th>feature_1162_sms</th>\n",
       "      <th>feature_1163_sms</th>\n",
       "      <th>feature_1164_sms</th>\n",
       "      <th>feature_1165_sms</th>\n",
       "      <th>feature_1166_sms</th>\n",
       "      <th>feature_1167_sms</th>\n",
       "      <th>feature_1168_sms</th>\n",
       "      <th>feature_1169_sms</th>\n",
       "      <th>feature_1170_sms</th>\n",
       "      <th>feature_1171_sms</th>\n",
       "      <th>feature_1172_sms</th>\n",
       "      <th>feature_1173_sms</th>\n",
       "      <th>feature_1174_sms</th>\n",
       "      <th>feature_1175_sms</th>\n",
       "      <th>feature_1176_sms</th>\n",
       "      <th>feature_1177_sms</th>\n",
       "      <th>feature_1178_sms</th>\n",
       "      <th>feature_1179_sms</th>\n",
       "      <th>feature_1180_sms</th>\n",
       "      <th>feature_1181_sms</th>\n",
       "      <th>feature_1182_sms</th>\n",
       "      <th>feature_1183_sms</th>\n",
       "      <th>feature_1184_sms</th>\n",
       "      <th>feature_1185_sms</th>\n",
       "      <th>feature_1186_sms</th>\n",
       "      <th>feature_1187_sms</th>\n",
       "      <th>feature_1188_sms</th>\n",
       "      <th>feature_1189_sms</th>\n",
       "      <th>feature_1190_sms</th>\n",
       "      <th>feature_1191_sms</th>\n",
       "      <th>feature_1192_sms</th>\n",
       "      <th>feature_1193_sms</th>\n",
       "      <th>feature_1194_sms</th>\n",
       "      <th>feature_1195_sms</th>\n",
       "      <th>feature_1196_sms</th>\n",
       "      <th>feature_1197_sms</th>\n",
       "      <th>feature_1198_sms</th>\n",
       "      <th>feature_1199_sms</th>\n",
       "      <th>feature_1200_sms</th>\n",
       "      <th>feature_1201_sms</th>\n",
       "      <th>feature_1202_sms</th>\n",
       "      <th>feature_1203_sms</th>\n",
       "      <th>feature_1204_sms</th>\n",
       "      <th>feature_1205_sms</th>\n",
       "      <th>feature_1206_sms</th>\n",
       "      <th>feature_1207_sms</th>\n",
       "      <th>feature_1208_sms</th>\n",
       "      <th>feature_1209_sms</th>\n",
       "      <th>feature_1210_sms</th>\n",
       "      <th>feature_1211_sms</th>\n",
       "      <th>feature_1212_sms</th>\n",
       "      <th>feature_1213_sms</th>\n",
       "      <th>feature_1214_sms</th>\n",
       "      <th>feature_1215_sms</th>\n",
       "      <th>feature_1216_sms</th>\n",
       "      <th>feature_1217_sms</th>\n",
       "      <th>feature_1218_sms</th>\n",
       "      <th>feature_1219_sms</th>\n",
       "      <th>feature_1220_sms</th>\n",
       "      <th>feature_1221_sms</th>\n",
       "      <th>feature_1222_sms</th>\n",
       "      <th>feature_1223_sms</th>\n",
       "      <th>feature_1224_sms</th>\n",
       "      <th>feature_1225_sms</th>\n",
       "      <th>feature_1226_sms</th>\n",
       "      <th>feature_1227_sms</th>\n",
       "      <th>feature_1228_sms</th>\n",
       "      <th>feature_1229_sms</th>\n",
       "      <th>feature_1230_sms</th>\n",
       "      <th>feature_1231_sms</th>\n",
       "      <th>feature_1232_sms</th>\n",
       "      <th>feature_1233_sms</th>\n",
       "      <th>feature_1234_sms</th>\n",
       "      <th>feature_1235_sms</th>\n",
       "      <th>feature_1236_sms</th>\n",
       "      <th>feature_1237_sms</th>\n",
       "      <th>feature_1238_sms</th>\n",
       "      <th>feature_1239_sms</th>\n",
       "      <th>feature_1240_sms</th>\n",
       "      <th>feature_1241_sms</th>\n",
       "      <th>feature_1242_sms</th>\n",
       "      <th>feature_1243_sms</th>\n",
       "      <th>feature_1244_sms</th>\n",
       "      <th>feature_1245_sms</th>\n",
       "      <th>feature_1246_sms</th>\n",
       "      <th>feature_1247_sms</th>\n",
       "      <th>feature_1248_sms</th>\n",
       "      <th>feature_1249_sms</th>\n",
       "      <th>feature_1250_sms</th>\n",
       "      <th>feature_1251_sms</th>\n",
       "      <th>feature_1252_sms</th>\n",
       "      <th>feature_1253_sms</th>\n",
       "      <th>feature_1254_sms</th>\n",
       "      <th>feature_1255_sms</th>\n",
       "      <th>feature_1256_sms</th>\n",
       "      <th>feature_1257_sms</th>\n",
       "      <th>feature_1258_sms</th>\n",
       "      <th>feature_1259_sms</th>\n",
       "      <th>feature_1260_sms</th>\n",
       "      <th>feature_1261_sms</th>\n",
       "      <th>feature_1262_sms</th>\n",
       "      <th>feature_1263_sms</th>\n",
       "      <th>feature_1264_sms</th>\n",
       "      <th>feature_1265_sms</th>\n",
       "      <th>feature_1266_sms</th>\n",
       "      <th>feature_1267_sms</th>\n",
       "      <th>feature_1268_sms</th>\n",
       "      <th>feature_1269_sms</th>\n",
       "      <th>feature_1270_sms</th>\n",
       "      <th>feature_1271_sms</th>\n",
       "      <th>feature_1272_sms</th>\n",
       "      <th>feature_1273_sms</th>\n",
       "      <th>feature_1274_sms</th>\n",
       "      <th>feature_1275_sms</th>\n",
       "      <th>feature_1276_sms</th>\n",
       "      <th>feature_1277_sms</th>\n",
       "      <th>feature_1278_sms</th>\n",
       "      <th>feature_1279_sms</th>\n",
       "      <th>feature_1280_sms</th>\n",
       "      <th>feature_1281_sms</th>\n",
       "      <th>feature_1282_sms</th>\n",
       "      <th>feature_1283_sms</th>\n",
       "      <th>feature_1284_sms</th>\n",
       "      <th>feature_1285_sms</th>\n",
       "      <th>feature_1286_sms</th>\n",
       "      <th>feature_1287_sms</th>\n",
       "      <th>feature_1288_sms</th>\n",
       "      <th>feature_1289_sms</th>\n",
       "      <th>feature_1290_sms</th>\n",
       "      <th>feature_1291_sms</th>\n",
       "      <th>feature_1292_sms</th>\n",
       "      <th>feature_1293_sms</th>\n",
       "      <th>feature_1294_sms</th>\n",
       "      <th>feature_1295_sms</th>\n",
       "      <th>feature_1296_sms</th>\n",
       "      <th>feature_1297_sms</th>\n",
       "      <th>feature_1298_sms</th>\n",
       "      <th>feature_1299_sms</th>\n",
       "      <th>feature_1300_sms</th>\n",
       "      <th>feature_1301_sms</th>\n",
       "      <th>feature_1302_sms</th>\n",
       "      <th>feature_1303_sms</th>\n",
       "      <th>feature_1304_sms</th>\n",
       "      <th>feature_1305_sms</th>\n",
       "      <th>feature_1306_sms</th>\n",
       "      <th>feature_1307_sms</th>\n",
       "      <th>feature_1308_sms</th>\n",
       "      <th>feature_1309_sms</th>\n",
       "      <th>feature_1310_sms</th>\n",
       "      <th>feature_1311_sms</th>\n",
       "      <th>feature_1312_sms</th>\n",
       "      <th>feature_1313_sms</th>\n",
       "      <th>feature_1314_sms</th>\n",
       "      <th>feature_1315_sms</th>\n",
       "      <th>feature_1316_sms</th>\n",
       "      <th>feature_1317_sms</th>\n",
       "      <th>feature_1318_sms</th>\n",
       "      <th>feature_1319_sms</th>\n",
       "      <th>feature_1320_sms</th>\n",
       "      <th>feature_1321_sms</th>\n",
       "      <th>feature_1322_sms</th>\n",
       "      <th>feature_1323_sms</th>\n",
       "      <th>feature_1324_sms</th>\n",
       "      <th>feature_1325_sms</th>\n",
       "      <th>feature_1326_sms</th>\n",
       "      <th>feature_1327_sms</th>\n",
       "      <th>feature_1328_sms</th>\n",
       "      <th>feature_1329_sms</th>\n",
       "      <th>feature_1330_sms</th>\n",
       "      <th>order_id</th>\n",
       "      <th>pan</th>\n",
       "      <th>label</th>\n",
       "      <th>label_pred</th>\n",
       "      <th>ift_socre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BPZPK3933F</td>\n",
       "      <td>20220210120018</td>\n",
       "      <td>558.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325254</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>11.329890</td>\n",
       "      <td>11.994503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>4.285245</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>0.636335</td>\n",
       "      <td>5064366</td>\n",
       "      <td>2</td>\n",
       "      <td>5181373</td>\n",
       "      <td>98</td>\n",
       "      <td>117007</td>\n",
       "      <td>13092</td>\n",
       "      <td>51.949051</td>\n",
       "      <td>22.489255</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13.246938</td>\n",
       "      <td>66.934066</td>\n",
       "      <td>5.498875</td>\n",
       "      <td>146</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>44.956044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6920.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>6920.0</td>\n",
       "      <td>2996.447897</td>\n",
       "      <td>3937140.0</td>\n",
       "      <td>2057589.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>547470.733164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114378.0</td>\n",
       "      <td>75400.0</td>\n",
       "      <td>28277.352966</td>\n",
       "      <td>6254569.0</td>\n",
       "      <td>284298.590909</td>\n",
       "      <td>1890000.0</td>\n",
       "      <td>509837.280159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.109609</td>\n",
       "      <td>501.0</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.033943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.227273</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.294892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97130.0</td>\n",
       "      <td>75400.0</td>\n",
       "      <td>30111.798663</td>\n",
       "      <td>2057589.0</td>\n",
       "      <td>539918.618880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19637.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.930</td>\n",
       "      <td>18.1860</td>\n",
       "      <td>47.880</td>\n",
       "      <td>7.55</td>\n",
       "      <td>15.316455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.769696</td>\n",
       "      <td>22.772727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.589290</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>113.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2884.0</td>\n",
       "      <td>1061.772727</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1742.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>720.625000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1742.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>401.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>33.25</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>140.25</td>\n",
       "      <td>163.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2478.0</td>\n",
       "      <td>974.136364</td>\n",
       "      <td>163.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>13</td>\n",
       "      <td>71</td>\n",
       "      <td>46</td>\n",
       "      <td>34</td>\n",
       "      <td>737</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>209</td>\n",
       "      <td>15</td>\n",
       "      <td>101</td>\n",
       "      <td>61</td>\n",
       "      <td>48</td>\n",
       "      <td>1876</td>\n",
       "      <td>51</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>445</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>541</td>\n",
       "      <td>30</td>\n",
       "      <td>322</td>\n",
       "      <td>154</td>\n",
       "      <td>113</td>\n",
       "      <td>3000</td>\n",
       "      <td>86</td>\n",
       "      <td>143</td>\n",
       "      <td>25</td>\n",
       "      <td>681</td>\n",
       "      <td>10</td>\n",
       "      <td>58</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>870</td>\n",
       "      <td>38</td>\n",
       "      <td>527</td>\n",
       "      <td>212</td>\n",
       "      <td>162</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>0.037333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>0.258929</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.098214</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>30.142857</td>\n",
       "      <td>30.142857</td>\n",
       "      <td>0.070333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>9.428571</td>\n",
       "      <td>0.312796</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.047393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>0.284360</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>0.113744</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>34.428571</td>\n",
       "      <td>34.428571</td>\n",
       "      <td>0.160667</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>0.035270</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>9.071429</td>\n",
       "      <td>0.263485</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>0.039419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>0.035270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.785714</td>\n",
       "      <td>0.284232</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>0.143154</td>\n",
       "      <td>3.214286</td>\n",
       "      <td>0.093361</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>0.068465</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.036190</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>6.523810</td>\n",
       "      <td>0.260952</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.036190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.238095</td>\n",
       "      <td>0.049524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>0.291429</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.024762</td>\n",
       "      <td>3.380952</td>\n",
       "      <td>0.135238</td>\n",
       "      <td>2.190476</td>\n",
       "      <td>0.087619</td>\n",
       "      <td>1.619048</td>\n",
       "      <td>0.064762</td>\n",
       "      <td>24.566667</td>\n",
       "      <td>35.095238</td>\n",
       "      <td>0.245667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.028494</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>6.466667</td>\n",
       "      <td>0.263229</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.006784</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>0.051560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.054274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.966667</td>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>0.137042</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>0.082768</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.065129</td>\n",
       "      <td>31.266667</td>\n",
       "      <td>36.784314</td>\n",
       "      <td>0.625333</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.031450</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>7.416667</td>\n",
       "      <td>0.237207</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.020256</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>0.050107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.183333</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.016667</td>\n",
       "      <td>0.288380</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>5.366667</td>\n",
       "      <td>0.171642</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>0.060235</td>\n",
       "      <td>3.000</td>\n",
       "      <td>34.883721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.047667</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.019333</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.175667</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.070667</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>A5CFUD6W</td>\n",
       "      <td>BPZPK3933F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.508873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FRGPM5396K</td>\n",
       "      <td>20211225195910</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353659</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.499750</td>\n",
       "      <td>5.497751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.749813</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>64753</td>\n",
       "      <td>0</td>\n",
       "      <td>38960</td>\n",
       "      <td>9491</td>\n",
       "      <td>1.999667</td>\n",
       "      <td>1.999667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.999667</td>\n",
       "      <td>8.992008</td>\n",
       "      <td>1.333222</td>\n",
       "      <td>129</td>\n",
       "      <td>28</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>4.996004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>820.000000</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>710.140831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27793.0</td>\n",
       "      <td>25793.0</td>\n",
       "      <td>11896.500000</td>\n",
       "      <td>89990.0</td>\n",
       "      <td>22497.500000</td>\n",
       "      <td>52822.0</td>\n",
       "      <td>19511.426992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25793.0</td>\n",
       "      <td>25793.0</td>\n",
       "      <td>12896.500000</td>\n",
       "      <td>38960.0</td>\n",
       "      <td>16844.306878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.924812</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>282.5</td>\n",
       "      <td>257.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>466.500000</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>624.000000</td>\n",
       "      <td>624.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>184.750000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>269.50</td>\n",
       "      <td>239.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>451.500000</td>\n",
       "      <td>239.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>788</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>113</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>790</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>114</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>795</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>115</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.181132</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>0.236111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>55.714286</td>\n",
       "      <td>55.714286</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.074359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017949</td>\n",
       "      <td>9.142857</td>\n",
       "      <td>0.164103</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.028205</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.161538</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>0.105128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>0.223077</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>0.058974</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.071795</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>53.214286</td>\n",
       "      <td>53.214286</td>\n",
       "      <td>0.937107</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>0.041611</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>0.144966</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>7.857143</td>\n",
       "      <td>0.147651</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>0.123490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.244295</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>3.785714</td>\n",
       "      <td>0.071141</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>0.088591</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.065772</td>\n",
       "      <td>37.523810</td>\n",
       "      <td>49.250000</td>\n",
       "      <td>0.991195</td>\n",
       "      <td>1.476190</td>\n",
       "      <td>0.039340</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>5.380952</td>\n",
       "      <td>0.143401</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.022843</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.151015</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>0.125635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.190476</td>\n",
       "      <td>0.244924</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>2.619048</td>\n",
       "      <td>0.069797</td>\n",
       "      <td>3.523810</td>\n",
       "      <td>0.093909</td>\n",
       "      <td>2.380952</td>\n",
       "      <td>0.063452</td>\n",
       "      <td>26.266667</td>\n",
       "      <td>49.250000</td>\n",
       "      <td>0.991195</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.039340</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>0.143401</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.022843</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>3.966667</td>\n",
       "      <td>0.151015</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.125635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.433333</td>\n",
       "      <td>0.244924</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.069797</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>0.093909</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.063452</td>\n",
       "      <td>13.166667</td>\n",
       "      <td>43.888889</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.039241</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.018987</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.144304</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.018987</td>\n",
       "      <td>1.983333</td>\n",
       "      <td>0.150633</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>0.125316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>0.245570</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.069620</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>0.093671</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.795</td>\n",
       "      <td>34.565217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.038994</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.144654</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.022642</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.149686</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.124528</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.246541</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.069182</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.093082</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.062893</td>\n",
       "      <td>OZFCFMGC</td>\n",
       "      <td>FRGPM5396K</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.609313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOTPT1160A</td>\n",
       "      <td>20211225200656</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462342</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>5.997501</td>\n",
       "      <td>3.999000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.332556</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.571347</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>52450</td>\n",
       "      <td>0</td>\n",
       "      <td>52450</td>\n",
       "      <td>10038</td>\n",
       "      <td>9.995502</td>\n",
       "      <td>8.996002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.999000</td>\n",
       "      <td>19.981019</td>\n",
       "      <td>2.332889</td>\n",
       "      <td>215</td>\n",
       "      <td>32</td>\n",
       "      <td>78</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>6.997001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5033.0</td>\n",
       "      <td>5033.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1761.183125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49825.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>5087.500000</td>\n",
       "      <td>81440.0</td>\n",
       "      <td>11634.285714</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>10802.348431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27519.0</td>\n",
       "      <td>27519.0</td>\n",
       "      <td>27519.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47345.0</td>\n",
       "      <td>27519.0</td>\n",
       "      <td>3846.500000</td>\n",
       "      <td>27519.0</td>\n",
       "      <td>10579.132457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.199125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>607.428571</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>877.000000</td>\n",
       "      <td>836.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>465.666667</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>503.714286</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>101.50</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>582.000000</td>\n",
       "      <td>878.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>BIHEWFB9</td>\n",
       "      <td>BOTPT1160A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.199260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUGPR1229F</td>\n",
       "      <td>20211225201101</td>\n",
       "      <td>741.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462164</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>3.999000</td>\n",
       "      <td>29.971029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.999334</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.133324</td>\n",
       "      <td>146833</td>\n",
       "      <td>2</td>\n",
       "      <td>150306</td>\n",
       "      <td>98</td>\n",
       "      <td>3473</td>\n",
       "      <td>9795</td>\n",
       "      <td>7.997667</td>\n",
       "      <td>7.997667</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11.994503</td>\n",
       "      <td>37.963037</td>\n",
       "      <td>7.496752</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>22.978022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>2344.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>216888.0</td>\n",
       "      <td>14459.200000</td>\n",
       "      <td>174000.0</td>\n",
       "      <td>42649.025768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1736.5</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1736.5</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1736.500000</td>\n",
       "      <td>146833.0</td>\n",
       "      <td>36574.914332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.612</td>\n",
       "      <td>88.306</td>\n",
       "      <td>88.306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.612</td>\n",
       "      <td>88.306</td>\n",
       "      <td>88.306</td>\n",
       "      <td>88.306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.612</td>\n",
       "      <td>46.1224</td>\n",
       "      <td>88.306</td>\n",
       "      <td>18.00</td>\n",
       "      <td>34.442765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.718022</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>614.400000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>662.923077</td>\n",
       "      <td>687.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>618.428571</td>\n",
       "      <td>687.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>564.933333</td>\n",
       "      <td>756.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>601.400000</td>\n",
       "      <td>756.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>893</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>31</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>1565</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>495</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>421</td>\n",
       "      <td>48</td>\n",
       "      <td>95</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>3000</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>264</td>\n",
       "      <td>1</td>\n",
       "      <td>880</td>\n",
       "      <td>65</td>\n",
       "      <td>195</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>33.285714</td>\n",
       "      <td>33.285714</td>\n",
       "      <td>0.077667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.012876</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>0.188841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.077253</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>0.115880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.360515</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.085837</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.034335</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.034335</td>\n",
       "      <td>31.285714</td>\n",
       "      <td>31.285714</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>7.357143</td>\n",
       "      <td>0.235160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>0.141553</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>0.105023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.071429</td>\n",
       "      <td>0.321918</td>\n",
       "      <td>1.642857</td>\n",
       "      <td>0.052511</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>0.070776</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.020548</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>30.142857</td>\n",
       "      <td>30.142857</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.265403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>2.761905</td>\n",
       "      <td>0.091627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.238095</td>\n",
       "      <td>0.306477</td>\n",
       "      <td>1.238095</td>\n",
       "      <td>0.041074</td>\n",
       "      <td>1.952381</td>\n",
       "      <td>0.064771</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.026856</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>29.766667</td>\n",
       "      <td>29.766667</td>\n",
       "      <td>0.297667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.010078</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.268757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.022396</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.010078</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.083987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.933333</td>\n",
       "      <td>0.300112</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.061590</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.029115</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>26.083333</td>\n",
       "      <td>26.083333</td>\n",
       "      <td>0.521667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.011502</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>0.316294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.017891</td>\n",
       "      <td>3.716667</td>\n",
       "      <td>0.142492</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.092013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.016667</td>\n",
       "      <td>0.269010</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.030671</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>0.060703</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.024920</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.023642</td>\n",
       "      <td>3.000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>1.012</td>\n",
       "      <td>0.337333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.014667</td>\n",
       "      <td>MN6E2VSW</td>\n",
       "      <td>BUGPR1229F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDMPS5726L</td>\n",
       "      <td>20211225201949</td>\n",
       "      <td>828.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480803</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>8.992008</td>\n",
       "      <td>3.998501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>1.833194</td>\n",
       "      <td>422</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13509</td>\n",
       "      <td>4.665445</td>\n",
       "      <td>3.999000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.665445</td>\n",
       "      <td>16.984016</td>\n",
       "      <td>2.999000</td>\n",
       "      <td>125</td>\n",
       "      <td>14</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>10.990010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14400.0</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>748.331477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>852.666667</td>\n",
       "      <td>749.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>817.666667</td>\n",
       "      <td>686.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>834.333333</td>\n",
       "      <td>714.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>776.166667</td>\n",
       "      <td>786.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>837.333333</td>\n",
       "      <td>909.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>89</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>109</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>114</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>0.359649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>0.429825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>2.619048</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>0.482456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>3.869565</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>1.816667</td>\n",
       "      <td>3.205882</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.073394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.055046</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.091743</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.339450</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.114</td>\n",
       "      <td>3.081081</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.324561</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.359649</td>\n",
       "      <td>8KCEGVBW</td>\n",
       "      <td>IDMPS5726L</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1803 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID report_timestamp  BureauScore  BureauScoreConfidLevel  \\\n",
       "0  BPZPK3933F   20220210120018        558.0                     0.0   \n",
       "1  FRGPM5396K   20211225195910        719.0                     0.0   \n",
       "2  BOTPT1160A   20211225200656        781.0                     0.0   \n",
       "3  BUGPR1229F   20211225201101        741.0                     0.0   \n",
       "4  IDMPS5726L   20211225201949        828.0                     0.0   \n",
       "\n",
       "   MissingRate  Current_Enquiry_Reason  Current_Gender_Code  First_Name1  \\\n",
       "0     0.325254                       2                    2          0.0   \n",
       "1     0.353659                       2                    1          0.0   \n",
       "2     0.462342                       2                    1          0.0   \n",
       "3     0.462164                       2                    1          0.0   \n",
       "4     0.480803                       2                    1          0.0   \n",
       "\n",
       "   Len_Name  Tel_nuniq  Email_nuniq  IncomeTaxPAN_5  Len_of_addrs  City_nuniq  \\\n",
       "0        13  11.329890    11.994503             0.0            46    4.285245   \n",
       "1        42   1.499750     5.497751             0.0            46    1.000000   \n",
       "2        26   5.997501     3.999000             0.0            46    3.332556   \n",
       "3        14   3.999000    29.971029             0.0            46    2.999334   \n",
       "4        26   8.992008     3.998501             0.0            46    1.833194   \n",
       "\n",
       "   PinCode3  Current_State  Current_City  CreditAccountActive  \\\n",
       "0       422             27           0.0                   14   \n",
       "1       422             27           0.0                    3   \n",
       "2       422             27           0.0                    4   \n",
       "3       422             27           0.0                    2   \n",
       "4       422             27           0.0                    0   \n",
       "\n",
       "   CreditAccountTotal  CreditAccountActivePor  Outstanding_Balance_Secured  \\\n",
       "0                  22                0.636335                      5064366   \n",
       "1                   4                0.749813                            0   \n",
       "2                   7                0.571347                            0   \n",
       "3                  15                0.133324                       146833   \n",
       "4                   6                0.000000                            0   \n",
       "\n",
       "   Outstanding_Balance_UnSecured_Percentage  Outstanding_Balance_All  \\\n",
       "0                                         2                  5181373   \n",
       "1                                        60                    64753   \n",
       "2                                       100                    52450   \n",
       "3                                         2                   150306   \n",
       "4                                         0                        0   \n",
       "\n",
       "   Outstanding_Balance_Secured_Percentage  Outstanding_Balance_UnSecured  \\\n",
       "0                                      98                         117007   \n",
       "1                                       0                          38960   \n",
       "2                                       0                          52450   \n",
       "3                                      98                           3473   \n",
       "4                                       0                              0   \n",
       "\n",
       "   Diff_dateBirth  State_nuniq  Birth_nuniq  TotalCAPSLast90Days  \\\n",
       "0           13092    51.949051    22.489255                    4   \n",
       "1            9491     1.999667     1.999667                    1   \n",
       "2           10038     9.995502     8.996002                    1   \n",
       "3            9795     7.997667     7.997667                    5   \n",
       "4           13509     4.665445     3.999000                    5   \n",
       "\n",
       "   TotalCAPSLast7Days  TotalCAPSLast30Days  TotalCAPSLast180Days  \\\n",
       "0                   3                    3                     4   \n",
       "1                   0                    0                     1   \n",
       "2                   0                    0                     2   \n",
       "3                   2                    3                     5   \n",
       "4                   3                    5                     5   \n",
       "\n",
       "   CAPSLast30Days  CAPSLast7Days  CAPSLast180Days  NonCreditCAPSLast180Days  \\\n",
       "0               2              2                3                         1   \n",
       "1               0              0                1                         0   \n",
       "2               0              0                2                         0   \n",
       "3               1              0                3                         2   \n",
       "4               3              1                3                         2   \n",
       "\n",
       "   Pin_nuniq  Pan_nuniq  Ident_nuniq  Name_nuniq2  Tel_nuniq2  Email_nuniq2  \\\n",
       "0  13.246938  66.934066     5.498875          146          44            54   \n",
       "1   1.999667   8.992008     1.333222          129          28            39   \n",
       "2   4.999000  19.981019     2.332889          215          32            78   \n",
       "3  11.994503  37.963037     7.496752           27          42            27   \n",
       "4   4.665445  16.984016     2.999000          125          14            58   \n",
       "\n",
       "   Pan_nuniq2  Account_nuniq2  Ident_nuniq2  Gender_nuniq  \\\n",
       "0          14              14            60     44.956044   \n",
       "1          14              14            45      4.996004   \n",
       "2          14              14            45      6.997001   \n",
       "3          14              14            30     22.978022   \n",
       "4          14              14            30     10.990010   \n",
       "\n",
       "   Amount_Past_Due35_sum_30  Amount_Past_Due35_min_30  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Amount_Past_Due35_sum_90  Amount_Past_Due35_mean_90  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                       0.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   Amount_Past_Due35_max_90  Amount_Past_Due35_min_90  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Amount_Past_Due35_std_90  Amount_Past_Due35_sum_360  \\\n",
       "0                       0.0                     6920.0   \n",
       "1                       0.0                     1640.0   \n",
       "2                       0.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   Amount_Past_Due35_mean_360  Amount_Past_Due35_max_360  \\\n",
       "0                      1730.0                     6920.0   \n",
       "1                       820.0                     1640.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         0.0                        0.0   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   Amount_Past_Due35_std_360  Amount_Past_Due35_sum_9999  \\\n",
       "0                2996.447897                   3937140.0   \n",
       "1                 820.000000                      1640.0   \n",
       "2                   0.000000                      5033.0   \n",
       "3                   0.000000                         0.0   \n",
       "4                   0.000000                         0.0   \n",
       "\n",
       "   Amount_Past_Due35_max_9999  Amount_Past_Due35_min_9999  \\\n",
       "0                   2057589.0                         0.0   \n",
       "1                      1640.0                         0.0   \n",
       "2                      5033.0                         0.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "   Amount_Past_Due35_std_9999  \\\n",
       "0               547470.733164   \n",
       "1                  710.140831   \n",
       "2                 1761.183125   \n",
       "3                    0.000000   \n",
       "4                    0.000000   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_max_30  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_min_30  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_std_30  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_sum_90  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                          30000.0   \n",
       "3                                           4688.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_mean_90  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                           30000.0   \n",
       "3                                            2344.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_max_90  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                          30000.0   \n",
       "3                                           3473.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_min_90  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                          30000.0   \n",
       "3                                           1215.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_std_90  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                           1129.0   \n",
       "4                                              0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_sum_360  \\\n",
       "0                                          114378.0   \n",
       "1                                           27793.0   \n",
       "2                                           49825.0   \n",
       "3                                            4688.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_max_360  \\\n",
       "0                                           75400.0   \n",
       "1                                           25793.0   \n",
       "2                                           30000.0   \n",
       "3                                            3473.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_std_360  \\\n",
       "0                                      28277.352966   \n",
       "1                                      11896.500000   \n",
       "2                                       5087.500000   \n",
       "3                                       1129.000000   \n",
       "4                                          0.000000   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_sum_9999  \\\n",
       "0                                          6254569.0   \n",
       "1                                            89990.0   \n",
       "2                                            81440.0   \n",
       "3                                           216888.0   \n",
       "4                                            14400.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_mean_9999  \\\n",
       "0                                      284298.590909    \n",
       "1                                       22497.500000    \n",
       "2                                       11634.285714    \n",
       "3                                       14459.200000    \n",
       "4                                        2400.000000    \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_max_9999  \\\n",
       "0                                          1890000.0   \n",
       "1                                            52822.0   \n",
       "2                                            30000.0   \n",
       "3                                           174000.0   \n",
       "4                                             4000.0   \n",
       "\n",
       "   Highest_Credit_or_Original_Loan_Amount58_std_9999  Terms_Duration34_sum_30  \\\n",
       "0                                      509837.280159                      0.0   \n",
       "1                                       19511.426992                      0.0   \n",
       "2                                       10802.348431                      0.0   \n",
       "3                                       42649.025768                      0.0   \n",
       "4                                         748.331477                      0.0   \n",
       "\n",
       "   Terms_Duration34_std_30  Terms_Duration34_sum_90  Terms_Duration34_std_90  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                     12.0                      0.0   \n",
       "3                      0.0                      4.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   Terms_Duration34_mean_360  Terms_Duration34_max_360  \\\n",
       "0                   7.333333                      12.0   \n",
       "1                   0.000000                       0.0   \n",
       "2                  12.000000                      12.0   \n",
       "3                   2.000000                       2.0   \n",
       "4                   0.000000                       0.0   \n",
       "\n",
       "   Terms_Duration34_min_360  Terms_Duration34_std_360  \\\n",
       "0                       2.0                  4.109609   \n",
       "1                       0.0                  0.000000   \n",
       "2                      12.0                  0.000000   \n",
       "3                       2.0                  0.000000   \n",
       "4                       0.0                  0.000000   \n",
       "\n",
       "   Terms_Duration34_sum_9999  Terms_Duration34_mean_9999  \\\n",
       "0                      501.0                   55.666667   \n",
       "1                       42.0                   21.000000   \n",
       "2                       12.0                   12.000000   \n",
       "3                        7.0                    1.400000   \n",
       "4                        0.0                    0.000000   \n",
       "\n",
       "   Terms_Duration34_max_9999  Terms_Duration34_min_9999  \\\n",
       "0                      240.0                        2.0   \n",
       "1                       36.0                        6.0   \n",
       "2                       12.0                       12.0   \n",
       "3                        2.0                        1.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Terms_Duration34_std_9999  Payment_Rating34_sum_90  \\\n",
       "0                  72.033943                      0.0   \n",
       "1                  15.000000                      0.0   \n",
       "2                   0.000000                      0.0   \n",
       "3                   0.489898                      0.0   \n",
       "4                   0.000000                      0.0   \n",
       "\n",
       "   Payment_Rating34_mean_90  Payment_Rating34_max_90  Payment_Rating34_min_90  \\\n",
       "0                       0.0                      0.0                      0.0   \n",
       "1                       0.0                      0.0                      0.0   \n",
       "2                       0.0                      0.0                      0.0   \n",
       "3                       0.0                      0.0                      0.0   \n",
       "4                       0.0                      0.0                      0.0   \n",
       "\n",
       "   Payment_Rating34_std_90  Payment_Rating34_sum_360  \\\n",
       "0                      0.0                       1.0   \n",
       "1                      0.0                       0.0   \n",
       "2                      0.0                       0.0   \n",
       "3                      0.0                       0.0   \n",
       "4                      0.0                       0.0   \n",
       "\n",
       "   Payment_Rating34_mean_360  Payment_Rating34_max_360  \\\n",
       "0                       0.25                       1.0   \n",
       "1                       0.00                       0.0   \n",
       "2                       0.00                       0.0   \n",
       "3                       0.00                       0.0   \n",
       "4                       0.00                       0.0   \n",
       "\n",
       "   Payment_Rating34_min_360  Payment_Rating34_std_360  \\\n",
       "0                       0.0                  0.433013   \n",
       "1                       0.0                  0.000000   \n",
       "2                       0.0                  0.000000   \n",
       "3                       0.0                  0.000000   \n",
       "4                       0.0                  0.000000   \n",
       "\n",
       "   Payment_Rating34_sum_9999  Payment_Rating34_mean_9999  \\\n",
       "0                       27.0                    1.227273   \n",
       "1                        0.0                    0.000000   \n",
       "2                        0.0                    0.000000   \n",
       "3                        0.0                    0.000000   \n",
       "4                        0.0                    0.000000   \n",
       "\n",
       "   Payment_Rating34_max_9999  Payment_Rating34_min_9999  \\\n",
       "0                        6.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Payment_Rating34_std_9999  Current_Balance35_mean_30  \\\n",
       "0                   2.294892                        0.0   \n",
       "1                   0.000000                        0.0   \n",
       "2                   0.000000                        0.0   \n",
       "3                   0.000000                        0.0   \n",
       "4                   0.000000                        0.0   \n",
       "\n",
       "   Current_Balance35_min_30  Current_Balance35_std_30  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Current_Balance35_sum_90  Current_Balance35_mean_90  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                   27519.0                    27519.0   \n",
       "3                    3473.0                     1736.5   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   Current_Balance35_max_90  Current_Balance35_std_90  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                   27519.0                       0.0   \n",
       "3                    3473.0                    1736.5   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   Current_Balance35_sum_360  Current_Balance35_max_360  \\\n",
       "0                    97130.0                    75400.0   \n",
       "1                    25793.0                    25793.0   \n",
       "2                    47345.0                    27519.0   \n",
       "3                     3473.0                     3473.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Current_Balance35_std_360  Current_Balance35_max_9999  \\\n",
       "0               30111.798663                   2057589.0   \n",
       "1               12896.500000                     38960.0   \n",
       "2                3846.500000                     27519.0   \n",
       "3                1736.500000                    146833.0   \n",
       "4                   0.000000                         0.0   \n",
       "\n",
       "   Current_Balance35_std_9999  Settlement_Amount37_max_360  \\\n",
       "0               539918.618880                          0.0   \n",
       "1                16844.306878                          0.0   \n",
       "2                10579.132457                          0.0   \n",
       "3                36574.914332                          0.0   \n",
       "4                    0.000000                          0.0   \n",
       "\n",
       "   Settlement_Amount37_min_360  Settlement_Amount37_std_360  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   Settlement_Amount37_sum_9999  Settlement_Amount37_mean_9999  \\\n",
       "0                           0.0                            0.0   \n",
       "1                           0.0                            0.0   \n",
       "2                           0.0                            0.0   \n",
       "3                           0.0                            0.0   \n",
       "4                           0.0                            0.0   \n",
       "\n",
       "   Settlement_Amount37_max_9999  Settlement_Amount37_min_9999  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   Settlement_Amount37_std_9999  Value_of_Collateral39_std_90  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   Value_of_Collateral39_std_360  Written_Off_Amt_Total41_sum_360  \\\n",
       "0                            0.0                              0.0   \n",
       "1                            0.0                              0.0   \n",
       "2                            0.0                              0.0   \n",
       "3                            0.0                              0.0   \n",
       "4                            0.0                              0.0   \n",
       "\n",
       "   Written_Off_Amt_Total41_mean_360  Written_Off_Amt_Total41_min_360  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "\n",
       "   Written_Off_Amt_Total41_std_360  Written_Off_Amt_Total41_sum_9999  \\\n",
       "0                              0.0                               0.0   \n",
       "1                              0.0                               0.0   \n",
       "2                              0.0                               0.0   \n",
       "3                              0.0                               0.0   \n",
       "4                              0.0                               0.0   \n",
       "\n",
       "   Written_Off_Amt_Total41_mean_9999  Written_Off_Amt_Total41_max_9999  \\\n",
       "0                                0.0                               0.0   \n",
       "1                                0.0                               0.0   \n",
       "2                                0.0                               0.0   \n",
       "3                                0.0                               0.0   \n",
       "4                                0.0                               0.0   \n",
       "\n",
       "   Written_Off_Amt_Total41_min_9999  Written_Off_Amt_Total41_std_9999  \\\n",
       "0                               0.0                               0.0   \n",
       "1                               0.0                               0.0   \n",
       "2                               0.0                               0.0   \n",
       "3                               0.0                               0.0   \n",
       "4                               0.0                               0.0   \n",
       "\n",
       "   Written_Off_Amt_Principal45_sum_360  Written_Off_Amt_Principal45_mean_360  \\\n",
       "0                                  0.0                                   0.0   \n",
       "1                                  0.0                                   0.0   \n",
       "2                                  0.0                                   0.0   \n",
       "3                                  0.0                                   0.0   \n",
       "4                                  0.0                                   0.0   \n",
       "\n",
       "   Written_Off_Amt_Principal45_min_360  Written_Off_Amt_Principal45_std_360  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  0.0   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  0.0   \n",
       "4                                  0.0                                  0.0   \n",
       "\n",
       "   Written_Off_Amt_Principal45_max_9999  Written_Off_Amt_Principal45_min_9999  \\\n",
       "0                               19637.0                                   0.0   \n",
       "1                                   0.0                                   0.0   \n",
       "2                                   0.0                                   0.0   \n",
       "3                                   0.0                                   0.0   \n",
       "4                                   0.0                                   0.0   \n",
       "\n",
       "   Rate_of_Interest36_sum_30  Rate_of_Interest36_std_30  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Rate_of_Interest36_sum_90  Rate_of_Interest36_mean_90  \\\n",
       "0                      0.000                       0.000   \n",
       "1                      0.000                       0.000   \n",
       "2                     28.000                      28.000   \n",
       "3                    176.612                      88.306   \n",
       "4                      0.000                       0.000   \n",
       "\n",
       "   Rate_of_Interest36_max_90  Rate_of_Interest36_std_90  \\\n",
       "0                      0.000                        0.0   \n",
       "1                      0.000                        0.0   \n",
       "2                     28.000                        0.0   \n",
       "3                     88.306                        0.0   \n",
       "4                      0.000                        0.0   \n",
       "\n",
       "   Rate_of_Interest36_sum_360  Rate_of_Interest36_mean_360  \\\n",
       "0                      18.000                       18.000   \n",
       "1                       0.000                        0.000   \n",
       "2                      28.000                       28.000   \n",
       "3                     176.612                       88.306   \n",
       "4                       0.000                        0.000   \n",
       "\n",
       "   Rate_of_Interest36_max_360  Rate_of_Interest36_min_360  \\\n",
       "0                      18.000                      18.000   \n",
       "1                       0.000                       0.000   \n",
       "2                      28.000                      28.000   \n",
       "3                      88.306                      88.306   \n",
       "4                       0.000                       0.000   \n",
       "\n",
       "   Rate_of_Interest36_std_360  Rate_of_Interest36_sum_9999  \\\n",
       "0                         0.0                       90.930   \n",
       "1                         0.0                        0.000   \n",
       "2                         0.0                       28.000   \n",
       "3                         0.0                      230.612   \n",
       "4                         0.0                        0.000   \n",
       "\n",
       "   Rate_of_Interest36_mean_9999  Rate_of_Interest36_max_9999  \\\n",
       "0                       18.1860                       47.880   \n",
       "1                        0.0000                        0.000   \n",
       "2                       28.0000                       28.000   \n",
       "3                       46.1224                       88.306   \n",
       "4                        0.0000                        0.000   \n",
       "\n",
       "   Rate_of_Interest36_min_9999  Rate_of_Interest36_std_9999  \\\n",
       "0                         7.55                    15.316455   \n",
       "1                         0.00                     0.000000   \n",
       "2                        28.00                     0.000000   \n",
       "3                        18.00                    34.442765   \n",
       "4                         0.00                     0.000000   \n",
       "\n",
       "   Repayment_Tenure36_std_30  Repayment_Tenure36_mean_90  \\\n",
       "0                        0.0                         0.0   \n",
       "1                        0.0                         0.0   \n",
       "2                        0.0                        12.0   \n",
       "3                        0.0                         2.0   \n",
       "4                        0.0                         0.0   \n",
       "\n",
       "   Repayment_Tenure36_max_90  Repayment_Tenure36_min_90  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                       12.0                       12.0   \n",
       "3                        2.0                        2.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Repayment_Tenure36_std_90  Repayment_Tenure36_sum_360  \\\n",
       "0                        0.0                        22.0   \n",
       "1                        0.0                         0.0   \n",
       "2                        0.0                        12.0   \n",
       "3                        0.0                         4.0   \n",
       "4                        0.0                         0.0   \n",
       "\n",
       "   Repayment_Tenure36_mean_360  Repayment_Tenure36_min_360  \\\n",
       "0                          5.5                         0.0   \n",
       "1                          0.0                         0.0   \n",
       "2                          6.0                         0.0   \n",
       "3                          2.0                         2.0   \n",
       "4                          0.0                         0.0   \n",
       "\n",
       "   Repayment_Tenure36_std_360  Repayment_Tenure36_mean_9999  \\\n",
       "0                    4.769696                     22.772727   \n",
       "1                    0.000000                     10.500000   \n",
       "2                    6.000000                      1.714286   \n",
       "3                    0.000000                      0.466667   \n",
       "4                    0.000000                      0.000000   \n",
       "\n",
       "   Repayment_Tenure36_min_9999  Repayment_Tenure36_std_9999  \\\n",
       "0                          0.0                    53.589290   \n",
       "1                          0.0                    14.924812   \n",
       "2                          0.0                     4.199125   \n",
       "3                          0.0                     0.718022   \n",
       "4                          0.0                     0.000000   \n",
       "\n",
       "   Income26_count_360  Income26_std_360  Open_Date29_max_30  \\\n",
       "0                 4.0               0.0                 0.0   \n",
       "1                 2.0               0.0                 0.0   \n",
       "2                 2.0               0.0                 0.0   \n",
       "3                 2.0               0.0                 0.0   \n",
       "4                 0.0               0.0                 0.0   \n",
       "\n",
       "   Open_Date29_min_30  Open_Date29_mean_30  Open_Date29_nuniq_30  \\\n",
       "0                 0.0                  0.0                   0.0   \n",
       "1                 0.0                  0.0                   0.0   \n",
       "2                 0.0                  0.0                   0.0   \n",
       "3                 0.0                  0.0                   0.0   \n",
       "4                 0.0                  0.0                   0.0   \n",
       "\n",
       "   Open_Date29_maxcount_30  Open_Date29_max_90  Open_Date29_mean_90  \\\n",
       "0                      0.0                 0.0                  0.0   \n",
       "1                      0.0                 0.0                  0.0   \n",
       "2                      0.0                42.0                 42.0   \n",
       "3                      0.0                68.0                 53.0   \n",
       "4                      0.0                 0.0                  0.0   \n",
       "\n",
       "   Open_Date29_mode_90  Open_Date29_nuniq_90  Open_Date29_maxcount_90  \\\n",
       "0                  0.0                   0.0                      0.0   \n",
       "1                  0.0                   0.0                      0.0   \n",
       "2                 42.0                   1.0                      1.0   \n",
       "3                 38.0                   2.0                      1.0   \n",
       "4                  0.0                   0.0                      0.0   \n",
       "\n",
       "   Open_Date29_max_360  Open_Date29_mean_360  Open_Date29_mode_360  \\\n",
       "0                180.0                 153.5                 113.0   \n",
       "1                308.0                 282.5                 257.0   \n",
       "2                224.0                 133.0                  42.0   \n",
       "3                 68.0                  53.0                  38.0   \n",
       "4                  0.0                   0.0                   0.0   \n",
       "\n",
       "   Open_Date29_nuniq_360  Open_Date29_maxcount_360  Open_Date29_max_9999  \\\n",
       "0                    4.0                       1.0                2884.0   \n",
       "1                    2.0                       1.0                 813.0   \n",
       "2                    2.0                       1.0                 906.0   \n",
       "3                    2.0                       1.0                 772.0   \n",
       "4                    0.0                       0.0                 932.0   \n",
       "\n",
       "   Open_Date29_mean_9999  Open_Date29_mode_9999  Open_Date29_maxcount_9999  \\\n",
       "0            1061.772727                 1182.0                        2.0   \n",
       "1             466.500000                  257.0                        1.0   \n",
       "2             607.428571                   42.0                        1.0   \n",
       "3             614.400000                   38.0                        1.0   \n",
       "4             852.666667                  749.0                        1.0   \n",
       "\n",
       "   Portfolio_Type34_mode_30  Portfolio_Type34_nuniq_30  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                       0.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   Portfolio_Type34_nuniq_90  Portfolio_Type34_mode_360  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        1.0                        0.0   \n",
       "3                        1.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Portfolio_Type34_nuniq_360  Portfolio_Type34_mode_9999  \\\n",
       "0                         1.0                         0.0   \n",
       "1                         2.0                         0.0   \n",
       "2                         2.0                         0.0   \n",
       "3                         1.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "   Portfolio_Type34_nuniq_9999  Account_Type32_nuniq_30  \\\n",
       "0                          3.0                      0.0   \n",
       "1                          2.0                      0.0   \n",
       "2                          2.0                      0.0   \n",
       "3                          1.0                      0.0   \n",
       "4                          1.0                      0.0   \n",
       "\n",
       "   Account_Type32_mode_90  Account_Type32_nuniq_90  Account_Type32_mode_360  \\\n",
       "0                     0.0                      0.0                      5.0   \n",
       "1                     0.0                      0.0                      6.0   \n",
       "2                     5.0                      1.0                      5.0   \n",
       "3                     5.0                      1.0                      5.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   Account_Type32_nuniq_360  Account_Type32_mode_9999  \\\n",
       "0                       3.0                       7.0   \n",
       "1                       2.0                       6.0   \n",
       "2                       2.0                       5.0   \n",
       "3                       1.0                       5.0   \n",
       "4                       0.0                       5.0   \n",
       "\n",
       "   Account_Type32_nuniq_9999  Occupation_Code35_nuniq_30  \\\n",
       "0                        9.0                         0.0   \n",
       "1                        3.0                         0.0   \n",
       "2                        3.0                         0.0   \n",
       "3                        2.0                         0.0   \n",
       "4                        1.0                         0.0   \n",
       "\n",
       "   Occupation_Code35_nuniq_90  Occupation_Code35_nuniq_360  \\\n",
       "0                         0.0                          1.0   \n",
       "1                         0.0                          1.0   \n",
       "2                         1.0                          2.0   \n",
       "3                         1.0                          1.0   \n",
       "4                         0.0                          0.0   \n",
       "\n",
       "   Occupation_Code35_nuniq_9999  CurrencyCode32_mode_360  \\\n",
       "0                           1.0                      0.0   \n",
       "1                           1.0                      0.0   \n",
       "2                           3.0                      0.0   \n",
       "3                           2.0                      0.0   \n",
       "4                           1.0                      0.0   \n",
       "\n",
       "   CurrencyCode32_mode_9999  AccountHoldertypeCode41_mode_90  \\\n",
       "0                       0.0                              0.0   \n",
       "1                       0.0                              0.0   \n",
       "2                       0.0                              1.0   \n",
       "3                       0.0                              1.0   \n",
       "4                       0.0                              0.0   \n",
       "\n",
       "   AccountHoldertypeCode41_nuniq_90  AccountHoldertypeCode41_nuniq_360  \\\n",
       "0                               0.0                                1.0   \n",
       "1                               0.0                                1.0   \n",
       "2                               1.0                                1.0   \n",
       "3                               1.0                                1.0   \n",
       "4                               0.0                                0.0   \n",
       "\n",
       "   AccountHoldertypeCode41_mode_9999  AccountHoldertypeCode41_nuniq_9999  \\\n",
       "0                                1.0                                 2.0   \n",
       "1                                1.0                                 1.0   \n",
       "2                                1.0                                 1.0   \n",
       "3                                1.0                                 2.0   \n",
       "4                                1.0                                 1.0   \n",
       "\n",
       "   Payment_History_Profile43_mode_30  Payment_History_Profile43_mode_90  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  0   \n",
       "2                                  0                                  1   \n",
       "3                                  0                                 36   \n",
       "4                                  0                                  0   \n",
       "\n",
       "   Payment_History_Profile43_nuniq_90  Payment_History_Profile43_mode_360  \\\n",
       "0                                 0.0                                  36   \n",
       "1                                 0.0                                  36   \n",
       "2                                 1.0                                  36   \n",
       "3                                 2.0                                  36   \n",
       "4                                 0.0                                   0   \n",
       "\n",
       "   Payment_History_Profile43_nuniq_360  Payment_History_Profile43_mode_9999  \\\n",
       "0                                  2.0                                   36   \n",
       "1                                  2.0                                   36   \n",
       "2                                  2.0                                    1   \n",
       "3                                  2.0                                    1   \n",
       "4                                  0.0                                   36   \n",
       "\n",
       "   Payment_History_Profile43_nuniq_9999  Date_Closed31_nuniq_30  \\\n",
       "0                                  17.0                     0.0   \n",
       "1                                   4.0                     0.0   \n",
       "2                                   4.0                     0.0   \n",
       "3                                   5.0                     0.0   \n",
       "4                                   4.0                     0.0   \n",
       "\n",
       "   Date_Closed31_maxcount_30  Date_Closed31_max_90  Date_Closed31_min_90  \\\n",
       "0                        0.0                   0.0                   0.0   \n",
       "1                        0.0                   0.0                   0.0   \n",
       "2                        0.0                   0.0                   0.0   \n",
       "3                        0.0                  38.0                  38.0   \n",
       "4                        0.0                   0.0                   0.0   \n",
       "\n",
       "   Date_Closed31_mean_90  Date_Closed31_mode_90  Date_Closed31_nuniq_90  \\\n",
       "0                    0.0                    0.0                     0.0   \n",
       "1                    0.0                    0.0                     0.0   \n",
       "2                    0.0                    0.0                     1.0   \n",
       "3                   38.0                   38.0                     2.0   \n",
       "4                    0.0                    0.0                     0.0   \n",
       "\n",
       "   Date_Closed31_maxcount_90  Date_Closed31_min_360  Date_Closed31_mode_360  \\\n",
       "0                        0.0                    0.0                     0.0   \n",
       "1                        0.0                    0.0                     0.0   \n",
       "2                        0.0                    0.0                     0.0   \n",
       "3                        1.0                   38.0                    38.0   \n",
       "4                        0.0                    0.0                     0.0   \n",
       "\n",
       "   Date_Closed31_nuniq_360  Date_Closed31_maxcount_360  \\\n",
       "0                      1.0                         0.0   \n",
       "1                      1.0                         0.0   \n",
       "2                      1.0                         0.0   \n",
       "3                      2.0                         1.0   \n",
       "4                      0.0                         0.0   \n",
       "\n",
       "   Date_Closed31_max_9999  Date_Closed31_min_9999  Date_Closed31_mean_9999  \\\n",
       "0                  1742.0                    87.0               720.625000   \n",
       "1                   624.0                   624.0               624.000000   \n",
       "2                   903.0                   836.0               877.000000   \n",
       "3                   764.0                    38.0               662.923077   \n",
       "4                   915.0                   686.0               817.666667   \n",
       "\n",
       "   Date_Closed31_mode_9999  Date_Closed31_nuniq_9999  \\\n",
       "0                     87.0                       9.0   \n",
       "1                    624.0                       2.0   \n",
       "2                    836.0                       4.0   \n",
       "3                    687.0                      13.0   \n",
       "4                    686.0                       6.0   \n",
       "\n",
       "   Date_of_Last_Payment40_nuniq_30  Date_of_Last_Payment40_maxcount_30  \\\n",
       "0                              0.0                                 0.0   \n",
       "1                              0.0                                 0.0   \n",
       "2                              0.0                                 0.0   \n",
       "3                              0.0                                 0.0   \n",
       "4                              0.0                                 0.0   \n",
       "\n",
       "   Date_of_Last_Payment40_min_90  Date_of_Last_Payment40_nuniq_90  \\\n",
       "0                            0.0                              0.0   \n",
       "1                            0.0                              0.0   \n",
       "2                           24.0                              1.0   \n",
       "3                           38.0                              2.0   \n",
       "4                            0.0                              0.0   \n",
       "\n",
       "   Date_of_Last_Payment40_maxcount_90  Date_of_Last_Payment40_max_360  \\\n",
       "0                                 0.0                           150.0   \n",
       "1                                 0.0                            42.0   \n",
       "2                                 1.0                            65.0   \n",
       "3                                 1.0                            38.0   \n",
       "4                                 0.0                             0.0   \n",
       "\n",
       "   Date_of_Last_Payment40_min_360  Date_of_Last_Payment40_mean_360  \\\n",
       "0                            70.0                             97.0   \n",
       "1                            42.0                             42.0   \n",
       "2                            24.0                             44.5   \n",
       "3                            38.0                             38.0   \n",
       "4                             0.0                              0.0   \n",
       "\n",
       "   Date_of_Last_Payment40_mode_360  Date_of_Last_Payment40_nuniq_360  \\\n",
       "0                             70.0                               4.0   \n",
       "1                             42.0                               2.0   \n",
       "2                             24.0                               2.0   \n",
       "3                             38.0                               2.0   \n",
       "4                              0.0                               0.0   \n",
       "\n",
       "   Date_of_Last_Payment40_maxcount_360  Date_of_Last_Payment40_max_9999  \\\n",
       "0                                  1.0                           1742.0   \n",
       "1                                  1.0                            632.0   \n",
       "2                                  1.0                            903.0   \n",
       "3                                  1.0                            764.0   \n",
       "4                                  0.0                            932.0   \n",
       "\n",
       "   Date_of_Last_Payment40_min_9999  Date_of_Last_Payment40_mean_9999  \\\n",
       "0                             54.0                        436.000000   \n",
       "1                             42.0                        248.000000   \n",
       "2                             24.0                        465.666667   \n",
       "3                             38.0                        618.428571   \n",
       "4                            714.0                        834.333333   \n",
       "\n",
       "   Date_of_Last_Payment40_mode_9999  Date_of_Last_Payment40_maxcount_9999  \\\n",
       "0                             401.0                                   2.0   \n",
       "1                              42.0                                   1.0   \n",
       "2                              24.0                                   1.0   \n",
       "3                             687.0                                   2.0   \n",
       "4                             714.0                                   1.0   \n",
       "\n",
       "   Date_Reported33_nuniq_30  Date_Reported33_max_90  Date_Reported33_mean_90  \\\n",
       "0                       0.0                     0.0                      0.0   \n",
       "1                       0.0                     0.0                      0.0   \n",
       "2                       0.0                    25.0                     25.0   \n",
       "3                       0.0                    25.0                     25.0   \n",
       "4                       0.0                     0.0                      0.0   \n",
       "\n",
       "   Date_Reported33_mode_90  Date_Reported33_nuniq_90  \\\n",
       "0                      0.0                       0.0   \n",
       "1                      0.0                       0.0   \n",
       "2                     25.0                       1.0   \n",
       "3                     25.0                       1.0   \n",
       "4                      0.0                       0.0   \n",
       "\n",
       "   Date_Reported33_maxcount_90  Date_Reported33_max_360  \\\n",
       "0                          0.0                     41.0   \n",
       "1                          0.0                     55.0   \n",
       "2                          1.0                     25.0   \n",
       "3                          2.0                     25.0   \n",
       "4                          0.0                      0.0   \n",
       "\n",
       "   Date_Reported33_mean_360  Date_Reported33_mode_360  \\\n",
       "0                     33.25                      41.0   \n",
       "1                     40.00                      25.0   \n",
       "2                     25.00                      25.0   \n",
       "3                     25.00                      25.0   \n",
       "4                      0.00                       0.0   \n",
       "\n",
       "   Date_Reported33_nuniq_360  Date_Reported33_maxcount_360  \\\n",
       "0                        2.0                           3.0   \n",
       "1                        2.0                           1.0   \n",
       "2                        1.0                           2.0   \n",
       "3                        1.0                           2.0   \n",
       "4                        0.0                           0.0   \n",
       "\n",
       "   Date_Reported33_max_9999  Date_Reported33_mean_9999  \\\n",
       "0                    1716.0                 304.000000   \n",
       "1                     604.0                 184.750000   \n",
       "2                     878.0                 503.714286   \n",
       "3                     756.0                 564.933333   \n",
       "4                     878.0                 776.166667   \n",
       "\n",
       "   Date_Reported33_mode_9999  Date_Reported33_nuniq_9999  \\\n",
       "0                       41.0                        12.0   \n",
       "1                       55.0                         3.0   \n",
       "2                       25.0                         3.0   \n",
       "3                      756.0                         7.0   \n",
       "4                      786.0                         5.0   \n",
       "\n",
       "   Date_Reported33_maxcount_9999  DateOfAddition34_nuniq_30  \\\n",
       "0                           10.0                        0.0   \n",
       "1                            2.0                        0.0   \n",
       "2                            3.0                        0.0   \n",
       "3                            4.0                        0.0   \n",
       "4                            2.0                        0.0   \n",
       "\n",
       "   DateOfAddition34_max_90  DateOfAddition34_mean_90  \\\n",
       "0                      0.0                       0.0   \n",
       "1                      0.0                       0.0   \n",
       "2                     25.0                      25.0   \n",
       "3                     55.0                      40.0   \n",
       "4                      0.0                       0.0   \n",
       "\n",
       "   DateOfAddition34_mode_90  DateOfAddition34_nuniq_90  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                      25.0                        1.0   \n",
       "3                      25.0                        2.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   DateOfAddition34_maxcount_90  DateOfAddition34_max_360  \\\n",
       "0                           0.0                     163.0   \n",
       "1                           0.0                     300.0   \n",
       "2                           1.0                     178.0   \n",
       "3                           1.0                      55.0   \n",
       "4                           0.0                       0.0   \n",
       "\n",
       "   DateOfAddition34_mean_360  DateOfAddition34_mode_360  \\\n",
       "0                     140.25                      163.0   \n",
       "1                     269.50                      239.0   \n",
       "2                     101.50                       25.0   \n",
       "3                      40.00                       25.0   \n",
       "4                       0.00                        0.0   \n",
       "\n",
       "   DateOfAddition34_nuniq_360  DateOfAddition34_maxcount_360  \\\n",
       "0                         3.0                            2.0   \n",
       "1                         2.0                            1.0   \n",
       "2                         2.0                            1.0   \n",
       "3                         2.0                            1.0   \n",
       "4                         0.0                            0.0   \n",
       "\n",
       "   DateOfAddition34_max_9999  DateOfAddition34_mean_9999  \\\n",
       "0                     2478.0                  974.136364   \n",
       "1                      786.0                  451.500000   \n",
       "2                      878.0                  582.000000   \n",
       "3                      756.0                  601.400000   \n",
       "4                      909.0                  837.333333   \n",
       "\n",
       "   DateOfAddition34_mode_9999  DateOfAddition34_nuniq_9999  \\\n",
       "0                       163.0                         18.0   \n",
       "1                       239.0                          4.0   \n",
       "2                       878.0                          4.0   \n",
       "3                       756.0                          7.0   \n",
       "4                       909.0                          5.0   \n",
       "\n",
       "   DateOfAddition34_maxcount_9999  Account_Status34_mode_30  \\\n",
       "0                             2.0                       0.0   \n",
       "1                             1.0                       0.0   \n",
       "2                             4.0                       0.0   \n",
       "3                             6.0                       0.0   \n",
       "4                             2.0                       0.0   \n",
       "\n",
       "   Account_Status34_nuniq_30  Account_Status34_mode_90  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                      11.0   \n",
       "3                        0.0                      11.0   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   Account_Status34_nuniq_90  Account_Status34_mode_360  \\\n",
       "0                        0.0                       11.0   \n",
       "1                        0.0                       11.0   \n",
       "2                        1.0                       11.0   \n",
       "3                        2.0                       11.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   Account_Status34_nuniq_360  Account_Status34_mode_9999  \\\n",
       "0                         2.0                        13.0   \n",
       "1                         1.0                        11.0   \n",
       "2                         1.0                        11.0   \n",
       "3                         2.0                        13.0   \n",
       "4                         0.0                        13.0   \n",
       "\n",
       "   Account_Status34_nuniq_9999  Month50_sum_30  Month50_max_30  \\\n",
       "0                          7.0             0.0             0.0   \n",
       "1                          2.0             0.0             0.0   \n",
       "2                          2.0             0.0             0.0   \n",
       "3                          3.0             0.0             0.0   \n",
       "4                          1.0             0.0             0.0   \n",
       "\n",
       "   Month50_std_30  Month50_sum_90  Month50_mean_90  ...  feature_1036_sms  \\\n",
       "0             0.0             0.0              0.0  ...               137   \n",
       "1             0.0             0.0              0.0  ...               113   \n",
       "2             0.0            11.0             11.0  ...                 0   \n",
       "3             0.0            22.0             11.0  ...               168   \n",
       "4             0.0             0.0              0.0  ...                 1   \n",
       "\n",
       "   feature_1037_sms  feature_1038_sms  feature_1039_sms  feature_1040_sms  \\\n",
       "0                 1                 3                19                 0   \n",
       "1                18                15               119                 2   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 4                93                 1   \n",
       "4                 1                 1                 0                 0   \n",
       "\n",
       "   feature_1041_sms  feature_1042_sms  feature_1043_sms  feature_1044_sms  \\\n",
       "0                 0                26                 0               153   \n",
       "1                 1                99                 0               193   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 5                58                 0               194   \n",
       "4                 1                 7                 0                 6   \n",
       "\n",
       "   feature_1045_sms  feature_1046_sms  feature_1047_sms  feature_1048_sms  \\\n",
       "0                13                71                46                34   \n",
       "1                 3                55                74                50   \n",
       "2                 0                 0                 0                 1   \n",
       "3                26                41                17                18   \n",
       "4                 0                 3                20                13   \n",
       "\n",
       "   feature_1049_sms  feature_1050_sms  feature_1051_sms  feature_1052_sms  \\\n",
       "0               737                21                21                 4   \n",
       "1               788                16                31                15   \n",
       "2                 1                 1                 0                 0   \n",
       "3               893                30                 3                 9   \n",
       "4                89                23                 0                 2   \n",
       "\n",
       "   feature_1053_sms  feature_1054_sms  feature_1055_sms  feature_1056_sms  \\\n",
       "0               194                 1                 5                38   \n",
       "1               113                18                15               119   \n",
       "2                 0                 0                 0                 0   \n",
       "3               240                 0                20               133   \n",
       "4                 1                 1                 1                 0   \n",
       "\n",
       "   feature_1057_sms  feature_1058_sms  feature_1059_sms  feature_1060_sms  \\\n",
       "0                 0                 0                40                 0   \n",
       "1                 2                 1                99                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 1                 9                75                 0   \n",
       "4                 0                 2                 8                 0   \n",
       "\n",
       "   feature_1061_sms  feature_1062_sms  feature_1063_sms  feature_1064_sms  \\\n",
       "0               209                15               101                61   \n",
       "1               193                 3                55                74   \n",
       "2                 0                 0                 0                 0   \n",
       "3               268                31                55                26   \n",
       "4                 6                 0                 6                31   \n",
       "\n",
       "   feature_1065_sms  feature_1066_sms  feature_1067_sms  feature_1068_sms  \\\n",
       "0                48              1876                51                59   \n",
       "1                50               790                18                31   \n",
       "2                 1                 1                 1                 0   \n",
       "3                23              1565                60                 3   \n",
       "4                31               109                34                 0   \n",
       "\n",
       "   feature_1069_sms  feature_1070_sms  feature_1071_sms  feature_1072_sms  \\\n",
       "0                 7               445                 2                38   \n",
       "1                15               114                18                15   \n",
       "2                 0                 0                 0                 0   \n",
       "3                18               495                 0                28   \n",
       "4                 2                 1                 1                 1   \n",
       "\n",
       "   feature_1073_sms  feature_1074_sms  feature_1075_sms  feature_1076_sms  \\\n",
       "0                94                 0                 0                71   \n",
       "1               119                 2                 1                99   \n",
       "2                 0                 0                 0                 0   \n",
       "3               223                 1                13               144   \n",
       "4                 0                 0                 2                 8   \n",
       "\n",
       "   feature_1077_sms  feature_1078_sms  feature_1079_sms  feature_1080_sms  \\\n",
       "0                 0               541                30               322   \n",
       "1                 0               194                 3                55   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0               421                48                95   \n",
       "4                 0                 6                 0                10   \n",
       "\n",
       "   feature_1081_sms  feature_1082_sms  feature_1083_sms  feature_1084_sms  \\\n",
       "0               154               113              3000                86   \n",
       "1                74                50               795                23   \n",
       "2                 0                 1                 1                 1   \n",
       "3                39                37              3000               150   \n",
       "4                37                41               114                37   \n",
       "\n",
       "   feature_1085_sms  feature_1086_sms  feature_1087_sms  feature_1088_sms  \\\n",
       "0               143                25               681                10   \n",
       "1                31                15               115                18   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 6                22              1012                 0   \n",
       "4                 0                 2                 4                 1   \n",
       "\n",
       "   feature_1089_sms  feature_1090_sms  feature_1091_sms  feature_1092_sms  \\\n",
       "0                58               181                 0                 1   \n",
       "1                16               119                 2                 1   \n",
       "2                 0                 0                 0                 0   \n",
       "3                99               314                 1                16   \n",
       "4                 1                 0                 0                 2   \n",
       "\n",
       "   feature_1093_sms  feature_1094_sms  feature_1095_sms  feature_1096_sms  \\\n",
       "0                90                 2               870                38   \n",
       "1                99                 1               196                 3   \n",
       "2                 0                 0                 0                 0   \n",
       "3               264                 1               880                65   \n",
       "4                 9                 0                 6                 1   \n",
       "\n",
       "   feature_1097_sms  feature_1098_sms  feature_1099_sms  feature_1100_sms  \\\n",
       "0               527               212               162         37.333333   \n",
       "1                55                74                50         48.000000   \n",
       "2                 0                 0                 1          0.333333   \n",
       "3               195                77                44         32.000000   \n",
       "4                10                37                41          9.000000   \n",
       "\n",
       "   feature_1101_sms  feature_1102_sms  feature_1103_sms  feature_1104_sms  \\\n",
       "0         37.333333          0.037333          0.000000          0.000000   \n",
       "1         48.000000          0.181132          5.000000          0.104167   \n",
       "2          1.000000          1.000000          0.000000          0.000000   \n",
       "3         32.000000          0.032000          0.666667          0.020833   \n",
       "4          9.000000          0.236842          0.000000          0.000000   \n",
       "\n",
       "   feature_1105_sms  feature_1106_sms  feature_1107_sms  feature_1108_sms  \\\n",
       "0          0.666667          0.017857          9.666667          0.258929   \n",
       "1          1.666667          0.034722          7.333333          0.152778   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          1.000000          0.031250          5.000000          0.156250   \n",
       "4          0.666667          0.074074          0.000000          0.000000   \n",
       "\n",
       "   feature_1109_sms  feature_1110_sms  feature_1111_sms  feature_1112_sms  \\\n",
       "0          0.333333          0.008929          0.333333          0.008929   \n",
       "1          1.000000          0.020833          3.333333          0.069444   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.000000          0.000000          0.666667          0.020833   \n",
       "4          0.000000          0.000000          0.333333          0.037037   \n",
       "\n",
       "   feature_1113_sms  feature_1114_sms  feature_1115_sms  feature_1116_sms  \\\n",
       "0          1.333333          0.035714          0.000000          0.000000   \n",
       "1          8.000000          0.166667          0.000000          0.000000   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          3.666667          0.114583          0.333333          0.010417   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1117_sms  feature_1118_sms  feature_1119_sms  feature_1120_sms  \\\n",
       "0          0.000000          0.000000          1.333333          0.035714   \n",
       "1          0.333333          0.006944          1.666667          0.034722   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.333333          0.010417          3.000000          0.093750   \n",
       "4          0.333333          0.037037          2.333333          0.259259   \n",
       "\n",
       "   feature_1121_sms  feature_1122_sms  feature_1123_sms  feature_1124_sms  \\\n",
       "0               0.0               0.0         10.000000          0.267857   \n",
       "1               0.0               0.0         11.333333          0.236111   \n",
       "2               0.0               0.0          0.000000          0.000000   \n",
       "3               0.0               0.0         13.333333          0.416667   \n",
       "4               0.0               0.0          1.666667          0.185185   \n",
       "\n",
       "   feature_1125_sms  feature_1126_sms  feature_1127_sms  feature_1128_sms  \\\n",
       "0               1.0          0.026786          4.666667          0.125000   \n",
       "1               0.0          0.000000          3.333333          0.069444   \n",
       "2               0.0          0.000000          0.000000          0.000000   \n",
       "3               0.0          0.000000          2.333333          0.072917   \n",
       "4               0.0          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1129_sms  feature_1130_sms  feature_1131_sms  feature_1132_sms  \\\n",
       "0          3.666667          0.098214          4.333333          0.116071   \n",
       "1          3.333333          0.069444          1.666667          0.034722   \n",
       "2          0.000000          0.000000          0.333333          1.000000   \n",
       "3          1.000000          0.031250          0.666667          0.020833   \n",
       "4          2.333333          0.259259          1.333333          0.148148   \n",
       "\n",
       "   feature_1133_sms  feature_1134_sms  feature_1135_sms  feature_1136_sms  \\\n",
       "0         30.142857         30.142857          0.070333          0.714286   \n",
       "1         55.714286         55.714286          0.490566          4.142857   \n",
       "2          0.142857          1.000000          1.000000          0.000000   \n",
       "3         33.285714         33.285714          0.077667          0.285714   \n",
       "4          5.857143          5.857143          0.359649          0.000000   \n",
       "\n",
       "   feature_1137_sms  feature_1138_sms  feature_1139_sms  feature_1140_sms  \\\n",
       "0          0.023697          0.285714          0.009479          9.428571   \n",
       "1          0.074359          1.000000          0.017949          9.142857   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.008584          0.428571          0.012876          6.285714   \n",
       "4          0.000000          0.285714          0.048780          0.000000   \n",
       "\n",
       "   feature_1141_sms  feature_1142_sms  feature_1143_sms  feature_1144_sms  \\\n",
       "0          0.312796          0.142857          0.004739          0.142857   \n",
       "1          0.164103          1.571429          0.028205          1.714286   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.188841          0.000000          0.000000          0.285714   \n",
       "4          0.000000          0.142857          0.024390          0.142857   \n",
       "\n",
       "   feature_1145_sms  feature_1146_sms  feature_1147_sms  feature_1148_sms  \\\n",
       "0          0.004739          0.857143          0.028436          0.000000   \n",
       "1          0.030769          9.000000          0.161538          0.285714   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.008584          2.571429          0.077253          0.142857   \n",
       "4          0.024390          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1149_sms  feature_1150_sms  feature_1151_sms  feature_1152_sms  \\\n",
       "0          0.000000          0.000000          0.000000          1.428571   \n",
       "1          0.005128          0.142857          0.002564          5.857143   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.004292          0.285714          0.008584          3.857143   \n",
       "4          0.000000          0.142857          0.024390          1.000000   \n",
       "\n",
       "   feature_1153_sms  feature_1154_sms  feature_1155_sms  feature_1156_sms  \\\n",
       "0          0.047393               0.0               0.0          8.571429   \n",
       "1          0.105128               0.0               0.0         12.428571   \n",
       "2          0.000000               0.0               0.0          0.000000   \n",
       "3          0.115880               0.0               0.0         12.000000   \n",
       "4          0.170732               0.0               0.0          0.714286   \n",
       "\n",
       "   feature_1157_sms  feature_1158_sms  feature_1159_sms  feature_1160_sms  \\\n",
       "0          0.284360          0.857143          0.028436          3.428571   \n",
       "1          0.223077          0.285714          0.005128          3.285714   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.360515          2.000000          0.060086          2.857143   \n",
       "4          0.121951          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1161_sms  feature_1162_sms  feature_1163_sms  feature_1164_sms  \\\n",
       "0          0.113744          2.142857          0.071090          2.142857   \n",
       "1          0.058974          4.000000          0.071795          2.857143   \n",
       "2          0.000000          0.000000          0.000000          0.142857   \n",
       "3          0.085837          1.142857          0.034335          1.142857   \n",
       "4          0.000000          2.428571          0.414634          1.000000   \n",
       "\n",
       "   feature_1165_sms  feature_1166_sms  feature_1167_sms  feature_1168_sms  \\\n",
       "0          0.071090         34.428571         34.428571          0.160667   \n",
       "1          0.051282         53.214286         53.214286          0.937107   \n",
       "2          1.000000          0.071429          1.000000          1.000000   \n",
       "3          0.034335         31.285714         31.285714          0.146000   \n",
       "4          0.170732          3.500000          3.769231          0.429825   \n",
       "\n",
       "   feature_1169_sms  feature_1170_sms  feature_1171_sms  feature_1172_sms  \\\n",
       "0          1.214286          0.035270          0.214286          0.006224   \n",
       "1          2.214286          0.041611          1.071429          0.020134   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.142857          0.004566          0.214286          0.006849   \n",
       "4          0.000000          0.000000          0.142857          0.040816   \n",
       "\n",
       "   feature_1173_sms  feature_1174_sms  feature_1175_sms  feature_1176_sms  \\\n",
       "0          9.071429          0.263485          0.071429          0.002075   \n",
       "1          7.714286          0.144966          1.285714          0.024161   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          7.357143          0.235160          0.000000          0.000000   \n",
       "4          0.071429          0.020408          0.071429          0.020408   \n",
       "\n",
       "   feature_1177_sms  feature_1178_sms  feature_1179_sms  feature_1180_sms  \\\n",
       "0          0.142857          0.004149          1.357143          0.039419   \n",
       "1          1.071429          0.020134          7.857143          0.147651   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.142857          0.004566          4.428571          0.141553   \n",
       "4          0.071429          0.020408          0.000000          0.000000   \n",
       "\n",
       "   feature_1181_sms  feature_1182_sms  feature_1183_sms  feature_1184_sms  \\\n",
       "0          0.000000          0.000000          0.000000          0.000000   \n",
       "1          0.142857          0.002685          0.071429          0.001342   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.071429          0.002283          0.214286          0.006849   \n",
       "4          0.000000          0.000000          0.071429          0.020408   \n",
       "\n",
       "   feature_1185_sms  feature_1186_sms  feature_1187_sms  feature_1188_sms  \\\n",
       "0          1.214286          0.035270               0.0               0.0   \n",
       "1          6.571429          0.123490               0.0               0.0   \n",
       "2          0.000000          0.000000               0.0               0.0   \n",
       "3          3.285714          0.105023               0.0               0.0   \n",
       "4          0.500000          0.142857               0.0               0.0   \n",
       "\n",
       "   feature_1189_sms  feature_1190_sms  feature_1191_sms  feature_1192_sms  \\\n",
       "0          9.785714          0.284232          0.857143          0.024896   \n",
       "1         13.000000          0.244295          0.214286          0.004027   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3         10.071429          0.321918          1.642857          0.052511   \n",
       "4          0.428571          0.122449          0.000000          0.000000   \n",
       "\n",
       "   feature_1193_sms  feature_1194_sms  feature_1195_sms  feature_1196_sms  \\\n",
       "0          4.928571          0.143154          3.214286          0.093361   \n",
       "1          3.785714          0.071141          4.714286          0.088591   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          2.214286          0.070776          0.642857          0.020548   \n",
       "4          0.000000          0.000000          1.357143          0.387755   \n",
       "\n",
       "   feature_1197_sms  feature_1198_sms  feature_1199_sms  feature_1200_sms  \\\n",
       "0          2.357143          0.068465         25.000000         35.000000   \n",
       "1          3.500000          0.065772         37.523810         49.250000   \n",
       "2          0.071429          1.000000          0.047619          1.000000   \n",
       "3          0.857143          0.027397         30.142857         30.142857   \n",
       "4          0.785714          0.224490          2.619048          3.437500   \n",
       "\n",
       "   feature_1201_sms  feature_1202_sms  feature_1203_sms  feature_1204_sms  \\\n",
       "0          0.175000          0.904762          0.036190          0.142857   \n",
       "1          0.991195          1.476190          0.039340          0.714286   \n",
       "2          1.000000          0.000000          0.000000          0.000000   \n",
       "3          0.211000          0.142857          0.004739          0.238095   \n",
       "4          0.482456          0.000000          0.000000          0.095238   \n",
       "\n",
       "   feature_1205_sms  feature_1206_sms  feature_1207_sms  feature_1208_sms  \\\n",
       "0          0.005714          6.523810          0.260952          0.047619   \n",
       "1          0.019036          5.380952          0.143401          0.857143   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.007899          8.000000          0.265403          0.000000   \n",
       "4          0.036364          0.047619          0.018182          0.047619   \n",
       "\n",
       "   feature_1209_sms  feature_1210_sms  feature_1211_sms  feature_1212_sms  \\\n",
       "0          0.001905          0.142857          0.005714          0.904762   \n",
       "1          0.022843          0.714286          0.019036          5.666667   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.000000          0.190476          0.006319          4.428571   \n",
       "4          0.018182          0.047619          0.018182          0.000000   \n",
       "\n",
       "   feature_1213_sms  feature_1214_sms  feature_1215_sms  feature_1216_sms  \\\n",
       "0          0.036190          0.000000          0.000000          0.000000   \n",
       "1          0.151015          0.095238          0.002538          0.047619   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.146919          0.047619          0.001580          0.238095   \n",
       "4          0.000000          0.000000          0.000000          0.047619   \n",
       "\n",
       "   feature_1217_sms  feature_1218_sms  feature_1219_sms  feature_1220_sms  \\\n",
       "0          0.000000          1.238095          0.049524               0.0   \n",
       "1          0.001269          4.714286          0.125635               0.0   \n",
       "2          0.000000          0.000000          0.000000               0.0   \n",
       "3          0.007899          2.761905          0.091627               0.0   \n",
       "4          0.018182          0.333333          0.127273               0.0   \n",
       "\n",
       "   feature_1221_sms  feature_1222_sms  feature_1223_sms  feature_1224_sms  \\\n",
       "0               0.0          7.285714          0.291429          0.619048   \n",
       "1               0.0          9.190476          0.244924          0.142857   \n",
       "2               0.0          0.000000          0.000000          0.000000   \n",
       "3               0.0          9.238095          0.306477          1.238095   \n",
       "4               0.0          0.285714          0.109091          0.000000   \n",
       "\n",
       "   feature_1225_sms  feature_1226_sms  feature_1227_sms  feature_1228_sms  \\\n",
       "0          0.024762          3.380952          0.135238          2.190476   \n",
       "1          0.003807          2.619048          0.069797          3.523810   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.041074          1.952381          0.064771          0.809524   \n",
       "4          0.000000          0.142857          0.054545          0.952381   \n",
       "\n",
       "   feature_1229_sms  feature_1230_sms  feature_1231_sms  feature_1232_sms  \\\n",
       "0          0.087619          1.619048          0.064762         24.566667   \n",
       "1          0.093909          2.380952          0.063452         26.266667   \n",
       "2          0.000000          0.047619          1.000000          0.033333   \n",
       "3          0.026856          0.857143          0.028436         29.766667   \n",
       "4          0.363636          0.619048          0.236364          2.966667   \n",
       "\n",
       "   feature_1233_sms  feature_1234_sms  feature_1235_sms  feature_1236_sms  \\\n",
       "0         35.095238          0.245667          0.700000          0.028494   \n",
       "1         49.250000          0.991195          1.033333          0.039340   \n",
       "2          1.000000          1.000000          0.000000          0.000000   \n",
       "3         29.766667          0.297667          0.100000          0.003359   \n",
       "4          3.869565          0.780702          0.000000          0.000000   \n",
       "\n",
       "   feature_1237_sms  feature_1238_sms  feature_1239_sms  feature_1240_sms  \\\n",
       "0          0.133333          0.005427          6.466667          0.263229   \n",
       "1          0.500000          0.019036          3.766667          0.143401   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.300000          0.010078          8.000000          0.268757   \n",
       "4          0.066667          0.022472          0.033333          0.011236   \n",
       "\n",
       "   feature_1241_sms  feature_1242_sms  feature_1243_sms  feature_1244_sms  \\\n",
       "0          0.033333          0.001357          0.166667          0.006784   \n",
       "1          0.600000          0.022843          0.500000          0.019036   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.000000          0.000000          0.666667          0.022396   \n",
       "4          0.033333          0.011236          0.033333          0.011236   \n",
       "\n",
       "   feature_1245_sms  feature_1246_sms  feature_1247_sms  feature_1248_sms  \\\n",
       "0          1.266667          0.051560          0.000000          0.000000   \n",
       "1          3.966667          0.151015          0.066667          0.002538   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          4.433333          0.148936          0.033333          0.001120   \n",
       "4          0.000000          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1249_sms  feature_1250_sms  feature_1251_sms  feature_1252_sms  \\\n",
       "0          0.000000          0.000000          1.333333          0.054274   \n",
       "1          0.033333          0.001269          3.300000          0.125635   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.300000          0.010078          2.500000          0.083987   \n",
       "4          0.066667          0.022472          0.266667          0.089888   \n",
       "\n",
       "   feature_1253_sms  feature_1254_sms  feature_1255_sms  feature_1256_sms  \\\n",
       "0               0.0               0.0          6.966667          0.283582   \n",
       "1               0.0               0.0          6.433333          0.244924   \n",
       "2               0.0               0.0          0.000000          0.000000   \n",
       "3               0.0               0.0          8.933333          0.300112   \n",
       "4               0.0               0.0          0.200000          0.067416   \n",
       "\n",
       "   feature_1257_sms  feature_1258_sms  feature_1259_sms  feature_1260_sms  \\\n",
       "0          0.500000          0.020353          3.366667          0.137042   \n",
       "1          0.100000          0.003807          1.833333          0.069797   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          1.033333          0.034714          1.833333          0.061590   \n",
       "4          0.000000          0.000000          0.200000          0.067416   \n",
       "\n",
       "   feature_1261_sms  feature_1262_sms  feature_1263_sms  feature_1264_sms  \\\n",
       "0          2.033333          0.082768          1.600000          0.065129   \n",
       "1          2.466667          0.093909          1.666667          0.063452   \n",
       "2          0.000000          0.000000          0.033333          1.000000   \n",
       "3          0.866667          0.029115          0.766667          0.025756   \n",
       "4          1.033333          0.348315          1.033333          0.348315   \n",
       "\n",
       "   feature_1265_sms  feature_1266_sms  feature_1267_sms  feature_1268_sms  \\\n",
       "0         31.266667         36.784314          0.625333          0.983333   \n",
       "1         13.166667         43.888889          0.993711          0.516667   \n",
       "2          0.016667          1.000000          1.000000          0.000000   \n",
       "3         26.083333         26.083333          0.521667          0.050000   \n",
       "4          1.816667          3.205882          0.956140          0.000000   \n",
       "\n",
       "   feature_1269_sms  feature_1270_sms  feature_1271_sms  feature_1272_sms  \\\n",
       "0          0.031450          0.116667          0.003731          7.416667   \n",
       "1          0.039241          0.250000          0.018987          1.900000   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.001917          0.300000          0.011502          8.250000   \n",
       "4          0.000000          0.033333          0.018349          0.016667   \n",
       "\n",
       "   feature_1273_sms  feature_1274_sms  feature_1275_sms  feature_1276_sms  \\\n",
       "0          0.237207          0.033333          0.001066          0.633333   \n",
       "1          0.144304          0.300000          0.022785          0.250000   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.316294          0.000000          0.000000          0.466667   \n",
       "4          0.009174          0.016667          0.009174          0.016667   \n",
       "\n",
       "   feature_1277_sms  feature_1278_sms  feature_1279_sms  feature_1280_sms  \\\n",
       "0          0.020256          1.566667          0.050107          0.000000   \n",
       "1          0.018987          1.983333          0.150633          0.033333   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.017891          3.716667          0.142492          0.016667   \n",
       "4          0.009174          0.000000          0.000000          0.000000   \n",
       "\n",
       "   feature_1281_sms  feature_1282_sms  feature_1283_sms  feature_1284_sms  \\\n",
       "0          0.000000          0.000000          0.000000          1.183333   \n",
       "1          0.002532          0.016667          0.001266          1.650000   \n",
       "2          0.000000          0.000000          0.000000          0.000000   \n",
       "3          0.000639          0.216667          0.008307          2.400000   \n",
       "4          0.000000          0.033333          0.018349          0.133333   \n",
       "\n",
       "   feature_1285_sms  feature_1286_sms  feature_1287_sms  feature_1288_sms  \\\n",
       "0          0.037846               0.0               0.0          9.016667   \n",
       "1          0.125316               0.0               0.0          3.233333   \n",
       "2          0.000000               0.0               0.0          0.000000   \n",
       "3          0.092013               0.0               0.0          7.016667   \n",
       "4          0.073394               0.0               0.0          0.100000   \n",
       "\n",
       "   feature_1289_sms  feature_1290_sms  feature_1291_sms  feature_1292_sms  \\\n",
       "0          0.288380              0.50          0.015991          5.366667   \n",
       "1          0.245570              0.05          0.003797          0.916667   \n",
       "2          0.000000              0.00          0.000000          0.000000   \n",
       "3          0.269010              0.80          0.030671          1.583333   \n",
       "4          0.055046              0.00          0.000000          0.166667   \n",
       "\n",
       "   feature_1293_sms  feature_1294_sms  feature_1295_sms  feature_1296_sms  \\\n",
       "0          0.171642          2.566667          0.082090          1.883333   \n",
       "1          0.069620          1.233333          0.093671          0.833333   \n",
       "2          0.000000          0.000000          0.000000          0.016667   \n",
       "3          0.060703          0.650000          0.024920          0.616667   \n",
       "4          0.091743          0.616667          0.339450          0.683333   \n",
       "\n",
       "   feature_1297_sms  feature_1298_sms  feature_1299_sms  feature_1300_sms  \\\n",
       "0          0.060235             3.000         34.883721               1.0   \n",
       "1          0.063291             0.795         34.565217               1.0   \n",
       "2          1.000000             0.001          1.000000               1.0   \n",
       "3          0.023642             3.000         20.000000               1.0   \n",
       "4          0.376147             0.114          3.081081               1.0   \n",
       "\n",
       "   feature_1301_sms  feature_1302_sms  feature_1303_sms  feature_1304_sms  \\\n",
       "0             0.143          0.047667             0.025          0.008333   \n",
       "1             0.031          0.038994             0.015          0.018868   \n",
       "2             0.000          0.000000             0.000          0.000000   \n",
       "3             0.006          0.002000             0.022          0.007333   \n",
       "4             0.000          0.000000             0.002          0.017544   \n",
       "\n",
       "   feature_1305_sms  feature_1306_sms  feature_1307_sms  feature_1308_sms  \\\n",
       "0             0.681          0.227000             0.010          0.003333   \n",
       "1             0.115          0.144654             0.018          0.022642   \n",
       "2             0.000          0.000000             0.000          0.000000   \n",
       "3             1.012          0.337333             0.000          0.000000   \n",
       "4             0.004          0.035088             0.001          0.008772   \n",
       "\n",
       "   feature_1309_sms  feature_1310_sms  feature_1311_sms  feature_1312_sms  \\\n",
       "0             0.058          0.019333             0.181          0.060333   \n",
       "1             0.016          0.020126             0.119          0.149686   \n",
       "2             0.000          0.000000             0.000          0.000000   \n",
       "3             0.099          0.033000             0.314          0.104667   \n",
       "4             0.001          0.008772             0.000          0.000000   \n",
       "\n",
       "   feature_1313_sms  feature_1314_sms  feature_1315_sms  feature_1316_sms  \\\n",
       "0             0.000          0.000000             0.001          0.000333   \n",
       "1             0.002          0.002516             0.001          0.001258   \n",
       "2             0.000          0.000000             0.000          0.000000   \n",
       "3             0.001          0.000333             0.016          0.005333   \n",
       "4             0.000          0.000000             0.002          0.017544   \n",
       "\n",
       "   feature_1317_sms  feature_1318_sms  feature_1319_sms  feature_1320_sms  \\\n",
       "0             0.090          0.030000             0.002          0.000667   \n",
       "1             0.099          0.124528             0.001          0.001258   \n",
       "2             0.000          0.000000             0.000          0.000000   \n",
       "3             0.264          0.088000             0.001          0.000333   \n",
       "4             0.009          0.078947             0.000          0.000000   \n",
       "\n",
       "   feature_1321_sms  feature_1322_sms  feature_1323_sms  feature_1324_sms  \\\n",
       "0             0.870          0.290000             0.038          0.012667   \n",
       "1             0.196          0.246541             0.003          0.003774   \n",
       "2             0.000          0.000000             0.000          0.000000   \n",
       "3             0.880          0.293333             0.065          0.021667   \n",
       "4             0.006          0.052632             0.001          0.008772   \n",
       "\n",
       "   feature_1325_sms  feature_1326_sms  feature_1327_sms  feature_1328_sms  \\\n",
       "0             0.527          0.175667             0.212          0.070667   \n",
       "1             0.055          0.069182             0.074          0.093082   \n",
       "2             0.000          0.000000             0.000          0.000000   \n",
       "3             0.195          0.065000             0.077          0.025667   \n",
       "4             0.010          0.087719             0.037          0.324561   \n",
       "\n",
       "   feature_1329_sms  feature_1330_sms  order_id         pan  label  \\\n",
       "0             0.162          0.054000  A5CFUD6W  BPZPK3933F    1.0   \n",
       "1             0.050          0.062893  OZFCFMGC  FRGPM5396K    1.0   \n",
       "2             0.001          1.000000  BIHEWFB9  BOTPT1160A    1.0   \n",
       "3             0.044          0.014667  MN6E2VSW  BUGPR1229F    1.0   \n",
       "4             0.041          0.359649  8KCEGVBW  IDMPS5726L    1.0   \n",
       "\n",
       "   label_pred  ift_socre  \n",
       "0         NaN   0.508873  \n",
       "1         NaN   0.609313  \n",
       "2         NaN   0.199260  \n",
       "3         NaN   0.254405  \n",
       "4         NaN   0.111287  \n",
       "\n",
       "[5 rows x 1803 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ift_socre'] = ift[:,1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "004a50fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./data/filter_feas_df_0403_n_old_itf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c73bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
