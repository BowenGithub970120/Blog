{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# https://zhuanlan.zhihu.com/p/113397045\n",
    "# https://gitee.com/tang_wan_qiang/GBDT_Simple_Tutorial\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# 对数据集的说明：\n",
    "# CRIM\tZN\tINDUS\tCHAS\tNOX\tRM\tAGE\tDIS\tRAD\tTAX\tPTRATIO\tB\tLSTAT\tMEDV\n",
    "# CRIM：城镇人均犯罪率。\n",
    "# ZN：住宅用地超过 25000 sq.ft. 的比例。\n",
    "# INDUS：城镇非零售商用土地的比例。\n",
    "# CHAS：查理斯河空变量（如果边界是河流，则为1；否则为0）。\n",
    "# NOX：一氧化氮浓度。\n",
    "# RM：住宅平均房间数。\n",
    "# AGE：1940 年之前建成的自用房屋比例。\n",
    "# DIS：到波士顿五个中心区域的加权距离。\n",
    "# RAD：辐射性公路的接近指数。\n",
    "# TAX：每 10000 美元的全值财产税率。\n",
    "# PTRATIO：城镇师生比例。\n",
    "# B：1000（Bk-0.63）^ 2，其中 Bk 指代城镇中黑人的比例。\n",
    "# LSTAT：人口中地位低下者的比例。\n",
    "# MEDV：自住房的平均房价，以千美元计。\n",
    "\n",
    "\n",
    "def loaddata(filename,rate=0.2):\n",
    "    data=pd.read_csv(filename).astype(np.float64)\n",
    "    data = shuffle(data)\n",
    "    # 你也可以设置种子保证结果的一致\n",
    "    # data = shuffle(data,random_state=666)\n",
    "\n",
    "    # 切分样本，作为训练集和测试集\n",
    "    \n",
    "    data=data.values\n",
    "    train_data=data[:int(len(data)*(1-rate)),:]\n",
    "    test_data=data[int(len(data)*(1-rate)):,:]\n",
    "    return train_data,test_data\n",
    "\n",
    "\n",
    "def findBestFeatureAndPoint(node):\n",
    "    '''\n",
    "    依据MSE准则，找到最佳切分特征和最佳切分点\n",
    "    :param node: 进行分裂的节点, 一个矩阵\n",
    "    :return: 切分特征与切分点\n",
    "    '''\n",
    "\n",
    "    # n为特征数\n",
    "    m,n=node.shape\n",
    "    # 因为最后一列是标签值\n",
    "    n=n-1\n",
    "    # 需要预测的真实值\n",
    "    y = node[:, -1]\n",
    "\n",
    "    # 用来保存最佳切分特征与切分点\n",
    "    # 以及左右子树\n",
    "    min_loss = np.Inf\n",
    "    best_feature = -1\n",
    "    best_point = -1\n",
    "    best_left=None\n",
    "    best_right=None\n",
    "\n",
    "\n",
    "\n",
    "    # 找到最佳切分特征与切分点\n",
    "    # 我们遍历所有特征，然后遍历该特征所有（或者部分）切分点\n",
    "    # 取决于该特征是离散还是连续变量\n",
    "    for feature in range(n):\n",
    "\n",
    "        # 获得进行切分列\n",
    "        # 因为是连续数据，有可能有很多不同的值\n",
    "        # 所以此处我们进行切分的时候，若是离散数据（默认种类小于等于10），我们进行精确切分\n",
    "        # 若类型大于10，认为是连续变量，进行10分位点切分\n",
    "        column=node[:,feature]\n",
    "        category=sorted(set(column))\n",
    "        if len(category)<=10:\n",
    "            split_point=category\n",
    "        else:\n",
    "            # 使用np.arrange来每次找到1/10数据点所在的索引\n",
    "            # 然后进行切分\n",
    "            split_point = np.arange(0, len(category), len(category) // 10)\n",
    "            split_point = [category[split_point[i]] for i in range(0, len(split_point))]\n",
    "\n",
    "\n",
    "\n",
    "        # 确定了所有切分点之后，对切分点进行遍历，找到最佳切分点\n",
    "        for point in split_point:\n",
    "            # 尝试切分\n",
    "            left=column[column<=point]\n",
    "            right=column[column>point]\n",
    "\n",
    "            # 左右两边的需要预测的真实值\n",
    "            y_left=y[column<=point]\n",
    "            y_right=y[column>point]\n",
    "            # 计算左右两边最佳的Cmj\n",
    "            # cart回归树损失函数为MSE\n",
    "            # 所以我们只需要取节点上的均值即可\n",
    "\n",
    "            c_left = np.average(y_left)\n",
    "            c_right = np.average(y_right)\n",
    "\n",
    "            loss=np.sum(np.square(y_left-c_left))+np.sum(np.square(y_right-c_right))\n",
    "            if loss<min_loss:\n",
    "                min_loss=loss\n",
    "                best_feature=feature\n",
    "                best_point=point\n",
    "                best_left=node[column<=point]\n",
    "                best_right=node[column>point]\n",
    "    return (best_feature,best_point,best_left,best_right)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def createCART(data,deep,max_deep=2):\n",
    "    '''\n",
    "    创建回归树，分裂准则MSE（最小均方误差）\n",
    "    :param deep: 树的当前深度\n",
    "    :param max_deep:  树的最大深度（从0开始），默认为2，即产生4个叶子节点\n",
    "    :param data: 训练样本，其中data中的最后一列值为上一轮训练之后的残差\n",
    "    :return: 一颗回归树\n",
    "    '''\n",
    "\n",
    "    # 树的结构例如\n",
    "    # tree={3:{'left':{4:{'left':23.1,'right':19.6},'point':0},'right':{6:{'left':23.1,'right':19.6},'point':4.5}},'point':10.4}\n",
    "    # 上面是一颗2层的回归树\n",
    "    # 3代表根节点以第三个特征进行分类，分裂的切分点是point=10.4\n",
    "    # 然后是左右子树left，right\n",
    "    # left也是一个字典，对应左子树\n",
    "    # 4代表左子树以特征四为分裂特征，切分点是point=0\n",
    "    # 分裂之后的left仍然是一个字典，其中有left和right对应着23.1,19.6\n",
    "    # 这两个值即为我们的预测值\n",
    "    # 右子树也同理\n",
    "\n",
    "    if deep<=max_deep:\n",
    "        feature,point,left,right=findBestFeatureAndPoint(data)\n",
    "        tree = {feature: {}}\n",
    "        if deep!=max_deep:\n",
    "            # 不是最后一层，继续生成树\n",
    "            tree['point']=point\n",
    "            if len(left)>=2:\n",
    "                # 必须要保证样本长度大于1，才能分裂\n",
    "                tree[feature]['left']=createCART(left,deep+1,max_deep)\n",
    "            else:\n",
    "                tree[feature]['left']=np.average(left)\n",
    "            if len(right)>=2:\n",
    "                tree[feature]['right']=createCART(right,deep+1,max_deep)\n",
    "            else:\n",
    "                tree[feature]['right']=np.average(right)\n",
    "\n",
    "        else:\n",
    "            # feature, point, left, right = findBestFeatureAndPoint(data)\n",
    "            # tree['point']=point\n",
    "            # # y标签在训练样本最后一列，用-1获取\n",
    "            # y_left=left[:,-1]\n",
    "            # y_right=right[:,-1]\n",
    "            # c_left = np.average(y_left)\n",
    "            # c_right = np.average(y_right)\n",
    "\n",
    "            # 最后一层树，保存叶节点的值\n",
    "            return np.average(data[:,-1])\n",
    "        return tree\n",
    "\n",
    "\n",
    "def gradientBoosting(rdd, data, alpha):\n",
    "    '''\n",
    "\n",
    "    :param rdd: 迭代论数，也就是树的个数\n",
    "    :param data: 训练集\n",
    "    :param alpha: 防止过拟合，每一棵树的正则化系数\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    tree_list=[]\n",
    "    # 第一步，初始化fx0，即找到使得损失函数最小的c\n",
    "    # 即所有样本点的均值\n",
    "    # -1 代表没有切分特征，所有值均预测为样本点均值\n",
    "    fx0={-1: np.average(data[:,-1])}\n",
    "\n",
    "    tree_list.append(fx0)\n",
    "    # 开始迭代训练，对每一轮的残差拟合回归树\n",
    "    for i in range(1,rdd):\n",
    "        # 更新样本值，rmi=yi-fmx\n",
    "        # TODO:没有想到更新残差较好的方式\n",
    "        #  目前想到的就是对每一个样本以当前的提升树进行一次预测\n",
    "        #  然后获得预测值与真实值进行相减，将样本真实值变为残差\n",
    "        #  如果你碰巧看到了，有好的想法，欢迎与我交流～\n",
    "        if i==1:\n",
    "            data[:,-1]=data[:,-1]-fx0[-1]\n",
    "        else:\n",
    "            for i in range(len(data)):\n",
    "                # 注意，这里穿的列表是tree_list中最后一个\n",
    "                # 因为我们只需要对残差进行拟合，data[:,-1]每一轮都进行了更新，所以我们只要减去上一颗提升树的预测结果就是残差了\n",
    "                data[i, -1] = data[i, -1] - predict_for_rm(data[i], tree_list[-1], alpha)\n",
    "        # 上面已经将样本值变为了残差，下面对残差拟合一颗回归树\n",
    "        fx = createCART(data, deep=0, max_deep=4)\n",
    "        # 将树添加到列表\n",
    "        tree_list.append(fx)\n",
    "    return tree_list\n",
    "\n",
    "\n",
    "def predict_for_rm(data, tree, alpha):\n",
    "    '''\n",
    "    获得前一轮 第m-1颗树 的预测值，从而获得残差\n",
    "    :param data: 一条样本\n",
    "    :param tree: 第 m-1 颗树\n",
    "    :param alpha: 正则化系数\n",
    "    :return:  第m-1颗树预测的值\n",
    "    '''\n",
    "\n",
    "    while True:\n",
    "        # 遍历该棵树，直到叶节点\n",
    "        # 叶节点与子树的区别在于一节点上的值为float\n",
    "        # 而子树是一个字典，有point键，用作切分点\n",
    "        # tree={3:{'left':{4:{'left':23.1,'right':19.6},'point':0},'right':{6:{'left':23.1,'right':19.6},'point':4.5}},'point':10.4}\n",
    "        #\n",
    "        if type(tree).__name__=='dict':\n",
    "            # 如果是字典，那么这是一颗子树,\n",
    "            point = tree['point']\n",
    "            # tree.keys()=dict_keys([3, 'point'])\n",
    "            # 所以int值对应的是特征，但是字典的键值是无序的，我们无法保证第一个是特征，所以用类型来判断\n",
    "            feature = list(tree.keys())[0] if type(list(tree.keys())[0]).__name__ == 'int' else list(tree.keys())[1]\n",
    "            if data[feature] <= point:\n",
    "                tree = tree[feature]['left']\n",
    "            else:\n",
    "                tree = tree[feature]['right']\n",
    "        else:\n",
    "            # 当tree中没有切分点point，证明这是一个叶节点，tree就是预测值，返回获得预测值\n",
    "            return alpha * tree\n",
    "\n",
    "\n",
    "def predict(data, tree_list, alpha):\n",
    "    '''\n",
    "    对一条样本进行预测\n",
    "    :param tree_list: 所有树的列表\n",
    "    :param data: 一条需要预测的样本点\n",
    "    :param alpha:正则化系数\n",
    "    :return: 预测值\n",
    "    '''\n",
    "    m=len(tree_list)\n",
    "    fmx=0\n",
    "    for i in range(m):\n",
    "        tree=tree_list[i]\n",
    "        if i==0:\n",
    "            #  fx0={-1:np.average(data[:,-1])}\n",
    "            # fx0是一个叶节点，只有一个预测值，树的深度为0\n",
    "            fmx+=tree[-1]\n",
    "        else:\n",
    "            while True:\n",
    "                # 遍历该棵树，直到叶节点\n",
    "                # 叶节点与子树的区别在于一节点上的值为float\n",
    "                # 而子树是一个字典，有point键，用作切分点\n",
    "                # tree={3:{'left':{4:{'left':23.1,'right':19.6},'point':0},'right':{6:{'left':23.1,'right':19.6},'point':4.5}},'point':10.4}\n",
    "                #\n",
    "                if type(tree).__name__=='dict':\n",
    "                    # 如果是字典，那么这是一颗子树,\n",
    "                    point=tree['point']\n",
    "                    # tree.keys()=dict_keys([3, 'point'])\n",
    "                    # 所以int值对应的是特征，但是字典的键值是无序的，我们无法保证第一个是特征，所以用类型来判断\n",
    "                    feature=list(tree.keys())[0] if type(list(tree.keys())[0]).__name__=='int' else list(tree.keys())[1]\n",
    "                    if data[feature]<=point:\n",
    "                        tree=tree[feature]['left']\n",
    "                    else:\n",
    "                        tree=tree[feature]['right']\n",
    "                else:\n",
    "                    # 当tree中没有切分点point，证明这是一个叶节点，tree就是预测值，返回获得预测值\n",
    "                    fmx+= alpha * tree\n",
    "                    break\n",
    "    return fmx\n",
    "\n",
    "\n",
    "def test(X_test, y_test, tree_list, alpha):\n",
    "    acc = 0  # 正确率\n",
    "    acc_num = 0  # 正确个数\n",
    "    y_predict=[]\n",
    "    for i in range(len(X_test)):\n",
    "        print('testing ***', i)\n",
    "        x = X_test[i]\n",
    "        y_pred =predict(x, tree_list, alpha)\n",
    "        y_predict.append(y_pred)\n",
    "        if y_pred/y_test[i]<1.25 and y_pred/y_test[i]>0.8:\n",
    "            acc_num += 1\n",
    "        print(f'testing {i}th data :y_pred={y_pred},y={y_test[i]}')\n",
    "        print('now_acc=', acc_num / (i + 1))\n",
    "    return y_predict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing *** 0\n",
      "testing 0th data :y_pred=22.439860254189096,y=22.6\n",
      "now_acc= 1.0\n",
      "testing *** 1\n",
      "testing 1th data :y_pred=17.838619597510853,y=15.2\n",
      "now_acc= 1.0\n",
      "testing *** 2\n",
      "testing 2th data :y_pred=18.264405187032047,y=19.9\n",
      "now_acc= 1.0\n",
      "testing *** 3\n",
      "testing 3th data :y_pred=35.44533036535232,y=50.0\n",
      "now_acc= 0.75\n",
      "testing *** 4\n",
      "testing 4th data :y_pred=24.02117542916527,y=26.7\n",
      "now_acc= 0.8\n",
      "testing *** 5\n",
      "testing 5th data :y_pred=29.229065195984408,y=34.9\n",
      "now_acc= 0.8333333333333334\n",
      "testing *** 6\n",
      "testing 6th data :y_pred=27.80711739541533,y=30.1\n",
      "now_acc= 0.8571428571428571\n",
      "testing *** 7\n",
      "testing 7th data :y_pred=20.567954385811806,y=19.6\n",
      "now_acc= 0.875\n",
      "testing *** 8\n",
      "testing 8th data :y_pred=20.406176967366456,y=26.4\n",
      "now_acc= 0.7777777777777778\n",
      "testing *** 9\n",
      "testing 9th data :y_pred=27.650323917692667,y=23.9\n",
      "now_acc= 0.8\n",
      "testing *** 10\n",
      "testing 10th data :y_pred=21.140553160666567,y=23.1\n",
      "now_acc= 0.8181818181818182\n",
      "testing *** 11\n",
      "testing 11th data :y_pred=32.54115828760869,y=42.8\n",
      "now_acc= 0.75\n",
      "testing *** 12\n",
      "testing 12th data :y_pred=25.67487973672256,y=26.2\n",
      "now_acc= 0.7692307692307693\n",
      "testing *** 13\n",
      "testing 13th data :y_pred=39.24132481280048,y=50.0\n",
      "now_acc= 0.7142857142857143\n",
      "testing *** 14\n",
      "testing 14th data :y_pred=21.140553160666567,y=21.2\n",
      "now_acc= 0.7333333333333333\n",
      "testing *** 15\n",
      "testing 15th data :y_pred=17.87734887410466,y=10.4\n",
      "now_acc= 0.6875\n",
      "testing *** 16\n",
      "testing 16th data :y_pred=15.876869182960462,y=13.8\n",
      "now_acc= 0.7058823529411765\n",
      "testing *** 17\n",
      "testing 17th data :y_pred=18.33399452970716,y=19.1\n",
      "now_acc= 0.7222222222222222\n",
      "testing *** 18\n",
      "testing 18th data :y_pred=27.1195851733723,y=20.0\n",
      "now_acc= 0.6842105263157895\n",
      "testing *** 19\n",
      "testing 19th data :y_pred=18.447282198048455,y=7.0\n",
      "now_acc= 0.65\n",
      "testing *** 20\n",
      "testing 20th data :y_pred=23.364829354424252,y=24.5\n",
      "now_acc= 0.6666666666666666\n",
      "testing *** 21\n",
      "testing 21th data :y_pred=27.80711739541533,y=30.5\n",
      "now_acc= 0.6818181818181818\n",
      "testing *** 22\n",
      "testing 22th data :y_pred=28.920990351826962,y=25.0\n",
      "now_acc= 0.6956521739130435\n",
      "testing *** 23\n",
      "testing 23th data :y_pred=20.839505521122717,y=23.0\n",
      "now_acc= 0.7083333333333334\n",
      "testing *** 24\n",
      "testing 24th data :y_pred=16.80661929557307,y=17.9\n",
      "now_acc= 0.72\n",
      "testing *** 25\n",
      "testing 25th data :y_pred=25.260597121055053,y=22.4\n",
      "now_acc= 0.7307692307692307\n",
      "testing *** 26\n",
      "testing 26th data :y_pred=14.038416206460598,y=8.8\n",
      "now_acc= 0.7037037037037037\n",
      "testing *** 27\n",
      "testing 27th data :y_pred=37.60103033579981,y=50.0\n",
      "now_acc= 0.6785714285714286\n",
      "testing *** 28\n",
      "testing 28th data :y_pred=23.03527127588779,y=23.7\n",
      "now_acc= 0.6896551724137931\n",
      "testing *** 29\n",
      "testing 29th data :y_pred=20.83657744589969,y=20.3\n",
      "now_acc= 0.7\n",
      "testing *** 30\n",
      "testing 30th data :y_pred=26.50332790388976,y=31.5\n",
      "now_acc= 0.7096774193548387\n",
      "testing *** 31\n",
      "testing 31th data :y_pred=17.076740014506246,y=17.2\n",
      "now_acc= 0.71875\n",
      "testing *** 32\n",
      "testing 32th data :y_pred=17.652710221558056,y=16.1\n",
      "now_acc= 0.7272727272727273\n",
      "testing *** 33\n",
      "testing 33th data :y_pred=25.67487973672256,y=24.8\n",
      "now_acc= 0.7352941176470589\n",
      "testing *** 34\n",
      "testing 34th data :y_pred=20.38204500985901,y=21.7\n",
      "now_acc= 0.7428571428571429\n",
      "testing *** 35\n",
      "testing 35th data :y_pred=24.65279724832346,y=23.1\n",
      "now_acc= 0.75\n",
      "testing *** 36\n",
      "testing 36th data :y_pred=19.002284582460256,y=19.4\n",
      "now_acc= 0.7567567567567568\n",
      "testing *** 37\n",
      "testing 37th data :y_pred=21.140553160666567,y=20.7\n",
      "now_acc= 0.7631578947368421\n",
      "testing *** 38\n",
      "testing 38th data :y_pred=17.555859238922757,y=17.8\n",
      "now_acc= 0.7692307692307693\n",
      "testing *** 39\n",
      "testing 39th data :y_pred=30.526540380691234,y=36.5\n",
      "now_acc= 0.775\n",
      "testing *** 40\n",
      "testing 40th data :y_pred=20.648673564536736,y=19.1\n",
      "now_acc= 0.7804878048780488\n",
      "testing *** 41\n",
      "testing 41th data :y_pred=23.03527127588779,y=21.2\n",
      "now_acc= 0.7857142857142857\n",
      "testing *** 42\n",
      "testing 42th data :y_pred=21.140553160666567,y=29.6\n",
      "now_acc= 0.7674418604651163\n",
      "testing *** 43\n",
      "testing 43th data :y_pred=23.03527127588779,y=25.0\n",
      "now_acc= 0.7727272727272727\n",
      "testing *** 44\n",
      "testing 44th data :y_pred=44.25450190008704,y=50.0\n",
      "now_acc= 0.7777777777777778\n",
      "testing *** 45\n",
      "testing 45th data :y_pred=17.32801742954742,y=16.3\n",
      "now_acc= 0.782608695652174\n",
      "testing *** 46\n",
      "testing 46th data :y_pred=39.908912009143336,y=50.0\n",
      "now_acc= 0.7659574468085106\n",
      "testing *** 47\n",
      "testing 47th data :y_pred=27.1195851733723,y=14.4\n",
      "now_acc= 0.75\n",
      "testing *** 48\n",
      "testing 48th data :y_pred=20.869002025355655,y=19.0\n",
      "now_acc= 0.7551020408163265\n",
      "testing *** 49\n",
      "testing 49th data :y_pred=28.064606533360173,y=37.0\n",
      "now_acc= 0.74\n",
      "testing *** 50\n",
      "testing 50th data :y_pred=14.038416206460598,y=7.4\n",
      "now_acc= 0.7254901960784313\n",
      "testing *** 51\n",
      "testing 51th data :y_pred=19.890300986717197,y=16.6\n",
      "now_acc= 0.7307692307692307\n",
      "testing *** 52\n",
      "testing 52th data :y_pred=25.67487973672256,y=23.9\n",
      "now_acc= 0.7358490566037735\n",
      "testing *** 53\n",
      "testing 53th data :y_pred=14.038416206460598,y=10.4\n",
      "now_acc= 0.7222222222222222\n",
      "testing *** 54\n",
      "testing 54th data :y_pred=18.61251386419182,y=15.0\n",
      "now_acc= 0.7272727272727273\n",
      "testing *** 55\n",
      "testing 55th data :y_pred=21.140553160666567,y=24.7\n",
      "now_acc= 0.7321428571428571\n",
      "testing *** 56\n",
      "testing 56th data :y_pred=20.567954385811806,y=19.2\n",
      "now_acc= 0.7368421052631579\n",
      "testing *** 57\n",
      "testing 57th data :y_pred=14.038416206460598,y=5.0\n",
      "now_acc= 0.7241379310344828\n",
      "testing *** 58\n",
      "testing 58th data :y_pred=23.03527127588779,y=22.1\n",
      "now_acc= 0.7288135593220338\n",
      "testing *** 59\n",
      "testing 59th data :y_pred=23.364829354424252,y=22.9\n",
      "now_acc= 0.7333333333333333\n",
      "testing *** 60\n",
      "testing 60th data :y_pred=30.687729710791015,y=33.3\n",
      "now_acc= 0.7377049180327869\n",
      "testing *** 61\n",
      "testing 61th data :y_pred=20.648673564536736,y=25.0\n",
      "now_acc= 0.7419354838709677\n",
      "testing *** 62\n",
      "testing 62th data :y_pred=14.038416206460598,y=5.6\n",
      "now_acc= 0.7301587301587301\n",
      "testing *** 63\n",
      "testing 63th data :y_pred=18.447282198048455,y=8.1\n",
      "now_acc= 0.71875\n",
      "testing *** 64\n",
      "testing 64th data :y_pred=20.723433613432768,y=17.5\n",
      "now_acc= 0.7230769230769231\n",
      "testing *** 65\n",
      "testing 65th data :y_pred=16.993928938520302,y=16.7\n",
      "now_acc= 0.7272727272727273\n",
      "testing *** 66\n",
      "testing 66th data :y_pred=19.430877923107428,y=27.9\n",
      "now_acc= 0.7164179104477612\n",
      "testing *** 67\n",
      "testing 67th data :y_pred=14.038416206460598,y=10.8\n",
      "now_acc= 0.7058823529411765\n",
      "testing *** 68\n",
      "testing 68th data :y_pred=23.03527127588779,y=23.0\n",
      "now_acc= 0.7101449275362319\n",
      "testing *** 69\n",
      "testing 69th data :y_pred=26.087387862036742,y=15.0\n",
      "now_acc= 0.7\n",
      "testing *** 70\n",
      "testing 70th data :y_pred=27.80711739541533,y=31.2\n",
      "now_acc= 0.704225352112676\n",
      "testing *** 71\n",
      "testing 71th data :y_pred=25.67487973672256,y=28.4\n",
      "now_acc= 0.7083333333333334\n",
      "testing *** 72\n",
      "testing 72th data :y_pred=19.843251235144937,y=18.4\n",
      "now_acc= 0.7123287671232876\n",
      "testing *** 73\n",
      "testing 73th data :y_pred=29.562589602459337,y=34.7\n",
      "now_acc= 0.7162162162162162\n",
      "testing *** 74\n",
      "testing 74th data :y_pred=14.038416206460598,y=13.4\n",
      "now_acc= 0.72\n",
      "testing *** 75\n",
      "testing 75th data :y_pred=23.364829354424252,y=22.6\n",
      "now_acc= 0.7236842105263158\n",
      "testing *** 76\n",
      "testing 76th data :y_pred=25.67487973672256,y=23.9\n",
      "now_acc= 0.7272727272727273\n",
      "testing *** 77\n",
      "testing 77th data :y_pred=20.869002025355655,y=21.7\n",
      "now_acc= 0.7307692307692307\n",
      "testing *** 78\n",
      "testing 78th data :y_pred=25.67487973672256,y=24.1\n",
      "now_acc= 0.7341772151898734\n",
      "testing *** 79\n",
      "testing 79th data :y_pred=28.768793910467483,y=22.8\n",
      "now_acc= 0.725\n",
      "testing *** 80\n",
      "testing 80th data :y_pred=39.24132481280048,y=43.5\n",
      "now_acc= 0.7283950617283951\n",
      "testing *** 81\n",
      "testing 81th data :y_pred=20.915652653780533,y=21.7\n",
      "now_acc= 0.7317073170731707\n",
      "testing *** 82\n",
      "testing 82th data :y_pred=25.67487973672256,y=22.0\n",
      "now_acc= 0.7349397590361446\n",
      "testing *** 83\n",
      "testing 83th data :y_pred=44.25450190008704,y=48.5\n",
      "now_acc= 0.7380952380952381\n",
      "testing *** 84\n",
      "testing 84th data :y_pred=25.67487973672256,y=23.8\n",
      "now_acc= 0.7411764705882353\n",
      "testing *** 85\n",
      "testing 85th data :y_pred=17.555859238922757,y=11.8\n",
      "now_acc= 0.7325581395348837\n",
      "testing *** 86\n",
      "testing 86th data :y_pred=16.883759201423647,y=13.1\n",
      "now_acc= 0.7241379310344828\n",
      "testing *** 87\n",
      "testing 87th data :y_pred=20.569948891221962,y=22.6\n",
      "now_acc= 0.7272727272727273\n",
      "testing *** 88\n",
      "testing 88th data :y_pred=26.50332790388976,y=29.8\n",
      "now_acc= 0.7303370786516854\n",
      "testing *** 89\n",
      "testing 89th data :y_pred=18.520791023186845,y=13.1\n",
      "now_acc= 0.7222222222222222\n",
      "testing *** 90\n",
      "testing 90th data :y_pred=17.54395263641731,y=19.0\n",
      "now_acc= 0.7252747252747253\n",
      "testing *** 91\n",
      "testing 91th data :y_pred=21.155409345661084,y=21.7\n",
      "now_acc= 0.7282608695652174\n",
      "testing *** 92\n",
      "testing 92th data :y_pred=25.10282186822809,y=16.5\n",
      "now_acc= 0.7204301075268817\n",
      "testing *** 93\n",
      "testing 93th data :y_pred=17.358043260464513,y=14.1\n",
      "now_acc= 0.723404255319149\n",
      "testing *** 94\n",
      "testing 94th data :y_pred=23.03527127588779,y=25.2\n",
      "now_acc= 0.7263157894736842\n",
      "testing *** 95\n",
      "testing 95th data :y_pred=42.61420742308638,y=46.0\n",
      "now_acc= 0.7291666666666666\n",
      "testing *** 96\n",
      "testing 96th data :y_pred=22.950546738756746,y=20.6\n",
      "now_acc= 0.7319587628865979\n",
      "testing *** 97\n",
      "testing 97th data :y_pred=17.58734218246968,y=13.6\n",
      "now_acc= 0.7244897959183674\n",
      "testing *** 98\n",
      "testing 98th data :y_pred=31.41243352324705,y=35.2\n",
      "now_acc= 0.7272727272727273\n",
      "testing *** 99\n",
      "testing 99th data :y_pred=20.567954385811806,y=17.1\n",
      "now_acc= 0.73\n",
      "testing *** 100\n",
      "testing 100th data :y_pred=23.03527127588779,y=24.1\n",
      "now_acc= 0.7326732673267327\n",
      "testing *** 101\n",
      "testing 101th data :y_pred=27.13543264027127,y=24.0\n",
      "now_acc= 0.7352941176470589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7582283402601001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data,test_data=loaddata('boston.csv')\n",
    "\n",
    "\n",
    "tree_list=gradientBoosting(10,train_data,0.12)\n",
    "\n",
    "X_test,y_test=test_data[:,:-1],test_data[:,-1]\n",
    "\n",
    "y_pred=test(X_test,y_test,tree_list,0.12)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
