{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n示例：\\'BBXPJ2333J\\'\\n\\nSMS_NSMS\\n\\nZX_NSMS\\n\\nSMS_ZX_NSMS\\n\\n\\n--\\n传入json_date\\n\\n返回 {\"msg\":\"\",\"result\":\"\",\"pred\":\"\"}\\n\\nmsg就是 调用结果 成功就success 失败写上失败的原因\\n\\nTommy\\n传入json_date\\n方法预设了一个默认阈值 ，比如是0.8，允许传入自定义的阈值，当返回的pred在大于等于阈值，那么 result=1 ，反之=0 result相当于模型给的label\\n\\npred就是概率\\n\\n如果msg是失败 ，那另外两个都是none\\n\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "示例：'BBXPJ2333J'\n",
    "\n",
    "SMS_NSMS\n",
    "\n",
    "ZX_NSMS\n",
    "\n",
    "SMS_ZX_NSMS\n",
    "\n",
    "\n",
    "--\n",
    "传入json_date\n",
    "\n",
    "返回 {\"msg\":\"\",\"result\":\"\",\"pred\":\"\"}\n",
    "\n",
    "msg就是 调用结果 成功就success 失败写上失败的原因\n",
    "\n",
    "\n",
    "传入json_date\n",
    "方法预设了一个默认阈值 ，比如是0.8，允许传入自定义的阈值，当返回的pred在大于等于阈值，那么 result=1 ，反之=0 result相当于模型给的label\n",
    "\n",
    "pred就是概率\n",
    "\n",
    "如果msg是失败 ，那另外两个都是none\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:108: RuntimeWarning: Mean of empty slice\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:108: RuntimeWarning: All-NaN axis encountered\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/lib/nanfunctions.py:1665: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:54: RuntimeWarning: All-NaN axis encountered\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'msg': '', 'result': 1, 'pred': 0.9113404483157409}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('./data/apisample.json', 'r') as file_obj:\n",
    "\n",
    "    json_data = json.load(file_obj)\n",
    "    \n",
    "predict(json_data , model='SMS_ZX_NSMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "division by zero\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-85-ec3bdc87527c>\", line 4, in <module>\n",
      "    1/0\n",
      "ZeroDivisionError: division by zero\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "try:\n",
    "    1/0\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "def predict(jsondata, model='SMS_ZX_NSMS'):\n",
    "    if len(jsondata)>0:\n",
    "        try:\n",
    "            df,response_error = json2fea(jsondata)\n",
    "            result,pred = fea2predict(df,model)\n",
    "            return {'msg':response_error,'result':result[0],'pred':pred[0]}\n",
    "        except Exception as e:\n",
    "            return  {'msg':'Predict Error：{}'.format(str(e)),'result':'','pred':''}\n",
    "    else:\n",
    "        return {'msg':'No json-data','result':'','pred':''}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:108: RuntimeWarning: Mean of empty slice\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:108: RuntimeWarning: All-NaN axis encountered\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/lib/nanfunctions.py:1665: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:54: RuntimeWarning: All-NaN axis encountered\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'msg': '', 'result': 1, 'pred': 0.9113404483157409}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_category_or_num(df, category_list, drop_list,model='tree'):\n",
    "    if model == 'nn':  # 神经网络的全数值型\n",
    "        for ft in set(df.columns)-set(drop_list):\n",
    "            df[ft] = pd.to_numeric(df[ft], errors='coerce').replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    else:\n",
    "        for ft in set(df.columns)-set(drop_list):\n",
    "            if ft in category_list:\n",
    "                df[ft] = df[ft].astype('category')\n",
    "            else:\n",
    "                df[ft] = pd.to_numeric(df[ft], errors='coerce')\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def fea2predict(df, model='SMS_ZX_NSMS'):\n",
    "    # 加载模型\n",
    "    \n",
    "    model = pd.read_pickle(MODEL_DICT[model])\n",
    "    feas = model.feature_name_\n",
    "    # 数值化\n",
    "    df[feas] = to_category_or_num(df[feas], [], [])\n",
    "    # 预测评分\n",
    "    pred = model.predict_proba(df[feas])[:,1]\n",
    "    result = (pred > Threhold).astype(int)\n",
    "    return result,pred\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### cofig\n",
    "\n",
    "MODEL_DICT={'SMS_ZX_NSMS':'./saved_models/SMS_ZX_NSMS.pkl',\n",
    "            'SMS_NSMS':'./saved_models/SMS_NSMS.pkl',\n",
    "            'ZX_NSMS':'./saved_models/ZX_NSMS.pkl'  \n",
    "               }\n",
    "\n",
    "Threhold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime as ddt\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import numba as nb\n",
    "\n",
    "def to_float_ornan(value):\n",
    "    \"\"\"数值转换\"\"\"\n",
    "    if not str(value).strip():return np.nan\n",
    "    try:\n",
    "        value = float(value)\n",
    "        if value % 1 == 0:\n",
    "            return int(value)\n",
    "        return value\n",
    "    except:\n",
    "        return  np.nan\n",
    "    \n",
    "\n",
    "def add_notna_set(seta, value):\n",
    "    \"\"\"非空计数\"\"\"\n",
    "    if str(value).strip():\n",
    "        seta.append(value)\n",
    "        \n",
    "    \n",
    "def diff_date(dt1, dt2):\n",
    "    \"\"\"日期间隔\"\"\"\n",
    "    try:\n",
    "        a = ddt.datetime.strptime(str(dt1),\"%Y%m%d\") \n",
    "        if len(dt2) >4:\n",
    "            b =  ddt.datetime.strptime(str(dt2),\"%Y%m%d\")\n",
    "        else:\n",
    "            b =  ddt.datetime.strptime(str(dt2),\"%Y\")\n",
    "    except:\n",
    "        return np.nan\n",
    "    return (a-b).days\n",
    "\n",
    "def get_muti_max(datas, key):\n",
    "    \"\"\"取多条记录求和或者最大值\"\"\"\n",
    "    temp_list = []\n",
    "    \n",
    "    for data in con_list(datas):\n",
    "        if key == 'Duecount' or key == 'Duesum':\n",
    "            temp_list.append(to_float_ornan(data['Days_Past_Due']))\n",
    "        else :\n",
    "            temp_list.append(to_float_ornan(data[key]))\n",
    "    if key == 'Duecount':\n",
    "        return len(temp_list)\n",
    "    elif key == 'Duesum':\n",
    "        return np.nansum(temp_list)\n",
    "    \n",
    "    return np.nanmax(temp_list)\n",
    "    \n",
    "def con_list(mult_datas): \n",
    "    if type(mult_datas) != list:\n",
    "        return [mult_datas] # 统一为列表形式\n",
    "    else:\n",
    "        return mult_datas\n",
    "\n",
    "# 函数库\n",
    "fun_dict = {\n",
    "    'count':len,\n",
    "    'sum':np.nansum,\n",
    "    'mean':np.nanmean,\n",
    "    'median':np.nanmedian,\n",
    "    'max':np.nanmax,\n",
    "    'min':np.nanmin,\n",
    "    'std':np.nanstd,\n",
    "    'nuniq':lambda x: len(set(x)),\n",
    "    'mode':lambda x:stats.mode(x, nan_policy='omit')[0][0],\n",
    "    'maxcount':lambda x:stats.mode(x, nan_policy='omit')[1][0]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def add_fea_grids(fea_dict, mult_datas, apply_dt='20200807', dt_key='Open_Date', calc_key=\"data['Amount_Past_Due']\",groupfun=['count','sum', 'median','mean','max','min','std'], dt_grids=[7, 30,60,360,9999]):\n",
    "    \"\"\"\n",
    "    滑动时间窗口 近N天 字段A的 计数、平均、求和\n",
    "    fea_dict最终特征存储的字典\n",
    "    mult_datas多条的记录值\n",
    "    calc_key 数据特征字段的相对位置 pd.eval @nb.jit()\n",
    "    \n",
    "    \"\"\"\n",
    "    new_fea = {} # 记录各时间窗口的原始特征\n",
    "    for _dt in dt_grids:\n",
    "        new_fea.setdefault(_dt, [])# 按时间窗口初始化\n",
    "    fea_suffix = calc_key.split(\"'\")[-2]  + str(len(calc_key))   # 前缀备注\n",
    "    if mult_datas:\n",
    "        mult_datas = con_list(mult_datas) \n",
    "        for data in mult_datas:\n",
    "            if len(data[dt_key]) >=4  and  data[dt_key] < apply_dt: #筛选申请日期前的记录,报告应该为准实时调用的\n",
    "                for _dt in dt_grids:\n",
    "                    if (_dt==9999) or (ddt.datetime.strptime(str(data[dt_key]),\"%Y%m%d\") >= (ddt.datetime.strptime(str(apply_dt),\"%Y%m%d\") + ddt.timedelta(days=-_dt))) :# 筛选为近N天的记录，为9999则不做筛选\n",
    "                        if \"Date\" in  calc_key or \"Year\" in   calc_key : #判断是否为日期型，日期直接计算为时间间隔\n",
    "                            fea_value = diff_date(apply_dt, eval(calc_key) )\n",
    "                        elif \"mean\" in groupfun: # 判断是否为数值型，直接提取到相应的时间窗\n",
    "                            fea_value = to_float_ornan(eval(calc_key))\n",
    "                        else:# 其他按字符型处理\n",
    "                            fea_value = eval(calc_key)\n",
    "                        new_fea[_dt].append(fea_value)  #  { 30: [2767.0, 0.0]}\n",
    "    for _k, data_list in new_fea.items(): # 生成具体特征\n",
    "        for fun in groupfun:\n",
    "            fea_name = fea_suffix+ '_'+ fun + '_' +str(_k)\n",
    "            fea_dict.setdefault(fea_name, [])\n",
    "            if len(data_list) > 0:\n",
    "                final_value = fun_dict[fun](data_list)\n",
    "            else :\n",
    "                final_value = np.nan\n",
    "            fea_dict[fea_name].append(final_value)\n",
    "        \n",
    "def calclen(alist):\n",
    "    \"\"\"一致率计算，最小为1.越大表示信息越一致 \"\"\"\n",
    "    return (len(alist)+0.001)/(len(set(alist))+0.001)\n",
    "\n",
    "def json2fea(jsondata):\n",
    "    zx_df,response_error = zxfea(jsondata)\n",
    "    sms_df = pd.DataFrame(json_data['sms'])\n",
    "    df = pd.concat([zx_df, sms_df],axis=1)\n",
    "    if len(df)==0:response_error += '|All data is empty!'\n",
    "    return df,response_error\n",
    "\n",
    "def zxfea(jsondata):\n",
    "    \"\"\"\n",
    "    json数据转换为特征\n",
    "    申请日期、申请额度、panid\n",
    "    \"\"\"\n",
    "    raw_fea = jsondata['zx'][\"INProfileResponse\"]  # ijson\n",
    "    if raw_fea.get('UserMessage',{}).get('UserMessageText','') != 'Normal Response' :  # 非正常报文\n",
    "        respone_error = raw_fea.get('UserMessage',{}).get('UserMessageText','')\n",
    "        return pd.DataFrame(),respone_error\n",
    "        \n",
    "    apply_dt= raw_fea[\"CreditProfileHeader\"].get('ReportDate','20201231')  #申请贷款日期=报告时间\n",
    "    apply_amt = float(100000)    ## \n",
    "    # 初始化\n",
    "    fea_dict = {}\n",
    "    for _fea in (['ID','apply_dt','apply_amt', 'report_timestamp','BureauScore', 'BureauScoreConfidLevel', 'MissingRate', 'Current_Enquiry_Reason', 'Current_Finance_Purpose', 'Current_Amount_Financed', \n",
    "              'Current_Duration_Of_Agreement', 'Current_Gender_Code', 'First_Name1', 'Len_Name', 'Name_nuniq', 'Tel_nuniq', 'Email_nuniq', 'Tel_type', \n",
    "              'IncomeTaxPAN_4', 'IncomeTaxPAN_5', 'Diff_datePassport', 'Diff_datePAN', 'Diff_dateDriver', 'IsPassport', 'IsDriver', 'Current_Income', \n",
    "              'IncomeApplyPor', 'Marital_Status', 'Employment_Status', 'Time_with_Employer', 'Number_of_Major_Credit_Card_Held', 'Len_of_addrs', \n",
    "              'City_nuniq', 'Country_Code', 'PinCode3', 'Current_State', 'Current_City', 'CreditAccountActive', 'CreditAccountClosed', \n",
    "              'CreditAccountDefault', 'CreditAccountTotal', 'CADSuitFiledCurrentBalance', 'CreditAccountActivePor', 'CADSuitFiledCurrentBalancePer', \n",
    "              'Outstanding_Balance_Secured', 'Outstanding_Balance_UnSecured_Percentage', 'Outstanding_Balance_All', 'Outstanding_Balance_Secured_Percentage', \n",
    "              'Outstanding_Balance_UnSecured','Outstanding_Balance_All_CADSuitPor','Diff_dateBirth','State_nuniq','Birth_nuniq','TotalCAPSLast90Days',\n",
    "              'TotalCAPSLast7Days','TotalCAPSLast30Days','TotalCAPSLast180Days','CAPSLast30Days', 'CAPSLast7Days', 'CAPSLast180Days', 'CAPSLast90Days',\n",
    "              'NonCreditCAPSLast30Days', 'NonCreditCAPSLast180Days', 'NonCreditCAPSLast90Days', 'NonCreditCAPSLast7Days','Pin_nuniq','Pan_nuniq','Account_nuniq','Ident_nuniq',\n",
    "              'Name_nuniq2','Tel_nuniq2','Email_nuniq2','Pan_nuniq2','Account_nuniq2','Ident_nuniq2','Gender_nuniq']):\n",
    "        fea_dict.setdefault(_fea,[])\n",
    "    State_nuniq=[]\n",
    "    Birth_nuniq=[]\n",
    "    City_nuniq=[]\n",
    "    Email_nuniq=[]\n",
    "    Tel_nuniq=[]\n",
    "    Name_nuniq=[]\n",
    "    Pin_nuniq=[]\n",
    "    Pan_nuniq=[]\n",
    "    Account_nuniq=[]\n",
    "    Ident_nuniq=[]\n",
    "    Gender_nuniq=[]\n",
    "    fea_dict['report_timestamp'].append(raw_fea[\"CreditProfileHeader\"].get('ReportDate','') +  raw_fea[\"CreditProfileHeader\"].get('ReportTime',''))\n",
    "    fea_dict['ID'].append('') # pan卡ID\n",
    "    fea_dict['apply_dt'].append(apply_dt) \n",
    "    fea_dict['apply_amt'].append(apply_amt)\n",
    "\n",
    "\n",
    "    # score类特征           \n",
    "    fea_dict['BureauScore'].append(to_float_ornan(raw_fea['SCORE'].get( 'BureauScore', np.nan))) \n",
    "    fea_dict['BureauScoreConfidLevel'].append(raw_fea['SCORE'].get( 'BureauScoreConfidLevel', ''))\n",
    "    miss_rate = str(raw_fea).count(\"''\")/ str(raw_fea).count(\":\") # 报告缺失率\n",
    "    fea_dict['MissingRate'].append(miss_rate)\n",
    "\n",
    "\n",
    "    # Current_Application类特征 \n",
    "    fea_dict['IncomeTaxPAN_4'].append('')\n",
    "    fea_dict['IncomeTaxPAN_5'].append('')\n",
    "    all_nm = '' # 名字信息-拼接\n",
    "    for nm in ['First_Name',\"Middle_Name1\",\"Middle_Name2\",\"Middle_Name3\",'Last_Name']:\n",
    "        if raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get(nm , '').strip():\n",
    "            all_nm += raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get(nm , '').strip() + ' '\n",
    "    fea_dict['Len_Name'].append(len(all_nm)) # 名字长度\n",
    "    fea_dict['First_Name1'].append(all_nm[0])\n",
    "    add_notna_set(Name_nuniq, all_nm.lower().strip())\n",
    "    add_notna_set(Tel_nuniq, raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get( 'Telephone_Number_Applicant_1st' , ''))\n",
    "    add_notna_set(Tel_nuniq, raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get('MobilePhoneNumber',''))\n",
    "    add_notna_set(Email_nuniq, raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get('EMailId','').lower().strip())\n",
    "    fea_dict['Current_Enquiry_Reason'].append(raw_fea['Current_Application']['Current_Application_Details'].get('Enquiry_Reason','')) # 同类型特征待优化为for遍历\n",
    "    fea_dict['Current_Finance_Purpose'].append(raw_fea['Current_Application']['Current_Application_Details'].get('Finance_Purpose',''))\n",
    "    fea_dict['Current_Amount_Financed'].append(to_float_ornan(raw_fea['Current_Application']['Current_Application_Details'].get('Amount_Financed','')))\n",
    "    fea_dict['Current_Duration_Of_Agreement'].append(to_float_ornan(raw_fea['Current_Application']['Current_Application_Details'].get('Duration_Of_Agreement' , '')))\n",
    "    fea_dict['Current_Gender_Code'].append(raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get('Gender_Code' , ''))\n",
    "    add_notna_set(Gender_nuniq, raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get('Gender_Code' , ''))\n",
    "    fea_dict['Tel_type'].append(raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get('Telephone_Type', ''))\n",
    "    fea_dict['IsPassport'].append(int(bool(raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get('Passport_Number' , ''))))\n",
    "    fea_dict['IsDriver'].append(int(bool(raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get('Driver_License_Number' , ''))))\n",
    "    add_notna_set(Birth_nuniq, raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get('Date_Of_Birth_Applicant' , ''))\n",
    "    fea_dict['Diff_dateBirth'].append( diff_date(apply_dt,raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get('Date_Of_Birth_Applicant' , '')))\n",
    "    fea_dict['Diff_datePAN'].append( diff_date(apply_dt,raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get('PAN_Issue_Date' , '')))\n",
    "    fea_dict['Diff_datePassport'].append( diff_date(apply_dt,raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get('Passport_Issue_Date' , '')))\n",
    "    fea_dict['Diff_dateDriver'].append( diff_date(apply_dt,raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Details'].get('Driver_License_Issue_Date' , '')))\n",
    "    fea_dict['Current_Income'].append(to_float_ornan(raw_fea['Current_Application']['Current_Application_Details']['Current_Other_Details'].get('Income' , '')))\n",
    "    fea_dict['IncomeApplyPor'].append(to_float_ornan(raw_fea['Current_Application']['Current_Application_Details']['Current_Other_Details'].get('Income' , ''))/apply_amt)\n",
    "    fea_dict['Time_with_Employer'].append(to_float_ornan(raw_fea['Current_Application']['Current_Application_Details']['Current_Other_Details'].get('Time_with_Employer' , '')))\n",
    "    fea_dict['Number_of_Major_Credit_Card_Held'].append(to_float_ornan(raw_fea['Current_Application']['Current_Application_Details']['Current_Other_Details'].get('Number_of_Major_Credit_Card_Held' , '')))\n",
    "    fea_dict['Marital_Status'].append(raw_fea['Current_Application']['Current_Application_Details']['Current_Other_Details'].get('Marital_Status',''))\n",
    "    fea_dict['Employment_Status'].append(raw_fea['Current_Application']['Current_Application_Details']['Current_Other_Details'].get('Employment_Status',''))\n",
    "    all_addr = ''  # Current_Application地址信息特征\n",
    "    for _addr in ['Country_Code', 'State', 'City', 'BldgNoSocietyName', 'RoadNoNameAreaLocality', 'FlatNoPlotNoHouseNo', 'Landmark']:\n",
    "        all_addr += raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Address_Details'].get(_addr , '')\n",
    "    fea_dict['Len_of_addrs'].append(len(all_addr))\n",
    "    add_notna_set(City_nuniq, raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Address_Details'].get('City',''))\n",
    "    add_notna_set(State_nuniq, raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Address_Details'].get('State',''))\n",
    "    add_notna_set(Pin_nuniq, raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Address_Details'].get('PINCode',''))\n",
    "    fea_dict['Country_Code'].append(raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Address_Details'].get('Country_Code',''))\n",
    "    fea_dict['PinCode3'].append(raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Address_Details'].get('PINCode','')[:3])\n",
    "    fea_dict['Current_State'].append(raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Address_Details'].get('State',''))\n",
    "    fea_dict['Current_City'].append(raw_fea['Current_Application']['Current_Application_Details']['Current_Applicant_Address_Details'].get('City',''))\n",
    "\n",
    "    #  CAIS_Account 类特征\n",
    "    fea_dict['CreditAccountActive'].append(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Credit_Account'].get('CreditAccountActive','')))\n",
    "    fea_dict['CreditAccountClosed'].append(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Credit_Account'].get('CreditAccountClosed','')))\n",
    "    fea_dict['CreditAccountDefault'].append(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Credit_Account'].get('CreditAccountDefault','')))\n",
    "    fea_dict['CreditAccountTotal'].append(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Credit_Account'].get('CreditAccountTotal','')))\n",
    "    fea_dict['CADSuitFiledCurrentBalance'].append(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Credit_Account'].get('CADSuitFiledCurrentBalance','')))\n",
    "    fea_dict['CreditAccountActivePor'].append(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Credit_Account'].get('CreditAccountActive',''))/(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Credit_Account'].get('CreditAccountTotal',''))+0.001))\n",
    "    fea_dict['CADSuitFiledCurrentBalancePer'].append(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Credit_Account'].get('CADSuitFiledCurrentBalance',''))/(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Credit_Account'].get('CreditAccountActive',''))+0.001))\n",
    "    fea_dict['Outstanding_Balance_Secured'].append(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Total_Outstanding_Balance'].get('Outstanding_Balance_Secured','')))\n",
    "    fea_dict['Outstanding_Balance_UnSecured_Percentage'].append(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Total_Outstanding_Balance'].get('Outstanding_Balance_UnSecured_Percentage')))\n",
    "    fea_dict['Outstanding_Balance_All'].append(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Total_Outstanding_Balance'].get('Outstanding_Balance_All','')))\n",
    "    fea_dict['Outstanding_Balance_Secured_Percentage'].append(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Total_Outstanding_Balance'].get('Outstanding_Balance_Secured_Percentage','')))\n",
    "    fea_dict['Outstanding_Balance_UnSecured'].append(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Total_Outstanding_Balance'].get('Outstanding_Balance_UnSecured','')))\n",
    "    fea_dict['Outstanding_Balance_All_CADSuitPor'].append(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Credit_Account'].get('CADSuitFiledCurrentBalance',''))/(to_float_ornan(raw_fea['CAIS_Account']['CAIS_Summary']['Total_Outstanding_Balance'].get('Outstanding_Balance_All',''))+0.001))\n",
    "\n",
    "    #   CAIS_Account_DETAILS 账户的多条记录特征\n",
    "    for cais_fea in ['Amount_Past_Due','Highest_Credit_or_Original_Loan_Amount','Terms_Duration','Terms_Frequency','Scheduled_Monthly_Payment_Amount',\n",
    "                    'Payment_Rating','Current_Balance','Original_Charge_off_Amount','Value_of_Credits_Last_Month','Settlement_Amount',\n",
    "                    'Value_of_Collateral','Written_Off_Amt_Total','Written_Off_Amt_Principal','Rate_of_Interest','Repayment_Tenure','Income']:  # 数值型特征\n",
    "        if cais_fea == 'Income':\n",
    "            groupfun = ['count','sum', 'median','mean','max','min','std']\n",
    "        else:\n",
    "            groupfun = ['sum','mean','max','min','std']\n",
    "        add_fea_grids(fea_dict, raw_fea['CAIS_Account'].get('CAIS_Account_DETAILS',  []), apply_dt=apply_dt, dt_key='Open_Date', calc_key=\"data.get('%s', np.nan)\"%cais_fea, groupfun=groupfun, dt_grids=[7, 30,90,360,9999])     \n",
    "    for cais_fea in ['Open_Date','Portfolio_Type','Account_Type','Type_of_Collateral','Promotional_Rate_Flag','Occupation_Code',\n",
    "                    'Income_Indicator','Income_Frequency_Indicator','CurrencyCode','AccountHoldertypeCode','Payment_History_Profile','Subscriber_comments','Consumer_comments',\n",
    "                    'Date_Closed',\"Date_of_Last_Payment\",\"Date_Reported\",'DefaultStatusDate','LitigationStatusDate','WriteOffStatusDate','DateOfAddition','Account_Status']:  # 类别型特征\n",
    "        if \"Date\" in cais_fea or cais_fea==\"Year\" : # 日期型\n",
    "            groupfun = ['max','min','mean','mode','nuniq','maxcount']\n",
    "        else:\n",
    "            groupfun = ['mode','nuniq']\n",
    "        add_fea_grids(fea_dict, raw_fea['CAIS_Account'].get('CAIS_Account_DETAILS',  []), apply_dt=apply_dt, dt_key='Open_Date', calc_key=\"data.get('%s', np.nan)\"%cais_fea, groupfun=groupfun, dt_grids=[7, 30,90,360,9999])     \n",
    "    for cais_fea in ['Year','Month','Days_Past_Due','Duecount','Duesum']:# CAIS_Account_History 数值及日期\n",
    "        if \"Date\" in cais_fea or cais_fea==\"Year\" :  \n",
    "            groupfun = ['max','min','mean','mode','nuniq','maxcount']\n",
    "        else:\n",
    "            groupfun = ['sum','mean','max','min','std']\n",
    "        add_fea_grids(fea_dict, raw_fea['CAIS_Account'].get('CAIS_Account_DETAILS',  []), apply_dt=apply_dt, dt_key='Open_Date', calc_key=\"get_muti_max(data['CAIS_Account_History'],'%s')\"%cais_fea, groupfun=groupfun, dt_grids=[7, 30,90,360,9999]) # get_muti_max：子记录再取max    \n",
    "    for data in con_list(raw_fea['CAIS_Account'].get('CAIS_Account_DETAILS',  [])):  # 名字等资料非重复计数\n",
    "        add_notna_set(Account_nuniq, data.get(\"Account_Number\",''))\n",
    "        add_notna_set(Ident_nuniq, data.get(\"Identification_Number\",''))\n",
    "        for _data in con_list(data.get('CAIS_Holder_Details',[]) ):\n",
    "            add_notna_set(Pan_nuniq, _data.get('Income_TAX_PAN',''))\n",
    "            add_notna_set(Gender_nuniq, _data.get('Gender_Code',''))\n",
    "            add_notna_set(Name_nuniq, _data.get('Surname_Non_Normalized','').lower())  \n",
    "            add_notna_set(Birth_nuniq, _data.get('Date_of_birth',''))     \n",
    "        for _data in con_list(data.get('CAIS_Holder_Address_Details',[])):\n",
    "            add_notna_set(City_nuniq, _data.get('City_non_normalized',''))\n",
    "            add_notna_set(State_nuniq, _data.get('State_non_normalized',''))\n",
    "            add_notna_set(Pin_nuniq, _data.get('ZIP_Postal_Code_non_normalized',''))       \n",
    "        for _data in con_list(data.get('CAIS_Holder_ID_Details', [])):\n",
    "            add_notna_set(Email_nuniq,_data.get('EMailId','').lower().strip())\n",
    "            add_notna_set(Pan_nuniq,_data.get('Income_TAX_PAN',''))\n",
    "        for _data in con_list(data.get('CAIS_Holder_Phone_Details',[])):\n",
    "            add_notna_set(Email_nuniq,_data.get('EMailId','').lower().strip())\n",
    "            add_notna_set(Tel_nuniq,_data.get('Telephone_Number',''))\n",
    "\n",
    "    # CAPS\n",
    "    for key in ['TotalCAPSLast90Days','TotalCAPSLast7Days','TotalCAPSLast30Days','TotalCAPSLast180Days']:   # TotalCAPS_Summary\n",
    "        fea_dict[key].append(to_float_ornan(raw_fea['TotalCAPS_Summary'].get(key, '')))\n",
    "\n",
    "    # CAPS_Application_Details  申请贷款的多条记录特征\n",
    "    for caps_fea in [\"Amount_Financed\",\"Duration_Of_Agreement\"]: # 数值型\n",
    "        if caps_fea == 'Amount_Financed':  \n",
    "            groupfun = ['count','sum', 'median','mean','max','min','std']\n",
    "        else:\n",
    "            groupfun = ['sum','mean','max','min','std']\n",
    "        add_fea_grids(fea_dict, raw_fea['CAPS'].get('CAPS_Application_Details', []), apply_dt=apply_dt, dt_key=\"Date_of_Request\", calc_key=\"data.get('%s', np.nan)\"%caps_fea, groupfun=groupfun, dt_grids=[7, 30,90,360,9999])            \n",
    "    for caps_fea in [\"Date_of_Request\",\"Enquiry_Reason\",\"Finance_Purpose\"]: # 类别型\n",
    "        if \"Date\" in cais_fea or cais_fea==\"Year\" : # 日期型\n",
    "            groupfun = ['max','min','mean','mode','nuniq','maxcount']\n",
    "        else:\n",
    "            groupfun = ['mode','nuniq']\n",
    "        add_fea_grids(fea_dict, raw_fea['CAPS'].get('CAPS_Application_Details', []), apply_dt=apply_dt, dt_key=\"Date_of_Request\", calc_key=\"data.get('%s', np.nan)\"%caps_fea, groupfun=groupfun, dt_grids=[7, 30,90,360,9999])  \n",
    "    for caps_fea in [\"Time_with_Employer\",\"Number_of_Major_Credit_Card_Held\",\"Income\"]: # ['CAPS_Other_Details'] 数值型\n",
    "        if caps_fea == '':  \n",
    "            groupfun = ['count','sum', 'median','mean','max','min','std']\n",
    "        else:\n",
    "            groupfun = ['sum','mean','max','min','std']\n",
    "        add_fea_grids(fea_dict, raw_fea['CAPS'].get('CAPS_Application_Details', []), apply_dt=apply_dt, dt_key=\"Date_of_Request\", calc_key=\"data['CAPS_Other_Details']['%s']\"%caps_fea, groupfun=groupfun, dt_grids=[7, 30,90,360,9999])            \n",
    "    for caps_fea in [\"Employment_Status\",\"Marital_Status\"]: #  ['CAPS_Other_Details'] 类别型\n",
    "        if \"Date\" in cais_fea or cais_fea==\"Year\" : # 日期型\n",
    "            groupfun = ['max','min','mean','mode','nuniq','maxcount']\n",
    "        else:\n",
    "            groupfun = ['mode','nuniq']\n",
    "        add_fea_grids(fea_dict, raw_fea['CAPS'].get('CAPS_Application_Details', []), apply_dt=apply_dt, dt_key=\"Date_of_Request\", calc_key=\"data['CAPS_Other_Details']['%s']\"%caps_fea, groupfun=groupfun, dt_grids=[7, 30,90,360,9999])  \n",
    "    for caps_fea in ['CAPSLast30Days', 'CAPSLast7Days', 'CAPSLast180Days', 'CAPSLast90Days']: # ['CAPS_Summary']\n",
    "        fea_dict[caps_fea].append(to_float_ornan(raw_fea['CAPS']['CAPS_Summary'].get(caps_fea,'')))\n",
    "    for caps_fea in ['NonCreditCAPSLast30Days', 'NonCreditCAPSLast180Days', 'NonCreditCAPSLast90Days', 'NonCreditCAPSLast7Days']:  # 'NonCreditCAPS_Summary'\n",
    "        fea_dict[caps_fea].append(to_float_ornan(raw_fea[\"NonCreditCAPS\"]['NonCreditCAPS_Summary'].get(caps_fea,'')))\n",
    "    # 名字等资料非重复计数\n",
    "    for  data in con_list(raw_fea['CAPS'].get('CAPS_Application_Details', [])):\n",
    "        add_notna_set(Tel_nuniq, data[\"CAPS_Applicant_Details\"].get('MobilePhoneNumber',''))\n",
    "        add_notna_set(Tel_nuniq, data[\"CAPS_Applicant_Details\"].get('Telephone_Number_Applicant_1st',''))\n",
    "        add_notna_set(Birth_nuniq, data[\"CAPS_Applicant_Details\"].get('Date_Of_Birth_Applicant' , ''))\n",
    "        add_notna_set(Email_nuniq, data[\"CAPS_Applicant_Details\"].get('EMailId','').lower().strip())\n",
    "        add_notna_set(Pan_nuniq, data[\"CAPS_Applicant_Details\"].get('IncomeTaxPan',''))\n",
    "        add_notna_set(Gender_nuniq, data[\"CAPS_Applicant_Details\"].get(\"Gender_Code\",''))\n",
    "\n",
    "        all_nm = '' # 名字信息-拼接\n",
    "        for nm in ['First_Name',\"Middle_Name1\",\"Middle_Name2\",\"Middle_Name3\",'Last_Name']:\n",
    "            if data[\"CAPS_Applicant_Details\"].get(nm,'').strip():\n",
    "                all_nm += data[\"CAPS_Applicant_Details\"].get(nm,'').strip() + ' '\n",
    "        add_notna_set(Name_nuniq, all_nm.lower().strip())\n",
    "        add_notna_set(State_nuniq, data[\"CAPS_Applicant_Address_Details\"].get('State',''))\n",
    "        add_notna_set(City_nuniq, data[\"CAPS_Applicant_Address_Details\"].get('City',''))\n",
    "        add_notna_set(Pin_nuniq, data[\"CAPS_Applicant_Address_Details\"].get('PINCode',''))\n",
    "    fea_dict['Name_nuniq'].append(calclen(Name_nuniq)) # 计算信息一致率\n",
    "    fea_dict['Tel_nuniq'].append(calclen(Tel_nuniq))\n",
    "    fea_dict['Gender_nuniq'].append(calclen(Gender_nuniq))\n",
    "    fea_dict['Email_nuniq'].append(calclen(Email_nuniq)) \n",
    "    fea_dict['City_nuniq'].append(calclen(City_nuniq))\n",
    "    fea_dict['Birth_nuniq'].append(calclen(Birth_nuniq))\n",
    "    fea_dict['State_nuniq'].append(calclen(State_nuniq))\n",
    "    fea_dict['Pin_nuniq'].append(calclen(Pin_nuniq))\n",
    "    fea_dict['Pan_nuniq'].append(calclen(Pan_nuniq))\n",
    "    fea_dict['Account_nuniq'].append(calclen(Account_nuniq))\n",
    "    fea_dict['Ident_nuniq'].append(calclen(Ident_nuniq))\n",
    "    fea_dict['Name_nuniq2'].append(set(Name_nuniq)) # 信息汇总\n",
    "    fea_dict['Tel_nuniq2'].append(set(Tel_nuniq)) \n",
    "    fea_dict['Email_nuniq2'].append(set(Email_nuniq)) \n",
    "    fea_dict['Pan_nuniq2'].append(set(Pan_nuniq))\n",
    "    fea_dict['Account_nuniq2'].append(set(Account_nuniq))\n",
    "    fea_dict['Ident_nuniq2'].append(set(Ident_nuniq))\n",
    "    df = pd.DataFrame(fea_dict)\n",
    "    #清洗 数据异常值、空格、缺失值处理\n",
    "    df = df.replace('',np.nan)\n",
    "    # 部分长度字符特征预处理\n",
    "    len_feas = [col for col in df.columns if ('comments' in col.lower() or 'profile' in col.lower() ) and 'mode' in col.lower() or 'nuniq2' in col.lower()]\n",
    "    df[len_feas] = df[len_feas].fillna('').applymap(lambda x: len(str(x)))\n",
    "    # 交互特征加工\n",
    "    df['Scheduled_income_diff'] = df.Scheduled_Monthly_Payment_Amount52_mean_9999 - df.Income26_mean_9999\n",
    "    df['Current_Balance_apply_por'] = df['Current_Balance35_mean_9999'] / df.apply_amt\n",
    "    df['Current_Balance_apply_diff'] = df['Current_Balance35_mean_9999'] - df.apply_amt\n",
    "    df['Current_Balance_Income_por'] = df['Current_Balance35_mean_9999'] / df.Income26_mean_9999\n",
    "    df['Current_Balance_Income_diff'] = df['Current_Balance35_mean_9999'] - df.Income26_mean_9999\n",
    "    df['CAPSLast180Days_nocrt_por'] = df['NonCreditCAPSLast180Days']/df['CAPSLast180Days']\n",
    "    df['CAPSLast180Days_apply_por'] = df['Amount_Financed35_count_9999']/df['CAPSLast180Days'] # 申请与查询次数占比\n",
    "    df['Duesum_days_mean'] = df['Duesum51_sum_9999'] / df['Duecount53_sum_9999']# 平均逾期天数 \n",
    "    df['Duesum_amt_mean'] = df['Days_Past_Due58_sum_9999'] / df['Income26_count_9999'] # 平均逾期额度 \n",
    "    \n",
    "    return  df,''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
